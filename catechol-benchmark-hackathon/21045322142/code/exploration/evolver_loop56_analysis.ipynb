{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bab1b01",
   "metadata": {},
   "source": [
    "# Loop 56 Analysis: Post-Chemical Constraints Assessment\n",
    "\n",
    "**Situation:**\n",
    "- 56 experiments completed, 25 consecutive failures since exp_030\n",
    "- Best LB: 0.0877 (exp_030), Target: 0.0347\n",
    "- Gap: 2.53x (0.0877 / 0.0347)\n",
    "- 5 submissions remaining\n",
    "- exp_055 (Chemical Constraints with Softmax) FAILED - CV 0.020769 (150% worse)\n",
    "\n",
    "**Key Finding from exp_055:**\n",
    "The targets DON'T sum to 1 (mean ~0.80), so softmax constraint is INCORRECT.\n",
    "\n",
    "**Questions:**\n",
    "1. What fundamentally different approaches remain?\n",
    "2. Can we change the CV-LB relationship?\n",
    "3. What do the top kernels do differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701020e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:17.441377Z",
     "iopub.status.busy": "2026-01-16T03:03:17.440646Z",
     "iopub.status.idle": "2026-01-16T03:03:18.728083Z",
     "shell.execute_reply": "2026-01-16T03:03:18.727511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n",
      "exp_026 0.0085 0.0887\n",
      "exp_030 0.0083 0.0877\n",
      "exp_035 0.0098 0.0970\n",
      "\n",
      "Target LB: 0.0347\n",
      "Best LB: 0.0877 (exp_030)\n",
      "Gap to target: 2.53x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nTarget LB: 0.0347\")\n",
    "print(f\"Best LB: {df['lb'].min():.4f} ({df.loc[df['lb'].idxmin(), 'exp']})\")\n",
    "print(f\"Gap to target: {df['lb'].min() / 0.0347:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9370c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.730161Z",
     "iopub.status.busy": "2026-01-16T03:03:18.729615Z",
     "iopub.status.idle": "2026-01-16T03:03:18.737082Z",
     "shell.execute_reply": "2026-01-16T03:03:18.736487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Linear Relationship:\n",
      "  LB = 4.31 * CV + 0.0525\n",
      "  R² = 0.9505\n",
      "  Intercept = 0.0525\n",
      "  Target LB = 0.0347\n",
      "\n",
      "CRITICAL INSIGHT:\n",
      "  Intercept (0.0525) > Target (0.0347)\n",
      "  This means even with CV=0, LB would be 0.0525 > 0.0347\n",
      "\n",
      "Required CV to hit target:\n",
      "  CV = (0.0347 - 0.0525) / 4.31 = -0.004130\n",
      "  NEGATIVE CV required - target is UNREACHABLE with current approach!\n"
     ]
    }
   ],
   "source": [
    "# CV-LB relationship analysis\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f\"CV-LB Linear Relationship:\")\n",
    "print(f\"  LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"  R² = {r_value**2:.4f}\")\n",
    "print(f\"  Intercept = {intercept:.4f}\")\n",
    "print(f\"  Target LB = 0.0347\")\n",
    "print(f\"\")\n",
    "print(f\"CRITICAL INSIGHT:\")\n",
    "print(f\"  Intercept ({intercept:.4f}) > Target ({0.0347})\")\n",
    "print(f\"  This means even with CV=0, LB would be {intercept:.4f} > 0.0347\")\n",
    "print(f\"\")\n",
    "print(f\"Required CV to hit target:\")\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f\"  CV = (0.0347 - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}\")\n",
    "if required_cv < 0:\n",
    "    print(f\"  NEGATIVE CV required - target is UNREACHABLE with current approach!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42609e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.738998Z",
     "iopub.status.busy": "2026-01-16T03:03:18.738815Z",
     "iopub.status.idle": "2026-01-16T03:03:18.745538Z",
     "shell.execute_reply": "2026-01-16T03:03:18.745065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS: What does 'mixall' kernel do differently?\n",
      "============================================================\n",
      "\n",
      "1. VALIDATION SCHEME:\n",
      "   - Our approach: Leave-One-Solvent-Out (24 folds for single, 13 for mixtures)\n",
      "   - mixall kernel: GroupKFold (5 splits)\n",
      "   - This is a LESS PESSIMISTIC CV scheme\n",
      "   - BUT: The LB evaluation uses the OFFICIAL scheme\n",
      "\n",
      "2. MODEL ARCHITECTURE:\n",
      "   - mixall uses: MLP + XGBoost + RandomForest + LightGBM ensemble\n",
      "   - Our best (exp_030): GP + MLP + LightGBM ensemble\n",
      "   - Key difference: mixall uses XGBoost and RandomForest\n",
      "\n",
      "3. FEATURE ENGINEERING:\n",
      "   - mixall uses: Spange descriptors only\n",
      "   - Our best: Spange + DRFP + ACS PCA + Arrhenius\n",
      "   - We have MORE features\n",
      "\n",
      "4. HYPERPARAMETER OPTIMIZATION:\n",
      "   - mixall uses: Optuna for hyperparameter tuning\n",
      "   - Our approach: Manual tuning\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the 'mixall' kernel does differently\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS: What does 'mixall' kernel do differently?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. VALIDATION SCHEME:\")\n",
    "print(\"   - Our approach: Leave-One-Solvent-Out (24 folds for single, 13 for mixtures)\")\n",
    "print(\"   - mixall kernel: GroupKFold (5 splits)\")\n",
    "print(\"   - This is a LESS PESSIMISTIC CV scheme\")\n",
    "print(\"   - BUT: The LB evaluation uses the OFFICIAL scheme\")\n",
    "\n",
    "print(\"\\n2. MODEL ARCHITECTURE:\")\n",
    "print(\"   - mixall uses: MLP + XGBoost + RandomForest + LightGBM ensemble\")\n",
    "print(\"   - Our best (exp_030): GP + MLP + LightGBM ensemble\")\n",
    "print(\"   - Key difference: mixall uses XGBoost and RandomForest\")\n",
    "\n",
    "print(\"\\n3. FEATURE ENGINEERING:\")\n",
    "print(\"   - mixall uses: Spange descriptors only\")\n",
    "print(\"   - Our best: Spange + DRFP + ACS PCA + Arrhenius\")\n",
    "print(\"   - We have MORE features\")\n",
    "\n",
    "print(\"\\n4. HYPERPARAMETER OPTIMIZATION:\")\n",
    "print(\"   - mixall uses: Optuna for hyperparameter tuning\")\n",
    "print(\"   - Our approach: Manual tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91956ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.747588Z",
     "iopub.status.busy": "2026-01-16T03:03:18.747231Z",
     "iopub.status.idle": "2026-01-16T03:03:18.756216Z",
     "shell.execute_reply": "2026-01-16T03:03:18.755736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CV-LB GAP ANALYSIS\n",
      "============================================================\n",
      "\n",
      "CV-LB Gap (LB/CV ratio):\n",
      "  exp_000: CV=0.0111, LB=0.0982, Gap=8.85x, Residual=-0.0022\n",
      "  exp_001: CV=0.0123, LB=0.1065, Gap=8.66x, Residual=0.0009\n",
      "  exp_003: CV=0.0105, LB=0.0972, Gap=9.26x, Residual=-0.0006\n",
      "  exp_005: CV=0.0104, LB=0.0969, Gap=9.32x, Residual=-0.0005\n",
      "  exp_006: CV=0.0097, LB=0.0946, Gap=9.75x, Residual=0.0002\n",
      "  exp_007: CV=0.0093, LB=0.0932, Gap=10.02x, Residual=0.0006\n",
      "  exp_009: CV=0.0092, LB=0.0936, Gap=10.17x, Residual=0.0014\n",
      "  exp_012: CV=0.0090, LB=0.0913, Gap=10.14x, Residual=-0.0001\n",
      "  exp_024: CV=0.0087, LB=0.0893, Gap=10.26x, Residual=-0.0008\n",
      "  exp_026: CV=0.0085, LB=0.0887, Gap=10.44x, Residual=-0.0005\n",
      "  exp_030: CV=0.0083, LB=0.0877, Gap=10.57x, Residual=-0.0006\n",
      "  exp_035: CV=0.0098, LB=0.0970, Gap=9.90x, Residual=0.0022\n",
      "\n",
      "Best residual (below regression line): exp_000 (-0.0022)\n",
      "Worst residual (above regression line): exp_035 (0.0022)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the CV-LB gap for different experiments\n",
    "print(\"=\"*60)\n",
    "print(\"CV-LB GAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df['gap'] = df['lb'] / df['cv']\n",
    "df['residual'] = df['lb'] - (slope * df['cv'] + intercept)\n",
    "\n",
    "print(\"\\nCV-LB Gap (LB/CV ratio):\")\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"  {row['exp']}: CV={row['cv']:.4f}, LB={row['lb']:.4f}, Gap={row['gap']:.2f}x, Residual={row['residual']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest residual (below regression line): {df.loc[df['residual'].idxmin(), 'exp']} ({df['residual'].min():.4f})\")\n",
    "print(f\"Worst residual (above regression line): {df.loc[df['residual'].idxmax(), 'exp']} ({df['residual'].max():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37eaceec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.758049Z",
     "iopub.status.busy": "2026-01-16T03:03:18.757652Z",
     "iopub.status.idle": "2026-01-16T03:03:18.763808Z",
     "shell.execute_reply": "2026-01-16T03:03:18.763312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACHES NOT YET TRIED\n",
      "============================================================\n",
      "\n",
      "1. DIFFERENT ENSEMBLE MEMBERS:\n",
      "   - XGBoost (used in mixall, not in our best model)\n",
      "   - RandomForest (used in mixall, not in our best model)\n",
      "   - CatBoost (not tried)\n",
      "\n",
      "2. DIFFERENT LOSS FUNCTIONS:\n",
      "   - Quantile loss (for uncertainty estimation)\n",
      "   - Asymmetric loss (penalize over/under predictions differently)\n",
      "   - Focal loss (focus on hard examples)\n",
      "\n",
      "3. DIFFERENT VALIDATION SCHEMES:\n",
      "   - GroupKFold (like mixall) - but this is a gray area in rules\n",
      "   - Stratified by target values\n",
      "   - Time-based splits (if there's temporal structure)\n",
      "\n",
      "4. POST-PROCESSING:\n",
      "   - Prediction calibration (isotonic regression)\n",
      "   - Ensemble of predictions from different CV folds\n",
      "   - Prediction clipping/normalization\n",
      "\n",
      "5. DOMAIN-SPECIFIC APPROACHES:\n",
      "   - Physics-informed constraints (NOT sum-to-1, but other constraints)\n",
      "   - Solvent similarity-based weighting\n",
      "   - Transfer learning from related datasets\n"
     ]
    }
   ],
   "source": [
    "# What approaches have NOT been tried?\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES NOT YET TRIED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. DIFFERENT ENSEMBLE MEMBERS:\")\n",
    "print(\"   - XGBoost (used in mixall, not in our best model)\")\n",
    "print(\"   - RandomForest (used in mixall, not in our best model)\")\n",
    "print(\"   - CatBoost (not tried)\")\n",
    "\n",
    "print(\"\\n2. DIFFERENT LOSS FUNCTIONS:\")\n",
    "print(\"   - Quantile loss (for uncertainty estimation)\")\n",
    "print(\"   - Asymmetric loss (penalize over/under predictions differently)\")\n",
    "print(\"   - Focal loss (focus on hard examples)\")\n",
    "\n",
    "print(\"\\n3. DIFFERENT VALIDATION SCHEMES:\")\n",
    "print(\"   - GroupKFold (like mixall) - but this is a gray area in rules\")\n",
    "print(\"   - Stratified by target values\")\n",
    "print(\"   - Time-based splits (if there's temporal structure)\")\n",
    "\n",
    "print(\"\\n4. POST-PROCESSING:\")\n",
    "print(\"   - Prediction calibration (isotonic regression)\")\n",
    "print(\"   - Ensemble of predictions from different CV folds\")\n",
    "print(\"   - Prediction clipping/normalization\")\n",
    "\n",
    "print(\"\\n5. DOMAIN-SPECIFIC APPROACHES:\")\n",
    "print(\"   - Physics-informed constraints (NOT sum-to-1, but other constraints)\")\n",
    "print(\"   - Solvent similarity-based weighting\")\n",
    "print(\"   - Transfer learning from related datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054fb6c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.765327Z",
     "iopub.status.busy": "2026-01-16T03:03:18.765162Z",
     "iopub.status.idle": "2026-01-16T03:03:18.770777Z",
     "shell.execute_reply": "2026-01-16T03:03:18.770240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STRATEGIC RECOMMENDATIONS FOR LOOP 56\n",
      "============================================================\n",
      "\n",
      "1. TRY XGBOOST + RANDOMFOREST IN ENSEMBLE:\n",
      "   - The mixall kernel uses these, we don't\n",
      "   - Could provide different inductive biases\n",
      "   - May have different CV-LB relationship\n",
      "\n",
      "2. TRY PREDICTION CALIBRATION:\n",
      "   - Use isotonic regression to calibrate predictions\n",
      "   - This explicitly corrects systematic bias\n",
      "   - Could reduce the intercept in CV-LB relationship\n",
      "\n",
      "3. TRY DIFFERENT LOSS FUNCTION:\n",
      "   - Quantile loss for uncertainty estimation\n",
      "   - May produce more robust predictions\n",
      "\n",
      "4. TRY OPTUNA HYPERPARAMETER OPTIMIZATION:\n",
      "   - The mixall kernel uses this\n",
      "   - Could find better hyperparameters\n",
      "\n",
      "5. SUBMISSION STRATEGY:\n",
      "   - 5 submissions remaining\n",
      "   - Try 2-3 fundamentally different approaches\n",
      "   - Save 2 submissions for final attempts\n"
     ]
    }
   ],
   "source": [
    "# Strategic recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIC RECOMMENDATIONS FOR LOOP 56\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. TRY XGBOOST + RANDOMFOREST IN ENSEMBLE:\")\n",
    "print(\"   - The mixall kernel uses these, we don't\")\n",
    "print(\"   - Could provide different inductive biases\")\n",
    "print(\"   - May have different CV-LB relationship\")\n",
    "\n",
    "print(\"\\n2. TRY PREDICTION CALIBRATION:\")\n",
    "print(\"   - Use isotonic regression to calibrate predictions\")\n",
    "print(\"   - This explicitly corrects systematic bias\")\n",
    "print(\"   - Could reduce the intercept in CV-LB relationship\")\n",
    "\n",
    "print(\"\\n3. TRY DIFFERENT LOSS FUNCTION:\")\n",
    "print(\"   - Quantile loss for uncertainty estimation\")\n",
    "print(\"   - May produce more robust predictions\")\n",
    "\n",
    "print(\"\\n4. TRY OPTUNA HYPERPARAMETER OPTIMIZATION:\")\n",
    "print(\"   - The mixall kernel uses this\")\n",
    "print(\"   - Could find better hyperparameters\")\n",
    "\n",
    "print(\"\\n5. SUBMISSION STRATEGY:\")\n",
    "print(\"   - 5 submissions remaining\")\n",
    "print(\"   - Try 2-3 fundamentally different approaches\")\n",
    "print(\"   - Save 2 submissions for final attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d51d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T03:03:18.772579Z",
     "iopub.status.busy": "2026-01-16T03:03:18.772413Z",
     "iopub.status.idle": "2026-01-16T03:03:18.778487Z",
     "shell.execute_reply": "2026-01-16T03:03:18.778019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOOP 56 SUMMARY\n",
      "============================================================\n",
      "\n",
      "Current Status:\n",
      "  - Best CV: 0.008298 (exp_030)\n",
      "  - Best LB: 0.0877 (exp_030)\n",
      "  - Target LB: 0.0347\n",
      "  - Gap: 2.53x\n",
      "  - Submissions remaining: 5\n",
      "  - Consecutive failures: 25\n",
      "\n",
      "Key Findings:\n",
      "  1. CV-LB relationship: LB = 4.31*CV + 0.0525\n",
      "  2. Intercept (0.0525) > Target (0.0347) - target unreachable with current approach\n",
      "  3. exp_055 (softmax constraint) FAILED because targets don't sum to 1\n",
      "  4. The 'mixall' kernel uses different ensemble members (XGBoost, RF)\n",
      "\n",
      "Recommended Next Steps:\n",
      "  1. Try XGBoost + RandomForest in ensemble (like mixall)\n",
      "  2. Try prediction calibration (isotonic regression)\n",
      "  3. Try Optuna hyperparameter optimization\n",
      "  4. Focus on approaches that might change the CV-LB relationship\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"LOOP 56 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCurrent Status:\")\n",
    "print(f\"  - Best CV: 0.008298 (exp_030)\")\n",
    "print(f\"  - Best LB: 0.0877 (exp_030)\")\n",
    "print(f\"  - Target LB: 0.0347\")\n",
    "print(f\"  - Gap: 2.53x\")\n",
    "print(f\"  - Submissions remaining: 5\")\n",
    "print(f\"  - Consecutive failures: 25\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"  1. CV-LB relationship: LB = 4.31*CV + 0.0525\")\n",
    "print(\"  2. Intercept (0.0525) > Target (0.0347) - target unreachable with current approach\")\n",
    "print(\"  3. exp_055 (softmax constraint) FAILED because targets don't sum to 1\")\n",
    "print(\"  4. The 'mixall' kernel uses different ensemble members (XGBoost, RF)\")\n",
    "\n",
    "print(\"\\nRecommended Next Steps:\")\n",
    "print(\"  1. Try XGBoost + RandomForest in ensemble (like mixall)\")\n",
    "print(\"  2. Try prediction calibration (isotonic regression)\")\n",
    "print(\"  3. Try Optuna hyperparameter optimization\")\n",
    "print(\"  4. Focus on approaches that might change the CV-LB relationship\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
