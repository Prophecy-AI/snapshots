{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29aa293d",
   "metadata": {},
   "source": [
    "# Loop 25 LB Feedback Analysis\n",
    "\n",
    "**exp_024 submitted**: CV 0.0087 → LB 0.0893 (gap: -0.0806)\n",
    "\n",
    "This is our BEST LB score yet! Let's analyze the trajectory and plan next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2a7e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:20.062802Z",
     "iopub.status.busy": "2026-01-14T03:20:20.062088Z",
     "iopub.status.idle": "2026-01-14T03:20:21.184360Z",
     "shell.execute_reply": "2026-01-14T03:20:21.183810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBMISSION HISTORY ===\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n",
      "\n",
      "Best CV: 0.0087 (exp_024)\n",
      "Best LB: 0.0893 (exp_024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},  # NEW!\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== SUBMISSION HISTORY ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.4f} ({df.loc[df[\"cv\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} ({df.loc[df[\"lb\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d7f1cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.186671Z",
     "iopub.status.busy": "2026-01-14T03:20:21.186122Z",
     "iopub.status.idle": "2026-01-14T03:20:21.193212Z",
     "shell.execute_reply": "2026-01-14T03:20:21.192716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UPDATED CV-LB LINEAR FIT ===\n",
      "LB = 4.19 * CV + 0.0537\n",
      "R² = 0.9551\n",
      "Slope std error: 0.3431\n",
      "CV 0.008 → Predicted LB 0.0872\n",
      "CV 0.007 → Predicted LB 0.0830\n",
      "CV 0.006 → Predicted LB 0.0788\n",
      "CV 0.005 → Predicted LB 0.0746\n",
      "CV 0.004 → Predicted LB 0.0704\n",
      "CV 0.003 → Predicted LB 0.0662\n",
      "\n",
      "To beat target 0.01727: need CV < -0.008685\n"
     ]
    }
   ],
   "source": [
    "# Updated CV-LB linear fit with new data point\n",
    "cv_scores = df['cv'].values\n",
    "lb_scores = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print('=== UPDATED CV-LB LINEAR FIT ===')\n",
    "print(f'LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Slope std error: {std_err:.4f}')\n",
    "\n",
    "# Prediction for various CV scores\n",
    "for cv in [0.008, 0.007, 0.006, 0.005, 0.004, 0.003]:\n",
    "    pred_lb = slope * cv + intercept\n",
    "    print(f'CV {cv:.3f} → Predicted LB {pred_lb:.4f}')\n",
    "\n",
    "# What CV do we need to beat target 0.01727?\n",
    "target = 0.01727\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\nTo beat target {target}: need CV < {required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfbce69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.194948Z",
     "iopub.status.busy": "2026-01-14T03:20:21.194777Z",
     "iopub.status.idle": "2026-01-14T03:20:21.202015Z",
     "shell.execute_reply": "2026-01-14T03:20:21.201463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONFIDENCE INTERVALS ===\n",
      "Standard error of estimate: 0.001128\n",
      "Mean CV: 0.010022\n",
      "SS_CV: 0.0000108156\n",
      "\n",
      "Intercept 95% CI: [0.0455, 0.0618]\n",
      "Slope 95% CI: [3.38, 5.00]\n"
     ]
    }
   ],
   "source": [
    "# Confidence intervals for the linear fit\n",
    "n = len(cv_scores)\n",
    "mean_cv = np.mean(cv_scores)\n",
    "ss_cv = np.sum((cv_scores - mean_cv)**2)\n",
    "\n",
    "# Standard error of the estimate\n",
    "residuals = lb_scores - (slope * cv_scores + intercept)\n",
    "mse_residuals = np.sum(residuals**2) / (n - 2)\n",
    "se_estimate = np.sqrt(mse_residuals)\n",
    "\n",
    "print('=== CONFIDENCE INTERVALS ===')\n",
    "print(f'Standard error of estimate: {se_estimate:.6f}')\n",
    "print(f'Mean CV: {mean_cv:.6f}')\n",
    "print(f'SS_CV: {ss_cv:.10f}')\n",
    "\n",
    "# 95% CI for intercept\n",
    "t_crit = stats.t.ppf(0.975, n - 2)\n",
    "se_intercept = se_estimate * np.sqrt(1/n + mean_cv**2/ss_cv)\n",
    "ci_intercept = (intercept - t_crit * se_intercept, intercept + t_crit * se_intercept)\n",
    "print(f'\\nIntercept 95% CI: [{ci_intercept[0]:.4f}, {ci_intercept[1]:.4f}]')\n",
    "\n",
    "# 95% CI for slope\n",
    "se_slope = se_estimate / np.sqrt(ss_cv)\n",
    "ci_slope = (slope - t_crit * se_slope, slope + t_crit * se_slope)\n",
    "print(f'Slope 95% CI: [{ci_slope[0]:.2f}, {ci_slope[1]:.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97fed6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.203561Z",
     "iopub.status.busy": "2026-01-14T03:20:21.203399Z",
     "iopub.status.idle": "2026-01-14T03:20:21.210343Z",
     "shell.execute_reply": "2026-01-14T03:20:21.209815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPROVEMENT TRAJECTORY ===\n",
      "exp_000 → exp_001: CV +10.81%, LB +8.45%\n",
      "exp_001 → exp_003: CV -14.63%, LB -8.73%\n",
      "exp_003 → exp_005: CV -0.95%, LB -0.31%\n",
      "exp_005 → exp_006: CV -6.73%, LB -2.37%\n",
      "exp_006 → exp_007: CV -4.12%, LB -1.48%\n",
      "exp_007 → exp_009: CV -1.08%, LB +0.43%\n",
      "exp_009 → exp_012: CV -2.17%, LB -2.46%\n",
      "exp_012 → exp_024: CV -3.33%, LB -2.19%\n",
      "\n",
      "Overall: CV -21.6%, LB -9.1%\n"
     ]
    }
   ],
   "source": [
    "# Analyze improvement trajectory\n",
    "print('=== IMPROVEMENT TRAJECTORY ===')\n",
    "for i in range(1, len(df)):\n",
    "    prev = df.iloc[i-1]\n",
    "    curr = df.iloc[i]\n",
    "    cv_change = (curr['cv'] - prev['cv']) / prev['cv'] * 100\n",
    "    lb_change = (curr['lb'] - prev['lb']) / prev['lb'] * 100\n",
    "    print(f\"{prev['exp']} → {curr['exp']}: CV {cv_change:+.2f}%, LB {lb_change:+.2f}%\")\n",
    "\n",
    "# Overall improvement\n",
    "first = df.iloc[0]\n",
    "last = df.iloc[-1]\n",
    "print(f\"\\nOverall: CV {(last['cv']-first['cv'])/first['cv']*100:+.1f}%, LB {(last['lb']-first['lb'])/first['lb']*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913f5d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.211751Z",
     "iopub.status.busy": "2026-01-14T03:20:21.211574Z",
     "iopub.status.idle": "2026-01-14T03:20:21.217073Z",
     "shell.execute_reply": "2026-01-14T03:20:21.216573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GAP TO TARGET ===\n",
      "Target: 0.01727\n",
      "Best LB: 0.0893\n",
      "Gap: 0.0720 (417.1% above target)\n",
      "Ratio: 5.17x\n",
      "\n",
      "Need to improve LB by 80.7% to reach target\n"
     ]
    }
   ],
   "source": [
    "# Gap to target analysis\n",
    "print('=== GAP TO TARGET ===')\n",
    "target = 0.01727\n",
    "best_lb = df['lb'].min()\n",
    "gap = best_lb - target\n",
    "gap_pct = gap / target * 100\n",
    "\n",
    "print(f'Target: {target}')\n",
    "print(f'Best LB: {best_lb:.4f}')\n",
    "print(f'Gap: {gap:.4f} ({gap_pct:.1f}% above target)')\n",
    "print(f'Ratio: {best_lb/target:.2f}x')\n",
    "\n",
    "# How much improvement needed?\n",
    "improvement_needed = (best_lb - target) / best_lb * 100\n",
    "print(f'\\nNeed to improve LB by {improvement_needed:.1f}% to reach target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dafd17f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.218672Z",
     "iopub.status.busy": "2026-01-14T03:20:21.218513Z",
     "iopub.status.idle": "2026-01-14T03:20:21.223781Z",
     "shell.execute_reply": "2026-01-14T03:20:21.223205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. 4-Model Ensemble (MLP + XGB + RF + LGBM)\n",
      "   - Current: MLP + LGBM only\n",
      "   - Potential: More diversity in ensemble\n",
      "\n",
      "2. Per-Target Models\n",
      "   - SM has different characteristics (mean 0.52) vs Products (mean 0.13)\n",
      "   - Competition explicitly allows different hyperparameters per target\n",
      "\n",
      "3. Stacking Meta-Learner\n",
      "   - Current: Fixed weights (0.6 MLP + 0.4 LGBM)\n",
      "   - Potential: Learn optimal weights from OOF predictions\n",
      "\n",
      "4. Non-linear Mixture Encoding\n",
      "   - Current: Linear interpolation A*(1-pct) + B*pct\n",
      "   - Potential: Add interaction term A*B*pct*(1-pct)\n",
      "\n",
      "5. Larger MLP Ensemble\n",
      "   - Current: 5 MLPs\n",
      "   - Potential: 10-15 MLPs for variance reduction\n",
      "\n",
      "6. Different Feature Subsets\n",
      "   - Try DRFP-only, Spange-only, ACS-only models\n",
      "   - Ensemble models trained on different feature sets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('''\n",
    "1. 4-Model Ensemble (MLP + XGB + RF + LGBM)\n",
    "   - Current: MLP + LGBM only\n",
    "   - Potential: More diversity in ensemble\n",
    "\n",
    "2. Per-Target Models\n",
    "   - SM has different characteristics (mean 0.52) vs Products (mean 0.13)\n",
    "   - Competition explicitly allows different hyperparameters per target\n",
    "\n",
    "3. Stacking Meta-Learner\n",
    "   - Current: Fixed weights (0.6 MLP + 0.4 LGBM)\n",
    "   - Potential: Learn optimal weights from OOF predictions\n",
    "\n",
    "4. Non-linear Mixture Encoding\n",
    "   - Current: Linear interpolation A*(1-pct) + B*pct\n",
    "   - Potential: Add interaction term A*B*pct*(1-pct)\n",
    "\n",
    "5. Larger MLP Ensemble\n",
    "   - Current: 5 MLPs\n",
    "   - Potential: 10-15 MLPs for variance reduction\n",
    "\n",
    "6. Different Feature Subsets\n",
    "   - Try DRFP-only, Spange-only, ACS-only models\n",
    "   - Ensemble models trained on different feature sets\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa75a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:20:21.225255Z",
     "iopub.status.busy": "2026-01-14T03:20:21.225089Z",
     "iopub.status.idle": "2026-01-14T03:20:21.230341Z",
     "shell.execute_reply": "2026-01-14T03:20:21.229854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRIORITY RANKING ===\n",
      "\n",
      "HIGH IMPACT (try first):\n",
      "1. 4-Model Ensemble - More model diversity typically helps\n",
      "2. Per-Target Models - Exploit target-specific patterns\n",
      "3. Stacking Meta-Learner - Learn optimal combination\n",
      "\n",
      "MEDIUM IMPACT:\n",
      "4. Non-linear Mixture Encoding - May capture interaction effects\n",
      "5. Larger MLP Ensemble - Variance reduction\n",
      "\n",
      "LOW IMPACT (already tried variations):\n",
      "6. Different architectures - Already optimized\n",
      "7. Different features - ACS PCA already added\n",
      "\n",
      "\n",
      "=== RECOMMENDED NEXT EXPERIMENT ===\n",
      "\n",
      "exp_025: 4-Model Ensemble with ACS PCA Features\n",
      "- MLP (5 models, [32,16])\n",
      "- LightGBM\n",
      "- XGBoost\n",
      "- Random Forest\n",
      "- Weights: MLP 0.4, XGB 0.2, RF 0.2, LGBM 0.2\n",
      "- Expected CV improvement: 2-5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Priority ranking based on expected impact\n",
    "print('=== PRIORITY RANKING ===')\n",
    "print('''\n",
    "HIGH IMPACT (try first):\n",
    "1. 4-Model Ensemble - More model diversity typically helps\n",
    "2. Per-Target Models - Exploit target-specific patterns\n",
    "3. Stacking Meta-Learner - Learn optimal combination\n",
    "\n",
    "MEDIUM IMPACT:\n",
    "4. Non-linear Mixture Encoding - May capture interaction effects\n",
    "5. Larger MLP Ensemble - Variance reduction\n",
    "\n",
    "LOW IMPACT (already tried variations):\n",
    "6. Different architectures - Already optimized\n",
    "7. Different features - ACS PCA already added\n",
    "''')\n",
    "\n",
    "print('\\n=== RECOMMENDED NEXT EXPERIMENT ===')\n",
    "print('''\n",
    "exp_025: 4-Model Ensemble with ACS PCA Features\n",
    "- MLP (5 models, [32,16])\n",
    "- LightGBM\n",
    "- XGBoost\n",
    "- Random Forest\n",
    "- Weights: MLP 0.4, XGB 0.2, RF 0.2, LGBM 0.2\n",
    "- Expected CV improvement: 2-5%\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
