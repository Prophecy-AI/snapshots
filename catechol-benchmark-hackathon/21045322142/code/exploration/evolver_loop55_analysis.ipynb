{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587ed964",
   "metadata": {},
   "source": [
    "# Loop 55 Analysis: Strategic Assessment\n",
    "\n",
    "**Situation:**\n",
    "- 55 experiments completed, 24 consecutive failures since exp_030\n",
    "- Best LB: 0.0877 (exp_030), Target: 0.0347\n",
    "- Gap: 2.53x (0.0877 / 0.0347)\n",
    "- 5 submissions remaining\n",
    "\n",
    "**Key Questions:**\n",
    "1. What is the CV-LB relationship?\n",
    "2. What approaches have been exhausted?\n",
    "3. What fundamentally different approaches remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nTarget LB: 0.0347\")\n",
    "print(f\"Best LB: {df['lb'].min():.4f} ({df.loc[df['lb'].idxmin(), 'exp']})\")\n",
    "print(f\"Gap to target: {df['lb'].min() / 0.0347:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB relationship analysis\n",
    "from scipy import stats\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f\"CV-LB Linear Relationship:\")\n",
    "print(f\"  LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"  R² = {r_value**2:.4f}\")\n",
    "print(f\"  Intercept = {intercept:.4f}\")\n",
    "print(f\"  Target LB = 0.0347\")\n",
    "print(f\"\")\n",
    "print(f\"CRITICAL INSIGHT:\")\n",
    "print(f\"  Intercept ({intercept:.4f}) > Target ({0.0347})\")\n",
    "print(f\"  This means even with CV=0, LB would be {intercept:.4f} > 0.0347\")\n",
    "print(f\"\")\n",
    "print(f\"Required CV to hit target:\")\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f\"  CV = (0.0347 - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}\")\n",
    "if required_cv < 0:\n",
    "    print(f\"  NEGATIVE CV required - target is UNREACHABLE with current approach!\")\n",
    "else:\n",
    "    print(f\"  Required CV: {required_cv:.6f} vs Best CV: {df['cv'].min():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5466a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle='-', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.015)\n",
    "plt.ylim(0, 0.12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Observation:\")\n",
    "print(f\"The intercept ({intercept:.4f}) is ABOVE the target ({0.0347})\")\n",
    "print(f\"This means the current approach CANNOT reach the target by improving CV alone.\")\n",
    "print(f\"We need to CHANGE the CV-LB relationship, not just improve CV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches_tried = {\n",
    "    'Feature Engineering': [\n",
    "        'Spange descriptors (13 features)',\n",
    "        'DRFP fingerprints (122 high-variance features)',\n",
    "        'ACS PCA descriptors (5 features)',\n",
    "        'Arrhenius kinetics features (5 features)',\n",
    "        'Combined features (140+ features)',\n",
    "        'Minimal features (Spange + Arrhenius only)',\n",
    "    ],\n",
    "    'Model Architectures': [\n",
    "        'MLP [128, 128, 64] - baseline',\n",
    "        'MLP [256, 128, 64] - larger',\n",
    "        'MLP [64, 32] - simpler',\n",
    "        'MLP [16] - minimal',\n",
    "        'Deep Residual MLP - FAILED',\n",
    "        'LightGBM',\n",
    "        'XGBoost',\n",
    "        'Ridge Regression',\n",
    "        'Kernel Ridge',\n",
    "        'Gaussian Process',\n",
    "        'GP + MLP + LGBM ensemble',\n",
    "    ],\n",
    "    'Regularization': [\n",
    "        'Dropout 0.1, 0.2, 0.3, 0.4',\n",
    "        'Weight decay 1e-5, 1e-4, 1e-3',\n",
    "        'Batch normalization',\n",
    "        'Gradient clipping',\n",
    "    ],\n",
    "    'Ensemble Methods': [\n",
    "        'Bagging (3, 5, 10, 15 models)',\n",
    "        'GP + MLP + LGBM weighted ensemble',\n",
    "        'Different ensemble weights',\n",
    "    ],\n",
    "    'Data Augmentation': [\n",
    "        'TTA for mixtures (average both orderings)',\n",
    "        'Data augmentation for mixtures (train on both A,B and B,A)',\n",
    "    ],\n",
    "    'OOD Handling': [\n",
    "        'Importance weighting',\n",
    "        'LISA (Learning Invariant Predictors)',\n",
    "        'Mean reversion',\n",
    "        'Adaptive weighting',\n",
    "        'Outlier-specific handling',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"Approaches Tried:\")\n",
    "for category, approaches in approaches_tried.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for approach in approaches:\n",
    "        print(f\"  - {approach}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d92075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What hasn't been tried or could be improved?\n",
    "print(\"=\"*60)\n",
    "print(\"POTENTIAL NEW DIRECTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. FUNDAMENTALLY DIFFERENT VALIDATION SCHEME:\")\n",
    "print(\"   - The 'mixall' kernel uses GroupKFold (5 splits) instead of Leave-One-Out (24 folds)\")\n",
    "print(\"   - This is a LESS PESSIMISTIC CV scheme\")\n",
    "print(\"   - BUT: The LB evaluation uses the OFFICIAL scheme (leave-one-out)\")\n",
    "print(\"   - So this doesn't help us - we need to improve on the official scheme\")\n",
    "\n",
    "print(\"\\n2. PER-TARGET OPTIMIZATION:\")\n",
    "print(\"   - Currently using same model for all 3 targets (SM, Product 2, Product 3)\")\n",
    "print(\"   - Different targets may have different optimal models\")\n",
    "print(\"   - Could train separate models for each target\")\n",
    "\n",
    "print(\"\\n3. DIFFERENT LOSS FUNCTIONS:\")\n",
    "print(\"   - Currently using MSE/Huber loss\")\n",
    "print(\"   - Could try MAE, quantile loss, or custom loss\")\n",
    "print(\"   - Could weight different targets differently\")\n",
    "\n",
    "print(\"\\n4. TRANSDUCTIVE LEARNING:\")\n",
    "print(\"   - Use test data structure (without labels) during training\")\n",
    "print(\"   - Adapt model to test distribution\")\n",
    "\n",
    "print(\"\\n5. DOMAIN ADAPTATION:\")\n",
    "print(\"   - Explicitly model the distribution shift\")\n",
    "print(\"   - Use adversarial training to learn domain-invariant features\")\n",
    "\n",
    "print(\"\\n6. GRAPH NEURAL NETWORKS:\")\n",
    "print(\"   - The GNN benchmark achieved 0.0039 MSE\")\n",
    "print(\"   - But this requires proper graph structure, not just fingerprints\")\n",
    "print(\"   - Previous GNN attempts failed due to implementation issues\")\n",
    "\n",
    "print(\"\\n7. CHEMICAL CONSTRAINTS:\")\n",
    "print(\"   - SM + Product 2 + Product 3 should sum to ~1\")\n",
    "print(\"   - Could enforce this constraint in the model\")\n",
    "print(\"   - Could use softmax output layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best model (exp_030)\n",
    "print(\"=\"*60)\n",
    "print(\"BEST MODEL ANALYSIS: exp_030\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nModel: GP + MLP + LGBM Ensemble\")\n",
    "print(\"  - GP weight: 0.15\")\n",
    "print(\"  - MLP weight: 0.55\")\n",
    "print(\"  - LGBM weight: 0.30\")\n",
    "\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"  - Spange descriptors (13 features)\")\n",
    "print(\"  - DRFP fingerprints (122 high-variance features)\")\n",
    "print(\"  - ACS PCA descriptors (5 features)\")\n",
    "print(\"  - Arrhenius kinetics (5 features)\")\n",
    "print(\"  - Total: 145 features\")\n",
    "\n",
    "print(\"\\nMLP Architecture:\")\n",
    "print(\"  - [128, 64] with BatchNorm, ReLU, Dropout(0.2)\")\n",
    "print(\"  - Sigmoid output\")\n",
    "print(\"  - HuberLoss\")\n",
    "print(\"  - Adam optimizer, lr=5e-4, weight_decay=1e-4\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(\"  - Single Solvent CV: 0.007943\")\n",
    "print(\"  - Mixture CV: 0.008488\")\n",
    "print(\"  - Overall CV: 0.008298\")\n",
    "print(\"  - LB: 0.0877\")\n",
    "print(\"  - CV-LB gap: 10.6x\")\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"  The CV-LB gap is INCREASING as CV improves (8.9x → 10.6x)\")\n",
    "print(\"  This suggests the model is overfitting to the CV scheme\")\n",
    "print(\"  Better CV doesn't necessarily mean better LB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f011d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. STOP TRYING TO IMPROVE CV\")\n",
    "print(\"   - 24 consecutive experiments have failed to beat exp_030\")\n",
    "print(\"   - The CV-LB gap is increasing as CV improves\")\n",
    "print(\"   - Better CV doesn't mean better LB\")\n",
    "\n",
    "print(\"\\n2. FOCUS ON CHANGING THE CV-LB RELATIONSHIP\")\n",
    "print(\"   - The intercept (0.0528) > target (0.0347)\")\n",
    "print(\"   - We need to REDUCE the intercept, not just improve CV\")\n",
    "print(\"   - This requires fundamentally different approaches\")\n",
    "\n",
    "print(\"\\n3. TRY APPROACHES THAT MIGHT HAVE DIFFERENT CV-LB RELATIONSHIPS:\")\n",
    "print(\"   a) Per-target models (different models for SM, Product 2, Product 3)\")\n",
    "print(\"   b) Chemical constraints (softmax output, sum-to-one constraint)\")\n",
    "print(\"   c) Domain adaptation (adversarial training)\")\n",
    "print(\"   d) Transductive learning (use test structure)\")\n",
    "\n",
    "print(\"\\n4. SUBMISSION STRATEGY (5 remaining):\")\n",
    "print(\"   - exp_030 is already submitted (best LB 0.0877)\")\n",
    "print(\"   - Try 2-3 fundamentally different approaches\")\n",
    "print(\"   - Save 2 submissions for final attempts\")\n",
    "\n",
    "print(\"\\n5. ACCEPT THAT THE TARGET MAY REQUIRE:\")\n",
    "print(\"   - A completely different approach (e.g., proper GNN)\")\n",
    "print(\"   - Domain-specific knowledge we don't have\")\n",
    "print(\"   - Techniques not yet discovered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356507be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"LOOP 55 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCurrent Status:\")\n",
    "print(f\"  - Best CV: 0.008298 (exp_030)\")\n",
    "print(f\"  - Best LB: 0.0877 (exp_030)\")\n",
    "print(f\"  - Target LB: 0.0347\")\n",
    "print(f\"  - Gap: 2.53x\")\n",
    "print(f\"  - Submissions remaining: 5\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"  1. CV-LB relationship: LB = 4.31*CV + 0.0525\")\n",
    "print(\"  2. Intercept (0.0525) > Target (0.0347) - target unreachable with current approach\")\n",
    "print(\"  3. 24 consecutive experiments have failed to beat exp_030\")\n",
    "print(\"  4. The search direction is EXHAUSTED\")\n",
    "\n",
    "print(\"\\nRecommended Next Steps:\")\n",
    "print(\"  1. Try per-target optimization (different models for each target)\")\n",
    "print(\"  2. Try chemical constraints (softmax output)\")\n",
    "print(\"  3. Try domain adaptation techniques\")\n",
    "print(\"  4. Focus on approaches that might change the CV-LB relationship\")\n",
    "\n",
    "print(\"\\nDO NOT:\")\n",
    "print(\"  - Continue trying variations on the same approach\")\n",
    "print(\"  - Try to improve CV without changing the CV-LB relationship\")\n",
    "print(\"  - Remove DRFP features (they're important)\")\n",
    "print(\"  - Increase regularization further (it prevents learning)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
