{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50939be",
   "metadata": {},
   "source": [
    "# Loop 41 Analysis: GNN Failed - What Next?\n",
    "\n",
    "**Situation:**\n",
    "- GNN (AttentiveFP) test fold MSE: 0.068767 (8.4x WORSE than baseline)\n",
    "- Best CV: 0.008194 (exp_035)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.30*CV + 0.0524 (R²=0.97)\n",
    "- Submissions remaining: 4\n",
    "\n",
    "**Key Question:** Why did GNN fail when the benchmark achieved MSE 0.0039?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fd6623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:43.131036Z",
     "iopub.status.busy": "2026-01-15T05:06:43.130781Z",
     "iopub.status.idle": "2026-01-15T05:06:44.240779Z",
     "shell.execute_reply": "2026-01-15T05:06:44.240248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "        exp      cv      lb\n",
      "0   exp_000  0.0111  0.0982\n",
      "1   exp_001  0.0123  0.1065\n",
      "2   exp_003  0.0105  0.0972\n",
      "3   exp_005  0.0104  0.0969\n",
      "4   exp_006  0.0097  0.0946\n",
      "5   exp_007  0.0093  0.0932\n",
      "6   exp_009  0.0092  0.0936\n",
      "7   exp_012  0.0090  0.0913\n",
      "8   exp_024  0.0087  0.0893\n",
      "9   exp_026  0.0085  0.0887\n",
      "10  exp_030  0.0083  0.0877\n",
      "11  exp_035  0.0098  0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV-LB Relationship: LB = 4.31*CV + 0.0525 (R²=0.951)\n",
      "Intercept: 0.0525\n",
      "Target: 0.0347\n",
      "Gap: Intercept is 1.51x larger than target\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df)\n",
    "\n",
    "# Linear fit\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: Intercept is {intercept/0.0347:.2f}x larger than target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064d483a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.243065Z",
     "iopub.status.busy": "2026-01-15T05:06:44.242392Z",
     "iopub.status.idle": "2026-01-15T05:06:44.247093Z",
     "shell.execute_reply": "2026-01-15T05:06:44.246574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GNN FAILURE ANALYSIS ===\n",
      "\n",
      "GNN Test Fold MSE: 0.068767\n",
      "Baseline (exp_035) CV: 0.008194\n",
      "GNN is 8.4x WORSE than baseline\n",
      "\n",
      "Possible reasons for GNN failure:\n",
      "1. Training data too small (~619 samples) for GNN to learn meaningful representations\n",
      "2. Leave-one-solvent-out CV is extremely challenging for GNN\n",
      "3. The GNN benchmark may have used different CV scheme (not leave-one-solvent-out)\n",
      "4. AttentiveFP may need more training epochs or different hyperparameters\n",
      "5. The molecular graphs may need more sophisticated features\n",
      "\n",
      "Key insight: The GNN benchmark (MSE 0.0039) may have used a different evaluation scheme!\n",
      "Our leave-one-solvent-out CV is MUCH harder than standard random splits.\n"
     ]
    }
   ],
   "source": [
    "# Analyze GNN failure\n",
    "print('=== GNN FAILURE ANALYSIS ===')\n",
    "print()\n",
    "print('GNN Test Fold MSE: 0.068767')\n",
    "print('Baseline (exp_035) CV: 0.008194')\n",
    "print('GNN is 8.4x WORSE than baseline')\n",
    "print()\n",
    "print('Possible reasons for GNN failure:')\n",
    "print('1. Training data too small (~619 samples) for GNN to learn meaningful representations')\n",
    "print('2. Leave-one-solvent-out CV is extremely challenging for GNN')\n",
    "print('3. The GNN benchmark may have used different CV scheme (not leave-one-solvent-out)')\n",
    "print('4. AttentiveFP may need more training epochs or different hyperparameters')\n",
    "print('5. The molecular graphs may need more sophisticated features')\n",
    "print()\n",
    "print('Key insight: The GNN benchmark (MSE 0.0039) may have used a different evaluation scheme!')\n",
    "print('Our leave-one-solvent-out CV is MUCH harder than standard random splits.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50325e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.248827Z",
     "iopub.status.busy": "2026-01-15T05:06:44.248643Z",
     "iopub.status.idle": "2026-01-15T05:06:44.259612Z",
     "shell.execute_reply": "2026-01-15T05:06:44.259083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. Pre-trained molecular embeddings (ChemBERTa, MolBERT)\n",
      "   - Use embeddings from models trained on millions of molecules\n",
      "   - These capture general chemical knowledge that transfers to new solvents\n",
      "\n",
      "2. k-NN with Tanimoto similarity\n",
      "   - For test solvent, find k most similar training solvents\n",
      "   - Weight predictions by similarity\n",
      "   - Simple but may work for distribution shift\n",
      "\n",
      "3. Meta-learning / Few-shot learning\n",
      "   - Learn a model that can quickly adapt to new solvents\n",
      "   - MAML, Prototypical Networks, etc.\n",
      "\n",
      "4. Adversarial domain adaptation\n",
      "   - Learn features that are invariant across solvents\n",
      "   - May reduce distribution shift\n",
      "\n",
      "5. Pure GP with different kernels\n",
      "   - GP provides uncertainty estimates\n",
      "   - May have different CV-LB relationship\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print()\n",
    "print('1. Pre-trained molecular embeddings (ChemBERTa, MolBERT)')\n",
    "print('   - Use embeddings from models trained on millions of molecules')\n",
    "print('   - These capture general chemical knowledge that transfers to new solvents')\n",
    "print()\n",
    "print('2. k-NN with Tanimoto similarity')\n",
    "print('   - For test solvent, find k most similar training solvents')\n",
    "print('   - Weight predictions by similarity')\n",
    "print('   - Simple but may work for distribution shift')\n",
    "print()\n",
    "print('3. Meta-learning / Few-shot learning')\n",
    "print('   - Learn a model that can quickly adapt to new solvents')\n",
    "print('   - MAML, Prototypical Networks, etc.')\n",
    "print()\n",
    "print('4. Adversarial domain adaptation')\n",
    "print('   - Learn features that are invariant across solvents')\n",
    "print('   - May reduce distribution shift')\n",
    "print()\n",
    "print('5. Pure GP with different kernels')\n",
    "print('   - GP provides uncertainty estimates')\n",
    "print('   - May have different CV-LB relationship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5b8888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.261199Z",
     "iopub.status.busy": "2026-01-15T05:06:44.261040Z",
     "iopub.status.idle": "2026-01-15T05:06:44.266849Z",
     "shell.execute_reply": "2026-01-15T05:06:44.266362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BENCHMARK ANALYSIS ===\n",
      "\n",
      "GNN Benchmark (arXiv:2512.19530) achieved MSE 0.0039\n",
      "Our best LB: 0.0877 (22x worse)\n",
      "Target: 0.0347 (8.9x worse than benchmark)\n",
      "\n",
      "Possible differences in benchmark evaluation:\n",
      "1. Different CV scheme (random splits vs leave-one-solvent-out)\n",
      "2. Pre-training on larger molecular datasets\n",
      "3. Different GNN architecture (not AttentiveFP)\n",
      "4. Different feature engineering\n",
      "5. Different evaluation metric\n",
      "\n",
      "CRITICAL: The competition uses leave-one-solvent-out CV!\n",
      "This is MUCH harder than random splits because:\n",
      "- Test solvent is NEVER seen during training\n",
      "- Model must generalize to completely new molecular structures\n",
      "- This is an out-of-distribution (OOD) problem\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the benchmark paper might have done differently\n",
    "print('=== BENCHMARK ANALYSIS ===')\n",
    "print()\n",
    "print('GNN Benchmark (arXiv:2512.19530) achieved MSE 0.0039')\n",
    "print('Our best LB: 0.0877 (22x worse)')\n",
    "print('Target: 0.0347 (8.9x worse than benchmark)')\n",
    "print()\n",
    "print('Possible differences in benchmark evaluation:')\n",
    "print('1. Different CV scheme (random splits vs leave-one-solvent-out)')\n",
    "print('2. Pre-training on larger molecular datasets')\n",
    "print('3. Different GNN architecture (not AttentiveFP)')\n",
    "print('4. Different feature engineering')\n",
    "print('5. Different evaluation metric')\n",
    "print()\n",
    "print('CRITICAL: The competition uses leave-one-solvent-out CV!')\n",
    "print('This is MUCH harder than random splits because:')\n",
    "print('- Test solvent is NEVER seen during training')\n",
    "print('- Model must generalize to completely new molecular structures')\n",
    "print('- This is an out-of-distribution (OOD) problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1036ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.268454Z",
     "iopub.status.busy": "2026-01-15T05:06:44.268285Z",
     "iopub.status.idle": "2026-01-15T05:06:44.274081Z",
     "shell.execute_reply": "2026-01-15T05:06:44.273563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBMISSION STRATEGY ===\n",
      "\n",
      "Submissions remaining: 4\n",
      "Best LB so far: 0.0877 (exp_030)\n",
      "Target: 0.0347\n",
      "Gap: 2.53x\n",
      "\n",
      "Options:\n",
      "1. Submit exp_035 (CV 0.008194) - our best CV model\n",
      "   - Expected LB: 4.30*0.008194 + 0.0524 = 0.0876 (similar to exp_030)\n",
      "   - Unlikely to beat target\n",
      "\n",
      "2. Try pre-trained embeddings (ChemBERTa)\n",
      "   - May have different CV-LB relationship\n",
      "   - Worth trying before submitting\n",
      "\n",
      "3. Try k-NN with Tanimoto similarity\n",
      "   - Simple approach that may work for OOD\n",
      "   - Worth trying before submitting\n",
      "\n",
      "4. Try pure GP with sophisticated kernels\n",
      "   - GP may have different CV-LB relationship\n",
      "   - Worth trying before submitting\n",
      "\n",
      "RECOMMENDATION: Try pre-trained embeddings first, then k-NN, then submit best.\n"
     ]
    }
   ],
   "source": [
    "# What can we do with 4 submissions remaining?\n",
    "print('=== SUBMISSION STRATEGY ===')\n",
    "print()\n",
    "print('Submissions remaining: 4')\n",
    "print('Best LB so far: 0.0877 (exp_030)')\n",
    "print('Target: 0.0347')\n",
    "print('Gap: 2.53x')\n",
    "print()\n",
    "print('Options:')\n",
    "print('1. Submit exp_035 (CV 0.008194) - our best CV model')\n",
    "print('   - Expected LB: 4.30*0.008194 + 0.0524 = 0.0876 (similar to exp_030)')\n",
    "print('   - Unlikely to beat target')\n",
    "print()\n",
    "print('2. Try pre-trained embeddings (ChemBERTa)')\n",
    "print('   - May have different CV-LB relationship')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('3. Try k-NN with Tanimoto similarity')\n",
    "print('   - Simple approach that may work for OOD')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('4. Try pure GP with sophisticated kernels')\n",
    "print('   - GP may have different CV-LB relationship')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('RECOMMENDATION: Try pre-trained embeddings first, then k-NN, then submit best.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d0c86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.275702Z",
     "iopub.status.busy": "2026-01-15T05:06:44.275523Z",
     "iopub.status.idle": "2026-01-15T05:06:44.899308Z",
     "shell.execute_reply": "2026-01-15T05:06:44.898755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available packages for pre-trained embeddings...\n",
      "✓ transformers is available\n",
      "✓ torch is available\n",
      "✓ rdkit is available\n"
     ]
    }
   ],
   "source": [
    "# Check if we have the right packages for pre-trained embeddings\n",
    "import subprocess\n",
    "result = subprocess.run(['pip', 'list'], capture_output=True, text=True)\n",
    "print('Checking available packages for pre-trained embeddings...')\n",
    "if 'transformers' in result.stdout:\n",
    "    print('✓ transformers is available')\n",
    "else:\n",
    "    print('✗ transformers is NOT available')\n",
    "\n",
    "if 'torch' in result.stdout:\n",
    "    print('✓ torch is available')\n",
    "else:\n",
    "    print('✗ torch is NOT available')\n",
    "\n",
    "if 'rdkit' in result.stdout.lower():\n",
    "    print('✓ rdkit is available')\n",
    "else:\n",
    "    print('✗ rdkit is NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f11dfcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:44.901608Z",
     "iopub.status.busy": "2026-01-15T05:06:44.901162Z",
     "iopub.status.idle": "2026-01-15T05:06:50.369815Z",
     "shell.execute_reply": "2026-01-15T05:06:50.369033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ChemBERTa...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6fabcd690e48e9a14951b7138a79eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14b66ce3c724b87b97f9637d09212b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/501 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6ae6f699f74986976abd7aa834c40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13df1748f50f49c7adfe052e099791bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a9b65aa541435cb9fe092dd7f15eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/agent/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032bdb06336e4f1bb5bf46476326e897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/179M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ChemBERTa is available!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "# Check if ChemBERTa is available\n",
    "try:\n",
    "    from transformers import AutoModel, AutoTokenizer\n",
    "    print('Testing ChemBERTa...')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "    model = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "    print('✓ ChemBERTa is available!')\n",
    "    \n",
    "    # Test on a simple SMILES\n",
    "    smiles = 'CCO'  # Ethanol\n",
    "    inputs = tokenizer(smiles, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    print(f'Embedding shape: {outputs.last_hidden_state.shape}')\n",
    "except Exception as e:\n",
    "    print(f'✗ ChemBERTa not available: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9079858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:06:50.372253Z",
     "iopub.status.busy": "2026-01-15T05:06:50.371616Z",
     "iopub.status.idle": "2026-01-15T05:06:50.376876Z",
     "shell.execute_reply": "2026-01-15T05:06:50.376250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOOP 41 SUMMARY ===\n",
      "\n",
      "GNN (AttentiveFP) FAILED with MSE 0.068767 (8.4x worse than baseline)\n",
      "\n",
      "Key insight: The GNN benchmark (MSE 0.0039) likely used a different CV scheme.\n",
      "Our leave-one-solvent-out CV is an OOD problem that is MUCH harder.\n",
      "\n",
      "Next steps:\n",
      "1. Try pre-trained molecular embeddings (ChemBERTa) if available\n",
      "2. Try k-NN with Tanimoto similarity as a simple OOD approach\n",
      "3. Try pure GP with sophisticated kernels\n",
      "4. If none work, submit exp_035 (best CV) and accept the gap\n",
      "\n",
      "The target (0.0347) may be achievable with a fundamentally different approach,\n",
      "but we need to find what changes the CV-LB relationship.\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print('=== LOOP 41 SUMMARY ===')\n",
    "print()\n",
    "print('GNN (AttentiveFP) FAILED with MSE 0.068767 (8.4x worse than baseline)')\n",
    "print()\n",
    "print('Key insight: The GNN benchmark (MSE 0.0039) likely used a different CV scheme.')\n",
    "print('Our leave-one-solvent-out CV is an OOD problem that is MUCH harder.')\n",
    "print()\n",
    "print('Next steps:')\n",
    "print('1. Try pre-trained molecular embeddings (ChemBERTa) if available')\n",
    "print('2. Try k-NN with Tanimoto similarity as a simple OOD approach')\n",
    "print('3. Try pure GP with sophisticated kernels')\n",
    "print('4. If none work, submit exp_035 (best CV) and accept the gap')\n",
    "print()\n",
    "print('The target (0.0347) may be achievable with a fundamentally different approach,')\n",
    "print('but we need to find what changes the CV-LB relationship.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
