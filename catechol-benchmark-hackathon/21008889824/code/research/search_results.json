{
  "query": "How can I use pseudo-labeling or test-time adaptation to improve model generalization when the test distribution is unknown?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Based on recent research on test\u2011time adaptation (TTA) and pseudo\u2011labeling, you can improve generalization to an unknown test distribution by iteratively generating reliable pseudo\u2011labels from the unlabeled test data and updating the model with a self\u2011training loss\u202f([arXiv:2210.10019](https://arxiv.org/abs/2210.10019); [arXiv:2207.10792](https://arxiv.org/abs/2207.10792); [arXiv:2207.09640](https://arxiv.org/abs/2207.09640); [arXiv:2301.06013](https://arxiv.org/abs/2301.06013)).\n\n**Step\u2011by\u2011step procedure**\n\n1. **Start from a pretrained source model**  \n   Train your classifier on the source domain (e.g., with cross\u2011entropy). Keep the feature extractor fixed for later adaptation.\n\n2. **Collect a batch of unlabeled test samples**  \n   As test data arrive, buffer a small window (e.g., a few hundred samples) to compute statistics and pseudo\u2011labels.\n\n3. **Generate pseudo\u2011labels**  \n   - **Hard labels**: assign each sample the class with highest predicted probability.  \n   - **Conjugate (soft) labels**: compute the convex\u2011conjugate of the training loss to obtain a temperature\u2011scaled soft label that better approximates the original supervised loss\u202f([arXiv:2207.09640](https://arxiv.org/abs/2207.09640)).  \n   - **Nearest\u2011neighbor distribution**: for each sample, find its nearest neighbor in the feature space and form a pseudo\u2011label distribution that mixes the model\u2019s prediction with the neighbor\u2019s label\u202f([arXiv:2207.10792](https://arxiv.org/abs/2207.10792)).  \n   - **Complementary learning**: treat low\u2011confidence classes as \u201cnegative\u201d information to sharpen the label distribution\u202f([arXiv:2301.06013](https://arxiv.org/abs/2301.06013)).\n\n4. **Define a self\u2011training loss**  \n   Use a loss that matches the model\u2019s output to the chosen pseudo\u2011label distribution (e.g., squared loss for conjugate labels, cross\u2011entropy for hard/soft labels, or a prototype\u2011based KL loss when using nearest\u2011neighbor distributions)\u202f([arXiv:2210.10019](https://arxiv.org/abs/2210.10019)).\n\n5. **Adapt the model with a few gradient\u2011descent steps**  \n   - Optionally insert lightweight adaptation modules (e.g., batch\u2011norm or affine layers) on top of the frozen feature extractor.  \n   - Perform 1\u20135 SGD/Adam updates on the buffered test batch, minimizing the self\u2011training loss.  \n   - Stop early to avoid over\u2011fitting to noisy pseudo\u2011labels.\n\n6. **Update pseudo\u2011labels and repeat**  \n   After each adaptation round, recompute pseudo\u2011labels with the updated model and repeat steps\u202f3\u20135 for the next test batch. This online loop enables continual alignment to the unknown test distribution\u202f([arXiv:2209.11459](https://arxiv.org/abs/2209.11459)).\n\n7. **Make predictions with the adapted model**  \n   Once adaptation for the current batch is finished, use the updated parameters to predict labels for the incoming test samples.\n\nFollowing these steps lets you exploit unlabeled test data through robust pseudo\u2011labeling (hard, conjugate, nearest\u2011neighbor, or complementary) and lightweight test\u2011time adaptation, thereby improving generalization even when the test distribution is not known in advance.",
      "url": ""
    },
    {
      "title": "Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2210.10019** (cs)\n\n\\[Submitted on 18 Oct 2022 ( [v1](https://arxiv.org/abs/2210.10019v1)), last revised 26 Feb 2023 (this version, v4)\\]\n\n# Title:Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation\n\nAuthors: [Jun-Kun Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+J), [Andre Wibisono](https://arxiv.org/search/cs?searchtype=author&query=Wibisono,+A)\n\nView a PDF of the paper titled Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation, by Jun-Kun Wang and Andre Wibisono\n\n[View PDF](https://arxiv.org/pdf/2210.10019)\n\n> Abstract:We consider a setting that a model needs to adapt to a new domain under distribution shifts, given that only unlabeled test samples from the new domain are accessible at test time. A common idea in most of the related works is constructing pseudo-labels for the unlabeled test samples and applying gradient descent (GD) to a loss function with the pseudo-labels. Recently, \\\\cite{GSRK22} propose conjugate labels, which is a new kind of pseudo-labels for self-training at test time. They empirically show that the conjugate label outperforms other ways of pseudo-labeling on many domain adaptation benchmarks. However, provably showing that GD with conjugate labels learns a good classifier for test-time adaptation remains open. In this work, we aim at theoretically understanding GD with hard and conjugate labels for a binary classification problem. We show that for square loss, GD with conjugate labels converges to an $\\\\epsilon$-optimal predictor under a Gaussian model for any arbitrarily small $\\\\epsilon$, while GD with hard pseudo-labels fails in this task. We also analyze them under different loss functions for the update. Our results shed lights on understanding when and why GD with hard labels or conjugate labels works in test-time adaptation.\n\n|     |     |\n| --- | --- |\n| Comments: | Accepted at ICLR (International Conference on Learning Representations), 2023 |\n| Subjects: | Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2210.10019](https://arxiv.org/abs/2210.10019) \\[cs.LG\\] |\n|  | (or [arXiv:2210.10019v4](https://arxiv.org/abs/2210.10019v4) \\[cs.LG\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2210.10019](https://doi.org/10.48550/arXiv.2210.10019)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jun-Kun Wang \\[ [view email](https://arxiv.org/show-email/44ff5321/2210.10019)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2210.10019v1)**\nTue, 18 Oct 2022 17:39:32 UTC (792 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2210.10019v2)**\nWed, 15 Feb 2023 14:51:55 UTC (1,018 KB)\n\n**[\\[v3\\]](https://arxiv.org/abs/2210.10019v3)**\nSat, 18 Feb 2023 21:03:44 UTC (885 KB)\n\n**\\[v4\\]**\nSun, 26 Feb 2023 03:53:32 UTC (885 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation, by Jun-Kun Wang and Andre Wibisono\n\n- [View PDF](https://arxiv.org/pdf/2210.10019)\n- [TeX Source](https://arxiv.org/src/2210.10019)\n- [Other Formats](https://arxiv.org/format/2210.10019)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2210.10019&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2210.10019&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2022-10](https://arxiv.org/list/cs.LG/2022-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2210.10019?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.10019)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.10019)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.10019)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2210.10019&description=Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2210.10019&title=Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.10019) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2210.10019"
    },
    {
      "title": "Test-Time Adaptation via Self-Training with Nearest Neighbor Information",
      "text": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2207.10792** (cs)\n\n\\[Submitted on 8 Jul 2022 ( [v1](https://arxiv.org/abs/2207.10792v1)), last revised 28 Feb 2023 (this version, v2)\\]\n\n# Title:Test-Time Adaptation via Self-Training with Nearest Neighbor Information\n\nAuthors: [Minguk Jang](https://arxiv.org/search/cs?searchtype=author&query=Jang,+M), [Sae-Young Chung](https://arxiv.org/search/cs?searchtype=author&query=Chung,+S), [Hye Won Chung](https://arxiv.org/search/cs?searchtype=author&query=Chung,+H+W)\n\nView a PDF of the paper titled Test-Time Adaptation via Self-Training with Nearest Neighbor Information, by Minguk Jang and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2207.10792)\n\n> Abstract:Test-time adaptation (TTA) aims to adapt a trained classifier using online unlabeled test data only, without any information related to the training procedure. Most existing TTA methods adapt the trained classifier using the classifier's prediction on the test data as pseudo-label. However, under test-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and thus the TTA methods often encounter performance degradation at the adapted classifier. To overcome this limitation, we propose a novel test-time adaptation method, called Test-time Adaptation via Self-Training with nearest neighbor information (TAST), which is composed of the following procedures: (1) adds trainable adaptation modules on top of the trained feature extractor; (2) newly defines a pseudo-label distribution for the test data by using the nearest neighbor information; (3) trains these modules only a few times during test time to match the nearest neighbor-based pseudo label distribution and a prototype-based class distribution for the test data; and (4) predicts the label of test data using the average predicted class distribution from these modules. The pseudo-label generation is based on the basic intuition that a test data and its nearest neighbor in the embedding space are likely to share the same label under the domain shift. By utilizing multiple randomly initialized adaptation modules, TAST extracts useful information for the classification of the test data under the domain shift, using the nearest neighbor information. TAST showed better performance than the state-of-the-art TTA methods on two standard benchmark tasks, domain generalization, namely VLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly CIFAR-10/100C.\n\n|     |     |\n| --- | --- |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2207.10792](https://arxiv.org/abs/2207.10792) \\[cs.CV\\] |\n|  | (or [arXiv:2207.10792v2](https://arxiv.org/abs/2207.10792v2) \\[cs.CV\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2207.10792](https://doi.org/10.48550/arXiv.2207.10792)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Minguk Jang \\[ [view email](https://arxiv.org/show-email/e9ed05a2/2207.10792)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2207.10792v1)**\nFri, 8 Jul 2022 05:02:15 UTC (152 KB)\n\n**\\[v2\\]**\nTue, 28 Feb 2023 03:21:35 UTC (436 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Test-Time Adaptation via Self-Training with Nearest Neighbor Information, by Minguk Jang and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2207.10792)\n- [TeX Source](https://arxiv.org/src/2207.10792)\n- [Other Formats](https://arxiv.org/format/2207.10792)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2207.10792&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2207.10792&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2022-07](https://arxiv.org/list/cs.CV/2022-07)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2207.10792?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2207.10792?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2207.10792)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2207.10792)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2207.10792)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2207.10792&description=Test-Time Adaptation via Self-Training with Nearest Neighbor Information) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2207.10792&title=Test-Time Adaptation via Self-Training with Nearest Neighbor Information)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2207.10792) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2207.10792"
    },
    {
      "title": "Computer Science > Computer Vision and Pattern Recognition",
      "text": "[2301.06013] Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2301.06013\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computer Vision and Pattern Recognition\n**arXiv:2301.06013**(cs)\n[Submitted on 15 Jan 2023]\n# Title:Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning\nAuthors:[Jiayi Han](https://arxiv.org/search/cs?searchtype=author&amp;query=Han,+J),[Longbin Zeng](https://arxiv.org/search/cs?searchtype=author&amp;query=Zeng,+L),[Liang Du](https://arxiv.org/search/cs?searchtype=author&amp;query=Du,+L),[Weiyang Ding](https://arxiv.org/search/cs?searchtype=author&amp;query=Ding,+W),[Jianfeng Feng](https://arxiv.org/search/cs?searchtype=author&amp;query=Feng,+J)\nView a PDF of the paper titled Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning, by Jiayi Han and 4 other authors\n[View PDF](https://arxiv.org/pdf/2301.06013)> > Abstract:\n> In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the &#34;less probable categories&#34; to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings. Subjects:|Computer Vision and Pattern Recognition (cs.CV)|\nCite as:|[arXiv:2301.06013](https://arxiv.org/abs/2301.06013)[cs.CV]|\n|(or[arXiv:2301.06013v1](https://arxiv.org/abs/2301.06013v1)[cs.CV]for this version)|\n|[https://doi.org/10.48550/arXiv.2301.06013](https://doi.org/10.48550/arXiv.2301.06013)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nRelated DOI:|[https://doi.org/10.1016/j.patrec.2023.12.001](https://doi.org/10.1016/j.patrec.2023.12.001)\nFocus to learn more\nDOI(s) linking to related resources\n|\n## Submission history\nFrom: Jiayi Han [[view email](https://arxiv.org/show-email/fca9a741/2301.06013)]\n**[v1]**Sun, 15 Jan 2023 03:36:33 UTC (466 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning, by Jiayi Han and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2301.06013)\n* [TeX Source](https://arxiv.org/src/2301.06013)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.CV\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2301.06013&amp;function=prev&amp;context=cs.CV) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2301.06013&amp;function=next&amp;context=cs.CV)\n[new](https://arxiv.org/list/cs.CV/new)|[recent](https://arxiv.org/list/cs.CV/recent)|[2023-01](https://arxiv.org/list/cs.CV/2023-01)\nChange to browse by:\n[cs](https://arxiv.org/abs/2301.06013?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2301.06013)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2301.06013)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2301.06013)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2301.06013&amp;description=Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2301.06013&amp;title=Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/...",
      "url": "https://arxiv.org/abs/2301.06013"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2207.09640] Test-Time Adaptation via Conjugate Pseudo-labels\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2207.09640\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2207.09640**(cs)\n[Submitted on 20 Jul 2022 ([v1](https://arxiv.org/abs/2207.09640v1)), last revised 23 Nov 2022 (this version, v2)]\n# Title:Test-Time Adaptation via Conjugate Pseudo-labels\nAuthors:[Sachin Goyal](https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal,+S),[Mingjie Sun](https://arxiv.org/search/cs?searchtype=author&amp;query=Sun,+M),[Aditi Raghunathan](https://arxiv.org/search/cs?searchtype=author&amp;query=Raghunathan,+A),[Zico Kolter](https://arxiv.org/search/cs?searchtype=author&amp;query=Kolter,+Z)\nView a PDF of the paper titled Test-Time Adaptation via Conjugate Pseudo-labels, by Sachin Goyal and 3 other authors\n[View PDF](https://arxiv.org/pdf/2207.09640)> > Abstract:\n> Test-time adaptation (TTA) refers to adapting neural networks to distribution shifts, with access to only the unlabeled test samples from the new domain at test-time. Prior TTA methods optimize over unsupervised objectives such as the entropy of model predictions in TENT [Wang et al., 2021], but it is unclear what exactly makes a good TTA loss. In this paper, we start by presenting a surprising phenomenon: if we attempt to meta-learn the best possible TTA loss over a wide class of functions, then we recover a function that is remarkably similar to (a temperature-scaled version of) the softmax-entropy employed by TENT. This only holds, however, if the classifier we are adapting is trained via cross-entropy; if trained via squared loss, a different best TTA loss emerges. To explain this phenomenon, we analyze TTA through the lens of the training losses&#39;s convex conjugate. We show that under natural conditions, this (unsupervised) conjugate function can be viewed as a good local approximation to the original supervised loss and indeed, it recovers the best losses found by meta-learning. This leads to a generic recipe that can be used to find a good TTA loss for any given supervised training loss function of a general class. Empirically, our approach consistently dominates other baselines over a wide range of benchmarks. Our approach is particularly of interest when applied to classifiers trained with novel loss functions, e.g., the recently-proposed PolyLoss, where it differs substantially from (and outperforms) an entropy-based loss. Further, we show that our approach can also be interpreted as a kind of self-training using a very specific soft label, which we refer to as the conjugate pseudolabel. Overall, our method provides a broad framework for better understanding and improving test-time adaptation. Code is available at [> this https URL\n](https://github.com/locuslab/tta_conjugate)> . Comments:|Published in Neural Information Processing Systems (NeurIPS) 2022|\nSubjects:|Machine Learning (cs.LG)|\nCite as:|[arXiv:2207.09640](https://arxiv.org/abs/2207.09640)[cs.LG]|\n|(or[arXiv:2207.09640v2](https://arxiv.org/abs/2207.09640v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2207.09640](https://doi.org/10.48550/arXiv.2207.09640)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Sachin Goyal [[view email](https://arxiv.org/show-email/a9e34416/2207.09640)]\n**[[v1]](https://arxiv.org/abs/2207.09640v1)**Wed, 20 Jul 2022 04:02:19 UTC (3,051 KB)\n**[v2]**Wed, 23 Nov 2022 00:08:40 UTC (6,618 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Test-Time Adaptation via Conjugate Pseudo-labels, by Sachin Goyal and 3 other authors\n* [View PDF](https://arxiv.org/pdf/2207.09640)\n* [TeX Source](https://arxiv.org/src/2207.09640)\n[![license icon](https://arxiv.org/icons/licenses/by-nc-sa-4.0.png)view license](http://creativecommons.org/licenses/by-nc-sa/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2207.09640&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2207.09640&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2022-07](https://arxiv.org/list/cs.LG/2022-07)\nChange to browse by:\n[cs](https://arxiv.org/abs/2207.09640?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2207.09640)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2207.09640)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2207.09640)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2207.09640&amp;description=Test-Time Adaptation via Conjugate Pseudo-labels>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2207.09640&amp;title=Test-Time Adaptation via Conjugate Pseudo-labels>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with co...",
      "url": "https://arxiv.org/abs/2207.09640"
    },
    {
      "title": "Computer Science > Computer Vision and Pattern Recognition",
      "text": "[2209.11459] TeST: Test-time Self-Training under Distribution Shift\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2209.11459\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computer Vision and Pattern Recognition\n**arXiv:2209.11459**(cs)\n[Submitted on 23 Sep 2022]\n# Title:TeST: Test-time Self-Training under Distribution Shift\nAuthors:[Samarth Sinha](https://arxiv.org/search/cs?searchtype=author&amp;query=Sinha,+S),[Peter Gehler](https://arxiv.org/search/cs?searchtype=author&amp;query=Gehler,+P),[Francesco Locatello](https://arxiv.org/search/cs?searchtype=author&amp;query=Locatello,+F),[Bernt Schiele](https://arxiv.org/search/cs?searchtype=author&amp;query=Schiele,+B)\nView a PDF of the paper titled TeST: Test-time Self-Training under Distribution Shift, by Samarth Sinha and 3 other authors\n[View PDF](https://arxiv.org/pdf/2209.11459)> > Abstract:\n> Despite their recent success, deep neural networks continue to perform poorly when they encounter distribution shifts at test time. Many recently proposed approaches try to counter this by aligning the model to the new distribution prior to inference. With no labels available this requires unsupervised objectives to adapt the model on the observed test data. In this paper, we propose Test-Time Self-Training (TeST): a technique that takes as input a model trained on some source data and a novel data distribution at test time, and learns invariant and robust representations using a student-teacher framework. We find that models adapted using TeST significantly improve over baseline test-time adaptation algorithms. TeST achieves competitive performance to modern domain adaptation algorithms, while having access to 5-10x less data at time of adaption. We thoroughly evaluate a variety of baselines on two tasks: object detection and image segmentation and find that models adapted with TeST. We find that TeST sets the new state-of-the art for test-time domain adaptation algorithms. Subjects:|Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)|\nCite as:|[arXiv:2209.11459](https://arxiv.org/abs/2209.11459)[cs.CV]|\n|(or[arXiv:2209.11459v1](https://arxiv.org/abs/2209.11459v1)[cs.CV]for this version)|\n|[https://doi.org/10.48550/arXiv.2209.11459](https://doi.org/10.48550/arXiv.2209.11459)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nJournalreference:|WACV 2023|\n## Submission history\nFrom: Samarth Sinha [[view email](https://arxiv.org/show-email/75899eda/2209.11459)]\n**[v1]**Fri, 23 Sep 2022 07:47:33 UTC (6,645 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled TeST: Test-time Self-Training under Distribution Shift, by Samarth Sinha and 3 other authors\n* [View PDF](https://arxiv.org/pdf/2209.11459)\n* [TeX Source](https://arxiv.org/src/2209.11459)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.CV\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2209.11459&amp;function=prev&amp;context=cs.CV) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2209.11459&amp;function=next&amp;context=cs.CV)\n[new](https://arxiv.org/list/cs.CV/new)|[recent](https://arxiv.org/list/cs.CV/recent)|[2022-09](https://arxiv.org/list/cs.CV/2022-09)\nChange to browse by:\n[cs](https://arxiv.org/abs/2209.11459?context=cs)\n[cs.LG](https://arxiv.org/abs/2209.11459?context=cs.LG)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2209.11459)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2209.11459)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2209.11459)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2209.11459&amp;description=TeST: Test-time Self-Training under Distribution Shift>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2209.11459&amp;title=TeST: Test-time Self-Training under Distribution Shift>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2209.11459)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2209.11459"
    },
    {
      "title": "Computer Science > Computer Vision and Pattern Recognition",
      "text": "[2204.10377] Contrastive Test-Time Adaptation\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2204.10377\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computer Vision and Pattern Recognition\n**arXiv:2204.10377**(cs)\n[Submitted on 21 Apr 2022]\n# Title:Contrastive Test-Time Adaptation\nAuthors:[Dian Chen](https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+D),[Dequan Wang](https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+D),[Trevor Darrell](https://arxiv.org/search/cs?searchtype=author&amp;query=Darrell,+T),[Sayna Ebrahimi](https://arxiv.org/search/cs?searchtype=author&amp;query=Ebrahimi,+S)\nView a PDF of the paper titled Contrastive Test-Time Adaptation, by Dian Chen and 3 other authors\n[View PDF](https://arxiv.org/pdf/2204.10377)> > Abstract:\n> Test-time adaptation is a special setting of unsupervised domain adaptation where a trained model on the source domain has to adapt to the target domain without accessing source data. We propose a novel way to leverage self-supervised contrastive learning to facilitate target feature learning, along with an online pseudo labeling scheme with refinement that significantly denoises pseudo labels. The contrastive learning task is applied jointly with pseudo labeling, contrasting positive and negative pairs constructed similarly as MoCo but with source-initialized encoder, and excluding same-class negative pairs indicated by pseudo labels. Meanwhile, we produce pseudo labels online and refine them via soft voting among their nearest neighbors in the target feature space, enabled by maintaining a memory queue. Our method, AdaContrast, achieves state-of-the-art performance on major benchmarks while having several desirable properties compared to existing works, including memory efficiency, insensitivity to hyper-parameters, and better model calibration. Project page: [> this http URL\n](http://sites.google.com/view/adacontrast)> . Comments:|CVPR 2022 camera-ready version|\nSubjects:|Computer Vision and Pattern Recognition (cs.CV)|\nCite as:|[arXiv:2204.10377](https://arxiv.org/abs/2204.10377)[cs.CV]|\n|(or[arXiv:2204.10377v1](https://arxiv.org/abs/2204.10377v1)[cs.CV]for this version)|\n|[https://doi.org/10.48550/arXiv.2204.10377](https://doi.org/10.48550/arXiv.2204.10377)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Dian Chen [[view email](https://arxiv.org/show-email/456a7ca3/2204.10377)]\n**[v1]**Thu, 21 Apr 2022 19:17:22 UTC (604 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Contrastive Test-Time Adaptation, by Dian Chen and 3 other authors\n* [View PDF](https://arxiv.org/pdf/2204.10377)\n* [TeX Source](https://arxiv.org/src/2204.10377)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.CV\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2204.10377&amp;function=prev&amp;context=cs.CV) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2204.10377&amp;function=next&amp;context=cs.CV)\n[new](https://arxiv.org/list/cs.CV/new)|[recent](https://arxiv.org/list/cs.CV/recent)|[2022-04](https://arxiv.org/list/cs.CV/2022-04)\nChange to browse by:\n[cs](https://arxiv.org/abs/2204.10377?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2204.10377)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2204.10377)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2204.10377)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2204.10377&amp;description=Contrastive Test-Time Adaptation>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2204.10377&amp;title=Contrastive Test-Time Adaptation>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2204.10377)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2204.10377"
    },
    {
      "title": "",
      "text": "Test-Time Adaptation via Conjugate Pseudo-labels\nSachin Goyal?1 Mingjie Sun?1 Aditi Raghunathan1 Zico Kolter1,2\n1Carnegie Mellon University, 2Bosch Center for AI\n{sachingo, mingjies, raditi, zkolter}@cs.cmu.edu\nAbstract\nTest-time adaptation (TTA) refers to adapting neural networks to distribution shifts,\nwith access to only the unlabeled test samples from the new domain at test-time.\nPrior TTA methods optimize over unsupervised objectives such as the entropy of\nmodel predictions in TENT [50], but it is unclear what exactly makes a good TTA\nloss. In this paper, we start by presenting a surprising phenomenon: if we attempt\nto meta-learn the \u201cbest\u201d possible TTA loss over a wide class of functions, then we\nrecover a function that is remarkably similar to (a temperature-scaled version of) the\nsoftmax-entropy employed by TENT. This only holds, however, if the classifier we\nare adapting is trained via cross-entropy loss; if the classifier is trained via squared\nloss, a different \u201cbest\u201d TTA loss emerges. To explain this phenomenon, we analyze\ntest-time adaptation through the lens of the training losses\u2019s convex conjugate. We\nshow that under natural conditions, this (unsupervised) conjugate function can be\nviewed as a good local approximation to the original supervised loss and indeed, it\nrecovers the \u201cbest\u201d losses found by meta-learning. This leads to a generic recipe\nthat can be used to find a good TTA loss for any given supervised training loss\nfunction of a general class. Empirically, our approach consistently dominates\nother TTA alternatives over a wide range of domain adaptation benchmarks. Our\napproach is particularly of interest when applied to classifiers trained with novel\nloss functions, e.g., the recently-proposed PolyLoss [25] function, where it differs\nsubstantially from (and outperforms) an entropy-based loss. Further, we show that\nour conjugate based approach can also be interpreted as a kind of self-training using\na very specific soft label, which we refer to as the conjugate pseudo-label. Overall,\nour method provides a broad framework for better understanding and improving\ntest-time adaptation. Code is available at https://github.com/locuslab/\ntta_conjugate.\n1 Introduction\nModern deep networks perform exceeding well on new test inputs that are close to the training\ndistribution. However, this performance dramatically decreases on test inputs drawn from a different\ndistribution. While there is a large body of work on improving the robustness of models, most robust\ntraining methods are highly specialized to the setting they cater to. For e.g., they assume pre-specified\nperturbations, subpopulations, and spurious correlations, or access to unlabeled data from the target\ndistribution, and most methods offer close to no improvement on general distribution shifts beyond\nwhat they were trained for [12, 21].\nIn practice, it is often cumbersome (or even impossible) to precisely characterize all possible distri\u0002bution shifts a model could encounter and then train accordingly. Instead, a model already trained\non some source data must be able to adapt at test-time to new inputs from a different domain. This\nsetting of test-time adaptation (TTA) has gained interest in recent years [6, 47, 50, 54]. TTA is\ntypically accomplished by updating the source model parameters via a few steps of optimization on\nan unsupervised objective involving the new test sample from the target distribution. The choice\n? Equal Contribution\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\narXiv:2207.09640v2 [cs.LG] 23 Nov 2022\nof this unsupervised objective, which we call the TTA loss, dictates the success of the adaptation\nprocedure. [47] uses a self-supervised objective on the test sample, [50] uses the entropy of model\npredictions, and several follow-ups have proposed variants or alternatives [40, 54]. However, it\nremains unclear as to how to choose or guide the selection of this TTA loss, and thus far the choice of\nthese losses has remained largely heuristic in nature.\nIn this work, we begin by presenting a set of intriguing experiments where we attempt to learn\nthe \u201cbest\u201d TTA loss for a given source classifier and distribution shift. We parameterize the TTA\nloss by another neural network whose parameters are learnt via meta-learning [3, 9] where we\ndifferentiate through the adaptation process to find the TTA loss that achieves the best adaptation on\ndistribution shifts. Surprisingly, we ultimately learn a TTA loss that looks remarkably similar to (a\ntemperature-scaled version of) the softmax-entropy loss, which was already proposed by [50]. Why\ndid we recover the commonly used softmax-entropy loss despite the fact that the procedure is capable\nof learning a very general class of losses and the meta-learning process could potentially specialize to\nboth the source classifier and the distribution shift of interest? Furthermore, we find that this pattern\nonly holds when the loss used to train the source classifier is cross-entropy loss; when a different loss\nsuch as squared loss is used instead, the meta-learning procedure recovers a TTA loss that itself looks\nmore like a negative squared error, and is very different from the softmax-entropy loss (Section 3).\nIn order to explain this phenomenon, we propose to consider TTA through the lens of the convex\nconjugate function. Specifically, given a hypothesis function h(x) and label y, several common losses\n(cross-entropy and the squared loss amongst them, but not limited to these) can be written in the\nform L(h(x), y) = f(h(x)) \u2212 y\nT h(x) for some function f. In these cases, we show that \u201cnatural\u201d\nTTA loss for such classifiers is precisely the (negation of) the convex conjugate evaluated at the\ngradient of h, LTTA(x) = \u2212f\n\u2217\n(\u2207f(h(x)), where f\n\u2217\nis the convex conjugate of f. This framework\nnot only recovers the results of our meta-learning experiments, but also justifies why some specific\nchoices of TTA loss in the previous literature work well (e.g., this framework recovers TENT\u2019s\nchoice of softmax-entropy for cross-entropy-trained classifier). Moreover, it also provides a broad\nframework for what the TTA loss should be when the source model is trained using various different\nloss functions (for example the recently-proposed PolyLoss [25, 29]) as is becoming increasingly\ncommon in machine learning. Further, we show that our proposed conjugate adaptation loss is in\nfact a kind of self-training with pseudo-labels [42], a classic approach in machine learning. Various\nformulations of the pseudo-label have been proposed in the literature, and our conjugate analysis\nprovides a general recipe for the \u201ccorrect\u201d choice of soft pseudo-labels given by y\u02c6(x) = \u2207f(h(x)).\nWe thus refer to these as conjugate pseudo-labels (Conjugate PL\u2019s), and believe our work provides a\nbroad framework for understanding adaptation with unlabeled data in general.\nFinally, we empirically verify the effectiveness of our proposed conjugate adaptation loss across\nseveral datasets and training losses, such as cross-entropy and squared loss, along with the recently\u0002proposed PolyLoss [25] (which itself has shown higher standard test accuracy on a wide range\nof vision tasks). Over all models, datasets and training losses, we find our proposed conjugate\npseudo-labeling consistently outperforms prior TTA losses and improves TTA performance over the\ncurrent state of the art.\n2 Background and preliminaries.\nTest-time adaptation. We are interested in mapping an input x \u2208 R\nd\nto a label y \u2208 Y. We learn a\nmodel h\u03b8 : R\nd\n7\u2192 R\n|Y| parameterized by \u03b8 that maps an input x to predictions h\u03b8(x). We assume\naccess to a trained source model and adapt at test-time over the test input, before making the final\nprediction. This is the standard test-time adaptation (TTA) setting [47, 50]. During TTA, we update\nthe model parameters on an unsupervised objective L(x, h\u03b8). For example, in TENT [50], this loss is\nthe entropy of the softmax-normalized predictions of the m...",
      "url": "https://arxiv.org/pdf/2207.09640"
    },
    {
      "title": "Probabilistic Test-Time Generalization by Variational Neighbor-Labeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2307.04033v3"
    }
  ]
}