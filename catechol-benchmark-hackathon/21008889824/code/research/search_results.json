{
  "query": "How can I improve machine learning model predictions when test data contains completely new categories not seen during training?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Open\u2011world (or open\u2011set) learning studies the situation where test instances belong to categories that were never present in the training set.  Traditional supervised models assume a closed world and will force an unknown sample into one of the known classes, often with high confidence, which degrades overall accuracy.  The literature therefore treats the problem as a two\u2011step process: first **detect** that a sample is \u201calien\u201d (out\u2011of\u2011distribution, OOD) and then either reject it, assign it to a special \u201cunknown\u201d class, or adapt the model to learn the new category on\u2011the\u2011fly\u202f([arxiv.org/abs/2105.13448](https://arxiv.org/abs/2105.13448);\u202f[cs.uic.edu](https://www.cs.uic.edu/~liub/open-classification.html)).  \n\nPractical ways to improve predictions under this setting include:  \n\n* **Explicit unknown detection** \u2013 use confidence\u2011based thresholds, distance\u2011based scores in the feature space, or specialized heads such as OpenMax or energy\u2011based OOD detectors.  Papers on OOD generalization provide surveys of these methods and benchmark them on realistic shifts\u202f([arxiv.org/abs/2108.13624](https://arxiv.org/abs/2108.13624);\u202f[arxiv.org/abs/2403.01874](https://arxiv.org/abs/2403.01874)).  \n* **Add a \u201creject/unknown\u201d class** \u2013 during training, augment the data with synthetic or unlabeled \u201cbackground\u201d examples and train the classifier to output a low\u2011confidence or separate label for anything that does not match known patterns.  The open\u2011category detection work with PAC guarantees shows how a small fraction of known\u2011alien examples can be used to bound detection error\u202f([arxiv.org/pdf/1807.03184.pdf](https://arxiv.org/pdf/1807.03184.pdf)).  \n* **Robust categorical encoding** \u2013 for tabular data, map any unseen category to a reserved token (e.g., \u201c<UNK>\u201d) or use target/mean encoding that can handle new levels without expanding the feature matrix.  A Stack\u2011Overflow discussion illustrates this approach for one\u2011hot encoding\u202f([stackoverflow.com/q/41733997](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python)).  \n* **Continual / lifelong learning** \u2013 allow the model to update its parameters after deployment when a batch of newly labeled instances becomes available, thereby expanding its label space without retraining from scratch.  Open\u2011world learning surveys describe algorithms that combine detection, self\u2011labeling, and incremental training\u202f([cs.uic.edu](https://www.cs.uic.edu/~liub/open-classification.html)).  \n\nBy integrating an OOD detector, reserving an \u201cunknown\u201d output, using encodings that gracefully handle novel categories, and optionally employing continual\u2011learning updates, you can substantially reduce mis\u2011classification of unseen categories and improve overall predictive performance in open\u2011world scenarios.",
      "url": ""
    },
    {
      "title": "Open-world Machine Learning: Applications, Challenges, and Opportunities",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2105.13448** (cs)\n\n\\[Submitted on 27 May 2021 ( [v1](https://arxiv.org/abs/2105.13448v1)), last revised 20 Feb 2022 (this version, v2)\\]\n\n# Title:Open-world Machine Learning: Applications, Challenges, and Opportunities\n\nAuthors: [Jitendra Parmar](https://arxiv.org/search/cs?searchtype=author&query=Parmar,+J), [Satyendra Singh Chouhan](https://arxiv.org/search/cs?searchtype=author&query=Chouhan,+S+S), [Vaskar Raychoudhury](https://arxiv.org/search/cs?searchtype=author&query=Raychoudhury,+V), [Santosh Singh Rathore](https://arxiv.org/search/cs?searchtype=author&query=Rathore,+S+S)\n\nView a PDF of the paper titled Open-world Machine Learning: Applications, Challenges, and Opportunities, by Jitendra Parmar and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2105.13448)\n\n> Abstract:Traditional machine learning mainly supervised learning, follows the assumptions of closed-world learning, i.e., for each testing class, a training class is available. However, such machine learning models fail to identify the classes which were not available during training time. These classes can be referred to as unseen classes. Whereas open-world machine learning (OWML) deals with unseen classes. In this paper, first, we present an overview of OWML with importance to the real-world context. Next, different dimensions of open-world machine learning are explored and discussed. The area of OWML gained the attention of the research community in the last decade only. We have searched through different online digital libraries and scrutinized the work done in the last decade. This paper presents a systematic review of various techniques for OWML. It also presents the research gaps, challenges, and future directions in open-world machine learning. This paper will help researchers understand the comprehensive developments of OWML and the likelihood of extending the research in suitable areas. It will also help to select applicable methodologies and datasets to explore this further.\n\n|     |     |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2105.13448](https://arxiv.org/abs/2105.13448) \\[cs.LG\\] |\n|  | (or [arXiv:2105.13448v2](https://arxiv.org/abs/2105.13448v2) \\[cs.LG\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2105.13448](https://doi.org/10.48550/arXiv.2105.13448)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jitendra Parmar \\[ [view email](https://arxiv.org/show-email/f412a42b/2105.13448)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2105.13448v1)**\nThu, 27 May 2021 21:05:10 UTC (6,515 KB)\n\n**\\[v2\\]**\nSun, 20 Feb 2022 06:00:41 UTC (2,657 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Open-world Machine Learning: Applications, Challenges, and Opportunities, by Jitendra Parmar and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2105.13448)\n- [TeX Source](https://arxiv.org/src/2105.13448)\n- [Other Formats](https://arxiv.org/format/2105.13448)\n\n[![license icon](https://arxiv.org/icons/licenses/by-nc-sa-4.0.png)view license](http://creativecommons.org/licenses/by-nc-sa/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2105.13448&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2105.13448&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-05](https://arxiv.org/list/cs.LG/2021-05)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2105.13448?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2105.13448?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2105.13448)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2105.13448)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2105.13448)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2105.html#abs-2105-13448) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2105-13448)\n\n[Santosh Singh Rathore](https://dblp.uni-trier.de/search/author?author=Santosh%20Singh%20Rathore)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2105.13448&description=Open-world Machine Learning: Applications, Challenges, and Opportunities) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2105.13448&title=Open-world Machine Learning: Applications, Challenges, and Opportunities)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2105.13448) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2105.13448"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2108.13624] Towards Out-Of-Distribution Generalization: A Survey\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2108.13624\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2108.13624**(cs)\n[Submitted on 31 Aug 2021 ([v1](https://arxiv.org/abs/2108.13624v1)), last revised 27 Jul 2023 (this version, v2)]\n# Title:Towards Out-Of-Distribution Generalization: A Survey\nAuthors:[Jiashuo Liu](https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J),[Zheyan Shen](https://arxiv.org/search/cs?searchtype=author&amp;query=Shen,+Z),[Yue He](https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Y),[Xingxuan Zhang](https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X),[Renzhe Xu](https://arxiv.org/search/cs?searchtype=author&amp;query=Xu,+R),[Han Yu](https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H),[Peng Cui](https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+P)\nView a PDF of the paper titled Towards Out-Of-Distribution Generalization: A Survey, by Jiashuo Liu and 6 other authors\n[View PDF](https://arxiv.org/pdf/2108.13624)> > Abstract:\n> Traditional machine learning paradigms are based on the assumption that both training and test data follow the same statistical pattern, which is mathematically referred to as Independent and Identically Distributed ($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often fails to hold due to unforeseen distributional shifts, leading to considerable degradation in model performance upon deployment. This observed discrepancy indicates the significance of investigating the Out-of-Distribution (OOD) generalization problem. OOD generalization is an emerging topic of machine learning research that focuses on complex scenarios wherein the distributions of the test data differ from those of the training data. This paper represents the first comprehensive, systematic review of OOD generalization, encompassing a spectrum of aspects from problem definition, methodological development, and evaluation procedures, to the implications and future directions of the field. Our discussion begins with a precise, formal characterization of the OOD generalization problem. Following that, we categorize existing methodologies into three segments: unsupervised representation learning, supervised model learning, and optimization, according to their positions within the overarching learning process. We provide an in-depth discussion on representative methodologies for each category, further elucidating the theoretical links between them. Subsequently, we outline the prevailing benchmark datasets employed in OOD generalization studies. To conclude, we overview the existing body of work in this domain and suggest potential avenues for future research on OOD generalization. A summary of the OOD generalization methodologies surveyed in this paper can be accessed at [> this http URL\n](http://out-of-distribution-generalization.com)> . Comments:|51 pages|\nSubjects:|Machine Learning (cs.LG)|\nCite as:|[arXiv:2108.13624](https://arxiv.org/abs/2108.13624)[cs.LG]|\n|(or[arXiv:2108.13624v2](https://arxiv.org/abs/2108.13624v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2108.13624](https://doi.org/10.48550/arXiv.2108.13624)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Jiashuo Liu [[view email](https://arxiv.org/show-email/b1e61827/2108.13624)]\n**[[v1]](https://arxiv.org/abs/2108.13624v1)**Tue, 31 Aug 2021 05:28:42 UTC (4,533 KB)\n**[v2]**Thu, 27 Jul 2023 13:13:11 UTC (360 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Towards Out-Of-Distribution Generalization: A Survey, by Jiashuo Liu and 6 other authors\n* [View PDF](https://arxiv.org/pdf/2108.13624)\n* [TeX Source](https://arxiv.org/src/2108.13624)\n[![license icon](https://arxiv.org/icons/licenses/by-nc-sa-4.0.png)view license](http://creativecommons.org/licenses/by-nc-sa/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2108.13624&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2108.13624&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2021-08](https://arxiv.org/list/cs.LG/2021-08)\nChange to browse by:\n[cs](https://arxiv.org/abs/2108.13624?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2108.13624)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2108.13624)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2108.13624)\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2108.html#abs-2108-13624)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2108-13624)\n[Zheyan Shen](<https://dblp.uni-trier.de/search/author?author=Zheyan Shen>)\n[Yue He](<https://dblp.uni-trier.de/search/author?author=Yue He>)\n[Han Yu](<https://dblp.uni-trier.de/search/author?author=Han Yu>)\n[Peng Cui](<https://dblp.uni-trier.de/search/author?author=Peng Cui>)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2108.13624&amp;description=Towards Out-Of-Distribution Generalization: A Survey>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2108.13624&amp;title=Towards Out-Of-Distribution Generalization: A Survey>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggl...",
      "url": "https://arxiv.org/abs/2108.13624"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2403.01874] A Survey on Evaluation of Out-of-Distribution Generalization\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2403.01874\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2403.01874**(cs)\n[Submitted on 4 Mar 2024]\n# Title:A Survey on Evaluation of Out-of-Distribution Generalization\nAuthors:[Han Yu](https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+H),[Jiashuo Liu](https://arxiv.org/search/cs?searchtype=author&amp;query=Liu,+J),[Xingxuan Zhang](https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+X),[Jiayun Wu](https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J),[Peng Cui](https://arxiv.org/search/cs?searchtype=author&amp;query=Cui,+P)\nView a PDF of the paper titled A Survey on Evaluation of Out-of-Distribution Generalization, by Han Yu and 4 other authors\n[View PDF](https://arxiv.org/pdf/2403.01874)[HTML (experimental)](https://arxiv.org/html/2403.01874v1)> > Abstract:\n> Machine learning models, while progressively advanced, rely heavily on the IID assumption, which is often unfulfilled in practice due to inevitable distribution shifts. This renders them susceptible and untrustworthy for deployment in risk-sensitive applications. Such a significant problem has consequently spawned various branches of works dedicated to developing algorithms capable of Out-of-Distribution (OOD) generalization. Despite these efforts, much less attention has been paid to the evaluation of OOD generalization, which is also a complex and fundamental problem. Its goal is not only to assess whether a model&#39;s OOD generalization capability is strong or not, but also to evaluate where a model generalizes well or poorly. This entails characterizing the types of distribution shifts that a model can effectively address, and identifying the safe and risky input regions given a model. This paper serves as the first effort to conduct a comprehensive review of OOD evaluation. We categorize existing research into three paradigms: OOD performance testing, OOD performance prediction, and OOD intrinsic property characterization, according to the availability of test data. Additionally, we briefly discuss OOD evaluation in the context of pretrained models. In closing, we propose several promising directions for future research in OOD evaluation. Subjects:|Machine Learning (cs.LG)|\nCite as:|[arXiv:2403.01874](https://arxiv.org/abs/2403.01874)[cs.LG]|\n|(or[arXiv:2403.01874v1](https://arxiv.org/abs/2403.01874v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2403.01874](https://doi.org/10.48550/arXiv.2403.01874)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Han Yu [[view email](https://arxiv.org/show-email/6465b1ce/2403.01874)]\n**[v1]**Mon, 4 Mar 2024 09:30:35 UTC (289 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled A Survey on Evaluation of Out-of-Distribution Generalization, by Han Yu and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2403.01874)\n* [HTML (experimental)](https://arxiv.org/html/2403.01874v1)\n* [TeX Source](https://arxiv.org/src/2403.01874)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2403.01874&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2403.01874&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-03](https://arxiv.org/list/cs.LG/2024-03)\nChange to browse by:\n[cs](https://arxiv.org/abs/2403.01874?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2403.01874)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2403.01874)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2403.01874)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2403.01874&amp;description=A Survey on Evaluation of Out-of-Distribution Generalization>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2403.01874&amp;title=A Survey on Evaluation of Out-of-Distribution Generalization>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2403.01874)|[Disable MathJax](javascript:setMath...",
      "url": "https://arxiv.org/abs/2403.01874"
    },
    {
      "title": "Open-World Machine Learning and Classification",
      "text": "Open-World Machine Learning or Set Recognition or Classification# Open-World Machine Learning and Classification\n### (Open-world Recognition, Open Set Recognition, Open-world AI)\nA form of[Lifelong Learning](https://www.cs.uic.edu/~liub/lifelong-learning.html)\n**Second Edition:\"[Lifelong Machine Learning](https://www.cs.uic.edu/~liub/lifelong-machine-learning.html).\"\nby Z. Chen and B. Liu, Morgan & Claypool, August 2018 (1st edition, 2016)**\n* Three new chapters have been added and others have been updated and/or reorganized.\n* One Chapter is dedicated to[Open World Learning](http://www.cs.uic.edu/~liub/lifelong-learning/open-world-learning.pdf)\n* **Any AI system (e.g., chatbot and self-driving car) that cannot learn in deployment (e.g., chatting and driving) in the real-world open envoronment is not truly intelligent.**\n**An interview in[Nature](https://www.nature.com/articles/d41586-022-01962-y)Outlook, July 20, 2022.**\n**[Learning on the Job in the Open World](http://www.cs.uic.edu/~liub/On-the-Job-Learning-ICML2020-CL-WS.pdf). Invited talk given at the*Continual Learning Workshop*@ ICML-2020, July 17, 2020.**\n**Motivation**: Sooner or later, AI agents will need to explore and learn by themsleves in the real world. They cannot forever depend on manually labeled data. The real world is open and dynamic, and\nfull of unknowns. AI agents must be able to detect the unknowns and learn them in a self-supervised manner. They should not make the*[closed-world assumption](https://aclweb.org/anthology/N16-1061)*any more.\n**Open world learning (OWL)**(a.k.a.**open world recognition or classification,**or**open-world AI)**is getting increasingly important as the learning agent is increasingly**working in or facing the real-world open and dynamic environment**, e.g., chatbot and self-driving car, where the agent**cannot assume or expect**what it will see in the real-world contains only what it has learned previously. For example, a chatbot cannot assume that it knows everything that a user may say. A self-driving car cannot assume that the real-world has only things that it has seen and learned before.**The core of open-world learning or open-world AI is about recognizing unknowns and learning them so that the AI agent will become more and more knowledgeable**.\nClassic machine learning makes the***[closed world assumption](https://aclweb.org/anthology/N16-1061)***, i.e., the classes that the agent sees in training are what it will see in testing (no new objects or classes can appear in testing) (Fei and Liu 2016). A more realistic scenario is to expect**unseen classes**during testing (open world). In this case, the goal is to design a learning algorithm that can classify data of the known/seen classes into their respective classes and also to reject/detect instances from unknown/unseen classes. This problem is called**open-world learning (or open-world classification)**. Apart from detecting the unseen classes, open-world learning should also incrementally or continually learn the new classes.### Tasks of open-world learning (OWL)\n* **Task 1**: learn a classifier that can perform classification of test instances that belong to training/seen classes used in learning, and detect/reject instances that do not belong to the training/seen classes - (the**DOC**algorithm ([EMNLP-2017](https://www.cs.uic.edu/~liub/publications/emnlp17-camera-ready.pdf)) is quite powerful for this task for both text and images).\n* Note -**Rejection here is not the same as the traditional outlier/anormaly detection**. Tradtional outlier detection typically detects outliers from a given dataset based on some unsupervised learning methods, while rejection in open-world learning detects unseen class instances (\"outliers\") on the fly in testing using the classifier trained with only seen class examples (supervised learning), and the classifier also does classification of test instances from the seen classes.\n* **Task 2**: ask the user to provide the unseen classes in the rejected instances or automatically discover the unseen classes based on the knowledge learned in the past ([Shu et al. 2018](https://arxiv.org/abs/1801.05609)).\n* **Task 3**: incrementally learn the new/unseen classes ([Fei et al. 2016](http://www.kdd.org/kdd2016/papers/files/rpp0426-feiA.pdf);[Xu et al. 2019](https://arxiv.org/abs/1809.06004)) without retraining from scratch and without catastrophic forgetting.**Open-world learning in dialogue systems**: We have been working on this topic for the past two years because in dialogues unknown or new things happen all the time. See our 2020 and 2021 papers below.\nIn the process, the system learns and accumulates more and more knowledge ([Fei et al. 2016](http://www.kdd.org/kdd2016/papers/files/rpp0426-feiA.pdf)). The learner is*self-motivated*and*it knows what it does and does not know.*With intelligent systems such as chatbots and self-driving cars increasingly facing the real-world open (unknown) environments, we can no longer make the**closed world assumption**.\n### Publications\n**TextBook**: Zhiyuan Chen and Bing Liu.[Lifelong Machine Learning](https://www.cs.uic.edu/~liub/lifelong-machine-learning.html). Morgan & Claypool, 2018 (2nd edition), 2016 (1st edition).\n* Saleh Momeni, Changnan Xiao, Bing Liu.[Continual Out-of-Distribution Detection with Analytic Neural Collapse](https://www.cs.uic.edu/~liub/publications/AAAI-2025--AnaNC.pdf),*Proceedings of AAAI-2026 (**Oral**)*, Jan. 20 - Jan. 27, 2026, Singapore.\n* Alexander Politowicz, Sahisnu Mazumder, Bing Liu.[Improving OOD Detection Using Segmented Images and Cross-View Attention Fusion](https://www.cs.uic.edu/~liub/publications/WACV-2026.pdf),*Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision 2026 (WACV-2026)*, March 6 - 10, 2026, Tucson, Arizona.\n* Derda Kaymak, Gyuhak Kim, Tomoya Kaichi, Tatsuya Konishi and Bing Liu.[Learning after Model Deployment](https://arxiv.org/abs/2510.17160).*Proceedings of the European Conference on Artificial Intelligence (ECAI-2025)*, Oct 25-30, 2025, Bogona, Italy.\n* Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, Bing Liu.[Open-World Continual Learning: Unifying Novelty Detection and Continual Learning](https://arxiv.org/pdf/2304.10038).*Artificial Intelligence Journal*, 2024.\n* Bing Liu, Sahisnu Mazumder, Eric Robertson, and Scott Grigsby.[AI Autonomy: Self-Initiated Open-World Continual Learning and Adaptation](https://onlinelibrary.wiley.com/doi/10.1002/aaai.12087).**AI Magazine**, May 21, 2023.\n* Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, Bing Liu.[Open-World Continual Learning: Unifying Novelty Detection and Continual Learning](https://arxiv.org/abs/2304.10038). arXiv:2304.10038 [cs.LG].\n* Nianzu Ma, Sahisnu Mazumder, Alexander Politowicz, Bing Liu, Eric Robertson and Scott Grigsby.[Detecting and Characterizing Semantic Novelties in Factual Text Involving Named Entities](https://www.cs.uic.edu/~liub/publications/EMNLP-Ma.pdf).*Proceedings of The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP-2022)*, December 7\u201311, 2022.\n* Sepideh Esmaeilpour, Lei Shu, Bing Liu.[Open-set Recognition via Augmentation-based Similarity Learning](https://www.cs.uic.edu/~liub/publications/CoLLAs2022_open_set_recognition).*Proceedings of Conference on Lifelong Learning Agents (CoLLAs 2022)*, August 22-24, 2022.\n* Mengyu Wang, Yijia Shao, Haowei Lin, Wenpeng Hu, and Bing Liu.[CMG: A Class-Mixed Generation Approach to Out-of-Distribution Detection](https://www.cs.uic.edu/~liub/publications/ECML-2022-OOD-detection.pdf).*Proceedings of ECML/PKDD-2022*, September 19-23, 2022, Grenoble, France.\n* Bing Liu, Sahisnu Mazumder, Eric Robertson, and Scott Grigsby.[AI Autonomy: Self-Initiation, Adaptation and Continual Learning](https://arxiv.org/abs/2203.08994).*arXiv:2203.08994 [cs.AI]*, March 17, 2022.\n* Bing Liu, Eric Robertson, Scott Grigsby, and Sahisnu Mazumder.[Self-Initiated Open World Learning for Autonomous AI Agents](https://arxiv....",
      "url": "https://www.cs.uic.edu/~liub/open-classification.html"
    },
    {
      "title": "How to handle unseen categorical values in test data set using python?",
      "text": "##### Collectives\u2122 on Stack Overflow\n\nFind centralized, trusted content and collaborate around the technologies you use most.\n\n[Learn more about Collectives](https://stackoverflow.com/collectives)\n\n**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\nGet early access and see previews of new features.\n\n[Learn more about Labs](https://stackoverflow.co/labs/)\n\n# [How to handle unseen categorical values in test data set using python?](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python)\n\n[Ask Question](https://stackoverflow.com/questions/ask)\n\nAsked7 years, 5 months ago\n\nModified [3 years, 6 months ago](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python?lastactivity)\n\nViewed\n6k times\n\n7\n\nSuppose I have location feature. In train data set its unique values are 'NewYork', 'Chicago'. But in test set it has 'NewYork', 'Chicago', 'London'.\nSo while creating one hot encoding how to ignore 'London'?\nIn other words, How not to encode the categories that only appear in the test set?\n\n- [python](https://stackoverflow.com/questions/tagged/python)\n- [machine-learning](https://stackoverflow.com/questions/tagged/machine-learning)\n- [feature-extraction](https://stackoverflow.com/questions/tagged/feature-extraction)\n- [categorical-data](https://stackoverflow.com/questions/tagged/categorical-data)\n- [one-hot-encoding](https://stackoverflow.com/questions/tagged/one-hot-encoding)\n\n[Share](https://stackoverflow.com/q/41733997)\n\n[Improve this question](https://stackoverflow.com/posts/41733997/edit)\n\nFollow\n\n[edited Jan 19, 2017 at 5:17](https://stackoverflow.com/posts/41733997/revisions)\n\nNeo\n\nasked Jan 19, 2017 at 4:52\n\n[![Neo's user avatar](https://www.gravatar.com/avatar/6535cd1a64a7309276f6ea0da042a62e?s=64&d=identicon&r=PG&f=y&so-version=2)](https://stackoverflow.com/users/3516936/neo)\n\n[Neo](https://stackoverflow.com/users/3516936/neo) Neo\n\n4,41855 gold badges2222 silver badges2828 bronze badges\n\n0\n\n[Add a comment](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python)\u00a0\\|\n\n## 3 Answers 3\n\nSorted by:\n[Reset to default](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python?answertab=scoredesc#tab-top)\n\nHighest score (default)Trending (recent votes count more)Date modified (newest first)Date created (oldest first)\n\n2\n\nYou can use the parameter handle\\_unknown in one hot encoding.\n\n```\nohe = OneHotEncoder(handle_unknown=\u2018ignore\u2019)\n\n```\n\nThis will not show an error and will let execution occur.\n\nSee Documentation for more\n[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n\n[Share](https://stackoverflow.com/a/65268659)\n\n[Improve this answer](https://stackoverflow.com/posts/65268659/edit)\n\nFollow\n\nanswered Dec 12, 2020 at 18:55\n\n[![devansh's user avatar](https://www.gravatar.com/avatar/7f83f423fc8d65750f9d2dbd1b52a65b?s=64&d=identicon&r=PG)](https://stackoverflow.com/users/13540874/devansh)\n\n[devansh](https://stackoverflow.com/users/13540874/devansh) devansh\n\n8922 silver badges88 bronze badges\n\n[Add a comment](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python)\u00a0\\|\n\n1\n\n**Often you never want to eliminate information.** You want to wrap this information prior within your model. For example you might have some data with NaN values:\n\n```\ntrain_data = ['NewYork', 'Chicago', NaN]\n\n```\n\n### Solution 1\n\nYou will likely have a way of dealing with this, whether you impute, delete, etc.. is up to you based on the problem. More often than not you can have NaN be it's own category, as this is information as well. Something like this can suffice:\n\n```\n# function to replace NA in categorical variables\ndef fill_categorical_na(df, var_list):\n  X = df.copy()\n  X[var_list] = df[var_list].fillna('Missing')\n  return X\n\n# replace missing values with new label: \"Missing\"\nX_train = fill_categorical_na(X_train, vars_with_na)\nX_test = fill_categorical_na(X_test, vars_with_na)\n\n```\n\nTherefore, when you move to production you could write a script that pushes unseen categories into this \"missing\" category you've established earlier.\n\n### Solution 2\n\nIf you're not satisfied with that idea, you could always turn these unusual cases into a new unique category that we'll call \"rare\" because it's not present often.\n\n```\ntrain_data = ['NewYork', 'Chicago', 'NewYork', 'Chicago', 'London']\n\n# let's capture the categorical variables first\ncat_vars = [var for var in X_train.columns if X_train[var].dtype == 'O']\n\ndef find_frequent_labels(df, var, rare_perc):\n  df = df.copy()\n  tmp = df.groupby(var)['Target_Variable'].count() / len(df)\n  return tmp[tmp>rare_perc].index\n\nfor var in cat_vars:\n  frequent_ls = find_frequent_labels(X_train, var, 0.01)\n  X_train[var] = np.where(X_train[var].isin(frequent_ls), X_train[var], 'Rare')\n  X_test[var] = np.where(X_test[var].isin(frequent_ls), X_test[var], 'Rare')\n\n```\n\nNow, given enough instances of the \"normal\" categories, London will get pushed into the \"Rare\" category. Regardless of how many new categories might show up, they will be grouped into 'Rare' as a category; pending they remain rare instances and don't become dominate categories.\n\n[Share](https://stackoverflow.com/a/55998159)\n\n[Improve this answer](https://stackoverflow.com/posts/55998159/edit)\n\nFollow\n\nanswered May 6, 2019 at 2:37\n\n[![kevin_theinfinityfund's user avatar](https://i.sstatic.net/nKoP1.png?s=64)](https://stackoverflow.com/users/8419574/kevin-theinfinityfund)\n\n[kevin\\_theinfinityfund](https://stackoverflow.com/users/8419574/kevin-theinfinityfund) kevin\\_theinfinityfund\n\n2,0071717 silver badges1818 bronze badges\n\n4\n\n- Someone explain the downvote. This clearly addresses the question.\n\n\u2013\u00a0[kevin\\_theinfinityfund](https://stackoverflow.com/users/8419574/kevin-theinfinityfund)\n\nCommentedJan 20, 2020 at 8:09\n\n- The problem with your answer is that you conveniently ignore that unseen categories remain unseen. It does not matter if you rename `London` into `NaN` or `rare`, and what encoding scheme you use. If every training example is either `NewYork` or `Chicago`, the model has no opportunity to learn what to do with other categories.\n\n\u2013\u00a0[paperskilltrees](https://stackoverflow.com/users/11932910/paperskilltrees)\n\nCommentedAug 24, 2022 at 4:41\n\n- 1\n\n\n\n\n\nI\u2019m saying that during the serving layer of whatever ML system you\u2019re using you\u2019d always be filling in any non-frequent type as \u201crare\u201d. In your training layer and model development stage you will have some small percentage of \u201crare\u201d categories. Ex: If it\u2019s mean imputation let\u2019s say \u201crare\u201d=0.1. During model serving you get a never-before-seen \u201cToronto.\u201d Your serving layer will map \u201cToronto\u201d -> \u201crare\u201d -> 0.1.\n\n\u2013\u00a0[kevin\\_theinfinityfund](https://stackoverflow.com/users/8419574/kevin-theinfinityfund)\n\nCommentedAug 25, 2022 at 5:49\n\n- Fair enough! I guess this would be the normal real-world scenario. Still it is possible OP had a toy, academic or a very special example in which this is not the case. One could probably synthesize the \"rare\" category by sampling from other categories or by hard-code the train mean into the imputer for unseen categories.\n\n\u2013\u00a0[paperskilltrees](https://stackoverflow.com/users/11932910/paperskilltrees)\n\nCommentedAug 25, 2022 at 6:01\n\n\n[Add a comment](https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python)\u00a0\\|\n\n-1\n\nAssuming this to be your lists\n\n```\ntrain_data = ['NewYork', 'Chicago']\ntest_set = ['NewYork', 'Chicago', 'London']\n\n```\n\nBased on your question :\n\n> How not to encode the categories that only appear in the test...",
      "url": "https://stackoverflow.com/questions/41733997/how-to-handle-unseen-categorical-values-in-test-data-set-using-python"
    },
    {
      "title": "Detecting and Learning Out-of-Distribution Data in the Open world: Algorithm and Theory",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2310.06221"
    },
    {
      "title": "",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/pdf/2507.21160"
    },
    {
      "title": "Learning and the Unknown: Surveying Steps toward Open World Recognition",
      "text": "Learning and the Unknown: Surveying Steps toward Open World Recognition - AAAI\n* [Skip to main content](#genesis-content)\n* [Skip to primary sidebar](#genesis-sidebar-primary)\n[![AAAI](https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White.png)](https://aaai.org/)\nAAAI\nAssociation for the Advancement of Artificial Intelligence\n**Menu\n**Menu\n[Home](https://aaai.org)\\>[Proceedings](https://aaai.org/aaai-publications/aaai-conference-proceedings/)/[Proceedings of the AAAI Conference on Artificial Intelligence, 33](https://aaai.org/proceeding/aaai-33-2019/)\\>[No. 1: AAAI-19, IAAI-19, EAAI-20](https://aaai.org/proceeding/01-aaai-19-iaai-19-eaai-20/)\n# Learning and the Unknown: Surveying Steps toward Open World Recognition\nFebruary 1, 2023\n#### Authors\nT. E. Boult\nUniversity of Colorado\nS. Cruz\nUniversity of Colorado\nA.R. Dhamija\nUniversity of Colorado\nM. Gunther\nUniversity of Colorado\nJ. Henrydoss\nUniversity of Colorado\nW.J. Scheirer\nUniversity of Notre Dame\n#### Proceedings:\nNo. 1: AAAI-19, IAAI-19, EAAI-20\nVolume\n#### Issue:\nProceedings of the AAAI Conference on Artificial Intelligence, 33\n#### Track:\nSenior Member Presentation Track: Summary Talks\n#### Downloads:\n[Download PDF](<https://cdn.aaai.org/ojs/5054/5054-Article Text-8117-1-10-20190709.pdf>)\n#### Abstract:\nAs science attempts to close the gap between man and machine by building systems capable of learning, we must embrace the importance of the unknown. The ability to differentiate between known and unknown can be considered a critical element of any intelligent self-learning system. The ability to reject uncertain inputs has a very long history in machine learning, as does including a background or garbage class to account for inputs that are not of interest. This paper explains why neither of these is genuinely sufficient for handling unknown inputs \u2013uncertain is not unknown, and unknowns need not appear to be uncertain to a learning system. The past decade has seen the formalization and development of many open set algorithms, which provably bound the risk from unknown classes. We summarize the state of the art, core ideas, and results and explain why, despite the efforts to date, the current techniques are genuinely insufficient for handling unknown inputs, especially for deep networks.\n#### DOI:\n10.1609/aaai.v33i01.33019801\nAAAI\nProceedings of the AAAI Conference on Artificial Intelligence, 33\n## Primary Sidebar\nWe use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking \u201cAccept All\u201d, you consent to the use of ALL the cookies. However, you may visit \"Cookie Settings\" to provide a controlled consent.\nCookie SettingsAccept All\nManage consent\nClose\n#### Privacy Overview\nThis website uses cookies to improve your experience while you navigate through the website. Out of these, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may affect your browsing experience.\nNecessary\nNecessary\nAlways Enabled\nNecessary cookies are absolutely essential for the website to function properly. These cookies ensure basic functionalities and security features of the website, anonymously.|Cookie|Duration|Description|\ncookielawinfo-checkbox-analytics|11 months|This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category \"Analytics\".|\ncookielawinfo-checkbox-functional|11 months|The cookie is set by GDPR cookie consent to record the user consent for the cookies in the category \"Functional\".|\ncookielawinfo-checkbox-necessary|11 months|This cookie is set by GDPR Cookie Consent plugin. The cookies is used to store the user consent for the cookies in the category \"Necessary\".|\ncookielawinfo-checkbox-others|11 months|This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category \"Other.|\ncookielawinfo-checkbox-performance|11 months|This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category \"Performance\".|\nviewed\\_cookie\\_policy|11 months|The cookie is set by the GDPR Cookie Consent plugin and is used to store whether or not user has consented to the use of cookies. It does not store any personal data.|\nFunctional\nFunctional\nFunctional cookies help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features.\nPerformance\nPerformance\nPerformance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.\nAnalytics\nAnalytics\nAnalytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics the number of visitors, bounce rate, traffic source, etc.\nAdvertisement\nAdvertisement\nAdvertisement cookies are used to provide visitors with relevant ads and marketing campaigns. These cookies track visitors across websites and collect information to provide customized ads.\nOthers\nOthers\nOther uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.\nSAVE &amp; ACCEPT\nWe are using cookies to give you the best experience on our website.\nYou can find out more about which cookies we are using or switch them off insettings.\nAccept\nClose GDPR Cookie Settings\n![AAAI](https://aaai.org/wp-content/plugins/gdpr-cookie-compliance/dist/images/gdpr-logo.png)\n* Privacy Overview\n* Strictly Necessary Cookies\n[Powered byGDPR Cookie Compliance](https://wordpress.org/plugins/gdpr-cookie-compliance/)\nPrivacy Overview\nThis website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful.\nStrictly Necessary Cookies\nStrictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings.\nEnable or Disable CookiesEnabledDisabled\nEnable AllSave Settings",
      "url": "https://aaai.org/papers/09801-learning-and-the-unknown-surveying-steps-toward-open-world-recognition"
    }
  ]
}