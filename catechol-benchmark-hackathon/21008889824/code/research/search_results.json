{
  "query": "How can I use PyTorch Geometric for molecular property prediction with SMILES input?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Based on the PyTorch\u202fGeometric documentation and a practical tutorial, you can go from a SMILES string to a trained molecular\u2011property predictor in just a few steps ([torch_geometric.utils.smiles](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/utils/smiles.html); [MoleculeNet](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html); [Blopig blog](https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric)).\n\n1. **Install the required packages**  \n   ```bash\n   conda install -c conda-forge pytorch pytorch-geometric rdkit\n   ```  \n   (PyTorch\u202fGeometric pulls in `torch`, `torch_scatter`, etc.; RDKit is needed to parse SMILES.)  \n\n2. **Import libraries and the SMILES\u2011to\u2011graph helper**  \n   ```python\n   import torch\n   from torch_geometric.data import Data, DataLoader\n   from torch_geometric.utils import from_smiles   # wrapper around RDKit conversion\n   ```  \n   (`from_smiles` internally uses the `from_rdmol` routine that maps atoms and bonds to feature vectors\u202f([torch_geometric.utils.smiles](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/utils/smiles.html)).)  \n\n3. **Convert SMILES strings to `torch_geometric.data.Data` objects**  \n   ```python\n   smiles_list = [\"CCO\", \"c1ccccc1O\", ...]          # your molecules\n   labels      = [0.5, -1.2, ...]                   # target property values\n\n   graphs = [from_smiles(s) for s in smiles_list]  # each is a Data object\n   for g, y in zip(graphs, labels):\n       g.y = torch.tensor([y], dtype=torch.float)\n   ```  \n\n4. **Create a dataset (optional: use a built\u2011in benchmark)**  \n   *If you want a ready\u2011made benchmark, instantiate `MoleculeNet` and pass the same `from_smiles` function:*  \n   ```python\n   from torch_geometric.datasets import MoleculeNet\n   dataset = MoleculeNet(root=\"data/moleculenet\",\n                         name=\"ESOL\",               # any MoleculeNet split\n                         from_smiles=from_smiles)   # converts raw SMILES on the fly\n   ```  \n   (The `MoleculeNet` class automatically adds the OGB node/edge features\u202f([MoleculeNet docs](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html)).)  \n\n5. **Define a simple GNN model** (e.g., Graph Convolutional Network)  \n   ```python\n   import torch.nn.functional as F\n   from torch_geometric.nn import GCNConv, global_mean_pool\n\n   class GCN(torch.nn.Module):\n       def __init__(self, hidden_dim=64):\n           super().__init__()\n           self.conv1 = GCNConv(dataset.num_node_features, hidden_dim)\n           self.conv2 = GCNConv(hidden_dim, hidden_dim)\n           self.lin   = torch.nn.Linear(hidden_dim, 1)\n\n       def forward(self, data):\n           x, edge_index, batch = data.x, data.edge_index, data.batch\n           x = F.relu(self.conv1(x, edge_index))\n           x = F.relu(self.conv2(x, edge_index))\n           x = global_mean_pool(x, batch)          # graph\u2011level readout\n           return self.lin(x).squeeze()\n   ```  \n\n6. **Train the model**  \n   ```python\n   loader = DataLoader(dataset, batch_size=32, shuffle=True)\n   model  = GCN()\n   optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n   for epoch in range(1, 101):\n       model.train()\n       total_loss = 0\n       for batch in loader:\n           optimizer.zero_grad()\n           pred = model(batch)\n           loss = F.mse_loss(pred, batch.y)\n           loss.backward()\n           optimizer.step()\n           total_loss += loss.item()\n       print(f\"Epoch {epoch}: loss {total_loss/len(loader):.4f}\")\n   ```  \n\n7. **Evaluate on a test split** (the `MoleculeNet` object already provides `train_mask`, `val_mask`, `test_mask`):  \n   ```python\n   model.eval()\n   with torch.no_grad():\n       pred = model(dataset)\n       test_mae = torch.mean(torch.abs(pred[dataset.test_mask] -\n                                      dataset.y[dataset.test_mask]))\n   print(f\"Test MAE: {test_mae.item():.3f}\")\n   ```  \n\nThese seven steps take a list of SMILES strings, turn them into graph objects via `torch_geometric.utils.from_smiles`, optionally load a standard benchmark with `MoleculeNet`, build a GNN, and train it to predict any molecular property you supply as labels.",
      "url": ""
    },
    {
      "title": "torch_geometric.utils.smiles \u2014 pytorch_geometric documentation",
      "text": "- [Module code](https://pytorch-geometric.readthedocs.io/en/latest/_modules/index.html)\n- torch\\_geometric.utils.smiles\n\n* * *\n\n# Source code for torch\\_geometric.utils.smiles\n\n```\nfromtypingimport Any, Dict, List\n\nimporttorch\n\nimporttorch_geometric\n\nx_map: Dict[str, List[Any]] = {\n    'atomic_num':\n    list(range(0, 119)),\n    'chirality': [\n        'CHI_UNSPECIFIED',\n        'CHI_TETRAHEDRAL_CW',\n        'CHI_TETRAHEDRAL_CCW',\n        'CHI_OTHER',\n        'CHI_TETRAHEDRAL',\n        'CHI_ALLENE',\n        'CHI_SQUAREPLANAR',\n        'CHI_TRIGONALBIPYRAMIDAL',\n        'CHI_OCTAHEDRAL',\n    ],\n    'degree':\n    list(range(0, 11)),\n    'formal_charge':\n    list(range(-5, 7)),\n    'num_hs':\n    list(range(0, 9)),\n    'num_radical_electrons':\n    list(range(0, 5)),\n    'hybridization': [\n        'UNSPECIFIED',\n        'S',\n        'SP',\n        'SP2',\n        'SP3',\n        'SP3D',\n        'SP3D2',\n        'OTHER',\n    ],\n    'is_aromatic': [False, True],\n    'is_in_ring': [False, True],\n}\n\ne_map: Dict[str, List[Any]] = {\n    'bond_type': [\n        'UNSPECIFIED',\n        'SINGLE',\n        'DOUBLE',\n        'TRIPLE',\n        'QUADRUPLE',\n        'QUINTUPLE',\n        'HEXTUPLE',\n        'ONEANDAHALF',\n        'TWOANDAHALF',\n        'THREEANDAHALF',\n        'FOURANDAHALF',\n        'FIVEANDAHALF',\n        'AROMATIC',\n        'IONIC',\n        'HYDROGEN',\n        'THREECENTER',\n        'DATIVEONE',\n        'DATIVE',\n        'DATIVEL',\n        'DATIVER',\n        'OTHER',\n        'ZERO',\n    ],\n    'stereo': [\n        'STEREONONE',\n        'STEREOANY',\n        'STEREOZ',\n        'STEREOE',\n        'STEREOCIS',\n        'STEREOTRANS',\n    ],\n    'is_conjugated': [False, True],\n}\n\n[docs]deffrom_rdmol(mol: Any) -> 'torch_geometric.data.Data':\nr\"\"\"Converts a :class:`rdkit.Chem.Mol` instance to a\n    :class:`torch_geometric.data.Data` instance.\n\n    Args:\n        mol (rdkit.Chem.Mol): The :class:`rdkit` molecule.\n    \"\"\"\n    fromrdkitimport Chem\n\n    fromtorch_geometric.dataimport Data\n\n    assert isinstance(mol, Chem.Mol)\n\n    xs: List[List[int]] = []\n    for atom in mol.GetAtoms():\n        row: List[int] = []\n        row.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n        row.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n        row.append(x_map['degree'].index(atom.GetTotalDegree()))\n        row.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n        row.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n        row.append(x_map['num_radical_electrons'].index(\n            atom.GetNumRadicalElectrons()))\n        row.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n        row.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n        row.append(x_map['is_in_ring'].index(atom.IsInRing()))\n        xs.append(row)\n\n    x = torch.tensor(xs, dtype=torch.long).view(-1, 9)\n\n    edge_indices, edge_attrs = [], []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n\n        e = []\n        e.append(e_map['bond_type'].index(str(bond.GetBondType())))\n        e.append(e_map['stereo'].index(str(bond.GetStereo())))\n        e.append(e_map['is_conjugated'].index(bond.GetIsConjugated()))\n\n        edge_indices += [[i, j], [j, i]]\n        edge_attrs += [e, e]\n\n    edge_index = torch.tensor(edge_indices)\n    edge_index = edge_index.t().to(torch.long).view(2, -1)\n    edge_attr = torch.tensor(edge_attrs, dtype=torch.long).view(-1, 3)\n\n    if edge_index.numel() > 0:  # Sort indices.\n        perm = (edge_index[0] * x.size(0) + edge_index[1]).argsort()\n        edge_index, edge_attr = edge_index[:, perm], edge_attr[perm]\n\n    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n\n[docs]deffrom_smiles(\n    smiles: str,\n    with_hydrogen: bool = False,\n    kekulize: bool = False,\n) -> 'torch_geometric.data.Data':\nr\"\"\"Converts a SMILES string to a :class:`torch_geometric.data.Data`\n    instance.\n\n    Args:\n        smiles (str): The SMILES string.\n        with_hydrogen (bool, optional): If set to :obj:`True`, will store\n            hydrogens in the molecule graph. (default: :obj:`False`)\n        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n            bonds to single/double bonds. (default: :obj:`False`)\n    \"\"\"\n    fromrdkitimport Chem, RDLogger\n\n    RDLogger.DisableLog('rdApp.*')  # type: ignore\n\n    mol = Chem.MolFromSmiles(smiles)\n\n    if mol is None:\n        mol = Chem.MolFromSmiles('')\n    if with_hydrogen:\n        mol = Chem.AddHs(mol)\n    if kekulize:\n        Chem.Kekulize(mol)\n\n    data = from_rdmol(mol)\n    data.smiles = smiles\n    return data\n\n[docs]defto_rdmol(\n    data: 'torch_geometric.data.Data',\n    kekulize: bool = False,\n) -> Any:\n\"\"\"Converts a :class:`torch_geometric.data.Data` instance to a\n    :class:`rdkit.Chem.Mol` instance.\n\n    Args:\n        data (torch_geometric.data.Data): The molecular graph data.\n        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n            bonds to single/double bonds. (default: :obj:`False`)\n    \"\"\"\n    fromrdkitimport Chem\n\n    mol = Chem.RWMol()\n\n    assert data.x is not None\n    assert data.num_nodes is not None\n    assert data.edge_index is not None\n    assert data.edge_attr is not None\n    for i in range(data.num_nodes):\n        atom = Chem.Atom(int(data.x[i, 0]))\n        atom.SetChiralTag(Chem.rdchem.ChiralType.values[int(data.x[i, 1])])\n        atom.SetFormalCharge(x_map['formal_charge'][int(data.x[i, 3])])\n        atom.SetNumExplicitHs(x_map['num_hs'][int(data.x[i, 4])])\n        atom.SetNumRadicalElectrons(x_map['num_radical_electrons'][int(\n            data.x[i, 5])])\n        atom.SetHybridization(Chem.rdchem.HybridizationType.values[int(\n            data.x[i, 6])])\n        atom.SetIsAromatic(bool(data.x[i, 7]))\n        mol.AddAtom(atom)\n\n    edges = [tuple(i) for i in data.edge_index.t().tolist()]\n    visited = set()\n\n    for i in range(len(edges)):\n        src, dst = edges[i]\n        if tuple(sorted(edges[i])) in visited:\n            continue\n\n        bond_type = Chem.BondType.values[int(data.edge_attr[i, 0])]\n        mol.AddBond(src, dst, bond_type)\n\n        # Set stereochemistry:\n        stereo = Chem.rdchem.BondStereo.values[int(data.edge_attr[i, 1])]\n        if stereo != Chem.rdchem.BondStereo.STEREONONE:\n            db = mol.GetBondBetweenAtoms(src, dst)\n            db.SetStereoAtoms(dst, src)\n            db.SetStereo(stereo)\n\n        # Set conjugation:\n        is_conjugated = bool(data.edge_attr[i, 2])\n        mol.GetBondBetweenAtoms(src, dst).SetIsConjugated(is_conjugated)\n\n        visited.add(tuple(sorted(edges[i])))\n\n    mol = mol.GetMol()\n\n    if kekulize:\n        Chem.Kekulize(mol)\n\n    Chem.SanitizeMol(mol)\n    Chem.AssignStereochemistry(mol)\n\n    return mol\n\n[docs]defto_smiles(\n    data: 'torch_geometric.data.Data',\n    kekulize: bool = False,\n) -> str:\n\"\"\"Converts a :class:`torch_geometric.data.Data` instance to a SMILES\n    string.\n\n    Args:\n        data (torch_geometric.data.Data): The molecular graph.\n        kekulize (bool, optional): If set to :obj:`True`, converts aromatic\n            bonds to single/double bonds. (default: :obj:`False`)\n    \"\"\"\n    fromrdkitimport Chem\n    mol = to_rdmol(data, kekulize=kekulize)\n    return Chem.MolToSmiles(mol, isomericSmiles=True)\n\n```",
      "url": "https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/utils/smiles.html"
    },
    {
      "title": "torch_geometric.datasets.MoleculeNet \u2014 pytorch_geometric documentation",
      "text": "torch_geometric.datasets.MoleculeNet \u2014 pytorch_geometric documentation https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html\ntorch_geometric.datasets.MoleculeNet \u2014 pytorch_geometric documentation\nNone\n2025-01-01T00:00:00Z\n# torch_geometric.datasets.MoleculeNet [](pytorch-geometric.readthedocs.io/en/latest/...)\n_class_ MoleculeNet( _root:[str](https://docs.python.org/3/library/stdtypes.html#str)_, _name:[str](https://docs.python.org/3/library/stdtypes.html#str)_, _transform:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _pre_transform:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _pre_filter:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _force_reload:[bool](https://docs.python.org/3/library/functions.html#bool)=False_, _from_smiles:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_) [[source]](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/molecule_net.html#MoleculeNet) [](pytorch-geometric.readthedocs.io/en/latest/...)\nBases: [`InMemoryDataset`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset)\nThe [MoleculeNet](http://moleculenet.org/datasets-1) benchmark\ncollection from the [\u201cMoleculeNet: A Benchmark for Molecular Machine\nLearning\u201d](https://arxiv.org/abs/1703.00564) paper, containing datasets\nfrom physical chemistry, biophysics and physiology.\nAll datasets come with the additional node and edge features introduced by\nthe\n[Open Graph Benchmark](https://ogb.stanford.edu/docs/graphprop/).\nParameters:\n- **root** ( [_str_](https://docs.python.org/3/library/stdtypes.html#str)) \u2013 Root directory where the dataset should be saved.\n- **name** ( [_str_](https://docs.python.org/3/library/stdtypes.html#str)) \u2013 The name of the dataset ( `\"ESOL\"`, `\"FreeSolv\"`,\n`\"Lipo\"`, `\"PCBA\"`, `\"MUV\"`, `\"HIV\"`,\n`\"BACE\"`, `\"BBBP\"`, `\"Tox21\"`, `\"ToxCast\"`,\n`\"SIDER\"`, `\"ClinTox\"`).\n- **transform** ( _callable_ _,_ _optional_) \u2013 A function/transform that takes in an\n[`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a transformed\nversion. The data object will be transformed before every access.\n(default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **pre_transform** ( _callable_ _,_ _optional_) \u2013 A function/transform that takes in\nan [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a\ntransformed version. The data object will be transformed before\nbeing saved to disk. (default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **pre_filter** ( _callable_ _,_ _optional_) \u2013 A function that takes in an\n[`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a boolean\nvalue, indicating whether the data object should be included in the\nfinal dataset. (default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **force_reload** ( [_bool_](https://docs.python.org/3/library/functions.html#bool) _,_ _optional_) \u2013 Whether to re-process the dataset.\n(default: [`False`](https://docs.python.org/3/library/constants.html#False))\n- **from_smiles** ( _callable_ _,_ _optional_) \u2013 A custom function that takes a SMILES\nstring and outputs a [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object.\nIf not set, defaults to [`from_smiles()`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.from_smiles).\n(default: [`None`](https://docs.python.org/3/library/constants.html#None))\n**STATS:**\n| Name | #graphs | #nodes | #edges | #features | #classes |\n| ESOL | 1,128 | ~13.3 | ~27.4 | 9 | 1 |\n| FreeSolv | 642 | ~8.7 | ~16.8 | 9 | 1 |\n| Lipophilicity | 4,200 | ~27.0 | ~59.0 | 9 | 1 |\n| PCBA | 437,929 | ~26.0 | ~56.2 | 9 | 128 |\n| MUV | 93,087 | ~24.2 | ~52.6 | 9 | 17 |\n| HIV | 41,127 | ~25.5 | ~54.9 | 9 | 1 |\n| BACE | 1513 | ~34.1 | ~73.7 | 9 | 1 |\n| BBBP | 2,050 | ~23.9 | ~51.6 | 9 | 1 |\n| Tox21 | 7,831 | ~18.6 | ~38.6 | 9 | 12 |\n| ToxCast | 8,597 | ~18.7 | ~38.4 | 9 | 617 |\n| SIDER | 1,427 | ~33.6 | ~70.7 | 9 | 27 |\n| ClinTox | 1,484 | ~26.1 | ~55.5 | 9 | 2 |",
      "url": "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html"
    },
    {
      "title": "How to turn a SMILES string into a molecular graph for Pytorch Geometric",
      "text": "Despite some of their technical [issues](https://www.blopig.com/blog/2021/10/issues-with-graph-neural-networks-the-cracks-are-where-the-light-shines-through/), graph neural networks (GNNs) are quickly being adopted as one of the state-of-the-art methods for molecular property prediction. The differentiable extraction of molecular features from low-level molecular graphs has become a viable (although not always superior) alternative to classical molecular representation techniques such as Morgan fingerprints and molecular descriptor vectors.\n\nBut molecular data usually comes in the sequential form of labeled SMILES strings. It is not obvious for beginners how to optimally transform a SMILES string into a structured molecular graph object that can be used as an input for a GNN. In this post, we show how to convert a SMILES string into a molecular graph object which can subsequently be used for graph-based machine learning. We do so within the framework of **Pytorch Geometric** which currently is one of the best and most commonly used Python-based GNN-libraries.\n\nWe divide our task into three high-level steps:\n\n1. We define a function that maps an RDKit atom object to a suitable atom feature vector.\n2. We define a function that maps an RDKit bond object to a suitable bond feature vector.\n3. We define a function that takes as its input a list of SMILES strings and associated labels and then uses the functions from 1.) and 2.) to create a list of labeled Pytorch Geometric graph objects as its output.\n\n**Step 0: Import Packages**\n\nAs always, we first import the necessary Python packages for our endeavour:\n\n```\n# import packages\n\n# general tools\nimport numpy as np\n\n# RDkit\nfrom rdkit import Chem\nfrom rdkit.Chem.rdmolops import GetAdjacencyMatrix\n\n# Pytorch and Pytorch Geometric\nimport torch\nfrom torch_geometric.data import Data\nfrom torch.utils.data import DataLoader\n```\n\n**Step 1: Atom Featurisation**\n\nWe start by defining an auxiliary function which transforms a value x into a one-hot encoding based on a list of permitted values for x:\n\n```\ndef one_hot_encoding(x, permitted_list):\n    \"\"\"\n    Maps input elements x which are not in the permitted list to the last element\n    of the permitted list.\n    \"\"\"\n\n    if x not in permitted_list:\n        x = permitted_list[-1]\n\n    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n\n    return binary_encoding\n```\n\nNow we use this auxiliary function to define the actual atom featurisation function:\n\n```\ndef get_atom_features(atom,\n                      use_chirality = True,\n                      hydrogens_implicit = True):\n    \"\"\"\n    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n    \"\"\"\n\n    # define list of permitted atoms\n\n    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n\n    if hydrogens_implicit == False:\n        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n\n    # compute atom features\n\n    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n\n    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n\n    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n\n    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n\n    is_in_a_ring_enc = [int(atom.IsInRing())]\n\n    is_aromatic_enc = [int(atom.GetIsAromatic())]\n\n    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n\n    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n\n    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n\n    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n\n    if use_chirality == True:\n        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n        atom_feature_vector += chirality_type_enc\n\n    if hydrogens_implicit == True:\n        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n        atom_feature_vector += n_hydrogens_enc\n\n    return np.array(atom_feature_vector)\n```\n\nTo encapsulate as much information as possible within the molecular graph, we include a plethora of atomic features: atom type, number of heavy atom neighbours, formal charge, hybridisation type, whether the atom is in a ring, whether the atom is aromatic, atomic mass, Van der Waals radius, and covalent radius. The last three properties are numerical in nature and are thus automatically scaled to a reasonable range using empirically estimated quantities. The user can explicitly specify whether to use chirality as a stereochemical feature and whether to treat hydrogen atoms implicitly or explicitly.\n\n**Step 2: Bond Featurisation**\n\nNow that we have constructed a function to conveniently turn RDKit atom objects into feature vectors, we define an analogous function for RDKit bond objects:\n\n```\ndef get_bond_features(bond,\n                      use_stereochemistry = True):\n    \"\"\"\n    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n    \"\"\"\n\n    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n\n    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n\n    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n\n    bond_is_in_ring_enc = [int(bond.IsInRing())]\n\n    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n\n    if use_stereochemistry == True:\n        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n        bond_feature_vector += stereo_type_enc\n\n    return np.array(bond_feature_vector)\n```\n\nThe bond features we consider in the above function are: bond type, whether the bond is conjugated, and whether the bond is in a ring. As an additional option, the user can specify whether to include E-Z stereochemical features around double bonds.\n\n**Step 3: Generating labeled Pytorch Geometric Graph Objects**\n\nEquipped with suitable functions to turn RDKit atom objects and RDKit bond objects into informative feature vectors, we swiftly move on to define a function which turns a list of SMILES strings and an associated list of labels (such as pKi values) into a list of Pytorch Geometric graph objects:\n\n```\ndef create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n    \"\"\"\n    Inputs:\n\n    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n\n    Outputs:\n\n    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n\n    \"\"\"\n\n    data_list = []\n\n    for (smiles, y_val) in zip(x_smiles, y):\n\n        # convert SMILES to RDKit mol object\n        mol = Chem.MolFromSmiles(smiles)\n\n        # get feature dimensions\n        n_nodes = mol.GetNumAtoms()\n        n_edges = 2*mol.GetNumBonds()\n        unrelated_smiles = \"O=O\"\n        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n\n        # construct node feature matrix X of shape ...",
      "url": "https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric"
    },
    {
      "title": "Source code for torch_geometric.datasets.molecule_net",
      "text": "<div><div><pre><span></span><span>import</span><span> </span><span>os</span>\n<span>import</span><span> </span><span>os.path</span><span> </span><span>as</span><span> </span><span>osp</span>\n<span>import</span><span> </span><span>re</span>\n<span>import</span><span> </span><span>warnings</span>\n<span>from</span><span> </span><span>typing</span><span> </span><span>import</span> <span>Callable</span><span>,</span> <span>Dict</span><span>,</span> <span>Optional</span><span>,</span> <span>Tuple</span><span>,</span> <span>Union</span>\n<span>import</span><span> </span><span>torch</span>\n<span>from</span><span> </span><span>torch_geometric.data</span><span> </span><span>import</span> <span>InMemoryDataset</span><span>,</span> <span>download_url</span><span>,</span> <span>extract_gz</span>\n<span>from</span><span> </span><span>torch_geometric.utils</span><span> </span><span>import</span> <span>from_smiles</span> <span>as</span> <span>_from_smiles</span>\n<p><a href=\"https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeNet.html#torch_geometric.datasets.MoleculeNet\">[docs]</a><span>class</span><span> </span><span>MoleculeNet</span><span>(</span><span>InMemoryDataset</span><span>):</span>\n<span> </span><span>r</span><span>\"\"\"The `MoleculeNet &lt;http://moleculenet.org/datasets-1&gt;`_ benchmark</span>\n<span> collection from the `\"MoleculeNet: A Benchmark for Molecular Machine</span>\n<span> Learning\" &lt;https://arxiv.org/abs/1703.00564&gt;`_ paper, containing datasets</span>\n<span> from physical chemistry, biophysics and physiology.</span>\n<span> All datasets come with the additional node and edge features introduced by</span>\n<span> the :ogb:`null`</span>\n<span> `Open Graph Benchmark &lt;https://ogb.stanford.edu/docs/graphprop/&gt;`_.</span>\n<span> Args:</span>\n<span> root (str): Root directory where the dataset should be saved.</span>\n<span> name (str): The name of the dataset (:obj:`\"ESOL\"`, :obj:`\"FreeSolv\"`,</span>\n<span> :obj:`\"Lipo\"`, :obj:`\"PCBA\"`, :obj:`\"MUV\"`, :obj:`\"HIV\"`,</span>\n<span> :obj:`\"BACE\"`, :obj:`\"BBBP\"`, :obj:`\"Tox21\"`, :obj:`\"ToxCast\"`,</span>\n<span> :obj:`\"SIDER\"`, :obj:`\"ClinTox\"`).</span>\n<span> transform (callable, optional): A function/transform that takes in an</span>\n<span> :obj:`torch_geometric.data.Data` object and returns a transformed</span>\n<span> version. The data object will be transformed before every access.</span>\n<span> (default: :obj:`None`)</span>\n<span> pre_transform (callable, optional): A function/transform that takes in</span>\n<span> an :obj:`torch_geometric.data.Data` object and returns a</span>\n<span> transformed version. The data object will be transformed before</span>\n<span> being saved to disk. (default: :obj:`None`)</span>\n<span> pre_filter (callable, optional): A function that takes in an</span>\n<span> :obj:`torch_geometric.data.Data` object and returns a boolean</span>\n<span> value, indicating whether the data object should be included in the</span>\n<span> final dataset. (default: :obj:`None`)</span>\n<span> force_reload (bool, optional): Whether to re-process the dataset.</span>\n<span> (default: :obj:`False`)</span>\n<span> from_smiles (callable, optional): A custom function that takes a SMILES</span>\n<span> string and outputs a :obj:`~torch_geometric.data.Data` object.</span>\n<span> If not set, defaults to :meth:`~torch_geometric.utils.from_smiles`.</span>\n<span> (default: :obj:`None`)</span>\n<span> **STATS:**</span>\n<span> .. list-table::</span>\n<span> :widths: 20 10 10 10 10 10</span>\n<span> :header-rows: 1</span>\n<span> * - Name</span>\n<span> - #graphs</span>\n<span> - #nodes</span>\n<span> - #edges</span>\n<span> - #features</span>\n<span> - #classes</span>\n<span> * - ESOL</span>\n<span> - 1,128</span>\n<span> - ~13.3</span>\n<span> - ~27.4</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - FreeSolv</span>\n<span> - 642</span>\n<span> - ~8.7</span>\n<span> - ~16.8</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - Lipophilicity</span>\n<span> - 4,200</span>\n<span> - ~27.0</span>\n<span> - ~59.0</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - PCBA</span>\n<span> - 437,929</span>\n<span> - ~26.0</span>\n<span> - ~56.2</span>\n<span> - 9</span>\n<span> - 128</span>\n<span> * - MUV</span>\n<span> - 93,087</span>\n<span> - ~24.2</span>\n<span> - ~52.6</span>\n<span> - 9</span>\n<span> - 17</span>\n<span> * - HIV</span>\n<span> - 41,127</span>\n<span> - ~25.5</span>\n<span> - ~54.9</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - BACE</span>\n<span> - 1513</span>\n<span> - ~34.1</span>\n<span> - ~73.7</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - BBBP</span>\n<span> - 2,050</span>\n<span> - ~23.9</span>\n<span> - ~51.6</span>\n<span> - 9</span>\n<span> - 1</span>\n<span> * - Tox21</span>\n<span> - 7,831</span>\n<span> - ~18.6</span>\n<span> - ~38.6</span>\n<span> - 9</span>\n<span> - 12</span>\n<span> * - ToxCast</span>\n<span> - 8,597</span>\n<span> - ~18.7</span>\n<span> - ~38.4</span>\n<span> - 9</span>\n<span> - 617</span>\n<span> * - SIDER</span>\n<span> - 1,427</span>\n<span> - ~33.6</span>\n<span> - ~70.7</span>\n<span> - 9</span>\n<span> - 27</span>\n<span> * - ClinTox</span>\n<span> - 1,484</span>\n<span> - ~26.1</span>\n<span> - ~55.5</span>\n<span> - 9</span>\n<span> - 2</span>\n<span> \"\"\"</span>\n <span>url</span> <span>=</span> <span>'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/</span><span>{}</span><span>'</span>\n <span># Format: name: (display_name, url_name, csv_name, smiles_idx, y_idx)</span>\n <span>names</span><span>:</span> <span>Dict</span><span>[</span><span>str</span><span>,</span> <span>Tuple</span><span>[</span><span>str</span><span>,</span> <span>str</span><span>,</span> <span>str</span><span>,</span> <span>int</span><span>,</span> <span>Union</span><span>[</span><span>int</span><span>,</span> <span>slice</span><span>]]]</span> <span>=</span> <span>{</span>\n <span>'esol'</span><span>:</span> <span>(</span><span>'ESOL'</span><span>,</span> <span>'delaney-processed.csv'</span><span>,</span> <span>'delaney-processed'</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>-</span><span>2</span><span>),</span>\n <span>'freesolv'</span><span>:</span> <span>(</span><span>'FreeSolv'</span><span>,</span> <span>'SAMPL.csv'</span><span>,</span> <span>'SAMPL'</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>),</span>\n <span>'lipo'</span><span>:</span> <span>(</span><span>'Lipophilicity'</span><span>,</span> <span>'Lipophilicity.csv'</span><span>,</span> <span>'Lipophilicity'</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>),</span>\n <span>'pcba'</span><span>:</span> <span>(</span><span>'PCBA'</span><span>,</span> <span>'pcba.csv.gz'</span><span>,</span> <span>'pcba'</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>slice</span><span>(</span><span>0</span><span>,</span> <span>128</span><span>)),</span>\n <span>'muv'</span><span>:</span> <span>(</span><span>'MUV'</span><span>,</span> <span>'muv.csv.gz'</span><span>,</span> <span>'muv'</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>slice</span><span>(</span><span>0</span><span>,</span> <span>17</span><span>)),</span>\n <span>'hiv'</span><span>:</span> <span>(</span><span>'HIV'</span><span>,</span> <span>'HIV.csv'</span><span>,</span> <span>'HIV'</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>),</span>\n <span>'bace'</span><span>:</span> <span>(</span><span>'BACE'</span><span>,</span> <span>'bace.csv'</span><span>,</span> <span>'bace'</span><span>,</span> <span>0</span><span>,</span> <span>2</span><span>),</span>\n <span>'bbbp'</span><span>:</span> <span>(</span><span>'BBBP'</span><span>,</span> <span>'BBBP.csv'</span><span>,</span> <span>'BBBP'</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>-</span><span>2</span><span>),</span>\n <span>'tox21'</span><span>:</span> <span>(</span><span>'Tox21'</span><span>,</span> <span>'tox21.csv.gz'</span><span>,</span> <span>'tox21'</span><span>...",
      "url": "https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/molecule_net.html"
    },
    {
      "title": "torch_geometric.llm.models.MoleculeGPT \u2014 pytorch_geometric documentation",
      "text": "<div> \n <div>\n <nav>\n \n </nav>\n <section><nav>\n <i></i>\n <a href=\"https://pytorch-geometric.readthedocs.io/en/latest/index.html\">pytorch_geometric</a>\n </nav>\n <section>\n<dl>\n<dt>\n<em><span>class</span><span> </span></em><span><span>MoleculeGPT</span></span><span>(</span><em><span><span>llm</span></span><span><span>:</span></span><span> </span><span><a href=\"https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.llm.models.LLM.html#torch_geometric.llm.models.LLM\"><span>LLM</span></a></span></em>, <em><span><span>graph_encoder</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module\"><span>Module</span></a></span></em>, <em><span><span>smiles_encoder</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module\"><span>Module</span></a></span></em>, <em><span><span>mlp_out_channels</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/functions.html#int\"><span>int</span></a></span><span> </span><span><span>=</span></span><span> </span><span><span>32</span></span></em>, <em><span><span>max_tokens</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.Optional\"><span>Optional</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/functions.html#int\"><span>int</span></a><span><span>]</span></span></span><span> </span><span><span>=</span></span><span> </span><span><span>20</span></span></em><span>)</span><a href=\"https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/llm/models/molecule_gpt.html#MoleculeGPT\"><span><span>[source]</span></span></a><a href=\"#torch_geometric.llm.models.MoleculeGPT\">\uf0c1</a></dt>\n<dd><p>Bases: <a href=\"https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module\"><code><span>Module</span></code></a></p>\n<p>The MoleculeGPT model from the <a href=\"https://ai4d3.github.io/papers/34.pdf\">\u201cMoleculeGPT: Instruction\nFollowing Large Language Models for Molecular Property Prediction\u201d</a> paper.</p>\n<dl>\n<dt>Parameters<span>:</span></dt>\n<dd><ul>\n<li><p><strong>llm</strong> (<a href=\"https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.llm.models.LLM.html#torch_geometric.llm.models.LLM\"><em>LLM</em></a>) \u2013 The LLM to use.</p></li>\n<li><p><strong>graph_encoder</strong> (<a href=\"https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module\"><em>torch.nn.Module</em></a>) \u2013 Encode 2D molecule graph.</p></li>\n<li><p><strong>smiles_encoder</strong> (<a href=\"https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module\"><em>torch.nn.Module</em></a>) \u2013 Encode 1D SMILES.</p></li>\n<li><p><strong>mlp_out_channels</strong> (<a href=\"https://docs.python.org/3/library/functions.html#int\"><em>int</em></a><em>, </em><em>optional</em>) \u2013 The size of each embedding\nafter qformer encoding. (default: <code><span>32</span></code>)</p></li>\n<li><p><strong>max_tokens</strong> (<a href=\"https://docs.python.org/3/library/functions.html#int\"><em>int</em></a><em>, </em><em>optional</em>) \u2013 Max output tokens of 1D/2D encoder.\n(default: <code><span>20</span></code>)</p></li>\n</ul>\n</dd>\n</dl>\n<div>\n<p>Warning</p>\n<p>This module has been tested with the following HuggingFace models</p>\n<ul>\n<li><p><code><span>llm_to_use=\"lmsys/vicuna-7b-v1.5\"</span></code></p></li>\n</ul>\n<p>and may not work with other models. See other models at <a href=\"https://huggingface.co/models\">HuggingFace\nModels</a> and let us know if you\nencounter any issues.</p>\n</div>\n<dl>\n<dt>\n<span><span>forward</span></span><span>(</span><em><span><span>x</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor\"><span>Tensor</span></a></span></em>, <em><span><span>edge_index</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor\"><span>Tensor</span></a></span></em>, <em><span><span>batch</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor\"><span>Tensor</span></a></span></em>, <em><span><span>edge_attr</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.Optional\"><span>Optional</span></a><span><span>[</span></span><a href=\"https://docs.pytorch.org/docs/main/tensors.html#torch.Tensor\"><span>Tensor</span></a><span><span>]</span></span></span></em>, <em><span><span>smiles</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.List\"><span>List</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/stdtypes.html#str\"><span>str</span></a><span><span>]</span></span></span></em>, <em><span><span>instructions</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.List\"><span>List</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/stdtypes.html#str\"><span>str</span></a><span><span>]</span></span></span></em>, <em><span><span>label</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.List\"><span>List</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/stdtypes.html#str\"><span>str</span></a><span><span>]</span></span></span></em>, <em><span><span>additional_text_context</span></span><span><span>:</span></span><span> </span><span><a href=\"https://docs.python.org/3/library/typing.html#typing.Optional\"><span>Optional</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/typing.html#typing.List\"><span>List</span></a><span><span>[</span></span><a href=\"https://docs.python.org/3/library/stdtypes.html#str\"><span>str</span></a><span><span>]</span></span><span><span>]</span></span></span><span> </span><span><span>=</span></span><span> </span><span><span>None</span></span></em><span>)</span><a href=\"https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/llm/models/molecule_gpt.html#MoleculeGPT.forward\"><span><span>[source]</span></span></a><a href=\"#torch_geometric.llm.models.MoleculeGPT.forward\">\uf0c1</a></dt>\n<dd><p>Define the computation performed at every call.</p>\n<p>Should be overridden by all subclasses.</p>\n<div>\n<p>Note</p>\n<p>Although the recipe for forward pass needs to be defined within\nthis function, one should call the <code><span>Module</span></code> instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.</p>\n</div>\n</dd></dl>\n</dd></dl>\n</section>\n </section>\n </div>\n \n</div>",
      "url": "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.llm.models.MoleculeGPT.html"
    },
    {
      "title": "torch_geometric.datasets.MoleculeGPTDataset \u2014 pytorch_geometric documentation",
      "text": "torch_geometric.datasets.MoleculeGPTDataset \u2014 pytorch_geometric documentation https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeGPTDataset.html\ntorch_geometric.datasets.MoleculeGPTDataset \u2014 pytorch_geometric documentation\nNone\n2025-01-01T00:00:00Z\n# torch_geometric.datasets.MoleculeGPTDataset [\uf0c1]\n_class_ MoleculeGPTDataset( _root:[str](https://docs.python.org/3/library/stdtypes.html#str)_, _transform:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _pre_transform:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _pre_filter:[Optional](https://docs.python.org/3/library/typing.html#typing.Optional)[ [Callable](https://docs.python.org/3/library/typing.html#typing.Callable)]=None_, _force_reload:[bool](https://docs.python.org/3/library/functions.html#bool)=False_, _total_page_num:[int](https://docs.python.org/3/library/functions.html#int)=10_, _total_block_num:[int](https://docs.python.org/3/library/functions.html#int)=1_, _num_units:[int](https://docs.python.org/3/library/functions.html#int)=-1_) [[source]](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/molecule_gpt_dataset.html#MoleculeGPTDataset) [\uf0c1]\nBases: [`InMemoryDataset`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html#torch_geometric.data.InMemoryDataset)\nThe dataset from the [\u201cMoleculeGPT: Instruction Following Large\nLanguage Models for Molecular Property Prediction\u201d](https://ai4d3.github.io/papers/34.pdf) paper.\nParameters:\n- **root** ( [_str_](https://docs.python.org/3/library/stdtypes.html#str)) \u2013 Root directory where the dataset should be saved.\n- **transform** ( _callable_ _,_ _optional_) \u2013 A function/transform that takes in an\n[`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a transformed\nversion. The data object will be transformed before every access.\n(default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **pre_transform** ( _callable_ _,_ _optional_) \u2013 A function/transform that takes in\nan [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a\ntransformed version. The data object will be transformed before\nbeing saved to disk. (default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **pre_filter** ( _callable_ _,_ _optional_) \u2013 A function that takes in an\n[`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object and returns a boolean\nvalue, indicating whether the data object should be included in the\nfinal dataset. (default: [`None`](https://docs.python.org/3/library/constants.html#None))\n- **force_reload** ( [_bool_](https://docs.python.org/3/library/functions.html#bool) _,_ _optional_) \u2013 Whether to re-process the dataset.\n(default: [`False`](https://docs.python.org/3/library/constants.html#False))\n- **total_page_num** ( [_int_](https://docs.python.org/3/library/functions.html#int) _,_ _optional_) \u2013 The number of pages from PubChem.\n(default: `10`)\n- **total_block_num** ( [_int_](https://docs.python.org/3/library/functions.html#int) _,_ _optional_) \u2013 The blocks of SDF files from PubChem.\n(default: `1`)\n- **num_units** ( [_int_](https://docs.python.org/3/library/functions.html#int) _,_ _optional_) \u2013 Number of units of the sample.\n(default: `-1`, which means all units will be used)",
      "url": "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.MoleculeGPTDataset.html"
    },
    {
      "title": "GitHub - itakigawa/pyg_chemprop: A concise and easy-to-customize reimplementation of \"ChemProp\" (Yang et al, 2019) in PyTorch Geometric.",
      "text": "[Skip to content](https://github.com/itakigawa/pyg_chemprop#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/itakigawa/pyg_chemprop) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/itakigawa/pyg_chemprop) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/itakigawa/pyg_chemprop) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[itakigawa](https://github.com/itakigawa)/ **[pyg\\_chemprop](https://github.com/itakigawa/pyg_chemprop)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fitakigawa%2Fpyg_chemprop) You must be signed in to change notification settings\n- [Fork\\\n6](https://github.com/login?return_to=%2Fitakigawa%2Fpyg_chemprop)\n- [Star\\\n16](https://github.com/login?return_to=%2Fitakigawa%2Fpyg_chemprop)\n\n\nA concise and easy-to-customize reimplementation of \"ChemProp\" (Yang et al, 2019) in PyTorch Geometric.\n\n### License\n\n[MIT license](https://github.com/itakigawa/pyg_chemprop/blob/main/LICENSE)\n\n[16\\\nstars](https://github.com/itakigawa/pyg_chemprop/stargazers) [6\\\nforks](https://github.com/itakigawa/pyg_chemprop/forks) [Branches](https://github.com/itakigawa/pyg_chemprop/branches) [Tags](https://github.com/itakigawa/pyg_chemprop/tags) [Activity](https://github.com/itakigawa/pyg_chemprop/activity)\n\n[Star](https://github.com/login?return_to=%2Fitakigawa%2Fpyg_chemprop)\n\n[Notifications](https://github.com/login?return_to=%2Fitakigawa%2Fpyg_chemprop) You must be signed in to change notification settings\n\n# itakigawa/pyg\\_chemprop\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/itakigawa/pyg_chemprop/branches) [Tags](https://github.com/itakigawa/pyg_chemprop/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[5 Commits](https://github.com/itakigawa/pyg_chemprop/commits/main/) |\n| [.gitignore](https://github.com/itakigawa/pyg_chemprop/blob/main/.gitignore) | [.gitignore](https://github.com/itakigawa/pyg_chemprop/blob/main/.gitignore) |  |  |\n| [LICENSE](https://github.com/itakigawa/pyg_chemprop/blob/main/LICENSE) | [LICENSE](https://github.com/itakigawa/pyg_chemprop/blob/main/LICENSE) |  |  |\n| [README.md](https://github.com/itakigawa/pyg_chemprop/blob/main/README.md) | [README.md](https://github.com/itakigawa/pyg_chemprop/blob/main/README.md) |  |  |\n| [pyg\\_chemprop.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop.py) | [pyg\\_chemprop.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop.py) |  |  |\n| [pyg\\_chemprop\\_naive.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop_naive.py) | [pyg\\_chemprop\\_naive.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop_naive.py) |  |  |\n| [pyg\\_chemprop\\_utils.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop_utils.py) | [pyg\\_chemprop\\_utils.py](https://github.com/itakigawa/pyg_chemprop/blob/main/pyg_chemprop_utils.py) |  |  |\n| [test\\_ogbg-molhiv.ipynb](https://github.com/itakigawa/pyg_chemprop/blob/main/test_ogbg-molhiv.ipynb) | [test\\_ogbg-molhiv.ipynb](https://github.com/itakigawa/pyg_chemprop/blob/main/test_ogbg-molhiv.ipynb) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# ChemProp in PyTorch Geometric\n\nA concise and easy-to-customize reimplementation of \"ChemProp\" (Yang et al, 2019) in [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric).\n\n# Features\n\n- \"pyg\\_chemprop\\_utils\" includes a converter from smiles to a pyg object defining a molecular graph with atom- and bond- features in the original ChemProp. (this requires [RDKit](https://github.com/rdkit/rdkit))\n- \"pyg\\_chemprop.py\" uses [pytorch\\_scatter](https://github.com/rusty1s/pytorch_scatter), and requires the \"index of reverse edges\" for ChemProp. You'll need to preprocess pyg datasets (or lists of pyg objects) like\n\n```\nfrom pyg_chemprop import RevIndexedDataset\nfrom ogb.graphproppred import PygGraphPropPredDataset\npyg_dataset = PygGraphPropPredDataset(name=\"ogbg-molhiv\", root=\"dataset/\")\ndataset = RevIndexedDataset(pyg_dataset)\n```\n\n- \"pyg\\_chemprop\\_naive.py\" does not use [pytorch\\_scatter](https://github.com/rusty1s/pytorch_scatter). It's very slow, but easy to understand what is going on inside ChemProp.\n\n# Usage\n\nSee [test\\_ogbg-molhiv.ipynb](https://github.com/itakigawa/pyg_chemprop/blob/main/test_ogbg-molhiv.ipynb).\n\n# Speed Test\n\nEnvironment\n\n- torch 1.8.1\n- torch\\_geometric 2.0.1\n- torch\\_scatter 2.0.8\n- ogb 1.3.2\n\nResults\n\n- data: \"ogbg-molhiv\" training dataset (32,901 molecules)\n- batch\\_size: 50\n- gpu: A100-PCIE-40GB\n\n|  | device | features | time per epoch |\n| --- | --- | --- | --- |\n| original chemprop | CPU | chemprop | 70 sec |\n|  | GPU | chemprop | 15 sec |\n| ours (w pytorch\\_scatter) | CPU | ogb default | **28 sec** |\n|  | GPU | ogb default | **5 sec** |\n| ours (w pytorch\\_scatter) | CPU | chemprop | **59 sec** |\n|  | GPU | chemprop | **7 sec** |\n| ours (w/o pytorch\\_scatter) | CPU | ogb default | 1277 sec |\n|  | GPU | ogb default | 1743 sec |\n\n# ChemProp (Yang et al, 2019)\n\n\"ChemProp\" is a simple but effective Graph Neural Network (GNN) for Molecular Property Prediction, and was successfully used in anti-biotic discovery by Machine Learning for Pharmaceutical Discovery and Synthesis Consortium (MLPDS), MIT.\n\n- The original code: [https://github.com/chemprop/chemprop](https://github.com/chemprop/chemprop)\n- Yang et al (2019). Analyzing Learned Molecular Representations for Property Prediction. _JCIM_, 59(8), 3370\u20133388. [https://doi.org/10.1021/acs.jcim.9b00237](https://doi.org/10.1021/acs.jcim.9b00237)\n- Yang et al (2019). Correction to Analyzing Learned Molecular Representations for Property Prediction. _JCIM_, 59(12), 5304\u20135305. [https://doi.org/10.1021/acs.jcim.9b01076](https://doi.org/10.1021/acs.jcim.9b01076)\n- Stokes et al (2020). A Deep Learning Approach to Antibiotic Discovery. _Cell_, 180(4), 688\u2013702.e13. [https://doi.org/10.1016/j.cell.2020.01.021](https://doi.org/10.1016/j.cell.2020.01.021)\n- Marchant (2020). Powerful antibiotics discovered using AI. _Nature_, [https://doi.org/10.1038/d41586-020-00018-3](https://doi.org/10.1038/d41586-020-00018-3)\n\n# Author\n\n- Ichigaku Takigawa\n\n## About\n\nA concise and easy-to-customize reimplementation of \"ChemProp\" (Yang et al, 2019) in PyTorch Geometric.\n\n### Resources\n\n[Readme](https://github.com/itakigawa/pyg_chemprop#readme-ov-file)\n\n### License\n\n[MIT license](https://github.com/itakigawa/pyg_chemprop#MIT-1-ov-file)\n\n[Activity](https://github.com/itakigawa/pyg_chemprop/activity)\n\n### Stars\n\n[**16**\\\nstars](https://github.com/itakigawa/pyg_chemprop/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/itakigawa/pyg_chemprop/watchers)\n\n### Forks\n\n[**6**\\\nforks](https://github.com/itakigawa/pyg_chemprop/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fitakigawa%2Fpyg_chemprop&report=itakigawa+%28user%29)\n\n## [Releases](https://github.com/itakigawa/pyg_chemprop/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/itakigawa/packages?repo_name=pyg_chemprop)\n\nNo packages published\n\n## Languages\n\n- [Jupyter Notebook79.4%](https://github.com/itakigawa/pyg_chemprop/search?l=jupyter-notebook)\n- [Python20.6%](https://github.com/itakigawa/pyg_chemprop/search?l=python)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/itakigawa/pyg_chemprop"
    },
    {
      "title": "Building A Graph Convolutional Network for Molecular Property Prediction",
      "text": "[Sitemap](https://medium.com/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F978b0ae10ec4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fbuilding-a-graph-convolutional-network-for-molecular-property-prediction-978b0ae10ec4&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2Fdata-science%2Fbuilding-a-graph-convolutional-network-for-molecular-property-prediction-978b0ae10ec4&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[**TDS Archive**](https://medium.com/data-science?source=post_page---publication_nav-7f60cf5620c9-978b0ae10ec4---------------------------------------)\n\n\u00b7\n\nAn archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.\n\n## Artificial Intelligence\n\n# Building A Graph Convolutional Network for Molecular Property Prediction\n\n## Tutorial to make molecular graphs and develop a simple PyTorch-based GCN\n\n[Gaurav Deshmukh](https://medium.com/@ChemAndCode?source=post_page---byline--978b0ae10ec4---------------------------------------)\n\n17 min read\n\n\u00b7\n\nDec 23, 2023\n\n--\n\n6\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\nArtificial intelligence has taken the world by storm. Every week, new models, tools, and applications emerge that promise to push the boundaries of human endeavor. The availability of open-source tools that enable users to train and employ complex machine learning models in a modest number of lines of code have truly democratized AI; at the same time, while many of these off-the-shelf models may provide excellent predictive capabilities, their usage as black box models may deprive inquisitive students of AI of a deeper understanding of how they work and why they were developed in the first place. This understanding is particularly important in the natural sciences, where knowing that a model is accurate is not enough \u2014 it is also essential to know its connection to other physical theories, its limitations, and its generalizability to other systems. In this article, we will explore the basics of one particular ML model \u2014 a graph convolutional network \u2014 through the lens of chemistry. This is not meant to be a mathematically rigorous exploration; instead, we will try to compare features of the network with traditional models in the natural sciences and think about why it works as well as it does.\n\n## 1\\. The need for graphs and graph neural networks\n\nA model in chemistry or physics is usually a continuous function, say _y=f(x\u2081, x\u2082, x\u2083, \u2026, x\u2099)_, in which _x\u2081, x\u2082, x\u2083, \u2026, x\u2099_ are the inputs and _y_ is the output. An example of such a model is the equation that determines the electrostatic interaction (or force) between two point charges _q\u2081_ and _q\u2082_ separated by a distance _r_ present in a medium with relative permittivity _\u03b5\u1d63_, commonly termed as Coulomb\u2019s law.\n\nPress enter or click to view image in full size\n\nFigure 1: The Coulomb equation as a model for electrostatic interactions between point charges (Image by author)\n\nIf we did not know this relationship but, hypothetically, had multiple datapoints each including the interaction between point charges (the output) and the corresponding inputs, we could fit an artificial neural network to predict the interaction for any given point charges for any given separation in a medium with a specified permittivity. In the case of this problem, admittedly ignoring some important caveats, creating a data-driven model for a physical problem is relatively straightforward.\n\nNow consider the problem of prediction of a particular property, say solubility in water, from the structure of a molecule. First, there is no obvious set of inputs to describe a molecule. You could use various features, such as bond lengths, bond angles, number of different types of elements, number of rings, and so forth. However, there is no guarantee that any such arbitrary set is bound to work well for all molecules.\n\nSecond, unlike the example of the point charges, the inputs may not necessarily reside in a continuous space. For example, we can think of methanol, ethanol, and propanol as a set of molecules with increasing chain lengths; there is no notion, however, of anything between them \u2014 chain length is a discrete parameter and there is no way to interpolate between methanol and ethanol to get other molecules. Having a continuous space of inputs is essential to calculate derivatives of the model, which can then be used for optimization of the chosen property.\n\nTo overcome these problems, various methods for encoding molecules have been proposed. One such method is textual representation using schemes such as SMILES and SELFIES. There is a large body of literature on this representation, and I direct the interested reader to this [helpful review](https://www.cell.com/patterns/pdf/S2666-3899(22)00206-9.pdf). The second method involves representing molecules as graphs. While each method has its advantages and shortcomings, graph representations feel more intuitive for chemistry.\n\nA graph is a mathematical structure consisting of nodes connected by edges that represent relationships between nodes. Molecules fit naturally into this structure \u2014 atoms become nodes, and bonds become edges. Each node in the graph is represented by a vector that encodes properties of the corresponding atom. Usually, a one-hot encoding scheme suffices (more on this in the next section). These vectors can be stacked to create a _node matrix._ Relationships between nodes \u2014 denoted by edges \u2014 can be delineated through a square _adjacency matrix,_ wherein every element _a\u1d62\u2c7c_ is either 1 or 0 depending on whether the two nodes _i_ and _j_ are connected by an edge or not respectively. The diagonal elements are set to 1, indicating a self-connection, which makes the matrix amenable to convolutions (as you will see in the next section). More complex graph representations can be developed, in which edge properties are also one-hot encoded in a separate matrix, but we shall leave that for another article. These node and adjacency matrices will serve as inputs to our model.\n\nPress enter or click to view image in full size\n\nFigure 2: Representation of an acetamide molecule as a graph with one-hot encodings of atomic numbers of nodes (Image by author)\n\nTypically, artificial neural network models accept a 1-dimensional vector of inputs. For multidimensional inputs, such as images, a class of models called convolutional neural networks was developed. In our case too we have 2-dimensional matrices as inputs, and therefore, need a modified network that can accept these as inputs. Graph neural networks were developed to operate on such node and adjacency matrices to convert them into appropriate 1-dimensional vectors that can then be passed through hidden layers of a vanilla artificial neural network to generate outputs. There are many types of graph neural networks, such as graph convolutional networks, message passing networks, graph attention networks, and so forth, which primarily differ ...",
      "url": "https://medium.com/data-science/building-a-graph-convolutional-network-for-molecular-property-prediction-978b0ae10ec4"
    }
  ]
}