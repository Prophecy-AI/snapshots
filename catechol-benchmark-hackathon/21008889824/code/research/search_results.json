{
  "query": "How does the evaluation work in Kaggle competitions where submissions are evaluated using cross-validation on the server side?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Kaggle competitions keep the true labels of the test data hidden from participants.\u202fWhen you upload a prediction file, the competition server scores it against a **hold\u2011out set** that is split into a public portion (used for the live leaderboard) and a private portion (used for the final ranking)\u202f\u30105\u2020L1-L4\u3011.\u202fRather than evaluating a single static slice, many competitions run a **k\u2011fold cross\u2011validation** on the hidden test set: the server partitions the hold\u2011out data into\u202fk\u202ffolds, computes the chosen metric on each fold, and then aggregates the results (often by averaging) to produce a single score for your submission.\u202fThis approach reduces variance caused by a particular split and gives a more reliable estimate of how the model would perform on unseen data.\n\nBecause participants can submit repeatedly, the leaderboard can become **adaptive**\u2014teams may unintentionally over\u2011fit to the public hold\u2011out.\u202fTo guard against this, Kaggle (and research such as *The Ladder*) uses algorithms that limit the information leaked from each evaluation (e.g., by rounding scores or restricting submission frequency) while still providing a useful public score\u202f\u301010\u2020L1-L9\u3011.\u202fThe private leaderboard, evaluated only once after the competition ends, provides the final, unbiased ranking.\n\nIn practice, you should treat the public score as a noisy proxy for the true performance and rely on robust cross\u2011validation on your own training data to select models, knowing that the server\u2011side CV will ultimately confirm which approach generalises best on the hidden test data.",
      "url": ""
    },
    {
      "title": "A note on \"proper\" Cross-Validation techniques for ...",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/getting-started/398047"
    },
    {
      "title": "Cross-Validation",
      "text": "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\n###### Something went wrong and this page crashed!\n\nIf the issue persists, it's likely a problem on our side.\n\n```\n\nLoading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)keyboard_arrow_upcontent_copyChunkLoadError: Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\n    at b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=f2bc5978f08b75213e7a:1:11021)\n```\n\nRefresh",
      "url": "https://www.kaggle.com/code/alexisbcook/cross-validation"
    },
    {
      "title": "Tutorial: K Fold Cross Validation",
      "text": "menu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\nCreate\n\nsearch\u200b\n\n- [explore\\\n\\\nHome](https://www.kaggle.com/)\n\n- [emoji\\_events\\\n\\\nCompetitions](https://www.kaggle.com/competitions)\n\n- [table\\_chart\\\n\\\nDatasets](https://www.kaggle.com/datasets)\n\n- [tenancy\\\n\\\nModels](https://www.kaggle.com/models)\n\n- [code\\\n\\\nCode](https://www.kaggle.com/code)\n\n- [comment\\\n\\\nDiscussions](https://www.kaggle.com/discussions)\n\n- [school\\\n\\\nLearn](https://www.kaggle.com/learn)\n\n\n- [expand\\_more\\\n\\\nMore](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation)\n\n\nauto\\_awesome\\_motion\n\nView Active Events\n\nmenu\n\n[Skip to\\\n\\\ncontent](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#site-content)\n\n[![Kaggle](https://www.kaggle.com/static/images/site-logo.svg)](https://www.kaggle.com/)\n\nsearch\u200b\n\n[Sign In](https://www.kaggle.com/account/login?phase=startSignInTab&returnUrl=%2Fcode%2Fsatishgunjal%2Ftutorial-k-fold-cross-validation)\n\n[Register](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2Fcode%2Fsatishgunjal%2Ftutorial-k-fold-cross-validation)\n\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\nSatish Gunjal \u00b7 4y ago \u00b7 92,586 views\n\narrow\\_drop\\_up131\n\nCopy & Edit249\n\n![gold medal](https://www.kaggle.com/static/images/medals/notebooks/goldl@1x.png)\n\nmore\\_vert\n\n# Tutorial: K Fold Cross Validation\n\n## Tutorial: K Fold Cross Validation\n\n[Notebook](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation/notebook) [Input](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation/input) [Output](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation/output) [Logs](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation/log) [Comments (5)](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation/comments)\n\nhistoryVersion 7 of 7chevron\\_right\n\n## Runtime\n\nplay\\_arrow\n\n2m 35s\n\n## Input\n\nCOMPETITIONS\n\n![](https://www.kaggle.com/competitions/5407/images/thumbnail)\n\nHouse Prices - Advanced Regression Techniques\n\n![](https://www.kaggle.com/competitions/3136/images/thumbnail)\n\nTitanic - Machine Learning from Disaster\n\n## Tags\n\n[Classification](https://www.kaggle.com/code?tagIds=13302-Classification) [Regression](https://www.kaggle.com/code?tagIds=14203-Regression)\n\n## Language\n\nPython\n\n## Table of Contents\n\n[Index](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Index) [Introduction](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Introduction-) [Inner Working of Cross Validation](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Inner-Working-of-Cross-Validation-) [K Fold Cross Validation](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#K-Fold-Cross-Validation-) [Stratified K Fold Cross Validation](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Stratified-K-Fold-Cross-Validation-) [Hyperparameter Tuning and Model Selection](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Hyperparameter-Tuning-and-Model-Selection-) [Advantages](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Advantages-) [Disadvantages](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Disadvantages-) [K Fold: Regression Example](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#K-Fold:-Regression-Example-) [Import Libraries](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Import-Libraries-) [Load Dataset](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Load-Dataset-) [Understanding the Data](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Understanding-the-Data-) [Model Score Using KFold](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Model-Score-Using-KFold-) [Model Tuning using KFold](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Model-Tuning-using-KFold-) [K Fold: Classification Example](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#K-Fold:-Classification-Example-) [Using Logistic Regression](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Using-Logistic-Regression-) [Using Decision Classifier](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Using-Decision-Classifier-) [Using Random Forest Classifier](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Using-Random-Forest-Classifier-) [Decision Tree Classifier Tuning](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Decision-Tree-Classifier-Tuning-) [Reference](https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation#Reference-)\n\n![Profile picture for undefined](https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1739697666&Signature=JVVWuDBwsOVtiIWfxdVES7uWSyf%2Bps87MWLfWJ4GthhX9l2wvME9fn8paJlGoTXB%2B61Ng1U%2F9Dws7W9CvZLWlNwwBrzkLSOK1MuCj%2FR3z4XcSWskcH8Ntiy74IZbEqlkNoEWj%2FI%2FVrI%2Fb1tGr3RWFKn7s61Z0MJ4ZbFPcPEO8kd5aLgU1t3IIiua3V8i1kbO%2B6iqnK92oZfS1io1qVBCS2L77pxDaV%2F0TCelxozeV%2B5e0B4Um7uVOg5mipGLJ74%2BGnkdf562hcqIUI3yQFBS68SRnnbbyMwbhIpfWtpHK56itpjIA5o6kbQwjg%2BMyKxnyCPPXNKEtDC93IVbQZvXWg%3D%3D)\n\nCompetition Notebook\n\n[Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\n\n[iframe](https://www.kaggleusercontent.com/kf/48636546/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..NNcXRlz1r7wVA_ZK7hc27A.fenyRROP0MgZU1Tk_PeeaOXMw36nI8G_UByr6iwE5r3uL9ZGOxHPxUrpb82HBc2ig7ZhFkyRQcXV-3-nyGWrXUhjUsFKXK7Xjjt4d3FEzA6Xenj3IXnN4K8f_ZcqQTdXSkkaTPTTSRixgMLYi2KoE0J8sWKlQ-63xQaj8ancpZ0H7B-QWFnfLvTmwqUDOaaenkJ73CwKvLmUVFNxP3Q7ki2xSCozzg5G6d3SLaj6v-dR4D8qYvWRr-vNiOkZJVZixLTk1vx5H-SVNTzxka7JSHpPCcpPj2KTtq9ngeuLjO_bHOX1ldNbGLq_uRIu9LbkV3sRFz2_IJs2pdU6-qtOU_WjhkAqyR6v9sXudACSV1x-MXbrttJvEB2i3kBoJzXcNRN8XH5K1Sss5-OdY2xj2q8PQCnqDlJBnWIWx4RSJeFxpaSPb1x3U7sWTF_4EYsOLCKM9Jo6QmWCFOUYLpwZ-vJVX5lEmSoHWiRGillmyCKXwGHTCvC9vApjgvYcwj6Cklu8EvuldNOYKp1Q6h6B0GKkjM2xoWDyflCBN6KdxVieDeYSY1kXLBrcT9eWdaHwmzhva1zHPVDZSocdHapOAfHFunmzkYnusqHpI66mFybxcKWRDTZBSDQSjEet401qkneujsqnaiHPiuUef9YLl1goUwXngf2oI0NwHICm0-Y.98Dh2ehJc4THR-HE0iz1SQ/__results__.html?sharingControls=true)\n\n## License\n\nThis Notebook has been released under the [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0) open source license.\n\n## Continue exploring\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/input_light.svg)\n\n\n\n\n\n\n\nInput\n\n2 files\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/output_light.svg)\n\n\n\n\n\n\n\nOutput\n\n0 files\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/logs_light.svg)\n\n\n\n\n\n\n\nLogs\n\n154.6 second run - successful\n\n\n\n\narrow\\_right\\_alt\n\n- ![](https://www.kaggle.com/static/images/kernel/viewer/comments_light.svg)\n\n\n\n\n\n\n\nComments\n\n5 comments\n\n\n\n\narrow\\_right\\_alt",
      "url": "https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation"
    },
    {
      "title": "Mastering Cross-Validation Techniques for Kaggle Data ...",
      "text": "[Sitemap](https://akbarikevin.medium.com/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd4a35c38ca16&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fakbarikevin.medium.com%2Fmastering-cross-validation-techniques-for-kaggle-data-science-competitions-d4a35c38ca16&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\n[Search](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fakbarikevin.medium.com%2Fmastering-cross-validation-techniques-for-kaggle-data-science-competitions-d4a35c38ca16&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\nMember-only story\n\n# Mastering Cross-Validation Techniques for Kaggle Data Science Competitions\n\n[Kevin Akbari](https://akbarikevin.medium.com/?source=post_page---byline--d4a35c38ca16---------------------------------------)\n\n5 min read\n\n\u00b7\n\nOct 7, 2024\n\n--\n\nShare\n\nWhen competing on **Kaggle**, where the tiniest edge can separate winners from the rest, one of the most crucial aspects of success is understanding **cross-validation (CV)** techniques. Cross-validation helps you estimate the model\u2019s performance on unseen data by splitting your training data into different subsets, ensuring your model generalizes well to future unseen data.\n\nPress enter or click to view image in full size\n\nIn this blog, we\u2019ll explore some of the most effective and widely used cross-validation techniques in Kaggle competitions, alongside Python code examples for each approach. Let\u2019s make sure your model doesn\u2019t just overfit the leaderboard but performs like a rock star on the hidden test set!\n\n## 1\\. Hold-Out Validation\n\nThis is the simplest form of cross-validation. You split your dataset into two parts: one for training and the other for testing. It\u2019s quick and easy but not robust for competition-level tasks, where we need reliable estimates of generalization error.\n\n### How it works:\n\n- **Train Split**: The model learns from this data.\n- **Test Split**: Evaluate the model\u2019s performance.\n\n### Code Example:\n\n```\nfrom sklearn.model_selection import train_test_splitfrom\u2026\n```\n\n[**Written by Kevin Akbari**](https://akbarikevin.medium.com/?source=post_page---post_author_info--d4a35c38ca16---------------------------------------)\n\n[70 followers](https://akbarikevin.medium.com/followers?source=post_page---post_author_info--d4a35c38ca16---------------------------------------)\n\n\u00b7 [14 following](https://akbarikevin.medium.com/following?source=post_page---post_author_info--d4a35c38ca16---------------------------------------)\n\nI enjoy exploring data science and delving into cutting-edge models currently utilized in various industries. [https://www.linkedin.com/in/kevinakbari/](https://www.linkedin.com/in/kevinakbari/)\n\n## No responses yet\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Status](https://status.medium.com/?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[About](https://medium.com/about?autoplay=1&source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Press](mailto:pressinquiries@medium.com)\n\n[Blog](https://blog.medium.com/?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d4a35c38ca16---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----d4a35c38ca16---------------------------------------)",
      "url": "https://akbarikevin.medium.com/mastering-cross-validation-techniques-for-kaggle-data-science-competitions-d4a35c38ca16"
    },
    {
      "title": "Cross validation best practice for competition purpose",
      "text": "**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\n# [Cross validation best practice for competition purpose](https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose)\n\n[Ask Question](https://stats.stackexchange.com/questions/ask)\n\nAsked4 years, 11 months ago\n\nModified [4 years, 11 months ago](https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose?lastactivity)\n\nViewed\n186 times\n\n1\n\n$\\\\begingroup$\n\nI'm fairly new to DS scene and I have been learning about theories and doing practices on kaggle/participate in private competition.\n\nFor real world problems, my understanding is that you split out test set from what you have, use training set for modeling building and tuning hyperparameters (gridsearch), and use test set to find best model, then possibly deploy the model.\n\nI'm getting little confused with regards to competitions that provide test set that has no answers, but provide public score upon submission.\n\nFor those cases, is it better to\u2026\n\n1. use same procedure (creating own test set) OR\n2. use all data available to train, and use public score to pick best model.\n\nI'm assuming max daily submission of 2-5 and public score comes from 50% of test set, and training set is ~1000, probably RF or XGboost models.\n\nMy main concern is whether using more training set and relying on public score to find better model is better for doing well on competitions. Published kernels usually show only one model and don't split out its own test set, so I wonder if such steps are performed outside published kernels. The presence of public score and it being called test set confuse me :(\n\n- [cross-validation](https://stats.stackexchange.com/questions/tagged/cross-validation)\n- [boosting](https://stats.stackexchange.com/questions/tagged/boosting)\n- [kaggle](https://stats.stackexchange.com/questions/tagged/kaggle)\n\n[Share](https://stats.stackexchange.com/q/415557)\n\nCite\n\n[Improve this question](https://stats.stackexchange.com/posts/415557/edit)\n\nFollow\n\nasked Jul 1, 2019 at 16:21\n\n[![bchoiNY's user avatar](https://lh3.googleusercontent.com/-VhRKuW0CxDw/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rdFF07eGldzcrm4ZiYT_uKUzTJltw/photo.jpg?sz=64)](https://stats.stackexchange.com/users/252449/bchoiny)\n\n[bchoiNY](https://stats.stackexchange.com/users/252449/bchoiny) bchoiNY\n\n1333 bronze badges\n\n$\\\\endgroup$\n\n[Add a comment](https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose)\u00a0\\|\n\n## 1 Answer 1\n\nSorted by:\n[Reset to default](https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose?answertab=scoredesc#tab-top)\n\nHighest score (default)Date modified (newest first)Date created (oldest first)\n\n2\n\n$\\\\begingroup$\n\nI'm not sure about what you call \"test sample\" but it depends on the kaggle.\n\nEither you have only one data sample and you have to separate the sample in 3 ways (if enough data): train sample (to learn your model), validation sample (to tune hyperparameters) and test sample (to achieve final evaluation for metric chosen).\n\nOr you have a train sample and a test sample, basically you use your train sample for train+validation split and use the test sample to be the final evaluation.\n\nThere is always a bit of misunderstood about the difference between validation and test sample.\n\nIt must be clear that the validation sample(s) are to tune hyperparameters for complex machine learning or chose the best model among different regression (reggresion 1 with x1 and x2, regression 2 with x1 only, etc.) for example.\n\nThe test sample is not mandatory if data is not enough but always welcome to have for final assessment and ensure yourself that your model is really well generalized.\n\n[Share](https://stats.stackexchange.com/a/415613)\n\nCite\n\n[Improve this answer](https://stats.stackexchange.com/posts/415613/edit)\n\nFollow\n\nanswered Jul 2, 2019 at 0:30\n\n[![josef_joestarr's user avatar](https://i.sstatic.net/M5ZyQ.jpg?s=64)](https://stats.stackexchange.com/users/252051/josef-joestarr)\n\n[josef\\_joestarr](https://stats.stackexchange.com/users/252051/josef-joestarr) josef\\_joestarr\n\n41722 silver badges33 bronze badges\n\n$\\\\endgroup$\n\n3\n\n- 1\n\n\n\n\n\n$\\\\begingroup$Thanks, I think my confusion stems from solving real world problem vs kaggle. Let's say I use xgboost, so hyperparameter tuning is taken care of through k-fold. In real world problem, there is no test set out there, so I would need to split out test set initially to see how the model performs in the end. In kaggle, there is already test set (usually), so I wonder if it's beneficial or detrimental to split out my own test set from training set. If it's beneficial, how do I best utilize two test sets?$\\\\endgroup$\n\n\u2013\u00a0[bchoiNY](https://stats.stackexchange.com/users/252449/bchoiny)\n\nCommentedJul 2, 2019 at 13:39\n\n- 1\n\n\n\n\n\n$\\\\begingroup$The test set for kaggle is just the one on which the final evaluation of the model is done. You don't need then to do a test sample on your own in this case, you just use train + validation for the best model and then assess its performance with the kaggle test sample. If you think it's not good enough, then you train again, validate again, test again. Normally, the performance on the validation set is always really really close of the test sample, it can be seen repetitive for some people even but in kaggle context it's just done for everyone to have the same test sample to evaluate the perf.$\\\\endgroup$\n\n\u2013\u00a0[josef\\_joestarr](https://stats.stackexchange.com/users/252051/josef-joestarr)\n\nCommentedJul 2, 2019 at 19:15\n\n- 1\n\n\n\n\n\n$\\\\begingroup$Thanks! That's what I was trying to get confirmation on.$\\\\endgroup$\n\n\u2013\u00a0[bchoiNY](https://stats.stackexchange.com/users/252449/bchoiny)\n\nCommentedJul 3, 2019 at 14:14\n\n\n[Add a comment](https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose)\u00a0\\|\n\n## Your Answer\n\nDraft saved\n\nDraft discarded\n\n### Sign up or [log in](https://stats.stackexchange.com/users/login?ssrc=question_page&returnurl=https%3a%2f%2fstats.stackexchange.com%2fquestions%2f415557%2fcross-validation-best-practice-for-competition-purpose%23new-answer)\n\nSign up using Google\n\nSign up using Email and Password\n\nSubmit\n\n### Post as a guest\n\nName\n\nEmail\n\nRequired, but never shown\n\nPost Your Answer\n\nDiscard\n\nBy clicking \u201cPost Your Answer\u201d, you agree to our [terms of service](https://stackoverflow.com/legal/terms-of-service/public) and acknowledge you have read our [privacy policy](https://stackoverflow.com/legal/privacy-policy).\n\n## Not the answer you're looking for? Browse other questions tagged  - [cross-validation](https://stats.stackexchange.com/questions/tagged/cross-validation) - [boosting](https://stats.stackexchange.com/questions/tagged/boosting) - [kaggle](https://stats.stackexchange.com/questions/tagged/kaggle)   or [ask your own question](https://stats.stackexchange.com/questions/ask).\n\n- Featured on Meta\n- [Upcoming sign-up experiments related to tags](https://meta.stackexchange.com/questions/400648/upcoming-sign-up-experiments-related-to-tags)\n\n\n#### Related\n\n[22](https://stats.stackexchange.com/q/188125) [\"Semi supervised learning\" - is this overfitting?](https://stats.stackexchange.com/questions/188125/semi-supervised-learning-is-this-overfitting)\n\n[14](https://stats.stackexchange.com/q/292415) [Are Kaggle competitions just won by chance?](https://stats.stackexchange.com/questions/292415/are-kaggle-competitions-just-won-by-chance)\n\n[0](https://stats.stackexchange.com/q/336751) [cross validation for model evaluation](https://stats.stackexchange.com/questions/336751/cross-validation-for-model-evaluation)\n\n[4](https://stats.stackexchange.com/q/355428) [is it a good practice to use K-Fold cross validation instead of training, validation and test set?](https://stats.stac...",
      "url": "https://stats.stackexchange.com/questions/415557/cross-validation-best-practice-for-competition-purpose"
    },
    {
      "title": "How to progress in Competitions.",
      "text": "<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><div><div><p></p></div><div><p>How should we participate in the competitions in kaggle to obtain maximum progress out of us?</p></div></div><div><div><p><span></span></p><p>Please <a href=\"https://www.kaggle.com/account/login\">sign in</a> to reply to this topic.</p><p></p></div><div><p></p><h2>4 Comments</h2><p></p></div><div><div><a href=\"https://www.kaggle.com/nmankodi\"></a><div><p></p></div><div><p>Participating in Kaggle competitions is a great way to advance your data science skills. Here\u2019s how to make the most out of it:</p>\n<ol>\n<li><p><strong>Understand the Problem:</strong> Thoroughly read the competition details, including the problem statement, evaluation metric, and any provided notebooks. Understanding the problem is crucial before diving into the data and this is something that beginners often forget.</p></li>\n<li><p><strong>Explore the Data:</strong> Conduct exploratory data analysis (EDA) to understand the data's structure, distributions, and relationships between variables. This step helps in identifying potential issues and guiding your preprocessing steps.</p></li>\n<li><p><strong>Clean and Pre-process the Data:</strong> Ensure your data is clean and pre-processed. Handle missing values, outliers, and inconsistencies. Remember, garbage in equals garbage out.</p></li>\n<li><p><strong>Split into Train and Test Sets:</strong> Divide your data into training and test sets to avoid data leakage and to evaluate your model's performance on unseen data.</p></li>\n<li><p><strong>Set Up Baselines:</strong> Establish baseline models to benchmark your performance. Simple models like linear regression or logistic regression can provide a reference point.</p></li>\n<li><p><strong>Start with Simple Models:</strong> Begin with simple models and gradually move to more complex ones. This approach helps in building a solid foundation and understanding the incremental improvements brought by advanced techniques.</p></li>\n<li><p><strong>Cross-Validation:</strong> Use cross-validation to find the optimal set of hyperparameters for each model. This ensures your model is not overfitting and generalizes well to unseen data.</p></li>\n<li><p><strong>Validate Performance:</strong> Use the test set to validate your model\u2019s performance. This provides a good estimate of what to expect in the competition before even making a submission.</p></li>\n<li><p><strong>Make Submissions:</strong> Regularly make submissions to check your progress. Each submission helps you understand how well your model is performing and where improvements can be made.</p></li>\n<li><p><strong>Avoid Post-Processing on Test Scores:</strong> Do not adjust your model based on test scores to prevent data leakage and ensure the test set remains a valid estimate of external performance.</p></li>\n<li><p><strong>Avoid Overcomplicating Models:</strong> Keep your models as simple as required. Overcomplicating increases the risk of overfitting and can lead to poorer performance on new data.</p></li>\n<li><p><strong>Take Your Time and Learn:</strong> Don't get discouraged by others' achievements. Focus on your learning journey and gradually improve your skills. Once the competition is over, review top solutions to learn new techniques and strategies.</p></li>\n<li><p><strong>Start with Simpler Competitions:</strong> Begin with easier competitions to build your skills and confidence. Consistency is key, so keep participating and learning from each competition.</p></li>\n</ol>\n<p>By following these steps, you can maximize your progress and develop a strong foundation in data science through Kaggle competitions. Good luck!</p></div></div><div><a href=\"https://www.kaggle.com/ravi20076\"></a><div><p></p></div><div><p>Anyone can participate in any competition. There is not entry requirement for competitions in Kaggle.</p>\n<p>Progression in competitions is a little difficult as it requires a combination of luck and skills and time and resource investment. One needs to be diligent over the 3 months of the competition, manage work and Kaggle and try and elicit meaningful results with learning and development too. This is certainly not everyone\u2019s cup of tea. If you decide to make a journey in competitions, I suggest a few points for you-</p>\n<ol>\n<li>Start early and be consistent </li>\n<li>Choose 1 competition at a time and don\u2019t digress </li>\n<li>Build a trustworthy cv scheme and trust the cv score. Your validation data should be the same across models for an effective comparison </li>\n<li>Don\u2019t blindly copy public materials but use the ideas in your kernels </li>\n<li>A better computer will help you a lot. Invest in GPU resources on the cloud/ locally but have a good GPU at your disposal. </li>\n<li>Don\u2019t post process or blend just for the public leaderboard and trust the cv score </li>\n</ol>\n<p>All the best <a href=\"https://www.kaggle.com/surajthakur21\">@surajthakur21</a> </p></div></div><div><a href=\"https://www.kaggle.com/nainavallurupalli\"></a><div><p></p></div></div></div></div></div></div></div>",
      "url": "https://www.kaggle.com/discussions/questions-and-answers/519268"
    },
    {
      "title": "Use Pipelines and Score with Cross-Validation",
      "text": "<div><div><div><p>Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.</p></div><div><p></p><h6>Something went wrong and this page crashed!</h6><p>If the issue persists, it's likely a problem on our side.</p><div><pre><div><p>Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)</p></div>ChunkLoadError: Loading CSS chunk 8198 failed.\n(error: https://www.kaggle.com/static/assets/KernelViewer.56ec1322d855ad0f5482.css)\nat b.onerror.b.onload (https://www.kaggle.com/static/assets/runtime.js?v=5d54a91cd927e8149fd6:1:11356)</pre></div></div></div></div>",
      "url": "https://www.kaggle.com/code/jonleon/use-pipelines-and-score-with-cross-validation"
    },
    {
      "title": "How to Use Kaggle",
      "text": "Getting Started on Kaggle | Kaggle\nKaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n[\nLearn more\n](https://www.kaggle.com/cookies)\nOK, Got it.\n# How to Use Kaggle\nkeyboard\\_arrow\\_right[Competitions](https://www.kaggle.com/docs/competitions)\nkeyboard\\_arrow\\_right[Datasets](https://www.kaggle.com/docs/datasets)\nkeyboard\\_arrow\\_right[Public API](https://www.kaggle.com/docs/api)\n[Efficient GPU Usage Tips](https://www.kaggle.com/docs/efficient-gpu-usage)\nkeyboard\\_arrow\\_right[Tensor Processing Units (TPUs)](https://www.kaggle.com/docs/tpu)\nkeyboard\\_arrow\\_right[Models](https://www.kaggle.com/docs/models)\nkeyboard\\_arrow\\_down\nCompetitions Setup\n[Overview](#overview)\nkeyboard\\_arrow\\_right\n[How Kaggle competitions work](#how-kaggle-competitions-work)\nkeyboard\\_arrow\\_right\n[Create your competition\ufe0f](#create-your-competition)\nkeyboard\\_arrow\\_right\n[Prepare the dataset](#prepare-the-dataset)\n[Set up scoring](#set-up-scoring)\n[Creating a New Metric](#creating-a-new-metric)\nkeyboard\\_arrow\\_right\n[Test your competition](#test-your-competition)\nkeyboard\\_arrow\\_right\n[Finalize your settings and descriptions](#finalize-your-settings-and-descriptions)\n[Launch and invite participants](#launch-and-invite-participants)\nkeyboard\\_arrow\\_right\n[FAQs](#faqs)\nkeyboard\\_arrow\\_right[Organizations](https://www.kaggle.com/docs/organizations)\nkeyboard\\_arrow\\_right[Groups](https://www.kaggle.com/docs/groups)\nkeyboard\\_arrow\\_right[Kaggle Packages](https://www.kaggle.com/docs/packages)\nkeyboard\\_arrow\\_right[Notebooks](https://www.kaggle.com/docs/notebooks)\nkeyboard\\_arrow\\_right[MCP Server](https://www.kaggle.com/docs/mcp)\nkeyboard\\_arrow\\_right[Benchmarks](https://www.kaggle.com/docs/benchmarks)\n## Competitions Setup\nCreate a new competition or competition metric\n### Overview\nAnybody can launch a machine learning competition using Kaggle's Community Competitions platform, including educators, researchers, companies, meetup groups, hackathon hosts, or inquisitive individuals! In this guide, you will learn how to set up your own competition, step-by-step.\nBefore diving in, it's helpful to understand how a Kaggle competition works.\n### How Kaggle competitions work\n#### Overview\nEvery competition has two things, a) a clearly defined problem that participants need to solve using a machine learning model and b) a dataset that\u2019s used both for training and evaluating the effectiveness of these models.\nFor example, in the[Store Sales \u2013Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting)competition, participants must accurately predict how many of each grocery item will sell using a dataset of past product and sales information from a grocery retailer.\nOnce the competition starts participants can submit their predictions, Kaggle will score them for accuracy, and the team will be placed on a ranked leaderboard. The team at the top of the leaderboard at the deadline wins!\n#### Datasets, Submissions &amp; Leaderboards\nEvery competition\u2019s dataset is split into two smaller datasets.\nOne of these smaller datasets will be given to participants to train their models, typically named`train.csv`.\nThe other dataset will be mostly hidden from participants and used by Kaggle for testing and scoring, named`test.csv`and`solution.csv`(`test.csv`is the same as`solution.csv`except that`test.csv`contains the feature values and`solution.csv`contains the ground truth variable(s) \u2013participants will never, ever see`solution.csv`).\nWhen a participant feels ready to make a submission to the competition, they will use`test.csv`to generate a prediction and upload a CSV file. Kaggle will automatically score the submission for accuracy using the hidden`solution.csv`file.\nMost competitions have a maximum number of submissions that a participant can make each day and a final deadline at which point the leaderboard will be frozen.\nIt\u2019s conceivable that a participant could use the mechanics of a Kaggle competition to overfit a solution - which would be great for winning a competition, but not valuable for a real-world application.\nTo help prevent this, Kaggle has two leaderboards \u2013the public and private leaderboard. The competition host splits the`solution.csv`dataset into two parts, using one part for the public leaderboard and another part for the private leaderboard. Participants generally will now know which samples are public vs private. The private leaderboard is kept a secret until after the competition deadline and is used as the official leaderboard for determining the final ranking.\n### Create your competition\ufe0f\nTo create a new competition, click on the \u201cCreate new competition\u201d button at the top of the Kaggle Community landing page.\nThen, enter a descriptive title, subtitle and URL for your competition. Be as descriptive and to the point as possible. In our example above, the title \u201cStore Sales - Time Series Forecasting\u201d quickly outlines the type of data, the industry of the dataset, and the type of problem to be solved.\nIf you want to create a competition with more privacy, you can limit your competition's visibility and restrict who can join on this page.\nVisibility: Competitions with their visibility set to public are viewable on Kaggle and appear in Kaggle search results. Competitions with visibility set to private are hidden and only accessible via invitation URLs from the host.\nWho Can Join: Competitions access can be set to three levels: anyone, only people with a link and restricted email list. If you select anyone, all Kagglers can join your competition. Selecting only people with a link, will restrict access to those users you provide a special URL. Finally, restricted email list is the most private competition. Only Kagglers with accounts that match the emails or email domains you specify will be able to join. Note: if you select restricted email list, notebooks will be turned off. This provides a way to ensure that any private data that you have in a competition is not accidentally leaked through shared notebooks. You can choose to re-enable notebooks if you choose.\nReview and accept our terms of service, then click \u201cCreate Competition\u201d.\nYour competition listing is now in draft mode. You can take your time to prepare the details before making the competition public.\n#### Offering Prizes\nCommunity competition hosts have the option to offer prizes with a total value of up to $10,000 USD.\nTo set up prizes:\n* Enable Prize Awards: When creating a competition, select \"Competition will award prizes.\" Enter the total amount of prize money to be awarded.\n* Document Prize Rules: You'll need to specify the number of prizes and the amount for each prize on the Competition Rules and Overview pages. Clearly define the criteria for winning in this section. These sections must be completed to launch the competition.Adjusting prize amounts:\n* Prize amounts can be adjusted or turned off entirely only before launch. After you launch a competition, prize settings are locked. We advise you to double-check your prizes before scheduling, as you won't be able to change them after launch.\n* If you are offering a valuable prize that is not cash (eg. gift cards, or valuable objects), please list the monetary value of the prizes in US dollars. The value should not exceed the prize limit of $10,000 USD.Prize fulfillment:\n* Prizes for Community Competitions must be manually awarded and announced.\nLeaderboards for Community Competitions will not display an \"In the money\" designation for winning participants. We advise reaching out to winners directly on Kaggle and announcing winners using the Discussions feature.\n* When you enable prizes for a competition, you are solely responsible for providing and distributing all prizes, fulfilling all promises and commitments, and for complying with all applicable tax rules related to competition winners. Kaggle does not participate in prize distribution or rule enforcement for...",
      "url": "https://www.kaggle.com/docs/competitions-setup"
    }
  ]
}