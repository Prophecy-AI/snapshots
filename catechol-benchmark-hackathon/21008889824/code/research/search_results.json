{
  "query": "What is TabNet and how does it achieve state-of-the-art performance on tabular data compared to gradient boosting?",
  "results": [
    {
      "title": "ANSWER",
      "text": "TabNet is a deep\u2011learning architecture specifically designed for tabular\u2011structured data.  It replaces the usual fully\u2011connected layers with a **sequential attention mechanism** that, at each decision step, softly selects a sparse subset of features to process and then aggregates the results into a final prediction.  By forcing the network to focus on the most salient columns, TabNet concentrates its representational capacity on the information that matters most, which both speeds up training and yields **interpretable feature\u2011selection masks** that can be visualized after the fact ([arxiv.org](https://arxiv.org/abs/1908.07442), [openreview.net](https://openreview.net/forum?id=BylRkAEKDH)).  \n\nBecause the model learns only from a compact set of features at each step, it avoids the over\u2011parameterisation that typical multilayer perceptrons suffer on heterogeneous tabular datasets.  This sparsity, together with **self\u2011supervised pre\u2011training** (masked feature reconstruction) when large amounts of unlabeled data are available, lets TabNet achieve higher predictive accuracy than many traditional tree\u2011based ensembles on \u201cnon\u2011performance\u2011saturated\u201d benchmarks.  Empirical results in the original paper show TabNet **outperforming both neural\u2011network baselines and decision\u2011tree variants\u2014including gradient\u2011boosted trees\u2014across a wide range of public tabular datasets** ([arxiv.org](https://arxiv.org/abs/1908.07442), [openreview.net](https://openreview.net/forum?id=BylRkAEKDH)).  \n\nIn practice, TabNet\u2019s advantage over gradient boosting stems from its ability to **learn hierarchical feature interactions end\u2011to\u2011end** while still providing a clear, per\u2011sample explanation of which features drove each decision.  Articles published after the original release note that TabNet narrows the long\u2011standing performance gap between deep learning and boosted\u2011tree models, offering a compelling alternative when both accuracy and interpretability are required for tabular problems ([medium.com](https://medium.com/@kdk199604/tabnet-a-deep-learning-breakthrough-for-tabular-data), [towardsdatascience.com](https://towardsdatascience.com/tabnet-e1b979907694)).",
      "url": ""
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[1908.07442] TabNet: Attentive Interpretable Tabular Learning\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:1908.07442\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:1908.07442**(cs)\n[Submitted on 20 Aug 2019 ([v1](https://arxiv.org/abs/1908.07442v1)), last revised 9 Dec 2020 (this version, v5)]\n# Title:TabNet: Attentive Interpretable Tabular Learning\nAuthors:[Sercan O. Arik](https://arxiv.org/search/cs?searchtype=author&amp;query=Arik,+S+O),[Tomas Pfister](https://arxiv.org/search/cs?searchtype=author&amp;query=Pfister,+T)\nView a PDF of the paper titled TabNet: Attentive Interpretable Tabular Learning, by Sercan O. Arik and Tomas Pfister\n[View PDF](https://arxiv.org/pdf/1908.07442)> > Abstract:\n> We propose a novel high-performance and interpretable canonical deep tabular data learning architecture, TabNet. TabNet uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of non-performance-saturated tabular datasets and yields interpretable feature attributions plus insights into the global model behavior. Finally, for the first time to our knowledge, we demonstrate self-supervised learning for tabular data, significantly improving performance with unsupervised representation learning when unlabeled data is abundant. Subjects:|Machine Learning (cs.LG); Machine Learning (stat.ML)|\nCite as:|[arXiv:1908.07442](https://arxiv.org/abs/1908.07442)[cs.LG]|\n|(or[arXiv:1908.07442v5](https://arxiv.org/abs/1908.07442v5)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.1908.07442](https://doi.org/10.48550/arXiv.1908.07442)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Sercan Arik [[view email](https://arxiv.org/show-email/d49ac80b/1908.07442)]\n**[[v1]](https://arxiv.org/abs/1908.07442v1)**Tue, 20 Aug 2019 15:46:53 UTC (1,030 KB)\n**[[v2]](https://arxiv.org/abs/1908.07442v2)**Wed, 28 Aug 2019 20:37:43 UTC (1,030 KB)\n**[[v3]](https://arxiv.org/abs/1908.07442v3)**Thu, 26 Sep 2019 00:59:17 UTC (1,031 KB)\n**[[v4]](https://arxiv.org/abs/1908.07442v4)**Fri, 14 Feb 2020 18:37:55 UTC (1,150 KB)\n**[v5]**Wed, 9 Dec 2020 05:00:33 UTC (1,149 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled TabNet: Attentive Interpretable Tabular Learning, by Sercan O. Arik and Tomas Pfister\n* [View PDF](https://arxiv.org/pdf/1908.07442)\n* [TeX Source](https://arxiv.org/src/1908.07442)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=1908.07442&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=1908.07442&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2019-08](https://arxiv.org/list/cs.LG/2019-08)\nChange to browse by:\n[cs](https://arxiv.org/abs/1908.07442?context=cs)\n[stat](https://arxiv.org/abs/1908.07442?context=stat)\n[stat.ML](https://arxiv.org/abs/1908.07442?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1908.07442)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1908.07442)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:1908.07442)\n### [5 blog links](https://arxiv.org/tb/1908.07442)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1908.html#abs-1908-07442)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1908-07442)\n[Sercan \u00d6mer Arik](<https://dblp.uni-trier.de/search/author?author=Sercan \u00d6mer Arik>)\n[Tomas Pfister](<https://dblp.uni-trier.de/search/author?author=Tomas Pfister>)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/1908.07442&amp;description=TabNet: Attentive Interpretable Tabular Learning>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/1908.07442&amp;title=TabNet: Attentive Interpretable Tabular Learning>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper a...",
      "url": "https://arxiv.org/abs/1908.07442"
    },
    {
      "title": "TabNet: Attentive Interpretable Tabular Learning | OpenReview",
      "text": "TabNet: Attentive Interpretable Tabular Learning | OpenReview\n[![back arrow](https://openreview.net/images/arrow_left.svg)Go to**ICLR 2020 Conference**homepage](https://openreview.net/group?id=ICLR.cc/2020/Conference)\n## TabNet: Attentive Interpretable Tabular Learning[![Download PDF](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=BylRkAEKDH)\n### [Sercan O. Arik](https://openreview.net/profile?email=soarik@google.com),[Tomas Pfister](https://openreview.net/profile?email=tpfister@google.com)\n25 Sept 2019 (modified: 12 Oct 2025)ICLR 2020 Conference Blind SubmissionReaders:Everyone\n**TL;DR:**We propose a novel high-performance interpretable deep tabular data learning network.\n**Abstract:**We propose a novel high-performance interpretable deep tabular data learning network, TabNet. TabNet utilizes a sequential attention mechanism that softly selects features to reason from at each decision step and then aggregates the processed information to make a final prediction decision. By explicitly selecting sparse features, TabNet learns very efficiently as the model capacity at each decision step is fully utilized for the most relevant features, resulting in a high performance model. This sparsity also enables more interpretable decision making through the visualization of feature selection masks. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of tabular data learning datasets and yields interpretable feature attributions and insights into the global model behavior.\n**Code:**https://drive.google.com/file/d/1oLQRgKygAEVRRmqCZTPwno7gyTq22wbb/view?usp=sharing\n**Keywords:**Tabular data, interpretable neural networks, attention models\n**Community Implementations:**[![CatalyzeX](/images/catalyzex\\_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/tabnet-attentive-interpretable-tabular/code)\n**Original Pdf:**[pdf](https://openreview.net/attachment?id=BylRkAEKDH&amp;name=original_pdf)\n15 Replies\nLoading\n[OpenReview](https://openreview.net/about)is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the[OpenReview Sponsors](https://openreview.net/sponsors). \u00a92026OpenReview",
      "url": "https://openreview.net/forum?id=BylRkAEKDH"
    },
    {
      "title": "TabNet: The End of Gradient Boosting?",
      "text": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe1b979907694&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_topnav-----------)\n\n[Sign up](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=post_page---two_column_layout_nav-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\nMember-only story\n\n# TabNet: The End of Gradient Boosting?\n\n## TabNet balances explainability and model performance on tabular data, but can it dethrone boosted tree models?\n\n[![Adam Shafi](https://miro.medium.com/v2/resize:fill:88:88/1*SH9YEM1KIgDam3v8YVdvrg.jpeg)](https://adam-shafi.medium.com/?source=post_page-----e1b979907694--------------------------------)[![Towards Data Science](https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page-----e1b979907694--------------------------------)\n\n[Adam Shafi](https://adam-shafi.medium.com/?source=post_page-----e1b979907694--------------------------------)\n\n\u00b7\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F159c0484eaef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&user=Adam+Shafi&userId=159c0484eaef&source=post_page-159c0484eaef----e1b979907694---------------------post_header-----------)\n\nPublished in\n\n[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e1b979907694--------------------------------)\n\n\u00b7\n\n7 min read\n\n\u00b7\n\nJun 7, 2021\n\n448\n\n3\n\n[Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3De1b979907694&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=-----e1b979907694---------------------post_audio_button-----------)\n\nShare\n\n![TabNet model architecture. How does TabNet work?](https://miro.medium.com/v2/resize:fit:1000/1*_DKm0iz5fATChDHjlWqNVQ.png)\n\nTabNet Model Architecture. Image by Author. Inspired by [https://arxiv.org/pdf/1908.07442.pdf](https://arxiv.org/pdf/1908.07442.pdf).\n\n# Introduction\n\nGradient Boosting models such as XGBoost, LightGBM and Catboost have long been considered [best in class for tabular data](https://www.kaggle.com/shivamb/data-science-trends-on-kaggle). Even with rapid progress in NLP and Computer Vision, Neural Networks are still routinely surpassed by tree-based models on tabular data.\n\nEnter Google\u2019s [TabNet](https://arxiv.org/abs/1908.07442) in 2019. According to the paper, this Neural Network was able to **outperform the leading tree based models** across a variety of benchmarks. Not only that, it is considerably more explainable than boosted tree models as it has **built-in explainability**. It can also be used **without any feature preprocessing**. If this is the case\u2026 why hasn\u2019t it caught on?\n\n> TabNet balances explainability with with state-of-the-art performance. It is easy to implement and requires limited hyperparameter tuning. So why is XGBoost still the Kaggle Grandmaster weapon of choice?\n\nThis article looks into the theory of TabNet and shows some examples of how to implement the model.\n\n## Create an account to read\u00a0the\u00a0full\u00a0story.\n\nThe\u00a0author made this story available to\u00a0Medium\u00a0members\u00a0only.\n\nIf you\u2019re new to Medium, create a new account to read this story on us.\n\n[Continue in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe1b979907694&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=regwall&source=-----e1b979907694---------------------post_regwall-----------)\n\nOr, continue in mobile web\n\n[Sign up with Google](https://medium.com/m/connect/google?state=google-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694%3Fsource%3D-----e1b979907694---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----e1b979907694---------------------post_regwall-----------)\n\n[Sign up with Facebook](https://medium.com/m/connect/facebook?state=facebook-%7Chttps%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694%3Fsource%3D-----e1b979907694---------------------post_regwall-----------%26skipOnboarding%3D1%7Cregister&source=-----e1b979907694---------------------post_regwall-----------)\n\n[Sign up with email](https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694%3Fsource%3D-----e1b979907694---------------------post_regwall-----------%26skipOnboarding%3D1&operation=register&stepOverride=ENTER_EMAIL&source=-----e1b979907694---------------------post_regwall-----------)\n\nAlready have an account? [Sign\u00a0in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&source=-----e1b979907694---------------------post_regwall-----------)\n\n[![Adam Shafi](https://miro.medium.com/v2/resize:fill:144:144/1*SH9YEM1KIgDam3v8YVdvrg.jpeg)](https://adam-shafi.medium.com/?source=post_page-----e1b979907694--------------------------------)[![Towards Data Science](https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg)](https://towardsdatascience.com/?source=post_page-----e1b979907694--------------------------------)\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F159c0484eaef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&user=Adam+Shafi&userId=159c0484eaef&source=post_page-159c0484eaef----e1b979907694---------------------follow_profile-----------)\n\n[**Written by Adam Shafi**](https://adam-shafi.medium.com/?source=post_page-----e1b979907694--------------------------------)\n\n[578 Followers](https://adam-shafi.medium.com/followers?source=post_page-----e1b979907694--------------------------------)\n\n\u00b7Writer for\n\n[Towards Data Science](https://towardsdatascience.com/?source=post_page-----e1b979907694--------------------------------)\n\nData Scientist \\| Get in touch: [https://www.linkedin.com/in/adamshafi](https://www.linkedin.com/in/adamshafi)\n\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F159c0484eaef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftabnet-e1b979907694&user=Adam+Shafi&userId=159c0484eaef&source=post_page-159c0484eaef----e1b979907694---------------------follow_profile-----------)\n\n## More from Adam Shafi and Towards Data Science\n\n![Linear Model vs Generalised Additive Model](https://miro.medium.com/v2/resize:fit:679/1*oMjo7R80uJ5rAuG61evEdA.png)\n\n[![Adam Shafi](https://miro.medium.com/v2/resize:fill:20:20/1*SH9YEM1KIgDam3v8YVdvrg.jpeg)](https://adam-shafi.medium.com/?source=author_recirc-----e1b979907694----0---------------------fc6f9c47_885a_41a3_a8da_3b61520ed3fd-------)\n\n[Adam Shafi](https://adam-shafi.medium.com/?source=author_recirc-----e1b979907694----0---------------------fc6f9c47_885a_41a3_a8da_3b61520ed3fd-------)\n\nin\n\n[Towards Data Science](https://towardsdatascience.com/?source=author_recirc-----e1b979907694----0---------------...",
      "url": "https://towardsdatascience.com/tabnet-e1b979907694"
    },
    {
      "title": "",
      "text": "TabNet: A\u0082entive Interpretable Tabular Learning\nSercan O. Ar\u0131k \u00a8\nGoogle Cloud AI\nsoarik@google.com\nTomas P\u0080ster\nGoogle Cloud AI\ntp\u0080ster@google.com\nABSTRACT\nWe propose a novel high-performance and interpretable canonical\ndeep tabular data learning architecture, TabNet. TabNet uses se\u0002quential a\u008aention to choose which features to reason from at each\ndecision step, enabling interpretability and more e\u0081cient learning\nas the learning capacity is used for the most salient features. We\ndemonstrate that TabNet outperforms other neural network and de\u0002cision tree variants on a wide range of non-performance-saturated\ntabular datasets and yields interpretable feature a\u008aributions plus\ninsights into the global model behavior. Finally, for the \u0080rst time to\nour knowledge, we demonstrate self-supervised learning for tabu\u0002lar data, signi\u0080cantly improving performance with unsupervised\nrepresentation learning when unlabeled data is abundant.\nKEYWORDS\nInterpretable deep learning, tabular data, a\u008aention, self-supervised.\n1 INTRODUCTION\nDeep neural networks (DNNs) have shown notable success with\nimages [21, 50], text [9, 34] and audio [1, 56]. For these data types,\na major enabler of the progress is the availability of canonical DNN\narchitectures that e\u0081ciently encode the raw data into meaningful\nrepresentations, resulting in high performance on new datasets and\nrelated tasks with minor e\u0082ort. For example, in image understand\u0002ing, variants of residual convolutional networks (e.g. ResNet [21])\nprovide reasonably-well performance on new image datasets or\nslightly di\u0082erent visual recognition problems (e.g. segmentation).\nOne data type that has yet to see such success with a canonical\nDNN architecture is tabular data. Despite being the most common\ndata type in real-world AI1[8], deep learning for tabular data re\u0002mains under-explored, with variants of ensemble decision trees\nstill dominating most applications [28]. Why is this? First, be\u0002cause tree-based approaches have certain bene\u0080ts that make them\npopular: (i) they are representionally e\u0081cient (and thus o\u0089en high\u0002performing) for decision manifolds with approximately hyperplane\nboundaries which are common in tabular data; and (ii) they are\nhighly interpretable in their basic form (e.g. by tracking decision\nnodes) and there are e\u0082ective post-hoc explainability methods for\ntheir ensemble form, e.g. [36] \u2013 this is an important concern in\nmany real-world applications (e.g. in \u0080nancial services, where\ntrust behind a high-risk action is crucial); (iii) they are fast to train.\nSecond, because previously-proposed DNN architectures are not\nwell-suited for tabular data: conventional DNNs based on stacked\nconvolutional layers or multi-layer perceptrons (MLPs) are vastly\noverparametrized \u2013 the lack of appropriate inductive bias o\u0089en\ncauses them to fail to \u0080nd optimal solutions for tabular decision\nmanifolds [17].\n1As it corresponds to a combination of any unrelated categorical and numerical feature.\nWhy is deep learning worth exploring for tabular data? One obvi\u0002ous motivation is that, similarly to other domains, one would expect\nperformance improvements from DNN-based architectures particu\u0002larly for large datasets [22]. In addition, unlike tree learning which\ndoes not use back-propagation into their inputs to guide e\u0081cient\nlearning from the error signal, DNNs enable gradient descent-based\nend-to-end learning for tabular data which can have a multitude of\nbene\u0080ts just like in the other domains it has already shown success:\n(i) it could e\u0081ciently encode multiple data types like images along\nwith tabular data; (ii) it would alleviate or eliminate the need for\nfeature engineering, which is currently a key aspect in tree-based\ntabular data learning methods; (iii) it would enable learning from\nstreaming data \u2013 tree learning needs global statistics to select split\npoints and straightforward modi\u0080cations such as [4] typically yield\nlower accuracy compared to learning from entire data \u2013 in contrast,\nDNNs show great potential for continual learning[44]; and per\u0002haps most importantly (iv) end-to-end models allow representation\nlearning which enables many valuable new application scenarios\nincluding data-e\u0081cient domain adaptation [17], generative mod\u0002eling [46] and semi-supervised learning [11]. Clearly there are\nsigni\u0080cant bene\u0080ts in both tree-based and DNN-based methods. Is\nthere a way to design a method that has the most bene\u0080cial aspects\nof both?\nIn this paper, we propose a new canonical DNN architecture for\ntabular data, TabNet, that is designed to learn a \u2018decision-tree-like\u2019\nmapping in order to inherit the valuable bene\u0080ts of tree-based meth\u0002ods (interpretability and sparse feature selection), while providing\nthe key bene\u0080ts of DNN-based methods (representation learning\nand end-to-end training). In particular, TabNet\u2019s design considers\ntwo key needs: high performance and interpretability. As men\u0002tioned, high performance alone is o\u0089en not enough \u2013 a DNN needs\nto be interpretable to substitute tree-based methods. Overall, we\nmake the following contributions in the design of our method:\n(1) Unlike tree-based methods, TabNet inputs raw tabular data\nwithout any feature preprocessing and is trained using gradient\ndescent-based optimization to learn \u0083exible representations and\nenable \u0083exible integration into end-to-end learning.\n(2) TabNet uses sequential a\u0088ention to choose which features to rea\u0002son from at each decision step, enabling interpretability and\nbe\u008aer learning as the learning capacity is used for the most\nsalient features (see Fig. 1). \u008cis feature selection is instance\u0002wise, e.g. it can be di\u0082erent for each input, and unlike other\ninstance-wise feature selection methods like [6] or [61], Tab\u0002Net employs a single deep learning architecture with end-to-end\nlearning.\n(3) We show that the above design choices lead to two valuable\nproperties: (1) TabNet outperforms or is on par with other tabular\nlearning models on various datasets for classi\u0080cation and regres\u0002sion problems from di\u0082erent domains; and (2) TabNet enables\narXiv:1908.07442v4 [cs.LG] 14 Feb 2020\nFeature selection Input processing\nAggregate information\nFeature selection Input processing\nPredicted output (whether the income level >$50k)\nProfessional occupation related Investment related\nInput features\nFeedback from \nprevious step\nFeedback to \nnext step\n\u2026 \u2026\nFigure 1: TabNet\u2019s sparse feature selection exempli\u0080ed for Adult Census Income prediction [14]. Sparse feature selection\nenables interpretability and better learning as the capacity is used for the most salient features. TabNet employs multiple\ndecision blocks that focus on processing a subset of input features for reasoning. Feature selection is based on feedback \u0083owing\nfrom the preceding decision step. Two decision blocks shown as examples process features that are related to professional\noccupation and investments, respectively, in order to predict the income level.\nAge Cap. gain Education Occupation Gender Relationship\n53 200000 ? Exec-managerial F Wife\n19 0 ? Farming-fishing M ?\n? 5000 Doctorate Prof-specialty M Husband\n25 ? ? Handlers-cleaners F Wife\n59 300000 Bachelors ? ? Husband\n33 0 Bachelors ? F ?\n? 0 High-school Armed-Forces ? Husband\nAge Cap. gain Education Occupation Gender Relationship\nMasters\nHigh-school Unmarried\n43\n0 High-school F\nExec-managerial M\nAdm-clerical Wife\n39 M\nIncome > $50k\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTabNet encoder\nTabNet decoder Decision making\nAge Cap. gain Education Occupation Gender Relationship\n60 200000 Bachelors Exec-managerial M Husband\n23 0 High-school Farming-fishing M Unmarried\n45 5000 Doctorate Prof-specialty M Husband\n23 0 High-school Handlers-cleaners F Wife\n56 300000 Bachelors Exec-managerial M Husband\n38 10000 Bachelors Prof-specialty F Wife\n23 0 High-school Armed-Forces M Husband\nUnsupervised pre-training Supervised fine-tuning\nTabNet encoder\nFigure 2: Self-supervised tabular learning. Real-world tabular datasets have interdependent feature columns, e.g., the educa\u0002tion le...",
      "url": "https://www.arxiv.org/pdf/1908.07442v4"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2410.12034] A Survey on Deep Tabular Learning\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2410.12034\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2410.12034**(cs)\n[Submitted on 15 Oct 2024]\n# Title:A Survey on Deep Tabular Learning\nAuthors:[Shriyank Somvanshi](https://arxiv.org/search/cs?searchtype=author&amp;query=Somvanshi,+S),[Subasish Das](https://arxiv.org/search/cs?searchtype=author&amp;query=Das,+S),[Syed Aaqib Javed](https://arxiv.org/search/cs?searchtype=author&amp;query=Javed,+S+A),[Gian Antariksa](https://arxiv.org/search/cs?searchtype=author&amp;query=Antariksa,+G),[Ahmed Hossain](https://arxiv.org/search/cs?searchtype=author&amp;query=Hossain,+A)\nView a PDF of the paper titled A Survey on Deep Tabular Learning, by Shriyank Somvanshi and 4 other authors\n[View PDF](https://arxiv.org/pdf/2410.12034)[HTML (experimental)](https://arxiv.org/html/2410.12034v1)> > Abstract:\n> Tabular data, widely used in industries like healthcare, finance, and transportation, presents unique challenges for deep learning due to its heterogeneous nature and lack of spatial structure. This survey reviews the evolution of deep learning models for tabular data, from early fully connected networks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and MambaNet. These models incorporate attention mechanisms, feature embeddings, and hybrid architectures to address tabular data complexities. TabNet uses sequential attention for instance-wise feature selection, improving interpretability, while SAINT combines self-attention and intersample attention to capture complex interactions across features and data points, both advancing scalability and reducing computational overhead. Hybrid architectures such as TabTransformer and FT-Transformer integrate attention mechanisms with multi-layer perceptrons (MLPs) to handle categorical and numerical data, with FT-Transformer adapting transformers for tabular datasets. Research continues to balance performance and efficiency for large datasets. Graph-based models like GNN4TDL and GANDALF combine neural networks with decision trees or graph structures, enhancing feature representation and mitigating overfitting in small datasets through advanced regularization techniques. Diffusion-based models like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM) generate synthetic data to address data scarcity, improving model robustness. Similarly, models like TabPFN and Ptab leverage pre-trained language models, incorporating transfer learning and self-supervised techniques into tabular tasks. This survey highlights key advancements and outlines future research directions on scalability, generalization, and interpretability in diverse tabular data applications. Comments:|43 pages, 18 figures, 3 tables|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2410.12034](https://arxiv.org/abs/2410.12034)[cs.LG]|\n|(or[arXiv:2410.12034v1](https://arxiv.org/abs/2410.12034v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2410.12034](https://doi.org/10.48550/arXiv.2410.12034)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Shriyank Somvanshi [[view email](https://arxiv.org/show-email/4b23fb4c/2410.12034)]\n**[v1]**Tue, 15 Oct 2024 20:08:08 UTC (2,101 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled A Survey on Deep Tabular Learning, by Shriyank Somvanshi and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2410.12034)\n* [HTML (experimental)](https://arxiv.org/html/2410.12034v1)\n* [TeX Source](https://arxiv.org/src/2410.12034)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2410.12034&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2410.12034&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2024-10](https://arxiv.org/list/cs.LG/2024-10)\nChange to browse by:\n[cs](https://arxiv.org/abs/2410.12034?context=cs)\n[cs.AI](https://arxiv.org/abs/2410.12034?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.12034)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.12034)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.12034)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2410.12034&amp;description=A Survey on Deep Tabular Learning>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2410.12034&amp;title=A Survey on Deep Tabular Learning>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features direct...",
      "url": "https://arxiv.org/abs/2410.12034"
    },
    {
      "title": "Papers with Code - TabNet: Attentive Interpretable Tabular Learning",
      "text": "new\n\nGet trending papers in your email inbox once a day!\n\nGet trending papers in your email inbox!\n\n[Subscribe](https://paperswithcode.com/login?next=%2Fpapers)\n\n# Trending Papers\n\n## by [AK](https://paperswithcode.com/akhaliq) and the research community\n\n- Daily\n- Weekly\n- Monthly\n\nTrending Papers\n\nSubmitted by\ntsbpp\n\n### [Diffusion Transformers with Representation Autoencoders](https://paperswithcode.com/papers/2510.11690)\n\nLatent generative modeling, where a pretrained autoencoder maps pixels into a\nlatent space for the diffusion process, has become the standard strategy for\nDiffusion Transformers (DiT); however, the autoencoder component has barely\nevolved. Most DiTs continue to rely on the original VAE encoder, which\nintroduces several limitations: outdated backbones that compromise\narchitectural simplicity, low-dimensional latent spaces that restrict\ninformation capacity, and weak representations that result from purely\nreconstruction-based training and ultimately limit generative quality. In this\nwork, we explore replacing the VAE with pretrained representation encoders\n(e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term\nRepresentation Autoencoders (RAEs). These models provide both high-quality\nreconstructions and semantically rich latent spaces, while allowing for a\nscalable transformer-based architecture. Since these latent spaces are\ntypically high-dimensional, a key challenge is enabling diffusion transformers\nto operate effectively within them. We analyze the sources of this difficulty,\npropose theoretically motivated solutions, and validate them empirically. Our\napproach achieves faster convergence without auxiliary representation alignment\nlosses. Using a DiT variant equipped with a lightweight, wide DDT head, we\nachieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no\nguidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers\nclear advantages and should be the new default for diffusion transformer\ntraining.\n\n[NYU VisionX](https://paperswithcode.com/nyu-visionx)\u00b7Published on Oct 13, 2025\n\n[Upvote\\\n\\\n122](https://paperswithcode.com/login?next=%2Fpapers%2F2510.11690)\n\n[GitHub960](https://github.com/bytetriper/RAE) [arXiv Page](https://arxiv.org/abs/2510.11690)\n\nSubmitted by\ntsbpp\n\n### [Diffusion Transformers with Representation Autoencoders](https://paperswithcode.com/papers/2510.11690)\n\nLatent generative modeling, where a pretrained autoencoder maps pixels into a\nlatent space for the diffusion process, has become the standard strategy for\nDiffusion Transformers (DiT); however, the autoencoder component has barely\nevolved. Most DiTs continue to rely on the original VAE encoder, which\nintroduces several limitations: outdated backbones that compromise\narchitectural simplicity, low-dimensional latent spaces that restrict\ninformation capacity, and weak representations that result from purely\nreconstruction-based training and ultimately limit generative quality. In this\nwork, we explore replacing the VAE with pretrained representation encoders\n(e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term\nRepresentation Autoencoders (RAEs). These models provide both high-quality\nreconstructions and semantically rich latent spaces, while allowing for a\nscalable transformer-based architecture. Since these latent spaces are\ntypically high-dimensional, a key challenge is enabling diffusion transformers\nto operate effectively within them. We analyze the sources of this difficulty,\npropose theoretically motivated solutions, and validate them empirically. Our\napproach achieves faster convergence without auxiliary representation alignment\nlosses. Using a DiT variant equipped with a lightweight, wide DDT head, we\nachieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no\nguidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers\nclear advantages and should be the new default for diffusion transformer\ntraining.\n\n[NYU VisionX](https://paperswithcode.com/nyu-visionx)\u00b7Oct 13, 2025\n\n[Upvote\\\n\\\n122](https://paperswithcode.com/login?next=%2Fpapers%2F2510.11690)\n\n[GitHub960](https://github.com/bytetriper/RAE) [arXiv Page](https://arxiv.org/abs/2510.11690)\n\nSubmitted by\nAlexiaJM\n\n### [Less is More: Recursive Reasoning with Tiny Networks](https://paperswithcode.com/papers/2510.04871)\n\nHierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.\n\n[Samsung SAIT AI Lab, Montreal](https://paperswithcode.com/SamsungSAILMontreal)\u00b7Published on Oct 6, 2025\n\n[Upvote\\\n\\\n384](https://paperswithcode.com/login?next=%2Fpapers%2F2510.04871)\n\n[GitHub4.41k](https://github.com/SamsungSAILMontreal/TinyRecursiveModels) [arXiv Page](https://arxiv.org/abs/2510.04871)\n\nSubmitted by\nAlexiaJM\n\n### [Less is More: Recursive Reasoning with Tiny Networks](https://paperswithcode.com/papers/2510.04871)\n\nHierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.\n\n[Samsung SAIT AI Lab, Montreal](https://paperswithcode.com/SamsungSAILMontreal)\u00b7Oct 6, 2025\n\n[Upvote\\\n\\\n384](https://paperswithcode.com/login?next=%2Fpapers%2F2510.04871)\n\n[GitHub4.41k](https://github.com/SamsungSAILMontreal/TinyRecursiveModels) [arXiv Page](https://arxiv.org/abs/2510.04871)\n\nSubmitted by\ntaesiri\n\n### [MinerU2.5: A Decoupled Vision-Language Model for Efficient\\ High-Resolution Document Parsing](https://paperswithcode.com/papers/2509.22186)\n\nWe introduce MinerU2.5, a 1.2B-parameter document parsing vision-language\nmodel that achieves state-of-the-art recognition accuracy while maintaining\nexceptional computational efficiency. Our approach employs a coarse-to-fine,\ntwo-stage parsing strategy that decouples global layout analysis from local\ncontent recognition. In the first stage, the model performs efficient layout\nanalysis on downsampled images to identify structural elements, circumventing\nthe computational overhead of processing high-resolution inputs. In the second\nstage, guided by the global layout, it performs targeted content recognition on\nnative-resolution crops extracted from the original image, preserving\nfine-grained details in dense text, complex formulas, and tables. To support\nthis strategy, we developed a comprehensive data engine that generates diverse,\nlarge-scale training corpora for both pretraining and fine-tuning. Ultimately,\nMinerU2.5 demonstrates strong document parsing ability, achieving\nstate-of-the-art performance on multiple...",
      "url": "https://paperswithcode.com/paper/tabnet-attentive-interpretable-tabular"
    },
    {
      "title": "TabNet: Attentive Interpretable Tabular Learning\n     \n      (1908.07442v5)",
      "text": "TabNet: Attentive Interpretable Tabular Learning\n1908.07442\nPapers\nTopics\nLightbulb On Streamline Icon: https://streamlinehq.com\nAuthors\nRecent\n[View all](https://www.emergentmind.com/history)\nMagnifying Glass Streamline Icon: https://streamlinehq.com\n</template>\n</form>\n2000 character limit reached\n[SponsorInformation Square Streamline Icon: https://streamlinehq.com](https://www.emergentmind.com/sponsorship)\n[![](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-logo-w343-d7fd7c8c33d166ed3ac6f5bb45f26f8b89eca7f00c1e1433295e91ce6a7d2fae.png)](https://www.paperpile.com?utm_source=emergentmind&utm_medium=sidebar-image)\nOrganize your preprints, BibTeX, and PDFs with Paperpile.\n[Get 30 days free](https://www.paperpile.com?utm_source=emergentmind&utm_medium=sidebar-text)\nChrome Extension\nEnhance arXiv with our new Chrome Extension.\n[Chrome Extension](https://chromewebstore.google.com/detail/emergent-mind-\u2014-arxiv-int/hgmnadjffdiipehljmhagdgpaoiiklml)\n# TabNet: Attentive Interpretable Tabular Learning(1908.07442v5)\nPublished20 Aug 2019 in cs.LG and stat.ML\n**Abstract:**We propose a novel high-performance and interpretable canonical deep tabular data learning architecture, TabNet. TabNet uses sequential attention to choose which features to reason from at each decision step, enabling interpretability and more efficient learning as the learning capacity is used for the most salient features. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of non-performance-saturated tabular datasets and yields interpretable feature attributions plus insights into the global model behavior. Finally, for the first time to our knowledge, we demonstrate self-supervised learning for tabular data, significantly improving performance with unsupervised representation learning when unlabeled data is abundant.\nCitations (1,094)\n[View on Semantic Scholar](<https://www.semanticscholar.org/search?q=TabNet: Attentive Interpretable Tabular Learning>)\n### Sponsor\n[![](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-logo-w343-d7fd7c8c33d166ed3ac6f5bb45f26f8b89eca7f00c1e1433295e91ce6a7d2fae.png)](https://www.paperpile.com?utm_source=emergentmind&utm_medium=inline-logo)\nOrganize your preprints, BibTeX, and PDFs with Paperpile.\n[Get 30 days free](https://www.paperpile.com?utm_source=emergentmind&amp;utm_medium=inline-button)\n[![Paperpile](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-on-laptop-caa897b8bd2dbb1dedf34da417761efa97093c381f939bf194fee6ef94a9b446.png)](https://www.paperpile.com?utm_source=emergentmind&amp;utm_medium=inline-screenshot)\n### Summary\n* The paper introduces a sequential attention mechanism that dynamically selects features for enhanced interpretability and efficient raw data integration.\n* The paper employs sparse feature selection and advanced feature transformers to achieve superior accuracy, exemplified by a 96.99% test accuracy on the Forest Cover Type dataset.\n* The paper demonstrates self-supervised learning to leverage unlabeled data, paving the way for scalable deep learning on complex tabular datasets.\n## An Analytical Overview of &quot;TabNet: Attentive Interpretable Tabular Learning&quot;\n&quot;TabNet: Attentive Interpretable Tabular Learning,&quot; authored by Sercan \u00d6. Ar\u0131k and Tomas Pfister and published by Google Cloud AI, introduces a deep neural network ([DNN](https://www.emergentmind.com/topics/dense-neural-network-dnn)) architecture explicitly designed for tabular data, a domain historically dominated by variants of ensemble decision trees. This paper presents TabNet, which combines high performance with interpretability via a[sequential attention mechanism](https://www.emergentmind.com/topics/sequential-attention-mechanism)that selects features at each decision step. This approach promotes efficient learning and provides insights into feature importance both locally and globally.\n### Introduction and Motivation\nDespite the proliferation of DNN architectures for modalities like images, text, and audio, tabular data, ubiquitous in real-world AI applications, remains an under-explored frontier. Traditional Decision Tree (DT)-based methods, which are favored due to their efficiency, interpretability, and ease of training, continue to be predominant. However, introducing deep learning into this domain aims to leverage advantages such as better performance on large datasets, seamless integration of diverse data types, elimination of extensive feature engineering, and end-to-end learning capabilities.\n### Core Contributions\nThe paper outlines four main contributions of TabNet:\n1. **Raw Data Integration**: TabNet processes tabular data without the prerequisite of extensive preprocessing, facilitated by gradient descent-based optimization.\n2. **Sequential Attention Mechanism**: By employing sequential attention to determine feature relevance at each decision step, TabNet ensures interpretability and efficient resource utilization, focusing on the most salient features dynamically for each instance.\n3. **Interpretability**: TabNet supports both local and global interpretability. Local interpretability elucidates the importance of features for individual predictions, whereas global interpretability provides aggregate feature importance mappings.\n4. **[Self-Supervised Learning](https://www.emergentmind.com/topics/self-supervised-learning-ssl)**: For the first time, the paper demonstrates significant performance improvements in tabular data by employing unsupervised pre-training to predict masked features, indicating the model&#39;s capability to benefit from abundant unlabeled data.### Technical Framework\nTabNet is underpinned by several key design principles:\n* **Sparse Feature Selection**: Through a multiplicative mask derived from an attentive transformer, the model selects the most relevant features at each step.[Sparsemax](https://www.emergentmind.com/topics/sparsemax)normalization enforces sparsity, making the feature selection interpretable.\n* **Feature Transformer and Non-linear Processing**: Composed of both shared and step-dependent fully connected layers followed by[batch normalization](https://www.emergentmind.com/topics/batch-normalization-bn)(BN) and gated linear units (GLU), the feature transformer processes the selected features. This arrangement enables higher learning capacity and efficient parameter utilization.\n* **Sequential Multi-step Architecture**: Each decision step processes a portion of the inputs, contributing iteratively to the overall decision. This mechanism mimics the ensembling effect found in traditional DT approaches while allowing more flexible and nuanced decision boundaries.\n* **Interpretability Mechanisms**: TabNet&#39;s output masks provide a quantifiable measure of feature importance at each step and collectively, yielding global interpretability by aggregating these masks over all decision steps.### Numerical Results and Performance Evaluation\nA range of experiments demonstrate TabNet&#39;s efficacy across various synthetic and real-world datasets. The following results are notable:\n* **Synthetic Datasets**: On datasets where feature importance is pre-defined or instance-dependent, TabNet either surpasses or matches state-of-the-art models like INVASE, achieving high performance with remarkably compact models.\n* **Real-World Datasets**: For datasets like the Forest Cover Type, Poker Hand, and Sarcos, TabNet significantly outperforms traditional and modern ensemble tree methods, including XGBoost, LightGBM, and[CatBoost](https://www.emergentmind.com/topics/categorical-boosting-catboost). For instance, in the Forest Cover Type dataset, TabNet achieves a test accuracy of 96.99%, well above the accuracies of other models.\n* **Interpretability**: Experiments on interpretability reveal that TabNet consistently aligns with known feature importance rankings in datasets like Mushroom Edibility and Adult Census Income, underscori...",
      "url": "https://www.emergentmind.com/articles/1908.07442"
    },
    {
      "title": "\"TabNet: Attentive Interpretable Tabular Learning.\"",
      "text": "dblp: TabNet: Attentive Interpretable Tabular Learning.\n[![Schloss Dagstuhl - Leibniz Center for Informatics](https://dblp.org/img/lzi-logo.82x57.png \"Schloss Dagstuhl - Leibniz Center for Informatics\")](https://www.dagstuhl.de/en)\n**Your feedback is essential**&ndash; not only for improving dblp, but also for demonstrating its impact to our public funders, who rely on our community input when evaluating our work. That\u2019s why we warmly invite you to**[take part in our 2025 user survey</em>](https://sidonia.dagstuhl.de/survey/index.php/141492)**. Your insights help us understand how the community uses dblp and directly shape its future development.**Thank you for contributing to dblp\u2019s future!**\n![](https://dblp.org/img/logo.320x120.png)\n![search dblp](https://dblp.org/img/search.dark.16x16.png \"search dblp\")\n![search dblp](https://dblp.org/img/search.dark.16x16.png)\n**default search action**\n* combined dblp search\n* author search\n* venue search\n* publication search\n**Authors:**\n* *no matches*\n* ![waiting...](https://dblp.org/img/waiting.anim.gif)\n**Venues:**\n* *no matches*\n* ![waiting...](https://dblp.org/img/waiting.anim.gif)\n**Publications:**\n* *no matches*\n* ![waiting...](https://dblp.org/img/waiting.anim.gif)\n![clear](https://dblp.org/img/clear-mark.medium.16x16.png \"clear\")\n[![ask others](https://dblp.org/img/search-external.dark.hollow.16x16.png)](https://google.com/search?q=)\n**ask others**\n* [![](https://dblp.org/img/google.dark.16x16.png)Google](https://google.com/search?q=)\n* [![](https://dblp.org/img/google-scholar.dark.16x16.png)Google Scholar](https://scholar.google.com/scholar?q=)\n* [![](https://dblp.org/img/semscholar.dark.16x16.png)Semantic Scholar](https://www.semanticscholar.org/search?q=)\n* [![](https://dblp.org/img/internetarchive.dark.16x16.png)Internet Archive Scholar](https://scholar.archive.org/search?q=)\n* [![](https://dblp.org/img/citeseer.dark.16x16.png)CiteSeerX](https://citeseerx.ist.psu.edu/search_result?query=)\n* [![](https://dblp.org/img/orcid.dark.16x16.png)ORCID](https://orcid.org/orcid-search/search?searchQuery=)\n# \"TabNet: Attentive Interpretable Tabular Learning.\"\nSercan &#214;mer Arik, Tomas Pfister (2019)\n* &gt;[Home](https://dblp.org)\n## SPARQL queries![](https://dblp.org/img/new.blue.24x12.png)\n&#9888;Please note that this publication does not have a DOI. Therefore, DOI-based queries won't return any results.\n**run query for this record**\n* [referenced publications](<https://sparql.dblp.org?exec=true&amp;query=##+Publications+referenced+in+journals/corr/abs-1908-07442\nPREFIX+dblp:+<https://dblp.org/rdf/schema#>\nPREFIX+cito:+<http://purl.org/spar/cito/>\nPREFIX+rdfs:+<http://www.w3.org/2000/01/rdf-schema#>\nPREFIX+schema:+<https://schema.org/>\nSELECT+?label+?year+(?ref+as+?dblp)+(SAMPLE(?dois)+as+?doi)+?url+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}\n++?publ+dblp:omid+?publ_omid+.\n++?cite+cito:hasCitingEntity+?publ_omid+.\n++?cite+cito:hasCitedEntity+?ref_omid+.\n++OPTIONAL+{\n++++?ref+dblp:omid+?ref_omid+.\n++++?ref+rdfs:label+?label+.\n++++OPTIONAL+{+?ref+dblp:yearOfPublication+?year+.+}\n++++OPTIONAL+{+?ref+dblp:doi+?dois+.+}\n++}\n++OPTIONAL+{+?ref_omid+schema:url+?url+.+}\n}\nGROUP+BY+?label+?ref+?year+?url\nORDER+BY+DESC(?year)>)\n* [cited by publications](<https://sparql.dblp.org?exec=true&amp;query=##+Publications+citing+journals/corr/abs-1908-07442\nPREFIX+dblp:+<https://dblp.org/rdf/schema#>\nPREFIX+cito:+<http://purl.org/spar/cito/>\nPREFIX+rdfs:+<http://www.w3.org/2000/01/rdf-schema#>\nPREFIX+schema:+<https://schema.org/>\nSELECT+?label+?year+(?citing+as+?dblp)+(SAMPLE(?dois)+as+?doi)+?url+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}\n++?publ+dblp:omid+?publ_omid+.\n++?cite+cito:hasCitedEntity+?publ_omid+.\n++?cite+cito:hasCitingEntity+?citing_omid+.\n++OPTIONAL+{\n++++?citing+dblp:omid+?citing_omid+.\n++++?citing+rdfs:label+?label+.\n++++OPTIONAL+{+?citing+dblp:yearOfPublication+?year+.+}\n++++OPTIONAL+{+?citing+dblp:doi+?dois+.+}\n++}\n++OPTIONAL+{+?citing_omid+schema:url+?url+.+}\n}\nGROUP+BY+?label+?year+?citing+?url\nORDER+BY+DESC(?year)>)\n* [co-cited publications](<https://sparql.dblp.org?exec=true&amp;query=##+Frequently+co-cited+publications+of+journals/corr/abs-1908-07442\nPREFIX+dblp:+<https://dblp.org/rdf/schema#>\nPREFIX+cito:+<http://purl.org/spar/cito/>\nPREFIX+rdfs:+<http://www.w3.org/2000/01/rdf-schema#>\nPREFIX+schema:+<https://schema.org/>\nSELECT+?label+?year+(COUNT(DISTINCT+?other_cite)+AS+?freq)+(?other_publ+as+?dblp)+(SAMPLE(?dois)+as+?doi)+?url+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}+.\n++?publ+dblp:omid+?publ_omid+.\n++?cite+cito:hasCitingEntity+?source_omid+.\n++?cite+cito:hasCitedEntity+?publ_omid+.\n++?other_cite+cito:hasCitingEntity+?source_omid+.\n++?other_cite+cito:hasCitedEntity+?other_omid+.\n++FILTER+(+?publ_omid+!=+?other_omid+)+.\n++OPTIONAL+{\n++++?other_publ+dblp:omid+?other_omid+.\n++++?other_publ+rdfs:label+?label+.\n++++OPTIONAL+{+?other_publ+dblp:yearOfPublication+?year+.+}\n++++OPTIONAL+{+?other_publ+dblp:doi+?dois+.+}\n++}\n++OPTIONAL+{+?other_omid+schema:url+?url+.+}\n}\nGROUP+BY+?label+?year+?other_publ+?url\nORDER+BY+DESC(?freq)\nLIMIT+10>)\n* [citing venues](<https://sparql.dblp.org?exec=true&amp;query=##+Venues+citing+journals/corr/abs-1908-07442\nPREFIX+dblp:+<https://dblp.org/rdf/schema#>\nPREFIX+cito:+<http://purl.org/spar/cito/>\nPREFIX+rdfs:+<http://www.w3.org/2000/01/rdf-schema#>\nSELECT+?venue+(?stream+as+?dblp)+(COUNT(DISTINCT+?cite)+AS+?cites)+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}\n++?publ+dblp:omid+?publ_omid+.\n++?cite+cito:hasCitedEntity+?publ_omid+.\n++?cite+cito:hasCitingEntity+?source_omid+.\n++?source+dblp:omid+?source_omid+.\n++?source+dblp:publishedInStream+?stream+.\n++?stream+rdfs:label+?venue+.\n}\nGROUP+BY+?venue+?stream\nORDER+BY+DESC(?cites)\nLIMIT+10>)\n* [co-cited venues](<https://sparql.dblp.org?exec=true&amp;query=##+Venues+frequently+co-cited+with+journals/corr/abs-1908-07442\nPREFIX+dblp:+<https://dblp.org/rdf/schema#>\nPREFIX+cito:+<http://purl.org/spar/cito/>\nPREFIX+rdfs:+<http://www.w3.org/2000/01/rdf-schema#>\nSELECT+?cocited_venue+(?stream+as+?dblp)+(COUNT(DISTINCT+?source_omid)+AS+?common_cites)+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}\n++?publ+dblp:omid+?publ_omid+.\n++?cite+cito:hasCitingEntity+?source_omid+.\n++?cite+cito:hasCitedEntity+?publ_omid+.\n++?other_cite+cito:hasCitingEntity+?source_omid+.\n++?other_cite+cito:hasCitedEntity+?other_omid+.\n++FILTER+(+?publ_omid+!=+?other_omid+)+.\n++?other_publ+dblp:omid+?other_omid+.\n++?other_publ+dblp:publishedInStream+?stream+.\n++?stream+rdfs:label+?cocited_venue+.\n}\nGROUP+BY+?cocited_venue+?stream+?other_publ+?other_omid\nORDER+BY+DESC(?common_cites)\nLIMIT+10>)\n[*or build your own?*](<https://sparql.dblp.org?query=SELECT+*+WHERE+{\n++VALUES+?publ+{+<https://dblp.org/rec/journals/corr/abs-1908-07442>+}+.\n}>)\n## Details and statistics\n**DOI:**&mdash;\n**access:**open![](https://dblp.org/img/oa.color.12x12.png)\n**type:**Informal or Other Publication\n**metadata version:**2019-08-26\nOpen Alex\n* ![](https://dblp.org/img/n.png \"Informal and Other Publications\")\n[> Sercan &#214;mer Arik\n](https://dblp.org/pid/78/10697.html)> , [> Tomas Pfister\n](https://dblp.org/pid/14/8360.html)> :\n> > TabNet: Attentive Interpretable Tabular Learning.\n> [> CoRR\n> > abs/1908.07442\n](https://dblp.org/db/journals/corr/corr1908.html#abs-1908-07442)> (\n> 2019\n> )\n*Please note:*Providing information about references and citations is only possible thanks to to the open metadata APIs provided by[crossref.org](https://github.com/CrossRef/rest-api-doc)and[opencitations.net](http://opencitations.net/index/api/v1/).**If citation data of your publications is not openly available yet, then please consider asking your publisher to release your citation data to the public.**For more information please see the[Initiative for Open Citations (I4OC)](https://i4oc.org). Please also note that there is no way o...",
      "url": "https://dblp.org/rec/journals/corr/abs-1908-07442"
    }
  ]
}