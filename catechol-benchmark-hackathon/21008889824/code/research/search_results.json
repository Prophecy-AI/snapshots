{
  "query": "How can I reduce the gap between cross-validation score and test set score when there is distribution shift in machine learning?",
  "results": [
    {
      "title": "ANSWER",
      "text": "**To narrow the gap between cross\u2011validation (CV) performance and the true test\u2011set score when a distribution shift is present, follow these core steps**\u202f([Sugiyama\u202f2007](https://jmlr.org/papers/v8/sugiyama07a.html); [Ericsson\u202f2023](https://arxiv.org/abs/2309.03879); [Wen\u202f2014](https://proceedings.mlr.press/v32/wen14.pdf); [Liang\u202f2023](https://arxiv.org/abs/2303.15361)):\n\n1. **Detect and characterize the shift**  \n   - Compare feature distributions of the training folds and a held\u2011out validation slice (e.g., using kernel density estimates or Maximum Mean Discrepancy).  \n   - If the conditional \\(p(y|x)\\) appears stable but \\(p(x)\\) differs, you are under *covariate shift*.\n\n2. **Estimate importance\u2011weights (density ratios)\u202f\\(w(x)=\\frac{p_{\\text{test}}(x)}{p_{\\text{train}}(x)}\\)**  \n   - Fit a probabilistic classifier to distinguish training vs. validation samples and convert its scores to probabilities; the odds give an estimate of \\(w(x)\\).  \n   - Alternative: use kernel\u2011based density\u2011ratio methods (e.g., KLIEP, uLSIF).\n\n3. **Apply Importance\u2011Weighted Cross\u2011Validation (IWCV)**  \n   - When computing CV loss on each fold, weight each training instance by its estimated \\(w(x)\\).  \n   - This restores the unbiasedness of CV under covariate shift, yielding a more realistic estimate of test error\u202f([Sugiyama\u202f2007](https://jmlr.org/papers/v8/sugiyama07a.html)).\n\n4. **Select or adapt a model using shift\u2011aware validation criteria**  \n   - Use validation metrics that do not require target labels, such as *reverse validation*, *entropy of predictions*, or *domain discrepancy* scores (e.g., CORAL, MMD).  \n   - These metrics have been shown to give reliable hyper\u2011parameter choices for unsupervised domain adaptation\u202f([Ericsson\u202f2023](https://arxiv.org/abs/2309.03879)).\n\n5. **Incorporate robust re\u2011weighting or covariate\u2011shift adjustment**  \n   - If simple importance weighting yields high variance, apply a *doubly robust* or *robust covariate shift adjustment* scheme that blends a low\u2011variance prior with the weighted estimator\u202f([Reddi\u202f2014](https://ojs.aaai.org/index.php/AAAI/article/download/9576/9435); [Wen\u202f2014](https://proceedings.mlr.press/v32/wen14.pdf)).  \n\n6. **Optionally perform Test\u2011Time Adaptation (TTA)**  \n   - After deployment, adapt the model on incoming unlabeled test batches (e.g., batch\u2011norm statistics updating, entropy minimization).  \n   - TTA can further close the CV\u2011test gap when the shift evolves over time\u202f([Liang\u202f2023](https://arxiv.org/abs/2303.15361)).\n\n7. **Re\u2011evaluate the CV estimate**  \n   - Run IWCV with the final weighting/re\u2011weighting scheme and the chosen validation metric.  \n   - The resulting CV score should now align closely with the observed test\u2011set performance, confirming that the distribution shift has been accounted for.  ",
      "url": ""
    },
    {
      "title": "Better Practices for Domain Adaptation",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2309.03879** (cs)\n\n\\[Submitted on 7 Sep 2023\\]\n\n# Title:Better Practices for Domain Adaptation\n\nAuthors: [Linus Ericsson](https://arxiv.org/search/cs?searchtype=author&query=Ericsson,+L), [Da Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+D), [Timothy M. Hospedales](https://arxiv.org/search/cs?searchtype=author&query=Hospedales,+T+M)\n\nView a PDF of the paper titled Better Practices for Domain Adaptation, by Linus Ericsson and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2309.03879)\n\n> Abstract:Distribution shifts are all too common in real-world applications of machine learning. Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels. However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set. The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available. This has resulted in over-optimism about DA research progress compared to reality. In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms. We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date. Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.\n\n|     |     |\n| --- | --- |\n| Comments: | AutoML 2023 (Best paper award) |\n| Subjects: | Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV) |\n| Cite as: | [arXiv:2309.03879](https://arxiv.org/abs/2309.03879) \\[cs.LG\\] |\n|  | (or [arXiv:2309.03879v1](https://arxiv.org/abs/2309.03879v1) \\[cs.LG\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2309.03879](https://doi.org/10.48550/arXiv.2309.03879)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Linus Ericsson \\[ [view email](https://arxiv.org/show-email/8d84eb61/2309.03879)\\]\n\n**\\[v1\\]**\nThu, 7 Sep 2023 17:44:18 UTC (252 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Better Practices for Domain Adaptation, by Linus Ericsson and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2309.03879)\n- [TeX Source](https://arxiv.org/src/2309.03879)\n- [Other Formats](https://arxiv.org/format/2309.03879)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2309.03879&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2309.03879&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2023-09](https://arxiv.org/list/cs.LG/2023-09)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2309.03879?context=cs)\n\n[cs.CV](https://arxiv.org/abs/2309.03879?context=cs.CV)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2309.03879)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2309.03879)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2309.03879)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2309.03879&description=Better Practices for Domain Adaptation) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2309.03879&title=Better Practices for Domain Adaptation)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2309.03879) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2309.03879"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2303.15361] A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2303.15361\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2303.15361**(cs)\n[Submitted on 27 Mar 2023 ([v1](https://arxiv.org/abs/2303.15361v1)), last revised 12 Dec 2024 (this version, v2)]\n# Title:A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts\nAuthors:[Jian Liang](https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+J),[Ran He](https://arxiv.org/search/cs?searchtype=author&amp;query=He,+R),[Tieniu Tan](https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+T)\nView a PDF of the paper titled A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts, by Jian Liang and Ran He and Tieniu Tan\n[View PDF](https://arxiv.org/pdf/2303.15361)[HTML (experimental)](https://arxiv.org/html/2303.15361v2)> > Abstract:\n> Machine learning methods strive to acquire a robust model during the training process that can effectively generalize to test samples, even in the presence of distribution shifts. However, these methods often suffer from performance degradation due to unknown test distributions. Test-time adaptation (TTA), an emerging paradigm, has the potential to adapt a pre-trained model to unlabeled data during testing, before making predictions. Recent progress in this paradigm has highlighted the significant benefits of using unlabeled data to train self-adapted models prior to inference. In this survey, we categorize TTA into several distinct groups based on the form of test data, namely, test-time domain adaptation, test-time batch adaptation, and online test-time adaptation. For each category, we provide a comprehensive taxonomy of advanced algorithms and discuss various learning scenarios. Furthermore, we analyze relevant applications of TTA and discuss open challenges and promising areas for future research. For a comprehensive list of TTA methods, kindly refer to \\url{\n[> this https URL\n](https://github.com/tim-learn/awesome-test-time-adaptation)> }. Comments:|Discussions, comments, and questions are all welcomed in \\\\url{[this https URL](https://github.com/tim-learn/awesome-test-time-adaptation)}|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)|\nCite as:|[arXiv:2303.15361](https://arxiv.org/abs/2303.15361)[cs.LG]|\n|(or[arXiv:2303.15361v2](https://arxiv.org/abs/2303.15361v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2303.15361](https://doi.org/10.48550/arXiv.2303.15361)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nJournalreference:|International Journal of Computer Vision (2024)|\nRelated DOI:|[https://doi.org/10.1007/s11263-024-02181-w](https://doi.org/10.1007/s11263-024-02181-w)\nFocus to learn more\nDOI(s) linking to related resources\n|\n## Submission history\nFrom: Jian Liang [[view email](https://arxiv.org/show-email/a8a6c287/2303.15361)]\n**[[v1]](https://arxiv.org/abs/2303.15361v1)**Mon, 27 Mar 2023 16:32:21 UTC (1,021 KB)\n**[v2]**Thu, 12 Dec 2024 09:06:56 UTC (686 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts, by Jian Liang and Ran He and Tieniu Tan\n* [View PDF](https://arxiv.org/pdf/2303.15361)\n* [HTML (experimental)](https://arxiv.org/html/2303.15361v2)\n* [TeX Source](https://arxiv.org/src/2303.15361)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2303.15361&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2303.15361&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2023-03](https://arxiv.org/list/cs.LG/2023-03)\nChange to browse by:\n[cs](https://arxiv.org/abs/2303.15361?context=cs)\n[cs.AI](https://arxiv.org/abs/2303.15361?context=cs.AI)\n[cs.CV](https://arxiv.org/abs/2303.15361?context=cs.CV)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2303.15361)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2303.15361)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2303.15361)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2303.15361&amp;description=A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2303.15361&amp;title=A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organiza...",
      "url": "https://arxiv.org/abs/2303.15361"
    },
    {
      "title": "Covariate Shift Adaptation by Importance Weighted Cross Validation",
      "text": "[Home Page](https://www.jmlr.org/)\n\n[Papers](https://www.jmlr.org/papers)\n\n[Submissions](https://www.jmlr.org/author-info.html)\n\n[News](https://www.jmlr.org/news.html)\n\n[Editorial Board](https://www.jmlr.org/editorial-board.html)\n\n[Special Issues](https://www.jmlr.org/special_issues/)\n\n[Open Source Software](https://www.jmlr.org/mloss)\n\n[Proceedings (PMLR)](https://proceedings.mlr.press/)\n\n[Data (DMLR)](https://data.mlr.press/)\n\n[Transactions (TMLR)](https://www.jmlr.org/tmlr)\n\n[Search](https://www.jmlr.org/search-jmlr.html)\n\n[Statistics](https://www.jmlr.org/stats.html)\n\n[Login](https://www.jmlr.org/manudb)\n\n[Frequently Asked Questions](https://www.jmlr.org/faq.html)\n\n[Contact Us](https://www.jmlr.org/contact.html)\n\n## Covariate Shift Adaptation by Importance Weighted Cross Validation\n\n**_Masashi Sugiyama, Matthias Krauledat, Klaus-Robert M\u00fcller_**; 8(35):985\u22121005, 2007.\n\n### Abstract\n\nA common assumption in supervised learning is that the input points in\nthe training set follow the _same_ probability distribution as\nthe input points that will be given in the future test phase.\nHowever, this assumption is not satisfied, for example, when the\noutside of the training region is extrapolated. The situation where\nthe training input points and test input points follow\n_different_ distributions while the conditional distribution of\noutput values given input points is unchanged is called the\n_covariate shift_. Under the covariate shift, standard model\nselection techniques such as cross validation do not work as desired\nsince its unbiasedness is no longer maintained. In this paper, we\npropose a new method called _importance weighted cross_\n_validation_ (IWCV), for which we prove its unbiasedness even under the\ncovariate shift. The IWCV procedure is the only one that can be\napplied for unbiased classification under covariate shift, whereas\nalternatives to IWCV exist for regression. The usefulness of our\nproposed method is illustrated by simulations, and furthermore\ndemonstrated in the brain-computer interface, where strong\nnon-stationarity effects can be seen between training and test\nsessions.\n\n\\[abs\\]\\[ [pdf](https://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf)\\]\\[ [bib](https://www.jmlr.org/papers/v8/sugiyama07a.bib)\\]\n\n\n|     |\n| --- |\n| \u00a9 [JMLR](https://www.jmlr.org) 2007.<br>( [edit](https://github.com/JmlrOrg/v8/tree/main/sugiyama07a), [beta](http://jmlr.org/beta/papers/v8/sugiyama07a.html)) |\n\n [Mastodon](https://sigmoid.social/@jmlr)",
      "url": "https://jmlr.org/papers/v8/sugiyama07a.html"
    },
    {
      "title": "",
      "text": "Robust Learning under Uncertain Test Distributions:\nRelating Covariate Shift to Model Misspecification\nJunfeng Wen1JUNFENG.WEN@UALBERTA.CA\nChun-Nam Yu2 CHUN-NAM.YU@ALCATEL-LUCENT.COM\nRussell Greiner1 RGREINER@UALBERTA.CA\n1Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E8 CANADA\n2Bell Labs, Alcatel-Lucent, 600 Mountain Avenue, Murray Hill, NJ 07974 USA\nAbstract\nMany learning situations involve learning the\nconditional distribution ppy|xq when the training\ninstances are drawn from the training distribu\u0002tion ptrpxq, even though it will later be used to\npredict for instances drawn from a different test\ndistribution ptepxq. Most current approaches fo\u0002cus on learning how to reweigh the training ex\u0002amples, to make them resemble the test distribu\u0002tion. However, reweighing does not always help,\nbecause (we show that) the test error also de\u0002pends on the correctness of the underlying model\nclass. This paper analyses this situation by view\u0002ing the problem of learning under changing dis\u0002tributions as a game between a learner and an ad\u0002versary. We characterize when such reweighing\nis needed, and also provide an algorithm, robust\ncovariate shift adjustment (RCSA), that provides\nrelevant weights. Our empirical studies, on UCI\ndatasets and a real-world cancer prognostic pre\u0002diction dataset, show that our analysis applies,\nand that our RCSA works effectively.\n1. Introduction\nTraditional machine learning often explicitly or implicitly\nassumes that the data used for training a model come from\nthe same distribution as that of the test data. However, this\nassumption is violated in many real-world applications. For\nexample, biostatisticians often try to collect a large and di\u0002verse training set, perhaps for building prognostic predic\u0002tors for patients with different diseases. When clinicians\ndeploy these predictors, they do not know whether the lo\u0002cal test patient population will be even close to that training\npopulation. Sometimes we can collect a small sample from\nthe target test population, but in most cases we have noth\u0002Proceedings of the 31 st International Conference on Machine\nLearning, Beijing, China, 2014. JMLR: W&CP volume 32. Copy\u0002right 2014 by the author(s).\ning more than weak prior knowledge about how the test\ndistribution may shift, such as anticipated changes in gen\u0002der ratio or age distribution. It is useful to build predictors\nthat are robust against such changes in test distributions.\nIn this work, we investigate the problem of distribu\u0002tion change under covariate shift assumption (Shimodaira,\n2000), in which both training and test distributions share\nthe same conditional distribution ppy|xq, while their\nmarginal distributions, ptrpxq and ptepxq, are different. To\ncorrect the shifted distribution, major efforts have been\ndedicated to importance reweighing (Quionero-Candela\net al., 2009; Sugiyama & Kawanabe, 2012). However,\nreweighing methods will not necessarily improve the per\u0002formance in test set, as prediction accuracy under covariate\nshift is also dependent on model misspecification (White,\n1981). Fig. 1 shows three examples of misspecified mod\u0002els, where we are considering the model class of straight\nlines of the form y\u201cax`b, for xP r\u00b41.5, 2.5s. In Fig. 1(a),\nno straight line is a good fit for the cubic curve across\nthe whole interval, but Model 2 fits the curve reasonably\nwell in the small interval r\u00b40.5, 0.5s. If training data is\nspread all over r\u00b41.5, 2.5s while test data concentrates on\nr\u00b40.5, 0.5s, improvement via reweighing could be signif\u0002icant. The situation in Fig. 1(b) is different: although the\ntrue model is a curve and not a straight line, the best linear\nfit is no more than \u000f away from the value of the true model.\nIn this case, no matter what test distributions we see in the\ninterval r\u00b41.5, 2.5s, the regression loss of the best linear\nmodel will never be more than \u000f from the Bayes optimal\nloss. In Fig. 1(c), the true model is a straight line except at\nx \u201c 0; perhaps this outlier is a cancer patient whose tumour\nspontaneously disappeared on its own. Unless the test dis\u0002tribution concentrates most of its mass at x \u201c 0, the straight\nline fit learned from the training data over the interval will\nstill be a very good predictor. Sometimes we can rule out\nthis type of covariate shift through prior knowledge. If such\noutliers are extremely rare during training time, we would\nnot expect the test population to have many such patients.\nReweighing will not help much in cases 1(b) and 1(c).\nRobust Learning under Uncertain Test Distributions\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22122\n0\n2\n4\n6\n8\n10\n12\n14\n16\nInput\nOutput\nTrue model\nModel 1\nModel 2\n(a) Large misspecification.\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22122\n\u22121\n0\n1\n2\n3\n4\n5\nInput\nOutput\n\u2191\n\u2193\n\u03b5\nTrue model\nBest linear fit\n(b) Small misspecification.\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22120.5\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\nInput\nOutput\nTrue model\n(c) Single point misspecification.\nFigure 1. Three different scenarios of model misspecifications.\nIn this paper, we relate covariate shift to model misspecifi\u0002cation and investigate when reweighing can help a learner\ndeal with covariate shift. We introduce a game between a\nlearner and an adversary that performs robust learning. The\nlearner chooses a model \u03b8 from a set \u0398 to minimize the\nloss, while the adversary chooses a reweighing function \u03b1\nfrom a set A to create new test distributions to maximize the\nloss. There are two major contributions in this paper: First,\nwe provide an improved understanding of the relation be\u0002tween covariate shift and model misspecification through\nthis game analysis. If the learner can find a \u03b8 that min\u0002imizes the loss against any possible \u03b1 that the adversary\ncan play, then it is not necessary to perform reweighing\nagainst covariate shift scenarios represented by A. Sec\u0002ond, we provide a systematic method for checking a model\nclass \u0398 against different covariate shift scenarios, such as\nchanging gender ratio and age distributions in the prognos\u0002tic predictor example, to help user decide whether impor\u0002tance reweighing would be beneficial.\nFor practical use, our method can be used to decide if the\nmodel class is sufficient against shifts that are close to a test\nsample; or robust against a known range of potential shifts\nif test sample is unavailable. If the model class is insuffi\u0002cient, we can consider different ways to deal with covariate\nshifts, such as reweighing using unlabelled test samples, or\nexploring a different model class for the problem.\n2. Related Work\nOur work is inspired by Grunwald & Dawid \u00a8 (2004), who\ninterpret maximum entropy as a game between an adver\u0002sary and a learner on minimizing the worst case expected\nlog loss. Teo et al. (2008) and Globerson & Roweis (2006)\nalso consider an adversarial scenario under changing test\nset conditions, but they are concerned with corruption or\ndeletion of features rather than covariate shift.\nMany results on covariate shift correction involve density\nratio estimation. Shimodaira (2000) showed that, given co\u0002variate shift and model misspecification, reweighing each\ninstance with ptepxq{ptrpxq is asymptotically optimal for\nlog-likelihood estimation, where ptrpxq and ptepxq are as\u0002sumed to be known or estimated in advance. Sugiyama\n& Muller \u00a8 (2005) extended this work by proposing an\n(almost) unbiased estimator for L2 generalization error.\nThere are several works focusing on minimizing differ\u0002ent types of divergence between distributions in the liter\u0002ature (Kanamori et al., 2008; Sugiyama et al., 2008; Ya\u0002mada et al., 2011). Kernel mean matching (KMM) (Huang\net al., 2007) reweighs instances to match means in a\nRKHS (Scholkopf & Smola \u00a8 , 2002). Our work and some\nother approaches (Pan et al., 2009) adapt the idea of match\u0002ing means of the datasets to correct shifted distribution,\nbut we extend their approaches from a two-step optimiza\u0002tion to a game framework that jointly learns a model\nand weights with covariate shift correction. Some other\napproaches (Zadrozny, 2004; Bickel et al.,...",
      "url": "https://proceedings.mlr.press/v32/wen14.pdf"
    },
    {
      "title": "",
      "text": "Doubly Robust Covariate Shift Correction\nSashank J. Reddi\nMachine Learning Department\nCarnegie Mellon University\nsjakkamr@cs.cmu.edu\nBarnabas P \u00b4 oczos \u00b4\nMachine Learning Department\nCarnegie Mellon University\nbapoczos@cs.cmu.edu\nAlex Smola\nMachine Learning Department\nCarnegie Mellon University\nalex@smola.org\nAbstract\nCovariate shift correction allows one to perform supervised\nlearning even when the distribution of the covariates on the\ntraining set does not match that on the test set. This is\nachieved by re-weighting observations. Such a strategy re\u0002moves bias, potentially at the expense of greatly increased\nvariance. We propose a simple strategy for removing bias\nwhile retaining small variance. It uses a biased, low variance\nestimate as a prior and corrects the final estimate relative to\nthe prior. We prove that this yields an efficient estimator and\ndemonstrate good experimental performance.\nIntroduction\nCovariate shift is a common problem when dealing with real\ndata. Quite often the experimental conditions under which a\ntraining set is generated are subtly different from the situa\u0002tion in which the system is deployed. For instance, in can\u0002cer diagnosis the training set may have an overabundance of\ndiseased patients, often of a specific subtype endemic in the\nlocation where the data was gathered. Likewise, due to tem\u0002poral changes in user interest the distribution of covariates in\nadvertising systems is nonstationary. This requires increas\u0002ing the weight of data related to, e.g., \u2018Gangnam style\u2019, when\nprocessing historic data logs.\nA common approach to addressing covariate shift is to\nreweight data such that the reweighted distribution matches\nthe target distribution. Briefly, suppose we observe X :=\n{x1, . . . , xm} drawn iid from q(x), typically with associated\nlabels Y := {y1, . . . , ym} drawn from p(y|x). This consti\u0002tutes the \u2018training set\u2019. However, we need to find a minimizer\nf\n\u2217\np of risk Rp\u2014 defined in Equation (1) \u2014 with regard to\np(y|x)p(x), for which we only have iid draws of the covari\u0002ates X0\n:= {x\n0\n1\n, . . . x0\nm0}. Note that simply minimizing the\nempirical risk on the training data leads to a biased estimate\n(since training set corresponds to samples from q(x)p(y|x)).\nIf p and q are known, this problem can be addressed via im\u0002Copyright \rc 2015, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nportance sampling in the following manner:\nRp[f] = Ex\u223cp(x)Ey|x(`(y, f(x)))\n=\nZ\np(x)\nq(x)\nq(x)Ey|x`(y, f(x))dx\n= Ex\u223cq(x)Ey|x [\u03b2(x)`(y, f(x))] , (1)\nwhere \u03b2(x) := p(x)\nq(x)\nand ` is a loss function. Correspond\u0002ingly, empirical averages with respect to X and X0\ncan\nbe reweighted, see, e.g., (Quinonero-Candela et al. 2008; \u02dc\nCortes et al. 2008) and the references therein for further de\u0002tails. While estimator based on Equation (1) is unbiased, it\ntends to increase the variance of the empirical averages con\u0002siderably by weighting the observations by \u03b2.\nThis issue is particularly exacerbated when the weights\nare large. As a rule of thumb the effective sample size of\na reweighted dataset is meff := k\u03b2(X)k\n2\n1\n/ k\u03b2(X)k\n2\n2 where\n\u03b2(X) is the vector of weights \u03b2(x1), . . . , \u03b2(xm). This quan\u0002tity naturally arises, e.g., for a weighted average of Gaussian\nrandom variables, while deriving Chernoff bounds using the\nweights \u03b2(X) (Gretton et al. 2008), or in the particle filter\u0002ing context (Doucet, de Freitas, and Gordon 2001). To gain\nbetter intuition for meff, consider the case where p = q. In\nthis case, we have high effective sample size (meff = m).\nWhereas in the undesirable case of a single observation hav\u0002ing very high weight, meff \u2248 1. Hence, meff is a good in\u0002dicator of the effect of \u03b2(x) on variance of the weighted\nempirical averages.\nThus, while one might obtain an unbiased estimator via\nEquation (1), it becomes nearly useless when the effective\nsample size is small relative to the original sample size.\nThis situation is frequently observed in practice insofar as\nwe encounter cases where simple covariate shift correction\nnot only fails to improve generalization performance on the\ntest set but, in fact, leads to estimates that perform worse\nthan simply minimizing the empirical risk on the training\ndata (i.e., unweighted estimation). Moreover, in many cases\nthe solutions of the biased and the unbiased risk estimates\nare closer than what the distributions p and q would suggest.\nFigure 1 shows an example of such a scenario.\nThe situation described above is often encountered in\npractice \u2014 covariate shift correction fails to improve mat\u0002ters due to high variance while the unweighted solution per\u0002forms reasonably well. This raises the question of how we\nProceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence 2949\n0\n1\n2\n3\n4\n5\n-6 -4 -2 0 2 4 6\nFigure 1: Assume that the dependence y|x is linear in x, as indi\u0002cated by the green line. In this case, inferring y|x using the blue\ndistribution q, as depicted by the blue crosses (with matching den\u0002sity), would lead to a perfectly accurate estimate, even if the test\nset is drawn according to red distribution p. On the other hand,\nreweighting with p(x)\nq(x) would lead to a very small effective sample\nsize since p and q are very different. While this example is ob\u0002viously somewhat artificial, there exist many situations where the\nminimizer of the biased risk is very good.\ncould benefit from the low variance of the biased estimate\nfound by using q while removing bias via weighting with\n\u03b2. This is precisely what doubly robust estimators address\n\u2014 see, e.g., (Kang and Schafer 2007) for an overview. They\nprovide us with two opportunities to obtain a good estimate.\nIf the unweighted estimate solves the problem, the estimate\nwill be very good and minimizing the unbiased risk will not\nchange the final outcome significantly. Conversely, if the un\u0002weighted estimate is useless, we still have the opportunity to\namend things in the context of estimating f\n\u2217\np by reweighting\nthe dataset. This work focuses on tackling the problem of\ncovariate shift correction from a doubly robust viewpoint by\neffectively utilizing the unweighted estimate.\nMain Contributions: In summary, the paper makes the fol\u0002lowing contributions. (1) We develop a simple, yet powerful,\nframework for doubly robust estimation in the context of co\u0002variate shift correction, which to the best of our knowledge,\nhas not been previously explored. (2) We demonstrate the\ngenerality of the framework by providing several concrete\nexamples. (3) We present a general theory for the framework\nand provide a detailed analysis in the case of kernel meth\u0002ods. (4) Finally, we show good experimental performance\non several UCI datasets.\nRelated Work\nThere has been extensive research in covariate shift correc\u0002tion problem. Most of the work is directed towards estimat\u0002ing the weights \u03b2. Several methods have been proposed to\nestimate these weights by optimization and statistical tech\u0002niques (Gretton et al. 2008; Agarwal, Li, and Smola 2011;\nSugiyama et al. 2008; Wen, nam Yu, and Greiner 2014).\nLikewise, there has been considerable work in developing\ndoubly robust estimators for many statistical and machine\nlearning problems, particularly in the problems involving\nmissing data and reinforcement learning (Kang and Schafer\n2007; Dud\u00b4\u0131k, Langford, and Li 2011; Bang and Robins\n2005). But none of these works address the problem of our\nconcern, namely doubly robust estimation for covariate shift\ncorrection. While a few works, e.g., (Shimodaira 2000), at\u0002tempt to reduce the variance by adjusting the weights and\nthereby, balancing the bias-variance tradeoff, they do not\ntackle the problem from doubly robust estimation point of\nview. In fact, these methods can be used in conjunction with\nour approach.\nThe most relevant to our work are (Kuzborskij and\nOrabona 2013), (Li and Bilmes 2007) and (Daume III 2007).\nAll these works use similar ideas for addressing related\nproblems in domain adaptation. However, none of these\nworks address th...",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/9576/9435"
    },
    {
      "title": "On the Interconnections of Calibration, Quantification, and Classifier Accuracy Prediction under Dataset Shift",
      "text": "On the Interconnections of Calibration, Quantification, and Classifier Accuracy Prediction under Dataset Shift\n# On the Interconnections of Calibration, Quantification, and Classifier Accuracy Prediction under Dataset Shift\nAlejandro MoreoAlejandro Moreo\nIstituto di Scienza e Tecnologie dell\u2019Informazione,\nConsiglio Nazionale delle Ricerche\nVia Giuseppe Moruzzi 1, 56124, Pisa, Italy\nalejandro.moreo@isti.cnr.it\n###### Abstract\nWhen the distribution of the data used to train a classifier differs from that of the test data, i.e., under dataset shift, well-established routines for calibrating the decision scores of the classifier, estimating the proportion of positives in a test sample, or estimating the accuracy of the classifier, become particularly challenging.\nThis paper investigates the interconnections among three fundamental problems, calibration, quantification, and classifier accuracy prediction, under dataset shift conditions.\nSpecifically, we prove their equivalence through mutual reduction, i.e., we show that access to an oracle for any one of these tasks enables the resolution of the other two. Based on these proofs, we propose new methods for each problem based on direct adaptations of well-established methods borrowed from the other disciplines. Our results show such methods are often competitive, and sometimes even surpass the performance of dedicated approaches from each discipline.\nThe main goal of this paper is to fostering cross-fertilization among these research areas, encouraging the development of unified approaches and promoting synergies across the fields.\n*K*eywordsdataset shift\u22c5\u22c5\\\\cdot\u22c5classifier calibration\u22c5\u22c5\\\\cdot\u22c5quantification\u22c5\u22c5\\\\cdot\u22c5classifier accuracy prediction\n## 1Introduction\nClassifiers are often deployed in contexts in which theindependent and identically distributed(IID) assumption is violated, i.e., in which the data used to train the model and the future data to be classified are not drawn from the same distribution.\nThis situation is generally referred to asdataset shiftin the machine learning literature> [\n[> Storkey, 2009\n](https://arxiv.org/html/2505.11380v1#bib.bibx70)> ]\n.\nIn this context, three problems have gained increased attention in the last years.Classifier calibration> [\n[> Flach and Webb, 2016\n](https://arxiv.org/html/2505.11380v1#bib.bibx27)> , [> Silva\u00a0Filho et\u00a0al., 2023\n](https://arxiv.org/html/2505.11380v1#bib.bibx69)> ]\nconcerns the manipulation of the confidence scores produced by a classifier so that these\neffectively reflect the likelihood that a given instance is positive.Quantification> [\n[> Gonz\u00e1lez et\u00a0al., 2017\n](https://arxiv.org/html/2505.11380v1#bib.bibx33)> , [> Esuli et\u00a0al., 2023\n](https://arxiv.org/html/2505.11380v1#bib.bibx20)> ]\nis instead concerned with estimating the prevalence of the classes of interest in an unlabelled set.\nFinally,classifier accuracy predictionaims at inferring how well a classifier will fare on unseen data> [\n[> Elsahar and Gall\u00e9, 2019\n](https://arxiv.org/html/2505.11380v1#bib.bibx19)> , [> Guillory et\u00a0al., 2021\n](https://arxiv.org/html/2505.11380v1#bib.bibx37)> ]\n.\nWell-established procedures for attaining these three goals when the IID assumption holds are known and routinely used.\nFor instance, calibrating the classifier\u2019s outputs can be attained by learning a calibration map (a function mapping classifier confidence scores into values reflecting the likelihood of the positive class) on held-out validation data> [\n[> Platt, 2000\n](https://arxiv.org/html/2505.11380v1#bib.bibx60)> , [> Zadrozny and Elkan, 2001a\n](https://arxiv.org/html/2505.11380v1#bib.bibx78)> , [> Barlow and Brunk, 1972\n](https://arxiv.org/html/2505.11380v1#bib.bibx3)> ]\n.111Notwithstanding this, calibration under IID conditions is still an active area of research; see, e.g.,> [\n[> Tasche, 2021\n](https://arxiv.org/html/2505.11380v1#bib.bibx72)> ]\n.Concerning quantification, the class proportions in a test set can be estimated by simply classifying and counting how many positives fall under which class. Finally, the performance that a classifier will exhibit on unseen data can be estimated on held-out validation data> [\n[> Hastie et\u00a0al., 2009\n](https://arxiv.org/html/2505.11380v1#bib.bibx39)> ]\n.\nHowever, when the IID assumption is violated, these standard routines are prone to failure.\nFor example, calibration is a property typically defined with respect to a specific distribution, meaning that a classifier is unlikely to remain well-calibrated across different distributions> [\n[> Ovadia et\u00a0al., 2019\n](https://arxiv.org/html/2505.11380v1#bib.bibx55)> ]\n. Similarly, the commonly used \u201cclassify and count\u201d approach for class prevalence estimation is known to yield biased predictions under certain dataset shift conditions> [\n[> Esuli et\u00a0al., 2023\n](https://arxiv.org/html/2505.11380v1#bib.bibx20)> , \u00a71.2]\n.\nLikewise, the accuracy of a classifier estimated on held-out validation data or via cross-validation is biased when the IID assumption does not hold> [\n[> Storkey, 2009\n](https://arxiv.org/html/2505.11380v1#bib.bibx70)> ]\n.\nThe three problems are deeply interconnected and may arise in related real-world applications. Consider, for example, a classifier trained on X-ray lung images to assist clinical decisions regarding medical interventions. In order for the classifier to aid in making informed decisions, the classifier must not only provide classifier decisions, but also a measure of uncertainty attached to it, i.e., its outputs must be well calibrated. Now, suppose a pandemic occurs, altering the natural prevalence of a pneumonic virus in the population. In response, several actions must be undertaken to develop a trustworthy response to the virus.\nEstimating the prevalence of the population affected by the virus (for which any of the quantification methods discussed in> [\n[> Gonz\u00e1lez et\u00a0al., 2017\n](https://arxiv.org/html/2505.11380v1#bib.bibx33)> ]\ncan be employed) is of the utmost importance for epidemiologists> [\n[> Patrone and Kearsley, 2024\n](https://arxiv.org/html/2505.11380v1#bib.bibx58)> ]\n; these prevalence estimates are useful to recalibrate the classifier outputs to reflect the new priors> [\n[> Godau et\u00a0al., 2025\n](https://arxiv.org/html/2505.11380v1#bib.bibx32)> ]\n(using techniques such as those in> [\n[> Elkan, 2001\n](https://arxiv.org/html/2505.11380v1#bib.bibx18)> , [> Guilbert et\u00a0al., 2024\n](https://arxiv.org/html/2505.11380v1#bib.bibx36)> ]\n). Alternatively, the practitioner might need to estimate the accuracy of different candidate classifiers under the new conditions in order to, e.g., replace the existing classifier with a different one that is expected to perform more accurately in the new distribution, or maybe to reweigh the relative importance of different classifiers in an ensemble (which necessitate methods for classifier accuracy prediction such as, e.g.,> [\n[> Guillory et\u00a0al., 2021\n](https://arxiv.org/html/2505.11380v1#bib.bibx37)> , [> Garg et\u00a0al., 2022\n](https://arxiv.org/html/2505.11380v1#bib.bibx30)> ]\n).\nA better understanding of the interdependencies between the three problems may lead to more robust and integrated solutions, especially in dynamic or high-stakes environments such as healthcare.\nHowever, the applicability of one technique or another is ultimately subject to verifying certain assumptions about the relationship between the underlying distributions.\nIn the context of dataset shift> [\n[> Storkey, 2009\n](https://arxiv.org/html/2505.11380v1#bib.bibx70)> ]\n, the two most important such types of shift include*covariate shift*(CS) and*prior probability shift*(aka*label shift*\u2013LS).\nCS presupposes a change in the marginal distribution of the observed features, while the posterior probabilities are assumed stationary. Conversely, LS has to do with a change in the class prevalence subject to stationary class-conditional distributions of the observed features. More formal definitions are provided later on.\nIn this paper, we argue that the interplay be...",
      "url": "https://arxiv.org/html/2505.11380v1"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2107.00643] Mandoline: Model Evaluation under Distribution Shift\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2107.00643\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2107.00643**(cs)\n[Submitted on 1 Jul 2021 ([v1](https://arxiv.org/abs/2107.00643v1)), last revised 11 Apr 2022 (this version, v2)]\n# Title:Mandoline: Model Evaluation under Distribution Shift\nAuthors:[Mayee Chen](https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+M),[Karan Goel](https://arxiv.org/search/cs?searchtype=author&amp;query=Goel,+K),[Nimit S. Sohoni](https://arxiv.org/search/cs?searchtype=author&amp;query=Sohoni,+N+S),[Fait Poms](https://arxiv.org/search/cs?searchtype=author&amp;query=Poms,+F),[Kayvon Fatahalian](https://arxiv.org/search/cs?searchtype=author&amp;query=Fatahalian,+K),[Christopher R\u00e9](https://arxiv.org/search/cs?searchtype=author&amp;query=R\u00e9,+C)\nView a PDF of the paper titled Mandoline: Model Evaluation under Distribution Shift, by Mayee Chen and 5 other authors\n[View PDF](https://arxiv.org/pdf/2107.00643)> > Abstract:\n> Machine learning models are often deployed in different settings than they were trained and validated on, posing a challenge to practitioners who wish to predict how well the deployed model will perform on a target distribution. If an unlabeled sample from the target distribution is available, along with a labeled sample from a possibly different source distribution, standard approaches such as importance weighting can be applied to estimate performance on the target. However, importance weighting struggles when the source and target distributions have non-overlapping support or are high-dimensional. Taking inspiration from fields such as epidemiology and polling, we develop Mandoline, a new evaluation framework that mitigates these issues. Our key insight is that practitioners may have prior knowledge about the ways in which the distribution shifts, which we can use to better guide the importance weighting procedure. Specifically, users write simple &#34;slicing functions&#34; - noisy, potentially correlated binary functions intended to capture possible axes of distribution shift - to compute reweighted performance estimates. We further describe a density ratio estimation framework for the slices and show how its estimation error scales with slice quality and dataset size. Empirical validation on NLP and vision tasks shows that Mandoline can estimate performance on the target distribution up to 3x more accurately compared to standard baselines. Comments:|33 pages. Published as a conference paper at ICML 2021|\nSubjects:|Machine Learning (cs.LG)|\nCite as:|[arXiv:2107.00643](https://arxiv.org/abs/2107.00643)[cs.LG]|\n|(or[arXiv:2107.00643v2](https://arxiv.org/abs/2107.00643v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2107.00643](https://doi.org/10.48550/arXiv.2107.00643)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Nimit Sohoni [[view email](https://arxiv.org/show-email/c336d188/2107.00643)]\n**[[v1]](https://arxiv.org/abs/2107.00643v1)**Thu, 1 Jul 2021 17:57:57 UTC (650 KB)\n**[v2]**Mon, 11 Apr 2022 00:14:55 UTC (489 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Mandoline: Model Evaluation under Distribution Shift, by Mayee Chen and 5 other authors\n* [View PDF](https://arxiv.org/pdf/2107.00643)\n* [TeX Source](https://arxiv.org/src/2107.00643)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2107.00643&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2107.00643&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2021-07](https://arxiv.org/list/cs.LG/2021-07)\nChange to browse by:\n[cs](https://arxiv.org/abs/2107.00643?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2107.00643)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2107.00643)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2107.00643)\n### [1 blog link](https://arxiv.org/tb/2107.00643)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2107.html#abs-2107-00643)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2107-00643)\n[Karan Goel](<https://dblp.uni-trier.de/search/author?author=Karan Goel>)\n[Nimit Sharad Sohoni](<https://dblp.uni-trier.de/search/author?author=Nimit Sharad Sohoni>)\n[Kayvon Fatahalian](<https://dblp.uni-trier.de/search/author?author=Kayvon Fatahalian>)\n[Christopher R\u00e9](<https://dblp.uni-trier.de/search/author?author=Christopher R\u00e9>)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2107.00643&amp;description=Mandoline: Model Evaluation under Distribution Shift>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2107.00643&amp;title=Mandoline: Model Evaluation under Distribution Shift>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencema...",
      "url": "https://arxiv.org/abs/2107.00643"
    },
    {
      "title": "",
      "text": "Journal of Machine Learning Research 8 (2007) 985-1005 Submitted 6/06; Revised 8/06; Published 5/07\nCovariate Shift Adaptation by Importance Weighted Cross Validation\nMasashi Sugiyama SUGI@CS.TITECH.AC.JP\nDepartment of Computer Science\nTokyo Institute of Technology\n2-12-1, O-okayama, Meguro-ku, Tokyo, 152-8552, Japan\nMatthias Krauledat MATTHIAS.KRAULEDAT@FIRST.FHG.DE\nKlaus-Robert Muller \u00a8 KLAUS@FIRST.FHG.DE\nDepartment of Computer Science\nTechnical University Berlin\nFranklinstr. 28/29, 10587 Berlin, Germany\nEditor: Yoshua Bengio\nAbstract\nA common assumption in supervised learning is that the input points in the training set follow\nthe same probability distribution as the input points that will be given in the future test phase.\nHowever, this assumption is not satisfied, for example, when the outside of the training region is\nextrapolated. The situation where the training input points and test input points follow different\ndistributions while the conditional distribution of output values given input points is unchanged\nis called the covariate shift. Under the covariate shift, standard model selection techniques such\nas cross validation do not work as desired since its unbiasedness is no longer maintained. In this\npaper, we propose a new method called importance weighted cross validation (IWCV), for which\nwe prove its unbiasedness even under the covariate shift. The IWCV procedure is the only one\nthat can be applied for unbiased classification under covariate shift, whereas alternatives to IWCV\nexist for regression. The usefulness of our proposed method is illustrated by simulations, and\nfurthermore demonstrated in the brain-computer interface, where strong non-stationarity effects\ncan be seen between training and test sessions.\nKeywords: covariate shift, cross validation, importance sampling, extrapolation, brain-computer\ninterface\n1. Introduction\nThe goal of supervised learning is to infer an unknown input-output dependency from training\nsamples, by which output values for unseen test input points can be estimated. When developing\na method of supervised learning, it is commonly assumed that the input points in the training set\nand the input points used for testing follow the same probability distribution (e.g., Wahba, 1990;\nBishop, 1995; Vapnik, 1998; Duda et al., 2001; Hastie et al., 2001; Scholk \u00a8 opf and Smola, 2002).\nHowever, this common assumption is not fulfilled, for example, when we extrapolate outside of\nthe training region1 or when training input points are designed by an active learning (experimental\ndesign) algorithm. The situation where the training input points and test input points follow different\n1. The term \u2018extrapolation\u2019 could have been defined in a narrow sense as prediction in regions with no training samples.\nOn the other hand, the situation we are considering here is \u2018weak\u2019 extrapolation; prediction is carried out in the region\nwhere only a small number of training samples is available.\n\rc 2007 Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Muller \u00a8 .\nSUGIYAMA, KRAULEDAT AND MU\u00a8 LLER\nprobability distributions but the conditional distributions of output values given input points are\nunchanged is called the covariate shift (Shimodaira, 2000). For data from many applications such\nas off-policy reinforcement learning (Shelton, 2001), spam filtering (Bickel and Scheffer, 2007),\nbioinformatics (Baldi et al., 1998; Borgwardt et al., 2006) or brain-computer interfacing (Wolpaw\net al., 2002), the covariate shift phenomenon is conceivable. Sample selection bias (Heckman, 1979)\nin economics may also include a form of the covariate shift. Illustrative examples of covariate shift\nsituations are depicted in Figures 1 and 3.\nIn this paper, we develop a new learning method and prove that we can alleviate misestimation\ndue to covariate shift. From the beginning, we note that all the theoretical discussions will be made\nunder the assumption that the ratio of test and training input densities at training input points is\nknown; in experimental studies, the density ratio will be replaced by their empirical estimates and\nthe practical performance of our approach will be evaluated.\nModel selection is one of the key ingredients in machine learning. However, under the covariate\nshift, a standard model selection technique such as cross validation (CV) (Stone, 1974; Wahba,\n1990) does not work as desired; more specifically, the unbiasedness that guarantees the accuracy\nof CV does not hold under the covariate shift anymore. To cope with this problem, we propose a\nnovel variant of CV called importance weighted CV (IWCV). We prove that IWCV gives an almost\nunbiased estimate of the risk even under the covariate shift. Model selection under the covariate\nshift has been studied so far only by few researchers (e.g., Shimodaira, 2000; Sugiyama and Muller, \u00a8\n2005)\u2014existing methods have a number of limitations, for example, in the loss function, parameter\nlearning method, and model. In particular, the existing methods can not be applied to classification\nscenarios. On the other hand, the proposed IWCV overcomes these limitations: it allows for any\nloss function, parameter learning method, and model; even non-parametric learning methods can\nbe employed. To the best of our knowledge, the proposed IWCV is the first method that can be\nsuccessfully applied to model selection in covariate-shifted classification tasks. The usefulness of\nthe proposed method is demonstrated in the brain-computer interface applications, in which existing\nmethods for covariate shift compensation could not be employed.\n2. Problem Formulation\nIn this section, we formulate the supervised learning problem with the covariate shift, and review\nexisting learning methods.\n2.1 Supervised Learning under Covariate Shift\nLet us consider the supervised learning problem of estimating an unknown input-output depen\u0002dency from training samples. Let T = {(xi\n, yi)}\nn\ni=1\nbe the training samples, where xi \u2208 X \u2282 R\nd\nis\nan i.i.d. training input point following a probability distribution Ptrain(x) and yi \u2208 Y \u2282 R is a corre\u0002sponding training output value following a conditional probability distribution P(y|x). P(y|x) may\nbe regarded as the sum of true output f(x) and noise.\nLet `(x, y, yb): X \u00d7Y \u00d7Y \u2192 [0,\u221e) be the loss function, which measures the discrepancy between\nthe true output value y at an input point x and its estimate yb. Let us employ a parametric model\nfb(x;\u03b8) for estimating the output value y, where \u03b8 \u2208 \u0398 \u2282 R\nb\n. Note that the range of application\nof our proposed method given in Section 3 includes non-parametric methods, but we focus on a\nparametric setting for simplicity. A model fb(x;\u03b8) is said to be correctly specified if there exists a\nparameter \u03b8\n\u2217\nsuch that fb(x;\u03b8\n\u2217\n) = f(x); otherwise the model is said to be misspecified. In practice,\n986\nCOVARIATE SHIFT ADAPTATION BY IMPORTANCE WEIGHTED CROSS VALIDATION\nthe model used for learning would be misspecified to a greater or lesser extent. For this reason,\nwe do not assume that the model is correct in this paper. The goal of supervised learning is to\ndetermine the value of the parameter \u03b8 so that output values for unlearned test input points are\naccurately estimated.\nLet us consider a test sample, which is not given to the user in the training phase, but will be\ngiven in the test phase in the future. We denote the test sample by (t,u), where t \u2208 X is a test input\npoint and u \u2208 Y is a corresponding test output value. The test error expected over test samples is\nexpressed as\nEt,u\nh\n`(t,u, fb(t;b\u03b8))i, (1)\nwhere E denotes the expectation. Note that the learned parameter b\u03b8 generally depends on the train\u0002ing set T = {(xi\n, yi)}\nn\ni=1\n. In the following, we consider the expected test error over the training\nsamples, which is called the risk or the generalization error:\nR\n(n) \u2261 E{xi\n,yi}\nn\ni=1\n,t,u\nh\n`(t,u, fb(t;b\u03b8))i. (2)\nIn standard supervised learning theories, the testsample (t,u)is assumed to follow P(u|t)Ptrain(t),\nwhich is the same probability...",
      "url": "https://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf"
    }
  ]
}