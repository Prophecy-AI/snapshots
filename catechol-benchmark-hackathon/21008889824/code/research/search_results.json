{
  "query": "How can I improve machine learning predictions when extrapolating to chemical compounds outside the training domain in molecular property prediction?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Improving extrapolative performance for molecular\u2011property models requires (1) realistic out\u2011of\u2011distribution (OOD) evaluation, (2) richer, physics\u2011based descriptors, (3) learning strategies that bridge the ID\u2011OOD gap, and (4) robust validation and calibration\u202f([Fooladi\u202f2025](https://chemrxiv.org/engage/chemrxiv/article-details/67c8a90bfa469535b9148866);\u202f[Yan\u202f2024](https://pubs.rsc.org/en/Content/ArticleLanding/2024/DD/D3DD00256J);\u202f[Kim\u202f2025](https://arxiv.org/abs/2506.11877)).\n\n**Step\u2011by\u2011step guide**\n\n1. **Create a challenging OOD test split**  \n   - Use chemical\u2011similarity clustering (e.g., K\u2011means on ECFP4 fingerprints) rather than simple scaffold splits, because cluster\u2011based splits expose the hardest extrapolation cases (Pearson\u202fr\u202f\u2248\u202f0.4) and give a realistic stress test for your model\u202f([Fooladi\u202f2025](https://chemrxiv.org/engage/chemrxiv/article-details/67c8a90bfa469535b9148866)).  \n\n2. **Enrich the feature set with quantum\u2011mechanical (QM) descriptors**  \n   - Augment the usual structural fingerprints with the QMex QM descriptor set.  \n   - Train an Interactive Linear Regression (ILR) model that adds interaction terms between QM descriptors and categorical structural information; this has shown state\u2011of\u2011the\u2011art extrapolative accuracy on small\u2011data properties\u202f([Nature\u202f2024](https://www.nature.com/articles/s41524-023-01194-2)).  \n\n3. **Apply a meta\u2011learning or transfer\u2011learning scheme that leverages unlabeled molecules**  \n   - Use a meta\u2011learner that interpolates between ID and OOD data by jointly optimizing on labeled training points and a large pool of unlabeled compounds.  \n   - This approach reduces covariate shift and yields significant gains on real\u2011world OOD benchmarks\u202f([Kim\u202f2025](https://arxiv.org/abs/2506.11877)).  \n\n4. **Incorporate active learning to target the domain boundary**  \n   - Iteratively query the most uncertain or diverse unlabeled compounds (e.g., highest predictive variance) for experimental measurement, then add them to the training set.  \n   - Active learning has been demonstrated to enable extrapolation in molecular generative models, effectively expanding the model\u2019s applicability domain\u202f([Antoniuk\u202f2025](https://arxiv.org/abs/2501.02059)).  \n\n5. **Validate with Extrapolation Validation (EV) and calibrate probabilistic outputs**  \n   - Use the EV protocol to assess extrapolation risk on the OOD split, adjusting model hyper\u2011parameters until EV metrics are acceptable.  \n   - Calibrate predictions with probabilistic methods such as DIONYSUS to ensure reliable uncertainty estimates on low\u2011data chemical sets\u202f([Yan\u202f2024](https://pubs.rsc.org/en/Content/ArticleLanding/2024/DD/D3DD00256J);\u202f[Tom\u202f2023](https://pubs.rsc.org/en/content/articlehtml/2023/dd/d2dd00146b)).  \n\n6. **Benchmark progress with an OOD benchmark suite**  \n   - Compare your model against the BOOM benchmark (which aggregates multiple OOD splits and metrics) to quantify improvements relative to existing baselines\u202f([Antoniuk\u202f2025](https://arxiv.org/abs/2505.01912)).  \n\nFollowing these steps\u2014realistic OOD evaluation, physics\u2011informed features, meta\u2011/active\u2011learning to bridge distribution gaps, and rigorous validation/calibration\u2014will systematically boost the reliability of molecular property predictions for compounds that lie outside the original training domain.",
      "url": ""
    },
    {
      "title": "Evaluating Machine Learning Models for Molecular Property Prediction: Performance and Robustness on Out-of-Distribution Data",
      "text": "<div><div><p></p><h2>Abstract</h2><p></p> <p>Today, machine learning models are employed extensively to predict the physicochemical and biological properties of molecules. Their performance is typically evaluated on in-distribution (ID) data, i.e., data originating from the same distribution as the training data. However, the real-world applications of such models often involve molecules that are more distant from the training data, which necessitates assessing their performance on out-of-distribution (OOD) data. In this work, we investigate and evaluate the performance of twelve machine learning models, including classical approaches like random forests, as well as graph neural network (GNN) methods, such as message-passing graph neural networks, across eight data sets using seven splitting strategies for OOD data generation. First, we investigate what constitutes OOD data in the molecular domain for bioactivity and ADMET prediction tasks. In contrast to the common point of view, we show that both classical machine learning and GNN models work well (not substantially different from random splitting) on data split based on Bemis-Murcko scaffolds. Splitting based on chemical similarity clustering (K-means clustering using ECFP4 fingerprints) poses the hardest challenge for both types of models. Second, we investigate the extent to which ID and OOD performance have a positive linear relationship. If a positive correlation holds, models with the best performance on the ID data can be selected with the promise of having the best performance on OOD data. We show that the strength of this linear relationship is strongly related to how the OOD data is generated, i.e., which splitting strategies are used for generating OOD data. While the correlation between ID and OOD performance for scaffold splitting is strong (Pearson r \u223c 0.9), this correlation decreases significantly for cluster-based splitting (Pearson r \u223c 0.4). Therefore, the relationship can be more nuanced, and a strong positive correlation is not guaranteed for all OOD scenarios. These findings suggest that OOD performance evaluation and model selection should be carefully aligned with the intended application domain.</p> </div></div>",
      "url": "https://chemrxiv.org/engage/chemrxiv/article-details/67c8a90bfa469535b9148866"
    },
    {
      "title": "Extrapolative prediction of small-data molecular property using quantum mechanics-assisted machine learning",
      "text": "[![npj Computational Materials](https://media.springernature.com/full/nature-cms/uploads/product/npjcompumats/header-4baba14304e9c3518bdc0d6f35b470b9.svg)](https://www.nature.com/npjcompumats)\n\nExtrapolative prediction of small-data molecular property using quantum mechanics-assisted machine learning\n\n[Download PDF](https://www.nature.com/articles/s41524-023-01194-2.pdf)\n\n[Download PDF](https://www.nature.com/articles/s41524-023-01194-2.pdf)\n\n### Subjects\n\n- [Computational methods](https://www.nature.com/subjects/computational-methods)\n- [Theoretical chemistry](https://www.nature.com/subjects/theoretical-chemistry)\n\n## Abstract\n\nData-driven materials science has realized a new paradigm by integrating materials domain knowledge and machine-learning (ML) techniques. However, ML-based research has often overlooked the inherent limitation in predicting unknown data: extrapolative performance, especially when dealing with small-scale experimental datasets. Here, we present a comprehensive benchmark for assessing extrapolative performance across 12 organic molecular properties. Our large-scale benchmark reveals that conventional ML models exhibit remarkable performance degradation beyond the training distribution of property range and molecular structures, particularly for small-data properties. To address this challenge, we introduce a quantum-mechanical (QM) descriptor dataset, called QMex, and an interactive linear regression (ILR), which incorporates interaction terms between QM descriptors and categorical information pertaining to molecular structures. The QMex-based ILR achieved state-of-the-art extrapolative performance while preserving its interpretability. Our benchmark results, QMex dataset, and proposed model serve as valuable assets for improving extrapolative predictions with small experimental datasets and for the discovery of novel materials/molecules that surpass existing candidates.\n\n### Similar content being viewed by others\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41524-024-01339-x/MediaObjects/41524_2024_1339_Fig1_HTML.png)\n\n### [Learning together: Towards foundation models for machine learning interatomic potentials with meta-learning](https://www.nature.com/articles/s41524-024-01339-x?fromPaywallRec=false)\n\nArticleOpen access17 July 2024\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41570-022-00416-3/MediaObjects/41570_2022_416_Figa_HTML.png)\n\n### [Extending machine learning beyond interatomic potentials for predicting molecular properties](https://www.nature.com/articles/s41570-022-00416-3?fromPaywallRec=false)\n\nArticle25 August 2022\n\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-025-04720-7/MediaObjects/41597_2025_4720_Fig1_HTML.png)\n\n### [The QCML dataset, Quantum chemistry reference data from 33.5M DFT and 14.7B semi-empirical calculations](https://www.nature.com/articles/s41597-025-04720-7?fromPaywallRec=false)\n\nArticleOpen access08 March 2025\n\n## Introduction\n\nMaterials science has greatly benefited from advancements in machine learning (ML) and deep learning (DL) techniques[1](https://www.nature.com/www.nature.com#ref-CR1), [2](https://www.nature.com/www.nature.com#ref-CR2), [3](https://www.nature.com/www.nature.com#ref-CR3), [4](https://www.nature.com/www.nature.com#ref-CR4), [5](https://www.nature.com/www.nature.com#ref-CR5), [6](https://www.nature.com/articles/s41524-023-01194-2#ref-CR6). These techniques have revolutionized the prediction of molecular properties, leveraging traditional computational approaches, such as the group contribution (GC) method[7](https://www.nature.com/www.nature.com#ref-CR7), [8](https://www.nature.com/www.nature.com#ref-CR8), [9](https://www.nature.com/articles/s41524-023-01194-2#ref-CR9), quantitative structure-activity/property relationship (QSAR/QSPR) method[10](https://www.nature.com/www.nature.com#ref-CR10), [11](https://www.nature.com/www.nature.com#ref-CR11), [12](https://www.nature.com/www.nature.com#ref-CR12), [13](https://www.nature.com/articles/s41524-023-01194-2#ref-CR13), quantum mechanics (QM), and molecular dynamics (MD) calculations[14](https://www.nature.com/www.nature.com#ref-CR14), [15](https://www.nature.com/www.nature.com#ref-CR15), [16](https://www.nature.com/www.nature.com#ref-CR16), [17](https://www.nature.com/www.nature.com#ref-CR17), [18](https://www.nature.com/www.nature.com#ref-CR18), [19](https://www.nature.com/www.nature.com#ref-CR19), [20](https://www.nature.com/www.nature.com#ref-CR20), [21](https://www.nature.com/www.nature.com#ref-CR21), [22](https://www.nature.com/www.nature.com#ref-CR22), [23](https://www.nature.com/www.nature.com#ref-CR23), [24](https://www.nature.com/www.nature.com#ref-CR24), [25](https://www.nature.com/www.nature.com#ref-CR25), [26](https://www.nature.com/articles/s41524-023-01194-2#ref-CR26). Graph neural networks (GNNs) have emerged as a promising DL-based method for property prediction by embedding molecular structures in a graph architecture[27](https://www.nature.com/articles/s41524-023-01194-2#ref-CR27), [28](https://www.nature.com/articles/s41524-023-01194-2#ref-CR28). Moreover, pre-trained GNNs, which employ self-supervised or transfer learning, have demonstrated the highest accuracies across various benchmarks in molecular property prediction[29](https://www.nature.com/www.nature.com#ref-CR29), [30](https://www.nature.com/www.nature.com#ref-CR30), [31](https://www.nature.com/www.nature.com#ref-CR31), [32](https://www.nature.com/www.nature.com#ref-CR32), [33](https://www.nature.com/articles/s41524-023-01194-2#ref-CR33). ML/DL techniques continue to enhance the accuracy and speed of property prediction, serving as indispensable tools for data-driven materials science.\n\nHowever, a fundamental contradiction persists in ML/DL techniques regarding their inherent extrapolation difficulty, i.e., the ability to predict beyond the available data. In molecular property prediction, two main limitations arise from the range of molecular properties and the diversity of molecular structures (see Fig. [1](https://www.nature.com/articles/s41524-023-01194-2#Fig1)). The primary objective of data-driven materials exploration is to identify high-performance molecules/materials that are not yet represented in databases. Hence, ML/DL models must possess the capability to extrapolate unexplored data solely from the available data. However, materials datasets often consist of small experimental results, typically containing fewer than 500 data points[34](https://www.nature.com/www.nature.com#ref-CR34), [35](https://www.nature.com/www.nature.com#ref-CR35), [36](https://www.nature.com/www.nature.com#ref-CR36), [37](https://www.nature.com/www.nature.com#ref-CR37), [38](https://www.nature.com/www.nature.com#ref-CR38), [39](https://www.nature.com/articles/s41524-023-01194-2#ref-CR39), which inevitably carries biases due to molecular structures and property ranges. It is crucial to determine whether ML/DL models can overcome these biases and effectively extrapolate molecular properties, even when dealing with limited data, to discover novel materials/molecules that outperform existing ones.\n\n**Fig. 1: Overview of extrapolative prediction of molecular property based on the range of molecular properties and the diversity of molecular structures.**\n\n[![figure 1](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41524-023-01194-2/MediaObjects/41524_2023_1194_Fig1_HTML.png)](https://www.nature.com/articles/s41524-023-01194-2/figures/1)\n\nThe interpolation task represents predictions within the available property range and molecular structures, while the extrapolation task represents predictions outside the training distribution of existing data. Plot illustrates the relationship between 1D-UMAP (Uniform Manifold Approximation and Projection[90](https://www.nature.com/articles/s41524-023-01194-2#ref-CR90)) compo...",
      "url": "https://www.nature.com/articles/s41524-023-01194-2"
    },
    {
      "title": "Robust Molecular Property Prediction via Densifying Scarce Labeled Data",
      "text": "[View PDF](https://arxiv.org/pdf/2506.11877) [HTML (experimental)](https://arxiv.org/html/2506.11877v1)\n\n> Abstract:A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial covariate shift, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data, stemming from the onerous and costly nature of experimental validation, further exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel meta-learning-based approach that leverages unlabeled data to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.\n\n## Submission history\n\nFrom: Jina Kim \\[ [view email](https://arxiv.org/show-email/96b77896/2506.11877)\\]\n\n**\\[v1\\]**\nFri, 13 Jun 2025 15:27:40 UTC (10,933 KB)",
      "url": "https://arxiv.org/abs/2506.11877"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2501.02059] Active Learning Enables Extrapolation in Molecular Generative Models\n[Skip to main content](#content)\n[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](/IgnoreMe)\n[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/)&gt;[cs](/list/cs/recent)&gt;arXiv:2501.02059\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2501.02059**(cs)\n[Submitted on 3 Jan 2025]\n# Title:Active Learning Enables Extrapolation in Molecular Generative Models\nAuthors:[Evan R. Antoniuk](https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniuk,+E+R),[Peggy Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+P),[Nathan Keilbart](https://arxiv.org/search/cs?searchtype=author&amp;query=Keilbart,+N),[Stephen Weitzner](https://arxiv.org/search/cs?searchtype=author&amp;query=Weitzner,+S),[Bhavya Kailkhura](https://arxiv.org/search/cs?searchtype=author&amp;query=Kailkhura,+B),[Anna M. Hiszpanski](https://arxiv.org/search/cs?searchtype=author&amp;query=Hiszpanski,+A+M)\nView a PDF of the paper titled Active Learning Enables Extrapolation in Molecular Generative Models, by Evan R. Antoniuk and 4 other authors\n[View PDF](/pdf/2501.02059)> > Abstract:\n> Although generative models hold promise for discovering molecules with optimized desired properties, they often fail to suggest synthesizable molecules that improve upon the known molecules seen in training. We find that a key limitation is not in the molecule generation process itself, but in the poor generalization capabilities of molecular property predictors. We tackle this challenge by creating an active-learning, closed-loop molecule generation pipeline, whereby molecular generative models are iteratively refined on feedback from quantum chemical simulations to improve generalization to new chemical space. Compared against other generative model approaches, only our active learning approach generates molecules with properties that extrapolate beyond the training data (reaching up to 0.44 standard deviations beyond the training data range) and out-of-distribution molecule classification accuracy is improved by 79%. By conditioning molecular generation on thermodynamic stability data from the active-learning loop, the proportion of stable molecules generated is 3.5x higher than the next-best model. Subjects:|Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Chemical Physics (physics.chem-ph)|\nCite as:|[arXiv:2501.02059](https://arxiv.org/abs/2501.02059)[cs.LG]|\n|(or[arXiv:2501.02059v1](https://arxiv.org/abs/2501.02059v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2501.02059](https://doi.org/10.48550/arXiv.2501.02059)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Evan Antoniuk [[view email](/show-email/77d99001/2501.02059)]\n**[v1]**Fri, 3 Jan 2025 19:07:06 UTC (4,348 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Active Learning Enables Extrapolation in Molecular Generative Models, by Evan R. Antoniuk and 4 other authors\n* [View PDF](/pdf/2501.02059)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](/prevnext?id=2501.02059&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](/prevnext?id=2501.02059&amp;function=next&amp;context=cs.LG)\n[new](/list/cs.LG/new)|[recent](/list/cs.LG/recent)|[2025-01](/list/cs.LG/2025-01)\nChange to browse by:\n[cond-mat](/abs/2501.02059?context=cond-mat)\n[cond-mat.mtrl-sci](/abs/2501.02059?context=cond-mat.mtrl-sci)\n[cs](/abs/2501.02059?context=cs)\n[physics](/abs/2501.02059?context=physics)\n[physics.chem-ph](/abs/2501.02059?context=physics.chem-ph)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2501.02059)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2501.02059)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2501.02059)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2501.02059&amp;description=Active Learning Enables Extrapolation in Molecular Generative Models>)[![Reddit logo](/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2501.02059&amp;title=Active Learning Enables Extrapolation in Molecular Generative Models>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2501.02059)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2501.02059"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2505.01912] BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2505.01912\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2505.01912**(cs)\n[Submitted on 3 May 2025 ([v1](https://arxiv.org/abs/2505.01912v1)), last revised 19 Dec 2025 (this version, v2)]\n# Title:BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models\nAuthors:[Evan R. Antoniuk](https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniuk,+E+R),[Shehtab Zaman](https://arxiv.org/search/cs?searchtype=author&amp;query=Zaman,+S),[Tal Ben-Nun](https://arxiv.org/search/cs?searchtype=author&amp;query=Ben-Nun,+T),[Peggy Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+P),[James Diffenderfer](https://arxiv.org/search/cs?searchtype=author&amp;query=Diffenderfer,+J),[Busra Sahin](https://arxiv.org/search/cs?searchtype=author&amp;query=Sahin,+B),[Obadiah Smolenski](https://arxiv.org/search/cs?searchtype=author&amp;query=Smolenski,+O),[Tim Hsu](https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu,+T),[Anna M. Hiszpanski](https://arxiv.org/search/cs?searchtype=author&amp;query=Hiszpanski,+A+M),[Kenneth Chiu](https://arxiv.org/search/cs?searchtype=author&amp;query=Chiu,+K),[Bhavya Kailkhura](https://arxiv.org/search/cs?searchtype=author&amp;query=Kailkhura,+B),[Brian Van Essen](https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Essen,+B)\nView a PDF of the paper titled BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models, by Evan R. Antoniuk and 11 other authors\n[View PDF](https://arxiv.org/pdf/2505.01912)[HTML (experimental)](https://arxiv.org/html/2505.01912v2)> > Abstract:\n> Data-driven molecular discovery leverages artificial intelligence/machine learning (AI/ML) and generative modeling to filter and design novel molecules. Discovering novel molecules requires accurate out-of-distribution (OOD) predictions, but ML models struggle to generalize OOD. Currently, no systematic benchmarks exist for molecular OOD prediction tasks. We present $\\mathbf{BOOM}$, $\\mathbf{b}$enchmarks for $\\mathbf{o}$ut-$\\mathbf{o}$f-distribution $\\mathbf{m}$olecular property predictions: a chemically-informed benchmark for OOD performance on common molecular property prediction tasks. We evaluate over 150 model-task combinations to benchmark deep learning models on OOD performance. Overall, we find that no existing model achieves strong generalization across all tasks: even the top-performing model exhibited an average OOD error 3x higher than in-distribution. Current chemical foundation models do not show strong OOD extrapolation, while models with high inductive bias can perform well on OOD tasks with simple, specific properties. We perform extensive ablation experiments, highlighting how data generation, pre-training, hyperparameter optimization, model architecture, and molecular representation impact OOD performance. Developing models with strong OOD generalization is a new frontier challenge in chemical ML. This open-source benchmark is available at [> this https URL\n](https://github.com/FLASK-LLNL/BOOM)> Subjects:|Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2505.01912](https://arxiv.org/abs/2505.01912)[cs.LG]|\n|(or[arXiv:2505.01912v2](https://arxiv.org/abs/2505.01912v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2505.01912](https://doi.org/10.48550/arXiv.2505.01912)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Evan Antoniuk [[view email](https://arxiv.org/show-email/6abb5e36/2505.01912)]\n**[[v1]](https://arxiv.org/abs/2505.01912v1)**Sat, 3 May 2025 19:51:23 UTC (35,134 KB)\n**[v2]**Fri, 19 Dec 2025 23:00:10 UTC (16,070 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models, by Evan R. Antoniuk and 11 other authors\n* [View PDF](https://arxiv.org/pdf/2505.01912)\n* [HTML (experimental)](https://arxiv.org/html/2505.01912v2)\n* [TeX Source](https://arxiv.org/src/2505.01912)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2505.01912&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2505.01912&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-05](https://arxiv.org/list/cs.LG/2025-05)\nChange to browse by:\n[cond-mat](https://arxiv.org/abs/2505.01912?context=cond-mat)\n[cond-mat.mtrl-sci](https://arxiv.org/abs/2505.01912?context=cond-mat.mtrl-sci)\n[cs](https://arxiv.org/abs/2505.01912?context=cs)\n[cs.AI](https://arxiv.org/abs/2505.01912?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2505.01912)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2505.01912)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2505.01912)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2505.01912&amp;description=BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2505.01912&amp;title=BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*...",
      "url": "https://arxiv.org/abs/2505.01912"
    },
    {
      "title": "Extrapolation validation (EV): a universal validation method for mitigating machine learning extrapolation risk - Digital Discovery (RSC Publishing)",
      "text": "Extrapolation validation (EV): a universal validation method for mitigating machine learning extrapolation risk - Digital Discovery (RSC Publishing)\n[\nJump to main content![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)\n](#maincontent)[\nJump to site search![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)\n](#SearchText)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/menu-light.png)](#)\n[Publishing](https://pubs.rsc.org/)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/search-light.png)](#)\nSearch\n![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right.png)[Advanced](https://pubs.rsc.org/en/search/advancedsearch)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/user-light.png)](https://pubs.rsc.org/en/account/logon)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/trolley-light.png)](https://www.rsc.org/basket/shoppingcart/orderitems?returnurl=https://pubs.rsc.org/en/Content/ArticleLanding/2024/DD/D3DD00256J)\n[![Royal Society of Chemistry homepage](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/rsc-logo-rev-pubs.svg)](https://www.rsc.org)\nSearch\n**![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right.png)\nYou must enter a search term\n[Advanced search](https://pubs.rsc.org/en/search/advancedsearch)\n[Issue 5, 2024](https://pubs.rsc.org/en/journals/journal/dd?issueid=dd003005&amp;type=current)\n[\n![](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=CoverIssue&amp;imageInfo.ImageIdentifier.SerCode=DD&amp;imageInfo.ImageIdentifier.IssueId=DD003005)\nFrom the journal:### Digital Discovery\n](https://pubs.rsc.org/en/journals/journal/dd)\n## Extrapolation validation (EV): a universal validation method for mitigating machine learning extrapolation risk[&#8224;](#fn1)\n![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg)\n[Mengxian\rYu](https://pubs.rsc.org/en/results?searchtext=Author:Mengxian%20Yu),*a*[Yin-Ning\rZhou](https://pubs.rsc.org/en/results?searchtext=Author:Yin-Ning%20Zhou),[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0003-3509-3983)*b*[Qiang\rWang](https://pubs.rsc.org/en/results?searchtext=Author:Qiang%20Wang)*a*and[Fangyou\rYan](https://pubs.rsc.org/en/results?searchtext=Author:Fangyou%20Yan)[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/orcid_16x16.png)](https://orcid.org/0009-0009-6394-4600)\\**a*\n[Author affiliations](#)\n\\*Corresponding authors\naSchool of Chemical Engineering and Material Science, Tianjin University of Science and Technology, Tianjin 300457, P. R. China\n**E-mail:**[yanfangyou@tust.edu.cn](mailto:yanfangyou@tust.edu.cn)\nbDepartment of Chemical Engineering, School of Chemistry and Chemical Engineering, Shanghai Jiao Tong University, Shanghai 200240, P. R. China\n### Abstract\nMachine learning (ML) can provide decision-making advice for major challenges in science and engineering, and its rapid development has led to advances in fields like chemistry &amp; medicine, earth &amp; life sciences, and communications &amp; transportation. Grasping the trustworthiness of the decision-making advice given by ML models remains challenging, especially when applying them to samples outside the domain-of-application. Here, an untrustworthy application situation (*i.e.*, complete extrapolation-failure) that would occur in models developed by ML methods involving tree algorithms is confirmed, and the root cause of its difficulty in discovering novel materials &amp; chemicals is revealed. Furthermore, a universal extrapolation risk evaluation scheme, termed the extrapolation validation (EV) method, is proposed, which is not restricted to specific ML methods and model architecture in its applicability. The EV method quantitatively evaluates the extrapolation ability of 11 popularly applied ML methods and digitalizes the extrapolation risk arising from variations of the independent variables in each method. Meanwhile, the EV method provides insights and solutions for evaluating the reliability of out-of-distribution sample prediction and selecting trustworthy ML methods.\n![Graphical abstract: Extrapolation validation (EV): a universal validation method for mitigating machine learning extrapolation risk](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=GA&amp;imageInfo.ImageIdentifier.ManuscriptID=D3DD00256J&amp;imageInfo.ImageIdentifier.Year=2024)\nThis article is Open Access\n![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/Ajax-GA-Loader.gif)Please wait while we load your content...Something went wrong.[Try again?](#)\n[About](#pnlAbstract)\n[Cited by](#pnlCitation)\n[Related](#pnlRelatedContent)\n[Download optionsPlease wait...](#)\n## Supplementary files\n* [Supplementary informationPDF (2680K)](https://www.rsc.org/suppdata/d3/dd/d3dd00256j/d3dd00256j1.pdf)\n## Article information\nDOI[https://doi.org/10.1039/D3DD00256J](https://doi.org/10.1039/D3DD00256J)\n**Article type**Paper\nSubmitted29 Dec 2023\nAccepted17 Apr 2024\nFirst published19 Apr 2024\n![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/open-access-icon-orange.png)\n**This article is Open Access**[![Creative Commons BY-NC license](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/CCBY-NC.svg)](http://creativecommons.org/licenses/by-nc/3.0/)\n### DownloadCitation\n***Digital Discovery***, 2024,**3**, 1058-1067\nBibTexEndNoteMEDLINEProCiteReferenceManagerRefWorksRIS\n### Permissions\n[Request permissions](#)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](#)### Extrapolation validation (EV): a universal validation method for mitigating machine learning extrapolation risk\nM. Yu, Y. Zhou, Q. Wang and F. Yan,*Digital Discovery*, 2024,**3**, 1058**DOI:**10.1039/D3DD00256J\nThis article is licensed under a[Creative Commons Attribution-NonCommercial 3.0 Unported Licence](https://creativecommons.org/licenses/by-nc/3.0/).**You can use material from this article in other publications, without requesting further permission**from the RSC, provided that the correct acknowledgement is given and it is not used for commercial purposes.\nTo request permission**to reproduce material from this article in a commercial publication**, please go to the[Copyright Clearance Center request page](https://marketplace.copyright.com/rs-ui-web/mp/search/all/10.1039/D3DD00256J).\nIf you are**an author contributing to an RSC publication, you do not need to request permission**provided correct acknowledgement is given.\nIf you are**the author of this article, you do not need to request permission to reproduce figures and diagrams**provided correct acknowledgement is given. If you want to reproduce the whole article in a third-party commercial publication (excluding your thesis/dissertation for which permission is not required) please go to the[Copyright Clearance Center request page](https://marketplace.copyright.com/rs-ui-web/mp/search/all/10.1039/D3DD00256J).\nRead more about[how to correctly acknowledge RSC content](https://www.rsc.org/journals-books-databases/journal-authors-reviewers/licences-copyright-permissions/#acknowledgements).\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](#)\n### Social activity\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/twitter.svg)Tweet](https://twitter.com/intent/tweet/?text=Extrapolation+validation+(EV):+a+universal+validation+method+for+mitigating+machine+learning+extrapolation+risk+-+now+published+in+Digital+Discovery&url=https://pubs.rsc.org/en/content/articlelanding/2024/dd/d3dd00256j)\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/wechat.svg)Share](https://pubs.rsc.org/en/Image/GetQrCode?url=https://pubs.rsc.org/en/content/articlelanding/2024/dd/d3dd00256j)\n## Search articles by author\nMengxian Yu\nYin-Ning Zhou\nQiang Wang\nFangyou Yan\n![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/Ajax-GA-Loader.gif)Fetching data from CrossRef.\nThis may ta...",
      "url": "https://pubs.rsc.org/en/Content/ArticleLanding/2024/DD/D3DD00256J"
    },
    {
      "title": "Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS \u2020",
      "text": "Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS - Digital Discovery (RSC Publishing) DOI:10.1039/D2DD00146B\n[![Royal Society of Chemistry](/content/NewImages/royal-society-of-chemistry-logo.png)](/)\n[View\u00a0PDF\u00a0Version](/en/content/articlepdf/2023/dd/d2dd00146b)[Previous\u00a0Article](/en/content/articlehtml/2023/dd/d3dd00012e)[Next\u00a0Article](/en/content/articlehtml/2023/dd/d3dd00061c)\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](#)\n![](/content/newimages/open_access_blue.png)Open Access Article\n![](/content/newimages/CCBY-NC.svg)This Open Access Article is licensed under a[Creative Commons Attribution-Non Commercial 3.0 Unported Licence](http://creativecommons.org/licenses/by-nc/3.0/)\nDOI:[10.1039/D2DD00146B](https://doi.org/10.1039/D2DD00146B)(Paper)[Digital Discovery](https://doi.org/10.1039/2635-098X/2022), 2023,**2**, 759-774\n# Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS[\u2020](#fn1)\nGary Tom[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-8470-6515)abc,Riley J. Hickman[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-5762-1006)abc,Aniket Zinzuwadiad,Afshan Mohajeri[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-3858-3024)e,Benjamin Sanchez-Lengeling[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-1116-1745)fandAl\u00e1n Aspuru-Guzik\\*abcghi\naChemical Physics Theory Group, Department of Chemistry, University of Toronto, Toronto, ON, Canada. E-mail:[alan@aspuru.com](mailto:alan@aspuru.com)\nbDepartment of Computer Science, University of Toronto, Toronto, ON, Canada\ncVector Institute for Artificial Intelligence, Toronto, ON, Canada\ndHarvard Medical School, Harvard University, Boston, MA, USA\neDepartment of Chemistry, Shiraz University, Shiraz, Iran\nfGoogle Research, Brain Team, USA\ngDepartment of Chemical Engineering &amp; Applied Chemistry, University of Toronto, Toronto, ON, Canada\nhDepartment of Materials Science &amp; Engineering, University of Toronto, Toronto, ON, Canada\niLebovic Fellow, Canadian Institute for Advanced Research, Toronto, ON, Canada\nReceived 21st December 2022, Accepted 21st April 2023\nFirst published on 2nd May 2023\n## Abstract\nDeep learning models that leverage large datasets are often the state of the art for modelling molecular properties. When the datasets are smaller (&lt;2000 molecules), it is not clear that deep learning approaches are the right modelling tool. In this work we perform an extensive study of the calibration and generalizability of probabilistic machine learning models on small chemical datasets. Using different molecular representations and models, we analyse the quality of their predictions and uncertainties in a variety of tasks (regression or binary classification) and datasets. We also introduce two simulated experiments that evaluate their performance: (1) Bayesian optimization guided molecular design, (2) inference on out-of-distribution dataviaablated cluster splits. We offer practical insights into model and feature choice for modelling small chemical datasets, a common scenario in new chemical experiments. We have packaged our analysis into the DIONYSUS repository, which is open sourced to aid in reproducibility and extension to new datasets.\n## 1. Introduction\nThe design and discovery of molecular materials routinely enables technologies which have crucial societal consequences. Given a library of compounds, prediction of molecular functionality from its structure enables ranking and selection of promising candidates prior to experimental validation or other screening filters. Therefore, building accurate quantitative structure\u2013activity relationship models (QSAR) is key to accelerated chemical design and efficient experimental decision-making.[1](#cit1)Models that leverage statistical patterns in data are now often the state of the art on such tasks. Specifically, data science and machine learning (ML) have played critical roles in modern science in general,[2](#cit2)enabling the utilization of data at unprecedented scales. Deep learning (DL) models are able to extract statistical patterns in dataset features and give accurate QSAR predictions and classifications.[3](#cit3)When compared to traditionalab initiotechniques, such as density functional theory (DFT), ML models are less computationally demanding, and can learn statistical patterns directly from experimental data. However, the quality of such models is determined by the quality of the original datasets they are trained on, and thus the models are still affected by the cost of accurate data generation.\nTo date, many studies consider molecular property prediction tasks where training data is plentiful.[4,5](#cit4)In real-world molecular design campaigns, particularly in the initial stages, only small molecular datasets (&lt;2000 data points) are available due to the expense (monetary, resource, or labour) associated with the design, synthesis, and characterization of chemicals. In addition to the datasets examined in this work, examples of applications in the low-data regime include design of optoelectronic materials (i.e.organic photovoltaics,[6](#cit6)or photoswitching molecules[7](#cit7)), prediction of biochemical properties (i.e.olfactory response,[8,9](#cit8)or mosquito repellency[10](#cit10)), and drug discovery.[11,12](#cit11)Despite the practical importance of this regime, molecular property prediction using ML with limited data instances has been relatively under-explored, and remains a challenging task, especially for deep learning models which often require large amounts of training instances due to large number of model parameters.\nIn the low-data setting, understanding a ML model's performance is important since predictions inform decisions about further research directions, or, in a sequential learning setting, promote molecules to be subject to property measurement. In particular, we place emphasis on (1) the generalizability, the ability of a model to predict accurately on new chemical data, and (2) uncertainty calibration, the ability of a model to estimate the confidence of its predictions ([Fig. 1](#imgfig1)).\n[![image file: d2dd00146b-f1.tif](/image/article/2023/DD/d2dd00146b/d2dd00146b-f1.gif)](/image/article/2023/DD/d2dd00146b/d2dd00146b-f1_hi-res.gif)|\n|**Fig. 1**Schematic of the evaluation of probabilistic model on small molecular datasets with DIONYSUS. We study the performance and calibration of probabilistic models with different molecular representations when applied to small molecular datasets. The models are then evaluated on their performance in a simulated optimization campaign and their ability to generalize to out-of-distribution molecules.||\nAdequate generalizability, the ability for a model to make accurate predictions on out-of-distribution (OOD) data, is paramount for many learning tasks, such as in the hit-to-lead and early lead optimization phases of drug discovery.[12,13](#cit12)After identification of a biological target (usually a protein or nucleic acid), initial molecular hits are optimized in an expensive and time-consuming make-design-test cycle. Using ML to predict molecular properties has indeed been shown to reduce the number of syntheses and measurements required.[14\u201316](#cit14)Commonly, drug discovery project permit the synthesis and measurement of hundreds of candidate molecules due to constraints in expense, and typically involve functionalizations of a common molecular core or scaffold. Model generalization is therefore critical for the reuse of QSAR models for unstudied molecular scaffolds.[17,18](#cit17)\nUncertainty calibration is the ability of a probabilistic model to produce accurate estimates of its confidence, and is also a crucial aspect of the molecular design process and high-risk decision making.[19](#c...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/dd/d2dd00146b"
    },
    {
      "title": "Known Unknowns: Out-of-Distribution Property Prediction in Materials and Molecules",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2502.05970"
    }
  ]
}