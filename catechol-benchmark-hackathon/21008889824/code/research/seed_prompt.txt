## Current Status
- Best CV score: 0.008194 from exp_032 (GP 0.15 + MLP 0.55 + LGBM 0.30)
- Best LB score: 0.0877 from exp_030
- CV-LB relationship: LB = 4.21 × CV + 0.0535 (R² = 0.98)
- **CRITICAL**: Intercept (0.0535) > Target (0.0347) - even with CV=0, predicted LB would be 0.0535
- Target: 0.0347 (requires 60.4% improvement from best LB)
- Remaining submissions: 5

## Response to Evaluator

**Technical verdict**: TRUSTWORTHY - Experiment 065 was correctly executed.

**Evaluator's top priority**: Try physical constraints with mass balance. **DISAGREE** - Analysis shows mass balance does NOT hold in the data (mean sum of yields = 0.7955, not 1.0). 63.1% of samples have |sum - 1| > 0.1. Normalizing to sum=1 would introduce errors.

**Key concerns raised**:
1. All uncertainty-based approaches failed (25-234% worse) - CONFIRMED. Conservative predictions hurt CV.
2. CV-LB relationship has high intercept - CONFIRMED. This is structural.
3. DO NOT submit exp_065 - AGREE. CV 0.010246 would yield LB ~0.096.

**Alternative approaches from evaluator**:
1. Solvent-type-specific models - Already tried (exp_054), 138% worse
2. NN blending with training solvents - Tried in exp_065, 234% worse
3. Ensemble with different CV strategies - Already tried (exp_042), didn't help

## Data Understanding

Reference notebooks:
- `exploration/evolver_loop64_analysis.ipynb` - CV-LB relationship analysis, mass balance analysis
- `exploration/evolver_loop63_analysis.ipynb` - CV-LB intercept analysis

Key patterns:
- 24 solvents in single solvent data, 13 ramps in full data
- Mass balance does NOT hold: mean sum = 0.7955, not 1.0
- Strong correlations: ET(30), SA, alpha correlate with yields
- The LB test set likely contains **completely different solvents** not in training
- This is an **out-of-distribution (OOD) generalization** problem

## Recommended Approaches

### PRIORITY 1: Post-Hoc Calibration with Isotonic Regression

**Hypothesis**: The high CV-LB intercept suggests systematic bias in predictions. Post-hoc calibration might reduce this bias.

**Implementation**:
1. Train the best model (GP+MLP+LGBM)
2. Collect OOF predictions from CV
3. Fit isotonic regression: calibrated_pred = isotonic(raw_pred)
4. Apply calibration to test predictions

**Why this might work**: Isotonic regression can learn a monotonic mapping that corrects systematic bias. If the model consistently over/under-predicts for certain ranges, calibration can fix this.

**Caution**: This might not help if the bias is OOD-specific (different for test solvents).

### PRIORITY 2: Prediction Clipping/Shrinkage

**Hypothesis**: The model might be making extreme predictions for OOD samples. Clipping or shrinking predictions toward the mean might help.

**Implementation**:
```python
# Shrink predictions toward global mean
shrinkage = 0.1  # Try different values
global_mean = train_y.mean()
final_pred = (1 - shrinkage) * model_pred + shrinkage * global_mean
```

**Why this might work**: If the model is overconfident on OOD samples, shrinking toward the mean reduces extreme errors.

### PRIORITY 3: Ensemble with Simpler Models

**Hypothesis**: exp_000 (simple MLP) had the best CV-LB residual (-0.00201). Simpler models might generalize better to OOD data.

**Implementation**:
1. Train a very simple model (e.g., Ridge Regression with Spange features only)
2. Ensemble with the best model (GP+MLP+LGBM)
3. Give more weight to the simpler model

**Why this might work**: Simpler models have less capacity to overfit to training distribution.

### PRIORITY 4: Feature Selection Based on OOD Robustness

**Hypothesis**: Some features might be more robust to distribution shift than others.

**Implementation**:
1. Identify features that correlate strongly with targets across ALL solvents
2. Remove features that only work for specific solvents
3. Retrain with robust features only

**Why this might work**: Features that generalize across all training solvents are more likely to generalize to test solvents.

### PRIORITY 5: Adversarial Training for OOD Robustness

**Hypothesis**: Training with adversarial perturbations might improve OOD robustness.

**Implementation**:
1. Add small random perturbations to features during training
2. Train model to be robust to these perturbations

**Why this might work**: Adversarial training has been shown to improve OOD generalization in some settings.

## What NOT to Try

1. **Mass balance normalization** - Data shows sum ≠ 1 (mean = 0.7955)
2. **Uncertainty-weighted blending** - Already tried (exp_065), made CV 25-234% worse
3. **NN blending** - Already tried (exp_065), made CV 234% worse
4. **Conservative predictions** - All conservative approaches hurt CV
5. **Solvent-type-specific models** - Already tried (exp_054), 138% worse
6. **GroupKFold CV** - Already tried (exp_042), didn't change CV-LB relationship
7. **Aggressive regularization** - Already tried (exp_041), made CV-LB relationship worse
8. **GNN/GAT** - Already tried (exp_051, exp_056), both failed significantly
9. **ChemBERTa** - Already tried (exp_052), 137-309% worse
10. **TabNet** - Already tried (exp_061), 347% worse
11. **Importance weighting** - Already tried (exp_063), 27% worse
12. **Mixup augmentation** - Already tried (exp_064), 15% worse

## Validation Notes

- Use Leave-One-Solvent-Out CV for single solvent data (24 folds)
- Use Leave-One-Ramp-Out CV for full data (13 folds)
- CV-LB relationship: LB ≈ 4.21 × CV + 0.0535
- The intercept (0.0535) is the key problem - we need approaches that reduce it
- DO NOT submit unless the approach shows fundamentally different behavior

## Key Insight

**The problem is structural, not procedural.** The CV-LB relationship has a high intercept (0.0535 > target 0.0347). This means:
1. Even with perfect CV=0, the expected LB would be 0.0535
2. The current approach CANNOT reach the target by minimizing CV alone
3. We need an approach that CHANGES the CV-LB relationship itself

**The solution must**:
1. Find a fundamentally different way to make predictions
2. Or find a way to calibrate predictions to reduce systematic bias
3. Or accept that the target might not be reachable with the available data

## Remaining Submissions: 5

Use submissions strategically:
- Only submit if the approach shows fundamentally different behavior
- Consider submitting the best CV model (exp_032) to verify the CV-LB relationship
- Save submissions for approaches that might change the CV-LB relationship