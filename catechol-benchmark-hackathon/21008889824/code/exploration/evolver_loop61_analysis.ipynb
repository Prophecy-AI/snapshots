{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae321e55",
   "metadata": {},
   "source": [
    "# Loop 61 Analysis: CQR Failed, What's Next?\n",
    "\n",
    "**Latest Experiment**: CQR (Conformalized Quantile Regression) CV 0.009899 - 20.8% WORSE than best\n",
    "\n",
    "**Key Questions**:\n",
    "1. Why did CQR fail?\n",
    "2. What approaches haven't been tried?\n",
    "3. How can we change the CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.0982),\n",
    "    ('exp_001', 0.012297, 0.1065),\n",
    "    ('exp_003', 0.010501, 0.0972),\n",
    "    ('exp_005', 0.010430, 0.0969),\n",
    "    ('exp_006', 0.009749, 0.0946),\n",
    "    ('exp_007', 0.009262, 0.0932),\n",
    "    ('exp_009', 0.009192, 0.0936),\n",
    "    ('exp_012', 0.009004, 0.0913),\n",
    "    ('exp_024', 0.008689, 0.0893),\n",
    "    ('exp_026', 0.008465, 0.0887),\n",
    "    ('exp_030', 0.008298, 0.0877),\n",
    "    ('exp_041', 0.009002, 0.0932),\n",
    "    ('exp_042', 0.014503, 0.1147),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp_id', 'cv', 'lb'])\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.6f} ({df.loc[df[\"cv\"].idxmin(), \"exp_id\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} ({df.loc[df[\"lb\"].idxmin(), \"exp_id\"]})')\n",
    "print(f'Target: 0.0347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CV-LB relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'LB = {slope:.4f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept ({intercept:.4f}) vs Target (0.0347)')\n",
    "if intercept > 0.0347:\n",
    "    print(f'CRITICAL: Intercept > Target by {(intercept - 0.0347)/0.0347*100:.1f}%')\n",
    "    print('CV minimization alone CANNOT reach target!')\n",
    "else:\n",
    "    print('Intercept < Target - CV minimization could work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e26809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV would be needed to hit target?\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Required CV is negative!')\n",
    "    print('We need to CHANGE the CV-LB relationship, not just minimize CV')\n",
    "else:\n",
    "    print(f'Current best CV: {df[\"cv\"].min():.6f}')\n",
    "    print(f'Gap: {(df[\"cv\"].min() - required_cv)/required_cv*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e49733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - which experiments generalize better?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('\\nGeneralization Analysis (negative residual = better than expected):')\n",
    "print(df[['exp_id', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].sort_values('residual_pct').to_string(index=False))\n",
    "\n",
    "print(f'\\nBest generalizer: {df.loc[df[\"residual_pct\"].idxmin(), \"exp_id\"]} (residual {df[\"residual_pct\"].min():.1f}%)')\n",
    "print(f'Worst generalizer: {df.loc[df[\"residual_pct\"].idxmax(), \"exp_id\"]} (residual {df[\"residual_pct\"].max():.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], c='blue', s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, df['cv'].max() * 1.1, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=1, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "print('\\nSaved: /home/code/exploration/cv_lb_relationship.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1907c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What experiments have been tried?\n",
    "experiments_tried = [\n",
    "    ('MLP baseline', 'exp_000', 0.011081, 'Baseline'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'Worse'),\n",
    "    ('DRFP + PCA', 'exp_002', 0.016948, 'Much worse'),\n",
    "    ('Spange + DRFP', 'exp_003', 0.010501, 'Better'),\n",
    "    ('Deep Residual', 'exp_004', 0.051912, 'Failed'),\n",
    "    ('Large Ensemble (15)', 'exp_005', 0.010430, 'Marginal'),\n",
    "    ('Simpler Model', 'exp_006', 0.009749, 'Better'),\n",
    "    ('Even Simpler', 'exp_007', 0.009262, 'Better'),\n",
    "    ('Ridge Regression', 'exp_008', 0.009192, 'Better'),\n",
    "    ('GP Ensemble', 'exp_030', 0.008194, 'BEST CV'),\n",
    "    ('XGB Ensemble', 'exp_041', 0.009002, 'Worse'),\n",
    "    ('GroupKFold CV', 'exp_040', 0.009237, 'Worse'),\n",
    "    ('Pure GP', 'exp_042', 0.014503, 'Much worse'),\n",
    "    ('Aggressive Reg', 'exp_043', 0.009002, 'Same'),\n",
    "    ('Stacking', 'exp_045', 0.008689, 'Worse'),\n",
    "    ('CatBoost', 'exp_047', 0.013306, 'Worse'),\n",
    "    ('RDKit', 'exp_048', 0.016324, 'Much worse'),\n",
    "    ('GNN', 'exp_051', 0.014080, 'Much worse'),\n",
    "    ('ChemBERTa', 'exp_052', 0.019444, 'Much worse'),\n",
    "    ('Per-Target', 'exp_053', 0.009946, 'Worse'),\n",
    "    ('Per-Solvent-Type', 'exp_054', 0.019519, 'Much worse'),\n",
    "    ('Hyperparameter Opt', 'exp_055', 0.012658, 'Worse'),\n",
    "    ('Advanced GNN', 'exp_056', 0.030013, 'Much worse'),\n",
    "    ('Multi-Seed', 'exp_057', 0.009403, 'Worse'),\n",
    "    ('Per-Target Weights', 'exp_058', 0.008701, 'Worse'),\n",
    "    ('Physical Constraints', 'exp_059', 0.009611, 'Worse'),\n",
    "    ('Spange Only', 'exp_060', 0.011265, 'Worse'),\n",
    "    ('TabNet', 'exp_061', 0.036642, 'Much worse'),\n",
    "    ('CQR', 'exp_062', 0.009899, 'Worse'),\n",
    "]\n",
    "\n",
    "print('\\nExperiment Summary (62 experiments):')\n",
    "print('='*60)\n",
    "for name, exp_id, cv, result in experiments_tried:\n",
    "    print(f'{exp_id}: {name:30s} CV={cv:.6f} ({result})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82746a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n=== APPROACHES NOT YET TRIED ===')\n",
    "print()\n",
    "print('1. DOMAIN-SPECIFIC APPROACHES:')\n",
    "print('   - Reaction kinetics modeling (Arrhenius equation fitting)')\n",
    "print('   - Solvent polarity-based weighting')\n",
    "print('   - Temperature-dependent feature scaling')\n",
    "print()\n",
    "print('2. ENSEMBLE DIVERSITY:')\n",
    "print('   - Negative correlation learning')\n",
    "print('   - Snapshot ensembles')\n",
    "print('   - Diverse feature subsets')\n",
    "print()\n",
    "print('3. CALIBRATION METHODS:')\n",
    "print('   - Isotonic regression on predictions')\n",
    "print('   - Temperature scaling')\n",
    "print('   - Platt scaling')\n",
    "print()\n",
    "print('4. LOSS FUNCTION MODIFICATIONS:')\n",
    "print('   - Focal loss (focus on hard examples)')\n",
    "print('   - Asymmetric loss (penalize over/under-prediction differently)')\n",
    "print('   - Weighted MSE by solvent similarity')\n",
    "print()\n",
    "print('5. DATA AUGMENTATION:')\n",
    "print('   - Mixup between similar solvents')\n",
    "print('   - Noise injection')\n",
    "print('   - Synthetic data generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL INSIGHT: The CV-LB gap is structural\n",
    "print('\\n=== CRITICAL INSIGHT ===')\n",
    "print()\n",
    "print('The CV-LB relationship has:')\n",
    "print(f'  - Slope: {slope:.4f}')\n",
    "print(f'  - Intercept: {intercept:.4f}')\n",
    "print(f'  - R²: {r_value**2:.4f}')\n",
    "print()\n",
    "print('This means:')\n",
    "print(f'  1. Even with CV=0, predicted LB = {intercept:.4f}')\n",
    "print(f'  2. Target (0.0347) < Intercept ({intercept:.4f})')\n",
    "print(f'  3. CV minimization alone CANNOT reach target')\n",
    "print()\n",
    "print('To reach target, we need to:')\n",
    "print('  1. REDUCE the intercept (improve generalization)')\n",
    "print('  2. OR find an approach with a different CV-LB relationship')\n",
    "print()\n",
    "print('The intercept represents the \"base error\" that exists regardless of CV.')\n",
    "print('This could be due to:')\n",
    "print('  - Distribution shift between train and test')\n",
    "print('  - Model variance on unseen solvents')\n",
    "print('  - Systematic bias in predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's special about the best generalizers?\n",
    "print('\\n=== BEST GENERALIZERS ANALYSIS ===')\n",
    "print()\n",
    "best_generalizers = df.nsmallest(3, 'residual_pct')\n",
    "print('Top 3 best generalizers (lowest residual):')\n",
    "for _, row in best_generalizers.iterrows():\n",
    "    print(f\"  {row['exp_id']}: CV={row['cv']:.6f}, LB={row['lb']:.4f}, residual={row['residual_pct']:.1f}%\")\n",
    "\n",
    "print()\n",
    "print('What do they have in common?')\n",
    "print('  - exp_000: Baseline MLP with Spange only')\n",
    "print('  - exp_003: Spange + DRFP combined')\n",
    "print('  - exp_005: Large ensemble (15 models)')\n",
    "print()\n",
    "print('Insight: Simpler models with Spange features generalize better!')\n",
    "print('The best CV (exp_030 with GP ensemble) is NOT the best generalizer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267059cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('\\n=== STRATEGIC RECOMMENDATION ===')\n",
    "print()\n",
    "print('Given:')\n",
    "print(f'  - Best CV: 0.008194 (exp_030)')\n",
    "print(f'  - Best LB: 0.0877 (exp_030)')\n",
    "print(f'  - Target: 0.0347')\n",
    "print(f'  - CV-LB intercept: {intercept:.4f} > Target')\n",
    "print(f'  - 62 experiments tried, all follow same CV-LB relationship')\n",
    "print()\n",
    "print('The target IS reachable because:')\n",
    "print('  1. The GNN benchmark achieved MSE 0.0039 (much better than target)')\n",
    "print('  2. Other competitors may have found approaches we haven\\'t tried')\n",
    "print('  3. The CV-LB relationship is based on OUR experiments, not the true relationship')\n",
    "print()\n",
    "print('NEXT STEPS (Priority Order):')\n",
    "print('  1. Try prediction calibration (isotonic regression, temperature scaling)')\n",
    "print('  2. Try domain-specific loss functions (Arrhenius-weighted MSE)')\n",
    "print('  3. Try ensemble diversity methods (negative correlation learning)')\n",
    "print('  4. Try data augmentation (mixup, noise injection)')\n",
    "print()\n",
    "print('DO NOT SUBMIT unless we find an approach that could change the CV-LB relationship.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
