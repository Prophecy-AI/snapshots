{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb471972",
   "metadata": {},
   "source": [
    "# Loop 42 LB Feedback Analysis\n",
    "\n",
    "**CRITICAL**: exp_041 (Aggressive Regularization) submission results:\n",
    "- CV: 0.0090\n",
    "- LB: 0.0932\n",
    "- CV-LB ratio: 10.36x\n",
    "\n",
    "**Hypothesis REJECTED**: Aggressive regularization did NOT reduce the CV-LB gap.\n",
    "\n",
    "Now we need to understand what's really happening and find a new path forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d054a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submission data\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'name': 'Baseline MLP'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'name': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'name': 'Spange+DRFP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'name': 'Large Ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'name': 'Simpler Model'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'name': 'Even Simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'name': 'Ridge Regression'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'name': 'Simple Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'name': 'ACS PCA Fixed'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'name': 'Weighted Loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'name': 'GP Ensemble (0.2)'},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932, 'name': 'Aggressive Regularization'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['ratio'] = df['lb'] / df['cv']\n",
    "df['gap'] = df['lb'] - df['cv']\n",
    "\n",
    "print('=== ALL SUBMISSIONS ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nTarget: 0.0347')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} (exp_030)')\n",
    "print(f'Gap to target: {df[\"lb\"].min() / 0.0347:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB relationship\n",
    "from scipy.stats import linregress\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(cv, lb)\n",
    "\n",
    "print('=== CV-LB LINEAR REGRESSION ===')\n",
    "print(f'LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'  - Slope: {slope:.2f} (each 0.001 CV improvement gives {slope*0.001:.4f} LB improvement)')\n",
    "print(f'  - Intercept: {intercept:.4f} (baseline LB when CV=0)')\n",
    "print(f'\\nTo reach target LB=0.0347:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'  - Required CV: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print(f'  - IMPOSSIBLE: Would require negative CV!')\n",
    "    print(f'  - The intercept ({intercept:.4f}) is already above target ({0.0347})')\n",
    "else:\n",
    "    print(f'  - This is {required_cv / df[\"cv\"].min():.2f}x better than best CV ({df[\"cv\"].min():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f409d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB with regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label=f'Target: 0.0347')\n",
    "\n",
    "# Best submission\n",
    "best_idx = df['lb'].idxmin()\n",
    "plt.scatter([df.loc[best_idx, 'cv']], [df.loc[best_idx, 'lb']], \n",
    "            s=200, marker='*', color='gold', edgecolors='black', linewidth=2,\n",
    "            label=f'Best: exp_030 (LB={df.loc[best_idx, \"lb\"]:.4f})')\n",
    "\n",
    "# Aggressive regularization (latest)\n",
    "latest = df[df['exp'] == 'exp_041'].iloc[0]\n",
    "plt.scatter([latest['cv']], [latest['lb']], \n",
    "            s=200, marker='X', color='red', edgecolors='black', linewidth=2,\n",
    "            label=f'Aggressive Reg: exp_041 (LB={latest[\"lb\"]:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)', fontsize=12)\n",
    "plt.ylabel('LB Score (MSE)', fontsize=12)\n",
    "plt.title('CV vs LB Relationship - Aggressive Regularization FAILED', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_analysis_loop42.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print('Aggressive regularization (exp_041) is ON THE SAME LINE as other submissions.')\n",
    "print('This means the CV-LB gap is NOT due to overfitting - it\\'s STRUCTURAL.')\n",
    "print('The gap is likely due to how Kaggle evaluates submissions (different data, different seeds, etc.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the CV-LB ratio for each submission\n",
    "print('=== CV-LB RATIO ANALYSIS ===')\n",
    "df_sorted = df.sort_values('lb')\n",
    "for _, row in df_sorted.iterrows():\n",
    "    print(f\"{row['exp']:8s} | CV: {row['cv']:.4f} | LB: {row['lb']:.4f} | Ratio: {row['ratio']:.2f}x | {row['name']}\")\n",
    "\n",
    "print(f'\\nMean ratio: {df[\"ratio\"].mean():.2f}x')\n",
    "print(f'Std ratio: {df[\"ratio\"].std():.2f}x')\n",
    "print(f'Min ratio: {df[\"ratio\"].min():.2f}x ({df.loc[df[\"ratio\"].idxmin(), \"exp\"]})')\n",
    "print(f'Max ratio: {df[\"ratio\"].max():.2f}x ({df.loc[df[\"ratio\"].idxmax(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b424b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('=== PATH TO TARGET ANALYSIS ===')\n",
    "print(f'\\nTarget: 0.0347')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f}')\n",
    "print(f'Gap: {df[\"lb\"].min() - 0.0347:.4f} ({(df[\"lb\"].min() - 0.0347) / 0.0347 * 100:.1f}% above target)')\n",
    "\n",
    "print('\\n=== OPTION 1: Improve CV (current approach) ===')\n",
    "print(f'Current CV-LB relationship: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "print(f'Intercept ({intercept:.4f}) > Target ({0.0347})')\n",
    "print('IMPOSSIBLE: Even with CV=0, LB would be {:.4f}'.format(intercept))\n",
    "\n",
    "print('\\n=== OPTION 2: Change the CV-LB relationship ===')\n",
    "print('Need to reduce the intercept from {:.4f} to below {:.4f}'.format(intercept, 0.0347))\n",
    "print('This requires a FUNDAMENTALLY DIFFERENT approach:')\n",
    "print('  1. Different model architecture (not just regularization)')\n",
    "print('  2. Different feature engineering')\n",
    "print('  3. Different training procedure')\n",
    "print('  4. Domain adaptation techniques')\n",
    "\n",
    "print('\\n=== OPTION 3: Find what makes Kaggle evaluation different ===')\n",
    "print('The CV-LB gap is consistent (~10x) across ALL submissions.')\n",
    "print('This suggests the gap is due to:')\n",
    "print('  1. Different random seeds in Kaggle evaluation')\n",
    "print('  2. Different data ordering')\n",
    "print('  3. Different train/test split')\n",
    "print('  4. Hidden test data with different distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's special about exp_030 (best LB)\n",
    "print('=== EXP_030 ANALYSIS (BEST LB) ===')\n",
    "print('exp_030: GP Ensemble with GP weight 0.2')\n",
    "print('  - CV: 0.0083')\n",
    "print('  - LB: 0.0877')\n",
    "print('  - Ratio: 10.57x')\n",
    "print('\\nWhat made it special?')\n",
    "print('  - GP weight: 0.2 (vs 0.15 in other experiments)')\n",
    "print('  - GP provides uncertainty estimates')\n",
    "print('  - GP is more robust to distribution shift')\n",
    "print('\\nBut aggressive regularization (exp_041) did NOT improve LB:')\n",
    "print('  - CV: 0.0090 (worse than exp_030)')\n",
    "print('  - LB: 0.0932 (worse than exp_030)')\n",
    "print('  - Ratio: 10.36x (similar to exp_030)')\n",
    "print('\\nConclusion: The CV-LB gap is NOT due to overfitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e415ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('\\n1. PURE GP MODEL (no MLP, no LGBM)')\n",
    "print('   - GP is known to generalize better to unseen data')\n",
    "print('   - exp_032 tried pure GP but was not submitted')\n",
    "print('   - Worth submitting to see if CV-LB relationship changes')\n",
    "\n",
    "print('\\n2. DIFFERENT FEATURE SETS')\n",
    "print('   - Current: Spange + DRFP + ACS PCA + Arrhenius')\n",
    "print('   - Try: Only Spange (simpler, more interpretable)')\n",
    "print('   - Try: Only DRFP (molecular structure)')\n",
    "print('   - Try: Only ACS PCA (chemical properties)')\n",
    "\n",
    "print('\\n3. DIFFERENT ENSEMBLE STRATEGIES')\n",
    "print('   - Current: Weighted average of GP + MLP + LGBM')\n",
    "print('   - Try: Stacking with meta-learner')\n",
    "print('   - Try: Blending with different weights per fold')\n",
    "\n",
    "print('\\n4. DOMAIN ADAPTATION')\n",
    "print('   - Train on single solvents, adapt to mixtures')\n",
    "print('   - Use adversarial training to align distributions')\n",
    "\n",
    "print('\\n5. TRANSFER LEARNING')\n",
    "print('   - Pre-train on related chemical data')\n",
    "print('   - Fine-tune on catechol data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e207f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('=== FINAL RECOMMENDATION ===')\n",
    "print('\\nThe aggressive regularization hypothesis was REJECTED.')\n",
    "print('The CV-LB gap is STRUCTURAL, not due to overfitting.')\n",
    "print('\\nWith 4 submissions remaining, we should:')\n",
    "print('\\n1. SUBMIT exp_032 (Pure GP) to test if GP alone has better CV-LB ratio')\n",
    "print('   - Pure GP might have different CV-LB relationship')\n",
    "print('   - GP is known to generalize better to unseen data')\n",
    "print('\\n2. Try DIFFERENT FEATURE ENGINEERING')\n",
    "print('   - The current features might not capture the right information')\n",
    "print('   - Try domain-specific features (reaction mechanism, transition states)')\n",
    "print('\\n3. Try ENSEMBLE DIVERSITY')\n",
    "print('   - Train models on different feature subsets')\n",
    "print('   - Use stacking instead of simple averaging')\n",
    "print('\\n4. ACCEPT that target might be unreachable with current approach')\n",
    "print('   - The intercept (0.0524) is 1.51x higher than target (0.0347)')\n",
    "print('   - Need a fundamentally different approach')\n",
    "print('\\nBUT WE NEVER GIVE UP! The target IS reachable.')\n",
    "print('We just need to find the RIGHT approach.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
