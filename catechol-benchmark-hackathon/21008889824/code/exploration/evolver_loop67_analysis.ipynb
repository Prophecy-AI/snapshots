{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a549885",
   "metadata": {},
   "source": [
    "# Loop 67 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Problem\n",
    "The CV-LB relationship is: LB = 4.24 × CV + 0.0532 (R² = 0.98)\n",
    "\n",
    "**CRITICAL**: Intercept (0.0532) > Target (0.0347)\n",
    "\n",
    "This means even with CV=0 (impossible), predicted LB would be 0.0532 > target.\n",
    "\n",
    "## Questions to Investigate\n",
    "1. What approaches have been tried that might change the CV-LB relationship?\n",
    "2. Are there any experiments with unusually good CV-LB relationships?\n",
    "3. What fundamentally different approaches remain untried?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11eee28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:37.469950Z",
     "iopub.status.busy": "2026-01-16T07:19:37.469547Z",
     "iopub.status.idle": "2026-01-16T07:19:38.254748Z",
     "shell.execute_reply": "2026-01-16T07:19:38.254314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CV-LB Relationship Analysis ===\n",
      "LB = 4.26 × CV + 0.0530\n",
      "R² = 0.9819\n",
      "Intercept: 0.0530\n",
      "Target: 0.0347\n",
      "Gap: 0.0183\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_041', 0.0090, 0.0932),\n",
    "    ('exp_042', 0.0145, 0.1147),\n",
    "    ('exp_032', 0.0082, 0.0873),\n",
    "]\n",
    "\n",
    "exp_ids = [s[0] for s in submissions]\n",
    "cvs = np.array([s[1] for s in submissions])\n",
    "lbs = np.array([s[2] for s in submissions])\n",
    "\n",
    "print('=== CV-LB Relationship Analysis ===')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cvs, lbs)\n",
    "print(f'LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: {intercept - 0.0347:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b3e006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.256031Z",
     "iopub.status.busy": "2026-01-16T07:19:38.255859Z",
     "iopub.status.idle": "2026-01-16T07:19:38.259837Z",
     "shell.execute_reply": "2026-01-16T07:19:38.259453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Residuals from CV-LB Relationship ===\n",
      "exp_000: CV=0.0111, LB=0.0982, Predicted=0.1003, Residual=-0.0021 ✓ BETTER\n",
      "exp_001: CV=0.0123, LB=0.1065, Predicted=0.1054, Residual=+0.0011 ✗ WORSE\n",
      "exp_003: CV=0.0105, LB=0.0972, Predicted=0.0977, Residual=-0.0005 ~ EXPECTED\n",
      "exp_005: CV=0.0104, LB=0.0969, Predicted=0.0973, Residual=-0.0004 ~ EXPECTED\n",
      "exp_006: CV=0.0097, LB=0.0946, Predicted=0.0943, Residual=+0.0003 ~ EXPECTED\n",
      "exp_007: CV=0.0093, LB=0.0932, Predicted=0.0926, Residual=+0.0006 ~ EXPECTED\n",
      "exp_009: CV=0.0092, LB=0.0936, Predicted=0.0922, Residual=+0.0014 ✗ WORSE\n",
      "exp_012: CV=0.0090, LB=0.0913, Predicted=0.0913, Residual=-0.0000 ~ EXPECTED\n",
      "exp_024: CV=0.0087, LB=0.0893, Predicted=0.0900, Residual=-0.0007 ~ EXPECTED\n",
      "exp_026: CV=0.0085, LB=0.0887, Predicted=0.0892, Residual=-0.0005 ~ EXPECTED\n",
      "exp_030: CV=0.0083, LB=0.0877, Predicted=0.0883, Residual=-0.0006 ~ EXPECTED\n",
      "exp_041: CV=0.0090, LB=0.0932, Predicted=0.0913, Residual=+0.0019 ✗ WORSE\n",
      "exp_042: CV=0.0145, LB=0.1147, Predicted=0.1147, Residual=-0.0000 ~ EXPECTED\n",
      "exp_032: CV=0.0082, LB=0.0873, Predicted=0.0879, Residual=-0.0006 ~ EXPECTED\n",
      "\n",
      "Best residual: exp_000 with -0.0021\n",
      "Worst residual: exp_041 with 0.0019\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals from the CV-LB relationship\n",
    "predicted_lbs = slope * cvs + intercept\n",
    "residuals = lbs - predicted_lbs\n",
    "\n",
    "print('=== Residuals from CV-LB Relationship ===')\n",
    "for exp_id, cv, lb, res in zip(exp_ids, cvs, lbs, residuals):\n",
    "    status = '✓ BETTER' if res < -0.001 else ('✗ WORSE' if res > 0.001 else '~ EXPECTED')\n",
    "    print(f'{exp_id}: CV={cv:.4f}, LB={lb:.4f}, Predicted={slope*cv+intercept:.4f}, Residual={res:+.4f} {status}')\n",
    "\n",
    "print(f'\\nBest residual: {exp_ids[np.argmin(residuals)]} with {residuals.min():.4f}')\n",
    "print(f'Worst residual: {exp_ids[np.argmax(residuals)]} with {residuals.max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4025319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.260814Z",
     "iopub.status.busy": "2026-01-16T07:19:38.260692Z",
     "iopub.status.idle": "2026-01-16T07:19:38.264341Z",
     "shell.execute_reply": "2026-01-16T07:19:38.263903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Required CV to Hit Target ===\n",
      "Target LB: 0.0347\n",
      "Required CV: -0.004286\n",
      "This is IMPOSSIBLE (negative CV)\n",
      "\n",
      "=== What if we could reduce the intercept? ===\n",
      "Intercept=0.04: Required CV = -0.001244\n",
      "Intercept=0.03: Required CV = 0.001103\n",
      "Intercept=0.02: Required CV = 0.003450\n",
      "Intercept=0.01: Required CV = 0.005797\n",
      "Intercept=0.00: Required CV = 0.008144\n"
     ]
    }
   ],
   "source": [
    "# What CV would be needed to hit the target?\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\n=== Required CV to Hit Target ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV: {required_cv:.6f}')\n",
    "print(f'This is IMPOSSIBLE (negative CV)')\n",
    "\n",
    "# What if we could reduce the intercept?\n",
    "print(f'\\n=== What if we could reduce the intercept? ===')\n",
    "for new_intercept in [0.04, 0.03, 0.02, 0.01, 0.0]:\n",
    "    new_required_cv = (target - new_intercept) / slope\n",
    "    print(f'Intercept={new_intercept:.2f}: Required CV = {new_required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8c50cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.270045Z",
     "iopub.status.busy": "2026-01-16T07:19:38.269912Z",
     "iopub.status.idle": "2026-01-16T07:19:38.278245Z",
     "shell.execute_reply": "2026-01-16T07:19:38.277819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Approaches Tried (67 experiments) ===\n",
      "exp_000: MLP with Arrhenius kinetics - CV=0.0111 - Baseline\n",
      "exp_001: LightGBM - CV=0.0123 - Worse than MLP\n",
      "exp_002: DRFP features - CV=0.0169 - Worse\n",
      "exp_003: Combined Spange+DRFP - CV=0.0105 - Better\n",
      "exp_004: Deep Residual MLP - CV=0.0519 - FAILED\n",
      "exp_005: Large Ensemble (15 models) - CV=0.0104 - Marginal improvement\n",
      "exp_006: Simpler Model [64,32] - CV=0.0097 - Better\n",
      "exp_007: Even Simpler [32,16] - CV=0.0093 - Better\n",
      "exp_009: Ridge Regression - CV=0.0092 - Similar\n",
      "exp_030: GP + MLP + LGBM Ensemble - CV=0.0083 - BEST CV\n",
      "exp_031: Higher GP Weight - CV=0.0085 - Similar\n",
      "exp_032: Pure GP - CV=0.0082 - BEST CV\n",
      "exp_041: Aggressive Regularization - CV=0.0090 - Worse LB than expected\n",
      "exp_042: GroupKFold CV - CV=0.0145 - Much worse\n",
      "exp_059: TabNet - CV=0.0366 - FAILED\n",
      "exp_060: CQR - CV=0.0099 - Worse\n",
      "exp_061: Importance Weighting - CV=0.0104 - Worse\n",
      "exp_062: Mixup Augmentation - CV=0.0094 - Similar\n",
      "exp_063: Uncertainty Weighting - CV=0.0102 - Worse\n",
      "exp_064: Isotonic Calibration - CV=0.0094 - Similar\n",
      "exp_065: Multi-Seed Ensemble - CV=0.0096 - Worse\n",
      "exp_066: Per-Target Analysis - CV=0.0093 - Similar\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print('=== Approaches Tried (67 experiments) ===')\n",
    "approaches = [\n",
    "    ('MLP with Arrhenius kinetics', 'exp_000', 0.0111, 'Baseline'),\n",
    "    ('LightGBM', 'exp_001', 0.0123, 'Worse than MLP'),\n",
    "    ('DRFP features', 'exp_002', 0.0169, 'Worse'),\n",
    "    ('Combined Spange+DRFP', 'exp_003', 0.0105, 'Better'),\n",
    "    ('Deep Residual MLP', 'exp_004', 0.0519, 'FAILED'),\n",
    "    ('Large Ensemble (15 models)', 'exp_005', 0.0104, 'Marginal improvement'),\n",
    "    ('Simpler Model [64,32]', 'exp_006', 0.0097, 'Better'),\n",
    "    ('Even Simpler [32,16]', 'exp_007', 0.0093, 'Better'),\n",
    "    ('Ridge Regression', 'exp_009', 0.0092, 'Similar'),\n",
    "    ('GP + MLP + LGBM Ensemble', 'exp_030', 0.0083, 'BEST CV'),\n",
    "    ('Higher GP Weight', 'exp_031', 0.0085, 'Similar'),\n",
    "    ('Pure GP', 'exp_032', 0.0082, 'BEST CV'),\n",
    "    ('Aggressive Regularization', 'exp_041', 0.0090, 'Worse LB than expected'),\n",
    "    ('GroupKFold CV', 'exp_042', 0.0145, 'Much worse'),\n",
    "    ('TabNet', 'exp_059', 0.0366, 'FAILED'),\n",
    "    ('CQR', 'exp_060', 0.0099, 'Worse'),\n",
    "    ('Importance Weighting', 'exp_061', 0.0104, 'Worse'),\n",
    "    ('Mixup Augmentation', 'exp_062', 0.0094, 'Similar'),\n",
    "    ('Uncertainty Weighting', 'exp_063', 0.0102, 'Worse'),\n",
    "    ('Isotonic Calibration', 'exp_064', 0.0094, 'Similar'),\n",
    "    ('Multi-Seed Ensemble', 'exp_065', 0.0096, 'Worse'),\n",
    "    ('Per-Target Analysis', 'exp_066', 0.0093, 'Similar'),\n",
    "]\n",
    "\n",
    "for name, exp_id, cv, result in approaches:\n",
    "    print(f'{exp_id}: {name} - CV={cv:.4f} - {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36b996a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.279264Z",
     "iopub.status.busy": "2026-01-16T07:19:38.279154Z",
     "iopub.status.idle": "2026-01-16T07:19:38.282389Z",
     "shell.execute_reply": "2026-01-16T07:19:38.281997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEY INSIGHT: The Intercept Problem ===\n",
      "\n",
      "The CV-LB relationship has:\n",
      "- Slope: 4.26 (each 0.001 CV improvement → 0.0043 LB improvement)\n",
      "- Intercept: 0.0530 (baseline LB when CV=0)\n",
      "\n",
      "The intercept (0.0530) is HIGHER than the target (0.0347).\n",
      "\n",
      "This means:\n",
      "1. Even with perfect CV=0, the expected LB would be 0.0530\n",
      "2. The current approach CANNOT reach the target by minimizing CV alone\n",
      "3. We need an approach that CHANGES the CV-LB relationship itself\n",
      "\n",
      "What might change the relationship:\n",
      "1. A model that generalizes better to OOD solvents (lower intercept)\n",
      "2. A training strategy that optimizes for OOD performance\n",
      "3. A fundamentally different approach to the problem\n",
      "\n",
      "The intercept represents the \"irreducible\" error when extrapolating to new solvents.\n",
      "To reduce it, we need to either:\n",
      "- Find features that better capture solvent similarity\n",
      "- Use a model that is more conservative on OOD samples\n",
      "- Find a way to leverage the test distribution information\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The intercept problem\n",
    "print('=== KEY INSIGHT: The Intercept Problem ===')\n",
    "print(f'''\n",
    "The CV-LB relationship has:\n",
    "- Slope: {slope:.2f} (each 0.001 CV improvement → {slope*0.001:.4f} LB improvement)\n",
    "- Intercept: {intercept:.4f} (baseline LB when CV=0)\n",
    "\n",
    "The intercept ({intercept:.4f}) is HIGHER than the target ({target}).\n",
    "\n",
    "This means:\n",
    "1. Even with perfect CV=0, the expected LB would be {intercept:.4f}\n",
    "2. The current approach CANNOT reach the target by minimizing CV alone\n",
    "3. We need an approach that CHANGES the CV-LB relationship itself\n",
    "\n",
    "What might change the relationship:\n",
    "1. A model that generalizes better to OOD solvents (lower intercept)\n",
    "2. A training strategy that optimizes for OOD performance\n",
    "3. A fundamentally different approach to the problem\n",
    "\n",
    "The intercept represents the \"irreducible\" error when extrapolating to new solvents.\n",
    "To reduce it, we need to either:\n",
    "- Find features that better capture solvent similarity\n",
    "- Use a model that is more conservative on OOD samples\n",
    "- Find a way to leverage the test distribution information\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2ddd3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.283533Z",
     "iopub.status.busy": "2026-01-16T07:19:38.283427Z",
     "iopub.status.idle": "2026-01-16T07:19:38.286489Z",
     "shell.execute_reply": "2026-01-16T07:19:38.286087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Approaches That Might Change the CV-LB Relationship ===\n",
      "\n",
      "1. PREDICTION SHRINKAGE TOWARD TRAINING MEAN\n",
      "   - For each test sample, compute its \"distance\" from training distribution\n",
      "   - Shrink predictions toward the training mean proportionally to distance\n",
      "   - Rationale: OOD samples should have more conservative predictions\n",
      "   - STATUS: Tried in exp_064 (isotonic calibration) - didn't help\n",
      "\n",
      "2. SIMILARITY-WEIGHTED PREDICTIONS\n",
      "   - For each test solvent, compute similarity to all training solvents\n",
      "   - Weight predictions by similarity to training solvents\n",
      "   - Rationale: Models that work well on similar solvents should be weighted higher\n",
      "   - STATUS: Tried in exp_037, exp_038 - didn't help\n",
      "\n",
      "3. UNCERTAINTY-BASED CONSERVATIVE PREDICTIONS\n",
      "   - Use GP uncertainty estimates\n",
      "   - For high-uncertainty predictions, shrink toward a safe default\n",
      "   - Rationale: When uncertain, be conservative\n",
      "   - STATUS: Tried in exp_063 - didn't help\n",
      "\n",
      "4. BIAS CORRECTION\n",
      "   - The analysis shows positive mean error (over-prediction)\n",
      "   - Apply a simple correction: subtract mean training error from predictions\n",
      "   - STATUS: Not explicitly tried\n",
      "\n",
      "5. DOMAIN ADAPTATION / TRANSFER LEARNING\n",
      "   - Use pre-trained molecular embeddings\n",
      "   - STATUS: Tried ChemBERTa (exp_050) - FAILED\n",
      "\n",
      "6. GRAPH NEURAL NETWORKS\n",
      "   - The benchmark paper achieved CV 0.0039 with GAT + DRFP\n",
      "   - STATUS: Tried simple GNN (exp_049, exp_054) - FAILED (OOM or worse CV)\n",
      "\n",
      "7. ENSEMBLE SELECTION BASED ON OOD PERFORMANCE\n",
      "   - Select models that generalize better, not just those with best CV\n",
      "   - STATUS: Not explicitly tried\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What approaches might change the CV-LB relationship?\n",
    "print('=== Approaches That Might Change the CV-LB Relationship ===')\n",
    "print('''\n",
    "1. PREDICTION SHRINKAGE TOWARD TRAINING MEAN\n",
    "   - For each test sample, compute its \"distance\" from training distribution\n",
    "   - Shrink predictions toward the training mean proportionally to distance\n",
    "   - Rationale: OOD samples should have more conservative predictions\n",
    "   - STATUS: Tried in exp_064 (isotonic calibration) - didn't help\n",
    "\n",
    "2. SIMILARITY-WEIGHTED PREDICTIONS\n",
    "   - For each test solvent, compute similarity to all training solvents\n",
    "   - Weight predictions by similarity to training solvents\n",
    "   - Rationale: Models that work well on similar solvents should be weighted higher\n",
    "   - STATUS: Tried in exp_037, exp_038 - didn't help\n",
    "\n",
    "3. UNCERTAINTY-BASED CONSERVATIVE PREDICTIONS\n",
    "   - Use GP uncertainty estimates\n",
    "   - For high-uncertainty predictions, shrink toward a safe default\n",
    "   - Rationale: When uncertain, be conservative\n",
    "   - STATUS: Tried in exp_063 - didn't help\n",
    "\n",
    "4. BIAS CORRECTION\n",
    "   - The analysis shows positive mean error (over-prediction)\n",
    "   - Apply a simple correction: subtract mean training error from predictions\n",
    "   - STATUS: Not explicitly tried\n",
    "\n",
    "5. DOMAIN ADAPTATION / TRANSFER LEARNING\n",
    "   - Use pre-trained molecular embeddings\n",
    "   - STATUS: Tried ChemBERTa (exp_050) - FAILED\n",
    "\n",
    "6. GRAPH NEURAL NETWORKS\n",
    "   - The benchmark paper achieved CV 0.0039 with GAT + DRFP\n",
    "   - STATUS: Tried simple GNN (exp_049, exp_054) - FAILED (OOM or worse CV)\n",
    "\n",
    "7. ENSEMBLE SELECTION BASED ON OOD PERFORMANCE\n",
    "   - Select models that generalize better, not just those with best CV\n",
    "   - STATUS: Not explicitly tried\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8737357d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T07:19:38.287620Z",
     "iopub.status.busy": "2026-01-16T07:19:38.287515Z",
     "iopub.status.idle": "2026-01-16T07:19:38.290753Z",
     "shell.execute_reply": "2026-01-16T07:19:38.290379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY AND RECOMMENDATIONS ===\n",
      "\n",
      "Current Status:\n",
      "- Best CV: 0.008194 (exp_032)\n",
      "- Best LB: 0.0873 (exp_032)\n",
      "- Target: 0.0347\n",
      "- Gap: 0.0526 (60.2% improvement needed)\n",
      "- Remaining submissions: 4\n",
      "\n",
      "The CV-LB relationship is:\n",
      "- LB = 4.26 × CV + 0.0530\n",
      "- Intercept (0.0530) > Target (0.0347)\n",
      "\n",
      "Key Insight:\n",
      "The intercept problem is the fundamental obstacle. All 67 experiments have followed\n",
      "the same CV-LB relationship. No approach has changed the intercept.\n",
      "\n",
      "Recommended Approaches (in order of priority):\n",
      "\n",
      "1. BIAS CORRECTION (NOT YET TRIED)\n",
      "   - The per-target analysis (exp_066) showed positive mean error (over-prediction)\n",
      "   - Apply a simple correction: subtract mean training error from predictions\n",
      "   - This might reduce the intercept\n",
      "\n",
      "2. SOLVENT-SPECIFIC BIAS CORRECTION\n",
      "   - Compute per-solvent bias on training data\n",
      "   - Apply correction based on similarity to training solvents\n",
      "   - This is a form of \"calibration\" that might help OOD generalization\n",
      "\n",
      "3. CONSERVATIVE PREDICTION FOR DISSIMILAR SOLVENTS\n",
      "   - Compute distance from each test sample to training distribution\n",
      "   - For distant samples, blend predictions with training mean\n",
      "   - This is a form of \"shrinkage\" based on OOD distance\n",
      "\n",
      "4. ENSEMBLE WITH DIFFERENT FEATURE SETS\n",
      "   - Train models with different feature sets (Spange-only, DRFP-only, combined)\n",
      "   - Ensemble by selecting the most conservative prediction for each sample\n",
      "   - Different models might have different failure modes on OOD samples\n",
      "\n",
      "5. SMALLER, MORE REGULARIZED MODELS\n",
      "   - The simpler models (exp_006, exp_007) had better CV\n",
      "   - Try even simpler models with stronger regularization\n",
      "   - Simpler models might generalize better to OOD samples\n",
      "\n",
      "DO NOT TRY:\n",
      "- Multi-seed averaging (exp_065) - made CV worse\n",
      "- Isotonic calibration (exp_064) - didn't help\n",
      "- Prediction shrinkage (uniform) - didn't help\n",
      "- Importance weighting (exp_061) - didn't help\n",
      "- GNN/GAT (exp_049, exp_054) - failed\n",
      "- ChemBERTa (exp_050) - failed\n",
      "- TabNet (exp_059) - failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY AND RECOMMENDATIONS ===')\n",
    "print(f'''\n",
    "Current Status:\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0873 (exp_032)\n",
    "- Target: 0.0347\n",
    "- Gap: {0.0873 - 0.0347:.4f} (60.2% improvement needed)\n",
    "- Remaining submissions: 4\n",
    "\n",
    "The CV-LB relationship is:\n",
    "- LB = {slope:.2f} × CV + {intercept:.4f}\n",
    "- Intercept ({intercept:.4f}) > Target (0.0347)\n",
    "\n",
    "Key Insight:\n",
    "The intercept problem is the fundamental obstacle. All 67 experiments have followed\n",
    "the same CV-LB relationship. No approach has changed the intercept.\n",
    "\n",
    "Recommended Approaches (in order of priority):\n",
    "\n",
    "1. BIAS CORRECTION (NOT YET TRIED)\n",
    "   - The per-target analysis (exp_066) showed positive mean error (over-prediction)\n",
    "   - Apply a simple correction: subtract mean training error from predictions\n",
    "   - This might reduce the intercept\n",
    "\n",
    "2. SOLVENT-SPECIFIC BIAS CORRECTION\n",
    "   - Compute per-solvent bias on training data\n",
    "   - Apply correction based on similarity to training solvents\n",
    "   - This is a form of \"calibration\" that might help OOD generalization\n",
    "\n",
    "3. CONSERVATIVE PREDICTION FOR DISSIMILAR SOLVENTS\n",
    "   - Compute distance from each test sample to training distribution\n",
    "   - For distant samples, blend predictions with training mean\n",
    "   - This is a form of \"shrinkage\" based on OOD distance\n",
    "\n",
    "4. ENSEMBLE WITH DIFFERENT FEATURE SETS\n",
    "   - Train models with different feature sets (Spange-only, DRFP-only, combined)\n",
    "   - Ensemble by selecting the most conservative prediction for each sample\n",
    "   - Different models might have different failure modes on OOD samples\n",
    "\n",
    "5. SMALLER, MORE REGULARIZED MODELS\n",
    "   - The simpler models (exp_006, exp_007) had better CV\n",
    "   - Try even simpler models with stronger regularization\n",
    "   - Simpler models might generalize better to OOD samples\n",
    "\n",
    "DO NOT TRY:\n",
    "- Multi-seed averaging (exp_065) - made CV worse\n",
    "- Isotonic calibration (exp_064) - didn't help\n",
    "- Prediction shrinkage (uniform) - didn't help\n",
    "- Importance weighting (exp_061) - didn't help\n",
    "- GNN/GAT (exp_049, exp_054) - failed\n",
    "- ChemBERTa (exp_050) - failed\n",
    "- TabNet (exp_059) - failed\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('=== FINAL RECOMMENDATION ===')\n",
    "print('''\n",
    "The target (0.0347) IS reachable. The solution exists.\n",
    "\n",
    "The key insight is that the CV-LB relationship has an intercept (0.0532) that exceeds\n",
    "the target (0.0347). This means we need an approach that CHANGES the relationship,\n",
    "not just minimizes CV.\n",
    "\n",
    "The most promising unexplored approach is BIAS CORRECTION:\n",
    "1. The per-target analysis showed positive mean error (over-prediction)\n",
    "2. Apply a simple correction: subtract mean training error from predictions\n",
    "3. This might reduce the intercept in the CV-LB relationship\n",
    "\n",
    "Alternatively, try SOLVENT-SPECIFIC BIAS CORRECTION:\n",
    "1. Compute per-solvent bias on training data\n",
    "2. Apply correction based on similarity to training solvents\n",
    "3. This is a form of \"calibration\" that might help OOD generalization\n",
    "\n",
    "With 4 submissions remaining, we should:\n",
    "1. Try bias correction approaches\n",
    "2. Submit if CV improves significantly\n",
    "3. Focus on approaches that might change the CV-LB relationship\n",
    "\n",
    "DO NOT GIVE UP. The target IS reachable.\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
