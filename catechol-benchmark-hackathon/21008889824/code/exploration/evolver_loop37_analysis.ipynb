{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5acd8f3",
   "metadata": {},
   "source": [
    "# Loop 37 Analysis: Diagnosing the CV-LB Gap\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.27×CV + 0.0527 (R²=0.967)\n",
    "\n",
    "**Key Problem:** The intercept (0.0527) is 1.52x higher than the target (0.0347). Even with CV=0, the predicted LB would be 0.0527.\n",
    "\n",
    "**This analysis will:**\n",
    "1. Examine the CV-LB relationship in detail\n",
    "2. Identify what's causing the intercept\n",
    "3. Explore approaches that could reduce the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions data\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'cv': 0.010430, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.08875},\n",
    "    {'exp': 'exp_030', 'cv': 0.008298, 'lb': 0.08772},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdeadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'  LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'  R² = {r_value**2:.4f}')\n",
    "print(f'  Intercept = {intercept:.4f}')\n",
    "print(f'  Target = 0.0347')\n",
    "print(f'  Intercept / Target = {intercept / 0.0347:.2f}x')\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "cv_needed = (0.0347 - intercept) / slope\n",
    "print(f'\\nTo reach target LB = 0.0347:')\n",
    "print(f'  CV needed = {cv_needed:.6f}')\n",
    "if cv_needed < 0:\n",
    "    print(f'  IMPOSSIBLE with current approach (would need negative CV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Intercept point\n",
    "plt.scatter([0], [intercept], s=150, c='red', marker='x', label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV-LB Relationship: The Intercept Problem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/home/code/exploration/loop37_cv_lb.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nKey Insight: The intercept ({intercept:.4f}) is {intercept/0.0347:.1f}x higher than the target.')\n",
    "print(f'Even with perfect CV=0, the LB would still be {intercept:.4f}, which is above the target.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a743bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's causing the intercept\n",
    "# The intercept represents the \"base error\" that doesn't depend on CV\n",
    "# This is likely due to:\n",
    "# 1. Distribution shift between train and test solvents\n",
    "# 2. Systematic overfitting to training solvents\n",
    "# 3. Features that work well on training but not test solvents\n",
    "\n",
    "print('=== Analyzing the Intercept ===')\n",
    "print()\n",
    "print('The intercept (0.0527) represents the \"base error\" that persists regardless of CV.')\n",
    "print('This is likely caused by:')\n",
    "print('  1. Distribution shift between train and test solvents')\n",
    "print('  2. Systematic overfitting to training solvents')\n",
    "print('  3. Features that work well on training but not test solvents')\n",
    "print()\n",
    "print('To reduce the intercept, we need approaches that:')\n",
    "print('  - Generalize better to unseen solvents')\n",
    "print('  - Are less sensitive to solvent-specific patterns')\n",
    "print('  - Use more robust features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25393a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "approaches = [\n",
    "    ('exp_000', 'MLP baseline', 0.011081, 0.09816),\n",
    "    ('exp_001', 'LightGBM', 0.012297, 0.10649),\n",
    "    ('exp_003', 'Combined features', 0.010501, 0.09719),\n",
    "    ('exp_006', 'Simpler MLP [64,32]', 0.009749, 0.09457),\n",
    "    ('exp_007', 'Even simpler [32,16]', 0.009262, 0.09316),\n",
    "    ('exp_012', 'Simple ensemble', 0.009004, 0.09134),\n",
    "    ('exp_024', 'ACS PCA features', 0.008689, 0.08929),\n",
    "    ('exp_026', 'Weighted loss', 0.008465, 0.08875),\n",
    "    ('exp_030', 'GP+MLP+LGBM', 0.008298, 0.08772),\n",
    "]\n",
    "\n",
    "print('=== Approaches Tried ===')\n",
    "for exp, name, cv, lb in approaches:\n",
    "    lb_pred = slope * cv + intercept\n",
    "    residual = lb - lb_pred\n",
    "    print(f'{exp}: {name}')\n",
    "    print(f'  CV={cv:.6f}, LB={lb:.5f}, Predicted={lb_pred:.5f}, Residual={residual:+.5f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals to see if any approach beats the linear relationship\n",
    "df['lb_pred'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['lb_pred']\n",
    "\n",
    "print('=== Residual Analysis ===')\n",
    "print('Positive residual = worse than expected')\n",
    "print('Negative residual = better than expected')\n",
    "print()\n",
    "print(df[['exp', 'cv', 'lb', 'lb_pred', 'residual']].sort_values('residual'))\n",
    "\n",
    "print(f'\\nBest residual: {df[\"residual\"].min():.5f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')\n",
    "print(f'Worst residual: {df[\"residual\"].max():.5f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')\n",
    "print(f'Mean residual: {df[\"residual\"].mean():.5f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== Unexplored Approaches ===')\n",
    "print()\n",
    "print('1. k-Nearest Neighbors (k-NN)')\n",
    "print('   - Completely different inductive bias')\n",
    "print('   - Predicts based on similar solvents in feature space')\n",
    "print('   - May generalize differently to unseen solvents')\n",
    "print()\n",
    "print('2. Kernel Ridge Regression with RBF kernel')\n",
    "print('   - Non-parametric, kernel-based approach')\n",
    "print('   - Similar to GP but without uncertainty')\n",
    "print('   - May capture non-linear relationships better')\n",
    "print()\n",
    "print('3. Solvent Clustering + Per-Cluster Models')\n",
    "print('   - Group solvents by similarity')\n",
    "print('   - Train separate models per cluster')\n",
    "print('   - Reduces distribution shift within each cluster')\n",
    "print()\n",
    "print('4. Adversarial Validation')\n",
    "print('   - Identify features that distinguish train vs test solvents')\n",
    "print('   - Remove or down-weight those features')\n",
    "print('   - May reduce the distribution shift')\n",
    "print()\n",
    "print('5. Meta-Learning / MAML')\n",
    "print('   - Learn to adapt quickly to new solvents')\n",
    "print('   - May generalize better to unseen solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The feature selection experiment (exp_036) was 16.83% worse in CV\n",
    "# but we don't know if it would be better on LB\n",
    "# The hypothesis was that simpler models would have a lower intercept\n",
    "\n",
    "print('=== Feature Selection Experiment (exp_036) ===')\n",
    "print()\n",
    "print('CV: 0.009573 (16.83% worse than best CV 0.008194)')\n",
    "print()\n",
    "print('Predicted LB using current relationship:')\n",
    "lb_pred_036 = slope * 0.009573 + intercept\n",
    "print(f'  LB = {slope:.2f} × 0.009573 + {intercept:.4f} = {lb_pred_036:.5f}')\n",
    "print()\n",
    "print('If the intercept is reduced by feature selection:')\n",
    "for new_intercept in [0.04, 0.03, 0.02]:\n",
    "    new_lb = slope * 0.009573 + new_intercept\n",
    "    print(f'  Intercept={new_intercept:.2f}: LB = {new_lb:.5f}')\n",
    "print()\n",
    "print('Key question: Does feature selection reduce the intercept?')\n",
    "print('This can only be answered by submitting exp_036.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca63cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY ===')\n",
    "print()\n",
    "print('Current State:')\n",
    "print(f'  - Best CV: 0.008194 (exp_032)')\n",
    "print(f'  - Best LB: 0.0877 (exp_030)')\n",
    "print(f'  - Target: 0.0347')\n",
    "print(f'  - Gap: {0.0877/0.0347:.1f}x')\n",
    "print()\n",
    "print('The Problem:')\n",
    "print(f'  - CV-LB relationship: LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "print(f'  - Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'  - Even with CV=0, LB would be {intercept:.4f}')\n",
    "print()\n",
    "print('Recommendations:')\n",
    "print('  1. Submit exp_036 (feature selection) to test if it reduces intercept')\n",
    "print('  2. Try k-NN as a completely different approach')\n",
    "print('  3. Try adversarial validation to identify distribution shift')\n",
    "print('  4. Consider solvent clustering for per-cluster models')\n",
    "print()\n",
    "print('Remaining submissions: 5')\n",
    "print('Each submission is precious - use strategically!')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
