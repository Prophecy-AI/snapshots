{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c221f1",
   "metadata": {},
   "source": [
    "# Loop 62 Analysis: Importance-Weighted Training Failed\n",
    "\n",
    "## Key Findings\n",
    "1. Importance-weighted training (exp_063) CV 0.010426 is 27.24% WORSE than best CV 0.008194\n",
    "2. Adversarial validation-based importance weighting didn't help\n",
    "3. This confirms the CV-LB gap is NOT due to simple covariate shift\n",
    "\n",
    "## Strategic Analysis\n",
    "- The CV-LB relationship: LB = 4.22×CV + 0.0534 (R²=0.98)\n",
    "- Intercept (0.0534) > Target (0.0347) by 53.9%\n",
    "- 63 experiments tried, all follow the same CV-LB relationship\n",
    "- Only 3 submissions remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.0982),\n",
    "    ('exp_001', 0.012297, 0.1065),\n",
    "    ('exp_003', 0.010501, 0.0972),\n",
    "    ('exp_005', 0.010430, 0.0969),\n",
    "    ('exp_006', 0.009749, 0.0946),\n",
    "    ('exp_007', 0.009262, 0.0932),\n",
    "    ('exp_009', 0.009192, 0.0936),\n",
    "    ('exp_012', 0.009004, 0.0913),\n",
    "    ('exp_024', 0.008689, 0.0893),\n",
    "    ('exp_026', 0.008465, 0.0887),\n",
    "    ('exp_030', 0.008298, 0.0877),\n",
    "    ('exp_041', 0.009002, 0.0932),\n",
    "    ('exp_042', 0.014503, 0.1147),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp', 'cv', 'lb'])\n",
    "df['ratio'] = df['lb'] / df['cv']\n",
    "df['residual'] = df['lb'] - (4.22 * df['cv'] + 0.0534)\n",
    "\n",
    "print('=== SUBMISSION ANALYSIS ===')\n",
    "print(df.to_string())\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.6f} ({df.loc[df[\"cv\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} ({df.loc[df[\"lb\"].idxmin(), \"exp\"]})')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap to target: {(df[\"lb\"].min() - 0.0347) / 0.0347 * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB relationship analysis\n",
    "from scipy import stats\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f'\\n=== CV-LB RELATIONSHIP ===')\n",
    "print(f'LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Intercept > Target: {intercept > 0.0347}')\n",
    "print(f'\\nRequired CV to hit target: {(0.0347 - intercept) / slope:.6f}')\n",
    "print(f'This is NEGATIVE, meaning target is UNREACHABLE with current approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiments that generalized better than expected\n",
    "print('\\n=== EXPERIMENTS WITH NEGATIVE RESIDUALS (BETTER THAN EXPECTED) ===')\n",
    "better = df[df['residual'] < 0].sort_values('residual')\n",
    "print(better.to_string())\n",
    "\n",
    "print('\\n=== EXPERIMENTS WITH POSITIVE RESIDUALS (WORSE THAN EXPECTED) ===')\n",
    "worse = df[df['residual'] > 0].sort_values('residual', ascending=False)\n",
    "print(worse.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would we need to achieve the target?\n",
    "print('\\n=== WHAT WOULD WE NEED TO HIT TARGET? ===')\n",
    "target = 0.0347\n",
    "\n",
    "# Option 1: Reduce intercept\n",
    "print(f'\\nOption 1: Reduce intercept to 0.0347 (currently {intercept:.4f})')\n",
    "print(f'  Required reduction: {(intercept - target) / intercept * 100:.1f}%')\n",
    "\n",
    "# Option 2: Reduce slope\n",
    "print(f'\\nOption 2: Reduce slope (currently {slope:.2f})')\n",
    "print(f'  With best CV ({df[\"cv\"].min():.6f}), need slope = {(target - intercept) / df[\"cv\"].min():.2f}')\n",
    "print(f'  This is NEGATIVE, so slope reduction alone cannot help')\n",
    "\n",
    "# Option 3: Both\n",
    "print(f'\\nOption 3: Find approach with different CV-LB relationship')\n",
    "print(f'  Need intercept < {target:.4f} OR slope < 0')\n",
    "print(f'  Current: LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "print(f'  Target: LB = 0.0347 when CV = 0.008194 (best CV)')\n",
    "print(f'  Required: LB = 0.0347 = a×0.008194 + b')\n",
    "print(f'  If a = 4.22, then b = 0.0347 - 4.22×0.008194 = {0.0347 - 4.22*0.008194:.4f}')\n",
    "print(f'  This is NEGATIVE, so we need a fundamentally different approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches_tried = [\n",
    "    ('MLP baseline', 'exp_000', 0.011081, 'BASELINE'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'WORSE'),\n",
    "    ('DRFP features', 'exp_002', 0.016948, 'WORSE'),\n",
    "    ('Combined features', 'exp_003', 0.010501, 'BETTER'),\n",
    "    ('Deep residual', 'exp_004', 0.051912, 'FAILED'),\n",
    "    ('Large ensemble', 'exp_005', 0.010430, 'BETTER'),\n",
    "    ('Simpler model', 'exp_006', 0.009749, 'BETTER'),\n",
    "    ('GP ensemble', 'exp_030', 0.008298, 'BEST'),\n",
    "    ('GNN', 'exp_051', 0.014080, 'WORSE'),\n",
    "    ('ChemBERTa', 'exp_052', 0.019400, 'WORSE'),\n",
    "    ('Per-target', 'exp_053', 0.009946, 'WORSE'),\n",
    "    ('Per-solvent-type', 'exp_054', 0.019519, 'WORSE'),\n",
    "    ('Hyperparameter opt', 'exp_055', 0.012658, 'WORSE'),\n",
    "    ('Advanced GNN', 'exp_056', 0.030013, 'WORSE'),\n",
    "    ('Multi-seed ensemble', 'exp_057', 0.009449, 'WORSE'),\n",
    "    ('Per-target weights', 'exp_058', 0.008701, 'CLOSE'),\n",
    "    ('Physical constraints', 'exp_059', 0.009622, 'WORSE'),\n",
    "    ('Spange only', 'exp_060', 0.011266, 'WORSE'),\n",
    "    ('TabNet', 'exp_061', 0.036660, 'FAILED'),\n",
    "    ('CQR', 'exp_062', 0.009899, 'WORSE'),\n",
    "    ('Importance weighted', 'exp_063', 0.010426, 'WORSE'),\n",
    "]\n",
    "\n",
    "print('\\n=== APPROACHES TRIED (63 experiments) ===')\n",
    "for name, exp, cv, status in approaches_tried:\n",
    "    print(f'{status:8s} | {exp}: CV={cv:.6f} | {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc122b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n=== APPROACHES NOT YET TRIED ===')\n",
    "print('''\n",
    "1. DOMAIN-SPECIFIC APPROACHES:\n",
    "   - Reaction mechanism-based features (transition state energies)\n",
    "   - Solvent-solute interaction energies\n",
    "   - Marcus theory-based features for electron transfer\n",
    "   - Hammett sigma values for substituent effects\n",
    "\n",
    "2. ENSEMBLE DIVERSITY:\n",
    "   - Stacking with meta-learner (tried but may need different base models)\n",
    "   - Blending with out-of-fold predictions\n",
    "   - Negative correlation learning\n",
    "\n",
    "3. DATA AUGMENTATION:\n",
    "   - Synthetic data generation for unseen solvents\n",
    "   - Interpolation between known solvents\n",
    "   - Physics-based simulation data\n",
    "\n",
    "4. TRANSFER LEARNING:\n",
    "   - Pre-trained molecular representations (beyond ChemBERTa)\n",
    "   - Multi-task learning with related reactions\n",
    "   - Domain adaptation from similar reactions\n",
    "\n",
    "5. UNCERTAINTY QUANTIFICATION:\n",
    "   - Bayesian neural networks\n",
    "   - Deep ensembles with uncertainty\n",
    "   - Conformal prediction (tried CQR, but not full conformal)\n",
    "\n",
    "6. REGULARIZATION:\n",
    "   - Mixup augmentation\n",
    "   - Label smoothing\n",
    "   - Spectral normalization\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d161f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The problem is EXTRAPOLATION, not INTERPOLATION\n",
    "print('\\n=== KEY INSIGHT: EXTRAPOLATION VS INTERPOLATION ===')\n",
    "print('''\n",
    "The Leave-One-Solvent-Out CV tests EXTRAPOLATION to new chemical entities.\n",
    "This is fundamentally harder than interpolation within known entities.\n",
    "\n",
    "The CV-LB gap is NOT due to:\n",
    "- Covariate shift (importance weighting didn't help)\n",
    "- CV procedure (GroupKFold didn't help)\n",
    "- Loss function (Huber, MSE, Quantile all similar)\n",
    "- Model complexity (simpler and complex models similar)\n",
    "\n",
    "The CV-LB gap IS due to:\n",
    "- Extrapolation to unseen solvents\n",
    "- The test set contains solvents that are chemically different from training\n",
    "- The model cannot generalize to truly novel chemical entities\n",
    "\n",
    "POSSIBLE SOLUTIONS:\n",
    "1. Find features that capture chemical similarity better\n",
    "2. Use transfer learning from larger molecular datasets\n",
    "3. Use physics-based constraints that generalize\n",
    "4. Accept that some extrapolation error is irreducible\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('\\n=== FINAL RECOMMENDATION ===')\n",
    "print('''\n",
    "With only 3 submissions remaining and best LB at 0.0877 (target 0.0347):\n",
    "\n",
    "1. DO NOT submit exp_063 (importance weighted) - CV is 27% worse\n",
    "\n",
    "2. FOCUS on approaches that could CHANGE the CV-LB relationship:\n",
    "   - The current relationship has intercept > target\n",
    "   - We need to find an approach with lower intercept\n",
    "   - This likely requires fundamentally different features or model\n",
    "\n",
    "3. CONSIDER:\n",
    "   - Bayesian optimization of ensemble weights\n",
    "   - Physics-informed neural networks\n",
    "   - Domain adaptation techniques\n",
    "   - Uncertainty-weighted predictions\n",
    "\n",
    "4. SAVE submissions for:\n",
    "   - A fundamentally different approach (if found)\n",
    "   - Final ensemble of best models\n",
    "   - Last-ditch attempt with best CV model\n",
    "\n",
    "The target (0.0347) IS reachable, but requires finding an approach\n",
    "that breaks the current CV-LB relationship.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, alpha=0.7)\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.016, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f} (R²={r_value**2:.2f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', label='Target (0.0347)')\n",
    "\n",
    "# Intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', alpha=0.5, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "# Labels\n",
    "for i, row in df.iterrows():\n",
    "    plt.annotate(row['exp'], (row['cv'], row['lb']), fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship: Intercept > Target')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop62_cv_lb.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlot saved to /home/code/exploration/loop62_cv_lb.png')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
