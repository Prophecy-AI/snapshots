{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4998bd",
   "metadata": {},
   "source": [
    "# Loop 47 Analysis: Post-RDKit Failure - What's Next?\n",
    "\n",
    "## Key Findings:\n",
    "1. RDKit descriptors (133 features) performed 62% WORSE than Spange + DRFP + ACS PCA\n",
    "2. CV = 0.013306 vs best CV = 0.008194\n",
    "3. This validates that Spange descriptors are well-suited for this problem\n",
    "\n",
    "## Critical Question:\n",
    "What approach can REDUCE THE INTERCEPT in the CV-LB relationship?\n",
    "- Current: LB = 4.23×CV + 0.0533 (R²=0.981)\n",
    "- Intercept (0.0533) > Target (0.0347)\n",
    "- We need to find an approach with a LOWER intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression to understand CV-LB relationship\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df['cv'].values.reshape(-1, 1)\n",
    "y = df['lb'].values\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "slope = reg.coef_[0]\n",
    "intercept = reg.intercept_\n",
    "r2 = reg.score(X, y)\n",
    "\n",
    "print(f'CV-LB Relationship: LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r2:.4f}')\n",
    "print(f'\\nIntercept ({intercept:.4f}) vs Target (0.0347)')\n",
    "print(f'Gap: {intercept - 0.0347:.4f} ({(intercept - 0.0347)/0.0347*100:.1f}% above target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96513187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.02, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle='-', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship: The Intercept Problem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.02)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.show()\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print(f'Even with CV = 0, the predicted LB would be {intercept:.4f}')\n",
    "print(f'This is {intercept/0.0347:.2f}x the target!')\n",
    "print('We CANNOT reach the target by improving CV alone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's different about the best submissions\n",
    "print('=== Best Submissions Analysis ===')\n",
    "print('\\nBest LB: exp_030 (CV=0.0083, LB=0.0877)')\n",
    "print('Best CV: exp_032 (CV=0.008194, NOT submitted)')\n",
    "print('\\nWorst LB: exp_042 (CV=0.0145, LB=0.1147) - Pure GP')\n",
    "print('\\nKey observations:')\n",
    "print('1. All submissions follow the SAME CV-LB relationship')\n",
    "print('2. Model type does NOT affect the relationship')\n",
    "print('3. Feature type does NOT affect the relationship')\n",
    "print('4. The intercept is STRUCTURAL, not model-dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "target = 0.0347\n",
    "\n",
    "print('=== What Would It Take to Reach the Target? ===')\n",
    "print(f'\\nTarget LB: {target}')\n",
    "print(f'Current intercept: {intercept:.4f}')\n",
    "print(f'Current slope: {slope:.2f}')\n",
    "\n",
    "# Option 1: Reduce intercept to 0.03\n",
    "new_intercept = 0.03\n",
    "required_cv = (target - new_intercept) / slope\n",
    "print(f'\\nOption 1: Reduce intercept to {new_intercept}')\n",
    "print(f'  Required CV: {required_cv:.6f}')\n",
    "print(f'  This is {required_cv/0.008194:.2f}x our best CV')\n",
    "\n",
    "# Option 2: Reduce slope to 2.0\n",
    "new_slope = 2.0\n",
    "required_cv = (target - intercept) / new_slope\n",
    "print(f'\\nOption 2: Reduce slope to {new_slope}')\n",
    "print(f'  Required CV: {required_cv:.6f}')\n",
    "print(f'  This is NEGATIVE! (impossible with current intercept)')\n",
    "\n",
    "# Option 3: Both\n",
    "new_intercept = 0.02\n",
    "new_slope = 2.0\n",
    "required_cv = (target - new_intercept) / new_slope\n",
    "print(f'\\nOption 3: Reduce intercept to {new_intercept} AND slope to {new_slope}')\n",
    "print(f'  Required CV: {required_cv:.6f}')\n",
    "print(f'  This is {required_cv/0.008194:.2f}x our best CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the experiments that haven't been submitted\n",
    "print('=== Unsubmitted Experiments with Good CV ===')\n",
    "print('\\nexp_032: CV 0.008194 (BEST CV, not submitted)')\n",
    "print('  - GP(0.15) + MLP(0.55) + LGBM(0.3) with Spange + DRFP + ACS PCA')\n",
    "print('  - Predicted LB: 4.23 × 0.008194 + 0.0533 = 0.0880')\n",
    "print('  - Similar to best LB (0.0877)')\n",
    "\n",
    "print('\\nexp_048: CV 0.013306 (62% worse, just tested)')\n",
    "print('  - RDKit descriptors instead of Spange')\n",
    "print('  - Predicted LB: 4.23 × 0.013306 + 0.0533 = 0.1096')\n",
    "print('  - Much worse than best LB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== Approaches NOT Yet Tried ===')\n",
    "print('\\n1. VERY SIMPLE LINEAR MODEL (Ridge with high alpha)')\n",
    "print('   - Hypothesis: Simpler model might have lower intercept')\n",
    "print('   - The CV-LB gap might be due to overfitting')\n",
    "print('   - A linear model can\\'t overfit as much')\n",
    "\n",
    "print('\\n2. WATER-SPECIFIC HANDLING')\n",
    "print('   - Water is an extreme outlier (6/13 Spange features out of range)')\n",
    "print('   - If Water-like solvents are in the hidden test, this could explain the gap')\n",
    "print('   - Try training with Water excluded, or with Water-specific handling')\n",
    "\n",
    "print('\\n3. DOMAIN ADAPTATION / TRANSFER LEARNING')\n",
    "print('   - The CV-LB gap suggests distribution shift')\n",
    "print('   - Domain adaptation techniques might help')\n",
    "print('   - But we don\\'t have access to the test distribution')\n",
    "\n",
    "print('\\n4. UNCERTAINTY-AWARE PREDICTIONS')\n",
    "print('   - Be more conservative on novel solvents')\n",
    "print('   - Use GP uncertainty to weight predictions')\n",
    "print('   - Might reduce the intercept')\n",
    "\n",
    "print('\\n5. DIFFERENT CV SCHEME')\n",
    "print('   - GroupKFold(5) was tried but didn\\'t help')\n",
    "print('   - The hidden test might have a different distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic Decision\n",
    "print('=== STRATEGIC DECISION ===')\n",
    "print('\\n3 submissions remaining, target is 0.0347, best LB is 0.0877 (2.53x away)')\n",
    "print('\\nOptions:')\n",
    "print('1. Submit exp_032 (best CV) - confirm CV-LB relationship')\n",
    "print('2. Try VERY SIMPLE LINEAR MODEL (Ridge with high alpha)')\n",
    "print('3. Try UNCERTAINTY-AWARE PREDICTIONS (GP uncertainty weighting)')\n",
    "\n",
    "print('\\n=== RECOMMENDATION ===')\n",
    "print('\\nTry a VERY SIMPLE LINEAR MODEL first:')\n",
    "print('- Ridge Regression with alpha = 10.0 or higher')\n",
    "print('- Use only Spange + Arrhenius kinetics features (18 features)')\n",
    "print('- Per-target models (3 separate Ridge regressors)')\n",
    "print('- TTA for mixtures')\n",
    "print('\\nHypothesis: A simpler model might have a LOWER INTERCEPT')\n",
    "print('because it can\\'t overfit to the training distribution.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
