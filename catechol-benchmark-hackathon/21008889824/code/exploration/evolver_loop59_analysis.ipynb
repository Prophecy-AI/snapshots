{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7655fd22",
   "metadata": {},
   "source": [
    "# Loop 59 Analysis: Understanding the CV-LB Gap and Path Forward\n",
    "\n",
    "## Key Questions:\n",
    "1. Why did Spange-only (exp_058) perform 37.5% worse than best CV?\n",
    "2. What is the true CV-LB relationship?\n",
    "3. What approaches haven't been tried that could reduce the gap?\n",
    "4. What is the path to reaching target 0.0347?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'name': 'Baseline MLP (Spange only)'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'name': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'name': 'Combined Spange+DRFP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'name': 'Large Ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'name': 'Simpler Model'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'name': 'Even Simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'name': 'Ridge Regression'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'name': 'Simple Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'name': 'ACS PCA Fixed'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'name': 'Weighted Loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'name': 'GP Ensemble'},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932, 'name': 'Aggressive Regularization'},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147, 'name': 'GroupKFold CV'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB relationship\n",
    "from scipy import stats\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'- Intercept: {intercept:.4f}')\n",
    "print(f'- Target: 0.0347')\n",
    "print(f'- Gap: {intercept - 0.0347:.4f} ({(intercept - 0.0347)/0.0347*100:.1f}% above target)')\n",
    "print(f'\\nTo reach target 0.0347:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'- Required CV: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print(f'- IMPOSSIBLE: Required CV is negative!')\n",
    "    print(f'- Even with CV=0, predicted LB would be {intercept:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d19ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, max(cv)*1.1, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle='-', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Best CV and LB\n",
    "plt.scatter([0.008194], [slope*0.008194 + intercept], s=200, c='orange', marker='*', label=f'Best CV (0.008194) -> Predicted LB: {slope*0.008194 + intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nBest CV: 0.008194 -> Predicted LB: {slope*0.008194 + intercept:.4f}')\n",
    "print(f'Best LB achieved: 0.0877')\n",
    "print(f'Target: 0.0347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze generalization residuals\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('=== Generalization Residuals ===')\n",
    "print('Negative residual = better generalization than expected')\n",
    "print(df[['exp', 'name', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].sort_values('residual').to_string(index=False))\n",
    "\n",
    "print(f'\\n=== Key Insights ===')\n",
    "best_gen = df.loc[df['residual'].idxmin()]\n",
    "print(f'Best generalization: {best_gen[\"exp\"]} ({best_gen[\"name\"]})')\n",
    "print(f'  - Residual: {best_gen[\"residual\"]:.4f} ({best_gen[\"residual_pct\"]:.1f}%)')\n",
    "print(f'  - CV: {best_gen[\"cv\"]:.4f}, LB: {best_gen[\"lb\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('=== Path to Target 0.0347 ===')\n",
    "print(f'\\nCurrent best LB: 0.0877')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347)/0.0347*100:.1f}% above target)')\n",
    "\n",
    "print(f'\\n=== Options to Reach Target ===')\n",
    "print(f'\\n1. Reduce CV (current approach):')\n",
    "print(f'   - Current best CV: 0.008194')\n",
    "print(f'   - Required CV: {required_cv:.6f} (IMPOSSIBLE - negative)')\n",
    "print(f'   - This approach CANNOT reach target')\n",
    "\n",
    "print(f'\\n2. Reduce intercept (improve generalization):')\n",
    "print(f'   - Current intercept: {intercept:.4f}')\n",
    "print(f'   - Required intercept: < 0.0347 (to have any chance)')\n",
    "print(f'   - Need to reduce intercept by: {intercept - 0.0347:.4f}')\n",
    "\n",
    "print(f'\\n3. Reduce slope (make CV more predictive):')\n",
    "print(f'   - Current slope: {slope:.4f}')\n",
    "print(f'   - If intercept stays same, need slope < 0 (IMPOSSIBLE)')\n",
    "\n",
    "print(f'\\n4. Change the CV-LB relationship fundamentally:')\n",
    "print(f'   - The current relationship is highly predictable (R²={r_value**2:.4f})')\n",
    "print(f'   - Need a fundamentally different approach that breaks this relationship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d164167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the \"mixall\" kernel does differently\n",
    "print('=== Analysis of \"mixall\" Kernel Approach ===')\n",
    "print(f'\\nKey difference: Uses GroupKFold(5) instead of Leave-One-Out')\n",
    "print(f'\\nLeave-One-Out CV:')\n",
    "print(f'  - Single solvent: 24 folds (one per solvent)')\n",
    "print(f'  - Full data: 13 folds (one per ramp)')\n",
    "print(f'  - Total: 37 folds')\n",
    "print(f'\\nGroupKFold(5) CV:')\n",
    "print(f'  - Single solvent: 5 folds')\n",
    "print(f'  - Full data: 5 folds')\n",
    "print(f'  - Total: 10 folds')\n",
    "\n",
    "print(f'\\nImplications:')\n",
    "print(f'  - GroupKFold has MORE training data per fold (80% vs ~96%)')\n",
    "print(f'  - GroupKFold has LARGER test sets per fold')\n",
    "print(f'  - GroupKFold may give HIGHER CV scores but BETTER generalization')\n",
    "print(f'\\nWe tested GroupKFold in exp_042:')\n",
    "print(f'  - CV: 0.0145 (77% worse than best)')\n",
    "print(f'  - LB: 0.1147 (31% worse than best)')\n",
    "print(f'  - This did NOT help!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d079e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== Unexplored Approaches ===')\n",
    "\n",
    "print(f'\\n1. DIFFERENT ENSEMBLE ARCHITECTURES:')\n",
    "print(f'   - Current best: GP(0.15) + MLP(0.55) + LGBM(0.30)')\n",
    "print(f'   - NOT tried: Stacking with neural network meta-learner')\n",
    "print(f'   - NOT tried: Blending with learned weights per sample')\n",
    "\n",
    "print(f'\\n2. DIFFERENT FEATURE ENGINEERING:')\n",
    "print(f'   - Tried: Spange, DRFP, ACS PCA, RDKit, fragprints')\n",
    "print(f'   - NOT tried: Learned embeddings from scratch')\n",
    "print(f'   - NOT tried: Contrastive learning for solvent embeddings')\n",
    "\n",
    "print(f'\\n3. DIFFERENT TRAINING STRATEGIES:')\n",
    "print(f'   - Tried: Standard training, regularization, per-target')\n",
    "print(f'   - NOT tried: Meta-learning (MAML, Reptile)')\n",
    "print(f'   - NOT tried: Domain adaptation techniques')\n",
    "\n",
    "print(f'\\n4. DIFFERENT MODEL ARCHITECTURES:')\n",
    "print(f'   - Tried: MLP, LGBM, XGBoost, CatBoost, GP, GNN, ChemBERTa')\n",
    "print(f'   - NOT tried: Transformer for tabular data')\n",
    "print(f'   - NOT tried: TabNet')\n",
    "\n",
    "print(f'\\n5. POST-PROCESSING:')\n",
    "print(f'   - Tried: Physical constraint normalization')\n",
    "print(f'   - NOT tried: Calibration (Platt scaling, isotonic regression)')\n",
    "print(f'   - NOT tried: Conformal prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical insight: The target IS reachable\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print(f'\\nThe target (0.0347) IS reachable because:')\n",
    "print(f'1. The GNN benchmark achieved MSE 0.0039 (much better than target)')\n",
    "print(f'2. Other competitors may have found approaches we haven\\'t tried')\n",
    "print(f'3. The CV-LB relationship is based on OUR experiments, not the true relationship')\n",
    "\n",
    "print(f'\\nThe problem is NOT that the target is unreachable.')\n",
    "print(f'The problem is that OUR APPROACH has a fundamental limitation.')\n",
    "\n",
    "print(f'\\n=== What We Need ===')\n",
    "print(f'1. A fundamentally different approach that changes the CV-LB relationship')\n",
    "print(f'2. OR a way to significantly reduce the intercept (improve generalization)')\n",
    "print(f'3. OR a completely different model architecture that captures different patterns')\n",
    "\n",
    "print(f'\\n=== Remaining Submissions: 3 ===')\n",
    "print(f'We should NOT submit unless we have a fundamentally different approach.')\n",
    "print(f'The current best (CV 0.008194) would give LB ~0.088, still far from target.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY AND RECOMMENDATIONS ===')\n",
    "\n",
    "print(f'\\n1. CURRENT SITUATION:')\n",
    "print(f'   - Best CV: 0.008194 (exp_030)')\n",
    "print(f'   - Best LB: 0.0877 (exp_030)')\n",
    "print(f'   - Target: 0.0347')\n",
    "print(f'   - Gap: 153% above target')\n",
    "\n",
    "print(f'\\n2. CV-LB RELATIONSHIP:')\n",
    "print(f'   - LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.4f})')\n",
    "print(f'   - Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'   - CANNOT reach target by CV minimization alone')\n",
    "\n",
    "print(f'\\n3. FAILED APPROACHES:')\n",
    "print(f'   - Simpler features (Spange only): 37.5% worse CV')\n",
    "print(f'   - GroupKFold CV: 77% worse CV, 31% worse LB')\n",
    "print(f'   - GNN: 72-266% worse CV')\n",
    "print(f'   - ChemBERTa: 137-309% worse CV')\n",
    "\n",
    "print(f'\\n4. RECOMMENDED NEXT STEPS:')\n",
    "print(f'   a. Try calibration techniques (Platt scaling, isotonic regression)')\n",
    "print(f'   b. Try domain adaptation (adversarial training)')\n",
    "print(f'   c. Try meta-learning (MAML, Reptile)')\n",
    "print(f'   d. Try TabNet or other tabular transformers')\n",
    "print(f'   e. Try learned embeddings with contrastive loss')\n",
    "\n",
    "print(f'\\n5. SUBMISSION STRATEGY:')\n",
    "print(f'   - 3 submissions remaining')\n",
    "print(f'   - DO NOT submit unless fundamentally different approach')\n",
    "print(f'   - Save at least 1 for final attempt')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
