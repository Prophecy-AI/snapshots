{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c3abc3",
   "metadata": {},
   "source": [
    "# Loop 60 Analysis: Post-TabNet Strategy Review\n",
    "\n",
    "**Key Finding**: TabNet failed dramatically (CV 0.036642 vs best 0.008194 - 347% worse)\n",
    "\n",
    "**Critical Question**: What approaches can CHANGE the CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645b534a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:40.879840Z",
     "iopub.status.busy": "2026-01-15T21:35:40.879273Z",
     "iopub.status.idle": "2026-01-15T21:35:41.611528Z",
     "shell.execute_reply": "2026-01-15T21:35:41.611124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "        exp      cv      lb\n",
      "0   exp_000  0.0111  0.0982\n",
      "1   exp_001  0.0123  0.1065\n",
      "2   exp_003  0.0105  0.0972\n",
      "3   exp_005  0.0104  0.0969\n",
      "4   exp_006  0.0097  0.0946\n",
      "5   exp_007  0.0093  0.0932\n",
      "6   exp_009  0.0092  0.0936\n",
      "7   exp_012  0.0090  0.0913\n",
      "8   exp_024  0.0087  0.0893\n",
      "9   exp_026  0.0085  0.0887\n",
      "10  exp_030  0.0083  0.0877\n",
      "11  exp_041  0.0090  0.0932\n",
      "12  exp_042  0.0145  0.1147\n",
      "\n",
      "Best CV: 0.0083 (exp_030)\n",
      "Best LB: 0.0877 (exp_030)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string())\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.4f} ({df.loc[df[\"cv\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} ({df.loc[df[\"lb\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59d4ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.612653Z",
     "iopub.status.busy": "2026-01-15T21:35:41.612484Z",
     "iopub.status.idle": "2026-01-15T21:35:41.616888Z",
     "shell.execute_reply": "2026-01-15T21:35:41.616558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Relationship: LB = 4.23×CV + 0.0533\n",
      "R² = 0.9807\n",
      "\n",
      "Target LB: 0.0347\n",
      "Intercept: 0.0533\n",
      "Gap: Intercept - Target = 0.0186\n",
      "\n",
      "Required CV to hit target: -0.004396\n",
      "IMPOSSIBLE: Required CV is negative!\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV-LB relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'CV-LB Relationship: LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nTarget LB: 0.0347')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'Gap: Intercept - Target = {intercept - 0.0347:.4f}')\n",
    "\n",
    "# Required CV to hit target\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Required CV is negative!')\n",
    "else:\n",
    "    print(f'Required CV improvement: {(df[\"cv\"].min() - required_cv) / df[\"cv\"].min() * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddeec0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.617801Z",
     "iopub.status.busy": "2026-01-15T21:35:41.617712Z",
     "iopub.status.idle": "2026-01-15T21:35:41.624382Z",
     "shell.execute_reply": "2026-01-15T21:35:41.624037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Analysis (negative = better than predicted):\n",
      "        exp      cv      lb  predicted_lb  residual  residual_pct\n",
      "0   exp_000  0.0111  0.0982      0.100269 -0.002069     -2.062964\n",
      "8   exp_024  0.0087  0.0893      0.090114 -0.000814     -0.902889\n",
      "10  exp_030  0.0083  0.0877      0.088421 -0.000721     -0.815582\n",
      "9   exp_026  0.0085  0.0887      0.089267 -0.000567     -0.635603\n",
      "2   exp_003  0.0105  0.0972      0.097730 -0.000530     -0.542091\n",
      "3   exp_005  0.0104  0.0969      0.097307 -0.000407     -0.417920\n",
      "7   exp_012  0.0090  0.0913      0.091383 -0.000083     -0.090811\n",
      "12  exp_042  0.0145  0.1147      0.114655  0.000045      0.039615\n",
      "4   exp_006  0.0097  0.0946      0.094345  0.000255      0.270471\n",
      "5   exp_007  0.0093  0.0932      0.092652  0.000548      0.591085\n",
      "1   exp_001  0.0123  0.1065      0.105346  0.001154      1.095494\n",
      "6   exp_009  0.0092  0.0936      0.092229  0.001371      1.486269\n",
      "11  exp_041  0.0090  0.0932      0.091383  0.001817      1.988351\n",
      "\n",
      "Best generalization (lowest residual): exp_000\n",
      "Worst generalization (highest residual): exp_041\n"
     ]
    }
   ],
   "source": [
    "# Analyze residuals from CV-LB relationship\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('Residual Analysis (negative = better than predicted):')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].sort_values('residual').to_string())\n",
    "\n",
    "print(f'\\nBest generalization (lowest residual): {df.loc[df[\"residual\"].idxmin(), \"exp\"]}')\n",
    "print(f'Worst generalization (highest residual): {df.loc[df[\"residual\"].idxmax(), \"exp\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5933b3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.625186Z",
     "iopub.status.busy": "2026-01-15T21:35:41.625097Z",
     "iopub.status.idle": "2026-01-15T21:35:41.628652Z",
     "shell.execute_reply": "2026-01-15T21:35:41.628302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRATEGIC ANALYSIS ===\n",
      "\n",
      "Current CV-LB relationship: LB = 4.23×CV + 0.0533\n",
      "Target: 0.0347\n",
      "\n",
      "To reach target, we need ONE of:\n",
      "1. Reduce intercept from 0.0533 to < 0.0347 (35% reduction)\n",
      "2. Reduce slope from 4.23 to < 0 (impossible - would mean better CV = worse LB)\n",
      "3. Find an approach that BREAKS the current CV-LB relationship\n",
      "\n",
      "=== APPROACHES TRIED (60 experiments) ===\n",
      "- MLP variants: exp_000, exp_004, exp_005, exp_006, exp_007, exp_008, exp_010, exp_017\n",
      "- LightGBM: exp_001, exp_002\n",
      "- XGBoost: exp_041\n",
      "- CatBoost: exp_047\n",
      "- GP: exp_030, exp_031, exp_032, exp_044\n",
      "- Ridge: exp_009, exp_033, exp_034, exp_049\n",
      "- KNN: exp_040\n",
      "- GNN: exp_051, exp_056\n",
      "- ChemBERTa: exp_052\n",
      "- TabNet: exp_061\n",
      "- Ensembles: exp_011, exp_012, exp_013, exp_028, exp_030, exp_041, exp_045, exp_050\n",
      "- Feature engineering: exp_003, exp_018, exp_019, exp_023, exp_024, exp_039, exp_044, exp_046, exp_048\n",
      "- Per-target models: exp_025, exp_053\n",
      "- Per-solvent-type models: exp_054\n",
      "- Hyperparameter optimization: exp_055\n",
      "- Physical constraints: exp_059\n",
      "- GroupKFold CV: exp_042\n"
     ]
    }
   ],
   "source": [
    "# What would we need to change the CV-LB relationship?\n",
    "print('=== STRATEGIC ANALYSIS ===')\n",
    "print('\\nCurrent CV-LB relationship: LB = 4.23×CV + 0.0533')\n",
    "print('Target: 0.0347')\n",
    "print('\\nTo reach target, we need ONE of:')\n",
    "print('1. Reduce intercept from 0.0533 to < 0.0347 (35% reduction)')\n",
    "print('2. Reduce slope from 4.23 to < 0 (impossible - would mean better CV = worse LB)')\n",
    "print('3. Find an approach that BREAKS the current CV-LB relationship')\n",
    "\n",
    "print('\\n=== APPROACHES TRIED (60 experiments) ===')\n",
    "approaches_tried = [\n",
    "    ('MLP variants', 'exp_000, exp_004, exp_005, exp_006, exp_007, exp_008, exp_010, exp_017'),\n",
    "    ('LightGBM', 'exp_001, exp_002'),\n",
    "    ('XGBoost', 'exp_041'),\n",
    "    ('CatBoost', 'exp_047'),\n",
    "    ('GP', 'exp_030, exp_031, exp_032, exp_044'),\n",
    "    ('Ridge', 'exp_009, exp_033, exp_034, exp_049'),\n",
    "    ('KNN', 'exp_040'),\n",
    "    ('GNN', 'exp_051, exp_056'),\n",
    "    ('ChemBERTa', 'exp_052'),\n",
    "    ('TabNet', 'exp_061'),\n",
    "    ('Ensembles', 'exp_011, exp_012, exp_013, exp_028, exp_030, exp_041, exp_045, exp_050'),\n",
    "    ('Feature engineering', 'exp_003, exp_018, exp_019, exp_023, exp_024, exp_039, exp_044, exp_046, exp_048'),\n",
    "    ('Per-target models', 'exp_025, exp_053'),\n",
    "    ('Per-solvent-type models', 'exp_054'),\n",
    "    ('Hyperparameter optimization', 'exp_055'),\n",
    "    ('Physical constraints', 'exp_059'),\n",
    "    ('GroupKFold CV', 'exp_042'),\n",
    "]\n",
    "for approach, exps in approaches_tried:\n",
    "    print(f'- {approach}: {exps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e958b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.629468Z",
     "iopub.status.busy": "2026-01-15T21:35:41.629383Z",
     "iopub.status.idle": "2026-01-15T21:35:41.632312Z",
     "shell.execute_reply": "2026-01-15T21:35:41.631969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== APPROACHES NOT YET TRIED ===\n",
      "1. Quantile regression (predict distribution, not point estimate)\n",
      "2. Conformal prediction (uncertainty quantification)\n",
      "3. Domain adaptation (explicitly model train-test shift)\n",
      "4. Adversarial training (make model robust to distribution shift)\n",
      "5. Bayesian neural networks (uncertainty-aware predictions)\n",
      "6. Mixture of experts (different models for different regions)\n",
      "7. Gradient-based meta-learning (MAML for few-shot generalization)\n",
      "8. Self-training / pseudo-labeling (use test predictions to improve)\n",
      "9. Temperature scaling (calibrate predictions)\n",
      "10. Ensemble selection (select best subset of models)\n",
      "\n",
      "=== MOST PROMISING APPROACHES ===\n",
      "1. Quantile regression - could provide better uncertainty estimates\n",
      "2. Temperature scaling - simple calibration method\n",
      "3. Ensemble selection - find optimal subset of diverse models\n",
      "4. Bayesian optimization of ensemble weights - find optimal weights\n"
     ]
    }
   ],
   "source": [
    "# What HASN'T been tried?\n",
    "print('\\n=== APPROACHES NOT YET TRIED ===')\n",
    "print('1. Quantile regression (predict distribution, not point estimate)')\n",
    "print('2. Conformal prediction (uncertainty quantification)')\n",
    "print('3. Domain adaptation (explicitly model train-test shift)')\n",
    "print('4. Adversarial training (make model robust to distribution shift)')\n",
    "print('5. Bayesian neural networks (uncertainty-aware predictions)')\n",
    "print('6. Mixture of experts (different models for different regions)')\n",
    "print('7. Gradient-based meta-learning (MAML for few-shot generalization)')\n",
    "print('8. Self-training / pseudo-labeling (use test predictions to improve)')\n",
    "print('9. Temperature scaling (calibrate predictions)')\n",
    "print('10. Ensemble selection (select best subset of models)')\n",
    "\n",
    "print('\\n=== MOST PROMISING APPROACHES ===')\n",
    "print('1. Quantile regression - could provide better uncertainty estimates')\n",
    "print('2. Temperature scaling - simple calibration method')\n",
    "print('3. Ensemble selection - find optimal subset of diverse models')\n",
    "print('4. Bayesian optimization of ensemble weights - find optimal weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ddebbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.633115Z",
     "iopub.status.busy": "2026-01-15T21:35:41.633029Z",
     "iopub.status.idle": "2026-01-15T21:35:41.635716Z",
     "shell.execute_reply": "2026-01-15T21:35:41.635376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSIS OF BEST MODEL (exp_030) ===\n",
      "Model: GP (0.15) + MLP (0.55) + LGBM (0.30)\n",
      "CV: 0.0083\n",
      "LB: 0.0877\n",
      "LB/CV ratio: 10.57x\n",
      "\n",
      "Key characteristics:\n",
      "- GP provides uncertainty-aware predictions\n",
      "- MLP captures non-linear patterns\n",
      "- LGBM provides tree-based diversity\n",
      "- Weighted ensemble combines strengths\n",
      "\n",
      "=== WHAT COULD IMPROVE IT? ===\n",
      "1. Better ensemble weights (Bayesian optimization)\n",
      "2. More diverse base models\n",
      "3. Stacking with meta-learner\n",
      "4. Post-hoc calibration\n",
      "5. Uncertainty-based weighting\n"
     ]
    }
   ],
   "source": [
    "# Analyze what makes exp_030 the best\n",
    "print('=== ANALYSIS OF BEST MODEL (exp_030) ===')\n",
    "print('Model: GP (0.15) + MLP (0.55) + LGBM (0.30)')\n",
    "print('CV: 0.0083')\n",
    "print('LB: 0.0877')\n",
    "print('LB/CV ratio: 10.57x')\n",
    "print('\\nKey characteristics:')\n",
    "print('- GP provides uncertainty-aware predictions')\n",
    "print('- MLP captures non-linear patterns')\n",
    "print('- LGBM provides tree-based diversity')\n",
    "print('- Weighted ensemble combines strengths')\n",
    "\n",
    "print('\\n=== WHAT COULD IMPROVE IT? ===')\n",
    "print('1. Better ensemble weights (Bayesian optimization)')\n",
    "print('2. More diverse base models')\n",
    "print('3. Stacking with meta-learner')\n",
    "print('4. Post-hoc calibration')\n",
    "print('5. Uncertainty-based weighting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a9bc5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.636588Z",
     "iopub.status.busy": "2026-01-15T21:35:41.636486Z",
     "iopub.status.idle": "2026-01-15T21:35:41.640020Z",
     "shell.execute_reply": "2026-01-15T21:35:41.639648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SENSITIVITY ANALYSIS ===\n",
      "\n",
      "If we could reduce the intercept:\n",
      "Intercept 0.050 -> LB 0.0851 (target: 0.0347)\n",
      "Intercept 0.045 -> LB 0.0801 (target: 0.0347)\n",
      "Intercept 0.040 -> LB 0.0751 (target: 0.0347)\n",
      "Intercept 0.035 -> LB 0.0701 (target: 0.0347)\n",
      "Intercept 0.030 -> LB 0.0651 (target: 0.0347)\n",
      "\n",
      "If we could reduce the slope:\n",
      "Slope 4.0 -> LB 0.0865 (target: 0.0347)\n",
      "Slope 3.5 -> LB 0.0824 (target: 0.0347)\n",
      "Slope 3.0 -> LB 0.0782 (target: 0.0347)\n",
      "Slope 2.5 -> LB 0.0741 (target: 0.0347)\n",
      "Slope 2.0 -> LB 0.0699 (target: 0.0347)\n",
      "\n",
      "To hit target 0.0347 with current best CV (0.0083):\n",
      "Required intercept: -0.0004 (current: 0.0533)\n",
      "Intercept reduction needed: 100.8%\n"
     ]
    }
   ],
   "source": [
    "# Calculate what LB we could achieve with different intercepts\n",
    "print('=== SENSITIVITY ANALYSIS ===')\n",
    "print('\\nIf we could reduce the intercept:')\n",
    "for new_intercept in [0.05, 0.045, 0.04, 0.035, 0.03]:\n",
    "    new_lb = slope * df['cv'].min() + new_intercept\n",
    "    print(f'Intercept {new_intercept:.3f} -> LB {new_lb:.4f} (target: 0.0347)')\n",
    "\n",
    "print('\\nIf we could reduce the slope:')\n",
    "for new_slope in [4.0, 3.5, 3.0, 2.5, 2.0]:\n",
    "    new_lb = new_slope * df['cv'].min() + intercept\n",
    "    print(f'Slope {new_slope:.1f} -> LB {new_lb:.4f} (target: 0.0347)')\n",
    "\n",
    "print('\\nTo hit target 0.0347 with current best CV (0.0083):')\n",
    "required_intercept = 0.0347 - slope * df['cv'].min()\n",
    "print(f'Required intercept: {required_intercept:.4f} (current: {intercept:.4f})')\n",
    "print(f'Intercept reduction needed: {(intercept - required_intercept) / intercept * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b57a96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:35:41.640879Z",
     "iopub.status.busy": "2026-01-15T21:35:41.640672Z",
     "iopub.status.idle": "2026-01-15T21:35:41.643390Z",
     "shell.execute_reply": "2026-01-15T21:35:41.643066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL RECOMMENDATIONS ===\n",
      "\n",
      "1. DO NOT submit TabNet (CV 0.036642 is 347% worse)\n",
      "\n",
      "2. Focus on approaches that could CHANGE the CV-LB relationship:\n",
      "   - Quantile regression (different loss function)\n",
      "   - Temperature scaling (post-hoc calibration)\n",
      "   - Bayesian optimization of ensemble weights\n",
      "\n",
      "3. With only 3 submissions remaining:\n",
      "   - Save at least 1 for final attempt\n",
      "   - Only submit if we find a fundamentally different approach\n",
      "   - The goal is to reduce the intercept, not just minimize CV\n",
      "\n",
      "=== CRITICAL INSIGHT ===\n",
      "The CV-LB relationship has intercept 0.0533 > target 0.0347\n",
      "This means CV minimization alone CANNOT reach the target\n",
      "We need to find an approach that BREAKS this relationship\n"
     ]
    }
   ],
   "source": [
    "# Final recommendations\n",
    "print('=== FINAL RECOMMENDATIONS ===')\n",
    "print('\\n1. DO NOT submit TabNet (CV 0.036642 is 347% worse)')\n",
    "print('\\n2. Focus on approaches that could CHANGE the CV-LB relationship:')\n",
    "print('   - Quantile regression (different loss function)')\n",
    "print('   - Temperature scaling (post-hoc calibration)')\n",
    "print('   - Bayesian optimization of ensemble weights')\n",
    "print('\\n3. With only 3 submissions remaining:')\n",
    "print('   - Save at least 1 for final attempt')\n",
    "print('   - Only submit if we find a fundamentally different approach')\n",
    "print('   - The goal is to reduce the intercept, not just minimize CV')\n",
    "\n",
    "print('\\n=== CRITICAL INSIGHT ===')\n",
    "print('The CV-LB relationship has intercept 0.0533 > target 0.0347')\n",
    "print('This means CV minimization alone CANNOT reach the target')\n",
    "print('We need to find an approach that BREAKS this relationship')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
