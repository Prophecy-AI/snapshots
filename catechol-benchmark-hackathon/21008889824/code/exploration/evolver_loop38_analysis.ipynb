{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47c6c43",
   "metadata": {},
   "source": [
    "# Loop 38 Analysis: k-NN Failed - What Next?\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.27×CV + 0.0527 (R²=0.967)\n",
    "\n",
    "**Latest Experiment (exp_040):**\n",
    "- k-NN with k=5, distance-weighted\n",
    "- CV: 0.026414 (222% WORSE than best)\n",
    "- k-NN is NOT suitable for this problem\n",
    "\n",
    "**Key Insight from Public Kernels:**\n",
    "The 'mixall' kernel uses GroupKFold(5) instead of leave-one-out CV. This might explain the CV-LB gap - the evaluation might use a different CV scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions data\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'cv': 0.010430, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.08875},\n",
    "    {'exp': 'exp_030', 'cv': 0.008298, 'lb': 0.08772},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'  LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'  R² = {r_value**2:.4f}')\n",
    "print(f'  Intercept = {intercept:.4f}')\n",
    "print(f'  Target = 0.0347')\n",
    "print(f'  Intercept / Target = {intercept / 0.0347:.2f}x')\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "cv_needed = (0.0347 - intercept) / slope\n",
    "print(f'\\nTo reach target LB = 0.0347:')\n",
    "print(f'  CV needed = {cv_needed:.6f}')\n",
    "if cv_needed < 0:\n",
    "    print(f'  IMPOSSIBLE with current approach (would need negative CV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2887f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The 'mixall' kernel uses GroupKFold(5) instead of leave-one-out\n",
    "# This might explain the CV-LB gap\n",
    "\n",
    "print('=== KEY INSIGHT FROM PUBLIC KERNELS ===')\n",
    "print()\n",
    "print('The \"mixall\" kernel uses GroupKFold(5) instead of leave-one-out CV.')\n",
    "print('This is a significant change to the validation strategy.')\n",
    "print()\n",
    "print('Possible explanations for CV-LB gap:')\n",
    "print('1. The evaluation uses a different CV procedure than leave-one-out')\n",
    "print('2. There is additional test data not in our training set')\n",
    "print('3. The evaluation uses a different random seed')\n",
    "print()\n",
    "print('If the evaluation uses GroupKFold(5), our leave-one-out CV might be')\n",
    "print('overly pessimistic (more folds = more variance in estimates).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c643827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print('=== APPROACHES TRIED ===')\n",
    "print()\n",
    "approaches = [\n",
    "    ('MLP (baseline)', 'exp_000', 0.011081, 'Works well'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'Slightly worse than MLP'),\n",
    "    ('DRFP + PCA', 'exp_002', 0.016948, 'Much worse'),\n",
    "    ('Spange + DRFP combined', 'exp_003', 0.010501, 'Better than baseline'),\n",
    "    ('Deep Residual MLP', 'exp_004', 0.051912, 'FAILED - too complex'),\n",
    "    ('Large Ensemble (15 models)', 'exp_005', 0.010430, 'Marginal improvement'),\n",
    "    ('Simpler MLP [64, 32]', 'exp_006', 0.009749, 'BETTER - simpler is better'),\n",
    "    ('Even Simpler [32, 16]', 'exp_008', 0.009262, 'BETTER'),\n",
    "    ('Ridge Regression', 'exp_009', 0.009192, 'Comparable to MLP'),\n",
    "    ('MLP + LGBM ensemble', 'exp_012', 0.009004, 'BETTER'),\n",
    "    ('ACS PCA features', 'exp_024', 0.008689, 'BETTER'),\n",
    "    ('Weighted loss', 'exp_026', 0.008465, 'BETTER'),\n",
    "    ('GP + MLP + LGBM', 'exp_030', 0.008298, 'BEST LB'),\n",
    "    ('Higher GP weight', 'exp_031', 0.009174, 'WORSE'),\n",
    "    ('Pure GP', 'exp_032', 0.008194, 'BEST CV'),\n",
    "    ('Feature selection', 'exp_036', 0.009573, 'WORSE'),\n",
    "    ('k-NN', 'exp_040', 0.026414, 'MUCH WORSE'),\n",
    "]\n",
    "\n",
    "for name, exp, cv, result in approaches:\n",
    "    print(f'{exp}: {name}')\n",
    "    print(f'  CV={cv:.6f} - {result}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the best path forward?\n",
    "print('=== STRATEGIC OPTIONS ===')\n",
    "print()\n",
    "print('OPTION 1: Try GroupKFold(5) locally')\n",
    "print('  - If CV scores change significantly, this might explain the CV-LB gap')\n",
    "print('  - Could reveal that our leave-one-out CV is overly pessimistic')\n",
    "print()\n",
    "print('OPTION 2: Submit exp_032 (best CV)')\n",
    "print('  - CV: 0.008194 (best)')\n",
    "print('  - Predicted LB: 4.27 × 0.008194 + 0.0527 = 0.0877')\n",
    "print('  - This is the same as exp_030 LB, so unlikely to improve')\n",
    "print()\n",
    "print('OPTION 3: Try a completely different approach')\n",
    "print('  - Solvent clustering + per-cluster models')\n",
    "print('  - Adversarial validation to identify distribution shift')\n",
    "print('  - Meta-learning / MAML')\n",
    "print()\n",
    "print('OPTION 4: Focus on reducing the intercept')\n",
    "print('  - The intercept (0.0527) is the bottleneck')\n",
    "print('  - Need to find an approach that has a lower intercept')\n",
    "print('  - This requires understanding WHY the intercept exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key question: What causes the intercept?\n",
    "print('=== WHAT CAUSES THE INTERCEPT? ===')\n",
    "print()\n",
    "print('The intercept (0.0527) represents the LB score when CV = 0.')\n",
    "print('This is impossible in practice, but it tells us something important:')\n",
    "print()\n",
    "print('Possible causes:')\n",
    "print('1. Distribution shift between train and test solvents')\n",
    "print('   - The test solvents are fundamentally different from training solvents')\n",
    "print('   - Our models learn patterns that dont generalize')\n",
    "print()\n",
    "print('2. Different CV procedure in evaluation')\n",
    "print('   - If evaluation uses GroupKFold(5), our leave-one-out CV is different')\n",
    "print('   - The intercept might be an artifact of this mismatch')\n",
    "print()\n",
    "print('3. Additional test data not in our training set')\n",
    "print('   - The evaluation might include solvents we havent seen')\n",
    "print('   - Our models cant extrapolate to these new solvents')\n",
    "print()\n",
    "print('4. Overfitting to the training distribution')\n",
    "print('   - Our models are too specialized to the training solvents')\n",
    "print('   - Need more regularization or simpler models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation\n",
    "print('=== RECOMMENDATION ===')\n",
    "print()\n",
    "print('Given the current state:')\n",
    "print('- Best CV: 0.008194 (exp_032)')\n",
    "print('- Best LB: 0.0877 (exp_030)')\n",
    "print('- Target: 0.0347')\n",
    "print('- Gap: 2.53x')\n",
    "print('- Submissions remaining: 5')\n",
    "print()\n",
    "print('The CV-LB relationship is highly linear (R² = 0.967).')\n",
    "print('All approaches follow the same pattern.')\n",
    "print('The intercept (0.0527) > target (0.0347) means we CANNOT reach target')\n",
    "print('with the current approach, no matter how much we improve CV.')\n",
    "print()\n",
    "print('PRIORITY 1: Try GroupKFold(5) locally')\n",
    "print('  - This is a quick experiment that could reveal the CV-LB gap cause')\n",
    "print('  - If CV scores change significantly, we might have found the issue')\n",
    "print()\n",
    "print('PRIORITY 2: Try a fundamentally different approach')\n",
    "print('  - Solvent clustering + per-cluster models')\n",
    "print('  - Domain adaptation techniques')\n",
    "print('  - Meta-learning / MAML')\n",
    "print()\n",
    "print('PRIORITY 3: Submit exp_032 (best CV) to verify CV-LB relationship')\n",
    "print('  - This uses 1 submission but gives us more data points')\n",
    "print('  - Could reveal if the relationship has changed')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
