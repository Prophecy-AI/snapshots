{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f17c3c",
   "metadata": {},
   "source": [
    "# Loop 65 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Problem\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- CV-LB relationship: LB = 4.21 × CV + 0.0535 (R² = 0.98)\n",
    "- **CRITICAL**: Intercept (0.0535) > Target (0.0347)\n",
    "- Target: 0.0347\n",
    "\n",
    "## What This Means\n",
    "Even with CV=0 (impossible), the predicted LB would be 0.0535 > target.\n",
    "The current approach CANNOT reach the target by minimizing CV alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ab2345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:58.555794Z",
     "iopub.status.busy": "2026-01-16T04:40:58.555257Z",
     "iopub.status.idle": "2026-01-16T04:40:59.085899Z",
     "shell.execute_reply": "2026-01-16T04:40:59.085479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "        exp      cv      lb\n",
      "0   exp_000  0.0111  0.0982\n",
      "1   exp_001  0.0123  0.1065\n",
      "2   exp_003  0.0105  0.0972\n",
      "3   exp_005  0.0104  0.0969\n",
      "4   exp_006  0.0097  0.0946\n",
      "5   exp_007  0.0093  0.0932\n",
      "6   exp_009  0.0092  0.0936\n",
      "7   exp_012  0.0090  0.0913\n",
      "8   exp_024  0.0087  0.0893\n",
      "9   exp_026  0.0085  0.0887\n",
      "10  exp_030  0.0083  0.0877\n",
      "11  exp_041  0.0090  0.0932\n",
      "12  exp_042  0.0145  0.1147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e87d845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.087123Z",
     "iopub.status.busy": "2026-01-16T04:40:59.086969Z",
     "iopub.status.idle": "2026-01-16T04:40:59.384787Z",
     "shell.execute_reply": "2026-01-16T04:40:59.384156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV-LB Relationship:\n",
      "LB = 4.23 × CV + 0.0533\n",
      "R² = 0.9807\n",
      "\n",
      "Intercept: 0.0533\n",
      "Target: 0.0347\n",
      "Gap: 0.0186\n"
     ]
    }
   ],
   "source": [
    "# Fit CV-LB relationship\n",
    "from scipy import stats\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: {intercept - 0.0347:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cf780a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.386019Z",
     "iopub.status.busy": "2026-01-16T04:40:59.385860Z",
     "iopub.status.idle": "2026-01-16T04:40:59.388816Z",
     "shell.execute_reply": "2026-01-16T04:40:59.388479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Required CV to hit target: -0.004396\n",
      "IMPOSSIBLE: Required CV is NEGATIVE!\n",
      "The current approach CANNOT reach the target.\n"
     ]
    }
   ],
   "source": [
    "# What CV would we need to hit target?\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Required CV is NEGATIVE!')\n",
    "    print('The current approach CANNOT reach the target.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f28d754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.390187Z",
     "iopub.status.busy": "2026-01-16T04:40:59.389888Z",
     "iopub.status.idle": "2026-01-16T04:40:59.396803Z",
     "shell.execute_reply": "2026-01-16T04:40:59.396475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Residual Analysis (negative = better than expected):\n",
      "        exp      cv      lb  predicted_lb  residual  residual_pct\n",
      "0   exp_000  0.0111  0.0982      0.100269 -0.002069     -2.062964\n",
      "1   exp_001  0.0123  0.1065      0.105346  0.001154      1.095494\n",
      "2   exp_003  0.0105  0.0972      0.097730 -0.000530     -0.542091\n",
      "3   exp_005  0.0104  0.0969      0.097307 -0.000407     -0.417920\n",
      "4   exp_006  0.0097  0.0946      0.094345  0.000255      0.270471\n",
      "5   exp_007  0.0093  0.0932      0.092652  0.000548      0.591085\n",
      "6   exp_009  0.0092  0.0936      0.092229  0.001371      1.486269\n",
      "7   exp_012  0.0090  0.0913      0.091383 -0.000083     -0.090811\n",
      "8   exp_024  0.0087  0.0893      0.090114 -0.000814     -0.902889\n",
      "9   exp_026  0.0085  0.0887      0.089267 -0.000567     -0.635603\n",
      "10  exp_030  0.0083  0.0877      0.088421 -0.000721     -0.815582\n",
      "11  exp_041  0.0090  0.0932      0.091383  0.001817      1.988351\n",
      "12  exp_042  0.0145  0.1147      0.114655  0.000045      0.039615\n",
      "\n",
      "Best residual: -0.0021 (exp_000)\n",
      "Worst residual: 0.0018 (exp_041)\n"
     ]
    }
   ],
   "source": [
    "# Analyze residuals - which submissions beat the trend?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('\\nResidual Analysis (negative = better than expected):')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].to_string())\n",
    "\n",
    "print(f'\\nBest residual: {df[\"residual\"].min():.4f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')\n",
    "print(f'Worst residual: {df[\"residual\"].max():.4f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c00c354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.398066Z",
     "iopub.status.busy": "2026-01-16T04:40:59.397826Z",
     "iopub.status.idle": "2026-01-16T04:40:59.401050Z",
     "shell.execute_reply": "2026-01-16T04:40:59.400702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaches Tried (66 experiments):\n",
      "1. MLP with Spange features\n",
      "2. LightGBM\n",
      "3. DRFP features (PCA)\n",
      "4. Combined Spange + DRFP + ACS PCA\n",
      "5. Deep Residual MLP (FAILED)\n",
      "6. Large Ensemble (15 models)\n",
      "7. Simpler models [64, 32]\n",
      "8. Ridge Regression\n",
      "9. Diverse Ensemble (MLP + LightGBM)\n",
      "10. GP + MLP + LGBM ensemble\n",
      "11. Per-target optimization\n",
      "12. Per-solvent-type models (FAILED)\n",
      "13. GNN/GAT (FAILED)\n",
      "14. ChemBERTa (FAILED)\n",
      "15. TabNet (FAILED)\n",
      "16. Importance weighting\n",
      "17. Mixup augmentation\n",
      "18. Uncertainty weighting\n",
      "19. Isotonic calibration\n",
      "20. Prediction shrinkage\n",
      "21. GroupKFold CV\n",
      "22. Aggressive regularization\n",
      "23. Physical constraints (mass balance)\n",
      "24. Conformalized Quantile Regression\n"
     ]
    }
   ],
   "source": [
    "# What approaches have been tried?\n",
    "approaches_tried = [\n",
    "    'MLP with Spange features',\n",
    "    'LightGBM',\n",
    "    'DRFP features (PCA)',\n",
    "    'Combined Spange + DRFP + ACS PCA',\n",
    "    'Deep Residual MLP (FAILED)',\n",
    "    'Large Ensemble (15 models)',\n",
    "    'Simpler models [64, 32]',\n",
    "    'Ridge Regression',\n",
    "    'Diverse Ensemble (MLP + LightGBM)',\n",
    "    'GP + MLP + LGBM ensemble',\n",
    "    'Per-target optimization',\n",
    "    'Per-solvent-type models (FAILED)',\n",
    "    'GNN/GAT (FAILED)',\n",
    "    'ChemBERTa (FAILED)',\n",
    "    'TabNet (FAILED)',\n",
    "    'Importance weighting',\n",
    "    'Mixup augmentation',\n",
    "    'Uncertainty weighting',\n",
    "    'Isotonic calibration',\n",
    "    'Prediction shrinkage',\n",
    "    'GroupKFold CV',\n",
    "    'Aggressive regularization',\n",
    "    'Physical constraints (mass balance)',\n",
    "    'Conformalized Quantile Regression',\n",
    "]\n",
    "\n",
    "print('Approaches Tried (66 experiments):')\n",
    "for i, approach in enumerate(approaches_tried, 1):\n",
    "    print(f'{i}. {approach}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b0348a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.402227Z",
     "iopub.status.busy": "2026-01-16T04:40:59.401963Z",
     "iopub.status.idle": "2026-01-16T04:40:59.404843Z",
     "shell.execute_reply": "2026-01-16T04:40:59.404498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potentially Untried Approaches:\n",
      "1. Multi-task learning with auxiliary targets (e.g., predict solvent properties)\n",
      "2. Domain adaptation techniques (e.g., DANN)\n",
      "3. Meta-learning (MAML) for few-shot adaptation to new solvents\n",
      "4. Bayesian Neural Networks for uncertainty quantification\n",
      "5. Neural Process for conditional predictions\n",
      "6. Prototype networks for solvent similarity\n",
      "7. Contrastive learning for solvent representations\n",
      "8. Self-supervised pre-training on solvent data\n",
      "9. Transfer learning from related chemistry tasks\n",
      "10. Ensemble of fundamentally different architectures (not just weights)\n"
     ]
    }
   ],
   "source": [
    "# What HASN'T been tried?\n",
    "untried_approaches = [\n",
    "    '1. Multi-task learning with auxiliary targets (e.g., predict solvent properties)',\n",
    "    '2. Domain adaptation techniques (e.g., DANN)',\n",
    "    '3. Meta-learning (MAML) for few-shot adaptation to new solvents',\n",
    "    '4. Bayesian Neural Networks for uncertainty quantification',\n",
    "    '5. Neural Process for conditional predictions',\n",
    "    '6. Prototype networks for solvent similarity',\n",
    "    '7. Contrastive learning for solvent representations',\n",
    "    '8. Self-supervised pre-training on solvent data',\n",
    "    '9. Transfer learning from related chemistry tasks',\n",
    "    '10. Ensemble of fundamentally different architectures (not just weights)',\n",
    "]\n",
    "\n",
    "print('\\nPotentially Untried Approaches:')\n",
    "for approach in untried_approaches:\n",
    "    print(approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b959d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:40:59.406190Z",
     "iopub.status.busy": "2026-01-16T04:40:59.405754Z",
     "iopub.status.idle": "2026-01-16T04:40:59.408832Z",
     "shell.execute_reply": "2026-01-16T04:40:59.408478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KEY INSIGHT ===\n",
      "The CV-LB gap suggests the test solvents are MORE different from training\n",
      "than any single training solvent is from the rest.\n",
      "\n",
      "This is an EXTRAPOLATION problem, not an INTERPOLATION problem.\n",
      "\n",
      "Possible reasons for the gap:\n",
      "1. Test solvents have properties outside the training range\n",
      "2. Test solvents belong to different chemical families\n",
      "3. The model overfits to training solvent patterns\n",
      "\n",
      "What might help:\n",
      "1. Features that generalize better across chemical space\n",
      "2. Models that are more robust to distribution shift\n",
      "3. Regularization that prevents overfitting to training solvents\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The problem is OOD generalization\n",
    "# The test set likely contains solvents NOT in training\n",
    "# Our CV (leave-one-solvent-out) simulates this but the gap suggests\n",
    "# the test solvents are MORE different than any single training solvent\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print('The CV-LB gap suggests the test solvents are MORE different from training')\n",
    "print('than any single training solvent is from the rest.')\n",
    "print('')\n",
    "print('This is an EXTRAPOLATION problem, not an INTERPOLATION problem.')\n",
    "print('')\n",
    "print('Possible reasons for the gap:')\n",
    "print('1. Test solvents have properties outside the training range')\n",
    "print('2. Test solvents belong to different chemical families')\n",
    "print('3. The model overfits to training solvent patterns')\n",
    "print('')\n",
    "print('What might help:')\n",
    "print('1. Features that generalize better across chemical space')\n",
    "print('2. Models that are more robust to distribution shift')\n",
    "print('3. Regularization that prevents overfitting to training solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996685af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on research, what approaches might change the CV-LB relationship?\n",
    "\n",
    "print('=== RESEARCH INSIGHTS ===')\n",
    "print('')\n",
    "print('1. BOOM benchmark (2025): \"No existing model achieves strong OOD generalization\"')\n",
    "print('   - Even top models have 3x higher OOD error than ID error')\n",
    "print('   - This matches our CV-LB gap (4.2x multiplier)')\n",
    "print('')\n",
    "print('2. QMex + ILR (Nature 2024): \"QM descriptors + interaction terms\"')\n",
    "print('   - State-of-the-art extrapolative performance')\n",
    "print('   - We have Spange descriptors (physicochemical) but not QM descriptors')\n",
    "print('')\n",
    "print('3. Meta-learning (Kim 2025): \"Leverage unlabeled data to interpolate ID-OOD\"')\n",
    "print('   - Not applicable - we don\\'t have unlabeled test solvents')\n",
    "print('')\n",
    "print('4. Key insight: \"Cluster-based splitting poses hardest challenge (r~0.4)\"')\n",
    "print('   - Our leave-one-solvent-out is similar to cluster-based splitting')\n",
    "print('   - This explains the weak CV-LB correlation')\n",
    "print('')\n",
    "print('=== WHAT WE HAVEN\\'T TRIED ===')\n",
    "print('')\n",
    "print('1. Interaction terms between features and categorical solvent info')\n",
    "print('2. Ensemble of models trained on different feature subsets')\n",
    "print('3. Stacking with meta-learner that learns from OOF predictions')\n",
    "print('4. Prediction averaging across multiple random seeds (variance reduction)')\n",
    "print('5. Feature engineering based on solvent similarity to training set')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
