{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f17c3c",
   "metadata": {},
   "source": [
    "# Loop 65 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Problem\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- CV-LB relationship: LB = 4.21 × CV + 0.0535 (R² = 0.98)\n",
    "- **CRITICAL**: Intercept (0.0535) > Target (0.0347)\n",
    "- Target: 0.0347\n",
    "\n",
    "## What This Means\n",
    "Even with CV=0 (impossible), the predicted LB would be 0.0535 > target.\n",
    "The current approach CANNOT reach the target by minimizing CV alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CV-LB relationship\n",
    "from scipy import stats\n",
    "\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: {intercept - 0.0347:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV would we need to hit target?\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE: Required CV is NEGATIVE!')\n",
    "    print('The current approach CANNOT reach the target.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - which submissions beat the trend?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('\\nResidual Analysis (negative = better than expected):')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].to_string())\n",
    "\n",
    "print(f'\\nBest residual: {df[\"residual\"].min():.4f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')\n",
    "print(f'Worst residual: {df[\"residual\"].max():.4f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "approaches_tried = [\n",
    "    'MLP with Spange features',\n",
    "    'LightGBM',\n",
    "    'DRFP features (PCA)',\n",
    "    'Combined Spange + DRFP + ACS PCA',\n",
    "    'Deep Residual MLP (FAILED)',\n",
    "    'Large Ensemble (15 models)',\n",
    "    'Simpler models [64, 32]',\n",
    "    'Ridge Regression',\n",
    "    'Diverse Ensemble (MLP + LightGBM)',\n",
    "    'GP + MLP + LGBM ensemble',\n",
    "    'Per-target optimization',\n",
    "    'Per-solvent-type models (FAILED)',\n",
    "    'GNN/GAT (FAILED)',\n",
    "    'ChemBERTa (FAILED)',\n",
    "    'TabNet (FAILED)',\n",
    "    'Importance weighting',\n",
    "    'Mixup augmentation',\n",
    "    'Uncertainty weighting',\n",
    "    'Isotonic calibration',\n",
    "    'Prediction shrinkage',\n",
    "    'GroupKFold CV',\n",
    "    'Aggressive regularization',\n",
    "    'Physical constraints (mass balance)',\n",
    "    'Conformalized Quantile Regression',\n",
    "]\n",
    "\n",
    "print('Approaches Tried (66 experiments):')\n",
    "for i, approach in enumerate(approaches_tried, 1):\n",
    "    print(f'{i}. {approach}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What HASN'T been tried?\n",
    "untried_approaches = [\n",
    "    '1. Multi-task learning with auxiliary targets (e.g., predict solvent properties)',\n",
    "    '2. Domain adaptation techniques (e.g., DANN)',\n",
    "    '3. Meta-learning (MAML) for few-shot adaptation to new solvents',\n",
    "    '4. Bayesian Neural Networks for uncertainty quantification',\n",
    "    '5. Neural Process for conditional predictions',\n",
    "    '6. Prototype networks for solvent similarity',\n",
    "    '7. Contrastive learning for solvent representations',\n",
    "    '8. Self-supervised pre-training on solvent data',\n",
    "    '9. Transfer learning from related chemistry tasks',\n",
    "    '10. Ensemble of fundamentally different architectures (not just weights)',\n",
    "]\n",
    "\n",
    "print('\\nPotentially Untried Approaches:')\n",
    "for approach in untried_approaches:\n",
    "    print(approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b959d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The problem is OOD generalization\n",
    "# The test set likely contains solvents NOT in training\n",
    "# Our CV (leave-one-solvent-out) simulates this but the gap suggests\n",
    "# the test solvents are MORE different than any single training solvent\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print('The CV-LB gap suggests the test solvents are MORE different from training')\n",
    "print('than any single training solvent is from the rest.')\n",
    "print('')\n",
    "print('This is an EXTRAPOLATION problem, not an INTERPOLATION problem.')\n",
    "print('')\n",
    "print('Possible reasons for the gap:')\n",
    "print('1. Test solvents have properties outside the training range')\n",
    "print('2. Test solvents belong to different chemical families')\n",
    "print('3. The model overfits to training solvent patterns')\n",
    "print('')\n",
    "print('What might help:')\n",
    "print('1. Features that generalize better across chemical space')\n",
    "print('2. Models that are more robust to distribution shift')\n",
    "print('3. Regularization that prevents overfitting to training solvents')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
