{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6084e093",
   "metadata": {},
   "source": [
    "# Loop 42 Analysis: Aggressive Regularization Hypothesis Testing\n",
    "\n",
    "## Key Question\n",
    "Should we submit exp_043 (aggressive regularization) to test if the CV-LB gap is due to overfitting?\n",
    "\n",
    "## Current State\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- exp_043 CV: 0.009002 (9.79% worse than best)\n",
    "\n",
    "## Hypothesis\n",
    "If the CV-LB gap is due to overfitting, aggressive regularization should:\n",
    "1. Make CV worse (confirmed: 9.79% worse)\n",
    "2. Make LB better relative to CV (untested - requires submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nCV-LB ratio range: {df[\"lb\"].min()/df[\"cv\"].min():.2f}x to {df[\"lb\"].max()/df[\"cv\"].max():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd716c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear model to CV-LB relationship\n",
    "from scipy import stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'CV-LB Linear Fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Intercept vs Target: {intercept/0.0347:.2f}x')\n",
    "\n",
    "# Predict LB for exp_043\n",
    "exp_043_cv = 0.009002\n",
    "predicted_lb = slope * exp_043_cv + intercept\n",
    "print(f'\\n=== exp_043 Predictions ===')\n",
    "print(f'exp_043 CV: {exp_043_cv:.6f}')\n",
    "print(f'Predicted LB (using old relationship): {predicted_lb:.4f}')\n",
    "print(f'Best LB so far: 0.0877')\n",
    "print(f'\\nIf predicted LB is correct: exp_043 would be WORSE than best LB')\n",
    "print(f'If actual LB is BETTER than predicted: overfitting hypothesis CONFIRMED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', label='Submitted experiments')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0.006, 0.014, 100)\n",
    "lb_fit = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_fit, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Mark exp_043\n",
    "plt.scatter([exp_043_cv], [predicted_lb], s=150, c='orange', marker='*', label=f'exp_043 predicted: ({exp_043_cv:.4f}, {predicted_lb:.4f})')\n",
    "\n",
    "# Mark target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target: 0.0347')\n",
    "\n",
    "# Mark intercept\n",
    "plt.axhline(y=intercept, color='red', linestyle=':', linewidth=1, alpha=0.5, label=f'Intercept: {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop42_cv_lb.png', dpi=100)\n",
    "plt.show()\n",
    "print('\\nPlot saved to loop42_cv_lb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Decision Analysis\n",
    "print('=== DECISION ANALYSIS ===')\n",
    "print()\n",
    "print('OPTION 1: Submit exp_043 (aggressive regularization)')\n",
    "print('  - CV: 0.009002 (9.79% worse than best CV 0.008194)')\n",
    "print(f'  - Predicted LB: {predicted_lb:.4f}')\n",
    "print('  - Purpose: Test if regularization reduces CV-LB gap')\n",
    "print('  - Risk: Uses 1 of 5 remaining submissions')\n",
    "print('  - Reward: If LB < predicted, confirms overfitting hypothesis')\n",
    "print()\n",
    "print('OPTION 2: Continue experimenting without submission')\n",
    "print('  - Try even more aggressive regularization')\n",
    "print('  - Try different model architectures')\n",
    "print('  - Risk: No feedback on whether approach is working')\n",
    "print()\n",
    "print('=== RECOMMENDATION ===')\n",
    "print('The evaluator strongly recommends submitting exp_043.')\n",
    "print('Rationale:')\n",
    "print('  1. We have 5 submissions remaining - can afford to test hypothesis')\n",
    "print('  2. The hypothesis is well-designed and testable')\n",
    "print('  3. Without submission, we cannot validate the approach')\n",
    "print('  4. If hypothesis is confirmed, we know to pursue more regularization')\n",
    "print('  5. If hypothesis is rejected, we know to try different approaches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9478437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would confirm/reject the hypothesis?\n",
    "print('=== HYPOTHESIS TESTING CRITERIA ===')\n",
    "print()\n",
    "print('HYPOTHESIS: Aggressive regularization reduces CV-LB gap')\n",
    "print()\n",
    "print('CONFIRMATION (LB better than predicted):')\n",
    "print(f'  - If actual LB < {predicted_lb:.4f}, the gap is reduced')\n",
    "print(f'  - If actual LB < 0.0877 (best LB), regularization HELPS')\n",
    "print(f'  - If CV-LB ratio < 10.5x (current best ratio), approach is working')\n",
    "print()\n",
    "print('REJECTION (LB worse than or equal to predicted):')\n",
    "print(f'  - If actual LB >= {predicted_lb:.4f}, the gap is NOT reduced')\n",
    "print(f'  - If actual LB > 0.0877, regularization HURTS')\n",
    "print(f'  - If CV-LB ratio > 10.5x, approach is NOT working')\n",
    "print()\n",
    "print('EXPECTED OUTCOMES:')\n",
    "print('  - Best case: LB = 0.080 (CV-LB ratio = 8.9x) → Pursue more regularization')\n",
    "print('  - Neutral: LB = 0.091 (CV-LB ratio = 10.1x) → Gap is structural, try different approach')\n",
    "print('  - Worst case: LB = 0.100 (CV-LB ratio = 11.1x) → Regularization hurts, revert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991517d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approaches if hypothesis is rejected\n",
    "print('=== ALTERNATIVE APPROACHES (if hypothesis rejected) ===')\n",
    "print()\n",
    "print('1. DOMAIN ADAPTATION')\n",
    "print('   - Train on source domain (training solvents)')\n",
    "print('   - Adapt to target domain (test solvents)')\n",
    "print('   - Use adversarial training to align distributions')\n",
    "print()\n",
    "print('2. TRANSFER LEARNING')\n",
    "print('   - Pre-train on related chemical data')\n",
    "print('   - Fine-tune on catechol data')\n",
    "print('   - May capture more generalizable patterns')\n",
    "print()\n",
    "print('3. ENSEMBLE DIVERSITY')\n",
    "print('   - Train models on different feature subsets')\n",
    "print('   - Use different model architectures')\n",
    "print('   - Combine predictions to reduce variance')\n",
    "print()\n",
    "print('4. FEATURE ENGINEERING')\n",
    "print('   - Create features that are more invariant to solvent identity')\n",
    "print('   - Focus on physicochemical properties rather than molecular structure')\n",
    "print('   - Use domain knowledge to create more generalizable features')\n",
    "print()\n",
    "print('5. BAYESIAN APPROACHES')\n",
    "print('   - Use Bayesian neural networks for uncertainty quantification')\n",
    "print('   - Predictions with high uncertainty can be regularized more')\n",
    "print('   - May help identify out-of-distribution test samples')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
