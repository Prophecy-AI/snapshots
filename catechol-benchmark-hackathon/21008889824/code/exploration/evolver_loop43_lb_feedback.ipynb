{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699d4b4",
   "metadata": {},
   "source": [
    "# Loop 43 LB Feedback Analysis\n",
    "\n",
    "**Pure GP Model Submission Results:**\n",
    "- CV: 0.0145\n",
    "- LB: 0.1147\n",
    "- Gap: -0.1001\n",
    "\n",
    "**Key Question:** Does Pure GP have a different CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c20988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},  # Pure GP\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('All submissions:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270050d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV-LB relationship for ALL submissions\n",
    "cv_all = df['cv'].values\n",
    "lb_all = df['lb'].values\n",
    "\n",
    "slope_all, intercept_all, r_all, p_all, se_all = stats.linregress(cv_all, lb_all)\n",
    "print(f'\\n=== CV-LB Relationship (ALL submissions) ===')\n",
    "print(f'LB = {slope_all:.2f} × CV + {intercept_all:.4f}')\n",
    "print(f'R² = {r_all**2:.4f}')\n",
    "print(f'Intercept: {intercept_all:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Intercept vs Target: {intercept_all/0.0347:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV-LB relationship EXCLUDING Pure GP\n",
    "df_no_gp = df[df['exp'] != 'exp_042']\n",
    "cv_no_gp = df_no_gp['cv'].values\n",
    "lb_no_gp = df_no_gp['lb'].values\n",
    "\n",
    "slope_no_gp, intercept_no_gp, r_no_gp, p_no_gp, se_no_gp = stats.linregress(cv_no_gp, lb_no_gp)\n",
    "print(f'\\n=== CV-LB Relationship (EXCLUDING Pure GP) ===')\n",
    "print(f'LB = {slope_no_gp:.2f} × CV + {intercept_no_gp:.4f}')\n",
    "print(f'R² = {r_no_gp**2:.4f}')\n",
    "print(f'Intercept: {intercept_no_gp:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Intercept vs Target: {intercept_no_gp/0.0347:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1240cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Pure GP is ON or OFF the line\n",
    "pure_gp_cv = 0.0145\n",
    "pure_gp_lb = 0.1147\n",
    "\n",
    "# Predicted LB using the relationship WITHOUT Pure GP\n",
    "predicted_lb = slope_no_gp * pure_gp_cv + intercept_no_gp\n",
    "\n",
    "print(f'\\n=== Pure GP Analysis ===')\n",
    "print(f'Pure GP CV: {pure_gp_cv:.4f}')\n",
    "print(f'Pure GP Actual LB: {pure_gp_lb:.4f}')\n",
    "print(f'Predicted LB (using non-GP relationship): {predicted_lb:.4f}')\n",
    "print(f'Difference: {pure_gp_lb - predicted_lb:.4f}')\n",
    "print(f'Ratio (actual/predicted): {pure_gp_lb/predicted_lb:.2f}x')\n",
    "\n",
    "if abs(pure_gp_lb - predicted_lb) < 0.005:\n",
    "    print(f'\\n✗ Pure GP is ON THE SAME LINE as other models')\n",
    "    print(f'  GP does NOT have a different CV-LB relationship')\n",
    "else:\n",
    "    if pure_gp_lb < predicted_lb:\n",
    "        print(f'\\n✓ Pure GP is BELOW the line (better than expected)')\n",
    "        print(f'  GP might have a lower intercept!')\n",
    "    else:\n",
    "        print(f'\\n✗ Pure GP is ABOVE the line (worse than expected)')\n",
    "        print(f'  GP has a HIGHER intercept (worse)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot all submissions\n",
    "plt.scatter(cv_no_gp, lb_no_gp, c='blue', s=100, label='MLP/LGBM models', alpha=0.7)\n",
    "plt.scatter([pure_gp_cv], [pure_gp_lb], c='red', s=200, marker='*', label='Pure GP (exp_042)', zorder=5)\n",
    "\n",
    "# Plot regression line (without GP)\n",
    "cv_range = np.linspace(0, 0.02, 100)\n",
    "lb_pred = slope_no_gp * cv_range + intercept_no_gp\n",
    "plt.plot(cv_range, lb_pred, 'b--', label=f'MLP/LGBM line: LB = {slope_no_gp:.2f}×CV + {intercept_no_gp:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Plot intercept\n",
    "plt.axhline(y=intercept_no_gp, color='orange', linestyle=':', linewidth=1, label=f'Intercept ({intercept_no_gp:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV-LB Relationship: Does Pure GP Have Different Relationship?')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.02)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop43_cv_lb_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlot saved to /home/code/exploration/loop43_cv_lb_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV-LB ratio for each submission\n",
    "df['ratio'] = df['lb'] / df['cv']\n",
    "print('\\n=== CV-LB Ratios ===')\n",
    "print(df[['exp', 'cv', 'lb', 'ratio']].to_string(index=False))\n",
    "print(f'\\nMean ratio: {df[\"ratio\"].mean():.2f}')\n",
    "print(f'Pure GP ratio: {pure_gp_lb/pure_gp_cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595066e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL ANALYSIS: What does this mean for reaching the target?\n",
    "print('\\n' + '='*60)\n",
    "print('CRITICAL ANALYSIS: Can We Reach the Target?')\n",
    "print('='*60)\n",
    "\n",
    "print(f'\\nTarget LB: 0.0347')\n",
    "print(f'Best LB so far: 0.0877 (exp_030)')\n",
    "print(f'Gap to target: {0.0877/0.0347:.2f}x')\n",
    "\n",
    "print(f'\\nCV-LB Relationship: LB = {slope_all:.2f} × CV + {intercept_all:.4f}')\n",
    "print(f'Intercept: {intercept_all:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "\n",
    "if intercept_all > 0.0347:\n",
    "    print(f'\\n⚠️ CRITICAL: Intercept ({intercept_all:.4f}) > Target ({0.0347})')\n",
    "    print(f'   Even with CV = 0, LB would be {intercept_all:.4f}')\n",
    "    print(f'   Current approach CANNOT reach target!')\n",
    "else:\n",
    "    # Calculate required CV to reach target\n",
    "    required_cv = (0.0347 - intercept_all) / slope_all\n",
    "    print(f'\\n✓ Intercept ({intercept_all:.4f}) < Target ({0.0347})')\n",
    "    print(f'   Required CV to reach target: {required_cv:.6f}')\n",
    "    print(f'   Best CV so far: 0.0083')\n",
    "    print(f'   Improvement needed: {(0.0083 - required_cv)/0.0083*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n' + '='*60)\n",
    "print('APPROACHES NOT YET TRIED')\n",
    "print('='*60)\n",
    "\n",
    "approaches_tried = [\n",
    "    'MLP with various architectures',\n",
    "    'LightGBM',\n",
    "    'Ridge Regression',\n",
    "    'Kernel Ridge Regression',\n",
    "    'Gaussian Process (pure and ensemble)',\n",
    "    'k-NN regression',\n",
    "    'XGBoost ensemble',\n",
    "    'Aggressive regularization',\n",
    "    'GroupKFold CV',\n",
    "    'Feature selection',\n",
    "    'Similarity weighting',\n",
    "    'Various feature combinations (Spange, DRFP, ACS PCA)',\n",
    "]\n",
    "\n",
    "approaches_not_tried = [\n",
    "    'Stacking (meta-learner on top of base models)',\n",
    "    'Bayesian optimization for hyperparameters',\n",
    "    'Neural network with attention mechanism',\n",
    "    'Graph Neural Networks (GNN)',\n",
    "    'Transfer learning from related datasets',\n",
    "    'Domain adaptation techniques',\n",
    "    'Quantile regression for uncertainty',\n",
    "    'Ensemble with different CV schemes',\n",
    "    'Target-specific models with different architectures',\n",
    "    'Pseudo-labeling on test data',\n",
    "]\n",
    "\n",
    "print('\\nApproaches TRIED:')\n",
    "for a in approaches_tried:\n",
    "    print(f'  - {a}')\n",
    "\n",
    "print('\\nApproaches NOT TRIED:')\n",
    "for a in approaches_not_tried:\n",
    "    print(f'  - {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e65762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGIC RECOMMENDATION\n",
    "print('\\n' + '='*60)\n",
    "print('STRATEGIC RECOMMENDATION')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "1. PURE GP RESULT: GP follows the SAME CV-LB relationship as other models.\n",
    "   - Predicted LB: {:.4f}, Actual LB: {:.4f}\n",
    "   - GP does NOT have a lower intercept\n",
    "   - This approach is NOT a path to the target\n",
    "\n",
    "2. THE INTERCEPT PROBLEM:\n",
    "   - CV-LB relationship: LB = {:.2f} × CV + {:.4f}\n",
    "   - Intercept ({:.4f}) > Target ({:.4f})\n",
    "   - Current approach CANNOT reach target mathematically\n",
    "\n",
    "3. REMAINING SUBMISSIONS: 3\n",
    "   - We need to find a fundamentally different approach\n",
    "   - Or accept that the target may not be reachable with current methods\n",
    "\n",
    "4. POSSIBLE PATHS FORWARD:\n",
    "   a) Stacking: Use predictions from multiple models as features for a meta-learner\n",
    "   b) Different CV scheme: The competition uses a specific CV procedure\n",
    "   c) Domain adaptation: Reduce distribution shift between train and test\n",
    "   d) Completely different model family: GNN, attention-based models\n",
    "\n",
    "5. RECOMMENDED NEXT EXPERIMENT:\n",
    "   - Try STACKING: Train a meta-learner on out-of-fold predictions\n",
    "   - This might have a different CV-LB relationship\n",
    "   - Use diverse base models (MLP, LGBM, GP, Ridge)\n",
    "'''.format(predicted_lb, pure_gp_lb, slope_all, intercept_all, intercept_all, 0.0347))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('\\n' + '='*60)\n",
    "print('FINAL SUMMARY')\n",
    "print('='*60)\n",
    "\n",
    "print(f'''\n",
    "Pure GP Submission Result:\n",
    "- CV: 0.0145\n",
    "- LB: 0.1147\n",
    "- Predicted LB (using MLP/LGBM relationship): {predicted_lb:.4f}\n",
    "- Actual vs Predicted: {pure_gp_lb/predicted_lb:.2f}x\n",
    "\n",
    "Conclusion: Pure GP is ON THE SAME LINE as other models.\n",
    "GP does NOT have a different CV-LB relationship.\n",
    "\n",
    "The CV-LB gap is STRUCTURAL and applies to ALL model families tested:\n",
    "- MLP\n",
    "- LightGBM\n",
    "- Ridge Regression\n",
    "- Gaussian Process\n",
    "- k-NN\n",
    "\n",
    "The intercept ({intercept_all:.4f}) is higher than the target (0.0347).\n",
    "This means the current approach CANNOT reach the target.\n",
    "\n",
    "We need a fundamentally different approach:\n",
    "1. Stacking with meta-learner\n",
    "2. Different CV scheme\n",
    "3. Domain adaptation\n",
    "4. GNN or attention-based models\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eac1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'mixall' kernel approach more carefully\n",
    "print('\\n' + '='*60)\n",
    "print('MIXALL KERNEL ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "The 'mixall' kernel uses:\n",
    "1. GroupKFold(5) instead of Leave-One-Out CV\n",
    "2. Ensemble of MLP + XGBoost + RF + LightGBM\n",
    "3. Optuna hyperparameter optimization\n",
    "\n",
    "We tested GroupKFold(5) in exp_040:\n",
    "- GroupKFold(5) CV: 0.009237\n",
    "- Leave-One-Out CV: 0.008199\n",
    "- Ratio: 1.13x (NOT the 3-5x expected)\n",
    "\n",
    "This DISPROVES the hypothesis that the CV-LB gap is due to CV procedure.\n",
    "\n",
    "The gap is due to DISTRIBUTION SHIFT between:\n",
    "- Training solvents (seen during CV)\n",
    "- Test solvents (unseen, different distribution)\n",
    "\n",
    "The test set likely contains solvents that are:\n",
    "- Out of distribution from training\n",
    "- Have different physicochemical properties\n",
    "- Require extrapolation, not interpolation\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the best LB score on the leaderboard?\n",
    "print('\\n' + '='*60)\n",
    "print('LEADERBOARD ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "Our best LB: 0.0877 (exp_030)\n",
    "Target: 0.0347\n",
    "Gap: 2.53x\n",
    "\n",
    "To reach the target, we need to:\n",
    "1. Find a model with a DIFFERENT CV-LB relationship (lower intercept)\n",
    "2. Or find a way to reduce the distribution shift\n",
    "3. Or accept that the target may not be reachable\n",
    "\n",
    "The fact that the target is 0.0347 suggests someone achieved this score.\n",
    "This means there IS a way to reach it.\n",
    "\n",
    "Possible explanations:\n",
    "1. They used a completely different approach (GNN, attention)\n",
    "2. They found a way to reduce distribution shift\n",
    "3. They used domain-specific knowledge we're missing\n",
    "4. They used a different CV scheme that better matches LB\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d306c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: What if we try a completely different approach?\n",
    "print('\\n' + '='*60)\n",
    "print('NEXT EXPERIMENT: STACKING META-LEARNER')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "Hypothesis: Stacking might have a different CV-LB relationship.\n",
    "\n",
    "Approach:\n",
    "1. Train diverse base models (MLP, LGBM, GP, Ridge)\n",
    "2. Generate out-of-fold predictions for each base model\n",
    "3. Train a meta-learner on these predictions\n",
    "4. The meta-learner learns to combine predictions optimally\n",
    "\n",
    "Why this might work:\n",
    "- Stacking can capture non-linear relationships between base predictions\n",
    "- The meta-learner might learn to weight models differently for different solvents\n",
    "- This is a fundamentally different approach from single-model ensembles\n",
    "\n",
    "Implementation:\n",
    "- Use the same CV scheme (Leave-One-Out for single, Leave-One-Ramp-Out for full)\n",
    "- Generate OOF predictions from each base model\n",
    "- Train a simple meta-learner (Ridge or small MLP) on OOF predictions\n",
    "- Final prediction is the meta-learner's output\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: What if the target is based on a different metric?\n",
    "print('\\n' + '='*60)\n",
    "print('ALTERNATIVE HYPOTHESIS: METRIC MISMATCH')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "What if the target (0.0347) is based on a different metric or evaluation?\n",
    "\n",
    "Possibilities:\n",
    "1. The target might be RMSE instead of MSE\n",
    "   - Our best MSE: 0.0877\n",
    "   - RMSE: sqrt(0.0877) = 0.296\n",
    "   - Target RMSE: sqrt(0.0347) = 0.186\n",
    "   - Still a 1.59x gap\n",
    "\n",
    "2. The target might be on a different subset of data\n",
    "   - Maybe only single solvent data?\n",
    "   - Maybe only certain targets?\n",
    "\n",
    "3. The target might be from a different competition phase\n",
    "   - Maybe the test set changed?\n",
    "\n",
    "4. The target might be achievable with domain-specific knowledge\n",
    "   - Chemical intuition we're missing\n",
    "   - Specific feature engineering for this reaction\n",
    "''')\n",
    "\n",
    "print(f'\\nOur best MSE: 0.0877')\n",
    "print(f'Our best RMSE: {np.sqrt(0.0877):.4f}')\n",
    "print(f'Target MSE: 0.0347')\n",
    "print(f'Target RMSE: {np.sqrt(0.0347):.4f}')\n",
    "print(f'Gap (MSE): {0.0877/0.0347:.2f}x')\n",
    "print(f'Gap (RMSE): {np.sqrt(0.0877)/np.sqrt(0.0347):.2f}x')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
