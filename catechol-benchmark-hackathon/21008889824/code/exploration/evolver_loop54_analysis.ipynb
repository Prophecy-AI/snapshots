{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abde0ff0",
   "metadata": {},
   "source": [
    "# Loop 54 Analysis: Post-Hyperparameter Optimization\n",
    "\n",
    "**Key Finding**: Hyperparameter optimization made CV 54% WORSE (0.012658 vs 0.008194)\n",
    "\n",
    "**Critical Questions**:\n",
    "1. What is the actual CV-LB relationship?\n",
    "2. What CV is needed to hit target 0.072990?\n",
    "3. What approaches haven't been tried that could achieve this CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab22798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_041', 'cv': 0.0090, 'lb': 0.0932},\n",
    "    {'exp': 'exp_042', 'cv': 0.0145, 'lb': 0.1147},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a371f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CV-LB relationship\n",
    "cv_values = df['cv'].values\n",
    "lb_values = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_values, lb_values)\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship ===')\n",
    "print(f'LB = {slope:.4f} × CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Standard Error: {std_err:.4f}')\n",
    "\n",
    "# Target analysis\n",
    "target = 0.072990\n",
    "required_cv = (target - intercept) / slope\n",
    "\n",
    "print(f'\\n=== Target Analysis ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV to hit target: {required_cv:.6f}')\n",
    "print(f'Best CV achieved: 0.008194')\n",
    "print(f'Gap: {0.008194 - required_cv:.6f} ({(0.008194 - required_cv)/required_cv*100:.1f}% above required)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot submissions\n",
    "ax.scatter(cv_values, lb_values, c='blue', s=100, label='Submissions', zorder=5)\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.02, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "ax.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}×CV + {intercept:.4f}')\n",
    "\n",
    "# Plot target\n",
    "ax.axhline(y=target, color='green', linestyle=':', linewidth=2, label=f'Target LB = {target}')\n",
    "ax.axvline(x=required_cv, color='green', linestyle=':', linewidth=2, alpha=0.5)\n",
    "\n",
    "# Plot best CV\n",
    "ax.axvline(x=0.008194, color='orange', linestyle='--', linewidth=2, label='Best CV = 0.008194')\n",
    "\n",
    "# Annotate key points\n",
    "for i, row in df.iterrows():\n",
    "    ax.annotate(row['exp'], (row['cv'], row['lb']), fontsize=8, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('CV Score (MSE)')\n",
    "ax.set_ylabel('LB Score (MSE)')\n",
    "ax.set_title('CV vs LB Relationship - 13 Submissions')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nPlot saved to /home/code/exploration/cv_lb_relationship.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all experiments tried\n",
    "experiments_summary = {\n",
    "    'Best Model (GP+MLP+LGBM)': {'cv': 0.008194, 'status': 'BEST'},\n",
    "    'Per-target models': {'cv': 0.009947, 'status': '21% worse'},\n",
    "    'Per-solvent-type models': {'cv': 0.019522, 'status': '138% worse'},\n",
    "    'GNN (our implementation)': {'cv': 0.01408, 'status': '72% worse'},\n",
    "    'ChemBERTa': {'cv': 0.0194, 'status': '137% worse'},\n",
    "    'Hyperparameter optimization': {'cv': 0.012658, 'status': '54% worse'},\n",
    "    'Stacking': {'cv': 0.010001, 'status': '22% worse'},\n",
    "    'Multi-model ensemble (no GP)': {'cv': 0.009435, 'status': '15% worse'},\n",
    "    'RDKit descriptors': {'cv': 0.013306, 'status': '62% worse'},\n",
    "    'Simple Ridge': {'cv': 0.016324, 'status': '99% worse'},\n",
    "}\n",
    "\n",
    "print('\\n=== Summary of All Approaches ===')\n",
    "for name, data in sorted(experiments_summary.items(), key=lambda x: x[1]['cv']):\n",
    "    print(f\"{name}: CV {data['cv']:.6f} ({data['status']})\")\n",
    "\n",
    "print(f'\\n=== Key Insight ===')\n",
    "print(f'The GP+MLP+LGBM ensemble with baseline hyperparameters is the BEST approach.')\n",
    "print(f'Hyperparameter optimization did NOT help - baseline is already near-optimal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV is achievable?\n",
    "print('\\n=== What CV is Achievable? ===')\n",
    "print(f'\\nGNN Benchmark (from competition description): CV 0.0039')\n",
    "print(f'Our GNN attempt: CV 0.01408 (3.6x worse)')\n",
    "print(f'Our best model: CV 0.008194 (2.1x worse than benchmark)')\n",
    "\n",
    "print(f'\\n=== If we achieved benchmark GNN CV ===')\n",
    "benchmark_cv = 0.0039\n",
    "predicted_lb = slope * benchmark_cv + intercept\n",
    "print(f'Predicted LB: {predicted_lb:.4f}')\n",
    "print(f'Target LB: {target}')\n",
    "if predicted_lb < target:\n",
    "    print(f'✓ WOULD BEAT TARGET by {(target - predicted_lb)*100:.2f}%')\n",
    "else:\n",
    "    print(f'✗ Would NOT beat target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical analysis: Why is our GNN 3.6x worse than benchmark?\n",
    "print('\\n=== GNN Analysis ===')\n",
    "print('\\nOur GNN implementation issues:')\n",
    "print('1. Used GCNConv (simple) vs benchmark may use more advanced layers')\n",
    "print('2. Only used solvent A graph for mixtures (ignored solvent B)')\n",
    "print('3. Combined with tabular features (may not be optimal)')\n",
    "print('4. Training for 300 epochs with early stopping')\n",
    "print('5. Used global_mean_pool (may lose information)')\n",
    "\n",
    "print('\\nPotential improvements:')\n",
    "print('1. Use GAT (Graph Attention) instead of GCN')\n",
    "print('2. Properly handle mixture solvents (both graphs)')\n",
    "print('3. Use edge features (bond types)')\n",
    "print('4. Try different pooling strategies (attention-based)')\n",
    "print('5. Increase model capacity (more layers, larger hidden dims)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae28c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative paths forward\n",
    "print('\\n=== Alternative Paths Forward ===')\n",
    "\n",
    "print('\\n1. IMPROVED GNN (High Risk, High Reward)')\n",
    "print('   - Potential: CV 0.0039 (benchmark) → LB ~0.070 (BEATS target)')\n",
    "print('   - Risk: Our attempt was 3.6x worse, may not be able to match benchmark')\n",
    "print('   - Effort: High (need to understand benchmark architecture)')\n",
    "\n",
    "print('\\n2. ENSEMBLE DIVERSITY (Medium Risk, Medium Reward)')\n",
    "print('   - Potential: 10-20% CV improvement → CV ~0.007 → LB ~0.083')\n",
    "print('   - Risk: May not be enough to hit target')\n",
    "print('   - Effort: Medium (try different base models, stacking)')\n",
    "\n",
    "print('\\n3. FEATURE ENGINEERING (Low Risk, Low Reward)')\n",
    "print('   - Potential: 5-10% CV improvement → CV ~0.0075 → LB ~0.085')\n",
    "print('   - Risk: Diminishing returns, already tried many features')\n",
    "print('   - Effort: Low-Medium')\n",
    "\n",
    "print('\\n4. SUBMIT BEST MODEL (No Risk, No Reward)')\n",
    "print('   - Current best: CV 0.008194 → Predicted LB ~0.088')\n",
    "print('   - Already submitted exp_030 with LB 0.0877')\n",
    "print('   - No improvement expected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60592663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('\\n=== FINAL RECOMMENDATION ===')\n",
    "print('\\nWith only 3 submissions remaining:')\n",
    "print('\\n1. DO NOT submit exp_055 (hyperparameter optimization) - CV is 54% worse')\n",
    "print('\\n2. Focus on approaches that could achieve CV < 0.006:')\n",
    "print('   a. Improved GNN with proper architecture')\n",
    "print('   b. Ensemble of best models with different random seeds')\n",
    "print('   c. Feature engineering with domain knowledge')\n",
    "print('\\n3. Only submit if CV improves significantly (>15% improvement)')\n",
    "print('\\n4. Save at least 1 submission for final attempt')\n",
    "\n",
    "print('\\n=== CRITICAL INSIGHT ===')\n",
    "print('The target IS reachable. The GNN benchmark proves CV 0.0039 is achievable.')\n",
    "print('Our best path is to improve the GNN implementation or find a novel approach.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
