{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe19dd",
   "metadata": {},
   "source": [
    "# Graph Neural Network (GNN) for Solvent Prediction\n",
    "\n",
    "**Hypothesis**: GNNs capture molecular structure that tabular features miss. The GNN benchmark achieved CV 0.0039 (5x better than our best CV 0.008194). GNNs might have a DIFFERENT CV-LB relationship.\n",
    "\n",
    "**Implementation**:\n",
    "- Use PyTorch Geometric with `from_smiles` utility\n",
    "- Represent molecules as graphs (atoms as nodes, bonds as edges)\n",
    "- Use GCNConv for message passing\n",
    "- Combine graph embeddings with reaction conditions (temperature, time)\n",
    "- Use global_mean_pool for graph-level readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)  # Use float32 for GNN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1dff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de09b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {SMILES_DF.shape}')\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute graph data for all solvents\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent, 'solvent smiles']\n",
    "    # Handle mixture solvents (e.g., \"Water.Acetonitrile\")\n",
    "    if '.' in smiles:\n",
    "        # For mixtures, we'll handle them separately\n",
    "        parts = smiles.split('.')\n",
    "        graphs = [from_smiles(s) for s in parts]\n",
    "        SOLVENT_GRAPHS[solvent] = graphs\n",
    "    else:\n",
    "        SOLVENT_GRAPHS[solvent] = from_smiles(smiles)\n",
    "\n",
    "print(f'Pre-computed graphs for {len(SOLVENT_GRAPHS)} solvents')\n",
    "\n",
    "# Check a few examples\n",
    "for solvent in ['Methanol', 'Ethanol', 'Water.Acetonitrile']:\n",
    "    if solvent in SOLVENT_GRAPHS:\n",
    "        g = SOLVENT_GRAPHS[solvent]\n",
    "        if isinstance(g, list):\n",
    "            print(f'{solvent}: mixture of {len(g)} components')\n",
    "        else:\n",
    "            print(f'{solvent}: x={g.x.shape}, edge_index={g.edge_index.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02948898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Model\n",
    "class GNNEncoder(nn.Module):\n",
    "    \"\"\"Encodes a molecular graph into a fixed-size embedding.\"\"\"\n",
    "    def __init__(self, node_features=9, hidden_dim=64, output_dim=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Graph-level representation\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    \"\"\"Full GNN model for yield prediction.\"\"\"\n",
    "    def __init__(self, node_features=9, hidden_dim=64, graph_dim=32, output_dim=3):\n",
    "        super().__init__()\n",
    "        self.gnn = GNNEncoder(node_features, hidden_dim, graph_dim)\n",
    "        # Combine graph embedding with conditions (temp, time, kinetics)\n",
    "        # 5 condition features: temp, time, 1/T, ln(t), 1/T * ln(t)\n",
    "        self.fc1 = nn.Linear(graph_dim + 5, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, graph_data, conditions):\n",
    "        # Get graph embedding\n",
    "        graph_emb = self.gnn(graph_data.x, graph_data.edge_index, graph_data.batch)\n",
    "        # Concatenate with conditions\n",
    "        x = torch.cat([graph_emb, conditions], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "print('GNN model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Model Wrapper with train_model and predict methods\n",
    "class GNNModelWrapper:\n",
    "    def __init__(self, data='single', epochs=200, lr=0.001, hidden_dim=64, graph_dim=32):\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.graph_dim = graph_dim\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def _get_conditions(self, X):\n",
    "        \"\"\"Extract and transform condition features.\"\"\"\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        return np.hstack([temp_c, time_m, inv_temp, log_time, interaction])\n",
    "    \n",
    "    def _get_graph_batch(self, X, flip=False):\n",
    "        \"\"\"Create a batch of graphs for the given samples.\"\"\"\n",
    "        graphs = []\n",
    "        for idx, row in X.iterrows():\n",
    "            if self.data == 'single':\n",
    "                solvent = row[\"SOLVENT NAME\"]\n",
    "                g = SOLVENT_GRAPHS.get(solvent)\n",
    "                if g is None or isinstance(g, list):\n",
    "                    # Fallback: create a simple graph\n",
    "                    g = from_smiles('C')  # Methane as fallback\n",
    "                graphs.append(g)\n",
    "            else:\n",
    "                # Mixed solvent - combine two graphs\n",
    "                solvent_a = row[\"SOLVENT A NAME\"]\n",
    "                solvent_b = row[\"SOLVENT B NAME\"]\n",
    "                pct = row[\"SolventB%\"]\n",
    "                \n",
    "                g_a = SOLVENT_GRAPHS.get(solvent_a)\n",
    "                g_b = SOLVENT_GRAPHS.get(solvent_b)\n",
    "                \n",
    "                # Handle missing or mixture solvents\n",
    "                if g_a is None or isinstance(g_a, list):\n",
    "                    g_a = from_smiles('C')\n",
    "                if g_b is None or isinstance(g_b, list):\n",
    "                    g_b = from_smiles('C')\n",
    "                \n",
    "                # For mixtures, we'll use weighted combination of embeddings\n",
    "                # For now, just use solvent A (or B if flip)\n",
    "                if flip:\n",
    "                    graphs.append(g_b)\n",
    "                else:\n",
    "                    graphs.append(g_a)\n",
    "        \n",
    "        return Batch.from_data_list(graphs)\n",
    "    \n",
    "    def train_model(self, X, Y):\n",
    "        \"\"\"Train the GNN model.\"\"\"\n",
    "        # Get conditions\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.fit_transform(conditions)\n",
    "        \n",
    "        # Get graph batch\n",
    "        graph_batch = self._get_graph_batch(X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        conditions_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = GNNModel(\n",
    "            node_features=9,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            graph_dim=self.graph_dim,\n",
    "            output_dim=3\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = self.model(graph_batch, conditions_tensor)\n",
    "            loss = criterion(predictions, y_tensor)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 50:\n",
    "                    break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get conditions\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.transform(conditions)\n",
    "        \n",
    "        # Get graph batch\n",
    "        graph_batch = self._get_graph_batch(X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        conditions_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(graph_batch, conditions_tensor)\n",
    "        \n",
    "        # TTA for mixed solvents\n",
    "        if self.data == 'full':\n",
    "            graph_batch_flip = self._get_graph_batch(X, flip=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                predictions_flip = self.model(graph_batch_flip, conditions_tensor)\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        predictions = torch.clamp(predictions, 0, 1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "print('GNN model wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a777303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f'Single solvent data: X={X_single.shape}, Y={Y_single.shape}')\n",
    "\n",
    "# Test on a small subset\n",
    "X_test = X_single.iloc[:50]\n",
    "Y_test = Y_single.iloc[:50]\n",
    "\n",
    "model = GNNModelWrapper(data='single', epochs=50)\n",
    "model.train_model(X_test, Y_test)\n",
    "preds = model.predict(X_test)\n",
    "print(f'Test predictions shape: {preds.shape}')\n",
    "print(f'Test predictions range: [{preds.min():.4f}, {preds.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on single solvent data\n",
    "print('\\n=== Single Solvent CV ===')\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "all_predictions_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GNNModelWrapper(data='single', epochs=200, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_single.append(predictions.cpu().numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "preds_single = np.vstack(all_predictions_single)\n",
    "actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((preds_single - actuals_single) ** 2)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={len(preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on full data\n",
    "print('\\n=== Full Data CV ===')\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = GNNModelWrapper(data='full', epochs=200, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_full.append(predictions.cpu().numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "preds_full = np.vstack(all_predictions_full)\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((preds_full - actuals_full) ** 2)\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={len(preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(preds_single)\n",
    "n_full = len(preds_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE SUMMARY ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'GNN Benchmark: 0.0039')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8340ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModelWrapper(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69130b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GNNModelWrapper(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final CV score verification\n",
    "print(f'\\n=== FINAL CV SCORE ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'GNN Benchmark: 0.0039')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
