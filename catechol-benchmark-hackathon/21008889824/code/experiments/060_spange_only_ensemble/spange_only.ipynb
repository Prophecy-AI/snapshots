{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1125b97",
   "metadata": {},
   "source": [
    "# Simpler Features (Spange Only) with GP+MLP+LGBM Ensemble\n",
    "\n",
    "**Hypothesis**: Simpler features may generalize better and reduce the CV-LB intercept.\n",
    "\n",
    "**Key Finding from Analysis**:\n",
    "- exp_000 (Spange only, 18 features) had BEST generalization residual (-0.0021)\n",
    "- Current best (exp_035) uses 145 features but has higher CV-LB gap\n",
    "- The intercept (0.0535) > Target (0.0347) - we need to reduce the intercept\n",
    "\n",
    "**Implementation**:\n",
    "1. Use only Spange descriptors (13 features) + Arrhenius kinetics (5 features) = 18 features\n",
    "2. Remove DRFP (122 features) and ACS PCA (5 features)\n",
    "3. Train GP + MLP + LGBM ensemble with weights (0.15, 0.55, 0.30)\n",
    "4. Compare CV and predicted LB with current best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe27731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature lookups - ONLY SPANGE (no DRFP, no ACS PCA)\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}')\n",
    "print(f'\\nUsing ONLY Spange features (13) + Arrhenius kinetics (5) = 18 features')\n",
    "print('Removed: DRFP (122 features) and ACS PCA (5 features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Featurizer - ONLY Spange + Arrhenius kinetics (18 features)\n",
    "class SpangeOnlyFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        # 2 (time, temp) + 3 (Arrhenius: 1/T, ln(t), interaction) + 13 (Spange) = 18 features\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'Spange-only feature dimension: {SpangeOnlyFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a040f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model - adjusted for smaller input dimension\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim=18, hidden_dim=32, output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "print('MLP model defined (smaller hidden dim for 18 features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spange-Only Ensemble Model\n",
    "class SpangeOnlyEnsemble:\n",
    "    \"\"\"GP + MLP + LGBM ensemble using only Spange features.\"\"\"\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30):\n",
    "        self.data = data\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.mixed = (data == 'full')\n",
    "        \n",
    "        self.featurizer = SpangeOnlyFeaturizer(mixed=self.mixed)\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        self.gp_models = []\n",
    "        self.mlp_model = None\n",
    "        self.lgbm_models = []\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        Y_np = Y.values\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Train GP for each target\n",
    "        for i in range(3):\n",
    "            kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "            gp = GaussianProcessRegressor(\n",
    "                kernel=kernel, alpha=0.01, n_restarts_optimizer=3, random_state=42\n",
    "            )\n",
    "            gp.fit(X_scaled, Y_np[:, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train MLP (smaller for 18 features)\n",
    "        self.mlp_model = MLPModel(\n",
    "            input_dim=self.featurizer.feats_dim,\n",
    "            hidden_dim=32,  # Smaller hidden dim\n",
    "            output_dim=3,\n",
    "            dropout=0.2\n",
    "        ).to(device)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "        Y_tensor = torch.tensor(Y_np, dtype=torch.double).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.mlp_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.mlp_model.train()\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.mlp_model(X_tensor)\n",
    "            loss = criterion(pred, Y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Train LGBM for each target\n",
    "        for i in range(3):\n",
    "            lgbm = lgb.LGBMRegressor(\n",
    "                n_estimators=100, learning_rate=0.05, max_depth=5,\n",
    "                num_leaves=31, min_child_samples=5, random_state=42, verbose=-1\n",
    "            )\n",
    "            lgbm.fit(X_scaled, Y_np[:, i])\n",
    "            self.lgbm_models.append(lgbm)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.column_stack([self.gp_models[i].predict(X_scaled) for i in range(3)])\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp_model.eval()\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(device)\n",
    "        with torch.no_grad():\n",
    "            mlp_preds = self.mlp_model(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # LGBM predictions\n",
    "        lgbm_preds = np.column_stack([self.lgbm_models[i].predict(X_scaled) for i in range(3)])\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        predictions = self.gp_weight * gp_preds + self.mlp_weight * mlp_preds + self.lgbm_weight * lgbm_preds\n",
    "        \n",
    "        # TTA for mixtures\n",
    "        if self.mixed:\n",
    "            X_feat_flip = self.featurizer.featurize(X, flip=True)\n",
    "            X_scaled_flip = self.scaler.transform(X_feat_flip)\n",
    "            \n",
    "            gp_preds_flip = np.column_stack([self.gp_models[i].predict(X_scaled_flip) for i in range(3)])\n",
    "            X_tensor_flip = torch.tensor(X_scaled_flip, dtype=torch.double).to(device)\n",
    "            with torch.no_grad():\n",
    "                mlp_preds_flip = self.mlp_model(X_tensor_flip).cpu().numpy()\n",
    "            lgbm_preds_flip = np.column_stack([self.lgbm_models[i].predict(X_scaled_flip) for i in range(3)])\n",
    "            \n",
    "            predictions_flip = self.gp_weight * gp_preds_flip + self.mlp_weight * mlp_preds_flip + self.lgbm_weight * lgbm_preds_flip\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        predictions = np.clip(predictions, 0, 1)\n",
    "        return torch.tensor(predictions)\n",
    "\n",
    "print('Spange-Only Ensemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on single solvent data\n",
    "print('=== Single Solvent CV (Spange Only, 18 features) ===')\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "all_predictions_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SpangeOnlyEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_single.append(predictions.numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "preds_single = np.vstack(all_predictions_single)\n",
    "actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((preds_single - actuals_single) ** 2)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={len(preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on full data\n",
    "print('\\n=== Full Data CV (Spange Only, 18 features) ===')\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SpangeOnlyEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_full.append(predictions.numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "preds_full = np.vstack(all_predictions_full)\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((preds_full - actuals_full) ** 2)\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={len(preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(preds_single)\n",
    "n_full = len(preds_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE SUMMARY (Spange Only, 18 features) ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_035, 145 features): 0.008194')\n",
    "print(f'exp_000 (Spange only, 18 features): ~0.0095 (had best generalization)')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')\n",
    "\n",
    "# Predict LB using CV-LB relationship\n",
    "predicted_lb = 4.21 * overall_mse + 0.0535\n",
    "print(f'\\nPredicted LB (using LB = 4.21*CV + 0.0535): {predicted_lb:.4f}')\n",
    "print(f'Best LB achieved: 0.0877')\n",
    "print(f'Target: 0.0347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SpangeOnlyEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c783359",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SpangeOnlyEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7244be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification\n",
    "print(f'\\n=== FINAL CV SCORE ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_035): 0.008194')\n",
    "print(f'Predicted LB: {predicted_lb:.4f}')\n",
    "print(f'Target: 0.0347')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
