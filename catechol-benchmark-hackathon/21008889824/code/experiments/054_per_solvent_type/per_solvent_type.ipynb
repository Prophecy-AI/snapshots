{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b061bd",
   "metadata": {},
   "source": [
    "# Per-Solvent-Type Models\n",
    "\n",
    "**Hypothesis**: Different solvent types have fundamentally different physicochemical properties. Per-type models could capture type-specific patterns that a global model misses.\n",
    "\n",
    "**Competition Rules**: \"Using a different model for alcohols vs esters is allowed\"\n",
    "\n",
    "**Implementation**:\n",
    "1. Classify solvents into types (Alcohols, Ethers, Esters, etc.)\n",
    "2. Train separate GP + MLP + LGBM ensembles for each solvent type\n",
    "3. Use the appropriate model based on solvent type during prediction\n",
    "4. For mixtures: use model based on dominant solvent type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ef63f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:02.730633Z",
     "iopub.status.busy": "2026-01-15T10:04:02.730107Z",
     "iopub.status.idle": "2026-01-15T10:04:04.469333Z",
     "shell.execute_reply": "2026-01-15T10:04:04.468885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2badaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.470533Z",
     "iopub.status.busy": "2026-01-15T10:04:04.470354Z",
     "iopub.status.idle": "2026-01-15T10:04:04.475073Z",
     "shell.execute_reply": "2026-01-15T10:04:04.474702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e2f373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.476151Z",
     "iopub.status.busy": "2026-01-15T10:04:04.476042Z",
     "iopub.status.idle": "2026-01-15T10:04:04.492060Z",
     "shell.execute_reply": "2026-01-15T10:04:04.491679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique solvents: 24\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: Fluorinated\n",
      "  2,2,2-Trifluoroethanol: Fluorinated\n",
      "  2-Methyltetrahydrofuran [2-MeTHF]: Ethers\n",
      "  Acetonitrile: Nitriles\n",
      "  Acetonitrile.Acetic Acid: Nitriles\n",
      "  Butanone [MEK]: Ketones\n",
      "  Cyclohexane: Others\n",
      "  DMA [N,N-Dimethylacetamide]: Amides\n",
      "  Decanol: Alcohols\n",
      "  Diethyl Ether [Ether]: Ethers\n",
      "  Dihydrolevoglucosenone (Cyrene): Others\n",
      "  Dimethyl Carbonate: Esters\n",
      "  Ethanol: Alcohols\n",
      "  Ethyl Acetate: Esters\n",
      "  Ethyl Lactate: Esters\n",
      "  Ethylene Glycol [1,2-Ethanediol]: Alcohols\n",
      "  IPA [Propan-2-ol]: Alcohols\n",
      "  MTBE [tert-Butylmethylether]: Ethers\n",
      "  Methanol: Alcohols\n",
      "  Methyl Propionate: Esters\n",
      "  THF [Tetrahydrofuran]: Ethers\n",
      "  Water.2,2,2-Trifluoroethanol: Others\n",
      "  Water.Acetonitrile: Others\n",
      "  tert-Butanol [2-Methylpropan-2-ol]: Alcohols\n"
     ]
    }
   ],
   "source": [
    "# Solvent type classification (based on chemical properties)\n",
    "SOLVENT_TYPES = {\n",
    "    'Alcohols': ['Methanol', 'Ethanol', 'IPA [Propan-2-ol]', 'tert-Butanol [2-Methylpropan-2-ol]', \n",
    "                 'Ethylene Glycol [1,2-Ethanediol]', 'Decanol'],\n",
    "    'Ethers': ['THF [Tetrahydrofuran]', '2-Methyltetrahydrofuran [2-MeTHF]', \n",
    "               'MTBE [tert-Butylmethylether]', 'Diethyl Ether [Ether]'],\n",
    "    'Esters': ['Ethyl Acetate', 'Ethyl Lactate', 'Methyl Propionate', 'Dimethyl Carbonate'],\n",
    "    'Ketones': ['Butanone [MEK]'],\n",
    "    'Nitriles': ['Acetonitrile'],\n",
    "    'Fluorinated': ['1,1,1,3,3,3-Hexafluoropropan-2-ol', '2,2,2-Trifluoroethanol'],\n",
    "    'Amides': ['DMA [N,N-Dimethylacetamide]'],\n",
    "    'Others': ['Cyclohexane', 'Dihydrolevoglucosenone (Cyrene)', 'Acetic Acid', 'Water'],\n",
    "}\n",
    "\n",
    "# Create reverse mapping\n",
    "SOLVENT_TO_TYPE = {}\n",
    "for stype, solvents in SOLVENT_TYPES.items():\n",
    "    for solvent in solvents:\n",
    "        SOLVENT_TO_TYPE[solvent] = stype\n",
    "\n",
    "def get_solvent_type(solvent_name):\n",
    "    # Handle mixture solvents\n",
    "    if '.' in solvent_name:\n",
    "        parts = solvent_name.split('.')\n",
    "        # Use the first component's type\n",
    "        return SOLVENT_TO_TYPE.get(parts[0], 'Others')\n",
    "    return SOLVENT_TO_TYPE.get(solvent_name, 'Others')\n",
    "\n",
    "# Verify all solvents are classified\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "all_solvents = set(X_single[\"SOLVENT NAME\"].unique())\n",
    "all_solvents.update(X_full[\"SOLVENT A NAME\"].unique())\n",
    "all_solvents.update(X_full[\"SOLVENT B NAME\"].unique())\n",
    "\n",
    "print(f'Total unique solvents: {len(all_solvents)}')\n",
    "for solvent in sorted(all_solvents):\n",
    "    print(f'  {solvent}: {get_solvent_type(solvent)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4da09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.493001Z",
     "iopub.status.busy": "2026-01-15T10:04:04.492899Z",
     "iopub.status.idle": "2026-01-15T10:04:04.522873Z",
     "shell.execute_reply": "2026-01-15T10:04:04.522521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82500a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.524117Z",
     "iopub.status.busy": "2026-01-15T10:04:04.523857Z",
     "iopub.status.idle": "2026-01-15T10:04:04.529452Z",
     "shell.execute_reply": "2026-01-15T10:04:04.528846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Full Featurizer - 145 features\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Full feature dimension: {FullFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75896dff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.530487Z",
     "iopub.status.busy": "2026-01-15T10:04:04.530366Z",
     "iopub.status.idle": "2026-01-15T10:04:04.534947Z",
     "shell.execute_reply": "2026-01-15T10:04:04.534553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature dimension: 18\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer (for GP) - 18 features\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'Simple feature dimension: {SimpleFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b545a747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.535914Z",
     "iopub.status.busy": "2026-01-15T10:04:04.535813Z",
     "iopub.status.idle": "2026-01-15T10:04:04.539306Z",
     "shell.execute_reply": "2026-01-15T10:04:04.538932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim=145, hidden_dim=64, output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "print('MLP model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fb8e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.540314Z",
     "iopub.status.busy": "2026-01-15T10:04:04.540190Z",
     "iopub.status.idle": "2026-01-15T10:04:04.549304Z",
     "shell.execute_reply": "2026-01-15T10:04:04.548918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP + MLP + LGBM Ensemble defined\n"
     ]
    }
   ],
   "source": [
    "# Standard GP + MLP + LGBM Ensemble (for comparison and as fallback)\n",
    "class GPMLPLGBMEnsemble:\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30):\n",
    "        self.data = data\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.mixed = (data == 'full')\n",
    "        \n",
    "        self.full_featurizer = FullFeaturizer(mixed=self.mixed)\n",
    "        self.simple_featurizer = SimpleFeaturizer(mixed=self.mixed)\n",
    "        \n",
    "        self.scaler_full = StandardScaler()\n",
    "        self.scaler_simple = StandardScaler()\n",
    "        \n",
    "        self.gp_models = [None, None, None]\n",
    "        self.mlp_model = None\n",
    "        self.lgbm_models = [None, None, None]\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        Y_np = Y.values\n",
    "        \n",
    "        X_full_scaled = self.scaler_full.fit_transform(X_full)\n",
    "        X_simple_scaled = self.scaler_simple.fit_transform(X_simple)\n",
    "        \n",
    "        # Train GP for each target\n",
    "        for i in range(3):\n",
    "            kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "            self.gp_models[i] = GaussianProcessRegressor(\n",
    "                kernel=kernel, alpha=0.01, n_restarts_optimizer=3, random_state=42\n",
    "            )\n",
    "            self.gp_models[i].fit(X_simple_scaled, Y_np[:, i])\n",
    "        \n",
    "        # Train MLP\n",
    "        self.mlp_model = MLPModel(\n",
    "            input_dim=self.full_featurizer.feats_dim,\n",
    "            hidden_dim=64,\n",
    "            output_dim=3,\n",
    "            dropout=0.2\n",
    "        ).to(device)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_full_scaled, dtype=torch.double).to(device)\n",
    "        Y_tensor = torch.tensor(Y_np, dtype=torch.double).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.mlp_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.mlp_model.train()\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred = self.mlp_model(X_tensor)\n",
    "            loss = criterion(pred, Y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Train LGBM for each target\n",
    "        for i in range(3):\n",
    "            self.lgbm_models[i] = lgb.LGBMRegressor(\n",
    "                n_estimators=100, learning_rate=0.05, max_depth=5,\n",
    "                num_leaves=31, min_child_samples=5, random_state=42, verbose=-1\n",
    "            )\n",
    "            self.lgbm_models[i].fit(X_full_scaled, Y_np[:, i])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        \n",
    "        X_full_scaled = self.scaler_full.transform(X_full)\n",
    "        X_simple_scaled = self.scaler_simple.transform(X_simple)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.column_stack([self.gp_models[i].predict(X_simple_scaled) for i in range(3)])\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp_model.eval()\n",
    "        X_tensor = torch.tensor(X_full_scaled, dtype=torch.double).to(device)\n",
    "        with torch.no_grad():\n",
    "            mlp_preds = self.mlp_model(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # LGBM predictions\n",
    "        lgbm_preds = np.column_stack([self.lgbm_models[i].predict(X_full_scaled) for i in range(3)])\n",
    "        \n",
    "        # Ensemble\n",
    "        predictions = self.gp_weight * gp_preds + self.mlp_weight * mlp_preds + self.lgbm_weight * lgbm_preds\n",
    "        \n",
    "        # TTA for mixtures\n",
    "        if self.mixed:\n",
    "            X_full_flip = self.full_featurizer.featurize(X, flip=True)\n",
    "            X_simple_flip = self.simple_featurizer.featurize(X, flip=True)\n",
    "            \n",
    "            X_full_scaled_flip = self.scaler_full.transform(X_full_flip)\n",
    "            X_simple_scaled_flip = self.scaler_simple.transform(X_simple_flip)\n",
    "            \n",
    "            gp_preds_flip = np.column_stack([self.gp_models[i].predict(X_simple_scaled_flip) for i in range(3)])\n",
    "            X_tensor_flip = torch.tensor(X_full_scaled_flip, dtype=torch.double).to(device)\n",
    "            with torch.no_grad():\n",
    "                mlp_preds_flip = self.mlp_model(X_tensor_flip).cpu().numpy()\n",
    "            lgbm_preds_flip = np.column_stack([self.lgbm_models[i].predict(X_full_scaled_flip) for i in range(3)])\n",
    "            \n",
    "            predictions_flip = self.gp_weight * gp_preds_flip + self.mlp_weight * mlp_preds_flip + self.lgbm_weight * lgbm_preds_flip\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        predictions = np.clip(predictions, 0, 1)\n",
    "        return torch.tensor(predictions)\n",
    "\n",
    "print('GP + MLP + LGBM Ensemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86b8754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.550399Z",
     "iopub.status.busy": "2026-01-15T10:04:04.550300Z",
     "iopub.status.idle": "2026-01-15T10:04:04.553950Z",
     "shell.execute_reply": "2026-01-15T10:04:04.553583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvent Type Aware Model defined\n"
     ]
    }
   ],
   "source": [
    "# Per-Solvent-Type Model\n",
    "# Since we have limited data per solvent type, we'll use a simpler approach:\n",
    "# Train a global model but with solvent type as an additional feature\n",
    "# This is more robust than training completely separate models\n",
    "\n",
    "class SolventTypeAwareModel:\n",
    "    \"\"\"Model that uses solvent type as an additional feature.\"\"\"\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30):\n",
    "        self.data = data\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.mixed = (data == 'full')\n",
    "        \n",
    "        # Use the standard ensemble as the base\n",
    "        self.ensemble = GPMLPLGBMEnsemble(data=data, gp_weight=gp_weight, \n",
    "                                          mlp_weight=mlp_weight, lgbm_weight=lgbm_weight)\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        # Just use the standard ensemble - solvent type info is already in Spange descriptors\n",
    "        self.ensemble.train_model(X, Y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.ensemble.predict(X)\n",
    "\n",
    "print('Solvent Type Aware Model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b02d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.554912Z",
     "iopub.status.busy": "2026-01-15T10:04:04.554810Z",
     "iopub.status.idle": "2026-01-15T10:04:04.560743Z",
     "shell.execute_reply": "2026-01-15T10:04:04.560361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Solvent-Type Model defined\n"
     ]
    }
   ],
   "source": [
    "# Actually, let's try a different approach:\n",
    "# Train separate models for each solvent type, but fall back to global model if not enough data\n",
    "\n",
    "class PerSolventTypeModel:\n",
    "    \"\"\"Train separate models for each solvent type.\"\"\"\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30, min_samples=50):\n",
    "        self.data = data\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.mixed = (data == 'full')\n",
    "        self.min_samples = min_samples\n",
    "        \n",
    "        # Models per solvent type\n",
    "        self.type_models = {}\n",
    "        # Global fallback model\n",
    "        self.global_model = None\n",
    "        \n",
    "    def _get_solvent_type_for_row(self, row):\n",
    "        if self.mixed:\n",
    "            # For mixtures, use the dominant solvent type (solvent A)\n",
    "            return get_solvent_type(row[\"SOLVENT A NAME\"])\n",
    "        else:\n",
    "            return get_solvent_type(row[\"SOLVENT NAME\"])\n",
    "    \n",
    "    def train_model(self, X, Y):\n",
    "        # First, train a global model as fallback\n",
    "        self.global_model = GPMLPLGBMEnsemble(\n",
    "            data=self.data, gp_weight=self.gp_weight, \n",
    "            mlp_weight=self.mlp_weight, lgbm_weight=self.lgbm_weight\n",
    "        )\n",
    "        self.global_model.train_model(X, Y)\n",
    "        \n",
    "        # Group data by solvent type\n",
    "        X_reset = X.reset_index(drop=True)\n",
    "        Y_reset = Y.reset_index(drop=True)\n",
    "        \n",
    "        solvent_types = X_reset.apply(self._get_solvent_type_for_row, axis=1)\n",
    "        \n",
    "        for stype in solvent_types.unique():\n",
    "            mask = solvent_types == stype\n",
    "            X_type = X_reset[mask]\n",
    "            Y_type = Y_reset[mask]\n",
    "            \n",
    "            if len(X_type) >= self.min_samples:\n",
    "                # Train a type-specific model\n",
    "                self.type_models[stype] = GPMLPLGBMEnsemble(\n",
    "                    data=self.data, gp_weight=self.gp_weight,\n",
    "                    mlp_weight=self.mlp_weight, lgbm_weight=self.lgbm_weight\n",
    "                )\n",
    "                self.type_models[stype].train_model(X_type, Y_type)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_reset = X.reset_index(drop=True)\n",
    "        predictions = np.zeros((len(X_reset), 3))\n",
    "        \n",
    "        for idx, row in X_reset.iterrows():\n",
    "            stype = self._get_solvent_type_for_row(row)\n",
    "            \n",
    "            # Use type-specific model if available, otherwise global\n",
    "            if stype in self.type_models:\n",
    "                model = self.type_models[stype]\n",
    "            else:\n",
    "                model = self.global_model\n",
    "            \n",
    "            # Predict for single row\n",
    "            row_df = pd.DataFrame([row])\n",
    "            pred = model.predict(row_df).numpy()\n",
    "            predictions[idx] = pred.squeeze()\n",
    "        \n",
    "        return torch.tensor(predictions)\n",
    "\n",
    "print('Per-Solvent-Type Model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cebde4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:04:04.561849Z",
     "iopub.status.busy": "2026-01-15T10:04:04.561745Z",
     "iopub.status.idle": "2026-01-15T10:04:07.337821Z",
     "shell.execute_reply": "2026-01-15T10:04:07.337391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: X=(656, 3), Y=(656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: torch.Size([50, 3])\n",
      "Test predictions range: [0.0000, 0.9688]\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f'Single solvent data: X={X_single.shape}, Y={Y_single.shape}')\n",
    "\n",
    "# Test on a small subset\n",
    "X_test = X_single.iloc[:50]\n",
    "Y_test = Y_single.iloc[:50]\n",
    "\n",
    "model = PerSolventTypeModel(data='single', min_samples=30)\n",
    "model.train_model(X_test, Y_test)\n",
    "preds = model.predict(X_test)\n",
    "print(f'Test predictions shape: {preds.shape}')\n",
    "print(f'Test predictions range: [{preds.min():.4f}, {preds.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on single solvent data\n",
    "print('\\n=== Single Solvent CV (Per-Solvent-Type Model) ===')\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "all_predictions_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    # Use min_samples=30 to allow type-specific models when enough data\n",
    "    model = PerSolventTypeModel(data='single', min_samples=30)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_single.append(predictions.numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "preds_single = np.vstack(all_predictions_single)\n",
    "actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((preds_single - actuals_single) ** 2)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={len(preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on full data\n",
    "print('\\n=== Full Data CV (Per-Solvent-Type Model) ===')\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = PerSolventTypeModel(data='full', min_samples=50)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_full.append(predictions.numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "preds_full = np.vstack(all_predictions_full)\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((preds_full - actuals_full) ** 2)\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={len(preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f321452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(preds_single)\n",
    "n_full = len(preds_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE SUMMARY (Per-Solvent-Type Model) ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerSolventTypeModel(data='single', min_samples=30)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5538d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerSolventTypeModel(data='full', min_samples=50)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b812d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification\n",
    "print(f'\\n=== FINAL CV SCORE ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
