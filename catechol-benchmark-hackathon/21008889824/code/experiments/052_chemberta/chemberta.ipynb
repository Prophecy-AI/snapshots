{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8a52cf",
   "metadata": {},
   "source": [
    "# ChemBERTa Pre-trained Molecular Embeddings\n",
    "\n",
    "**Hypothesis**: Pre-trained molecular embeddings may generalize better to unseen solvents and potentially break the CV-LB relationship.\n",
    "\n",
    "**Rationale**:\n",
    "- The GNN benchmark achieved CV 0.0039 (5x better than our best CV 0.008194)\n",
    "- The key difference is likely pre-training on large molecular datasets\n",
    "- ChemBERTa was trained on 77M molecules from ZINC database\n",
    "- Pre-trained embeddings capture chemical knowledge that may transfer to unseen solvents\n",
    "\n",
    "**Implementation**:\n",
    "1. Use ChemBERTa to generate 768-dim embeddings for each solvent SMILES\n",
    "2. Replace Spange/DRFP/ACS features with ChemBERTa embeddings\n",
    "3. Add Arrhenius kinetics features (1/T, ln(t), interaction)\n",
    "4. Train MLP on ChemBERTa embeddings + kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f386fdc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:40.233759Z",
     "iopub.status.busy": "2026-01-15T09:09:40.233207Z",
     "iopub.status.idle": "2026-01-15T09:09:41.826265Z",
     "shell.execute_reply": "2026-01-15T09:09:41.825842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec77026e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:41.827479Z",
     "iopub.status.busy": "2026-01-15T09:09:41.827309Z",
     "iopub.status.idle": "2026-01-15T09:09:42.699204Z",
     "shell.execute_reply": "2026-01-15T09:09:42.698777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seyonec/ChemBERTa-zinc-base-v1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load ChemBERTa\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'seyonec/ChemBERTa-zinc-base-v1'\n",
    "print(f'Loading {model_name}...')\n",
    "chemberta_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "chemberta_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "chemberta_model.eval()\n",
    "print('ChemBERTa loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f61520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:42.700376Z",
     "iopub.status.busy": "2026-01-15T09:09:42.700246Z",
     "iopub.status.idle": "2026-01-15T09:09:42.704805Z",
     "shell.execute_reply": "2026-01-15T09:09:42.704460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2553b3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:42.705853Z",
     "iopub.status.busy": "2026-01-15T09:09:42.705732Z",
     "iopub.status.idle": "2026-01-15T09:09:43.326876Z",
     "shell.execute_reply": "2026-01-15T09:09:43.326453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: (26, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ChemBERTa embeddings for 26 solvents\n",
      "Embedding dimension: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup and generate ChemBERTa embeddings\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {SMILES_DF.shape}')\n",
    "\n",
    "# Generate embeddings for all solvents\n",
    "CHEMBERTA_EMBEDDINGS = {}\n",
    "\n",
    "for solvent in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent, 'solvent smiles']\n",
    "    \n",
    "    # Handle mixture solvents (e.g., \"Water.Acetonitrile\")\n",
    "    if '.' in smiles:\n",
    "        # For mixtures, average the embeddings of components\n",
    "        parts = smiles.split('.')\n",
    "        embeddings = []\n",
    "        for part in parts:\n",
    "            inputs = chemberta_tokenizer(part, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = chemberta_model(**inputs)\n",
    "                emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token\n",
    "            embeddings.append(emb)\n",
    "        # Average the embeddings\n",
    "        CHEMBERTA_EMBEDDINGS[solvent] = np.mean(embeddings, axis=0).squeeze()\n",
    "    else:\n",
    "        inputs = chemberta_tokenizer(smiles, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = chemberta_model(**inputs)\n",
    "            emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token\n",
    "        CHEMBERTA_EMBEDDINGS[solvent] = emb.squeeze()\n",
    "\n",
    "print(f'Generated ChemBERTa embeddings for {len(CHEMBERTA_EMBEDDINGS)} solvents')\n",
    "print(f'Embedding dimension: {CHEMBERTA_EMBEDDINGS[\"Methanol\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e479edb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:43.328057Z",
     "iopub.status.busy": "2026-01-15T09:09:43.327861Z",
     "iopub.status.idle": "2026-01-15T09:09:43.336325Z",
     "shell.execute_reply": "2026-01-15T09:09:43.335896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa DataFrame: (26, 768)\n",
      "                                        0         1         2         3    \\\n",
      "SOLVENT NAME                                                                \n",
      "Cyclohexane                        2.490830  1.924160  0.295041 -2.139060   \n",
      "Ethyl Acetate                      1.831127  1.058668  0.755435 -1.189752   \n",
      "Acetic Acid                        0.455353  0.285686 -1.085794 -1.166156   \n",
      "2-Methyltetrahydrofuran [2-MeTHF]  3.420858  0.539570  0.030612 -1.840547   \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  1.213224  0.286342  0.117680 -0.057614   \n",
      "\n",
      "                                        4         5         6         7    \\\n",
      "SOLVENT NAME                                                                \n",
      "Cyclohexane                        0.529282  0.217540 -0.515373 -0.439706   \n",
      "Ethyl Acetate                     -0.021727 -0.906612  0.303518 -0.691459   \n",
      "Acetic Acid                       -0.172513 -1.243419 -0.003198  0.567491   \n",
      "2-Methyltetrahydrofuran [2-MeTHF]  0.469968  0.060588  0.383616 -1.050655   \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  0.303724 -0.450213 -0.040866  0.209504   \n",
      "\n",
      "                                        8         9    ...       758  \\\n",
      "SOLVENT NAME                                           ...             \n",
      "Cyclohexane                       -0.493365 -0.009738  ... -0.085112   \n",
      "Ethyl Acetate                     -0.905041  0.769409  ... -0.328233   \n",
      "Acetic Acid                       -0.697049  0.544779  ...  0.583936   \n",
      "2-Methyltetrahydrofuran [2-MeTHF] -1.446413  0.508267  ... -0.336345   \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol -1.370232  0.961113  ...  0.163799   \n",
      "\n",
      "                                        759       760       761       762  \\\n",
      "SOLVENT NAME                                                                \n",
      "Cyclohexane                       -0.123982 -0.139521 -1.529457 -0.148425   \n",
      "Ethyl Acetate                     -0.325601  1.005163 -1.000104  0.322205   \n",
      "Acetic Acid                       -0.007385  0.375436 -1.360039  0.959541   \n",
      "2-Methyltetrahydrofuran [2-MeTHF] -0.135662  0.869121 -1.143908  0.028430   \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  0.062699 -0.127131 -0.626010 -0.299648   \n",
      "\n",
      "                                        763       764       765       766  \\\n",
      "SOLVENT NAME                                                                \n",
      "Cyclohexane                       -1.231041 -0.469631 -1.682612  0.396521   \n",
      "Ethyl Acetate                      0.161322 -1.190839 -1.761986 -0.017609   \n",
      "Acetic Acid                        0.138111 -0.718372 -1.371684 -0.203832   \n",
      "2-Methyltetrahydrofuran [2-MeTHF] -0.943991 -0.770047 -1.662374  0.170986   \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol -0.473232 -0.836774 -0.098735 -0.419884   \n",
      "\n",
      "                                        767  \n",
      "SOLVENT NAME                                 \n",
      "Cyclohexane                        1.595592  \n",
      "Ethyl Acetate                      2.313148  \n",
      "Acetic Acid                        1.453714  \n",
      "2-Methyltetrahydrofuran [2-MeTHF]  1.723403  \n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  1.617441  \n",
      "\n",
      "[5 rows x 768 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for ChemBERTa embeddings\n",
    "CHEMBERTA_DF = pd.DataFrame(CHEMBERTA_EMBEDDINGS).T\n",
    "CHEMBERTA_DF.index.name = 'SOLVENT NAME'\n",
    "print(f'ChemBERTa DataFrame: {CHEMBERTA_DF.shape}')\n",
    "print(CHEMBERTA_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac07d573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:43.337442Z",
     "iopub.status.busy": "2026-01-15T09:09:43.337319Z",
     "iopub.status.idle": "2026-01-15T09:09:43.342690Z",
     "shell.execute_reply": "2026-01-15T09:09:43.342307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa feature dimension: 773\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa Featurizer\n",
    "class ChemBERTaFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.chemberta_df = CHEMBERTA_DF\n",
    "        # 5 kinetics features + 768 ChemBERTa features = 773 total\n",
    "        self.feats_dim = 5 + self.chemberta_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        # Kinetics features\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([temp_c, time_m, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_emb = self.chemberta_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_emb = self.chemberta_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_emb = B_emb * (1 - (1-pct)) + A_emb * (1-pct)\n",
    "            else:\n",
    "                X_emb = A_emb * (1 - pct) + B_emb * pct\n",
    "        else:\n",
    "            X_emb = self.chemberta_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_emb])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip), dtype=torch.float32)\n",
    "\n",
    "print(f'ChemBERTa feature dimension: {ChemBERTaFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5be4fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:43.343687Z",
     "iopub.status.busy": "2026-01-15T09:09:43.343573Z",
     "iopub.status.idle": "2026-01-15T09:09:43.347439Z",
     "shell.execute_reply": "2026-01-15T09:09:43.347043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa MLP model defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model for ChemBERTa embeddings\n",
    "class ChemBERTaMLP(nn.Module):\n",
    "    def __init__(self, input_dim=773, hidden_dim=256, output_dim=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "print('ChemBERTa MLP model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeacd87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:43.348331Z",
     "iopub.status.busy": "2026-01-15T09:09:43.348202Z",
     "iopub.status.idle": "2026-01-15T09:09:43.354912Z",
     "shell.execute_reply": "2026-01-15T09:09:43.354537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa model wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa Model Wrapper\n",
    "class ChemBERTaModel:\n",
    "    def __init__(self, data='single', epochs=300, lr=0.001, hidden_dim=256, dropout=0.3):\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.featurizer = ChemBERTaFeaturizer(mixed=(data == 'full'))\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        # Get features\n",
    "        features = self.featurizer.featurize(X)\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "        Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = ChemBERTaMLP(\n",
    "            input_dim=self.featurizer.feats_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=3,\n",
    "            dropout=self.dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=30, factor=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = self.model(X_tensor)\n",
    "            loss = criterion(predictions, Y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 50:\n",
    "                    break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get features\n",
    "        features = self.featurizer.featurize(X)\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        X_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X_tensor)\n",
    "        \n",
    "        # TTA for mixed solvents\n",
    "        if self.data == 'full':\n",
    "            features_flip = self.featurizer.featurize(X, flip=True)\n",
    "            features_flip_scaled = self.scaler.transform(features_flip)\n",
    "            X_flip_tensor = torch.tensor(features_flip_scaled, dtype=torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                predictions_flip = self.model(X_flip_tensor)\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        predictions = torch.clamp(predictions, 0, 1)\n",
    "        return predictions\n",
    "\n",
    "print('ChemBERTa model wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb5939e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:09:53.934828Z",
     "iopub.status.busy": "2026-01-15T09:09:53.934382Z",
     "iopub.status.idle": "2026-01-15T09:09:54.109174Z",
     "shell.execute_reply": "2026-01-15T09:09:54.108724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: X=(656, 3), Y=(656, 3)\n",
      "Test predictions shape: torch.Size([50, 3])\n",
      "Test predictions range: [0.1344, 0.5689]\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f'Single solvent data: X={X_single.shape}, Y={Y_single.shape}')\n",
    "\n",
    "# Test on a small subset\n",
    "X_test = X_single.iloc[:50]\n",
    "Y_test = Y_single.iloc[:50]\n",
    "\n",
    "model = ChemBERTaModel(data='single', epochs=50)\n",
    "model.train_model(X_test, Y_test)\n",
    "preds = model.predict(X_test)\n",
    "print(f'Test predictions shape: {preds.shape}')\n",
    "print(f'Test predictions range: [{preds.min():.4f}, {preds.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c781b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:10:04.092543Z",
     "iopub.status.busy": "2026-01-15T09:10:04.092066Z",
     "iopub.status.idle": "2026-01-15T09:10:12.470043Z",
     "shell.execute_reply": "2026-01-15T09:10:12.469646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Solvent CV (ChemBERTa) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:00<00:08,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:00<00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:01<00:07,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:01<00:07,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:01<00:06,  2.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:02<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:02<00:05,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:02<00:05,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:03<00:05,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:03<00:04,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:03<00:04,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:04<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:04<00:03,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:04<00:03,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:05<00:03,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:05<00:02,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:05<00:02,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:06<00:02,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:06<00:01,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:06<00:01,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:07<00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:07<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [00:08<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:08<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:08<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.029987 (n=656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV on single solvent data\n",
    "print('\\n=== Single Solvent CV (ChemBERTa) ===')\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "all_predictions_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = ChemBERTaModel(data='single', epochs=300, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_single.append(predictions.cpu().numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "preds_single = np.vstack(all_predictions_single)\n",
    "actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((preds_single - actuals_single) ** 2)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={len(preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a78060d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:10:22.621438Z",
     "iopub.status.busy": "2026-01-15T09:10:22.620597Z",
     "iopub.status.idle": "2026-01-15T09:10:27.272561Z",
     "shell.execute_reply": "2026-01-15T09:10:27.272079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full Data CV (ChemBERTa) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:00<00:04,  2.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [00:00<00:04,  2.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [00:01<00:03,  2.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [00:01<00:03,  2.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [00:01<00:02,  2.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [00:02<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [00:03<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [00:03<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [00:03<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [00:04<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:04<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:04<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.035375 (n=1227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV on full data\n",
    "print('\\n=== Full Data CV (ChemBERTa) ===')\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = ChemBERTaModel(data='full', epochs=300, lr=0.001)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_full.append(predictions.cpu().numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "preds_full = np.vstack(all_predictions_full)\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((preds_full - actuals_full) ** 2)\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={len(preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645c0d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:10:37.106310Z",
     "iopub.status.busy": "2026-01-15T09:10:37.105924Z",
     "iopub.status.idle": "2026-01-15T09:10:37.110343Z",
     "shell.execute_reply": "2026-01-15T09:10:37.109886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV SCORE SUMMARY (ChemBERTa) ===\n",
      "Single Solvent MSE: 0.029987 (n=656)\n",
      "Full Data MSE: 0.035375 (n=1227)\n",
      "Overall MSE: 0.033498\n",
      "\n",
      "Best CV (exp_032): 0.008194\n",
      "GNN Benchmark: 0.0039\n",
      "\n",
      "✗ WORSE: 308.81% worse than best CV\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(preds_single)\n",
    "n_full = len(preds_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE SUMMARY (ChemBERTa) ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'GNN Benchmark: 0.0039')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bab2c",
   "metadata": {},
   "source": [
    "# Hybrid ChemBERTa + Tabular Features\\n\\nThe pure ChemBERTa approach performed poorly (CV 0.033498, 308% worse than best).\\nLet's try combining ChemBERTa embeddings with the domain-specific features (Spange + DRFP + ACS PCA).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9248c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tabular feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Featurizer: ChemBERTa + Spange + DRFP + ACS PCA\n",
    "class HybridChemBERTaFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.chemberta_df = CHEMBERTA_DF\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        # 5 kinetics + 768 ChemBERTa + 13 Spange + 122 DRFP + 5 ACS PCA = 913 total\n",
    "        self.feats_dim = 5 + self.chemberta_df.shape[1] + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        # Kinetics features\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([temp_c, time_m, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            # ChemBERTa\n",
    "            A_chemberta = self.chemberta_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_chemberta = self.chemberta_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            # Spange\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            # DRFP\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            # ACS PCA\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            \n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_chemberta = B_chemberta * (1 - (1-pct)) + A_chemberta * (1-pct)\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_chemberta = A_chemberta * (1 - pct) + B_chemberta * pct\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_chemberta = self.chemberta_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_chemberta, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Hybrid feature dimension: {HybridChemBERTaFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid ChemBERTa Model Wrapper\n",
    "class HybridChemBERTaModel:\n",
    "    def __init__(self, data='single', epochs=300, lr=0.001, hidden_dim=256, dropout=0.3):\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.featurizer = HybridChemBERTaFeaturizer(mixed=(data == 'full'))\n",
    "        \n",
    "    def train_model(self, X, Y):\n",
    "        # Get features\n",
    "        features = self.featurizer.featurize(X)\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "        Y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = ChemBERTaMLP(\n",
    "            input_dim=self.featurizer.feats_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=3,\n",
    "            dropout=self.dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=30, factor=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        best_loss = float('inf')\\n        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = self.model(X_tensor)\n",
    "            loss = criterion(predictions, Y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 50:\n",
    "                    break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get features\n",
    "        features = self.featurizer.featurize(X)\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        X_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X_tensor)\n",
    "        \n",
    "        # TTA for mixed solvents\n",
    "        if self.data == 'full':\n",
    "            features_flip = self.featurizer.featurize(X, flip=True)\n",
    "            features_flip_scaled = self.scaler.transform(features_flip)\n",
    "            X_flip_tensor = torch.tensor(features_flip_scaled, dtype=torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                predictions_flip = self.model(X_flip_tensor)\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        predictions = torch.clamp(predictions, 0, 1)\n",
    "        return predictions\n",
    "\n",
    "print('Hybrid ChemBERTa model wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19df7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on single solvent data with hybrid model\n",
    "print('\\\\n=== Single Solvent CV (Hybrid ChemBERTa) ===')\\nX_single, Y_single = load_data(\\\"single_solvent\\\")\\n\\nsplit_generator = generate_leave_one_out_splits(X_single, Y_single)\\nall_predictions_single_hybrid = []\\nall_actuals_single_hybrid = []\\n\\nfor fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\\n    (train_X, train_Y), (test_X, test_Y) = split\\n    \\n    model = HybridChemBERTaModel(data='single', epochs=300, lr=0.001)\\n    model.train_model(train_X, train_Y)\\n    predictions = model.predict(test_X)\\n    \\n    all_predictions_single_hybrid.append(predictions.cpu().numpy())\\n    all_actuals_single_hybrid.append(test_Y.values)\\n\\npreds_single_hybrid = np.vstack(all_predictions_single_hybrid)\\nactuals_single_hybrid = np.vstack(all_actuals_single_hybrid)\\nmse_single_hybrid = np.mean((preds_single_hybrid - actuals_single_hybrid) ** 2)\\nprint(f'Single Solvent MSE (Hybrid): {mse_single_hybrid:.6f} (n={len(preds_single_hybrid)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6675f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV on full data with hybrid model\n",
    "print('\\\\n=== Full Data CV (Hybrid ChemBERTa) ===')\\nX_full, Y_full = load_data(\\\"full\\\")\\n\\nsplit_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\\nall_predictions_full_hybrid = []\\nall_actuals_full_hybrid = []\\n\\nfor fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\\n    (train_X, train_Y), (test_X, test_Y) = split\\n    \\n    model = HybridChemBERTaModel(data='full', epochs=300, lr=0.001)\\n    model.train_model(train_X, train_Y)\\n    predictions = model.predict(test_X)\\n    \\n    all_predictions_full_hybrid.append(predictions.cpu().numpy())\\n    all_actuals_full_hybrid.append(test_Y.values)\\n\\npreds_full_hybrid = np.vstack(all_predictions_full_hybrid)\\nactuals_full_hybrid = np.vstack(all_actuals_full_hybrid)\\nmse_full_hybrid = np.mean((preds_full_hybrid - actuals_full_hybrid) ** 2)\\nprint(f'Full Data MSE (Hybrid): {mse_full_hybrid:.6f} (n={len(preds_full_hybrid)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31291aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ChemBERTaModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246abaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb624572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification\n",
    "print(f'\\n=== FINAL CV SCORE ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'GNN Benchmark: 0.0039')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
