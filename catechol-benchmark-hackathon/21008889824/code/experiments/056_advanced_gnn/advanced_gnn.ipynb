{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8af3dc6",
   "metadata": {},
   "source": [
    "# Advanced GNN with GAT and Proper Mixture Handling\n",
    "\n",
    "**Hypothesis**: Our previous GNN (CV 0.01408) was 3.6x worse than the benchmark (CV 0.0039). Key improvements:\n",
    "1. Use GATConv (Graph Attention) instead of GCNConv\n",
    "2. Properly handle mixtures: encode BOTH solvent graphs, combine with attention\n",
    "3. Add edge features (bond types)\n",
    "4. Use attention-based pooling (GlobalAttention)\n",
    "5. Increase model capacity and train longer\n",
    "\n",
    "**Target**: Achieve CV < 0.006 (would predict LB ≈ 0.079)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8b359b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:44.395118Z",
     "iopub.status.busy": "2026-01-15T13:24:44.394627Z",
     "iopub.status.idle": "2026-01-15T13:24:46.744492Z",
     "shell.execute_reply": "2026-01-15T13:24:46.744055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "from torch_geometric.nn import GATConv, GlobalAttention, global_mean_pool\n",
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd0e677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.745734Z",
     "iopub.status.busy": "2026-01-15T13:24:46.745560Z",
     "iopub.status.idle": "2026-01-15T13:24:46.750098Z",
     "shell.execute_reply": "2026-01-15T13:24:46.749752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd4be2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.750923Z",
     "iopub.status.busy": "2026-01-15T13:24:46.750829Z",
     "iopub.status.idle": "2026-01-15T13:24:46.857227Z",
     "shell.execute_reply": "2026-01-15T13:24:46.856855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: (26, 1)\n",
      "Pre-computed graphs for 26 solvents\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup and pre-compute graphs\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {SMILES_DF.shape}')\n",
    "\n",
    "# Pre-compute graph data for all solvents\n",
    "SOLVENT_GRAPHS = {}\n",
    "for solvent in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent, 'solvent smiles']\n",
    "    # Handle mixture solvents (e.g., \"Water.Acetonitrile\")\n",
    "    if '.' in smiles:\n",
    "        parts = smiles.split('.')\n",
    "        graphs = [from_smiles(s) for s in parts]\n",
    "        SOLVENT_GRAPHS[solvent] = graphs\n",
    "    else:\n",
    "        SOLVENT_GRAPHS[solvent] = from_smiles(smiles)\n",
    "\n",
    "print(f'Pre-computed graphs for {len(SOLVENT_GRAPHS)} solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320498d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.858797Z",
     "iopub.status.busy": "2026-01-15T13:24:46.858428Z",
     "iopub.status.idle": "2026-01-15T13:24:46.863070Z",
     "shell.execute_reply": "2026-01-15T13:24:46.862734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT Encoder defined\n"
     ]
    }
   ],
   "source": [
    "# Advanced GAT-based GNN Encoder\n",
    "class GATEncoder(nn.Module):\n",
    "    \"\"\"Graph Attention Network encoder for molecular graphs.\"\"\"\n",
    "    def __init__(self, node_features=9, hidden_dim=64, output_dim=64, heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Multi-head attention layers\n",
    "        self.conv1 = GATConv(node_features, hidden_dim, heads=heads, concat=True, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=True, dropout=dropout)\n",
    "        self.conv3 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim * heads)\n",
    "        \n",
    "        # Attention-based pooling\n",
    "        gate_nn = nn.Sequential(\n",
    "            nn.Linear(output_dim, output_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim // 2, 1)\n",
    "        )\n",
    "        self.pool = GlobalAttention(gate_nn)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # First GAT layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        # Third GAT layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        # Attention-based pooling\n",
    "        x = self.pool(x, batch)\n",
    "        return x\n",
    "\n",
    "print('GAT Encoder defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2d14f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.863921Z",
     "iopub.status.busy": "2026-01-15T13:24:46.863826Z",
     "iopub.status.idle": "2026-01-15T13:24:46.869586Z",
     "shell.execute_reply": "2026-01-15T13:24:46.869205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced GNN Model defined\n"
     ]
    }
   ],
   "source": [
    "# Advanced GNN Model with proper mixture handling\n",
    "class AdvancedGNNModel(nn.Module):\n",
    "    \"\"\"Advanced GNN model with GAT encoder and proper mixture handling.\"\"\"\n",
    "    def __init__(self, node_features=9, hidden_dim=64, graph_dim=64, output_dim=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gnn = GATEncoder(node_features, hidden_dim, graph_dim, heads=4, dropout=dropout)\n",
    "        \n",
    "        # Mixture attention: learn to combine two solvent embeddings\n",
    "        self.mixture_attention = nn.Sequential(\n",
    "            nn.Linear(graph_dim * 2 + 1, graph_dim),  # +1 for mixture percentage\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(graph_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Condition encoder (temperature, time, kinetics)\n",
    "        self.condition_encoder = nn.Sequential(\n",
    "            nn.Linear(5, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        # Final prediction head\n",
    "        self.fc1 = nn.Linear(graph_dim + 32, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        \n",
    "    def forward(self, graph_data, conditions, graph_data_b=None, mixture_pct=None):\n",
    "        # Encode primary solvent graph\n",
    "        graph_emb_a = self.gnn(graph_data.x, graph_data.edge_index, graph_data.batch)\n",
    "        \n",
    "        if graph_data_b is not None and mixture_pct is not None:\n",
    "            # Encode secondary solvent graph\n",
    "            graph_emb_b = self.gnn(graph_data_b.x, graph_data_b.edge_index, graph_data_b.batch)\n",
    "            \n",
    "            # Compute attention weights for mixture\n",
    "            mixture_input = torch.cat([graph_emb_a, graph_emb_b, mixture_pct], dim=1)\n",
    "            attention_weights = self.mixture_attention(mixture_input)\n",
    "            \n",
    "            # Weighted combination of embeddings\n",
    "            graph_emb = attention_weights[:, 0:1] * graph_emb_a + attention_weights[:, 1:2] * graph_emb_b\n",
    "        else:\n",
    "            graph_emb = graph_emb_a\n",
    "        \n",
    "        # Encode conditions\n",
    "        cond_emb = self.condition_encoder(conditions)\n",
    "        \n",
    "        # Combine and predict\n",
    "        x = torch.cat([graph_emb, cond_emb], dim=1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "print('Advanced GNN Model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184fa675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.870488Z",
     "iopub.status.busy": "2026-01-15T13:24:46.870387Z",
     "iopub.status.idle": "2026-01-15T13:24:46.881522Z",
     "shell.execute_reply": "2026-01-15T13:24:46.880860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced GNN Wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Advanced GNN Model Wrapper\n",
    "class AdvancedGNNWrapper:\n",
    "    def __init__(self, data='single', epochs=500, lr=0.001, hidden_dim=64, graph_dim=64, dropout=0.2):\n",
    "        self.data = data\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.graph_dim = graph_dim\n",
    "        self.dropout = dropout\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def _get_conditions(self, X):\n",
    "        \"\"\"Extract and transform condition features.\"\"\"\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        return np.hstack([temp_c, time_m, inv_temp, log_time, interaction])\n",
    "    \n",
    "    def _get_graph(self, solvent_name):\n",
    "        \"\"\"Get graph for a solvent, handling mixtures.\"\"\"\n",
    "        g = SOLVENT_GRAPHS.get(solvent_name)\n",
    "        if g is None or isinstance(g, list):\n",
    "            # Fallback for unknown or mixture solvents\n",
    "            g = from_smiles('C')  # Methane as fallback\n",
    "        return Data(x=g.x.float(), edge_index=g.edge_index)\n",
    "    \n",
    "    def _get_graph_batch(self, X):\n",
    "        \"\"\"Create batches of graphs.\"\"\"\n",
    "        if self.data == 'single':\n",
    "            graphs = [self._get_graph(row[\"SOLVENT NAME\"]) for _, row in X.iterrows()]\n",
    "            return Batch.from_data_list(graphs), None, None\n",
    "        else:\n",
    "            graphs_a = [self._get_graph(row[\"SOLVENT A NAME\"]) for _, row in X.iterrows()]\n",
    "            graphs_b = [self._get_graph(row[\"SOLVENT B NAME\"]) for _, row in X.iterrows()]\n",
    "            mixture_pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            return Batch.from_data_list(graphs_a), Batch.from_data_list(graphs_b), mixture_pct\n",
    "    \n",
    "    def train_model(self, X, Y):\n",
    "        \"\"\"Train the advanced GNN model.\"\"\"\n",
    "        # Get conditions\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.fit_transform(conditions)\n",
    "        \n",
    "        # Get graph batches\n",
    "        graph_batch_a, graph_batch_b, mixture_pct = self._get_graph_batch(X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        conditions_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(Y.values, dtype=torch.float32).to(device)\n",
    "        graph_batch_a = graph_batch_a.to(device)\n",
    "        if graph_batch_b is not None:\n",
    "            graph_batch_b = graph_batch_b.to(device)\n",
    "            mixture_pct_tensor = torch.tensor(mixture_pct, dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            mixture_pct_tensor = None\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = AdvancedGNNModel(\n",
    "            node_features=9,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            graph_dim=self.graph_dim,\n",
    "            output_dim=3,\n",
    "            dropout=self.dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = self.model(graph_batch_a, conditions_tensor, graph_batch_b, mixture_pct_tensor)\n",
    "            loss = criterion(predictions, y_tensor)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Early stopping\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 100:\n",
    "                    break\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get conditions\n",
    "        conditions = self._get_conditions(X)\n",
    "        conditions_scaled = self.scaler.transform(conditions)\n",
    "        \n",
    "        # Get graph batches\n",
    "        graph_batch_a, graph_batch_b, mixture_pct = self._get_graph_batch(X)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        conditions_tensor = torch.tensor(conditions_scaled, dtype=torch.float32).to(device)\n",
    "        graph_batch_a = graph_batch_a.to(device)\n",
    "        if graph_batch_b is not None:\n",
    "            graph_batch_b = graph_batch_b.to(device)\n",
    "            mixture_pct_tensor = torch.tensor(mixture_pct, dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            mixture_pct_tensor = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(graph_batch_a, conditions_tensor, graph_batch_b, mixture_pct_tensor)\n",
    "        \n",
    "        # TTA for mixtures (flip A and B)\n",
    "        if self.data == 'full':\n",
    "            # Swap A and B\n",
    "            graphs_b = [self._get_graph(row[\"SOLVENT A NAME\"]) for _, row in X.iterrows()]\n",
    "            graphs_a = [self._get_graph(row[\"SOLVENT B NAME\"]) for _, row in X.iterrows()]\n",
    "            graph_batch_a_flip = Batch.from_data_list(graphs_a).to(device)\n",
    "            graph_batch_b_flip = Batch.from_data_list(graphs_b).to(device)\n",
    "            mixture_pct_flip = 1.0 - mixture_pct\n",
    "            mixture_pct_flip_tensor = torch.tensor(mixture_pct_flip, dtype=torch.float32).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predictions_flip = self.model(graph_batch_a_flip, conditions_tensor, graph_batch_b_flip, mixture_pct_flip_tensor)\n",
    "            predictions = (predictions + predictions_flip) / 2\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        predictions = torch.clamp(predictions, 0, 1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "print('Advanced GNN Wrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44109a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:24:46.882445Z",
     "iopub.status.busy": "2026-01-15T13:24:46.882330Z",
     "iopub.status.idle": "2026-01-15T13:24:47.846924Z",
     "shell.execute_reply": "2026-01-15T13:24:47.846492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: X=(656, 3), Y=(656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: torch.Size([50, 3])\n",
      "Test predictions range: [0.1308, 0.8841]\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "print(f'Single solvent data: X={X_single.shape}, Y={Y_single.shape}')\n",
    "\n",
    "# Test on a small subset\n",
    "X_test = X_single.iloc[:50]\n",
    "Y_test = Y_single.iloc[:50]\n",
    "\n",
    "model = AdvancedGNNWrapper(data='single', epochs=100)\n",
    "model.train_model(X_test, Y_test)\n",
    "preds = model.predict(X_test)\n",
    "print(f'Test predictions shape: {preds.shape}')\n",
    "print(f'Test predictions range: [{preds.min():.4f}, {preds.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d14ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:25:01.493992Z",
     "iopub.status.busy": "2026-01-15T13:25:01.493462Z",
     "iopub.status.idle": "2026-01-15T13:26:04.314684Z",
     "shell.execute_reply": "2026-01-15T13:26:04.314304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Single Solvent CV (Advanced GNN) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:02<01:01,  2.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:05<00:57,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:07<00:54,  2.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:10<00:52,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:13<00:49,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:15<00:47,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:18<00:44,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:20<00:41,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:23<00:39,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:26<00:36,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:28<00:34,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:31<00:31,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:34<00:28,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:36<00:26,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:39<00:23,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:41<00:20,  2.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:44<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:46<00:15,  2.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:49<00:12,  2.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:52<00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:54<00:07,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:57<00:05,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [01:00<00:02,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [01:02<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [01:02<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Solvent MSE: 0.016986 (n=656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV on single solvent data\n",
    "print('\\n=== Single Solvent CV (Advanced GNN) ===')\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X_single, Y_single)\n",
    "all_predictions_single = []\n",
    "all_actuals_single = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = AdvancedGNNWrapper(data='single', epochs=500, lr=0.001, hidden_dim=64, graph_dim=64)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_single.append(predictions.cpu().numpy())\n",
    "    all_actuals_single.append(test_Y.values)\n",
    "\n",
    "preds_single = np.vstack(all_predictions_single)\n",
    "actuals_single = np.vstack(all_actuals_single)\n",
    "mse_single = np.mean((preds_single - actuals_single) ** 2)\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={len(preds_single)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6603d42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:26:16.283903Z",
     "iopub.status.busy": "2026-01-15T13:26:16.283393Z",
     "iopub.status.idle": "2026-01-15T13:27:18.937992Z",
     "shell.execute_reply": "2026-01-15T13:27:18.937602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full Data CV (Advanced GNN) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:04<00:57,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [00:09<00:52,  4.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [00:14<00:47,  4.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [00:19<00:43,  4.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [00:23<00:38,  4.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [00:28<00:33,  4.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [00:33<00:28,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [00:38<00:24,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [00:43<00:19,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [00:48<00:14,  4.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [00:52<00:09,  4.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [00:57<00:04,  4.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [01:02<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [01:02<00:00,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data MSE: 0.036978 (n=1227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV on full data\n",
    "print('\\n=== Full Data CV (Advanced GNN) ===')\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X_full, Y_full)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = AdvancedGNNWrapper(data='full', epochs=500, lr=0.001, hidden_dim=64, graph_dim=64)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    all_predictions_full.append(predictions.cpu().numpy())\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "preds_full = np.vstack(all_predictions_full)\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "mse_full = np.mean((preds_full - actuals_full) ** 2)\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={len(preds_full)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(preds_single)\n",
    "n_full = len(preds_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE SUMMARY (Advanced GNN) ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'Previous GNN (exp_051): 0.01408')\n",
    "print(f'GNN Benchmark: 0.0039')\n",
    "\n",
    "if overall_mse < 0.008194:\n",
    "    improvement = (0.008194 - overall_mse) / 0.008194 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008194) / 0.008194 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = AdvancedGNNWrapper(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9497f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = AdvancedGNNWrapper(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification\n",
    "print(f'\\n=== FINAL CV SCORE ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest CV (exp_032): 0.008194')\n",
    "print(f'Previous GNN (exp_051): 0.01408')\n",
    "print(f'GNN Benchmark: 0.0039')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
