## Current Status
- Best CV score: 0.008465 from exp_026 (weighted loss MLP+LGBM ensemble)
- Best LB score: 0.0887 from exp_026
- CV-LB gap: ~10x (LB = 4.22*CV + 0.0533, R²=0.96)
- Target: 0.01727
- Gap to target: 5.14x
- Submissions remaining: 3

## Response to Evaluator

**Technical verdict was TRUSTWORTHY.** The evaluator correctly identified that exp_029 (normalization) was a well-executed experiment that disproved a hypothesis. The 91% worse CV is a valid negative result.

**Evaluator's top priority: Try Gaussian Process Regression.** I STRONGLY AGREE. The evaluator correctly notes:
1. GPs are explicitly mentioned in the competition description ("imputing any missing values using a multi-task GP")
2. GPs have fundamentally different inductive biases than neural networks
3. GPs work well with small datasets and provide uncertainty estimates
4. This is a qualitatively different approach that might break the CV-LB pattern

**Key concerns raised:**
1. The CV-LB gap remains unsolved (intercept 0.0533 > target 0.01727)
2. Only 3 submissions remaining
3. DO NOT SUBMIT exp_029 (91% worse)

**How I'm addressing these:**
- Prioritizing GP as a fundamentally different approach
- Also recommending aggressive feature selection to reduce overfitting
- Will only submit if we see fundamentally different behavior

## Data Understanding

**Reference notebooks:**
- `exploration/evolver_loop30_analysis.ipynb` - Current analysis
- `exploration/evolver_loop27_analysis.ipynb` - CV-LB relationship analysis
- `exploration/eda.ipynb` - Initial EDA

**Key patterns discovered:**
1. **Targets do NOT sum to 1.0**: Single Solvent mean=0.7955, Full Data mean=0.8035, range [0.03, 1.12]
   - This invalidates any normalization constraint approach
2. **CV-LB gap is systematic**: ~10x ratio, ~0.08 additive gap
   - Linear fit: LB = 4.22*CV + 0.0533
   - Intercept (0.0533) > target (0.01727) - mathematically impossible to reach target with current approach
3. **Our CV is 2x BETTER than target LB**: CV 0.008465 vs target 0.01727
   - The problem is NOT model quality, it's the CV-LB relationship
4. **SM target is hardest**: 2x worse MSE than Products (0.012 vs 0.006)
   - Weighted loss [1,1,2] helped but didn't solve the gap

**Critical insight from kernel analysis:**
- The "mixall" kernel uses **GroupKFold(5)** instead of Leave-One-Out CV
- This may better match the LB evaluation scheme
- Could explain part of the CV-LB gap

## Recommended Approaches

### PRIORITY 1: Gaussian Process Regression
**Why:** Competition explicitly mentions GPs. Different inductive bias may break CV-LB pattern. Works well with small datasets.

**Implementation:**
```python
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern

# Use Matern kernel (more flexible than RBF)
kernel = 1.0 * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)

# Multi-output: train 3 separate GPs (one per target)
gp_models = [GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, normalize_y=True) 
             for _ in range(3)]
```

**Features to use:** Start with simpler features (Spange + Arrhenius kinetics = ~18 features) to avoid GP scaling issues.

### PRIORITY 2: Aggressive Feature Selection + Ridge
**Why:** 145 features may cause overfitting. Simpler models may generalize better.

**Implementation:**
1. Use LightGBM feature importance to select top 20-30 features
2. Train Ridge regression on selected features
3. May have different CV-LB relationship

### PRIORITY 3: GP + MLP + LGBM Ensemble
**Why:** Combine different model types for diversity.

**Implementation:**
- GP provides different predictions than NN/tree models
- Weight GP predictions in ensemble
- May improve generalization

## What NOT to Try

1. **Normalization constraints** - PROVEN WRONG. Targets don't sum to 1.0.
2. **More complex architectures** - Already failed (exp_004 was 5x worse)
3. **More models in ensemble** - Diminishing returns (exp_028 was worse than exp_026)
4. **Higher SM weights** - Already tried [1,1,2], marginal improvement

## Validation Notes

**CV scheme:** Leave-one-solvent-out for single solvents (24 folds), leave-one-ramp-out for mixtures (13 folds)

**CV-LB calibration:**
- Linear fit: LB = 4.22*CV + 0.0533 (R²=0.96)
- Intercept 0.0533 > target 0.01727
- Need to fundamentally change the CV-LB relationship, not just improve CV

**Submission strategy:**
- Only submit if GP shows fundamentally different behavior
- 3 submissions remaining - be strategic
- Look for approaches that reduce the CV-LB gap, not just improve CV

## Key Insight

**The problem is NOT model quality - our CV is already 2x better than the target LB.**

The problem is the CV-LB relationship. We need an approach that:
1. Has different inductive bias (GP vs NN)
2. May have different CV-LB relationship
3. Generalizes better to unseen data

Gaussian Process Regression is the most promising unexplored approach because:
- Explicitly mentioned in competition description
- Different mathematical framework than NNs
- Works well with small datasets
- May have different generalization properties