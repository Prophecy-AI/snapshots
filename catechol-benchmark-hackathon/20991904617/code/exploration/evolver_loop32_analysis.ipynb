{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e37778",
   "metadata": {},
   "source": [
    "# Loop 32 Analysis: CatBoost RFE & Logit Transform\n",
    "\n",
    "**Objective**:\n",
    "1. Analyze why exp_031 (CatBoost Top 10) performed 18% worse than baseline.\n",
    "2. Test the Evaluator's suggestion: **Logit Transform** of targets.\n",
    "3. Determine if \"Top 10\" was too aggressive and if Top 20 is better.\n",
    "\n",
    "**Hypothesis**:\n",
    "- exp_031 underfitted due to lack of features.\n",
    "- Logit transform will handle [0,1] bounds better and might improve CV even with fewer features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "# Load data\n",
    "DATA_PATH = '/home/data'\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "\n",
    "# Load Spange for feature testing\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Load predictions\n",
    "# exp_026 (Baseline) - I need to find where its predictions are. \n",
    "# Usually in /home/submission/submission.csv if it was the last one, but exp_031 overwrote it.\n",
    "# I might not have exp_026 predictions saved on disk unless I explicitly saved them.\n",
    "# But I can re-run a quick validation of exp_031 since I have the code.\n",
    "\n",
    "print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304be023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logit Transform Helper\n",
    "def to_logit(y, clip_eps=1e-4):\n",
    "    # Clip to avoid inf\n",
    "    y_clipped = np.clip(y, clip_eps, 1 - clip_eps)\n",
    "    return np.log(y_clipped / (1 - y_clipped))\n",
    "\n",
    "def from_logit(y_logit):\n",
    "    return expit(y_logit)\n",
    "\n",
    "# Check distribution of targets\n",
    "targets = ['Product 2', 'Product 3', 'SM']\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, t in enumerate(targets):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.histplot(df_full[t], bins=50)\n",
    "    plt.title(f'{t} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check Logit distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, t in enumerate(targets):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    y_log = to_logit(df_full[t])\n",
    "    sns.histplot(y_log, bins=50)\n",
    "    plt.title(f'Logit({t}) Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Test: CatBoost with Logit Transform vs Raw\n",
    "# Using Single Solvent data (faster) and LOO split for a few folds\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "\n",
    "def get_features(df, spange_indices=None):\n",
    "    # Basic kinetic features\n",
    "    time = pd.to_numeric(df[\"Residence Time\"], errors='coerce').values\n",
    "    temp = pd.to_numeric(df[\"Temperature\"], errors='coerce').values\n",
    "    \n",
    "    temp_k = temp + 273.15\n",
    "    inv_temp = 1000.0 / temp_k\n",
    "    log_time = np.log(time + 1e-6)\n",
    "    interaction = inv_temp * log_time\n",
    "    \n",
    "    X_kinetic = np.column_stack([time, temp, inv_temp, interaction])\n",
    "    \n",
    "    # Spange features\n",
    "    # The error is likely in SPANGE_DF loading or indexing.\n",
    "    # Let's bypass the complex lookup and just use a simple map\n",
    "    \n",
    "    # Create a dictionary map first\n",
    "    spange_map = {}\n",
    "    for idx, row in SPANGE_DF.iterrows():\n",
    "        spange_map[idx] = row.values.astype(float)\n",
    "        \n",
    "    spange_vals_list = []\n",
    "    for solvent in df[\"SOLVENT NAME\"]:\n",
    "        if solvent in spange_map:\n",
    "            vals = spange_map[solvent]\n",
    "            if spange_indices is not None:\n",
    "                vals = vals[spange_indices]\n",
    "            spange_vals_list.append(vals)\n",
    "        else:\n",
    "            # Should not happen but handle it\n",
    "            print(f\"Missing solvent: {solvent}\")\n",
    "            spange_vals_list.append(np.zeros(13 if spange_indices is None else len(spange_indices)))\n",
    "            \n",
    "    spange_vals = np.array(spange_vals_list)\n",
    "        \n",
    "    return np.hstack([X_kinetic, spange_vals])\n",
    "\n",
    "# Setup data\n",
    "X = df_single.copy()\n",
    "Y = df_single[targets].copy()\n",
    "\n",
    "# Top 10 indices (from exp_031)\n",
    "top10_indices = [1, 2, 4, 7, 8, 11] \n",
    "\n",
    "# Prepare features\n",
    "print(\"Preparing features...\")\n",
    "try:\n",
    "    X_feat_top10 = get_features(X, top10_indices)\n",
    "    X_feat_all = get_features(X, None)\n",
    "except Exception as e:\n",
    "    print(f\"Error in feature prep: {e}\")\n",
    "    # Fallback to random if this still fails (it shouldn't)\n",
    "    X_feat_top10 = np.random.rand(len(X), 10)\n",
    "    X_feat_all = np.random.rand(len(X), 17)\n",
    "    print(\"USING RANDOM FEATURES DUE TO ERROR\")\n",
    "\n",
    "print(f\"Top 10 Feat Shape: {X_feat_top10.shape}\")\n",
    "print(f\"All Feat Shape: {X_feat_all.shape}\")\n",
    "\n",
    "# Run a quick CV (first 5 solvents) to compare approaches\n",
    "solvents = sorted(X[\"SOLVENT NAME\"].unique())[:5] # Test on 5 solvents\n",
    "print(f\"Testing on {len(solvents)} solvents...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for solvent in solvents:\n",
    "    mask_test = X[\"SOLVENT NAME\"] == solvent\n",
    "    mask_train = ~mask_test\n",
    "    \n",
    "    X_train_10, Y_train = X_feat_top10[mask_train], Y[mask_train]\n",
    "    X_test_10, Y_test = X_feat_top10[mask_test], Y[mask_test]\n",
    "    \n",
    "    X_train_all = X_feat_all[mask_train]\n",
    "    X_test_all = X_feat_all[mask_test]\n",
    "    \n",
    "    # 1. Raw Target + Top 10 (exp_031 style)\n",
    "    model_raw = CatBoostRegressor(iterations=100, verbose=0, loss_function='RMSE', allow_writing_files=False)\n",
    "    preds_raw = []\n",
    "    for i in range(3):\n",
    "        model_raw.fit(X_train_10, Y_train.iloc[:, i])\n",
    "        preds_raw.append(model_raw.predict(X_test_10))\n",
    "    preds_raw = np.column_stack(preds_raw)\n",
    "    mse_raw = np.mean((Y_test.values - preds_raw)**2)\n",
    "    \n",
    "    # 2. Logit Target + Top 10\n",
    "    model_logit = CatBoostRegressor(iterations=100, verbose=0, loss_function='RMSE', allow_writing_files=False)\n",
    "    preds_logit = []\n",
    "    for i in range(3):\n",
    "        y_tr_logit = to_logit(Y_train.iloc[:, i].values)\n",
    "        model_logit.fit(X_train_10, y_tr_logit)\n",
    "        p_logit = model_logit.predict(X_test_10)\n",
    "        preds_logit.append(from_logit(p_logit))\n",
    "    preds_logit = np.column_stack(preds_logit)\n",
    "    mse_logit = np.mean((Y_test.values - preds_logit)**2)\n",
    "    \n",
    "    # 3. Logit Target + All Features\n",
    "    model_logit_all = CatBoostRegressor(iterations=100, verbose=0, loss_function='RMSE', allow_writing_files=False)\n",
    "    preds_logit_all = []\n",
    "    for i in range(3):\n",
    "        y_tr_logit = to_logit(Y_train.iloc[:, i].values)\n",
    "        model_logit_all.fit(X_train_all, y_tr_logit)\n",
    "        p_logit = model_logit_all.predict(X_test_all)\n",
    "        preds_logit_all.append(from_logit(p_logit))\n",
    "    preds_logit_all = np.column_stack(preds_logit_all)\n",
    "    mse_logit_all = np.mean((Y_test.values - preds_logit_all)**2)\n",
    "\n",
    "    results.append({\n",
    "        'solvent': solvent,\n",
    "        'mse_raw_top10': mse_raw,\n",
    "        'mse_logit_top10': mse_logit,\n",
    "        'mse_logit_all': mse_logit_all\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(\"\\nResults (MSE):\")\n",
    "print(res_df.mean())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
