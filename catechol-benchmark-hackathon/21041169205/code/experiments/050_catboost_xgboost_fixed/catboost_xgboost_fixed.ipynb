{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b091d110",
   "metadata": {},
   "source": [
    "# Experiment 050: CatBoost + XGBoost Ensemble (FIXED CV Scheme)\n",
    "\n",
    "**Goal:** Fix the submission bug from exp_049 by using the CORRECT CV scheme:\n",
    "- Single solvent: Leave-one-solvent-out (24 folds) ✓\n",
    "- Full data: Leave-one-solvent-PAIR-out (13 folds) ✗ (was 87 RAMP NUM folds)\n",
    "\n",
    "**The Bug:** exp_049 used RAMP NUM (87 folds) instead of solvent PAIRS (13 folds) for full data CV.\n",
    "\n",
    "**The Fix:** Use the official `generate_leave_one_ramp_out_splits` function which splits by solvent PAIRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71eb6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:49:00.469847Z",
     "iopub.status.busy": "2026-01-15T21:49:00.469378Z",
     "iopub.status.idle": "2026-01-15T21:49:01.904824Z",
     "shell.execute_reply": "2026-01-15T21:49:01.904375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent: X=(656, 3), Y=(656, 3)\n",
      "Full data: X=(1227, 5), Y=(1227, 3)\n",
      "\n",
      "Single solvent folds: 24\n",
      "Full data folds (solvent PAIRS): 13\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "\n",
    "# Define constants\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"\n",
    "]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_FEATURES = [\"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "# Data loading functions\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "def load_data_local(name=\"full\"):\n",
    "    \"\"\"Load dataset.\"\"\"\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features_local(name=\"spange_descriptors\"):\n",
    "    \"\"\"Load feature lookup table.\"\"\"\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# OFFICIAL CV FUNCTIONS (from utils.py)\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvents (24 folds).\"\"\"\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvent PAIRS (13 folds).\n",
    "    \n",
    "    CRITICAL: This splits by solvent PAIRS (SOLVENT A NAME, SOLVENT B NAME),\n",
    "    NOT by RAMP NUM!\n",
    "    \"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).any(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single = load_data_local(\"single_solvent\")\n",
    "X_full, Y_full = load_data_local(\"full\")\n",
    "\n",
    "print(f\"Single solvent: X={X_single.shape}, Y={Y_single.shape}\")\n",
    "print(f\"Full data: X={X_full.shape}, Y={Y_full.shape}\")\n",
    "\n",
    "# Count folds\n",
    "print(f\"\\nSingle solvent folds: {len(X_single['SOLVENT NAME'].unique())}\")\n",
    "print(f\"Full data folds (solvent PAIRS): {len(X_full[['SOLVENT A NAME', 'SOLVENT B NAME']].drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0988527e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:49:01.906024Z",
     "iopub.status.busy": "2026-01-15T21:49:01.905916Z",
     "iopub.status.idle": "2026-01-15T21:49:01.912377Z",
     "shell.execute_reply": "2026-01-15T21:49:01.911968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering functions from ens-model kernel\n",
    "\n",
    "def feature_priority(name: str) -> int:\n",
    "    \"\"\"Assign priority score to feature name based on prefix.\"\"\"\n",
    "    if name.startswith(\"spange_\"):\n",
    "        return 5\n",
    "    if name.startswith(\"acs_\"):\n",
    "        return 4\n",
    "    if name.startswith(\"drfps_\"):\n",
    "        return 3\n",
    "    if name.startswith(\"frag_\"):\n",
    "        return 2\n",
    "    if name.startswith(\"smiles_\"):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def filter_correlated_features(df: pd.DataFrame, threshold: float = 0.90):\n",
    "    \"\"\"Drop columns that are highly correlated.\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if numeric_df.shape[1] == 0:\n",
    "        return df, []\n",
    "    \n",
    "    # Drop constant columns first\n",
    "    std = numeric_df.std(axis=0)\n",
    "    constant_cols = std[std == 0].index.tolist()\n",
    "    if constant_cols:\n",
    "        numeric_df = numeric_df.drop(columns=constant_cols)\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr = numeric_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)).fillna(0.0)\n",
    "    \n",
    "    cols = upper.columns.tolist()\n",
    "    to_drop = set()\n",
    "    \n",
    "    # Find high correlation pairs\n",
    "    for i, col_i in enumerate(cols):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            col_j = cols[j]\n",
    "            cval = upper.iloc[i, j]\n",
    "            if cval > threshold:\n",
    "                if col_i in to_drop or col_j in to_drop:\n",
    "                    continue\n",
    "                p_i = feature_priority(col_i)\n",
    "                p_j = feature_priority(col_j)\n",
    "                if p_i > p_j:\n",
    "                    to_drop.add(col_j)\n",
    "                elif p_j > p_i:\n",
    "                    to_drop.add(col_i)\n",
    "                else:\n",
    "                    idx_i = df.columns.get_loc(col_i) if col_i in df.columns else 999\n",
    "                    idx_j = df.columns.get_loc(col_j) if col_j in df.columns else 999\n",
    "                    to_drop.add(col_i if idx_i > idx_j else col_j)\n",
    "    \n",
    "    all_to_drop = list(set(constant_cols).union(to_drop))\n",
    "    df_filtered = df.drop(columns=all_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    return df_filtered, all_to_drop\n",
    "\n",
    "def add_numeric_features(X_numeric: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add engineered numeric features.\"\"\"\n",
    "    X_num = X_numeric.copy()\n",
    "    cols = set(X_num.columns)\n",
    "    \n",
    "    if {\"Temperature\", \"Residence Time\"} <= cols:\n",
    "        # Convert Temperature to Kelvin\n",
    "        X_num[\"Temperature\"] = X_num[\"Temperature\"] + 273.15\n",
    "        \n",
    "        T = X_num[\"Temperature\"]\n",
    "        rt = X_num[\"Residence Time\"]\n",
    "        \n",
    "        # Interaction term\n",
    "        X_num[\"T_x_RT\"] = T * rt\n",
    "        \n",
    "        # Log transformation\n",
    "        X_num[\"RT_log\"] = np.log(rt + 1e-6)\n",
    "        \n",
    "        # Inverse temperature\n",
    "        X_num[\"T_inv\"] = 1 / T\n",
    "        \n",
    "        # Scaled residence time\n",
    "        X_num[\"RT_scaled\"] = rt / rt.mean()\n",
    "    \n",
    "    return X_num\n",
    "\n",
    "print(\"Feature engineering functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd93c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:49:01.913279Z",
     "iopub.status.busy": "2026-01-15T21:49:01.913177Z",
     "iopub.status.idle": "2026-01-15T21:49:02.030135Z",
     "shell.execute_reply": "2026-01-15T21:49:02.029768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features before filtering: (26, 115)\n",
      "Combined features after filtering: (26, 68)\n",
      "Dropped 47 columns\n",
      "\n",
      "Final solvent table shape: (26, 68)\n"
     ]
    }
   ],
   "source": [
    "# Build combined solvent feature table\n",
    "\n",
    "def build_solvent_feature_table(threshold: float = 0.90):\n",
    "    \"\"\"Build combined solvent feature table from multiple sources.\"\"\"\n",
    "    sources = [\n",
    "        \"spange_descriptors\",\n",
    "        \"acs_pca_descriptors\",\n",
    "        \"drfps_catechol\",\n",
    "        \"fragprints\",\n",
    "        \"smiles\",\n",
    "    ]\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for src in sources:\n",
    "        df_src = load_features_local(src).copy()\n",
    "        \n",
    "        if \"SOLVENT NAME\" not in df_src.columns:\n",
    "            df_src = df_src.reset_index().rename(columns={\"index\": \"SOLVENT NAME\"})\n",
    "        \n",
    "        # Bit-table filtering for binary fingerprints\n",
    "        if src in [\"drfps_catechol\", \"fragprints\"]:\n",
    "            prefix = \"drfps\" if src == \"drfps_catechol\" else \"frag\"\n",
    "            \n",
    "            # Drop all-zero and all-one columns\n",
    "            df_src = df_src.loc[:, (df_src != 0).any(axis=0)]\n",
    "            df_src = df_src.loc[:, (df_src != 1).any(axis=0)]\n",
    "            \n",
    "            # Drop columns with only 1 occurrence\n",
    "            values = df_src.drop(columns={\"SOLVENT NAME\"}, errors=\"ignore\")\n",
    "            count = values.sum(axis=0).T\n",
    "            drop_cols = count[count == 1].index\n",
    "            df_src = df_src.drop(columns=drop_cols, errors=\"ignore\")\n",
    "            \n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"spange_descriptors\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"spange_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"acs_pca_descriptors\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"acs_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"smiles\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"smiles_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        dfs.append(df_src)\n",
    "    \n",
    "    # Merge all dataframes on SOLVENT NAME\n",
    "    from functools import reduce\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on=\"SOLVENT NAME\", how=\"outer\"), dfs)\n",
    "    \n",
    "    print(f\"Combined features before filtering: {merged.shape}\")\n",
    "    \n",
    "    # Apply correlation filtering\n",
    "    merged_filtered, dropped = filter_correlated_features(merged, threshold=threshold)\n",
    "    \n",
    "    print(f\"Combined features after filtering: {merged_filtered.shape}\")\n",
    "    print(f\"Dropped {len(dropped)} columns\")\n",
    "    \n",
    "    return merged_filtered\n",
    "\n",
    "# Build the feature table\n",
    "solvent_table = build_solvent_feature_table(threshold=0.90)\n",
    "print(f\"\\nFinal solvent table shape: {solvent_table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b77cab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:49:02.031194Z",
     "iopub.status.busy": "2026-01-15T21:49:02.031096Z",
     "iopub.status.idle": "2026-01-15T21:49:02.036486Z",
     "shell.execute_reply": "2026-01-15T21:49:02.036100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedFeaturizer class defined.\n"
     ]
    }
   ],
   "source": [
    "# Create featurizer class\n",
    "\n",
    "class CombinedFeaturizer:\n",
    "    \"\"\"Featurizer that combines solvent features with numeric features.\"\"\"\n",
    "    \n",
    "    def __init__(self, solvent_table, data='single'):\n",
    "        self.solvent_table = solvent_table\n",
    "        self.data_mode = data\n",
    "        self.scaler = None\n",
    "        self.feature_cols = None\n",
    "    \n",
    "    def featurize(self, X, fit_scaler=False):\n",
    "        \"\"\"Convert input DataFrame to feature matrix.\"\"\"\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.data_mode == 'single':\n",
    "            # Single solvent: merge with solvent table\n",
    "            X_merged = X.merge(self.solvent_table, on='SOLVENT NAME', how='left')\n",
    "            \n",
    "            # Get numeric columns\n",
    "            numeric_cols = [c for c in X_merged.columns if c != 'SOLVENT NAME' and X_merged[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "            X_numeric = X_merged[numeric_cols].copy()\n",
    "        else:\n",
    "            # Full data (mixture): merge with solvent table for both solvents\n",
    "            # Rename solvent table columns for solvent A\n",
    "            solvent_A = self.solvent_table.copy()\n",
    "            solvent_A = solvent_A.rename(columns={'SOLVENT NAME': 'SOLVENT A NAME'})\n",
    "            solvent_A.columns = ['SOLVENT A NAME'] + [f'{c}_A' for c in solvent_A.columns if c != 'SOLVENT A NAME']\n",
    "            \n",
    "            # Rename solvent table columns for solvent B\n",
    "            solvent_B = self.solvent_table.copy()\n",
    "            solvent_B = solvent_B.rename(columns={'SOLVENT NAME': 'SOLVENT B NAME'})\n",
    "            solvent_B.columns = ['SOLVENT B NAME'] + [f'{c}_B' for c in solvent_B.columns if c != 'SOLVENT B NAME']\n",
    "            \n",
    "            # Merge\n",
    "            X_merged = X.merge(solvent_A, on='SOLVENT A NAME', how='left')\n",
    "            X_merged = X_merged.merge(solvent_B, on='SOLVENT B NAME', how='left')\n",
    "            \n",
    "            # Get numeric columns\n",
    "            numeric_cols = [c for c in X_merged.columns if c not in ['SOLVENT A NAME', 'SOLVENT B NAME'] and X_merged[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "            X_numeric = X_merged[numeric_cols].copy()\n",
    "        \n",
    "        # Add engineered features\n",
    "        X_numeric = add_numeric_features(X_numeric)\n",
    "        \n",
    "        # Store feature columns\n",
    "        if self.feature_cols is None:\n",
    "            self.feature_cols = list(X_numeric.columns)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        X_np = X_numeric.values.astype(np.float64)\n",
    "        \n",
    "        # Handle NaN\n",
    "        X_np = np.nan_to_num(X_np, nan=0.0)\n",
    "        \n",
    "        # Scale features\n",
    "        if fit_scaler:\n",
    "            self.scaler = StandardScaler()\n",
    "            X_np = self.scaler.fit_transform(X_np)\n",
    "        elif self.scaler is not None:\n",
    "            X_np = self.scaler.transform(X_np)\n",
    "        \n",
    "        return torch.tensor(X_np, dtype=torch.double)\n",
    "\n",
    "print(\"CombinedFeaturizer class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe06b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:49:02.037364Z",
     "iopub.status.busy": "2026-01-15T21:49:02.037268Z",
     "iopub.status.idle": "2026-01-15T21:49:02.045098Z",
     "shell.execute_reply": "2026-01-15T21:49:02.044738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostXGBEnsemble class defined.\n",
      "Single solvent weights: CatBoost=0.54, XGBoost=0.46\n",
      "Full data weights: CatBoost=0.33, XGBoost=0.67\n"
     ]
    }
   ],
   "source": [
    "# CatBoost + XGBoost Ensemble Model\n",
    "\n",
    "class CatBoostXGBEnsemble:\n",
    "    \"\"\"CatBoost + XGBoost ensemble following ens-model kernel.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', verbose=False):\n",
    "        self.data_mode = data\n",
    "        self.verbose = verbose\n",
    "        self.featurizer = CombinedFeaturizer(solvent_table, data=data)\n",
    "        \n",
    "        # Ensemble weights from ens-model kernel\n",
    "        if data == 'single':\n",
    "            cat_weight = 7.0\n",
    "            xgb_weight = 6.0\n",
    "        else:\n",
    "            cat_weight = 1.0\n",
    "            xgb_weight = 2.0\n",
    "        \n",
    "        w_sum = cat_weight + xgb_weight\n",
    "        self.cat_weight = cat_weight / w_sum\n",
    "        self.xgb_weight = xgb_weight / w_sum\n",
    "        \n",
    "        # CatBoost parameters from ens-model kernel\n",
    "        if data == 'single':\n",
    "            self.cat_params = dict(\n",
    "                random_seed=42,\n",
    "                loss_function=\"MultiRMSE\",\n",
    "                depth=3,\n",
    "                learning_rate=0.07,\n",
    "                n_estimators=1050,\n",
    "                l2_leaf_reg=3.5,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.225,\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75,\n",
    "                verbose=False,\n",
    "            )\n",
    "        else:\n",
    "            self.cat_params = dict(\n",
    "                random_seed=42,\n",
    "                loss_function=\"MultiRMSE\",\n",
    "                depth=3,\n",
    "                learning_rate=0.06,\n",
    "                n_estimators=1100,\n",
    "                l2_leaf_reg=2.5,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.25,\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75,\n",
    "                verbose=False,\n",
    "            )\n",
    "        \n",
    "        # XGBoost parameters from ens-model kernel\n",
    "        if data == 'single':\n",
    "            self.xgb_params = dict(\n",
    "                random_state=42,\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"hist\",\n",
    "                subsample=0.5,\n",
    "                reg_lambda=0.6,\n",
    "                reg_alpha=0.0,\n",
    "                n_estimators=1000,\n",
    "                min_child_weight=1,\n",
    "                max_depth=4,\n",
    "                max_delta_step=1,\n",
    "                learning_rate=0.02,\n",
    "                grow_policy=\"depthwise\",\n",
    "                gamma=0.0,\n",
    "                colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        else:\n",
    "            self.xgb_params = dict(\n",
    "                random_state=42,\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"approx\",\n",
    "                subsample=0.5,\n",
    "                reg_lambda=0.6,\n",
    "                reg_alpha=0.0,\n",
    "                n_estimators=1000,\n",
    "                min_child_weight=1,\n",
    "                max_depth=4,\n",
    "                max_delta_step=1,\n",
    "                learning_rate=0.02,\n",
    "                grow_policy=\"lossguide\",\n",
    "                gamma=0.0,\n",
    "                colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        \n",
    "        self.cat_model = None\n",
    "        self.xgb_models = None\n",
    "        self.n_targets = None\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        \"\"\"Train CatBoost and XGBoost models.\"\"\"\n",
    "        # Featurize\n",
    "        X_np = self.featurizer.featurize(train_X, fit_scaler=True).numpy()\n",
    "        Y_np = train_Y.values\n",
    "        self.n_targets = Y_np.shape[1]\n",
    "        \n",
    "        # Train CatBoost (multi-target)\n",
    "        self.cat_model = CatBoostRegressor(**self.cat_params)\n",
    "        self.cat_model.fit(X_np, Y_np)\n",
    "        \n",
    "        # Train XGBoost (one per target)\n",
    "        self.xgb_models = []\n",
    "        for t in range(self.n_targets):\n",
    "            model_t = XGBRegressor(**self.xgb_params)\n",
    "            model_t.fit(X_np, Y_np[:, t])\n",
    "            self.xgb_models.append(model_t)\n",
    "        \n",
    "        if verbose or self.verbose:\n",
    "            print(f\"[CatBoostXGBEnsemble] Trained in '{self.data_mode}' mode\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict with ensemble and apply output normalization.\"\"\"\n",
    "        X_np = self.featurizer.featurize(X, fit_scaler=False).numpy()\n",
    "        \n",
    "        # CatBoost prediction\n",
    "        cat_pred = self.cat_model.predict(X_np)\n",
    "        cat_pred = np.asarray(cat_pred)\n",
    "        if cat_pred.ndim == 1:\n",
    "            cat_pred = cat_pred.reshape(-1, 1)\n",
    "        \n",
    "        # XGBoost prediction\n",
    "        xgb_preds = [m.predict(X_np) for m in self.xgb_models]\n",
    "        xgb_pred = np.column_stack(xgb_preds)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        out = self.cat_weight * cat_pred + self.xgb_weight * xgb_pred\n",
    "        \n",
    "        # Output normalization (sum to 1 constraint)\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        \n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"CatBoostXGBEnsemble class defined.\")\n",
    "print(f\"Single solvent weights: CatBoost={7/13:.2f}, XGBoost={6/13:.2f}\")\n",
    "print(f\"Full data weights: CatBoost={1/3:.2f}, XGBoost={2/3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31db2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Solvent-Out CV for single solvents (24 folds)\n",
    "print(\"Running Leave-One-Solvent-Out CV for single solvents (24 folds)...\")\n",
    "print()\n",
    "\n",
    "fold_mses = []\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X_single, Y_single)):\n",
    "    test_solvent = test_X[\"SOLVENT NAME\"].iloc[0]\n",
    "    \n",
    "    # Create fresh model for each fold\n",
    "    model = CatBoostXGBEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    # Predict on test solvent\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    actuals = test_Y.values\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - actuals) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "    fold_results.append({'solvent': test_solvent, 'mse': mse})\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: {test_solvent}: MSE = {mse:.6f}\")\n",
    "\n",
    "mean_mse_single = np.mean(fold_mses)\n",
    "std_mse_single = np.std(fold_mses)\n",
    "print(f\"\\nSingle Solvent CV MSE: {mean_mse_single:.6f} +/- {std_mse_single:.6f}\")\n",
    "print(f\"Baseline (exp_030): CV = 0.008298\")\n",
    "if mean_mse_single < 0.008298:\n",
    "    print(f\"IMPROVEMENT: {(0.008298 - mean_mse_single) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(mean_mse_single - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80974c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Solvent-PAIR-Out CV for full data (13 folds)\n",
    "# CRITICAL: This is the CORRECT CV scheme - by solvent PAIRS, not RAMP NUM!\n",
    "print(\"\\nRunning Leave-One-Solvent-PAIR-Out CV for full data (13 folds)...\")\n",
    "print(\"CRITICAL: Using solvent PAIRS, not RAMP NUM!\")\n",
    "print()\n",
    "\n",
    "mix_fold_mses = []\n",
    "mix_fold_results = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    solvent_a = test_X[\"SOLVENT A NAME\"].iloc[0]\n",
    "    solvent_b = test_X[\"SOLVENT B NAME\"].iloc[0]\n",
    "    \n",
    "    # Create fresh model for each fold\n",
    "    model = CatBoostXGBEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    # Predict on test solvent pair\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    actuals = test_Y.values\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - actuals) ** 2)\n",
    "    mix_fold_mses.append(mse)\n",
    "    mix_fold_results.append({'solvent_a': solvent_a, 'solvent_b': solvent_b, 'mse': mse, 'n_samples': len(test_X)})\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: {solvent_a} + {solvent_b} (n={len(test_X)}): MSE = {mse:.6f}\")\n",
    "\n",
    "mean_mse_full = np.mean(mix_fold_mses)\n",
    "std_mse_full = np.std(mix_fold_mses)\n",
    "print(f\"\\nFull Data CV MSE: {mean_mse_full:.6f} +/- {std_mse_full:.6f}\")\n",
    "print(f\"Number of folds: {len(mix_fold_mses)} (should be 13)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined CV score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINED CV SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Weight by number of samples\n",
    "n_single = len(X_single)\n",
    "n_full = len(X_full)\n",
    "total = n_single + n_full\n",
    "\n",
    "weighted_cv = (n_single * mean_mse_single + n_full * mean_mse_full) / total\n",
    "\n",
    "print(f\"Single solvent CV: {mean_mse_single:.6f} (n={n_single}, 24 folds)\")\n",
    "print(f\"Full data CV: {mean_mse_full:.6f} (n={n_full}, 13 folds)\")\n",
    "print(f\"Weighted combined CV: {weighted_cv:.6f}\")\n",
    "print(f\"\\nBaseline (exp_030): CV = 0.008298\")\n",
    "if mean_mse_single < 0.008298:\n",
    "    print(f\"Single solvent improvement: {(0.008298 - mean_mse_single) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Single solvent degradation: {(mean_mse_single - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef16909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-solvent-pair results\n",
    "print(\"\\nPer-solvent-pair MSE analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mix_df = pd.DataFrame(mix_fold_results)\n",
    "mix_df = mix_df.sort_values('mse', ascending=False)\n",
    "\n",
    "print(\"\\nHardest solvent pairs:\")\n",
    "for _, row in mix_df.head(5).iterrows():\n",
    "    print(f\"  {row['solvent_a']} + {row['solvent_b']} (n={row['n_samples']}): MSE = {row['mse']:.6f}\")\n",
    "\n",
    "print(\"\\nEasiest solvent pairs:\")\n",
    "for _, row in mix_df.tail(5).iterrows():\n",
    "    print(f\"  {row['solvent_a']} + {row['solvent_b']} (n={row['n_samples']}): MSE = {row['mse']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission in the CORRECT format\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single solvent predictions (24 folds)\n",
    "print(\"\\nGenerating single solvent predictions (24 folds)...\")\n",
    "all_predictions_single = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(tqdm.tqdm(list(generate_leave_one_out_splits(X_single, Y_single)))):\n",
    "    model = CatBoostXGBEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_single.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions_single)\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data predictions (13 folds by solvent PAIRS)\n",
    "print(\"\\nGenerating full data predictions (13 folds by solvent PAIRS)...\")\n",
    "all_predictions_full = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(tqdm.tqdm(list(generate_leave_one_ramp_out_splits(X_full, Y_full)))):\n",
    "    model = CatBoostXGBEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4422482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save submission\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "\n",
    "# Save to submission directory\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")\n",
    "print(f\"\\nSubmission head:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission tail:\")\n",
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 050: CatBoost + XGBoost Ensemble (FIXED CV Scheme)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"THE FIX:\")\n",
    "print(\"  - exp_049 used RAMP NUM (87 folds) for full data CV\")\n",
    "print(\"  - exp_050 uses solvent PAIRS (13 folds) - the CORRECT scheme\")\n",
    "print()\n",
    "print(\"RESULTS:\")\n",
    "print(f\"  Single solvent CV MSE: {mean_mse_single:.6f} +/- {std_mse_single:.6f} (24 folds)\")\n",
    "print(f\"  Full data CV MSE: {mean_mse_full:.6f} +/- {std_mse_full:.6f} (13 folds)\")\n",
    "print(f\"  Weighted combined CV: {weighted_cv:.6f}\")\n",
    "print()\n",
    "print(\"COMPARISON TO BASELINE (exp_030):\")\n",
    "print(f\"  Baseline CV: 0.008298\")\n",
    "print(f\"  This experiment CV: {mean_mse_single:.6f}\")\n",
    "if mean_mse_single < 0.008298:\n",
    "    print(f\"  Improvement: {(0.008298 - mean_mse_single) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"  Degradation: {(mean_mse_single - 0.008298) / 0.008298 * 100:.2f}%\")\n",
    "print()\n",
    "print(\"SUBMISSION:\")\n",
    "print(f\"  Saved to: /home/submission/submission.csv\")\n",
    "print(f\"  Total rows: {len(submission)}\")\n",
    "print(f\"  Single solvent rows: {len(submission_single_solvent)}\")\n",
    "print(f\"  Full data rows: {len(submission_full_data)}\")\n",
    "print()\n",
    "print(\"EXPECTED LB (based on CV-LB relationship):\")\n",
    "print(f\"  LB = 4.29 * {mean_mse_single:.6f} + 0.0528 = {4.29 * mean_mse_single + 0.0528:.4f}\")\n",
    "print(f\"  exp_030 LB: 0.0877\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
