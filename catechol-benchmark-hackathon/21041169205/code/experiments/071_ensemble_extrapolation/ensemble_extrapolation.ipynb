{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d94a466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:18.175790Z",
     "iopub.status.busy": "2026-01-16T06:00:18.175220Z",
     "iopub.status.idle": "2026-01-16T06:00:19.875787Z",
     "shell.execute_reply": "2026-01-16T06:00:19.875339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Experiment 071: GP+MLP+LGBM Ensemble with Extrapolation Detection\n",
    "#\n",
    "# Combines the best model (exp_030 GP+MLP+LGBM, CV=0.0083) with extrapolation detection\n",
    "# to try to reduce the CV-LB intercept.\n",
    "#\n",
    "# Key outlier solvents (z-score > 1.0):\n",
    "# - HFIP: 4.57 (z=2.24) -> blend_weight=0.617\n",
    "# - Cyclohexane: 4.18 (z=1.86) -> blend_weight=0.432\n",
    "# - Water: 3.70 (z=1.40) -> blend_weight=0.200\n",
    "# - Ethylene Glycol: 3.69 (z=1.39) -> blend_weight=0.193\n",
    "# - TFE: 3.59 (z=1.29) -> blend_weight=0.147\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2109149f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.876992Z",
     "iopub.status.busy": "2026-01-16T06:00:19.876838Z",
     "iopub.status.idle": "2026-01-16T06:00:19.881280Z",
     "shell.execute_reply": "2026-01-16T06:00:19.880925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc5036f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.882310Z",
     "iopub.status.busy": "2026-01-16T06:00:19.882210Z",
     "iopub.status.idle": "2026-01-16T06:00:19.910193Z",
     "shell.execute_reply": "2026-01-16T06:00:19.909841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fcf0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.911121Z",
     "iopub.status.busy": "2026-01-16T06:00:19.911023Z",
     "iopub.status.idle": "2026-01-16T06:00:19.916416Z",
     "shell.execute_reply": "2026-01-16T06:00:19.916077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed outlier scores. Mean: 2.2408, Std: 1.0424\n",
      "\n",
      "Top outliers:\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: 4.5701 (z=2.23)\n",
      "  Cyclohexane: 4.1844 (z=1.86)\n",
      "  Water: 3.7000 (z=1.40)\n",
      "  Ethylene Glycol [1,2-Ethanediol]: 3.6865 (z=1.39)\n",
      "  2,2,2-Trifluoroethanol: 3.5894 (z=1.29)\n",
      "  Decanol: 2.8970 (z=0.63)\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute outlier scores for all solvents (excluding self)\n",
    "# This identifies which solvents are \"outliers\" in the solvent space\n",
    "\n",
    "def compute_solvent_outlier_scores(k=3):\n",
    "    \"\"\"Compute outlier score for each solvent based on distance to k nearest OTHER solvents.\"\"\"\n",
    "    solvent_scaler = StandardScaler()\n",
    "    scaled_features = solvent_scaler.fit_transform(SPANGE_DF.values)\n",
    "    \n",
    "    outlier_scores = {}\n",
    "    for i, solvent in enumerate(SPANGE_DF.index):\n",
    "        other_indices = [j for j in range(len(SPANGE_DF)) if j != i]\n",
    "        other_features = scaled_features[other_indices]\n",
    "        distances = cdist([scaled_features[i]], other_features, metric='euclidean')[0]\n",
    "        k_nearest_dist = np.sort(distances)[:k].mean()\n",
    "        outlier_scores[solvent] = k_nearest_dist\n",
    "    \n",
    "    return outlier_scores\n",
    "\n",
    "SOLVENT_OUTLIER_SCORES = compute_solvent_outlier_scores(k=3)\n",
    "mean_outlier_score = np.mean(list(SOLVENT_OUTLIER_SCORES.values()))\n",
    "std_outlier_score = np.std(list(SOLVENT_OUTLIER_SCORES.values()))\n",
    "\n",
    "print(f\"Pre-computed outlier scores. Mean: {mean_outlier_score:.4f}, Std: {std_outlier_score:.4f}\")\n",
    "print(\"\\nTop outliers:\")\n",
    "for solvent, score in sorted(SOLVENT_OUTLIER_SCORES.items(), key=lambda x: x[1], reverse=True)[:6]:\n",
    "    z = (score - mean_outlier_score) / std_outlier_score\n",
    "    print(f\"  {solvent}: {score:.4f} (z={z:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31067ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.917475Z",
     "iopub.status.busy": "2026-01-16T06:00:19.917235Z",
     "iopub.status.idle": "2026-01-16T06:00:19.919971Z",
     "shell.execute_reply": "2026-01-16T06:00:19.919631Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98485e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.920799Z",
     "iopub.status.busy": "2026-01-16T06:00:19.920684Z",
     "iopub.status.idle": "2026-01-16T06:00:19.926176Z",
     "shell.execute_reply": "2026-01-16T06:00:19.925835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Full Featurizer (for MLP and LGBM) - 145 features\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - pct) + A_spange * pct\n",
    "                X_drfp = B_drfp * (1 - pct) + A_drfp * pct\n",
    "                X_acs = B_acs * (1 - pct) + A_acs * pct\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'Full feature dimension: {FullFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8b6a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.927060Z",
     "iopub.status.busy": "2026-01-16T06:00:19.926962Z",
     "iopub.status.idle": "2026-01-16T06:00:19.930816Z",
     "shell.execute_reply": "2026-01-16T06:00:19.930462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature dimension (for GP): 18\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer (for GP) - 18 features (Spange + Arrhenius kinetics)\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]  # 18 features\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - pct) + A_spange * pct\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'Simple feature dimension (for GP): {SimpleFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8afd9ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:19.931689Z",
     "iopub.status.busy": "2026-01-16T06:00:19.931582Z",
     "iopub.status.idle": "2026-01-16T06:00:19.940906Z",
     "shell.execute_reply": "2026-01-16T06:00:19.940557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtrapolationAwareGPMLPLGBMEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# GP+MLP+LGBM Ensemble with Extrapolation Detection\n",
    "\n",
    "class ExtrapolationAwareGPMLPLGBMEnsemble(BaseModel):\n",
    "    def __init__(self, data='single', blend_threshold=1.0, gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30):\n",
    "        self.data_type = data\n",
    "        self.blend_threshold = blend_threshold\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        \n",
    "        self.mixed = (data == 'full')\n",
    "        self.full_featurizer = FullFeaturizer(mixed=self.mixed)\n",
    "        self.simple_featurizer = SimpleFeaturizer(mixed=self.mixed)\n",
    "        \n",
    "        self.gp_scaler = StandardScaler()\n",
    "        self.mlp_scaler = StandardScaler()\n",
    "        self.lgbm_scaler = StandardScaler()\n",
    "        \n",
    "        self.gp_models = []  # One per target\n",
    "        self.lgbm_models = []  # One per target\n",
    "        self.mlp = None\n",
    "        \n",
    "        self.train_Y = None\n",
    "    \n",
    "    def get_blend_weight(self, solvent_name):\n",
    "        \"\"\"Get blend weight based on pre-computed outlier score.\"\"\"\n",
    "        score = SOLVENT_OUTLIER_SCORES.get(solvent_name, mean_outlier_score)\n",
    "        z_score = (score - mean_outlier_score) / std_outlier_score\n",
    "        blend_weight = np.clip((z_score - self.blend_threshold) / 2.0, 0, 1)\n",
    "        return blend_weight\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.train_Y = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "        \n",
    "        # Prepare features\n",
    "        X_simple = self.simple_featurizer.featurize(X_train)\n",
    "        X_full = self.full_featurizer.featurize(X_train)\n",
    "        \n",
    "        X_gp = self.gp_scaler.fit_transform(X_simple)\n",
    "        X_mlp = self.mlp_scaler.fit_transform(X_full)\n",
    "        X_lgbm = self.lgbm_scaler.fit_transform(X_full)\n",
    "        \n",
    "        Y = self.train_Y\n",
    "        \n",
    "        # Train GP models (one per target)\n",
    "        self.gp_models = []\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        for i in range(3):\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3, random_state=42)\n",
    "            gp.fit(X_gp, Y[:, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train LGBM models (one per target)\n",
    "        self.lgbm_models = []\n",
    "        lgbm_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_lgbm, label=Y[:, i])\n",
    "            model = lgb.train(lgbm_params, train_data, num_boost_round=200)\n",
    "            self.lgbm_models.append(model)\n",
    "        \n",
    "        # Train MLP\n",
    "        input_dim = X_mlp.shape[1]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()  # Ensure [0,1] output\n",
    "        ).double().to(device)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_mlp).to(device)\n",
    "        Y_tensor = torch.tensor(Y).to(device)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(200):\n",
    "            for batch_X, batch_Y in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(batch_X)\n",
    "                loss = criterion(pred, batch_Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Prepare features\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        \n",
    "        X_gp = self.gp_scaler.transform(X_simple)\n",
    "        X_mlp = self.mlp_scaler.transform(X_full)\n",
    "        X_lgbm = self.lgbm_scaler.transform(X_full)\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.column_stack([gp.predict(X_gp) for gp in self.gp_models])\n",
    "        \n",
    "        # LGBM predictions\n",
    "        lgbm_preds = np.column_stack([model.predict(X_lgbm) for model in self.lgbm_models])\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_mlp).to(device)\n",
    "            mlp_preds = self.mlp(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        raw_pred = self.gp_weight * gp_preds + self.mlp_weight * mlp_preds + self.lgbm_weight * lgbm_preds\n",
    "        \n",
    "        # Apply extrapolation detection\n",
    "        if self.data_type == 'single':\n",
    "            solvent_names = X[\"SOLVENT NAME\"].values\n",
    "            blend_weights = np.array([self.get_blend_weight(s) for s in solvent_names])\n",
    "        else:\n",
    "            # For mixtures, use max of both solvents' blend weights\n",
    "            solvent_a_names = X[\"SOLVENT A NAME\"].values\n",
    "            solvent_b_names = X[\"SOLVENT B NAME\"].values\n",
    "            blend_weights_a = np.array([self.get_blend_weight(s) for s in solvent_a_names])\n",
    "            blend_weights_b = np.array([self.get_blend_weight(s) for s in solvent_b_names])\n",
    "            blend_weights = np.maximum(blend_weights_a, blend_weights_b)\n",
    "        \n",
    "        # Compute population mean from training data\n",
    "        mean_pred = self.train_Y.mean(axis=0)\n",
    "        \n",
    "        # Blend: for outliers, move toward mean\n",
    "        blended = (1 - blend_weights.reshape(-1, 1)) * raw_pred + blend_weights.reshape(-1, 1) * mean_pred\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        blended = np.clip(blended, 0, 1)\n",
    "        \n",
    "        return torch.tensor(blended)\n",
    "\n",
    "print('ExtrapolationAwareGPMLPLGBMEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723dce1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:00:29.108674Z",
     "iopub.status.busy": "2026-01-16T06:00:29.108241Z",
     "iopub.status.idle": "2026-01-16T06:13:12.047241Z",
     "shell.execute_reply": "2026-01-16T06:13:12.046779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:31, 31.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:00, 29.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:27, 28.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:54, 28.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:28, 30.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:59, 30.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:32, 31.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [04:00, 30.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:32, 30.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [05:07, 32.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [05:41, 32.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [06:13, 32.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [06:44, 32.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [07:15, 31.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [07:50, 32.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [08:23, 32.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [09:00, 34.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [09:33, 33.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [10:04, 33.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [10:35, 32.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [11:05, 31.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [11:41, 32.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [12:09, 31.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [12:42, 32.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [12:42, 31.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent predictions shape: (656, 6)\n",
      "Single solvent CV MSE: 0.009978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ExtrapolationAwareGPMLPLGBMEnsemble(data='single', blend_threshold=1.0) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "print(f\"Single solvent predictions shape: {submission_single_solvent.shape}\")\n",
    "\n",
    "# Calculate CV score for single solvent\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_mse = []\n",
    "for fold_idx, split in enumerate(split_generator):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    fold_preds = submission_single_solvent[submission_single_solvent['fold'] == fold_idx]\n",
    "    pred_values = fold_preds[['target_1', 'target_2', 'target_3']].values\n",
    "    true_values = test_Y.values\n",
    "    mse = ((pred_values - true_values) ** 2).mean()\n",
    "    all_mse.append(mse)\n",
    "print(f\"Single solvent CV MSE: {np.mean(all_mse):.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c94a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:13:23.023917Z",
     "iopub.status.busy": "2026-01-16T06:13:23.023485Z",
     "iopub.status.idle": "2026-01-16T06:35:13.624455Z",
     "shell.execute_reply": "2026-01-16T06:35:13.624016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:38, 98.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [03:11, 95.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [04:44, 94.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [06:25, 96.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [08:18, 102.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [09:41, 95.89s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [11:44, 104.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [13:19, 101.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [14:57, 100.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [16:37, 100.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [18:22, 101.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [20:04, 101.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [21:50, 103.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [21:50, 100.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data predictions shape: (1227, 6)\n",
      "Full data CV MSE: 0.040984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ExtrapolationAwareGPMLPLGBMEnsemble(data='full', blend_threshold=1.0) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "print(f\"Full data predictions shape: {submission_full_data.shape}\")\n",
    "\n",
    "# Calculate CV score for full data\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_mse = []\n",
    "for fold_idx, split in enumerate(split_generator):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    fold_preds = submission_full_data[submission_full_data['fold'] == fold_idx]\n",
    "    pred_values = fold_preds[['target_1', 'target_2', 'target_3']].values\n",
    "    true_values = test_Y.values\n",
    "    mse = ((pred_values - true_values) ** 2).mean()\n",
    "    all_mse.append(mse)\n",
    "print(f\"Full data CV MSE: {np.mean(all_mse):.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6d5d16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:35:13.625821Z",
     "iopub.status.busy": "2026-01-16T06:35:13.625677Z",
     "iopub.status.idle": "2026-01-16T06:35:13.636418Z",
     "shell.execute_reply": "2026-01-16T06:35:13.636074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved. Shape: (1883, 7)\n",
      "Predictions range: target_1 [0.000, 0.398]\n",
      "Predictions range: target_2 [0.000, 0.377]\n",
      "Predictions range: target_3 [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to /home/submission/\n",
    "import shutil\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "\n",
    "print(f\"Submission saved. Shape: {submission.shape}\")\n",
    "print(f\"Predictions range: target_1 [{submission['target_1'].min():.3f}, {submission['target_1'].max():.3f}]\")\n",
    "print(f\"Predictions range: target_2 [{submission['target_2'].min():.3f}, {submission['target_2'].max():.3f}]\")\n",
    "print(f\"Predictions range: target_3 [{submission['target_3'].min():.3f}, {submission['target_3'].max():.3f}]\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0487ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:35:38.140802Z",
     "iopub.status.busy": "2026-01-16T06:35:38.140229Z",
     "iopub.status.idle": "2026-01-16T06:35:38.151075Z",
     "shell.execute_reply": "2026-01-16T06:35:38.150673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent shape: (656, 6)\n",
      "Full data shape: (1227, 6)\n",
      "Expected single: 656\n",
      "Expected full: 1227\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check submission shape\n",
    "print(f\"Single solvent shape: {submission_single_solvent.shape}\")\n",
    "print(f\"Full data shape: {submission_full_data.shape}\")\n",
    "\n",
    "# Check expected shapes\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "print(f\"Expected single: {len(Y_single)}\")\n",
    "print(f\"Expected full: {len(Y_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa27583f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:35:59.949411Z",
     "iopub.status.busy": "2026-01-16T06:35:59.948851Z",
     "iopub.status.idle": "2026-01-16T06:35:59.951360Z",
     "shell.execute_reply": "2026-01-16T06:35:59.951029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check number of folds for full data\\nX_full, Y_full = load_data(\\\"full\\\")\\nramps = X_full[[\\\"SOLVENT A NAME\\\", \\\"SOLVENT B NAME\\\"]].drop_duplicates()\\nprint(f\\\"Number of unique ramps: {len(ramps)}\\\")\\nprint(ramps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408df27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:17.899898Z",
     "iopub.status.busy": "2026-01-16T06:36:17.899703Z",
     "iopub.status.idle": "2026-01-16T06:36:17.909856Z",
     "shell.execute_reply": "2026-01-16T06:36:17.909448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ramps: 13\n",
      "                          SOLVENT A NAME                     SOLVENT B NAME\n",
      "0                               Methanol   Ethylene Glycol [1,2-Ethanediol]\n",
      "122    1,1,1,3,3,3-Hexafluoropropan-2-ol  2-Methyltetrahydrofuran [2-MeTHF]\n",
      "246                          Cyclohexane                  IPA [Propan-2-ol]\n",
      "350                   Water.Acetonitrile                       Acetonitrile\n",
      "475                         Acetonitrile           Acetonitrile.Acetic Acid\n",
      "600    2-Methyltetrahydrofuran [2-MeTHF]              Diethyl Ether [Ether]\n",
      "724               2,2,2-Trifluoroethanol       Water.2,2,2-Trifluoroethanol\n",
      "849          DMA [N,N-Dimethylacetamide]                            Decanol\n",
      "959                              Ethanol              THF [Tetrahydrofuran]\n",
      "1086     Dihydrolevoglucosenone (Cyrene)                      Ethyl Acetate\n",
      "1122        MTBE [tert-Butylmethylether]                     Butanone [MEK]\n",
      "1156  tert-Butanol [2-Methylpropan-2-ol]                 Dimethyl Carbonate\n",
      "1192                   Methyl Propionate                      Ethyl Lactate\n"
     ]
    }
   ],
   "source": [
    "# Check number of folds for full data\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "print(f\"Number of unique ramps: {len(ramps)}\")\n",
    "print(ramps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b55b508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:36:56.082937Z",
     "iopub.status.busy": "2026-01-16T06:36:56.082496Z",
     "iopub.status.idle": "2026-01-16T06:36:56.091152Z",
     "shell.execute_reply": "2026-01-16T06:36:56.090771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvents in full data: {'Ethylene Glycol [1,2-Ethanediol]', '1,1,1,3,3,3-Hexafluoropropan-2-ol', 'DMA [N,N-Dimethylacetamide]', 'Butanone [MEK]', 'Water.2,2,2-Trifluoroethanol', 'Ethyl Lactate', 'Methyl Propionate', 'Dimethyl Carbonate', 'Diethyl Ether [Ether]', 'Ethyl Acetate', 'Cyclohexane', 'Methanol', 'IPA [Propan-2-ol]', 'Water.Acetonitrile', 'Ethanol', 'Decanol', '2-Methyltetrahydrofuran [2-MeTHF]', 'Acetonitrile', 'MTBE [tert-Butylmethylether]', 'tert-Butanol [2-Methylpropan-2-ol]', 'Dihydrolevoglucosenone (Cyrene)', '2,2,2-Trifluoroethanol', 'THF [Tetrahydrofuran]', 'Acetonitrile.Acetic Acid'}\n",
      "\n",
      "Solvents in DRFP: {'Butanone [MEK]', 'Dimethyl Carbonate', 'Diethyl Ether [Ether]', 'Ethyl Acetate', 'IPA [Propan-2-ol]', 'Water.Acetonitrile', 'tert-Butanol [2-Methylpropan-2-ol]', 'Ethylene Glycol [1,2-Ethanediol]', 'THF [Tetrahydrofuran]', '1,1,1,3,3,3-Hexafluoropropan-2-ol', 'DMA [N,N-Dimethylacetamide]', 'Water.2,2,2-Trifluoroethanol', 'Ethyl Lactate', 'Methyl Propionate', 'Cyclohexane', 'Methanol', 'Ethanol', 'Decanol', '2-Methyltetrahydrofuran [2-MeTHF]', 'Acetonitrile', 'MTBE [tert-Butylmethylether]', 'Dihydrolevoglucosenone (Cyrene)', '2,2,2-Trifluoroethanol', 'Acetonitrile.Acetic Acid'}\n",
      "\n",
      "Missing from DRFP: set()\n",
      "\n",
      "Missing from ACS_PCA: set()\n"
     ]
    }
   ],
   "source": [
    "# Check if all solvents in full data are in the lookup tables\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "all_solvents_full = set(X_full[\"SOLVENT A NAME\"].unique()) | set(X_full[\"SOLVENT B NAME\"].unique())\n",
    "print(f\"Solvents in full data: {all_solvents_full}\")\n",
    "print(f\"\\nSolvents in DRFP: {set(DRFP_FILTERED.index)}\")\n",
    "print(f\"\\nMissing from DRFP: {all_solvents_full - set(DRFP_FILTERED.index)}\")\n",
    "print(f\"\\nMissing from ACS_PCA: {all_solvents_full - set(ACS_PCA_DF.index)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
