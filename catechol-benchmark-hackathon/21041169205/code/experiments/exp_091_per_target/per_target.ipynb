{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ff20ba",
   "metadata": {},
   "source": [
    "# Experiment 091: Per-Target Heterogeneous Ensemble\n",
    "\n",
    "**Rationale**: The strategy-to-get-0-11161 kernel (LB=0.11161) uses DIFFERENT model types for different targets:\n",
    "- SM target: HistGradientBoostingRegressor (HGB)\n",
    "- Product 2 & 3: ExtraTreesRegressor (ETR)\n",
    "- Ensemble: 0.65 * ACS_PCA + 0.35 * Spange\n",
    "\n",
    "**Why this could change the CV-LB relationship**:\n",
    "1. Different targets may have different optimal model types\n",
    "2. SM (starting material) may behave differently than products\n",
    "3. This is fundamentally different from using the same model for all targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb92e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[['Residence Time', 'Temperature', 'SOLVENT A NAME', 'SOLVENT B NAME', 'SolventB%']]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[['Residence Time', 'Temperature', 'SOLVENT NAME']]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature lookups\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "print(f'ACS PCA: {ACS_PCA_DF.shape}, Spange: {SPANGE_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BetterCatecholModel - exactly as in the kernel\n",
    "class BetterCatecholModel:\n",
    "    def __init__(self, feature_table=\"spange_descriptors\", base_type=\"hgb\"):\n",
    "        self.base_type = base_type\n",
    "        if feature_table == \"acs_pca_descriptors\":\n",
    "            self.lookup = ACS_PCA_DF\n",
    "        else:\n",
    "            self.lookup = SPANGE_DF\n",
    "        self.model = None\n",
    "\n",
    "    def _vec(self, s):\n",
    "        return self.lookup.loc[s].values if s in self.lookup.index else np.zeros(self.lookup.shape[1])\n",
    "\n",
    "    def _build_X(self, X):\n",
    "        rt = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "\n",
    "        if \"SOLVENT NAME\" in X.columns:\n",
    "            S = np.vstack([self._vec(s) for s in X[\"SOLVENT NAME\"]])\n",
    "            return np.hstack([rt, temp, S])\n",
    "\n",
    "        frac_b = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "        A = np.vstack([self._vec(s) for s in X[\"SOLVENT A NAME\"]])\n",
    "        B = np.vstack([self._vec(s) for s in X[\"SOLVENT B NAME\"]])\n",
    "        mix = (1 - frac_b) * A + frac_b * B\n",
    "\n",
    "        return np.hstack([rt, temp, frac_b, mix])\n",
    "\n",
    "    def train_model(self, X, Y):\n",
    "        Xf = self._build_X(X)\n",
    "        y = Y.values\n",
    "\n",
    "        if self.base_type == \"hgb\":\n",
    "            base = HistGradientBoostingRegressor(\n",
    "                max_depth=7, max_iter=700, learning_rate=0.04\n",
    "            )\n",
    "        else:\n",
    "            base = ExtraTreesRegressor(\n",
    "                n_estimators=900,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "\n",
    "        self.model = Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"reg\", MultiOutputRegressor(base))]\n",
    "        )\n",
    "        self.model.fit(Xf, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.clip(self.model.predict(self._build_X(X)), 0, 1)\n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print('BetterCatecholModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Target Heterogeneous Ensemble - exactly as in the kernel\n",
    "class PerTargetEnsembleModel:\n",
    "    def __init__(self):\n",
    "        self.targets = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "        self.models = {}\n",
    "\n",
    "        for t in self.targets:\n",
    "            if t == \"SM\":\n",
    "                # HGB for SM target\n",
    "                self.models[t] = [\n",
    "                    BetterCatecholModel(\"acs_pca_descriptors\", \"hgb\"),\n",
    "                    BetterCatecholModel(\"spange_descriptors\", \"hgb\"),\n",
    "                ]\n",
    "            else:\n",
    "                # ETR for Product 2 & 3\n",
    "                self.models[t] = [\n",
    "                    BetterCatecholModel(\"acs_pca_descriptors\", \"etr\"),\n",
    "                    BetterCatecholModel(\"spange_descriptors\", \"etr\"),\n",
    "                ]\n",
    "\n",
    "    def train_model(self, X, Y):\n",
    "        for t in self.targets:\n",
    "            y_single = Y[[t]]\n",
    "            for m in self.models[t]:\n",
    "                m.train_model(X, y_single)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "\n",
    "        for t in self.targets:\n",
    "            p1 = self.models[t][0].model.predict(self.models[t][0]._build_X(X))\n",
    "            p2 = self.models[t][1].model.predict(self.models[t][1]._build_X(X))\n",
    "\n",
    "            # Ensemble: 0.65 * ACS_PCA + 0.35 * Spange\n",
    "            pred_t = 0.65 * p1 + 0.35 * p2\n",
    "            preds.append(pred_t.reshape(-1, 1))\n",
    "\n",
    "        pred = np.clip(np.hstack(preds), 0, 1)\n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print('PerTargetEnsembleModel defined')\n",
    "print('SM: HGB (gradient boosting)')\n",
    "print('Product 2 & 3: ETR (random forest variant)')\n",
    "print('Ensemble: 0.65 * ACS_PCA + 0.35 * Spange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsembleModel()  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsembleModel()  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25190042",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b89da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV score (for verification only - NOT part of submission)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest previous CV: 0.008092 (CatBoost+XGBoost)')\n",
    "print(f'Best previous LB: 0.0877 (GP+MLP+LGBM)')\n",
    "print(f'\\nThis (Per-Target Heterogeneous Ensemble): CV {overall_mse:.6f}')\n",
    "\n",
    "if overall_mse < 0.008092:\n",
    "    improvement = (0.008092 - overall_mse) / 0.008092 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008092) / 0.008092 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
