{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e1f5de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:20.498223Z",
     "iopub.status.busy": "2026-01-16T05:32:20.497770Z",
     "iopub.status.idle": "2026-01-16T05:32:21.840669Z",
     "shell.execute_reply": "2026-01-16T05:32:21.840212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Experiment 068: Extrapolation Detection + Conservative Predictions\n",
    "# Goal: Reduce the CV-LB intercept by making conservative predictions when extrapolating\n",
    "#\n",
    "# Strategy:\n",
    "# 1. Compute distance from test solvent to nearest training solvents (using Spange descriptors)\n",
    "# 2. When extrapolating (high distance), blend predictions toward population mean\n",
    "# 3. This could reduce the intercept by making conservative predictions for hard cases\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "print('Imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9194a755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:21.841968Z",
     "iopub.status.busy": "2026-01-16T05:32:21.841793Z",
     "iopub.status.idle": "2026-01-16T05:32:21.848626Z",
     "shell.execute_reply": "2026-01-16T05:32:21.848268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange descriptors shape: (26, 13)\n",
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).all(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "# Load Spange descriptors for extrapolation detection\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "print(f'Spange descriptors shape: {SPANGE_DF.shape}')\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c040fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:21.849642Z",
     "iopub.status.busy": "2026-01-16T05:32:21.849536Z",
     "iopub.status.idle": "2026-01-16T05:32:21.852143Z",
     "shell.execute_reply": "2026-01-16T05:32:21.851823Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44cae979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:21.853051Z",
     "iopub.status.busy": "2026-01-16T05:32:21.852956Z",
     "iopub.status.idle": "2026-01-16T05:32:21.857140Z",
     "shell.execute_reply": "2026-01-16T05:32:21.856804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizers\n",
    "class PrecomputedFeaturizer(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = features\n",
    "        self.featurizer = load_features(self.features)\n",
    "        self.feats_dim = self.featurizer.shape[1] + 2\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = X[INPUT_LABELS_NUMERIC]\n",
    "        X_smiles_feat = self.featurizer.loc[X[\"SOLVENT NAME\"]]\n",
    "        X_numeric_tensor = torch.tensor(X_numeric.values)\n",
    "        X_smiles_feat_tensor = torch.tensor(X_smiles_feat.values)\n",
    "        X_out = torch.cat((X_numeric_tensor, X_smiles_feat_tensor), dim=1)\n",
    "        return X_out\n",
    "\n",
    "class PrecomputedFeaturizerMixed(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = features\n",
    "        self.featurizer = load_features(self.features)\n",
    "        self.feats_dim = self.featurizer.shape[1] + 2\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = X[INPUT_LABELS_NUMERIC]\n",
    "        X_smiles_A_feat = self.featurizer.loc[X[\"SOLVENT A NAME\"]]\n",
    "        X_smiles_B_feat = self.featurizer.loc[X[\"SOLVENT B NAME\"]]\n",
    "        X_numeric_tensor = torch.tensor(X_numeric.values)\n",
    "        X_smiles_feat_tensor = X_smiles_A_feat.values * (1 - X[\"SolventB%\"].values.reshape(-1, 1)) + X_smiles_B_feat.values * X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "        X_smiles_feat_tensor = torch.tensor(X_smiles_feat_tensor)\n",
    "        X_out = torch.cat((X_numeric_tensor, X_smiles_feat_tensor), dim=1)\n",
    "        return X_out\n",
    "\n",
    "print('Featurizers defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90c7dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:21.858058Z",
     "iopub.status.busy": "2026-01-16T05:32:21.857960Z",
     "iopub.status.idle": "2026-01-16T05:32:21.866844Z",
     "shell.execute_reply": "2026-01-16T05:32:21.866495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtrapolationAwareMLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model with Extrapolation Detection\n",
    "class ExtrapolationAwareMLPModel(nn.Module, BaseModel):\n",
    "    def __init__(self, features='spange_descriptors', hidden_dims=[64, 64], output_dim=3, dropout=0.0, data='single', blend_threshold=0.3):\n",
    "        super(ExtrapolationAwareMLPModel, self).__init__()\n",
    "        self.data_type = data\n",
    "        self.blend_threshold = blend_threshold\n",
    "        \n",
    "        if data == 'single':\n",
    "            self.smiles_featurizer = PrecomputedFeaturizer(features=features)\n",
    "        else:\n",
    "            self.smiles_featurizer = PrecomputedFeaturizerMixed(features=features)\n",
    "        \n",
    "        input_dim = self.smiles_featurizer.feats_dim\n",
    "        prev_dim = input_dim\n",
    "        layers = []\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Store training data for extrapolation detection\n",
    "        self.train_solvents = None\n",
    "        self.train_solvent_features = None\n",
    "        self.mean_pred = None\n",
    "        self.nn_model = None\n",
    "\n",
    "    def train_model(self, train_X, train_Y, criterion=nn.MSELoss, optimizer=torch.optim.Adam,\n",
    "                    num_epochs=100, batch_size=1048, device=\"cpu\", verbose=True, lr=1e-3):\n",
    "        self.train()\n",
    "        \n",
    "        # Store training solvents for extrapolation detection\n",
    "        if self.data_type == 'single':\n",
    "            self.train_solvents = train_X[\"SOLVENT NAME\"].unique().tolist()\n",
    "            self.train_solvent_features = SPANGE_DF.loc[self.train_solvents].values\n",
    "        else:\n",
    "            solvents_a = train_X[\"SOLVENT A NAME\"].unique().tolist()\n",
    "            solvents_b = train_X[\"SOLVENT B NAME\"].unique().tolist()\n",
    "            self.train_solvents = list(set(solvents_a + solvents_b))\n",
    "            self.train_solvent_features = SPANGE_DF.loc[self.train_solvents].values\n",
    "        \n",
    "        # Fit nearest neighbors for extrapolation detection\n",
    "        self.nn_model = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "        self.nn_model.fit(self.train_solvent_features)\n",
    "        \n",
    "        # Store mean prediction for blending\n",
    "        self.mean_pred = torch.tensor(train_Y.values.mean(axis=0), dtype=torch.double)\n",
    "        \n",
    "        # Train the MLP\n",
    "        train_X_tensor = self.smiles_featurizer.featurize(train_X)\n",
    "        train_Y_tensor = torch.tensor(train_Y.values)\n",
    "        train_dataset = TensorDataset(train_X_tensor, train_Y_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        criterion = criterion()\n",
    "        optimizer = optimizer(self.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            self.train()\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward_raw(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def forward_raw(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "    def compute_extrapolation_score(self, X):\n",
    "        \"\"\"Compute how far test solvents are from training distribution.\"\"\"\n",
    "        if self.data_type == 'single':\n",
    "            test_features = SPANGE_DF.loc[X[\"SOLVENT NAME\"]].values\n",
    "        else:\n",
    "            # For mixtures, use weighted average of solvent features\n",
    "            feat_a = SPANGE_DF.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            feat_b = SPANGE_DF.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            test_features = feat_a * (1 - pct) + feat_b * pct\n",
    "        \n",
    "        # Compute distance to nearest training solvent\n",
    "        distances, _ = self.nn_model.kneighbors(test_features)\n",
    "        return distances.flatten()\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        X_tensor = self.smiles_featurizer.featurize(X)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            raw_pred = self.forward_raw(X_tensor)\n",
    "        \n",
    "        # Compute extrapolation score\n",
    "        extrap_scores = self.compute_extrapolation_score(X)\n",
    "        \n",
    "        # Normalize extrapolation scores (0 = no extrapolation, 1 = max extrapolation)\n",
    "        max_score = extrap_scores.max() if extrap_scores.max() > 0 else 1.0\n",
    "        normalized_scores = extrap_scores / max_score\n",
    "        \n",
    "        # Blend predictions toward mean based on extrapolation score\n",
    "        # Higher extrapolation score = more conservative (closer to mean)\n",
    "        blend_weights = np.minimum(normalized_scores / self.blend_threshold, 1.0)\n",
    "        blend_weights = torch.tensor(blend_weights, dtype=torch.double).unsqueeze(1)\n",
    "        \n",
    "        # Blend: (1 - weight) * raw_pred + weight * mean_pred\n",
    "        blended_pred = (1 - blend_weights) * raw_pred + blend_weights * self.mean_pred\n",
    "        \n",
    "        return blended_pred\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.forward_raw(x)\n",
    "\n",
    "print('ExtrapolationAwareMLPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ccc5b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:32.833441Z",
     "iopub.status.busy": "2026-01-16T05:32:32.832863Z",
     "iopub.status.idle": "2026-01-16T05:32:41.776067Z",
     "shell.execute_reply": "2026-01-16T05:32:41.775612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  2.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  2.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:02,  2.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:03,  2.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:03,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:03,  2.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:04,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:04,  2.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:04,  2.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:05,  2.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:05,  3.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:05,  2.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:06,  2.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:06,  2.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:06,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:07,  2.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:07,  2.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:07,  2.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:08,  2.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:08,  2.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:08,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:08,  2.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ExtrapolationAwareMLPModel(blend_threshold=0.5) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a03560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:32:52.534970Z",
     "iopub.status.busy": "2026-01-16T05:32:52.534321Z",
     "iopub.status.idle": "2026-01-16T05:33:00.348815Z",
     "shell.execute_reply": "2026-01-16T05:33:00.348352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:02,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:04,  1.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:04,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:05,  1.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:06,  1.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:07,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:07,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:07,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ExtrapolationAwareMLPModel(data='full', blend_threshold=0.5) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26383ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:33:00.350502Z",
     "iopub.status.busy": "2026-01-16T05:33:00.349954Z",
     "iopub.status.idle": "2026-01-16T05:33:00.359221Z",
     "shell.execute_reply": "2026-01-16T05:33:00.358869Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
