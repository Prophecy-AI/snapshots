{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08a6587",
   "metadata": {},
   "source": [
    "# Experiment 053: Exact Template Submission\n",
    "\n",
    "**Goal:** Use EXACTLY the template code structure to ensure submission format is correct.\n",
    "\n",
    "**Approach:** Copy the template code exactly, only changing the model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166392fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:42.798325Z",
     "iopub.status.busy": "2026-01-15T22:53:42.797876Z",
     "iopub.status.idle": "2026-01-15T22:53:43.775382Z",
     "shell.execute_reply": "2026-01-15T22:53:43.774882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and setup (from template)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# Data path for local execution\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d455d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:43.776646Z",
     "iopub.status.busy": "2026-01-15T22:53:43.776482Z",
     "iopub.status.idle": "2026-01-15T22:53:43.781748Z",
     "shell.execute_reply": "2026-01-15T22:53:43.781381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data loading functions (adapted for local paths)\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"\n",
    "]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_FEATURES = [\"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvents.\"\"\"\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvent ramps.\"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).any(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276dab63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:43.782597Z",
     "iopub.status.busy": "2026-01-15T22:53:43.782497Z",
     "iopub.status.idle": "2026-01-15T22:53:43.786190Z",
     "shell.execute_reply": "2026-01-15T22:53:43.785847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base classes defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Base classes (from template)\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "print(\"Base classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4966e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:43.787033Z",
     "iopub.status.busy": "2026-01-15T22:53:43.786936Z",
     "iopub.status.idle": "2026-01-15T22:53:43.791476Z",
     "shell.execute_reply": "2026-01-15T22:53:43.791132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Featurizer (from template)\n",
    "\n",
    "class PrecomputedFeaturizer(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        assert features in ['drfps_catechol', 'fragprints', 'smiles', 'acs_pca_descriptors', 'spange_descriptors']\n",
    "        self.features = features\n",
    "        self.featurizer = load_features(self.features)\n",
    "        self.feats_dim = self.featurizer.shape[1] + 2\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = X[INPUT_LABELS_NUMERIC]\n",
    "        X_smiles_feat = self.featurizer.loc[X[\"SOLVENT NAME\"]]\n",
    "        X_numeric_tensor = torch.tensor(X_numeric.values)\n",
    "        X_smiles_feat_tensor = torch.tensor(X_smiles_feat.values)\n",
    "        X_out = torch.cat((X_numeric_tensor, X_smiles_feat_tensor), dim=1)\n",
    "        return X_out\n",
    "\n",
    "class PrecomputedFeaturizerMixed(SmilesFeaturizer):\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        assert features in ['drfps_catechol', 'fragprints', 'smiles', 'acs_pca_descriptors', 'spange_descriptors']\n",
    "        self.features = features\n",
    "        self.featurizer = load_features(self.features)\n",
    "        self.feats_dim = self.featurizer.shape[1] * 2 + 3\n",
    "\n",
    "    def featurize(self, X):\n",
    "        X_numeric = X[INPUT_LABELS_NUMERIC]\n",
    "        X_smiles_A_feat = self.featurizer.loc[X[\"SOLVENT A NAME\"]]\n",
    "        X_smiles_B_feat = self.featurizer.loc[X[\"SOLVENT B NAME\"]]\n",
    "        X_solventB_pct = X[[\"SolventB%\"]]\n",
    "        X_numeric_tensor = torch.tensor(X_numeric.values)\n",
    "        X_smiles_A_feat_tensor = torch.tensor(X_smiles_A_feat.values)\n",
    "        X_smiles_B_feat_tensor = torch.tensor(X_smiles_B_feat.values)\n",
    "        X_solventB_pct_tensor = torch.tensor(X_solventB_pct.values)\n",
    "        X_out = torch.cat((X_numeric_tensor, X_smiles_A_feat_tensor, X_smiles_B_feat_tensor, X_solventB_pct_tensor), dim=1)\n",
    "        return X_out\n",
    "\n",
    "print(\"Featurizers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbb1065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:43.792334Z",
     "iopub.status.busy": "2026-01-15T22:53:43.792233Z",
     "iopub.status.idle": "2026-01-15T22:53:43.797532Z",
     "shell.execute_reply": "2026-01-15T22:53:43.797176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Simple MLP Model (from template, with minor improvements)\n",
    "\n",
    "class MLPModel(BaseModel):\n",
    "    def __init__(self, data='single'):\n",
    "        self.data = data\n",
    "        if data == 'single':\n",
    "            self.smiles_featurizer = PrecomputedFeaturizer()\n",
    "        else:\n",
    "            self.smiles_featurizer = PrecomputedFeaturizerMixed()\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler_mean = None\n",
    "        self.scaler_std = None\n",
    "\n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        X_tensor = self.smiles_featurizer.featurize(train_X)\n",
    "        Y_tensor = torch.tensor(train_Y.values)\n",
    "        \n",
    "        # Normalize inputs\n",
    "        self.scaler_mean = X_tensor.mean(dim=0)\n",
    "        self.scaler_std = X_tensor.std(dim=0) + 1e-8\n",
    "        X_tensor = (X_tensor - self.scaler_mean) / self.scaler_std\n",
    "        \n",
    "        # Simple MLP\n",
    "        input_dim = X_tensor.shape[1]\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 3)\n",
    "        ).double()\n",
    "        \n",
    "        # Training\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(200):\n",
    "            for batch_X, batch_Y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(batch_X)\n",
    "                loss = criterion(pred, batch_Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = self.smiles_featurizer.featurize(X)\n",
    "        X_tensor = (X_tensor - self.scaler_mean) / self.scaler_std\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(X_tensor)\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        pred = torch.clamp(pred, 0, 1)\n",
    "        \n",
    "        return pred\n",
    "\n",
    "print(\"MLPModel defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c189b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:43.798565Z",
     "iopub.status.busy": "2026-01-15T22:53:43.798464Z",
     "iopub.status.idle": "2026-01-15T22:53:47.318836Z",
     "shell.execute_reply": "2026-01-15T22:53:47.318144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Single solvent data: X=(656, 3), Y=(656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([37, 3])\n",
      "Predictions range: [0.0028, 0.8619]\n",
      "Model test passed!\n"
     ]
    }
   ],
   "source": [
    "# Quick test to verify model works\n",
    "print(\"Testing model...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# Test one fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = MLPModel()\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Predictions range: [{preds.min():.4f}, {preds.max():.4f}]\")\n",
    "print(\"Model test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c561366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:53:58.383514Z",
     "iopub.status.busy": "2026-01-15T22:53:58.382974Z",
     "iopub.status.idle": "2026-01-15T22:55:06.126584Z",
     "shell.execute_reply": "2026-01-15T22:55:06.126147Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:05,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:08,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:11,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:13,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:16,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:19,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:22,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:25,  2.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:28,  2.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:30,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:33,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:36,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:39,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:42,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:45,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:47,  2.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:50,  2.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:53,  2.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:56,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:59,  2.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [01:02,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [01:04,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:07,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [01:07,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent predictions: 656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPModel() # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a49a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:55:06.127852Z",
     "iopub.status.busy": "2026-01-15T22:55:06.127745Z",
     "iopub.status.idle": "2026-01-15T22:56:13.679500Z",
     "shell.execute_reply": "2026-01-15T22:56:13.679051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:05,  5.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:10,  5.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:15,  5.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:20,  5.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:25,  5.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:30,  5.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:35,  5.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:40,  5.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:46,  5.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:51,  5.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:56,  5.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [01:02,  5.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:07,  5.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [01:07,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data predictions: 1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = MLPModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1fd826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:56:13.680619Z",
     "iopub.status.busy": "2026-01-15T22:56:13.680513Z",
     "iopub.status.idle": "2026-01-15T22:56:13.691045Z",
     "shell.execute_reply": "2026-01-15T22:56:13.690686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /home/submission/submission.csv\n",
      "Total rows: 1883\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530ab5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:56:25.145582Z",
     "iopub.status.busy": "2026-01-15T22:56:25.145035Z",
     "iopub.status.idle": "2026-01-15T22:56:25.154610Z",
     "shell.execute_reply": "2026-01-15T22:56:25.154226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBMISSION VERIFICATION\n",
      "============================================================\n",
      "\n",
      "Columns: ['id', 'index', 'task', 'fold', 'row', 'target_1', 'target_2', 'target_3']\n",
      "Total rows: 1883\n",
      "Tasks: [0 1]\n",
      "Folds per task:\n",
      "task\n",
      "0    24\n",
      "1    13\n",
      "Name: fold, dtype: int64\n",
      "\n",
      "Target statistics:\n",
      "  target_1: min=0.000000, max=0.434598\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "  target_2: min=0.000000, max=0.435151\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "  target_3: min=0.000000, max=1.000000\n",
      "    Values > 1: 0\n",
      "    Values < 0: 0\n",
      "\n",
      "First 5 rows:\n",
      "   id  index  task  fold  row  target_1  target_2  target_3\n",
      "0   0      0     0     0    0  0.001120  0.001556  0.984652\n",
      "1   1      1     0     0    1  0.010681  0.008359  0.949444\n",
      "2   2      2     0     0    2  0.039946  0.027438  0.847869\n",
      "3   3      3     0     0    3  0.090046  0.059719  0.678352\n",
      "4   4      4     0     0    4  0.137220  0.091779  0.518236\n"
     ]
    }
   ],
   "source": [
    "# Verify submission format\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Tasks: {df['task'].unique()}\")\n",
    "print(f\"Folds per task:\")\n",
    "print(df.groupby('task')['fold'].nunique())\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f\"  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}\")\n",
    "    print(f\"    Values > 1: {(df[col] > 1).sum()}\")\n",
    "    print(f\"    Values < 0: {(df[col] < 0).sum()}\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5389289b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:56:25.155505Z",
     "iopub.status.busy": "2026-01-15T22:56:25.155413Z",
     "iopub.status.idle": "2026-01-15T22:58:40.435518Z",
     "shell.execute_reply": "2026-01-15T22:58:40.434962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CV CALCULATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent CV MSE: 0.008504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data CV MSE: 0.014875\n",
      "\n",
      "FINAL CV FOR LOGGING: 0.008504\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV for logging\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CV CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single solvent CV\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X, Y)):\n",
    "    model = MLPModel()\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "\n",
    "single_cv = np.mean(fold_mses)\n",
    "print(f\"Single solvent CV MSE: {single_cv:.6f}\")\n",
    "\n",
    "# Full data CV\n",
    "X, Y = load_data(\"full\")\n",
    "full_fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X, Y)):\n",
    "    model = MLPModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    full_fold_mses.append(mse)\n",
    "\n",
    "full_cv = np.mean(full_fold_mses)\n",
    "print(f\"Full data CV MSE: {full_cv:.6f}\")\n",
    "\n",
    "print(f\"\\nFINAL CV FOR LOGGING: {single_cv:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
