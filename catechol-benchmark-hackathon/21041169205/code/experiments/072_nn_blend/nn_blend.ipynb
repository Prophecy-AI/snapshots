{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5cc666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:00.169454Z",
     "iopub.status.busy": "2026-01-16T06:45:00.169003Z",
     "iopub.status.idle": "2026-01-16T06:45:01.879589Z",
     "shell.execute_reply": "2026-01-16T06:45:01.879128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Experiment 072: Nearest Neighbor Blending (Instead of Global Mean)\n",
    "#\n",
    "# Key fix from exp_071: Instead of blending toward GLOBAL mean, blend toward\n",
    "# the mean of k NEAREST training solvents. This preserves chemical similarity.\n",
    "#\n",
    "# For HFIP (highest outlier), this means blending toward other fluorinated alcohols\n",
    "# like TFE, not toward the global average.\n",
    "#\n",
    "# Also: Disable extrapolation detection for full data (it hurt performance 383%)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1948278b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.880797Z",
     "iopub.status.busy": "2026-01-16T06:45:01.880632Z",
     "iopub.status.idle": "2026-01-16T06:45:01.885074Z",
     "shell.execute_reply": "2026-01-16T06:45:01.884708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e57a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.886216Z",
     "iopub.status.busy": "2026-01-16T06:45:01.885913Z",
     "iopub.status.idle": "2026-01-16T06:45:01.914194Z",
     "shell.execute_reply": "2026-01-16T06:45:01.913832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b8e44a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.915153Z",
     "iopub.status.busy": "2026-01-16T06:45:01.915056Z",
     "iopub.status.idle": "2026-01-16T06:45:01.920626Z",
     "shell.execute_reply": "2026-01-16T06:45:01.920272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed outlier scores. Mean: 2.2408, Std: 1.0424\n",
      "\n",
      "Top outliers:\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: 4.5701 (z=2.23)\n",
      "  Cyclohexane: 4.1844 (z=1.86)\n",
      "  Water: 3.7000 (z=1.40)\n",
      "  Ethylene Glycol [1,2-Ethanediol]: 3.6865 (z=1.39)\n",
      "  2,2,2-Trifluoroethanol: 3.5894 (z=1.29)\n",
      "  Decanol: 2.8970 (z=0.63)\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute outlier scores for all solvents (excluding self)\n",
    "def compute_solvent_outlier_scores(k=3):\n",
    "    solvent_scaler = StandardScaler()\n",
    "    scaled_features = solvent_scaler.fit_transform(SPANGE_DF.values)\n",
    "    \n",
    "    outlier_scores = {}\n",
    "    for i, solvent in enumerate(SPANGE_DF.index):\n",
    "        other_indices = [j for j in range(len(SPANGE_DF)) if j != i]\n",
    "        other_features = scaled_features[other_indices]\n",
    "        distances = cdist([scaled_features[i]], other_features, metric='euclidean')[0]\n",
    "        k_nearest_dist = np.sort(distances)[:k].mean()\n",
    "        outlier_scores[solvent] = k_nearest_dist\n",
    "    \n",
    "    return outlier_scores, solvent_scaler, scaled_features\n",
    "\n",
    "SOLVENT_OUTLIER_SCORES, SOLVENT_SCALER, SCALED_SOLVENT_FEATURES = compute_solvent_outlier_scores(k=3)\n",
    "mean_outlier_score = np.mean(list(SOLVENT_OUTLIER_SCORES.values()))\n",
    "std_outlier_score = np.std(list(SOLVENT_OUTLIER_SCORES.values()))\n",
    "\n",
    "print(f\"Pre-computed outlier scores. Mean: {mean_outlier_score:.4f}, Std: {std_outlier_score:.4f}\")\n",
    "print(\"\\nTop outliers:\")\n",
    "for solvent, score in sorted(SOLVENT_OUTLIER_SCORES.items(), key=lambda x: x[1], reverse=True)[:6]:\n",
    "    z = (score - mean_outlier_score) / std_outlier_score\n",
    "    print(f\"  {solvent}: {score:.4f} (z={z:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e8f694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.921771Z",
     "iopub.status.busy": "2026-01-16T06:45:01.921640Z",
     "iopub.status.idle": "2026-01-16T06:45:01.924532Z",
     "shell.execute_reply": "2026-01-16T06:45:01.924189Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e970bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.925504Z",
     "iopub.status.busy": "2026-01-16T06:45:01.925378Z",
     "iopub.status.idle": "2026-01-16T06:45:01.930407Z",
     "shell.execute_reply": "2026-01-16T06:45:01.930030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Full Featurizer (for MLP and LGBM) - 145 features\n",
    "class FullFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "            X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "            X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "\n",
    "print(f'Full feature dimension: {FullFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9010e61d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.931531Z",
     "iopub.status.busy": "2026-01-16T06:45:01.931415Z",
     "iopub.status.idle": "2026-01-16T06:45:01.935558Z",
     "shell.execute_reply": "2026-01-16T06:45:01.935172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature dimension: 18\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer (for GP) - 18 features\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange])\n",
    "\n",
    "print(f'Simple feature dimension: {SimpleFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a5a5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:01.936496Z",
     "iopub.status.busy": "2026-01-16T06:45:01.936394Z",
     "iopub.status.idle": "2026-01-16T06:45:01.948790Z",
     "shell.execute_reply": "2026-01-16T06:45:01.948427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNBlendGPMLPLGBMEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# GP+MLP+LGBM Ensemble with Nearest Neighbor Blending\n",
    "# Key fix: Blend toward k nearest training solvents, NOT global mean\n",
    "\n",
    "class NNBlendGPMLPLGBMEnsemble(BaseModel):\n",
    "    def __init__(self, data='single', blend_threshold=1.5, k_neighbors=3,\n",
    "                 gp_weight=0.15, mlp_weight=0.55, lgbm_weight=0.30,\n",
    "                 apply_blend_to_full=False):  # Disable blending for full data by default\n",
    "        self.data_type = data\n",
    "        self.blend_threshold = blend_threshold\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.apply_blend_to_full = apply_blend_to_full\n",
    "        \n",
    "        self.mixed = (data == 'full')\n",
    "        self.full_featurizer = FullFeaturizer(mixed=self.mixed)\n",
    "        self.simple_featurizer = SimpleFeaturizer(mixed=self.mixed)\n",
    "        \n",
    "        self.gp_scaler = StandardScaler()\n",
    "        self.mlp_scaler = StandardScaler()\n",
    "        self.lgbm_scaler = StandardScaler()\n",
    "        \n",
    "        self.gp_models = []\n",
    "        self.lgbm_models = []\n",
    "        self.mlp = None\n",
    "        \n",
    "        self.train_Y = None\n",
    "        self.training_solvents = None\n",
    "        self.solvent_mean_predictions = {}  # Store mean prediction per solvent\n",
    "    \n",
    "    def get_blend_weight(self, solvent_name):\n",
    "        \"\"\"Get blend weight based on pre-computed outlier score.\"\"\"\n",
    "        score = SOLVENT_OUTLIER_SCORES.get(solvent_name, mean_outlier_score)\n",
    "        z_score = (score - mean_outlier_score) / std_outlier_score\n",
    "        blend_weight = np.clip((z_score - self.blend_threshold) / 2.0, 0, 1)\n",
    "        return blend_weight\n",
    "    \n",
    "    def get_nearest_training_mean(self, test_solvent):\n",
    "        \"\"\"Get mean prediction for k nearest training solvents.\"\"\"\n",
    "        if test_solvent not in SPANGE_DF.index:\n",
    "            return self.train_Y.mean(axis=0)  # Fallback to global mean\n",
    "        \n",
    "        test_features = SPANGE_DF.loc[test_solvent].values\n",
    "        test_scaled = SOLVENT_SCALER.transform([test_features])[0]\n",
    "        \n",
    "        distances = []\n",
    "        for train_solvent in self.training_solvents:\n",
    "            if train_solvent not in SPANGE_DF.index:\n",
    "                continue\n",
    "            train_idx = list(SPANGE_DF.index).index(train_solvent)\n",
    "            train_scaled = SCALED_SOLVENT_FEATURES[train_idx]\n",
    "            dist = np.linalg.norm(test_scaled - train_scaled)\n",
    "            distances.append((train_solvent, dist))\n",
    "        \n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        nearest = distances[:self.k_neighbors]\n",
    "        \n",
    "        # Get mean of nearest solvents' mean predictions\n",
    "        nearest_preds = []\n",
    "        for solvent, _ in nearest:\n",
    "            if solvent in self.solvent_mean_predictions:\n",
    "                nearest_preds.append(self.solvent_mean_predictions[solvent])\n",
    "        \n",
    "        if len(nearest_preds) == 0:\n",
    "            return self.train_Y.mean(axis=0)\n",
    "        \n",
    "        return np.mean(nearest_preds, axis=0)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.train_Y = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "        \n",
    "        # Store training solvents and their mean predictions\n",
    "        if self.data_type == 'single':\n",
    "            self.training_solvents = X_train[\"SOLVENT NAME\"].unique().tolist()\n",
    "            for solvent in self.training_solvents:\n",
    "                mask = X_train[\"SOLVENT NAME\"] == solvent\n",
    "                self.solvent_mean_predictions[solvent] = y_train[mask].values.mean(axis=0)\n",
    "        else:\n",
    "            self.training_solvents = list(set(X_train[\"SOLVENT A NAME\"].unique()) | set(X_train[\"SOLVENT B NAME\"].unique()))\n",
    "        \n",
    "        # Prepare features\n",
    "        X_simple = self.simple_featurizer.featurize(X_train)\n",
    "        X_full = self.full_featurizer.featurize(X_train)\n",
    "        \n",
    "        X_gp = self.gp_scaler.fit_transform(X_simple)\n",
    "        X_mlp = self.mlp_scaler.fit_transform(X_full)\n",
    "        X_lgbm = self.lgbm_scaler.fit_transform(X_full)\n",
    "        \n",
    "        Y = self.train_Y\n",
    "        \n",
    "        # Train GP models\n",
    "        self.gp_models = []\n",
    "        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "        for i in range(3):\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3, random_state=42)\n",
    "            gp.fit(X_gp, Y[:, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train LGBM models\n",
    "        self.lgbm_models = []\n",
    "        lgbm_params = {\n",
    "            'objective': 'regression', 'metric': 'mse', 'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'seed': 42\n",
    "        }\n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_lgbm, label=Y[:, i])\n",
    "            model = lgb.train(lgbm_params, train_data, num_boost_round=200)\n",
    "            self.lgbm_models.append(model)\n",
    "        \n",
    "        # Train MLP\n",
    "        input_dim = X_mlp.shape[1]\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(64, 3), nn.Sigmoid()\n",
    "        ).double().to(device)\n",
    "        \n",
    "        X_tensor = torch.tensor(X_mlp).to(device)\n",
    "        Y_tensor = torch.tensor(Y).to(device)\n",
    "        dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(200):\n",
    "            for batch_X, batch_Y in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(batch_X)\n",
    "                loss = criterion(pred, batch_Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Prepare features\n",
    "        X_simple = self.simple_featurizer.featurize(X)\n",
    "        X_full = self.full_featurizer.featurize(X)\n",
    "        \n",
    "        X_gp = self.gp_scaler.transform(X_simple)\n",
    "        X_mlp = self.mlp_scaler.transform(X_full)\n",
    "        X_lgbm = self.lgbm_scaler.transform(X_full)\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        gp_preds = np.column_stack([gp.predict(X_gp) for gp in self.gp_models])\n",
    "        lgbm_preds = np.column_stack([model.predict(X_lgbm) for model in self.lgbm_models])\n",
    "        \n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X_mlp).to(device)\n",
    "            mlp_preds = self.mlp(X_tensor).cpu().numpy()\n",
    "        \n",
    "        # Ensemble prediction\n",
    "        raw_pred = self.gp_weight * gp_preds + self.mlp_weight * mlp_preds + self.lgbm_weight * lgbm_preds\n",
    "        \n",
    "        # Apply nearest neighbor blending (only for single solvents, or if explicitly enabled for full)\n",
    "        if self.data_type == 'single' or self.apply_blend_to_full:\n",
    "            if self.data_type == 'single':\n",
    "                solvent_names = X[\"SOLVENT NAME\"].values\n",
    "                unique_solvents = list(set(solvent_names))\n",
    "                \n",
    "                # For each unique solvent, compute blend weight and nearest neighbor mean\n",
    "                blended = raw_pred.copy()\n",
    "                for solvent in unique_solvents:\n",
    "                    blend_weight = self.get_blend_weight(solvent)\n",
    "                    if blend_weight > 0:\n",
    "                        nn_mean = self.get_nearest_training_mean(solvent)\n",
    "                        mask = solvent_names == solvent\n",
    "                        blended[mask] = (1 - blend_weight) * raw_pred[mask] + blend_weight * nn_mean\n",
    "            else:\n",
    "                blended = raw_pred  # Don't blend for full data\n",
    "        else:\n",
    "            blended = raw_pred\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        blended = np.clip(blended, 0, 1)\n",
    "        \n",
    "        return torch.tensor(blended)\n",
    "\n",
    "print('NNBlendGPMLPLGBMEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80731441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:11.080814Z",
     "iopub.status.busy": "2026-01-16T06:45:11.080278Z",
     "iopub.status.idle": "2026-01-16T06:57:54.416532Z",
     "shell.execute_reply": "2026-01-16T06:57:54.416064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:36, 36.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:06, 32.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:31, 29.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:58, 28.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:31, 30.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [03:03, 30.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:36, 31.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [04:04, 30.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:38, 31.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [05:10, 31.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [05:43, 31.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [06:14, 31.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [06:47, 32.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [07:17, 31.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [07:52, 32.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [08:25, 32.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [09:00, 33.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [09:33, 33.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [10:05, 32.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [10:35, 32.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [11:06, 31.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [11:43, 33.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [12:11, 31.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [12:43, 31.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [12:43, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent predictions shape: (656, 6)\n",
      "  Fold 0 (1,1,1,3,3,3-Hexafluoropropan-2-ol): MSE=0.035719, blend_weight=0.367\n",
      "  Fold 6 (Cyclohexane): MSE=0.006270, blend_weight=0.182\n",
      "Single solvent CV MSE: 0.008623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = NNBlendGPMLPLGBMEnsemble(data='single', blend_threshold=1.5, k_neighbors=3) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "print(f\"Single solvent predictions shape: {submission_single_solvent.shape}\")\n",
    "\n",
    "# Calculate CV score for single solvent\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_mse = []\n",
    "for fold_idx, split in enumerate(split_generator):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    fold_preds = submission_single_solvent[submission_single_solvent['fold'] == fold_idx]\n",
    "    pred_values = fold_preds[['target_1', 'target_2', 'target_3']].values\n",
    "    true_values = test_Y.values\n",
    "    mse = ((pred_values - true_values) ** 2).mean()\n",
    "    all_mse.append(mse)\n",
    "    solvent = test_X[\"SOLVENT NAME\"].iloc[0]\n",
    "    blend_weight = model.get_blend_weight(solvent)\n",
    "    if blend_weight > 0:\n",
    "        print(f\"  Fold {fold_idx} ({solvent}): MSE={mse:.6f}, blend_weight={blend_weight:.3f}\")\n",
    "print(f\"Single solvent CV MSE: {np.mean(all_mse):.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = NNBlendGPMLPLGBMEnsemble(data='full', blend_threshold=1.5, apply_blend_to_full=False) # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "print(f\"Full data predictions shape: {submission_full_data.shape}\")\n",
    "\n",
    "# Calculate CV score for full data\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_mse = []\n",
    "for fold_idx, split in enumerate(split_generator):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    fold_preds = submission_full_data[submission_full_data['fold'] == fold_idx]\n",
    "    pred_values = fold_preds[['target_1', 'target_2', 'target_3']].values\n",
    "    true_values = test_Y.values\n",
    "    mse = ((pred_values - true_values) ** 2).mean()\n",
    "    all_mse.append(mse)\n",
    "print(f\"Full data CV MSE: {np.mean(all_mse):.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687eddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"submission.csv\", index=True)\n",
    "\n",
    "# Also save to /home/submission/\n",
    "import shutil\n",
    "shutil.copy(\"submission.csv\", \"/home/submission/submission.csv\")\n",
    "\n",
    "print(f\"Submission saved. Shape: {submission.shape}\")\n",
    "print(f\"Predictions range: target_1 [{submission['target_1'].min():.3f}, {submission['target_1'].max():.3f}]\")\n",
    "print(f\"Predictions range: target_2 [{submission['target_2'].min():.3f}, {submission['target_2'].max():.3f}]\")\n",
    "print(f\"Predictions range: target_3 [{submission['target_3'].min():.3f}, {submission['target_3'].max():.3f}]\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
