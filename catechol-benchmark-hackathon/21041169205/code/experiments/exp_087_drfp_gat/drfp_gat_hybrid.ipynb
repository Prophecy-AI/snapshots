{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299f0dbe",
   "metadata": {},
   "source": [
    "# Experiment 087: DRFP + GAT Hybrid Model\n",
    "\n",
    "**Rationale**: The GNN benchmark (arXiv:2512.19530) achieved MSE 0.0039 using:\n",
    "1. GAT + DRFP combined\n",
    "2. Learned mixture-aware solvent encodings\n",
    "3. Explicit molecular graph message-passing\n",
    "\n",
    "**Key improvements over exp_086:**\n",
    "- Add DRFP features (2048-dim) alongside graph features\n",
    "- Implement learned mixture-aware encoding (not just concatenation)\n",
    "- Combine DRFP + GAT outputs before final MLP\n",
    "- Train for 500 epochs with proper LR scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cda7aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:42.413934Z",
     "iopub.status.busy": "2026-01-16T13:59:42.413454Z",
     "iopub.status.idle": "2026-01-16T13:59:44.492784Z",
     "shell.execute_reply": "2026-01-16T13:59:44.492342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "Memory: 85.0 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from rdkit import Chem\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d0554e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.494135Z",
     "iopub.status.busy": "2026-01-16T13:59:44.493973Z",
     "iopub.status.idle": "2026-01-16T13:59:44.534517Z",
     "shell.execute_reply": "2026-01-16T13:59:44.534147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 SMILES\n",
      "Loaded 24 DRFP vectors (dim=2048)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "def load_data(data_type):\n",
    "    if data_type == \"single_solvent\":\n",
    "        df = pd.read_csv('/home/data/catechol_single_solvent_yields.csv')\n",
    "        X = df[['Residence Time', 'Temperature', 'SOLVENT NAME']]\n",
    "        Y = df[['SM', 'Product 2', 'Product 3']]\n",
    "    elif data_type == \"full\":\n",
    "        df = pd.read_csv('/home/data/catechol_full_data_yields.csv')\n",
    "        X = df[['Residence Time', 'Temperature', 'SOLVENT A NAME', 'SOLVENT B NAME', 'SolventB%']]\n",
    "        Y = df[['SM', 'Product 2', 'Product 3']]\n",
    "    return X, Y\n",
    "\n",
    "# Load SMILES lookup\n",
    "smiles_df = pd.read_csv('/home/data/smiles_lookup.csv')\n",
    "smiles_dict = dict(zip(smiles_df['SOLVENT NAME'], smiles_df['solvent smiles']))\n",
    "print(f\"Loaded {len(smiles_dict)} SMILES\")\n",
    "\n",
    "# Load DRFP features\n",
    "drfp_df = pd.read_csv('/home/data/drfps_catechol_lookup.csv')\n",
    "drfp_cols = [str(i) for i in range(2048)]\n",
    "drfp_dict = {}\n",
    "for _, row in drfp_df.iterrows():\n",
    "    name = row['SOLVENT NAME']\n",
    "    drfp_dict[name] = row[drfp_cols].values.astype(np.float32)\n",
    "print(f\"Loaded {len(drfp_dict)} DRFP vectors (dim={len(drfp_cols)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3911a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.535497Z",
     "iopub.status.busy": "2026-01-16T13:59:44.535397Z",
     "iopub.status.idle": "2026-01-16T13:59:44.539127Z",
     "shell.execute_reply": "2026-01-16T13:59:44.538789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV split functions defined\n"
     ]
    }
   ],
   "source": [
    "# Official CV split functions (DO NOT MODIFY)\n",
    "from typing import Any, Generator\n",
    "\n",
    "def generate_leave_one_out_splits(\n",
    "    X: pd.DataFrame, Y: pd.DataFrame\n",
    ") -> Generator[\n",
    "    tuple[tuple[pd.DataFrame, pd.DataFrame], tuple[pd.DataFrame, pd.DataFrame]],\n",
    "    Any,\n",
    "    None,\n",
    "]:\n",
    "    for solvent in X[\"SOLVENT NAME\"].unique():\n",
    "        train_mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        test_mask = X[\"SOLVENT NAME\"] == solvent\n",
    "        yield (\n",
    "            (X[train_mask], Y[train_mask]),\n",
    "            (X[test_mask], Y[test_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(\n",
    "    X: pd.DataFrame, Y: pd.DataFrame\n",
    ") -> Generator[\n",
    "    tuple[tuple[pd.DataFrame, pd.DataFrame], tuple[pd.DataFrame, pd.DataFrame]],\n",
    "    Any,\n",
    "    None,\n",
    "]:\n",
    "    ramps = X[\"SOLVENT A NAME\"].astype(str) + \"_\" + X[\"SOLVENT B NAME\"].astype(str)\n",
    "    for ramp in ramps.unique():\n",
    "        train_mask = ramps != ramp\n",
    "        test_mask = ramps == ramp\n",
    "        yield (\n",
    "            (X[train_mask], Y[train_mask]),\n",
    "            (X[test_mask], Y[test_mask]),\n",
    "        )\n",
    "\n",
    "print(\"CV split functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512f5aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.539958Z",
     "iopub.status.busy": "2026-01-16T13:59:44.539868Z",
     "iopub.status.idle": "2026-01-16T13:59:44.552237Z",
     "shell.execute_reply": "2026-01-16T13:59:44.551902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 26 solvent graphs\n"
     ]
    }
   ],
   "source": [
    "# Convert SMILES to molecular graph with edge features\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "            int(atom.IsInRing()),\n",
    "            atom.GetMass() / 100.0,\n",
    "            int(atom.GetChiralTag()),\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    bond_type_map = {\n",
    "        Chem.rdchem.BondType.SINGLE: 0,\n",
    "        Chem.rdchem.BondType.DOUBLE: 1,\n",
    "        Chem.rdchem.BondType.TRIPLE: 2,\n",
    "        Chem.rdchem.BondType.AROMATIC: 3,\n",
    "    }\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type = bond_type_map.get(bond.GetBondType(), 0)\n",
    "        bond_order = bond.GetBondTypeAsDouble()\n",
    "        is_aromatic = int(bond.GetIsAromatic())\n",
    "        is_conjugated = int(bond.GetIsConjugated())\n",
    "        is_in_ring = int(bond.IsInRing())\n",
    "        edge_feat = [bond_type, bond_order, is_aromatic, is_conjugated, is_in_ring]\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "        edge_features.append(edge_feat)\n",
    "        edge_features.append(edge_feat)\n",
    "    \n",
    "    if len(edge_index) == 0:\n",
    "        edge_index = [[0, 0]]\n",
    "        edge_features = [[0, 1.0, 0, 0, 0]]\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Pre-compute all solvent graphs\n",
    "solvent_graphs = {}\n",
    "for name, smiles in smiles_dict.items():\n",
    "    graph = smiles_to_graph(smiles)\n",
    "    if graph is not None:\n",
    "        solvent_graphs[name] = graph\n",
    "print(f\"Total: {len(solvent_graphs)} solvent graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969df853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.553092Z",
     "iopub.status.busy": "2026-01-16T13:59:44.553003Z",
     "iopub.status.idle": "2026-01-16T13:59:44.558063Z",
     "shell.execute_reply": "2026-01-16T13:59:44.557716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRFPGATHybrid defined\n"
     ]
    }
   ],
   "source": [
    "# DRFP + GAT Hybrid Model for SINGLE SOLVENT\n",
    "class DRFPGATHybrid(nn.Module):\n",
    "    def __init__(self, drfp_dim=2048, atom_dim=9, edge_dim=5, hidden_dim=128, out_dim=3, heads=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DRFP encoder\n",
    "        self.drfp_encoder = nn.Sequential(\n",
    "            nn.Linear(drfp_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # GAT encoder\n",
    "        self.gat_convs = nn.ModuleList()\n",
    "        self.gat_bns = nn.ModuleList()\n",
    "        \n",
    "        self.gat_convs.append(GATConv(atom_dim, hidden_dim // heads, heads=heads, edge_dim=edge_dim, concat=True))\n",
    "        self.gat_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            self.gat_convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, edge_dim=edge_dim, concat=True))\n",
    "            self.gat_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Final MLP: DRFP_emb + GAT_emb + T + RT\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, out_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode_graph(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        for i, (conv, bn) in enumerate(zip(self.gat_convs, self.gat_bns)):\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "    def forward(self, drfp, graph_data, T, RT):\n",
    "        drfp_emb = self.drfp_encoder(drfp)\n",
    "        gat_emb = self.encode_graph(graph_data)\n",
    "        combined = torch.cat([drfp_emb, gat_emb, T.unsqueeze(1), RT.unsqueeze(1)], dim=1)\n",
    "        return self.final_mlp(combined)\n",
    "\n",
    "print(\"DRFPGATHybrid defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd40db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.558891Z",
     "iopub.status.busy": "2026-01-16T13:59:44.558787Z",
     "iopub.status.idle": "2026-01-16T13:59:44.564561Z",
     "shell.execute_reply": "2026-01-16T13:59:44.564221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRFPGATMixtureHybrid defined\n"
     ]
    }
   ],
   "source": [
    "# DRFP + GAT Hybrid Model for MIXTURES with LEARNED mixture encoding\n",
    "class DRFPGATMixtureHybrid(nn.Module):\n",
    "    def __init__(self, drfp_dim=2048, atom_dim=9, edge_dim=5, hidden_dim=128, out_dim=3, heads=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DRFP encoder (shared for both solvents)\n",
    "        self.drfp_encoder = nn.Sequential(\n",
    "            nn.Linear(drfp_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # GAT encoder (shared for both solvents)\n",
    "        self.gat_convs = nn.ModuleList()\n",
    "        self.gat_bns = nn.ModuleList()\n",
    "        \n",
    "        self.gat_convs.append(GATConv(atom_dim, hidden_dim // heads, heads=heads, edge_dim=edge_dim, concat=True))\n",
    "        self.gat_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            self.gat_convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, edge_dim=edge_dim, concat=True))\n",
    "            self.gat_bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # LEARNED mixture encoding - key innovation!\n",
    "        # Instead of simple concatenation, learn how to combine solvent embeddings\n",
    "        self.mixture_attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 4 + 1, hidden_dim),  # A_drfp + A_gat + B_drfp + B_gat + mix_frac\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Final MLP: mixture_emb + T + RT\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim // 2, out_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode_graph(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        for i, (conv, bn) in enumerate(zip(self.gat_convs, self.gat_bns)):\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "    def forward(self, drfp_A, drfp_B, graph_A, graph_B, mix_frac, T, RT):\n",
    "        # Encode both solvents\n",
    "        drfp_emb_A = self.drfp_encoder(drfp_A)\n",
    "        drfp_emb_B = self.drfp_encoder(drfp_B)\n",
    "        gat_emb_A = self.encode_graph(graph_A)\n",
    "        gat_emb_B = self.encode_graph(graph_B)\n",
    "        \n",
    "        # LEARNED mixture encoding\n",
    "        mixture_input = torch.cat([drfp_emb_A, gat_emb_A, drfp_emb_B, gat_emb_B, mix_frac.unsqueeze(1)], dim=1)\n",
    "        mixture_emb = self.mixture_attention(mixture_input)\n",
    "        \n",
    "        # Final prediction\n",
    "        combined = torch.cat([mixture_emb, T.unsqueeze(1), RT.unsqueeze(1)], dim=1)\n",
    "        return self.final_mlp(combined)\n",
    "\n",
    "print(\"DRFPGATMixtureHybrid defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5aa662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:44.565505Z",
     "iopub.status.busy": "2026-01-16T13:59:44.565411Z",
     "iopub.status.idle": "2026-01-16T13:59:44.583198Z",
     "shell.execute_reply": "2026-01-16T13:59:44.582653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridModel wrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Model wrapper\n",
    "class HybridModel:\n",
    "    def __init__(self, data='single', hidden_dim=128, num_epochs=400, lr=1e-3, heads=4, num_layers=3):\n",
    "        self.data_type = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.heads = heads\n",
    "        self.num_layers = num_layers\n",
    "        self.model = None\n",
    "        \n",
    "    def train_model(self, train_X, train_Y):\n",
    "        if self.mixed:\n",
    "            self._train_mixed(train_X, train_Y)\n",
    "        else:\n",
    "            self._train_single(train_X, train_Y)\n",
    "    \n",
    "    def _train_single(self, train_X, train_Y):\n",
    "        drfps = []\n",
    "        graphs = []\n",
    "        temps = []\n",
    "        rts = []\n",
    "        targets = []\n",
    "        \n",
    "        for i in range(len(train_X)):\n",
    "            row = train_X.iloc[i]\n",
    "            solvent_name = row['SOLVENT NAME']\n",
    "            \n",
    "            if solvent_name not in solvent_graphs or solvent_name not in drfp_dict:\n",
    "                continue\n",
    "            \n",
    "            drfps.append(drfp_dict[solvent_name])\n",
    "            graphs.append(solvent_graphs[solvent_name].clone())\n",
    "            temps.append(row['Temperature'])\n",
    "            rts.append(row['Residence Time'])\n",
    "            targets.append(train_Y.iloc[i].values)\n",
    "        \n",
    "        # Normalize\n",
    "        temps = np.array(temps)\n",
    "        rts = np.array(rts)\n",
    "        self.temp_mean, self.temp_std = temps.mean(), temps.std() + 1e-8\n",
    "        self.rt_mean, self.rt_std = rts.mean(), rts.std() + 1e-8\n",
    "        temps = (temps - self.temp_mean) / self.temp_std\n",
    "        rts = (rts - self.rt_mean) / self.rt_std\n",
    "        \n",
    "        drfps = torch.tensor(np.array(drfps), dtype=torch.float).to(device)\n",
    "        temps = torch.tensor(temps, dtype=torch.float).to(device)\n",
    "        rts = torch.tensor(rts, dtype=torch.float).to(device)\n",
    "        targets = torch.tensor(np.array(targets), dtype=torch.float).to(device)\n",
    "        \n",
    "        # Model\n",
    "        self.model = DRFPGATHybrid(\n",
    "            drfp_dim=2048, atom_dim=9, edge_dim=5, hidden_dim=self.hidden_dim,\n",
    "            out_dim=3, heads=self.heads, num_layers=self.num_layers\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.num_epochs, eta_min=1e-6)\n",
    "        \n",
    "        self.model.train()\n",
    "        batch_size = 32\n",
    "        n_samples = len(graphs)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            total_loss = 0\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                batch_graphs = [graphs[i].to(device) for i in batch_idx]\n",
    "                batch_data = Batch.from_data_list(batch_graphs)\n",
    "                batch_drfp = drfps[batch_idx]\n",
    "                batch_T = temps[batch_idx]\n",
    "                batch_RT = rts[batch_idx]\n",
    "                batch_targets = targets[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_drfp, batch_data, batch_T, batch_RT)\n",
    "                loss = F.mse_loss(outputs, batch_targets)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * len(batch_idx)\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def _train_mixed(self, train_X, train_Y):\n",
    "        drfps_A = []\n",
    "        drfps_B = []\n",
    "        graphs_A = []\n",
    "        graphs_B = []\n",
    "        mix_fracs = []\n",
    "        temps = []\n",
    "        rts = []\n",
    "        targets = []\n",
    "        \n",
    "        for i in range(len(train_X)):\n",
    "            row = train_X.iloc[i]\n",
    "            solvent_A = row['SOLVENT A NAME']\n",
    "            solvent_B = row['SOLVENT B NAME']\n",
    "            \n",
    "            if solvent_A not in solvent_graphs or solvent_A not in drfp_dict:\n",
    "                continue\n",
    "            if solvent_B not in solvent_graphs or solvent_B not in drfp_dict:\n",
    "                continue\n",
    "            \n",
    "            drfps_A.append(drfp_dict[solvent_A])\n",
    "            drfps_B.append(drfp_dict[solvent_B])\n",
    "            graphs_A.append(solvent_graphs[solvent_A].clone())\n",
    "            graphs_B.append(solvent_graphs[solvent_B].clone())\n",
    "            mix_fracs.append(row['SolventB%'] / 100.0)\n",
    "            temps.append(row['Temperature'])\n",
    "            rts.append(row['Residence Time'])\n",
    "            targets.append(train_Y.iloc[i].values)\n",
    "        \n",
    "        # Normalize\n",
    "        temps = np.array(temps)\n",
    "        rts = np.array(rts)\n",
    "        mix_fracs = np.array(mix_fracs)\n",
    "        self.temp_mean, self.temp_std = temps.mean(), temps.std() + 1e-8\n",
    "        self.rt_mean, self.rt_std = rts.mean(), rts.std() + 1e-8\n",
    "        temps = (temps - self.temp_mean) / self.temp_std\n",
    "        rts = (rts - self.rt_mean) / self.rt_std\n",
    "        \n",
    "        drfps_A = torch.tensor(np.array(drfps_A), dtype=torch.float).to(device)\n",
    "        drfps_B = torch.tensor(np.array(drfps_B), dtype=torch.float).to(device)\n",
    "        temps = torch.tensor(temps, dtype=torch.float).to(device)\n",
    "        rts = torch.tensor(rts, dtype=torch.float).to(device)\n",
    "        mix_fracs = torch.tensor(mix_fracs, dtype=torch.float).to(device)\n",
    "        targets = torch.tensor(np.array(targets), dtype=torch.float).to(device)\n",
    "        \n",
    "        # Model\n",
    "        self.model = DRFPGATMixtureHybrid(\n",
    "            drfp_dim=2048, atom_dim=9, edge_dim=5, hidden_dim=self.hidden_dim,\n",
    "            out_dim=3, heads=self.heads, num_layers=self.num_layers\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.num_epochs, eta_min=1e-6)\n",
    "        \n",
    "        self.model.train()\n",
    "        batch_size = 32\n",
    "        n_samples = len(graphs_A)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            total_loss = 0\n",
    "            \n",
    "            for start in range(0, n_samples, batch_size):\n",
    "                end = min(start + batch_size, n_samples)\n",
    "                batch_idx = indices[start:end]\n",
    "                \n",
    "                batch_A = [graphs_A[i].to(device) for i in batch_idx]\n",
    "                batch_B = [graphs_B[i].to(device) for i in batch_idx]\n",
    "                data_A = Batch.from_data_list(batch_A)\n",
    "                data_B = Batch.from_data_list(batch_B)\n",
    "                batch_drfp_A = drfps_A[batch_idx]\n",
    "                batch_drfp_B = drfps_B[batch_idx]\n",
    "                batch_mix = mix_fracs[batch_idx]\n",
    "                batch_T = temps[batch_idx]\n",
    "                batch_RT = rts[batch_idx]\n",
    "                batch_targets = targets[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_drfp_A, batch_drfp_B, data_A, data_B, batch_mix, batch_T, batch_RT)\n",
    "                loss = F.mse_loss(outputs, batch_targets)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * len(batch_idx)\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if self.mixed:\n",
    "                return self._predict_mixed(test_X)\n",
    "            else:\n",
    "                return self._predict_single(test_X)\n",
    "    \n",
    "    def _predict_single(self, test_X):\n",
    "        drfps = []\n",
    "        graphs = []\n",
    "        temps = []\n",
    "        rts = []\n",
    "        \n",
    "        for i in range(len(test_X)):\n",
    "            row = test_X.iloc[i]\n",
    "            solvent_name = row['SOLVENT NAME']\n",
    "            \n",
    "            if solvent_name not in solvent_graphs or solvent_name not in drfp_dict:\n",
    "                # Fallback\n",
    "                drfps.append(list(drfp_dict.values())[0])\n",
    "                graphs.append(list(solvent_graphs.values())[0].clone())\n",
    "            else:\n",
    "                drfps.append(drfp_dict[solvent_name])\n",
    "                graphs.append(solvent_graphs[solvent_name].clone())\n",
    "            \n",
    "            temps.append(row['Temperature'])\n",
    "            rts.append(row['Residence Time'])\n",
    "        \n",
    "        temps = (np.array(temps) - self.temp_mean) / self.temp_std\n",
    "        rts = (np.array(rts) - self.rt_mean) / self.rt_std\n",
    "        \n",
    "        drfps = torch.tensor(np.array(drfps), dtype=torch.float).to(device)\n",
    "        temps = torch.tensor(temps, dtype=torch.float).to(device)\n",
    "        rts = torch.tensor(rts, dtype=torch.float).to(device)\n",
    "        \n",
    "        batch_data = Batch.from_data_list([g.to(device) for g in graphs])\n",
    "        outputs = self.model(drfps, batch_data, temps, rts)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def _predict_mixed(self, test_X):\n",
    "        drfps_A = []\n",
    "        drfps_B = []\n",
    "        graphs_A = []\n",
    "        graphs_B = []\n",
    "        mix_fracs = []\n",
    "        temps = []\n",
    "        rts = []\n",
    "        \n",
    "        for i in range(len(test_X)):\n",
    "            row = test_X.iloc[i]\n",
    "            solvent_A = row['SOLVENT A NAME']\n",
    "            solvent_B = row['SOLVENT B NAME']\n",
    "            \n",
    "            if solvent_A not in solvent_graphs or solvent_A not in drfp_dict:\n",
    "                drfps_A.append(list(drfp_dict.values())[0])\n",
    "                graphs_A.append(list(solvent_graphs.values())[0].clone())\n",
    "            else:\n",
    "                drfps_A.append(drfp_dict[solvent_A])\n",
    "                graphs_A.append(solvent_graphs[solvent_A].clone())\n",
    "            \n",
    "            if solvent_B not in solvent_graphs or solvent_B not in drfp_dict:\n",
    "                drfps_B.append(list(drfp_dict.values())[0])\n",
    "                graphs_B.append(list(solvent_graphs.values())[0].clone())\n",
    "            else:\n",
    "                drfps_B.append(drfp_dict[solvent_B])\n",
    "                graphs_B.append(solvent_graphs[solvent_B].clone())\n",
    "            \n",
    "            mix_fracs.append(row['SolventB%'] / 100.0)\n",
    "            temps.append(row['Temperature'])\n",
    "            rts.append(row['Residence Time'])\n",
    "        \n",
    "        temps = (np.array(temps) - self.temp_mean) / self.temp_std\n",
    "        rts = (np.array(rts) - self.rt_mean) / self.rt_std\n",
    "        \n",
    "        drfps_A = torch.tensor(np.array(drfps_A), dtype=torch.float).to(device)\n",
    "        drfps_B = torch.tensor(np.array(drfps_B), dtype=torch.float).to(device)\n",
    "        temps = torch.tensor(temps, dtype=torch.float).to(device)\n",
    "        rts = torch.tensor(rts, dtype=torch.float).to(device)\n",
    "        mix_fracs = torch.tensor(np.array(mix_fracs), dtype=torch.float).to(device)\n",
    "        \n",
    "        data_A = Batch.from_data_list([g.to(device) for g in graphs_A])\n",
    "        data_B = Batch.from_data_list([g.to(device) for g in graphs_B])\n",
    "        \n",
    "        outputs = self.model(drfps_A, drfps_B, data_A, data_B, mix_fracs, temps, rts)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "print(\"HybridModel wrapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16545766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T13:59:54.459789Z",
     "iopub.status.busy": "2026-01-16T13:59:54.459310Z",
     "iopub.status.idle": "2026-01-16T14:22:20.247577Z",
     "shell.execute_reply": "2026-01-16T14:22:20.247168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: 656 samples, 24 solvents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:56<21:46, 56.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [01:53<20:44, 56.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [02:49<19:43, 56.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [03:43<18:27, 55.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [04:39<17:35, 55.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [05:38<17:01, 56.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [06:34<16:01, 56.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [07:27<14:48, 55.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [08:23<13:56, 55.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [09:20<13:04, 56.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [10:16<12:08, 56.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [11:12<11:12, 56.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [12:08<10:15, 55.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [13:04<09:19, 55.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [14:00<08:23, 55.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [14:56<07:28, 56.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [15:52<06:32, 56.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [16:48<05:36, 56.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [17:44<04:40, 56.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [18:40<03:44, 56.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [19:37<02:48, 56.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [20:33<01:52, 56.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [21:30<00:56, 56.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [22:25<00:00, 56.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [22:25<00:00, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single solvent predictions: 656 rows\n",
      "Mean fold MSE: 0.016990 ± 0.016228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV for single solvent data\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: {len(X)} samples, {len(X['SOLVENT NAME'].unique())} solvents\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = HybridModel(data='single', hidden_dim=128, num_epochs=400, lr=1e-3, heads=4, num_layers=3)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    fold_mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "    fold_mses.append(fold_mse)\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "print(f\"\\nSingle solvent predictions: {len(submission_single_solvent)} rows\")\n",
    "print(f\"Mean fold MSE: {np.mean(fold_mses):.6f} ± {np.std(fold_mses):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd37f4f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T14:22:31.800583Z",
     "iopub.status.busy": "2026-01-16T14:22:31.800019Z",
     "iopub.status.idle": "2026-01-16T15:02:59.734805Z",
     "shell.execute_reply": "2026-01-16T15:02:59.734371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data: 1227 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [03:01<36:18, 181.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [06:02<33:12, 181.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [09:08<30:32, 183.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [12:08<27:19, 182.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [15:09<24:12, 181.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [18:10<21:09, 181.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [21:11<18:08, 181.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [24:14<15:08, 181.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [27:15<12:06, 181.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [30:33<09:20, 186.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [33:51<06:20, 190.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [37:09<03:12, 192.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [40:27<00:00, 194.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [40:27<00:00, 186.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full data predictions: 1227 rows\n",
      "Mean fold MSE: 0.020746 ± 0.013590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run CV for full (mixture) data\n",
    "X, Y = load_data(\"full\")\n",
    "print(f\"Full data: {len(X)} samples\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = HybridModel(data='full', hidden_dim=128, num_epochs=400, lr=1e-3, heads=4, num_layers=3)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    fold_mse = np.mean((predictions_np - test_Y.values) ** 2)\n",
    "    fold_mses.append(fold_mse)\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "print(f\"\\nFull data predictions: {len(submission_full_data)} rows\")\n",
    "print(f\"Mean fold MSE: {np.mean(fold_mses):.6f} ± {np.std(fold_mses):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecbd59d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:03:10.207821Z",
     "iopub.status.busy": "2026-01-16T15:03:10.207262Z",
     "iopub.status.idle": "2026-01-16T15:03:10.218930Z",
     "shell.execute_reply": "2026-01-16T15:03:10.218437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1883, 7)\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "\n",
      "Submission rows: 1883\n",
      "target_1: min=0.0008, max=0.9817\n",
      "target_2: min=0.0003, max=0.4334\n",
      "target_3: min=0.0003, max=0.4641\n"
     ]
    }
   ],
   "source": [
    "# Combine and save submission\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "\n",
    "submission_check = pd.read_csv(\"/home/submission/submission.csv\")\n",
    "print(f\"\\nSubmission rows: {len(submission_check)}\")\n",
    "\n",
    "target_cols = ['target_1', 'target_2', 'target_3']\n",
    "for col in target_cols:\n",
    "    print(f\"{col}: min={submission_check[col].min():.4f}, max={submission_check[col].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1a8659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:03:10.220227Z",
     "iopub.status.busy": "2026-01-16T15:03:10.220075Z",
     "iopub.status.idle": "2026-01-16T15:03:10.222964Z",
     "shell.execute_reply": "2026-01-16T15:03:10.222614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EXPERIMENT 087 COMPLETE\n",
      "==================================================\n",
      "\n",
      "Key techniques:\n",
      "1. DRFP features (2048-dim) + GAT graph embeddings\n",
      "2. LEARNED mixture-aware encoding (not simple concatenation)\n",
      "3. GAT with 4 heads, 3 layers, 128 hidden dim\n",
      "4. 400 epochs with cosine annealing LR\n",
      "5. Combined DRFP + GAT before final MLP\n",
      "\n",
      "This implements the key ingredients from the GNN benchmark (arXiv:2512.19530).\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall CV score\n",
    "print(\"=\"*50)\n",
    "print(\"EXPERIMENT 087 COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get the MSE values from the fold results\n",
    "single_cv = 0.0  # Will be filled from output\n",
    "full_cv = 0.0  # Will be filled from output\n",
    "\n",
    "print(f\"\\nKey techniques:\")\n",
    "print(\"1. DRFP features (2048-dim) + GAT graph embeddings\")\n",
    "print(\"2. LEARNED mixture-aware encoding (not simple concatenation)\")\n",
    "print(\"3. GAT with 4 heads, 3 layers, 128 hidden dim\")\n",
    "print(\"4. 400 epochs with cosine annealing LR\")\n",
    "print(\"5. Combined DRFP + GAT before final MLP\")\n",
    "print(\"\\nThis implements the key ingredients from the GNN benchmark (arXiv:2512.19530).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV score\n",
    "single_cv = 0.016990\n",
    "full_cv = 0.020746\n",
    "\n",
    "# Weighted by sample count\n",
    "total_samples = 656 + 1227\n",
    "overall_cv = (656 * single_cv + 1227 * full_cv) / total_samples\n",
    "\n",
    "print(f\"\\nSingle solvent CV: {single_cv:.6f}\")\n",
    "print(f\"Full data CV: {full_cv:.6f}\")\n",
    "print(f\"Overall CV (sample-weighted): {overall_cv:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON WITH PREVIOUS RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"This experiment (DRFP+GAT): {overall_cv:.6f}\")\n",
    "print(f\"Previous GAT only: 0.018474\")\n",
    "print(f\"Previous GCN only: 0.020130\")\n",
    "print(f\"Best previous CV (Leave-One-Out): 0.008092 (exp_049)\")\n",
    "print(f\"Best verified LB: 0.0877 (exp_030, exp_067)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "if overall_cv < 0.018474:\n",
    "    print(f\"DRFP+GAT improved over GAT-only by {(0.018474 - overall_cv) / 0.018474 * 100:.1f}%\")\n",
    "else:\n",
    "    print(f\"DRFP+GAT did NOT improve over GAT-only\")\n",
    "    \n",
    "print(f\"\\nThe DRFP+GAT hybrid achieved CV={overall_cv:.6f}\")\n",
    "print(f\"This is still {(overall_cv - 0.008092) / 0.008092 * 100:.1f}% worse than best tabular (0.008092)\")\n",
    "print(f\"\\nPredicted LB: 4.36 * {overall_cv:.6f} + 0.052 = {4.36 * overall_cv + 0.052:.4f}\")\n",
    "print(f\"This would be worse than our best LB (0.0877)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
