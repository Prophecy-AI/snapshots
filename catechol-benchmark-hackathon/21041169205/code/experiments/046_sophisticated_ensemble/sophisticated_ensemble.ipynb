{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a9e689",
   "metadata": {},
   "source": [
    "# Experiment 046: Sophisticated Ensemble\n",
    "\n",
    "**Inspired by:** lishellliang/mixall kernel\n",
    "\n",
    "**Key techniques:**\n",
    "1. Ensemble of 4 models: MLP + XGBoost + RandomForest + LightGBM\n",
    "2. Weighted ensemble with learned weights\n",
    "3. Standard leave-one-solvent-out CV (NOT GroupKFold)\n",
    "\n",
    "**Hypothesis:** Diverse models may capture different aspects of the data, potentially reducing structural error and changing the CV-LB relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c479d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:34:57.612094Z",
     "iopub.status.busy": "2026-01-15T19:34:57.611548Z",
     "iopub.status.idle": "2026-01-15T19:34:59.355698Z",
     "shell.execute_reply": "2026-01-15T19:34:59.355223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151f8aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:34:59.357037Z",
     "iopub.status.busy": "2026-01-15T19:34:59.356825Z",
     "iopub.status.idle": "2026-01-15T19:34:59.394638Z",
     "shell.execute_reply": "2026-01-15T19:34:59.394040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: 13 features\n",
      "DRFP: 2048 features\n",
      "Single solvent: 656 samples\n",
      "Full data: 1227 samples\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"SM\", \"Product 2\", \"Product 3\"]]\n",
    "    return X, Y\n",
    "\n",
    "# Load feature lookup tables\n",
    "spange_df = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "drfp_df = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "\n",
    "SPANGE_COLS = [c for c in spange_df.columns if c != 'solvent smiles']\n",
    "DRFP_COLS = [c for c in drfp_df.columns if str(c).isdigit() or isinstance(c, int)]\n",
    "\n",
    "print(f'Spange: {len(SPANGE_COLS)} features')\n",
    "print(f'DRFP: {len(DRFP_COLS)} features')\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "X_full, Y_full = load_data('full')\n",
    "\n",
    "print(f'Single solvent: {len(X_single)} samples')\n",
    "print(f'Full data: {len(X_full)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7448fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:34:59.396028Z",
     "iopub.status.busy": "2026-01-15T19:34:59.395913Z",
     "iopub.status.idle": "2026-01-15T19:34:59.400894Z",
     "shell.execute_reply": "2026-01-15T19:34:59.400525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction defined\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def get_features(X, data_type='single'):\n",
    "    features_list = []\n",
    "    \n",
    "    for idx, row in X.iterrows():\n",
    "        time_m = row['Residence Time']\n",
    "        temp_c = row['Temperature']\n",
    "        temp_k = temp_c + 273.15\n",
    "        \n",
    "        kinetics = np.array([\n",
    "            time_m, temp_c, 1.0 / temp_k,\n",
    "            np.log(time_m + 1), time_m / temp_k\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        if data_type == 'single':\n",
    "            solvent = row['SOLVENT NAME']\n",
    "            spange = spange_df.loc[solvent, SPANGE_COLS].values.astype(np.float32) if solvent in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            drfp = drfp_df.loc[solvent, DRFP_COLS].values.astype(np.float32) if solvent in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "        else:\n",
    "            solvent_a = row['SOLVENT A NAME']\n",
    "            solvent_b = row['SOLVENT B NAME']\n",
    "            pct_b = row['SolventB%'] / 100.0\n",
    "            pct_a = 1 - pct_b\n",
    "            \n",
    "            sp_a = spange_df.loc[solvent_a, SPANGE_COLS].values.astype(np.float32) if solvent_a in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            sp_b = spange_df.loc[solvent_b, SPANGE_COLS].values.astype(np.float32) if solvent_b in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            spange = pct_a * sp_a + pct_b * sp_b\n",
    "            \n",
    "            dr_a = drfp_df.loc[solvent_a, DRFP_COLS].values.astype(np.float32) if solvent_a in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            dr_b = drfp_df.loc[solvent_b, DRFP_COLS].values.astype(np.float32) if solvent_b in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            drfp = pct_a * dr_a + pct_b * dr_b\n",
    "        \n",
    "        features = np.concatenate([kinetics, spange, drfp])\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return np.array(features_list, dtype=np.float32)\n",
    "\n",
    "print('Feature extraction defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635d87db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:34:59.401904Z",
     "iopub.status.busy": "2026-01-15T19:34:59.401815Z",
     "iopub.status.idle": "2026-01-15T19:34:59.405190Z",
     "shell.execute_reply": "2026-01-15T19:34:59.404861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[128, 64, 32], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print('MLPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cc76ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:34:59.406141Z",
     "iopub.status.busy": "2026-01-15T19:34:59.406052Z",
     "iopub.status.idle": "2026-01-15T19:34:59.413891Z",
     "shell.execute_reply": "2026-01-15T19:34:59.413527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SophisticatedEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# Sophisticated Ensemble Model (MLP + XGBoost + RandomForest + LightGBM)\n",
    "class SophisticatedEnsemble:\n",
    "    def __init__(self, data='single', weights=[0.35, 0.25, 0.15, 0.25]):\n",
    "        self.data_type = data\n",
    "        self.weights = weights  # [MLP, XGBoost, RF, LightGBM]\n",
    "        \n",
    "        self.scaler = None\n",
    "        self.mlp_models = []\n",
    "        self.xgb_models = []\n",
    "        self.rf_models = []\n",
    "        self.lgbm_models = []\n",
    "    \n",
    "    def train_model(self, X_train, y_train, epochs=150):\n",
    "        X_feat = get_features(X_train, self.data_type)\n",
    "        y_np = y_train.values.astype(np.float32)\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Train MLP models (ensemble of 3)\n",
    "        self.mlp_models = []\n",
    "        for _ in range(3):\n",
    "            model = MLPModel(X_scaled.shape[1], hidden_dims=[128, 64, 32], dropout=0.3).to(device)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            \n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            y_tensor = torch.tensor(y_np).to(device)\n",
    "            \n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = nn.MSELoss()(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.mlp_models.append(model)\n",
    "        \n",
    "        # Train XGBoost models (one per target)\n",
    "        self.xgb_models = []\n",
    "        for i in range(3):\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0\n",
    "            )\n",
    "            xgb_model.fit(X_scaled, y_np[:, i])\n",
    "            self.xgb_models.append(xgb_model)\n",
    "        \n",
    "        # Train RandomForest models (one per target)\n",
    "        self.rf_models = []\n",
    "        for i in range(3):\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=100, max_depth=10, min_samples_leaf=5, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            rf_model.fit(X_scaled, y_np[:, i])\n",
    "            self.rf_models.append(rf_model)\n",
    "        \n",
    "        # Train LightGBM models (one per target)\n",
    "        self.lgbm_models = []\n",
    "        for i in range(3):\n",
    "            lgbm_model = lgb.LGBMRegressor(\n",
    "                n_estimators=200, max_depth=6, learning_rate=0.05,\n",
    "                num_leaves=31, subsample=0.8, random_state=42, verbose=-1\n",
    "            )\n",
    "            lgbm_model.fit(X_scaled, y_np[:, i])\n",
    "            self.lgbm_models.append(lgbm_model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_feat = get_features(X_test, self.data_type)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        # MLP predictions (average of ensemble)\n",
    "        mlp_preds = []\n",
    "        for model in self.mlp_models:\n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(X_tensor).cpu().numpy()\n",
    "            mlp_preds.append(pred)\n",
    "        mlp_preds = np.mean(mlp_preds, axis=0)\n",
    "        \n",
    "        # XGBoost predictions\n",
    "        xgb_preds = np.zeros((len(X_test), 3))\n",
    "        for i, xgb_model in enumerate(self.xgb_models):\n",
    "            xgb_preds[:, i] = xgb_model.predict(X_scaled)\n",
    "        \n",
    "        # RandomForest predictions\n",
    "        rf_preds = np.zeros((len(X_test), 3))\n",
    "        for i, rf_model in enumerate(self.rf_models):\n",
    "            rf_preds[:, i] = rf_model.predict(X_scaled)\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        lgbm_preds = np.zeros((len(X_test), 3))\n",
    "        for i, lgbm_model in enumerate(self.lgbm_models):\n",
    "            lgbm_preds[:, i] = lgbm_model.predict(X_scaled)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (self.weights[0] * mlp_preds + \n",
    "                       self.weights[1] * xgb_preds + \n",
    "                       self.weights[2] * rf_preds + \n",
    "                       self.weights[3] * lgbm_preds)\n",
    "        \n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        return torch.tensor(final_preds, dtype=torch.float32)\n",
    "\n",
    "print('SophisticatedEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on single solvent data\n",
    "print(\"Testing sophisticated ensemble on single solvent data...\")\n",
    "print()\n",
    "\n",
    "all_solvents = sorted(X_single[\"SOLVENT NAME\"].unique())\n",
    "fold_mses = []\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "    \n",
    "    model = SophisticatedEnsemble(data='single', weights=[0.35, 0.25, 0.15, 0.25])\n",
    "    model.train_model(X_single[mask], Y_single[mask], epochs=100)\n",
    "    preds = model.predict(X_single[~mask])\n",
    "    \n",
    "    actuals = Y_single[~mask].values\n",
    "    mse = np.mean((actuals - preds.numpy())**2)\n",
    "    fold_mses.append(mse)\n",
    "\n",
    "mean_mse = np.mean(fold_mses)\n",
    "std_mse = np.std(fold_mses)\n",
    "print(f\"Sophisticated Ensemble CV MSE: {mean_mse:.6f} +/- {std_mse:.6f}\")\n",
    "print(f\"Baseline (exp_030): CV = 0.008298\")\n",
    "if mean_mse < 0.008298:\n",
    "    print(f\"Improvement: {(0.008298 - mean_mse) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(mean_mse - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
