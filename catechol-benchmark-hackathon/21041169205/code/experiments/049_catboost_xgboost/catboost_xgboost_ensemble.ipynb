{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0de6f9",
   "metadata": {},
   "source": [
    "# Experiment 049: CatBoost + XGBoost Ensemble\n",
    "\n",
    "**Goal:** Implement the CatBoost + XGBoost ensemble from the ens-model kernel.\n",
    "\n",
    "**Key differences from our previous approaches:**\n",
    "1. CatBoost with MultiRMSE loss (multi-target in single model)\n",
    "2. Output normalization (sum to 1 constraint)\n",
    "3. Combined feature table with correlation filtering\n",
    "4. Different ensemble weights for single vs full data\n",
    "\n",
    "**Hypothesis:** CatBoost may have different generalization properties that could CHANGE the CV-LB relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ffad710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:33.347592Z",
     "iopub.status.busy": "2026-01-15T21:23:33.347026Z",
     "iopub.status.idle": "2026-01-15T21:23:33.363349Z",
     "shell.execute_reply": "2026-01-15T21:23:33.362729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent: X=(656, 3), Y=(656, 3)\n",
      "Full data: X=(1227, 5), Y=(1227, 3)\n",
      "\n",
      "Solvents: ['1,1,1,3,3,3-Hexafluoropropan-2-ol', '2,2,2-Trifluoroethanol', '2-Methyltetrahydrofuran [2-MeTHF]', 'Acetonitrile', 'Acetonitrile.Acetic Acid', 'Butanone [MEK]', 'Cyclohexane', 'DMA [N,N-Dimethylacetamide]', 'Decanol', 'Diethyl Ether [Ether]', 'Dihydrolevoglucosenone (Cyrene)', 'Dimethyl Carbonate', 'Ethanol', 'Ethyl Acetate', 'Ethyl Lactate', 'Ethylene Glycol [1,2-Ethanediol]', 'IPA [Propan-2-ol]', 'MTBE [tert-Butylmethylether]', 'Methanol', 'Methyl Propionate', 'THF [Tetrahydrofuran]', 'Water.2,2,2-Trifluoroethanol', 'Water.Acetonitrile', 'tert-Butanol [2-Methylpropan-2-ol]']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Define constants\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"\n",
    "]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_FEATURES = [\"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "# Data loading functions\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "def load_data_local():\n",
    "    \"\"\"Load both single and full datasets.\"\"\"\n",
    "    # Single solvent\n",
    "    df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "    X_single = df_single[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y_single = df_single[TARGET_LABELS]\n",
    "    \n",
    "    # Full data\n",
    "    df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "    X_full = df_full[INPUT_LABELS_FULL_SOLVENT]\n",
    "    Y_full = df_full[TARGET_LABELS]\n",
    "    \n",
    "    return X_single, Y_single, X_full, Y_full\n",
    "\n",
    "def load_features_local(name=\"spange_descriptors\"):\n",
    "    \"\"\"Load feature lookup table.\"\"\"\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# Define base classes\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single, X_full, Y_full = load_data_local()\n",
    "print(f\"Single solvent: X={X_single.shape}, Y={Y_single.shape}\")\n",
    "print(f\"Full data: X={X_full.shape}, Y={Y_full.shape}\")\n",
    "print(f\"\\nSolvents: {sorted(X_single['SOLVENT NAME'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96128b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:33.364409Z",
     "iopub.status.busy": "2026-01-15T21:23:33.364300Z",
     "iopub.status.idle": "2026-01-15T21:23:33.370665Z",
     "shell.execute_reply": "2026-01-15T21:23:33.370283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering functions from ens-model kernel\n",
    "\n",
    "def feature_priority(name: str) -> int:\n",
    "    \"\"\"Assign priority score to feature name based on prefix.\"\"\"\n",
    "    if name.startswith(\"spange_\"):\n",
    "        return 5\n",
    "    if name.startswith(\"acs_\"):\n",
    "        return 4\n",
    "    if name.startswith(\"drfps_\"):\n",
    "        return 3\n",
    "    if name.startswith(\"frag_\"):\n",
    "        return 2\n",
    "    if name.startswith(\"smiles_\"):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def filter_correlated_features(df: pd.DataFrame, threshold: float = 0.90):\n",
    "    \"\"\"Drop columns that are highly correlated.\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if numeric_df.shape[1] == 0:\n",
    "        return df, []\n",
    "    \n",
    "    # Drop constant columns first\n",
    "    std = numeric_df.std(axis=0)\n",
    "    constant_cols = std[std == 0].index.tolist()\n",
    "    if constant_cols:\n",
    "        numeric_df = numeric_df.drop(columns=constant_cols)\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr = numeric_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)).fillna(0.0)\n",
    "    \n",
    "    cols = upper.columns.tolist()\n",
    "    to_drop = set()\n",
    "    \n",
    "    # Find high correlation pairs\n",
    "    for i, col_i in enumerate(cols):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            col_j = cols[j]\n",
    "            cval = upper.iloc[i, j]\n",
    "            if cval > threshold:\n",
    "                if col_i in to_drop or col_j in to_drop:\n",
    "                    continue\n",
    "                p_i = feature_priority(col_i)\n",
    "                p_j = feature_priority(col_j)\n",
    "                if p_i > p_j:\n",
    "                    to_drop.add(col_j)\n",
    "                elif p_j > p_i:\n",
    "                    to_drop.add(col_i)\n",
    "                else:\n",
    "                    idx_i = df.columns.get_loc(col_i) if col_i in df.columns else 999\n",
    "                    idx_j = df.columns.get_loc(col_j) if col_j in df.columns else 999\n",
    "                    to_drop.add(col_i if idx_i > idx_j else col_j)\n",
    "    \n",
    "    all_to_drop = list(set(constant_cols).union(to_drop))\n",
    "    df_filtered = df.drop(columns=all_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    return df_filtered, all_to_drop\n",
    "\n",
    "def add_numeric_features(X_numeric: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add engineered numeric features.\"\"\"\n",
    "    X_num = X_numeric.copy()\n",
    "    cols = set(X_num.columns)\n",
    "    \n",
    "    if {\"Temperature\", \"Residence Time\"} <= cols:\n",
    "        # Convert Temperature to Kelvin\n",
    "        X_num[\"Temperature\"] = X_num[\"Temperature\"] + 273.15\n",
    "        \n",
    "        T = X_num[\"Temperature\"]\n",
    "        rt = X_num[\"Residence Time\"]\n",
    "        \n",
    "        # Interaction term\n",
    "        X_num[\"T_x_RT\"] = T * rt\n",
    "        \n",
    "        # Log transformation\n",
    "        X_num[\"RT_log\"] = np.log(rt + 1e-6)\n",
    "        \n",
    "        # Inverse temperature\n",
    "        X_num[\"T_inv\"] = 1 / T\n",
    "        \n",
    "        # Scaled residence time\n",
    "        X_num[\"RT_scaled\"] = rt / rt.mean()\n",
    "    \n",
    "    return X_num\n",
    "\n",
    "print(\"Feature engineering functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb350028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:33.371491Z",
     "iopub.status.busy": "2026-01-15T21:23:33.371395Z",
     "iopub.status.idle": "2026-01-15T21:23:33.486468Z",
     "shell.execute_reply": "2026-01-15T21:23:33.486112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features before filtering: (26, 115)\n",
      "Combined features after filtering: (26, 68)\n",
      "Dropped 47 columns\n",
      "\n",
      "Final solvent table shape: (26, 68)\n",
      "Columns: ['SOLVENT NAME', 'spange_dielectric constant', 'spange_ET(30)', 'spange_beta', 'spange_pi*', 'spange_SB', 'spange_SP', 'spange_SdP', 'spange_N', 'spange_n', 'acs_PC1', 'acs_PC2', 'acs_PC3', 'acs_PC4', 'acs_PC5', 'drfps_34', 'drfps_67', 'drfps_110', 'drfps_125', 'drfps_209']...\n"
     ]
    }
   ],
   "source": [
    "# Build combined solvent feature table\n",
    "\n",
    "def build_solvent_feature_table(threshold: float = 0.90):\n",
    "    \"\"\"Build combined solvent feature table from multiple sources.\"\"\"\n",
    "    sources = [\n",
    "        \"spange_descriptors\",\n",
    "        \"acs_pca_descriptors\",\n",
    "        \"drfps_catechol\",\n",
    "        \"fragprints\",\n",
    "        \"smiles\",\n",
    "    ]\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for src in sources:\n",
    "        df_src = load_features_local(src).copy()\n",
    "        \n",
    "        if \"SOLVENT NAME\" not in df_src.columns:\n",
    "            df_src = df_src.reset_index().rename(columns={\"index\": \"SOLVENT NAME\"})\n",
    "        \n",
    "        # Bit-table filtering for binary fingerprints\n",
    "        if src in [\"drfps_catechol\", \"fragprints\"]:\n",
    "            prefix = \"drfps\" if src == \"drfps_catechol\" else \"frag\"\n",
    "            \n",
    "            # Drop all-zero and all-one columns\n",
    "            df_src = df_src.loc[:, (df_src != 0).any(axis=0)]\n",
    "            df_src = df_src.loc[:, (df_src != 1).any(axis=0)]\n",
    "            \n",
    "            # Drop columns with only 1 occurrence\n",
    "            values = df_src.drop(columns={\"SOLVENT NAME\"}, errors=\"ignore\")\n",
    "            count = values.sum(axis=0).T\n",
    "            drop_cols = count[count == 1].index\n",
    "            df_src = df_src.drop(columns=drop_cols, errors=\"ignore\")\n",
    "            \n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"{prefix}_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"spange_descriptors\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"spange_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"acs_pca_descriptors\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"acs_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        elif src == \"smiles\":\n",
    "            cols_to_rename = [c for c in df_src.columns if c != \"SOLVENT NAME\"]\n",
    "            df_src = df_src.rename(columns={c: f\"smiles_{c}\" for c in cols_to_rename})\n",
    "        \n",
    "        dfs.append(df_src)\n",
    "    \n",
    "    # Merge all dataframes on SOLVENT NAME\n",
    "    from functools import reduce\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on=\"SOLVENT NAME\", how=\"outer\"), dfs)\n",
    "    \n",
    "    print(f\"Combined features before filtering: {merged.shape}\")\n",
    "    \n",
    "    # Apply correlation filtering\n",
    "    merged_filtered, dropped = filter_correlated_features(merged, threshold=threshold)\n",
    "    \n",
    "    print(f\"Combined features after filtering: {merged_filtered.shape}\")\n",
    "    print(f\"Dropped {len(dropped)} columns\")\n",
    "    \n",
    "    return merged_filtered\n",
    "\n",
    "# Build the feature table\n",
    "solvent_table = build_solvent_feature_table(threshold=0.90)\n",
    "print(f\"\\nFinal solvent table shape: {solvent_table.shape}\")\n",
    "print(f\"Columns: {list(solvent_table.columns)[:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b35a168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:25:03.946396Z",
     "iopub.status.busy": "2026-01-15T21:25:03.945847Z",
     "iopub.status.idle": "2026-01-15T21:25:03.952008Z",
     "shell.execute_reply": "2026-01-15T21:25:03.951527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedFeaturizer class defined.\n"
     ]
    }
   ],
   "source": [
    "# Create featurizer class\n",
    "\n",
    "class CombinedFeaturizer:\n",
    "    \"\"\"Featurizer that combines solvent features with numeric features.\"\"\"\n",
    "    \n",
    "    def __init__(self, solvent_table, data='single'):\n",
    "        self.solvent_table = solvent_table\n",
    "        self.data_mode = data\n",
    "        self.scaler = None\n",
    "        self.feature_cols = None\n",
    "    \n",
    "    def featurize(self, X, fit_scaler=False):\n",
    "        \"\"\"Convert input DataFrame to feature matrix.\"\"\"\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.data_mode == 'single':\n",
    "            # Single solvent: merge with solvent table\n",
    "            X_merged = X.merge(self.solvent_table, on='SOLVENT NAME', how='left')\n",
    "            \n",
    "            # Get numeric columns\n",
    "            numeric_cols = [c for c in X_merged.columns if c != 'SOLVENT NAME' and X_merged[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "            X_numeric = X_merged[numeric_cols].copy()\n",
    "        else:\n",
    "            # Full data (mixture): merge with solvent table for both solvents\n",
    "            # Rename solvent table columns for solvent A\n",
    "            solvent_A = self.solvent_table.copy()\n",
    "            solvent_A = solvent_A.rename(columns={'SOLVENT NAME': 'SOLVENT A NAME'})\n",
    "            solvent_A.columns = ['SOLVENT A NAME'] + [f'{c}_A' for c in solvent_A.columns if c != 'SOLVENT A NAME']\n",
    "            \n",
    "            # Rename solvent table columns for solvent B\n",
    "            solvent_B = self.solvent_table.copy()\n",
    "            solvent_B = solvent_B.rename(columns={'SOLVENT NAME': 'SOLVENT B NAME'})\n",
    "            solvent_B.columns = ['SOLVENT B NAME'] + [f'{c}_B' for c in solvent_B.columns if c != 'SOLVENT B NAME']\n",
    "            \n",
    "            # Merge\n",
    "            X_merged = X.merge(solvent_A, on='SOLVENT A NAME', how='left')\n",
    "            X_merged = X_merged.merge(solvent_B, on='SOLVENT B NAME', how='left')\n",
    "            \n",
    "            # Get numeric columns\n",
    "            numeric_cols = [c for c in X_merged.columns if c not in ['SOLVENT A NAME', 'SOLVENT B NAME'] and X_merged[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "            X_numeric = X_merged[numeric_cols].copy()\n",
    "        \n",
    "        # Add engineered features\n",
    "        X_numeric = add_numeric_features(X_numeric)\n",
    "        \n",
    "        # Store feature columns\n",
    "        if self.feature_cols is None:\n",
    "            self.feature_cols = list(X_numeric.columns)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        X_np = X_numeric.values.astype(np.float64)\n",
    "        \n",
    "        # Handle NaN\n",
    "        X_np = np.nan_to_num(X_np, nan=0.0)\n",
    "        \n",
    "        # Scale features\n",
    "        if fit_scaler:\n",
    "            self.scaler = StandardScaler()\n",
    "            X_np = self.scaler.fit_transform(X_np)\n",
    "        elif self.scaler is not None:\n",
    "            X_np = self.scaler.transform(X_np)\n",
    "        \n",
    "        return torch.tensor(X_np, dtype=torch.double)\n",
    "\n",
    "print(\"CombinedFeaturizer class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95ea28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:25:03.953004Z",
     "iopub.status.busy": "2026-01-15T21:25:03.952902Z",
     "iopub.status.idle": "2026-01-15T21:25:03.961117Z",
     "shell.execute_reply": "2026-01-15T21:25:03.960721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostXGBEnsemble class defined.\n",
      "Single solvent weights: CatBoost=0.54, XGBoost=0.46\n",
      "Full data weights: CatBoost=0.33, XGBoost=0.67\n"
     ]
    }
   ],
   "source": [
    "# CatBoost + XGBoost Ensemble Model\n",
    "\n",
    "class CatBoostXGBEnsemble(BaseModel):\n",
    "    \"\"\"CatBoost + XGBoost ensemble following ens-model kernel.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', verbose=False):\n",
    "        self.data_mode = data\n",
    "        self.verbose = verbose\n",
    "        self.featurizer = CombinedFeaturizer(solvent_table, data=data)\n",
    "        \n",
    "        # Ensemble weights from ens-model kernel\n",
    "        if data == 'single':\n",
    "            cat_weight = 7.0\n",
    "            xgb_weight = 6.0\n",
    "        else:\n",
    "            cat_weight = 1.0\n",
    "            xgb_weight = 2.0\n",
    "        \n",
    "        w_sum = cat_weight + xgb_weight\n",
    "        self.cat_weight = cat_weight / w_sum\n",
    "        self.xgb_weight = xgb_weight / w_sum\n",
    "        \n",
    "        # CatBoost parameters from ens-model kernel\n",
    "        if data == 'single':\n",
    "            self.cat_params = dict(\n",
    "                random_seed=42,\n",
    "                loss_function=\"MultiRMSE\",\n",
    "                depth=3,\n",
    "                learning_rate=0.07,\n",
    "                n_estimators=1050,\n",
    "                l2_leaf_reg=3.5,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.225,\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75,\n",
    "                verbose=False,\n",
    "            )\n",
    "        else:\n",
    "            self.cat_params = dict(\n",
    "                random_seed=42,\n",
    "                loss_function=\"MultiRMSE\",\n",
    "                depth=3,\n",
    "                learning_rate=0.06,\n",
    "                n_estimators=1100,\n",
    "                l2_leaf_reg=2.5,\n",
    "                bootstrap_type=\"Bayesian\",\n",
    "                bagging_temperature=0.25,\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                rsm=0.75,\n",
    "                verbose=False,\n",
    "            )\n",
    "        \n",
    "        # XGBoost parameters from ens-model kernel\n",
    "        if data == 'single':\n",
    "            self.xgb_params = dict(\n",
    "                random_state=42,\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"hist\",\n",
    "                subsample=0.5,\n",
    "                reg_lambda=0.6,\n",
    "                reg_alpha=0.0,\n",
    "                n_estimators=1000,\n",
    "                min_child_weight=1,\n",
    "                max_depth=4,\n",
    "                max_delta_step=1,\n",
    "                learning_rate=0.02,\n",
    "                grow_policy=\"depthwise\",\n",
    "                gamma=0.0,\n",
    "                colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        else:\n",
    "            self.xgb_params = dict(\n",
    "                random_state=42,\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"approx\",\n",
    "                subsample=0.5,\n",
    "                reg_lambda=0.6,\n",
    "                reg_alpha=0.0,\n",
    "                n_estimators=1000,\n",
    "                min_child_weight=1,\n",
    "                max_depth=4,\n",
    "                max_delta_step=1,\n",
    "                learning_rate=0.02,\n",
    "                grow_policy=\"lossguide\",\n",
    "                gamma=0.0,\n",
    "                colsample_bytree=0.3,\n",
    "                colsample_bylevel=0.6,\n",
    "            )\n",
    "        \n",
    "        self.cat_model = None\n",
    "        self.xgb_models = None\n",
    "        self.n_targets = None\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, device=None, verbose=False):\n",
    "        \"\"\"Train CatBoost and XGBoost models.\"\"\"\n",
    "        # Featurize\n",
    "        X_np = self.featurizer.featurize(train_X, fit_scaler=True).numpy()\n",
    "        Y_np = train_Y.values\n",
    "        self.n_targets = Y_np.shape[1]\n",
    "        \n",
    "        # Train CatBoost (multi-target)\n",
    "        self.cat_model = CatBoostRegressor(**self.cat_params)\n",
    "        self.cat_model.fit(X_np, Y_np)\n",
    "        \n",
    "        # Train XGBoost (one per target)\n",
    "        self.xgb_models = []\n",
    "        for t in range(self.n_targets):\n",
    "            model_t = XGBRegressor(**self.xgb_params)\n",
    "            model_t.fit(X_np, Y_np[:, t])\n",
    "            self.xgb_models.append(model_t)\n",
    "        \n",
    "        if verbose or self.verbose:\n",
    "            print(f\"[CatBoostXGBEnsemble] Trained in '{self.data_mode}' mode\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict with ensemble and apply output normalization.\"\"\"\n",
    "        X_np = self.featurizer.featurize(X, fit_scaler=False).numpy()\n",
    "        \n",
    "        # CatBoost prediction\n",
    "        cat_pred = self.cat_model.predict(X_np)\n",
    "        cat_pred = np.asarray(cat_pred)\n",
    "        if cat_pred.ndim == 1:\n",
    "            cat_pred = cat_pred.reshape(-1, 1)\n",
    "        \n",
    "        # XGBoost prediction\n",
    "        xgb_preds = [m.predict(X_np) for m in self.xgb_models]\n",
    "        xgb_pred = np.column_stack(xgb_preds)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        out = self.cat_weight * cat_pred + self.xgb_weight * xgb_pred\n",
    "        \n",
    "        # Output normalization (sum to 1 constraint)\n",
    "        out = np.clip(out, a_min=0.0, a_max=None)\n",
    "        if out.shape[1] > 1:\n",
    "            totals = out.sum(axis=1, keepdims=True)\n",
    "            divisor = np.maximum(totals, 1.0)\n",
    "            out = out / divisor\n",
    "        \n",
    "        return torch.tensor(out, dtype=torch.double)\n",
    "\n",
    "print(\"CatBoostXGBEnsemble class defined.\")\n",
    "print(f\"Single solvent weights: CatBoost={7/13:.2f}, XGBoost={6/13:.2f}\")\n",
    "print(f\"Full data weights: CatBoost={1/3:.2f}, XGBoost={2/3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85dd4e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:23:43.653651Z",
     "iopub.status.busy": "2026-01-15T21:23:43.653559Z",
     "iopub.status.idle": "2026-01-15T21:24:07.335361Z",
     "shell.execute_reply": "2026-01-15T21:24:07.334932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Leave-One-Solvent-Out CV for single solvents...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1,1,1,3,3,3-Hexafluoropropan-2-ol: MSE = 0.029401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2,2,2-Trifluoroethanol: MSE = 0.019110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2-Methyltetrahydrofuran [2-MeTHF]: MSE = 0.002023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Acetonitrile: MSE = 0.011238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Acetonitrile.Acetic Acid: MSE = 0.022562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Butanone [MEK]: MSE = 0.003177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Cyclohexane: MSE = 0.002913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold DMA [N,N-Dimethylacetamide]: MSE = 0.001434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Decanol: MSE = 0.008781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Diethyl Ether [Ether]: MSE = 0.015867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Dihydrolevoglucosenone (Cyrene): MSE = 0.005143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Dimethyl Carbonate: MSE = 0.007844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Ethanol: MSE = 0.003238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Ethyl Acetate: MSE = 0.001843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Ethyl Lactate: MSE = 0.002626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Ethylene Glycol [1,2-Ethanediol]: MSE = 0.017804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold IPA [Propan-2-ol]: MSE = 0.012355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold MTBE [tert-Butylmethylether]: MSE = 0.000945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Methanol: MSE = 0.003990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Methyl Propionate: MSE = 0.001081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold THF [Tetrahydrofuran]: MSE = 0.000795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Water.2,2,2-Trifluoroethanol: MSE = 0.002372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Water.Acetonitrile: MSE = 0.016135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold tert-Butanol [2-Methylpropan-2-ol]: MSE = 0.001529\n",
      "\n",
      "Single Solvent CV MSE: 0.008092 +/- 0.007938\n",
      "Baseline (exp_030): CV = 0.008298\n",
      "IMPROVEMENT: 2.48%\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Solvent-Out CV for single solvents\n",
    "print(\"Running Leave-One-Solvent-Out CV for single solvents...\")\n",
    "print()\n",
    "\n",
    "all_solvents = sorted(X_single[\"SOLVENT NAME\"].unique())\n",
    "fold_mses = []\n",
    "fold_results = []\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "    \n",
    "    # Create fresh model and featurizer for each fold\n",
    "    model = CatBoostXGBEnsemble(data='single')\n",
    "    model.train_model(X_single[mask], Y_single[mask])\n",
    "    \n",
    "    # Predict on test solvent\n",
    "    preds = model.predict(X_single[~mask]).numpy()\n",
    "    actuals = Y_single[~mask].values\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - actuals) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "    fold_results.append({'solvent': test_solvent, 'mse': mse})\n",
    "    \n",
    "    print(f\"Fold {test_solvent}: MSE = {mse:.6f}\")\n",
    "\n",
    "mean_mse = np.mean(fold_mses)\n",
    "std_mse = np.std(fold_mses)\n",
    "print(f\"\\nSingle Solvent CV MSE: {mean_mse:.6f} +/- {std_mse:.6f}\")\n",
    "print(f\"Baseline (exp_030): CV = 0.008298\")\n",
    "if mean_mse < 0.008298:\n",
    "    print(f\"IMPROVEMENT: {(0.008298 - mean_mse) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(mean_mse - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-solvent results\n",
    "print(\"\\nPer-solvent MSE analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fold_df = pd.DataFrame(fold_results)\n",
    "fold_df = fold_df.sort_values('mse', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 hardest solvents:\")\n",
    "for _, row in fold_df.head(5).iterrows():\n",
    "    print(f\"  {row['solvent']}: MSE = {row['mse']:.6f}\")\n",
    "\n",
    "print(\"\\nTop 5 easiest solvents:\")\n",
    "for _, row in fold_df.tail(5).iterrows():\n",
    "    print(f\"  {row['solvent']}: MSE = {row['mse']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93756187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:25:14.983241Z",
     "iopub.status.busy": "2026-01-15T21:25:14.982812Z",
     "iopub.status.idle": "2026-01-15T21:27:51.237004Z",
     "shell.execute_reply": "2026-01-15T21:27:51.236565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Leave-One-Ramp-Out CV for mixtures...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 0: MSE = 0.001230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 1: MSE = 0.000673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 2: MSE = 0.005224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 3: MSE = 0.000410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 4: MSE = 0.000976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 5: MSE = 0.011362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 6: MSE = 0.001013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 7: MSE = 0.014924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 8: MSE = 0.000632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 9: MSE = 0.020679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 10: MSE = 0.011034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 11: MSE = 0.001982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 12: MSE = 0.010017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 13: MSE = 0.005755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 14: MSE = 0.012554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 15: MSE = 0.003189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 16: MSE = 0.013827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 17: MSE = 0.002977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 18: MSE = 0.000223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 19: MSE = 0.001116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 20: MSE = 0.000979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 21: MSE = 0.005766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 22: MSE = 0.003876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 23: MSE = 0.001458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 24: MSE = 0.004095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 25: MSE = 0.000745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 26: MSE = 0.000157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 27: MSE = 0.000322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 28: MSE = 0.009866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 29: MSE = 0.020048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 30: MSE = 0.000427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 31: MSE = 0.020731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 32: MSE = 0.000733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 33: MSE = 0.002274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 34: MSE = 0.000542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 35: MSE = 0.001680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 36: MSE = 0.001319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 37: MSE = 0.007119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 38: MSE = 0.019709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 39: MSE = 0.004595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 40: MSE = 0.014460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 41: MSE = 0.004359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 42: MSE = 0.000703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 43: MSE = 0.000075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 44: MSE = 0.000029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 45: MSE = 0.000231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 46: MSE = 0.002789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 47: MSE = 0.004459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 48: MSE = 0.000492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 49: MSE = 0.007894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 50: MSE = 0.003892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 51: MSE = 0.006231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 52: MSE = 0.001361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 53: MSE = 0.010827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 54: MSE = 0.000836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 55: MSE = 0.008135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 56: MSE = 0.008096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 57: MSE = 0.001967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 58: MSE = 0.015421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 59: MSE = 0.002281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 60: MSE = 0.000337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 61: MSE = 0.001102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 62: MSE = 0.002150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 63: MSE = 0.000234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 64: MSE = 0.001966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 65: MSE = 0.003417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 66: MSE = 0.000921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 67: MSE = 0.004653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 68: MSE = 0.000716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 69: MSE = 0.001661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 70: MSE = 0.000808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 71: MSE = 0.000203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 72: MSE = 0.004416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 73: MSE = 0.002106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 74: MSE = 0.003348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 75: MSE = 0.005658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 76: MSE = 0.001074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 77: MSE = 0.003537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 78: MSE = 0.002257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 79: MSE = 0.010185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 80: MSE = 0.007058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 81: MSE = 0.013841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 82: MSE = 0.013247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 83: MSE = 0.006776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 84: MSE = 0.011691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 85: MSE = 0.009946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramp 86: MSE = 0.009490\n",
      "\n",
      "Mixture CV MSE: 0.005099 +/- 0.005408\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Ramp-Out CV for mixtures\n",
    "print(\"\\nRunning Leave-One-Ramp-Out CV for mixtures...\")\n",
    "print()\n",
    "\n",
    "# Load full data with RAMP NUM\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "X_full_with_ramp = df_full[INPUT_LABELS_FULL_SOLVENT + ['RAMP NUM']]\n",
    "Y_full = df_full[TARGET_LABELS]\n",
    "\n",
    "# Get unique ramps\n",
    "ramps = X_full_with_ramp[\"RAMP NUM\"].unique()\n",
    "mix_fold_mses = []\n",
    "\n",
    "for test_ramp in ramps:\n",
    "    mask = X_full_with_ramp[\"RAMP NUM\"] != test_ramp\n",
    "    \n",
    "    # Get X without RAMP NUM for training\n",
    "    X_train = X_full_with_ramp[mask][INPUT_LABELS_FULL_SOLVENT]\n",
    "    X_test = X_full_with_ramp[~mask][INPUT_LABELS_FULL_SOLVENT]\n",
    "    \n",
    "    # Create fresh model for each fold\n",
    "    model = CatBoostXGBEnsemble(data='full')\n",
    "    model.train_model(X_train, Y_full[mask])\n",
    "    \n",
    "    # Predict on test ramp\n",
    "    preds = model.predict(X_test).numpy()\n",
    "    actuals = Y_full[~mask].values\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((preds - actuals) ** 2)\n",
    "    mix_fold_mses.append(mse)\n",
    "    \n",
    "    print(f\"Ramp {test_ramp}: MSE = {mse:.6f}\")\n",
    "\n",
    "mix_mean_mse = np.mean(mix_fold_mses)\n",
    "mix_std_mse = np.std(mix_fold_mses)\n",
    "print(f\"\\nMixture CV MSE: {mix_mean_mse:.6f} +/- {mix_std_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d05b16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:27:51.238101Z",
     "iopub.status.busy": "2026-01-15T21:27:51.238005Z",
     "iopub.status.idle": "2026-01-15T21:27:51.241343Z",
     "shell.execute_reply": "2026-01-15T21:27:51.240990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINED CV SCORE\n",
      "============================================================\n",
      "Single solvent CV: 0.008092 (n=656)\n",
      "Mixture CV: 0.005099 (n=1227)\n",
      "Weighted combined CV: 0.006141\n",
      "\n",
      "Baseline (exp_030): CV = 0.008298\n",
      "IMPROVEMENT: 25.99%\n"
     ]
    }
   ],
   "source": [
    "# Combined CV score (weighted average)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINED CV SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Weight by number of samples\n",
    "n_single = len(X_single)\n",
    "n_full = len(X_full)\n",
    "total = n_single + n_full\n",
    "\n",
    "weighted_cv = (n_single * mean_mse + n_full * mix_mean_mse) / total\n",
    "\n",
    "print(f\"Single solvent CV: {mean_mse:.6f} (n={n_single})\")\n",
    "print(f\"Mixture CV: {mix_mean_mse:.6f} (n={n_full})\")\n",
    "print(f\"Weighted combined CV: {weighted_cv:.6f}\")\n",
    "print(f\"\\nBaseline (exp_030): CV = 0.008298\")\n",
    "if weighted_cv < 0.008298:\n",
    "    print(f\"IMPROVEMENT: {(0.008298 - weighted_cv) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(weighted_cv - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde8a336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:28:02.132729Z",
     "iopub.status.busy": "2026-01-15T21:28:02.132340Z",
     "iopub.status.idle": "2026-01-15T21:28:04.812358Z",
     "shell.execute_reply": "2026-01-15T21:28:04.811911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating submission...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final models trained.\n",
      "Single solvent CV: 0.008092\n",
      "Mixture CV: 0.005099\n",
      "Weighted combined CV: 0.006141\n"
     ]
    }
   ],
   "source": [
    "# Generate submission\n",
    "print(\"\\nGenerating submission...\")\n",
    "\n",
    "# Train final models on all data\n",
    "final_single_model = CatBoostXGBEnsemble(data='single')\n",
    "final_single_model.train_model(X_single, Y_single)\n",
    "\n",
    "final_full_model = CatBoostXGBEnsemble(data='full')\n",
    "final_full_model.train_model(X_full, Y_full)\n",
    "\n",
    "# Save submission\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "\n",
    "# The submission format follows the competition template\n",
    "print(\"\\nFinal models trained.\")\n",
    "print(f\"Single solvent CV: {mean_mse:.6f}\")\n",
    "print(f\"Mixture CV: {mix_mean_mse:.6f}\")\n",
    "print(f\"Weighted combined CV: {weighted_cv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission in the required format\n",
    "# This mimics what the competition template does\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# Single solvent predictions\n",
    "print(\"Generating single solvent predictions...\")\n",
    "X_s, Y_s = X_single, Y_single\n",
    "all_solvents = sorted(X_s[\"SOLVENT NAME\"].unique())\n",
    "all_predictions_single = []\n",
    "\n",
    "for fold_idx, test_solvent in enumerate(tqdm.tqdm(all_solvents)):\n",
    "    mask = X_s[\"SOLVENT NAME\"] != test_solvent\n",
    "    train_X, train_Y = X_s[mask], Y_s[mask]\n",
    "    test_X, test_Y = X_s[~mask], Y_s[~mask]\n",
    "    \n",
    "    model = CatBoostXGBEnsemble(data='single')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_single.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions_single)\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3144df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data predictions\n",
    "print(\"Generating full data predictions...\")\n",
    "\n",
    "# Load full data with RAMP NUM\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "X_f = df_full[INPUT_LABELS_FULL_SOLVENT]\n",
    "Y_f = df_full[TARGET_LABELS]\n",
    "\n",
    "# Get unique ramps for leave-one-ramp-out\n",
    "all_ramps = df_full[\"RAMP NUM\"].unique()\n",
    "all_predictions_full = []\n",
    "\n",
    "for fold_idx, test_ramp in enumerate(tqdm.tqdm(all_ramps)):\n",
    "    mask = df_full[\"RAMP NUM\"] != test_ramp\n",
    "    train_X, train_Y = X_f[mask], Y_f[mask]\n",
    "    test_X, test_Y = X_f[~mask], Y_f[~mask]\n",
    "    \n",
    "    model = CatBoostXGBEnsemble(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8910617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and save submission\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "\n",
    "# Save to submission directory\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")\n",
    "print(f\"\\nSubmission head:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission tail:\")\n",
    "print(submission.tail())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
