{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae8f145",
   "metadata": {},
   "source": [
    "# Experiment 054: Mixall Kernel Approach\n",
    "\n",
    "**Goal:** Implement the mixall kernel approach exactly to verify our submission format is correct.\n",
    "\n",
    "**Key Differences from Official Template:**\n",
    "1. Uses GroupKFold (5 splits) instead of Leave-One-Out (24 folds)\n",
    "2. Uses ensemble of MLP + XGBoost + RandomForest + LightGBM\n",
    "3. Uses linear mixture interpolation for full data\n",
    "\n",
    "**Note:** This uses a DIFFERENT CV scheme than the official template. The purpose is to verify that our submission format is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdddf2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:49.527081Z",
     "iopub.status.busy": "2026-01-15T23:12:49.526483Z",
     "iopub.status.idle": "2026-01-15T23:12:51.007014Z",
     "shell.execute_reply": "2026-01-15T23:12:51.006563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data path\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "# Constants\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e9f882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:51.008250Z",
     "iopub.status.busy": "2026-01-15T23:12:51.008097Z",
     "iopub.status.idle": "2026-01-15T23:12:51.013063Z",
     "shell.execute_reply": "2026-01-15T23:12:51.012690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined (using GroupKFold).\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "# GroupKFold CV functions (from mixall kernel)\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate Group K-Fold splits across the solvents (5-fold).\"\"\"\n",
    "    groups = X[\"SOLVENT NAME\"]\n",
    "    n_groups = len(groups.unique())\n",
    "    n_splits = min(5, n_groups)\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    for train_idx, test_idx in gkf.split(X, Y, groups):\n",
    "        yield (\n",
    "            (X.iloc[train_idx], Y.iloc[train_idx]),\n",
    "            (X.iloc[test_idx], Y.iloc[test_idx]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate Group K-Fold splits across the solvent ramps (5-fold).\"\"\"\n",
    "    groups = X[\"SOLVENT A NAME\"].astype(str) + \"_\" + X[\"SOLVENT B NAME\"].astype(str)\n",
    "    n_groups = len(groups.unique())\n",
    "    n_splits = min(5, n_groups)\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    for train_idx, test_idx in gkf.split(X, Y, groups):\n",
    "        yield (\n",
    "            (X.iloc[train_idx], Y.iloc[train_idx]),\n",
    "            (X.iloc[test_idx], Y.iloc[test_idx]),\n",
    "        )\n",
    "\n",
    "print(\"Data loading functions defined (using GroupKFold).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be07a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:51.013885Z",
     "iopub.status.busy": "2026-01-15T23:12:51.013788Z",
     "iopub.status.idle": "2026-01-15T23:12:51.018125Z",
     "shell.execute_reply": "2026-01-15T23:12:51.017788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizers defined.\n"
     ]
    }
   ],
   "source": [
    "# Featurizers (from mixall kernel)\n",
    "class PrecomputedFeaturizer:\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = load_features(features)\n",
    "        self.feats_dim = self.features.shape[1] + 2\n",
    "        \n",
    "    def featurize(self, X):\n",
    "        res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        solvent_names = X['SOLVENT NAME']\n",
    "        feats = self.features.loc[solvent_names].values\n",
    "        final_feats = np.hstack([res_time, temp, feats])\n",
    "        return torch.tensor(final_feats, dtype=torch.float32)\n",
    "\n",
    "class PrecomputedFeaturizerMixed:\n",
    "    def __init__(self, features='spange_descriptors'):\n",
    "        self.features = load_features(features)\n",
    "        self.feats_dim = self.features.shape[1] + 3\n",
    "        \n",
    "    def featurize(self, X):\n",
    "        res_time = X['Residence Time'].values.reshape(-1, 1)\n",
    "        temp = X['Temperature'].values.reshape(-1, 1)\n",
    "        sb_pct = X['SolventB%'].values.reshape(-1, 1) / 100.0  # Normalize to [0, 1]\n",
    "        \n",
    "        desc_a = self.features.loc[X['SOLVENT A NAME']].values\n",
    "        desc_b = self.features.loc[X['SOLVENT B NAME']].values\n",
    "        \n",
    "        # Linear mixture interpolation\n",
    "        mixture_feats = (1 - sb_pct) * desc_a + sb_pct * desc_b\n",
    "        \n",
    "        final_feats = np.hstack([res_time, temp, sb_pct, mixture_feats])\n",
    "        return torch.tensor(final_feats, dtype=torch.float32)\n",
    "\n",
    "print(\"Featurizers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec2f082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:51.018924Z",
     "iopub.status.busy": "2026-01-15T23:12:51.018836Z",
     "iopub.status.idle": "2026-01-15T23:12:51.022215Z",
     "shell.execute_reply": "2026-01-15T23:12:51.021873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP defined.\n"
     ]
    }
   ],
   "source": [
    "# Simple MLP (from mixall kernel) - fixed for small batches\n",
    "class EnhancedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=3, hidden_dims=[128, 64, 32], dropout=0.1):\n",
    "        super(EnhancedMLP, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Handle batch size 1 by setting eval mode temporarily\n",
    "        if x.size(0) == 1 and self.training:\n",
    "            self.eval()\n",
    "            out = self.network(x)\n",
    "            self.train()\n",
    "            return out\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"MLP defined (with batch size 1 fix).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2e4829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:51.023021Z",
     "iopub.status.busy": "2026-01-15T23:12:51.022923Z",
     "iopub.status.idle": "2026-01-15T23:12:51.030236Z",
     "shell.execute_reply": "2026-01-15T23:12:51.029905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleModel defined.\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model (simplified from mixall kernel)\n",
    "class EnsembleModel:\n",
    "    def __init__(self, data='single', weights=None):\n",
    "        self.data = data\n",
    "        if data == 'single':\n",
    "            self.featurizer = PrecomputedFeaturizer()\n",
    "        else:\n",
    "            self.featurizer = PrecomputedFeaturizerMixed()\n",
    "        \n",
    "        self.weights = weights if weights else [0.4, 0.2, 0.2, 0.2]  # MLP, XGB, RF, LGB\n",
    "        self.scaler = StandardScaler()\n",
    "        self.mlp = None\n",
    "        self.xgb_models = None\n",
    "        self.rf_models = None\n",
    "        self.lgb_models = None\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, num_epochs=100, lr=0.001, verbose=False):\n",
    "        X_tensor = self.featurizer.featurize(train_X)\n",
    "        X_np = X_tensor.numpy()\n",
    "        Y_np = train_Y.values\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_np)\n",
    "        X_tensor_scaled = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        Y_tensor = torch.tensor(Y_np, dtype=torch.float32)\n",
    "        \n",
    "        # Train MLP\n",
    "        input_dim = X_scaled.shape[1]\n",
    "        self.mlp = EnhancedMLP(input_dim, output_dim=3, hidden_dims=[128, 64, 32], dropout=0.1)\n",
    "        optimizer = torch.optim.Adam(self.mlp.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor_scaled, Y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        self.mlp.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch_X, batch_Y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.mlp(batch_X)\n",
    "                loss = criterion(pred, batch_Y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Train XGBoost (one per target)\n",
    "        self.xgb_models = []\n",
    "        for i in range(3):\n",
    "            model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, verbosity=0)\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.xgb_models.append(model)\n",
    "        \n",
    "        # Train RandomForest (one per target)\n",
    "        self.rf_models = []\n",
    "        for i in range(3):\n",
    "            model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.rf_models.append(model)\n",
    "        \n",
    "        # Train LightGBM (one per target)\n",
    "        self.lgb_models = []\n",
    "        for i in range(3):\n",
    "            model = lgb.LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "            model.fit(X_scaled, Y_np[:, i])\n",
    "            self.lgb_models.append(model)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_tensor = self.featurizer.featurize(X)\n",
    "        X_np = X_tensor.numpy()\n",
    "        X_scaled = self.scaler.transform(X_np)\n",
    "        X_tensor_scaled = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        \n",
    "        # MLP predictions\n",
    "        self.mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            mlp_pred = self.mlp(X_tensor_scaled).numpy()\n",
    "        \n",
    "        # XGBoost predictions\n",
    "        xgb_pred = np.column_stack([m.predict(X_scaled) for m in self.xgb_models])\n",
    "        \n",
    "        # RandomForest predictions\n",
    "        rf_pred = np.column_stack([m.predict(X_scaled) for m in self.rf_models])\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        lgb_pred = np.column_stack([m.predict(X_scaled) for m in self.lgb_models])\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_pred = (self.weights[0] * mlp_pred + \n",
    "                      self.weights[1] * xgb_pred + \n",
    "                      self.weights[2] * rf_pred + \n",
    "                      self.weights[3] * lgb_pred)\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        final_pred = np.clip(final_pred, 0, 1)\n",
    "        \n",
    "        return torch.tensor(final_pred, dtype=torch.float32)\n",
    "\n",
    "print(\"EnsembleModel defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282bb099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:12:51.031030Z",
     "iopub.status.busy": "2026-01-15T23:12:51.030930Z",
     "iopub.status.idle": "2026-01-15T23:12:53.522295Z",
     "shell.execute_reply": "2026-01-15T23:12:53.521888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Single solvent data: X=(656, 3), Y=(656, 3)\n",
      "Train: 531, Test: 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([125, 3])\n",
      "Predictions range: [0.0000, 0.9478]\n",
      "Model test passed!\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(\"Testing model...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# Test one fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "print(f\"Train: {len(train_X)}, Test: {len(test_X)}\")\n",
    "\n",
    "model = EnsembleModel(data='single')\n",
    "model.train_model(train_X, train_Y, num_epochs=50)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Predictions range: [{preds.min():.4f}, {preds.max():.4f}]\")\n",
    "print(\"Model test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c547dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='single') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, num_epochs=50)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")\n",
    "print(f\"Unique folds: {submission_single_solvent['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y, num_epochs=50)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")\n",
    "print(f\"Unique folds: {submission_full_data['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e93c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "print(f\"\\nTask 0 (single solvent):\")\n",
    "task0 = df[df['task'] == 0]\n",
    "print(f\"  Rows: {len(task0)}\")\n",
    "print(f\"  Folds: {task0['fold'].nunique()}\")\n",
    "print(f\"  Fold range: {task0['fold'].min()} to {task0['fold'].max()}\")\n",
    "\n",
    "print(f\"\\nTask 1 (full data):\")\n",
    "task1 = df[df['task'] == 1]\n",
    "print(f\"  Rows: {len(task1)}\")\n",
    "print(f\"  Folds: {task1['fold'].nunique()}\")\n",
    "print(f\"  Fold range: {task1['fold'].min()} to {task1['fold'].max()}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f\"  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}\")\n",
    "\n",
    "print(f\"\\nNOTE: This uses GroupKFold (5 splits) instead of Leave-One-Out (24/13 folds)\")\n",
    "print(f\"This is the same approach as the 'mixall' kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 054: MIXALL APPROACH SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nKEY DIFFERENCES FROM OFFICIAL TEMPLATE:\")\n",
    "print(\"  1. Uses GroupKFold (5 splits) instead of Leave-One-Out\")\n",
    "print(\"  2. Single solvent: 5 folds instead of 24\")\n",
    "print(\"  3. Full data: 5 folds instead of 13\")\n",
    "print(\"  4. Ensemble: MLP + XGBoost + RandomForest + LightGBM\")\n",
    "print(\"  5. Linear mixture interpolation for full data\")\n",
    "\n",
    "print(f\"\\nSUBMISSION:\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Task 0 folds: {task0['fold'].nunique()}\")\n",
    "print(f\"  Task 1 folds: {task1['fold'].nunique()}\")\n",
    "\n",
    "print(\"\\nPURPOSE:\")\n",
    "print(\"  This experiment verifies that our submission format is correct.\")\n",
    "print(\"  If this submission works, it confirms the format is valid.\")\n",
    "print(\"  If it fails, there's something else wrong with the evaluation.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
