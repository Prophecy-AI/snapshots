{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574a13d2",
   "metadata": {},
   "source": [
    "# Experiment 056: Per-Target Model Selection\n",
    "\n",
    "**Goal:** Implement the approach from public kernel \"catechol-strategy-to-get-0-11161\" (LB 0.11161)\n",
    "\n",
    "**Approach:**\n",
    "- Different model types for different targets:\n",
    "  - SM (hardest): HistGradientBoostingRegressor\n",
    "  - Product 2, Product 3 (easier): ExtraTreesRegressor\n",
    "- Weighted ensemble: 0.65 * ACS + 0.35 * Spange features\n",
    "\n",
    "**Hypothesis:** This approach might change the CV-LB relationship by using target-specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# Data path for local execution\n",
    "DATA_PATH = \"/home/data\"\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bfefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants from official template\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT A NAME\",\n",
    "    \"SOLVENT B NAME\",\n",
    "    \"SolventB%\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT NAME\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "]\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"Product 2\",\n",
    "    \"Product 3\",\n",
    "    \"SM\",\n",
    "]\n",
    "\n",
    "print(\"Constants defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58845cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    assert name in [\"spange_descriptors\", \"acs_pca_descriptors\", \"drfps_catechol\", \"fragprints\", \"smiles\"]\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# CV functions from official template\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvents.\"\"\"\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    \"\"\"Generate all leave-one-out splits across the solvent ramps.\"\"\"\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = ~((X[\"SOLVENT A NAME\"] == solvent_pair[\"SOLVENT A NAME\"]) & \n",
    "                           (X[\"SOLVENT B NAME\"] == solvent_pair[\"SOLVENT B NAME\"]))\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "print(\"Data loading and CV functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base classes from official template\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(self, X):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "print(\"Base classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BetterCatecholModel from public kernel\n",
    "class BetterCatecholModel:\n",
    "    \"\"\"Sklearn-based model with proper feature building.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_table=\"spange_descriptors\", base_type=\"hgb\"):\n",
    "        self.base_type = base_type\n",
    "        self.lookup = (\n",
    "            pd.read_csv(\n",
    "                f\"{DATA_PATH}/{feature_table}_lookup.csv\",\n",
    "                index_col=0,\n",
    "            )\n",
    "            .apply(pd.to_numeric, errors=\"coerce\")\n",
    "            .fillna(0)\n",
    "        )\n",
    "        self.model = None\n",
    "\n",
    "    def _vec(self, s):\n",
    "        return self.lookup.loc[s].values if s in self.lookup.index else np.zeros(self.lookup.shape[1])\n",
    "\n",
    "    def _build_X(self, X):\n",
    "        rt = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "\n",
    "        if \"SOLVENT NAME\" in X.columns:\n",
    "            S = np.vstack([self._vec(s) for s in X[\"SOLVENT NAME\"]])\n",
    "            return np.hstack([rt, temp, S])\n",
    "\n",
    "        frac_b = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "        A = np.vstack([self._vec(s) for s in X[\"SOLVENT A NAME\"]])\n",
    "        B = np.vstack([self._vec(s) for s in X[\"SOLVENT B NAME\"]])\n",
    "        mix = (1 - frac_b) * A + frac_b * B\n",
    "\n",
    "        return np.hstack([rt, temp, frac_b, mix])\n",
    "\n",
    "    def train_model(self, X, Y):\n",
    "        Xf = self._build_X(X)\n",
    "        y = Y.values\n",
    "\n",
    "        if self.base_type == \"hgb\":\n",
    "            base = HistGradientBoostingRegressor(\n",
    "                max_depth=7, max_iter=700, learning_rate=0.04\n",
    "            )\n",
    "        else:\n",
    "            base = ExtraTreesRegressor(\n",
    "                n_estimators=900,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "\n",
    "        self.model = Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"reg\", MultiOutputRegressor(base))]\n",
    "        )\n",
    "        self.model.fit(Xf, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.clip(self.model.predict(self._build_X(X)), 0, 1)\n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print(\"BetterCatecholModel defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerTargetEnsembleModel from public kernel\n",
    "class PerTargetEnsembleModel:\n",
    "    \"\"\"Per-target model selection with weighted ensemble.\n",
    "    \n",
    "    - SM (hardest): HistGradientBoostingRegressor\n",
    "    - Product 2, Product 3 (easier): ExtraTreesRegressor\n",
    "    - Weighted ensemble: 0.65 * ACS + 0.35 * Spange\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data='single'):\n",
    "        self.data = data\n",
    "        self.targets = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "        self.models = {}\n",
    "\n",
    "        for t in self.targets:\n",
    "            if t == \"SM\":\n",
    "                # SM is hardest - use HistGradientBoostingRegressor\n",
    "                self.models[t] = [\n",
    "                    BetterCatecholModel(\"acs_pca_descriptors\", \"hgb\"),\n",
    "                    BetterCatecholModel(\"spange_descriptors\", \"hgb\"),\n",
    "                ]\n",
    "            else:\n",
    "                # Products are easier - use ExtraTreesRegressor\n",
    "                self.models[t] = [\n",
    "                    BetterCatecholModel(\"acs_pca_descriptors\", \"etr\"),\n",
    "                    BetterCatecholModel(\"spange_descriptors\", \"etr\"),\n",
    "                ]\n",
    "\n",
    "    def train_model(self, X, Y, device=None, verbose=False):\n",
    "        for t in self.targets:\n",
    "            y_single = Y[[t]]\n",
    "            for m in self.models[t]:\n",
    "                m.train_model(X, y_single)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "\n",
    "        for t in self.targets:\n",
    "            p1 = self.models[t][0].model.predict(self.models[t][0]._build_X(X))\n",
    "            p2 = self.models[t][1].model.predict(self.models[t][1]._build_X(X))\n",
    "\n",
    "            # Weighted ensemble: 0.65 * ACS + 0.35 * Spange\n",
    "            pred_t = 0.65 * p1 + 0.35 * p2\n",
    "            preds.append(pred_t.reshape(-1, 1))\n",
    "\n",
    "        pred = np.clip(np.hstack(preds), 0, 1)\n",
    "        return torch.tensor(pred, dtype=torch.double)\n",
    "\n",
    "print(\"PerTargetEnsembleModel defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c270e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test\n",
    "print(\"Testing PerTargetEnsembleModel...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent data: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# Test one fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = PerTargetEnsembleModel()\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Predictions sample: {preds[0]}\")\n",
    "print(f\"Actual sample: {test_Y.iloc[0].values}\")\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64910150",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsembleModel() # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")\n",
    "print(f\"Unique folds: {submission_single_solvent['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsembleModel(data = 'full') # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")\n",
    "print(f\"Unique folds: {submission_full_data['fold'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04153ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV for logging\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CV CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single solvent CV\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_out_splits(X, Y)):\n",
    "    model = PerTargetEnsembleModel()\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    fold_mses.append(mse)\n",
    "    if fold_idx % 5 == 0:\n",
    "        print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "single_cv = np.mean(fold_mses)\n",
    "single_std = np.std(fold_mses)\n",
    "print(f\"\\nSingle solvent CV MSE: {single_cv:.6f} ± {single_std:.6f}\")\n",
    "\n",
    "# Full data CV\n",
    "X, Y = load_data(\"full\")\n",
    "full_fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X, Y)):\n",
    "    model = PerTargetEnsembleModel(data='full')\n",
    "    model.train_model(train_X, train_Y)\n",
    "    preds = model.predict(test_X).numpy()\n",
    "    mse = np.mean((preds - test_Y.values) ** 2)\n",
    "    full_fold_mses.append(mse)\n",
    "    print(f\"  Fold {fold_idx}: MSE = {mse:.6f}\")\n",
    "\n",
    "full_cv = np.mean(full_fold_mses)\n",
    "full_std = np.std(full_fold_mses)\n",
    "print(f\"\\nFull data CV MSE: {full_cv:.6f} ± {full_std:.6f}\")\n",
    "\n",
    "print(f\"\\nFINAL CV FOR LOGGING: {single_cv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "print(f\"\\nTask 0 (single solvent):\")\n",
    "task0 = df[df['task'] == 0]\n",
    "print(f\"  Rows: {len(task0)}\")\n",
    "print(f\"  Folds: {task0['fold'].nunique()}\")\n",
    "print(f\"  Fold values: {sorted(task0['fold'].unique())}\")\n",
    "\n",
    "print(f\"\\nTask 1 (full data):\")\n",
    "task1 = df[df['task'] == 1]\n",
    "print(f\"  Rows: {len(task1)}\")\n",
    "print(f\"  Folds: {task1['fold'].nunique()}\")\n",
    "print(f\"  Fold values: {sorted(task1['fold'].unique())}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f\"  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}, mean={df[col].mean():.6f}\")\n",
    "    print(f\"    Values > 1: {(df[col] > 1).sum()}, Values < 0: {(df[col] < 0).sum()}, NaN: {df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 056: PER-TARGET MODEL SELECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nAPPROACH (from public kernel 'catechol-strategy-to-get-0-11161'):\")\n",
    "print(\"  - Per-target model selection:\")\n",
    "print(\"    - SM (hardest): HistGradientBoostingRegressor (max_depth=7, max_iter=700, lr=0.04)\")\n",
    "print(\"    - Product 2, Product 3: ExtraTreesRegressor (n_estimators=900)\")\n",
    "print(\"  - Weighted ensemble: 0.65 * ACS + 0.35 * Spange features\")\n",
    "\n",
    "print(f\"\\nCV SCORES:\")\n",
    "print(f\"  Single solvent: {single_cv:.6f} ± {single_std:.6f}\")\n",
    "print(f\"  Full data: {full_cv:.6f} ± {full_std:.6f}\")\n",
    "\n",
    "print(f\"\\nSUBMISSION FORMAT:\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Task 0: {len(task0)} rows, {task0['fold'].nunique()} folds\")\n",
    "print(f\"  Task 1: {len(task1)} rows, {task1['fold'].nunique()} folds\")\n",
    "print(f\"  All targets in [0, 1]: {(df['target_1'].between(0, 1)).all() and (df['target_2'].between(0, 1)).all() and (df['target_3'].between(0, 1)).all()}\")\n",
    "\n",
    "print(\"\\nHYPOTHESIS:\")\n",
    "print(\"  This approach might change the CV-LB relationship by using target-specific models.\")\n",
    "print(\"  The public kernel achieved LB 0.11161 with this approach.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
