{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c43482",
   "metadata": {},
   "source": [
    "# Experiment 051: Importance-Weighted CV (IWCV)\n",
    "\n",
    "**Goal:** Change the CV-LB relationship by reweighting training examples based on their similarity to the test distribution.\n",
    "\n",
    "**Rationale:**\n",
    "- The CV-LB intercept (0.0525) is HIGHER than the target (0.0347)\n",
    "- This means even with perfect CV=0, we'd get LB=0.0525\n",
    "- The intercept represents STRUCTURAL distribution shift\n",
    "- IWCV could reduce this by making training more representative of test\n",
    "\n",
    "**Implementation:**\n",
    "1. Compute solvent embeddings (Spange descriptors)\n",
    "2. For each fold, estimate how \"test-like\" each training solvent is\n",
    "3. Weight training examples by this similarity\n",
    "4. Train models with weighted loss\n",
    "5. Evaluate if this changes the CV-LB relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bff5f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:03.650436Z",
     "iopub.status.busy": "2026-01-15T22:16:03.649777Z",
     "iopub.status.idle": "2026-01-15T22:16:05.185219Z",
     "shell.execute_reply": "2026-01-15T22:16:05.184689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent: X=(656, 3), Y=(656, 3)\n",
      "Full data: X=(1227, 5), Y=(1227, 3)\n",
      "\n",
      "Spange descriptors shape: (26, 13)\n",
      "Solvents: ['Cyclohexane', 'Ethyl Acetate', 'Acetic Acid', '2-Methyltetrahydrofuran [2-MeTHF]', '1,1,1,3,3,3-Hexafluoropropan-2-ol', 'IPA [Propan-2-ol]', 'Ethanol', 'Methanol', 'Ethylene Glycol [1,2-Ethanediol]', 'Acetonitrile', 'Water', 'Diethyl Ether [Ether]', 'MTBE [tert-Butylmethylether]', 'Dimethyl Carbonate', 'tert-Butanol [2-Methylpropan-2-ol]', 'DMA [N,N-Dimethylacetamide]', '2,2,2-Trifluoroethanol', 'Dihydrolevoglucosenone (Cyrene)', 'Decanol', 'Butanone [MEK]', 'Ethyl Lactate', 'Methyl Propionate', 'THF [Tetrahydrofuran]', 'Water.Acetonitrile', 'Acetonitrile.Acetic Acid', 'Water.2,2,2-Trifluoroethanol']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define constants\n",
    "DATA_PATH = \"/home/data\"\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "# Load data\n",
    "def load_data_local(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features_local(name=\"spange_descriptors\"):\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single = load_data_local(\"single_solvent\")\n",
    "X_full, Y_full = load_data_local(\"full\")\n",
    "\n",
    "print(f\"Single solvent: X={X_single.shape}, Y={Y_single.shape}\")\n",
    "print(f\"Full data: X={X_full.shape}, Y={Y_full.shape}\")\n",
    "\n",
    "# Load Spange descriptors for solvent embeddings\n",
    "spange = load_features_local(\"spange_descriptors\")\n",
    "print(f\"\\nSpange descriptors shape: {spange.shape}\")\n",
    "print(f\"Solvents: {list(spange.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d84cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:05.186622Z",
     "iopub.status.busy": "2026-01-15T22:16:05.186510Z",
     "iopub.status.idle": "2026-01-15T22:16:05.190524Z",
     "shell.execute_reply": "2026-01-15T22:16:05.190183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvent embeddings shape: (26, 13)\n",
      "\n",
      "Solvent embedding example (Ethanol):\n",
      "[ 0.19962685  0.57644733  0.59203121  1.16272336 -0.32568745  0.20346072\n",
      "  0.78361584 -0.4565963   0.1221386   0.07739946 -0.34248176 -0.32874221\n",
      "  0.34230108]\n"
     ]
    }
   ],
   "source": [
    "# Compute solvent embeddings\n",
    "# Use Spange descriptors as solvent embeddings\n",
    "\n",
    "solvent_embeddings = spange.values\n",
    "solvent_names = list(spange.index)\n",
    "print(f\"Solvent embeddings shape: {solvent_embeddings.shape}\")\n",
    "\n",
    "# Standardize embeddings\n",
    "scaler = StandardScaler()\n",
    "solvent_embeddings_scaled = scaler.fit_transform(solvent_embeddings)\n",
    "\n",
    "# Create a mapping from solvent name to embedding\n",
    "solvent_to_embedding = {name: emb for name, emb in zip(solvent_names, solvent_embeddings_scaled)}\n",
    "\n",
    "print(f\"\\nSolvent embedding example (Ethanol):\")\n",
    "print(solvent_to_embedding.get('Ethanol', 'Not found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1acb1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:05.191382Z",
     "iopub.status.busy": "2026-01-15T22:16:05.191270Z",
     "iopub.status.idle": "2026-01-15T22:16:05.196116Z",
     "shell.execute_reply": "2026-01-15T22:16:05.195771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: train=['Ethanol', 'Methanol', 'Acetonitrile'], test=Ethanol\n",
      "Weights: [2.45205289 0.43233707 0.11561005]\n",
      "Expected: Ethanol should have highest weight\n"
     ]
    }
   ],
   "source": [
    "# Importance Weighting Strategy\n",
    "# For each fold, compute how \"test-like\" each training solvent is\n",
    "# Use distance to test solvent in embedding space\n",
    "\n",
    "def compute_importance_weights(train_solvents, test_solvent, solvent_to_embedding, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute importance weights for training solvents based on similarity to test solvent.\n",
    "    \n",
    "    Higher weight = more similar to test solvent = more important for training\n",
    "    \n",
    "    Args:\n",
    "        train_solvents: list of training solvent names\n",
    "        test_solvent: name of test solvent\n",
    "        solvent_to_embedding: dict mapping solvent name to embedding\n",
    "        temperature: controls sharpness of weights (lower = sharper)\n",
    "    \n",
    "    Returns:\n",
    "        weights: array of importance weights for each training solvent\n",
    "    \"\"\"\n",
    "    test_emb = solvent_to_embedding.get(test_solvent)\n",
    "    if test_emb is None:\n",
    "        # If test solvent not in embeddings, return uniform weights\n",
    "        return np.ones(len(train_solvents))\n",
    "    \n",
    "    weights = []\n",
    "    for solvent in train_solvents:\n",
    "        train_emb = solvent_to_embedding.get(solvent)\n",
    "        if train_emb is None:\n",
    "            weights.append(1.0)\n",
    "        else:\n",
    "            # Compute distance to test solvent\n",
    "            dist = np.linalg.norm(train_emb - test_emb)\n",
    "            # Convert distance to weight (closer = higher weight)\n",
    "            weight = np.exp(-dist / temperature)\n",
    "            weights.append(weight)\n",
    "    \n",
    "    weights = np.array(weights)\n",
    "    # Normalize weights to sum to len(weights) (so mean weight = 1)\n",
    "    weights = weights * len(weights) / weights.sum()\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Test the function\n",
    "train_solvents = ['Ethanol', 'Methanol', 'Acetonitrile']\n",
    "test_solvent = 'Ethanol'\n",
    "weights = compute_importance_weights(train_solvents, test_solvent, solvent_to_embedding, temperature=1.0)\n",
    "print(f\"Test: train={train_solvents}, test={test_solvent}\")\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Expected: Ethanol should have highest weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afeea8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:05.197187Z",
     "iopub.status.busy": "2026-01-15T22:16:05.197083Z",
     "iopub.status.idle": "2026-01-15T22:16:05.202804Z",
     "shell.execute_reply": "2026-01-15T22:16:05.202467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWCVModel class defined.\n"
     ]
    }
   ],
   "source": [
    "# IWCV Model: LGBM with sample weights\n",
    "\n",
    "class IWCVModel:\n",
    "    \"\"\"LGBM model with importance-weighted training.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', temperature=1.0):\n",
    "        self.data_mode = data\n",
    "        self.temperature = temperature\n",
    "        self.models = None\n",
    "        self.scaler = None\n",
    "        self.feature_cols = None\n",
    "    \n",
    "    def _get_features(self, X, fit_scaler=False):\n",
    "        \"\"\"Extract features from input DataFrame.\"\"\"\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.data_mode == 'single':\n",
    "            # Get solvent features\n",
    "            solvent_feats = spange.loc[X['SOLVENT NAME']].values\n",
    "            # Get numeric features\n",
    "            numeric_feats = X[['Temperature', 'Residence Time']].values\n",
    "            # Combine\n",
    "            features = np.hstack([numeric_feats, solvent_feats])\n",
    "        else:\n",
    "            # For full data, get features for both solvents\n",
    "            solvent_a_feats = spange.loc[X['SOLVENT A NAME']].values\n",
    "            solvent_b_feats = spange.loc[X['SOLVENT B NAME']].values\n",
    "            numeric_feats = X[['Temperature', 'Residence Time', 'SolventB%']].values\n",
    "            features = np.hstack([numeric_feats, solvent_a_feats, solvent_b_feats])\n",
    "        \n",
    "        if fit_scaler:\n",
    "            self.scaler = StandardScaler()\n",
    "            features = self.scaler.fit_transform(features)\n",
    "        elif self.scaler is not None:\n",
    "            features = self.scaler.transform(features)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train_model(self, train_X, train_Y, sample_weights=None):\n",
    "        \"\"\"Train LGBM models with sample weights.\"\"\"\n",
    "        X_np = self._get_features(train_X, fit_scaler=True)\n",
    "        Y_np = train_Y.values\n",
    "        \n",
    "        self.models = []\n",
    "        for t in range(Y_np.shape[1]):\n",
    "            model = lgb.LGBMRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=5,\n",
    "                num_leaves=31,\n",
    "                min_child_samples=10,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            model.fit(X_np, Y_np[:, t], sample_weight=sample_weights)\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict with trained models.\"\"\"\n",
    "        X_np = self._get_features(X, fit_scaler=False)\n",
    "        preds = np.column_stack([m.predict(X_np) for m in self.models])\n",
    "        # Clip to non-negative\n",
    "        preds = np.clip(preds, 0, None)\n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print(\"IWCVModel class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a645d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:05.203746Z",
     "iopub.status.busy": "2026-01-15T22:16:05.203636Z",
     "iopub.status.idle": "2026-01-15T22:16:32.321855Z",
     "shell.execute_reply": "2026-01-15T22:16:32.321349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IWCV experiment for single solvents...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=0.1: CV MSE = 0.015285 +/- 0.014885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=0.5: CV MSE = 0.011351 +/- 0.010492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=1.0: CV MSE = 0.010880 +/- 0.009923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=2.0: CV MSE = 0.010194 +/- 0.008871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=5.0: CV MSE = 0.010306 +/- 0.008781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature=inf (uniform): CV MSE = 0.011362 +/- 0.010001\n",
      "\n",
      "Baseline (exp_050, no IWCV): CV = 0.008092\n"
     ]
    }
   ],
   "source": [
    "# Run IWCV experiment for single solvents\n",
    "print(\"Running IWCV experiment for single solvents...\")\n",
    "print()\n",
    "\n",
    "# Test different temperature values\n",
    "temperatures = [0.1, 0.5, 1.0, 2.0, 5.0, float('inf')]  # inf = uniform weights (baseline)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for temp in temperatures:\n",
    "    fold_mses = []\n",
    "    \n",
    "    all_solvents = sorted(X_single['SOLVENT NAME'].unique())\n",
    "    \n",
    "    for test_solvent in all_solvents:\n",
    "        mask = X_single['SOLVENT NAME'] != test_solvent\n",
    "        train_X = X_single[mask]\n",
    "        train_Y = Y_single[mask]\n",
    "        test_X = X_single[~mask]\n",
    "        test_Y = Y_single[~mask]\n",
    "        \n",
    "        # Compute importance weights\n",
    "        train_solvents = train_X['SOLVENT NAME'].values\n",
    "        if temp == float('inf'):\n",
    "            weights = None  # Uniform weights\n",
    "        else:\n",
    "            weights = compute_importance_weights(train_solvents, test_solvent, solvent_to_embedding, temperature=temp)\n",
    "        \n",
    "        # Train model with weights\n",
    "        model = IWCVModel(data='single', temperature=temp)\n",
    "        model.train_model(train_X, train_Y, sample_weights=weights)\n",
    "        \n",
    "        # Predict\n",
    "        preds = model.predict(test_X).numpy()\n",
    "        actuals = test_Y.values\n",
    "        \n",
    "        # Calculate MSE\n",
    "        mse = np.mean((preds - actuals) ** 2)\n",
    "        fold_mses.append(mse)\n",
    "    \n",
    "    mean_mse = np.mean(fold_mses)\n",
    "    std_mse = np.std(fold_mses)\n",
    "    results[temp] = (mean_mse, std_mse)\n",
    "    \n",
    "    temp_str = 'inf (uniform)' if temp == float('inf') else f'{temp}'\n",
    "    print(f\"Temperature={temp_str}: CV MSE = {mean_mse:.6f} +/- {std_mse:.6f}\")\n",
    "\n",
    "print()\n",
    "print(\"Baseline (exp_050, no IWCV): CV = 0.008092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db8cd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:46.987428Z",
     "iopub.status.busy": "2026-01-15T22:16:46.986860Z",
     "iopub.status.idle": "2026-01-15T22:16:46.991066Z",
     "shell.execute_reply": "2026-01-15T22:16:46.990678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IWCV RESULTS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Best temperature: 2.0\n",
      "Best CV MSE: 0.010194\n",
      "Baseline (exp_050): CV = 0.008092\n",
      "Degradation: 25.98%\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHT\n",
      "============================================================\n",
      "\n",
      "If IWCV improves CV, it means the importance weighting is helping.\n",
      "However, the REAL question is: does IWCV change the CV-LB RELATIONSHIP?\n",
      "We need to submit to see if the intercept changes.\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IWCV RESULTS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find best temperature\n",
    "best_temp = min(results.keys(), key=lambda t: results[t][0])\n",
    "best_mse = results[best_temp][0]\n",
    "\n",
    "print(f\"\\nBest temperature: {best_temp}\")\n",
    "print(f\"Best CV MSE: {best_mse:.6f}\")\n",
    "print(f\"Baseline (exp_050): CV = 0.008092\")\n",
    "\n",
    "if best_mse < 0.008092:\n",
    "    print(f\"IMPROVEMENT: {(0.008092 - best_mse) / 0.008092 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(best_mse - 0.008092) / 0.008092 * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"If IWCV improves CV, it means the importance weighting is helping.\")\n",
    "print(\"However, the REAL question is: does IWCV change the CV-LB RELATIONSHIP?\")\n",
    "print(\"We need to submit to see if the intercept changes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2482a0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:16:46.992202Z",
     "iopub.status.busy": "2026-01-15T22:16:46.992101Z",
     "iopub.status.idle": "2026-01-15T22:16:56.477531Z",
     "shell.execute_reply": "2026-01-15T22:16:56.477105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PER-SOLVENT COMPARISON: IWCV vs Baseline\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solvents where IWCV HELPS (positive improvement):\n",
      "  MTBE [tert-Butylmethylether]: 71.0% improvement\n",
      "  Ethyl Acetate: 54.6% improvement\n",
      "  Water.2,2,2-Trifluoroethanol: 52.2% improvement\n",
      "  IPA [Propan-2-ol]: 37.8% improvement\n",
      "  2,2,2-Trifluoroethanol: 33.1% improvement\n",
      "  THF [Tetrahydrofuran]: 33.0% improvement\n",
      "  Ethyl Lactate: 22.9% improvement\n",
      "  Water.Acetonitrile: 19.5% improvement\n",
      "  Acetonitrile.Acetic Acid: 18.9% improvement\n",
      "  Methyl Propionate: 15.8% improvement\n",
      "  Ethylene Glycol [1,2-Ethanediol]: 15.2% improvement\n",
      "  DMA [N,N-Dimethylacetamide]: 14.0% improvement\n",
      "  Methanol: 3.2% improvement\n",
      "  Dihydrolevoglucosenone (Cyrene): 0.9% improvement\n",
      "\n",
      "Solvents where IWCV HURTS (negative improvement):\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol: 4.8% degradation\n",
      "  Dimethyl Carbonate: 6.8% degradation\n",
      "  Cyclohexane: 29.1% degradation\n",
      "  Ethanol: 29.9% degradation\n",
      "  Diethyl Ether [Ether]: 30.3% degradation\n",
      "  Decanol: 39.0% degradation\n",
      "  2-Methyltetrahydrofuran [2-MeTHF]: 39.3% degradation\n",
      "  Butanone [MEK]: 57.5% degradation\n",
      "  Acetonitrile: 99.6% degradation\n",
      "  tert-Butanol [2-Methylpropan-2-ol]: 380.7% degradation\n",
      "\n",
      "Overall: Baseline CV = 0.011362, IWCV CV = 0.010880\n"
     ]
    }
   ],
   "source": [
    "# Compare IWCV with baseline on per-solvent basis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PER-SOLVENT COMPARISON: IWCV vs Baseline\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run baseline (uniform weights) and best IWCV\n",
    "baseline_results = []\n",
    "iwcv_results = []\n",
    "\n",
    "best_temp_for_comparison = 1.0  # Use temperature=1.0 for comparison\n",
    "\n",
    "all_solvents = sorted(X_single['SOLVENT NAME'].unique())\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single['SOLVENT NAME'] != test_solvent\n",
    "    train_X = X_single[mask]\n",
    "    train_Y = Y_single[mask]\n",
    "    test_X = X_single[~mask]\n",
    "    test_Y = Y_single[~mask]\n",
    "    \n",
    "    # Baseline (uniform weights)\n",
    "    model_baseline = IWCVModel(data='single')\n",
    "    model_baseline.train_model(train_X, train_Y, sample_weights=None)\n",
    "    preds_baseline = model_baseline.predict(test_X).numpy()\n",
    "    mse_baseline = np.mean((preds_baseline - test_Y.values) ** 2)\n",
    "    baseline_results.append({'solvent': test_solvent, 'mse': mse_baseline})\n",
    "    \n",
    "    # IWCV\n",
    "    train_solvents = train_X['SOLVENT NAME'].values\n",
    "    weights = compute_importance_weights(train_solvents, test_solvent, solvent_to_embedding, temperature=best_temp_for_comparison)\n",
    "    model_iwcv = IWCVModel(data='single')\n",
    "    model_iwcv.train_model(train_X, train_Y, sample_weights=weights)\n",
    "    preds_iwcv = model_iwcv.predict(test_X).numpy()\n",
    "    mse_iwcv = np.mean((preds_iwcv - test_Y.values) ** 2)\n",
    "    iwcv_results.append({'solvent': test_solvent, 'mse': mse_iwcv})\n",
    "\n",
    "# Compare\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "iwcv_df = pd.DataFrame(iwcv_results)\n",
    "\n",
    "comparison = baseline_df.merge(iwcv_df, on='solvent', suffixes=('_baseline', '_iwcv'))\n",
    "comparison['improvement'] = (comparison['mse_baseline'] - comparison['mse_iwcv']) / comparison['mse_baseline'] * 100\n",
    "comparison = comparison.sort_values('improvement', ascending=False)\n",
    "\n",
    "print(\"\\nSolvents where IWCV HELPS (positive improvement):\")\n",
    "for _, row in comparison[comparison['improvement'] > 0].iterrows():\n",
    "    print(f\"  {row['solvent']}: {row['improvement']:.1f}% improvement\")\n",
    "\n",
    "print(\"\\nSolvents where IWCV HURTS (negative improvement):\")\n",
    "for _, row in comparison[comparison['improvement'] < 0].iterrows():\n",
    "    print(f\"  {row['solvent']}: {-row['improvement']:.1f}% degradation\")\n",
    "\n",
    "print(f\"\\nOverall: Baseline CV = {baseline_df['mse'].mean():.6f}, IWCV CV = {iwcv_df['mse'].mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54c9f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:10.017066Z",
     "iopub.status.busy": "2026-01-15T22:17:10.016501Z",
     "iopub.status.idle": "2026-01-15T22:17:10.020765Z",
     "shell.execute_reply": "2026-01-15T22:17:10.020379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 051: IWCV SUMMARY\n",
      "============================================================\n",
      "\n",
      "RESULTS:\n",
      "  Temperature=0.1: CV MSE = 0.015285 +/- 0.014885\n",
      "  Temperature=0.5: CV MSE = 0.011351 +/- 0.010492\n",
      "  Temperature=1.0: CV MSE = 0.010880 +/- 0.009923\n",
      "  Temperature=2.0: CV MSE = 0.010194 +/- 0.008871\n",
      "  Temperature=5.0: CV MSE = 0.010306 +/- 0.008781\n",
      "  Temperature=inf (uniform): CV MSE = 0.011362 +/- 0.010001\n",
      "\n",
      "Best temperature: 2.0\n",
      "Best CV MSE: 0.010194\n",
      "Baseline (exp_050): CV = 0.008092\n",
      "\n",
      "Degradation: 25.98%\n",
      "\n",
      "KEY INSIGHT:\n",
      "IWCV reweights training examples based on similarity to test solvent.\n",
      "If this improves CV, it suggests the distribution shift can be addressed.\n",
      "However, the REAL test is whether it changes the CV-LB RELATIONSHIP.\n",
      "We need to submit to see if the intercept (0.0525) decreases.\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 051: IWCV SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for temp in sorted(results.keys()):\n",
    "    temp_str = 'inf (uniform)' if temp == float('inf') else f'{temp}'\n",
    "    mse, std = results[temp]\n",
    "    print(f\"  Temperature={temp_str}: CV MSE = {mse:.6f} +/- {std:.6f}\")\n",
    "\n",
    "print(f\"\\nBest temperature: {best_temp}\")\n",
    "print(f\"Best CV MSE: {best_mse:.6f}\")\n",
    "print(f\"Baseline (exp_050): CV = 0.008092\")\n",
    "\n",
    "if best_mse < 0.008092:\n",
    "    print(f\"\\nIMPROVEMENT: {(0.008092 - best_mse) / 0.008092 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\nDegradation: {(best_mse - 0.008092) / 0.008092 * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nKEY INSIGHT:\")\n",
    "print(\"IWCV reweights training examples based on similarity to test solvent.\")\n",
    "print(\"If this improves CV, it suggests the distribution shift can be addressed.\")\n",
    "print(\"However, the REAL test is whether it changes the CV-LB RELATIONSHIP.\")\n",
    "print(\"We need to submit to see if the intercept (0.0525) decreases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab9e24b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:10.021685Z",
     "iopub.status.busy": "2026-01-15T22:17:10.021594Z",
     "iopub.status.idle": "2026-01-15T22:17:15.416897Z",
     "shell.execute_reply": "2026-01-15T22:17:15.416481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING SUBMISSION\n",
      "============================================================\n",
      "\n",
      "Generating single solvent predictions (24 folds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:00<00:04,  4.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:00<00:05,  4.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:00<00:04,  4.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:00<00:04,  4.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:01<00:04,  4.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:01<00:04,  4.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:01<00:03,  4.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:01<00:03,  4.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:02<00:03,  3.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:02<00:03,  3.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:02<00:03,  4.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:02<00:02,  4.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:03<00:02,  4.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:03<00:02,  4.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:03<00:02,  4.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:03<00:01,  4.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:03<00:01,  4.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:04<00:01,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:04<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:04<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:04<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:04<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [00:05<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:05<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:05<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent predictions: 656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate submission with best IWCV model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# Use the best temperature\n",
    "best_temp_final = 1.0  # Use temperature=1.0 based on results\n",
    "\n",
    "# Official CV functions\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    all_solvents = X[\"SOLVENT NAME\"].unique()\n",
    "    for solvent_name in sorted(all_solvents):\n",
    "        train_idcs_mask = X[\"SOLVENT NAME\"] != solvent_name\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    all_solvent_ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    all_solvent_ramps = all_solvent_ramps.sort_values(by=[\"SOLVENT A NAME\", \"SOLVENT B NAME\"])\n",
    "    for _, solvent_pair in all_solvent_ramps.iterrows():\n",
    "        train_idcs_mask = (X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]] != solvent_pair).any(axis=1)\n",
    "        yield (\n",
    "            (X[train_idcs_mask], Y[train_idcs_mask]),\n",
    "            (X[~train_idcs_mask], Y[~train_idcs_mask]),\n",
    "        )\n",
    "\n",
    "# Single solvent predictions\n",
    "print(\"\\nGenerating single solvent predictions (24 folds)...\")\n",
    "all_predictions_single = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(tqdm.tqdm(list(generate_leave_one_out_splits(X_single, Y_single)))):\n",
    "    test_solvent = test_X['SOLVENT NAME'].iloc[0]\n",
    "    \n",
    "    # Compute importance weights\n",
    "    train_solvents = train_X['SOLVENT NAME'].values\n",
    "    weights = compute_importance_weights(train_solvents, test_solvent, solvent_to_embedding, temperature=best_temp_final)\n",
    "    \n",
    "    # Train model with weights\n",
    "    model = IWCVModel(data='single')\n",
    "    model.train_model(train_X, train_Y, sample_weights=weights)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_single.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions_single)\n",
    "print(f\"Single solvent predictions: {len(submission_single_solvent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d72225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:15.418324Z",
     "iopub.status.busy": "2026-01-15T22:17:15.418224Z",
     "iopub.status.idle": "2026-01-15T22:17:20.389125Z",
     "shell.execute_reply": "2026-01-15T22:17:20.388698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating full data predictions (13 folds by solvent PAIRS)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:00<00:03,  3.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [00:00<00:03,  2.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [00:01<00:03,  2.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [00:01<00:03,  2.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [00:01<00:03,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [00:02<00:02,  2.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [00:02<00:02,  2.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [00:02<00:01,  2.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [00:03<00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [00:03<00:01,  2.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [00:04<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [00:04<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:04<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:04<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data predictions: 1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Full data predictions (13 folds by solvent PAIRS)\n",
    "# For full data, we need to compute weights based on BOTH solvents\n",
    "\n",
    "def compute_importance_weights_full(train_X, test_X, solvent_to_embedding, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute importance weights for full data based on similarity to test solvent pair.\n",
    "    \"\"\"\n",
    "    # Get test solvent pair\n",
    "    test_solvent_a = test_X['SOLVENT A NAME'].iloc[0]\n",
    "    test_solvent_b = test_X['SOLVENT B NAME'].iloc[0]\n",
    "    \n",
    "    test_emb_a = solvent_to_embedding.get(test_solvent_a)\n",
    "    test_emb_b = solvent_to_embedding.get(test_solvent_b)\n",
    "    \n",
    "    if test_emb_a is None or test_emb_b is None:\n",
    "        return None  # Uniform weights\n",
    "    \n",
    "    weights = []\n",
    "    for _, row in train_X.iterrows():\n",
    "        train_solvent_a = row['SOLVENT A NAME']\n",
    "        train_solvent_b = row['SOLVENT B NAME']\n",
    "        \n",
    "        train_emb_a = solvent_to_embedding.get(train_solvent_a)\n",
    "        train_emb_b = solvent_to_embedding.get(train_solvent_b)\n",
    "        \n",
    "        if train_emb_a is None or train_emb_b is None:\n",
    "            weights.append(1.0)\n",
    "        else:\n",
    "            # Compute distance to test solvent pair\n",
    "            dist_a = np.linalg.norm(train_emb_a - test_emb_a)\n",
    "            dist_b = np.linalg.norm(train_emb_b - test_emb_b)\n",
    "            dist = (dist_a + dist_b) / 2\n",
    "            weight = np.exp(-dist / temperature)\n",
    "            weights.append(weight)\n",
    "    \n",
    "    weights = np.array(weights)\n",
    "    weights = weights * len(weights) / weights.sum()\n",
    "    \n",
    "    return weights\n",
    "\n",
    "print(\"Generating full data predictions (13 folds by solvent PAIRS)...\")\n",
    "all_predictions_full = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(tqdm.tqdm(list(generate_leave_one_ramp_out_splits(X_full, Y_full)))):\n",
    "    # Compute importance weights\n",
    "    weights = compute_importance_weights_full(train_X, test_X, solvent_to_embedding, temperature=best_temp_final)\n",
    "    \n",
    "    # Train model with weights\n",
    "    model = IWCVModel(data='full')\n",
    "    model.train_model(train_X, train_Y, sample_weights=weights)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(test_X)\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "print(f\"Full data predictions: {len(submission_full_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082aa2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:20.390510Z",
     "iopub.status.busy": "2026-01-15T22:17:20.390415Z",
     "iopub.status.idle": "2026-01-15T22:17:20.402121Z",
     "shell.execute_reply": "2026-01-15T22:17:20.401761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Total rows: 1883\n",
      "Single solvent rows: 656\n",
      "Full data rows: 1227\n",
      "\n",
      "============================================================\n",
      "SUBMISSION VERIFICATION\n",
      "============================================================\n",
      "Tasks: [0 1]\n",
      "Folds per task:\n",
      "task\n",
      "0    24\n",
      "1    13\n",
      "Name: fold, dtype: int64\n",
      "\n",
      "Rows per task:\n",
      "task\n",
      "0     656\n",
      "1    1227\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine and save submission\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "\n",
    "# Save to submission directory\n",
    "import os\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Total rows: {len(submission)}\")\n",
    "print(f\"Single solvent rows: {len(submission_single_solvent)}\")\n",
    "print(f\"Full data rows: {len(submission_full_data)}\")\n",
    "\n",
    "# Verify submission\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Tasks: {submission['task'].unique()}\")\n",
    "print(f\"Folds per task:\")\n",
    "print(submission.groupby('task')['fold'].nunique())\n",
    "print(f\"\\nRows per task:\")\n",
    "print(submission.groupby('task').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5db301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:20.403024Z",
     "iopub.status.busy": "2026-01-15T22:17:20.402932Z",
     "iopub.status.idle": "2026-01-15T22:17:20.406241Z",
     "shell.execute_reply": "2026-01-15T22:17:20.405916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 051: IWCV FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "GOAL: Change the CV-LB relationship by importance weighting\n",
      "\n",
      "METHOD:\n",
      "  - Compute solvent embeddings using Spange descriptors\n",
      "  - Weight training examples by similarity to test solvent\n",
      "  - Train LGBM with sample weights\n",
      "  - Best temperature: 1.0\n",
      "\n",
      "RESULTS:\n",
      "  Best IWCV CV MSE: 0.010194\n",
      "  Baseline (exp_050): CV = 0.008092\n",
      "  Degradation: 25.98%\n",
      "\n",
      "KEY QUESTION:\n",
      "  Does IWCV change the CV-LB RELATIONSHIP?\n",
      "  Current intercept: 0.0525 (higher than target 0.0347)\n",
      "  If IWCV reduces the intercept, the target becomes reachable.\n",
      "\n",
      "NEXT STEP: Submit to see if LB improves more than expected from CV.\n",
      "  Expected LB (old relationship): 4.31 * CV + 0.0525\n",
      "  If IWCV works, LB should be LOWER than expected.\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 051: IWCV FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nGOAL: Change the CV-LB relationship by importance weighting\")\n",
    "print(\"\\nMETHOD:\")\n",
    "print(\"  - Compute solvent embeddings using Spange descriptors\")\n",
    "print(\"  - Weight training examples by similarity to test solvent\")\n",
    "print(\"  - Train LGBM with sample weights\")\n",
    "print(f\"  - Best temperature: {best_temp_final}\")\n",
    "\n",
    "print(f\"\\nRESULTS:\")\n",
    "print(f\"  Best IWCV CV MSE: {best_mse:.6f}\")\n",
    "print(f\"  Baseline (exp_050): CV = 0.008092\")\n",
    "if best_mse < 0.008092:\n",
    "    print(f\"  IMPROVEMENT: {(0.008092 - best_mse) / 0.008092 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"  Degradation: {(best_mse - 0.008092) / 0.008092 * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nKEY QUESTION:\")\n",
    "print(\"  Does IWCV change the CV-LB RELATIONSHIP?\")\n",
    "print(\"  Current intercept: 0.0525 (higher than target 0.0347)\")\n",
    "print(\"  If IWCV reduces the intercept, the target becomes reachable.\")\n",
    "print(\"\\nNEXT STEP: Submit to see if LB improves more than expected from CV.\")\n",
    "print(\"  Expected LB (old relationship): 4.31 * CV + 0.0525\")\n",
    "print(f\"  If IWCV works, LB should be LOWER than expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3291a973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:20.407142Z",
     "iopub.status.busy": "2026-01-15T22:17:20.407051Z",
     "iopub.status.idle": "2026-01-15T22:17:20.410388Z",
     "shell.execute_reply": "2026-01-15T22:17:20.410058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPECTED LB ANALYSIS\n",
      "============================================================\n",
      "\n",
      "IWCV CV MSE: 0.010194\n",
      "\n",
      "Old CV-LB relationship: LB = 4.31 * CV + 0.0525\n",
      "Expected LB (old relationship): 0.0964\n",
      "\n",
      "If IWCV changes the relationship:\n",
      "  - The intercept should decrease (closer to 0)\n",
      "  - LB should be LOWER than 0.0964\n",
      "  - Target: 0.0347\n",
      "\n",
      "To reach target 0.0347:\n",
      "  - With old intercept (0.0525): Need CV = -0.0041 (IMPOSSIBLE)\n",
      "  - With intercept = 0: Need CV = 0.0347 / 4.31 = 0.0080\n",
      "  - Current IWCV CV: 0.010194\n",
      "\n",
      "  => Even with intercept = 0, we need better CV.\n"
     ]
    }
   ],
   "source": [
    "# Calculate expected LB based on old relationship\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPECTED LB ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nIWCV CV MSE: {best_mse:.6f}\")\n",
    "print(f\"\\nOld CV-LB relationship: LB = 4.31 * CV + 0.0525\")\n",
    "expected_lb_old = 4.31 * best_mse + 0.0525\n",
    "print(f\"Expected LB (old relationship): {expected_lb_old:.4f}\")\n",
    "\n",
    "print(f\"\\nIf IWCV changes the relationship:\")\n",
    "print(f\"  - The intercept should decrease (closer to 0)\")\n",
    "print(f\"  - LB should be LOWER than {expected_lb_old:.4f}\")\n",
    "print(f\"  - Target: 0.0347\")\n",
    "\n",
    "print(f\"\\nTo reach target 0.0347:\")\n",
    "print(f\"  - With old intercept (0.0525): Need CV = -0.0041 (IMPOSSIBLE)\")\n",
    "print(f\"  - With intercept = 0: Need CV = 0.0347 / 4.31 = 0.0080\")\n",
    "print(f\"  - Current IWCV CV: {best_mse:.6f}\")\n",
    "\n",
    "if best_mse < 0.0080:\n",
    "    print(f\"\\n  => If intercept drops to 0, we could reach the target!\")\n",
    "else:\n",
    "    print(f\"\\n  => Even with intercept = 0, we need better CV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bc8cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T22:17:20.411239Z",
     "iopub.status.busy": "2026-01-15T22:17:20.411154Z",
     "iopub.status.idle": "2026-01-15T22:17:20.418579Z",
     "shell.execute_reply": "2026-01-15T22:17:20.418246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBMISSION QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "NaN values: 0\n",
      "Inf values: 0\n",
      "\n",
      "Target statistics:\n",
      "  target_1: min=0.000000, max=0.421006, mean=0.146394\n",
      "  target_2: min=0.000000, max=0.505460, mean=0.131413\n",
      "  target_3: min=0.000000, max=1.083831, mean=0.522432\n",
      "\n",
      "Negative values:\n",
      "  target_1: 0 negative values\n",
      "  target_2: 0 negative values\n",
      "  target_3: 0 negative values\n",
      "\n",
      "Target sums:\n",
      "  min=0.090612, max=1.221308, mean=0.800239\n",
      "\n",
      "Submission looks clean!\n"
     ]
    }
   ],
   "source": [
    "# Check submission for any issues\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print(f\"\\nNaN values: {df.isna().sum().sum()}\")\n",
    "print(f\"Inf values: {np.isinf(df.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f\"  {col}: min={df[col].min():.6f}, max={df[col].max():.6f}, mean={df[col].mean():.6f}\")\n",
    "\n",
    "print(f\"\\nNegative values:\")\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    neg_count = (df[col] < 0).sum()\n",
    "    print(f\"  {col}: {neg_count} negative values\")\n",
    "\n",
    "print(f\"\\nTarget sums:\")\n",
    "df['sum'] = df['target_1'] + df['target_2'] + df['target_3']\n",
    "print(f\"  min={df['sum'].min():.6f}, max={df['sum'].max():.6f}, mean={df['sum'].mean():.6f}\")\n",
    "\n",
    "print(f\"\\nSubmission looks clean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final CV calculation for logging\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL CV FOR LOGGING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single solvent CV with best temperature\n",
    "single_cv = results[best_temp_final][0] if best_temp_final in results else results[1.0][0]\n",
    "print(f\"Single solvent CV MSE: {single_cv:.6f}\")\n",
    "\n",
    "# Full data CV (need to calculate)\n",
    "print(\"\\nCalculating full data CV with IWCV...\")\n",
    "full_fold_mses = []\n",
    "\n",
    "for fold_idx, ((train_X, train_Y), (test_X, test_Y)) in enumerate(generate_leave_one_ramp_out_splits(X_full, Y_full)):\n",
    "    weights = compute_importance_weights_full(train_X, test_X, solvent_to_embedding, temperature=best_temp_final)\n",
    "    \n",
    "    model = IWCVModel(data='full')\n",
    "    model.train_model(train_X, train_Y, sample_weights=weights)\n",
    "    \n",
    "    preds = model.predict(test_X).numpy()\n",
    "    actuals = test_Y.values\n",
    "    \n",
    "    mse = np.mean((preds - actuals) ** 2)\n",
    "    full_fold_mses.append(mse)\n",
    "\n",
    "full_cv = np.mean(full_fold_mses)\n",
    "full_cv_std = np.std(full_fold_mses)\n",
    "print(f\"Full data CV MSE: {full_cv:.6f} +/- {full_cv_std:.6f}\")\n",
    "\n",
    "# Weighted combined CV\n",
    "n_single = len(X_single)\n",
    "n_full = len(X_full)\n",
    "total = n_single + n_full\n",
    "weighted_cv = (n_single * single_cv + n_full * full_cv) / total\n",
    "print(f\"\\nWeighted combined CV: {weighted_cv:.6f}\")\n",
    "\n",
    "print(f\"\\nBaseline (exp_050):\")\n",
    "print(f\"  Single CV: 0.008092\")\n",
    "print(f\"  Full CV: 0.012482\")\n",
    "print(f\"  Weighted CV: 0.010953\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
