{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3a9ec9",
   "metadata": {},
   "source": [
    "# Experiment 090: ens-model Kernel Replication\n",
    "\n",
    "**Rationale**: The ens-model kernel (matthewmaree) uses techniques we haven't fully implemented:\n",
    "1. Correlation-based feature filtering (threshold=0.90)\n",
    "2. Feature priority: Spange > ACS > DRFP > Fragprints\n",
    "3. Different ensemble weights: single (7:6 CatBoost:XGBoost), full (1:2 CatBoost:XGBoost)\n",
    "4. Clipping and renormalization of predictions\n",
    "\n",
    "**Key insight**: These techniques might change the CV-LB relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9a98ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:53.608548Z",
     "iopub.status.busy": "2026-01-16T15:58:53.607979Z",
     "iopub.status.idle": "2026-01-16T15:58:55.184252Z",
     "shell.execute_reply": "2026-01-16T15:58:55.183767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302b5b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.185431Z",
     "iopub.status.busy": "2026-01-16T15:58:55.185260Z",
     "iopub.status.idle": "2026-01-16T15:58:55.189908Z",
     "shell.execute_reply": "2026-01-16T15:58:55.189550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53874fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.190768Z",
     "iopub.status.busy": "2026-01-16T15:58:55.190654Z",
     "iopub.status.idle": "2026-01-16T15:58:55.232233Z",
     "shell.execute_reply": "2026-01-16T15:58:55.231855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP: (24, 2048), ACS PCA: (24, 5), Fragprints: (24, 2133)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "FRAGPRINTS_DF = pd.read_csv(f'{DATA_PATH}/fragprints_lookup.csv', index_col=0)\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP: {DRFP_DF.shape}, ACS PCA: {ACS_PCA_DF.shape}, Fragprints: {FRAGPRINTS_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499572fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.233307Z",
     "iopub.status.busy": "2026-01-16T15:58:55.233201Z",
     "iopub.status.idle": "2026-01-16T15:58:55.238599Z",
     "shell.execute_reply": "2026-01-16T15:58:55.238234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature filtering functions defined\n"
     ]
    }
   ],
   "source": [
    "# Feature priority function (from ens-model kernel)\n",
    "def feature_priority(name):\n",
    "    \"\"\"Higher number = more important to keep during correlation filtering.\"\"\"\n",
    "    if name.startswith(\"spange_\"):\n",
    "        return 5\n",
    "    if name.startswith(\"acs_\"):\n",
    "        return 4\n",
    "    if name.startswith(\"drfps_\"):\n",
    "        return 3\n",
    "    if name.startswith(\"frag_\"):\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def filter_correlated_features(df, threshold=0.90):\n",
    "    \"\"\"Drop columns that are highly correlated with any other column.\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if numeric_df.shape[1] == 0:\n",
    "        return df, []\n",
    "    \n",
    "    # Drop constant columns first\n",
    "    std = numeric_df.std(axis=0)\n",
    "    constant_cols = std[std == 0].index.tolist()\n",
    "    if constant_cols:\n",
    "        numeric_df = numeric_df.drop(columns=constant_cols)\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr = numeric_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)).fillna(0.0)\n",
    "    \n",
    "    cols = upper.columns.tolist()\n",
    "    to_drop = set()\n",
    "    \n",
    "    # Find all pairs with corr > threshold\n",
    "    high_corr_pairs = []\n",
    "    for i, col_i in enumerate(cols):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            col_j = cols[j]\n",
    "            cval = upper.iloc[i, j]\n",
    "            if cval > threshold:\n",
    "                high_corr_pairs.append((col_i, col_j, cval))\n",
    "    \n",
    "    # For each pair, decide which column to drop\n",
    "    for col_i, col_j, cval in high_corr_pairs:\n",
    "        if col_i in to_drop or col_j in to_drop:\n",
    "            continue\n",
    "        \n",
    "        p_i = feature_priority(col_i)\n",
    "        p_j = feature_priority(col_j)\n",
    "        \n",
    "        if p_i > p_j:\n",
    "            drop = col_j\n",
    "        elif p_j > p_i:\n",
    "            drop = col_i\n",
    "        else:\n",
    "            # Same priority; drop the one that appears later\n",
    "            idx_i = df.columns.get_loc(col_i) if col_i in df.columns else 0\n",
    "            idx_j = df.columns.get_loc(col_j) if col_j in df.columns else 0\n",
    "            drop = col_i if idx_i > idx_j else col_j\n",
    "        \n",
    "        to_drop.add(drop)\n",
    "    \n",
    "    all_to_drop = list(set(constant_cols).union(to_drop))\n",
    "    df_filtered = df.drop(columns=all_to_drop, errors=\"ignore\")\n",
    "    \n",
    "    return df_filtered, all_to_drop\n",
    "\n",
    "print('Feature filtering functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf739fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.239617Z",
     "iopub.status.busy": "2026-01-16T15:58:55.239522Z",
     "iopub.status.idle": "2026-01-16T15:58:55.638665Z",
     "shell.execute_reply": "2026-01-16T15:58:55.638275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features before filtering: (26, 284)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features after filtering: (26, 84)\n",
      "Dropped 200 features\n",
      "\n",
      "Final solvent feature table: (26, 84)\n"
     ]
    }
   ],
   "source": [
    "# Build combined solvent feature table with correlation filtering\n",
    "def build_solvent_feature_table(threshold=0.90):\n",
    "    \"\"\"Build combined solvent feature table with correlation filtering.\"\"\"\n",
    "    \n",
    "    # Prepare Spange features\n",
    "    spange = SPANGE_DF.copy()\n",
    "    spange.columns = [f'spange_{c}' for c in spange.columns]\n",
    "    \n",
    "    # Prepare ACS PCA features\n",
    "    acs = ACS_PCA_DF.copy()\n",
    "    acs.columns = [f'acs_{c}' for c in acs.columns]\n",
    "    \n",
    "    # Prepare DRFP features (filter zero-variance)\n",
    "    drfp = DRFP_DF.copy()\n",
    "    drfp = drfp.loc[:, (drfp != 0).any(axis=0)]  # Drop all-zero columns\n",
    "    drfp = drfp.loc[:, (drfp != 1).any(axis=0)]  # Drop all-one columns\n",
    "    drfp.columns = [f'drfps_{c}' for c in drfp.columns]\n",
    "    \n",
    "    # Prepare Fragprints features (filter zero-variance)\n",
    "    frag = FRAGPRINTS_DF.copy()\n",
    "    frag = frag.loc[:, (frag != 0).any(axis=0)]\n",
    "    frag = frag.loc[:, (frag != 1).any(axis=0)]\n",
    "    frag.columns = [f'frag_{c}' for c in frag.columns]\n",
    "    \n",
    "    # Merge all features\n",
    "    combined = spange.join(acs, how='outer').join(drfp, how='outer').join(frag, how='outer')\n",
    "    combined = combined.fillna(0)\n",
    "    \n",
    "    print(f'Combined features before filtering: {combined.shape}')\n",
    "    \n",
    "    # Apply correlation filtering\n",
    "    combined_filtered, dropped = filter_correlated_features(combined, threshold=threshold)\n",
    "    \n",
    "    print(f'Combined features after filtering: {combined_filtered.shape}')\n",
    "    print(f'Dropped {len(dropped)} features')\n",
    "    \n",
    "    return combined_filtered\n",
    "\n",
    "# Build the feature table\n",
    "SOLVENT_FEATURES = build_solvent_feature_table(threshold=0.90)\n",
    "print(f'\\nFinal solvent feature table: {SOLVENT_FEATURES.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6b8b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.639657Z",
     "iopub.status.busy": "2026-01-16T15:58:55.639553Z",
     "iopub.status.idle": "2026-01-16T15:58:55.643552Z",
     "shell.execute_reply": "2026-01-16T15:58:55.643211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizer defined\n"
     ]
    }
   ],
   "source": [
    "# Featurizer class\n",
    "class Featurizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.solvent_features = SOLVENT_FEATURES\n",
    "        \n",
    "    def featurize(self, X):\n",
    "        # Numeric features with engineering\n",
    "        X_num = X[INPUT_LABELS_NUMERIC].copy()\n",
    "        X_num['Temperature'] = X_num['Temperature'] + 273.15  # Convert to Kelvin\n",
    "        T = X_num['Temperature']\n",
    "        rt = X_num['Residence Time']\n",
    "        X_num['T_x_RT'] = T * rt\n",
    "        X_num['RT_log'] = np.log(rt + 1e-6)\n",
    "        X_num['T_inv'] = 1 / T\n",
    "        X_num['RT_scaled'] = rt / rt.mean()\n",
    "        \n",
    "        if self.mixed:\n",
    "            # Get solvent features for both solvents\n",
    "            A_feats = self.solvent_features.loc[X['SOLVENT A NAME']].values\n",
    "            B_feats = self.solvent_features.loc[X['SOLVENT B NAME']].values\n",
    "            pct = X['SolventB%'].values.reshape(-1, 1) / 100.0\n",
    "            # Weighted average of solvent features\n",
    "            solvent_feats = A_feats * (1 - pct) + B_feats * pct\n",
    "        else:\n",
    "            solvent_feats = self.solvent_features.loc[X['SOLVENT NAME']].values\n",
    "        \n",
    "        # Combine numeric and solvent features\n",
    "        features = np.hstack([X_num.values, solvent_feats])\n",
    "        return torch.tensor(features, dtype=torch.double)\n",
    "\n",
    "print('Featurizer defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b374b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.644433Z",
     "iopub.status.busy": "2026-01-16T15:58:55.644336Z",
     "iopub.status.idle": "2026-01-16T15:58:55.649420Z",
     "shell.execute_reply": "2026-01-16T15:58:55.649039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostModel defined\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Model\n",
    "class CatBoostModel:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_mode = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.featurizer = Featurizer(mixed=self.mixed)\n",
    "        self.models = None\n",
    "        \n",
    "        if data == 'single':\n",
    "            self.params = dict(\n",
    "                iterations=500,\n",
    "                learning_rate=0.05,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.params = dict(\n",
    "                iterations=500,\n",
    "                learning_rate=0.05,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                random_seed=42,\n",
    "                verbose=False\n",
    "            )\n",
    "    \n",
    "    def train_model(self, train_X, train_Y):\n",
    "        X = self.featurizer.featurize(train_X).numpy()\n",
    "        Y = train_Y.values\n",
    "        \n",
    "        self.models = []\n",
    "        for i in range(Y.shape[1]):\n",
    "            model = CatBoostRegressor(**self.params)\n",
    "            model.fit(X, Y[:, i])\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        X = self.featurizer.featurize(test_X).numpy()\n",
    "        \n",
    "        preds = np.zeros((len(test_X), len(self.models)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            preds[:, i] = model.predict(X)\n",
    "        \n",
    "        # Clip and renormalize\n",
    "        preds = np.clip(preds, 0, None)\n",
    "        totals = preds.sum(axis=1, keepdims=True)\n",
    "        divisor = np.maximum(totals, 1.0)\n",
    "        preds = preds / divisor\n",
    "        \n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print('CatBoostModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bac30a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.650363Z",
     "iopub.status.busy": "2026-01-16T15:58:55.650253Z",
     "iopub.status.idle": "2026-01-16T15:58:55.655421Z",
     "shell.execute_reply": "2026-01-16T15:58:55.655046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBModel defined\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Model\n",
    "class XGBModel:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_mode = data\n",
    "        self.mixed = (data == 'full')\n",
    "        self.featurizer = Featurizer(mixed=self.mixed)\n",
    "        self.models = None\n",
    "        \n",
    "        if data == 'single':\n",
    "            self.params = dict(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                reg_lambda=3,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "        else:\n",
    "            self.params = dict(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                reg_lambda=3,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "    \n",
    "    def train_model(self, train_X, train_Y):\n",
    "        X = self.featurizer.featurize(train_X).numpy()\n",
    "        Y = train_Y.values\n",
    "        \n",
    "        self.models = []\n",
    "        for i in range(Y.shape[1]):\n",
    "            model = xgb.XGBRegressor(**self.params)\n",
    "            model.fit(X, Y[:, i])\n",
    "            self.models.append(model)\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        X = self.featurizer.featurize(test_X).numpy()\n",
    "        \n",
    "        preds = np.zeros((len(test_X), len(self.models)))\n",
    "        for i, model in enumerate(self.models):\n",
    "            preds[:, i] = model.predict(X)\n",
    "        \n",
    "        # Clip and renormalize\n",
    "        preds = np.clip(preds, 0, None)\n",
    "        totals = preds.sum(axis=1, keepdims=True)\n",
    "        divisor = np.maximum(totals, 1.0)\n",
    "        preds = preds / divisor\n",
    "        \n",
    "        return torch.tensor(preds, dtype=torch.double)\n",
    "\n",
    "print('XGBModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3fa893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:58:55.656460Z",
     "iopub.status.busy": "2026-01-16T15:58:55.656359Z",
     "iopub.status.idle": "2026-01-16T15:58:55.660388Z",
     "shell.execute_reply": "2026-01-16T15:58:55.660025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleModel defined\n",
      "Single weights: CatBoost=0.538, XGBoost=0.462\n",
      "Full weights: CatBoost=0.333, XGBoost=0.667\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model with different weights for single vs full data\n",
    "class EnsembleModel:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_mode = data\n",
    "        \n",
    "        # Optimized fixed weights per dataset (from ens-model kernel)\n",
    "        if data == 'single':\n",
    "            cat_weight = 7.0\n",
    "            xgb_weight = 6.0\n",
    "        else:\n",
    "            cat_weight = 1.0\n",
    "            xgb_weight = 2.0\n",
    "        \n",
    "        # Normalize ensemble weights\n",
    "        w_sum = cat_weight + xgb_weight\n",
    "        self.cat_weight = cat_weight / w_sum\n",
    "        self.xgb_weight = xgb_weight / w_sum\n",
    "        \n",
    "        # Initialize base models\n",
    "        self.cat_model = CatBoostModel(data=data)\n",
    "        self.xgb_model = XGBModel(data=data)\n",
    "    \n",
    "    def train_model(self, train_X, train_Y):\n",
    "        self.cat_model.train_model(train_X, train_Y)\n",
    "        self.xgb_model.train_model(train_X, train_Y)\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        cat_pred = self.cat_model.predict(test_X)\n",
    "        xgb_pred = self.xgb_model.predict(test_X)\n",
    "        \n",
    "        out = self.cat_weight * cat_pred + self.xgb_weight * xgb_pred\n",
    "        return out\n",
    "\n",
    "print('EnsembleModel defined')\n",
    "print(f'Single weights: CatBoost={7/13:.3f}, XGBoost={6/13:.3f}')\n",
    "print(f'Full weights: CatBoost={1/3:.3f}, XGBoost={2/3:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2b4323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T15:59:06.889196Z",
     "iopub.status.busy": "2026-01-16T15:59:06.888983Z",
     "iopub.status.idle": "2026-01-16T15:59:43.120133Z",
     "shell.execute_reply": "2026-01-16T15:59:43.119727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:01,  1.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:03,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:04,  1.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:06,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:07,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:09,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:10,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:12,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:13,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:15,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:16,  1.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:18,  1.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:19,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:21,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:22,  1.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:23,  1.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [00:25,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [00:27,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:28,  1.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [00:30,  1.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [00:31,  1.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [00:33,  1.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [00:34,  1.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:36,  1.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [00:36,  1.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2c0ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T16:00:30.459099Z",
     "iopub.status.busy": "2026-01-16T16:00:30.458670Z",
     "iopub.status.idle": "2026-01-16T16:01:02.993773Z",
     "shell.execute_reply": "2026-01-16T16:01:02.993370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:04,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:07,  2.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:09,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:12,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:14,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:17,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:19,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:22,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:24,  2.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:27,  2.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:29,  2.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:32,  2.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:32,  2.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = EnsembleModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e92340",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV score (for verification only - NOT part of submission)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nBest previous CV: 0.008092 (CatBoost+XGBoost)')\n",
    "print(f'Best previous LB: 0.0877 (GP+MLP+LGBM)')\n",
    "print(f'\\nThis (ens-model replication): CV {overall_mse:.6f}')\n",
    "\n",
    "if overall_mse < 0.008092:\n",
    "    improvement = (0.008092 - overall_mse) / 0.008092 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than best CV!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008092) / 0.008092 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than best CV')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
