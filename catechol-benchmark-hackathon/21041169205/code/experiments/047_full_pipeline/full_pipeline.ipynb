{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e75bf59",
   "metadata": {},
   "source": [
    "# Experiment 047: Full Pipeline Implementation\n",
    "\n",
    "**Goal:** Implement the FULL pipeline from top kernels (gentilless/best-work-here)\n",
    "\n",
    "**Key techniques:**\n",
    "1. Non-linear mixture formula: `A * (1 - r) + B * r + 0.05 * A * B * r * (1 - r)`\n",
    "2. Advanced feature engineering (polynomial, interaction, statistical)\n",
    "3. Stronger hyperparameters (3000+ iterations for tree models)\n",
    "4. CatBoost + XGBoost + LightGBM ensemble\n",
    "5. Adaptive ensemble weighting\n",
    "\n",
    "**Hypothesis:** These techniques may CHANGE the CV-LB relationship, not just improve CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7c1dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:47:49.586560Z",
     "iopub.status.busy": "2026-01-15T19:47:49.586008Z",
     "iopub.status.idle": "2026-01-15T19:47:51.318564Z",
     "shell.execute_reply": "2026-01-15T19:47:51.318133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for CatBoost\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    HAS_CATBOOST = True\n",
    "    print('CatBoost available')\n",
    "except ImportError:\n",
    "    HAS_CATBOOST = False\n",
    "    print('CatBoost not available, will use XGBoost instead')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cd1c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:47:51.319716Z",
     "iopub.status.busy": "2026-01-15T19:47:51.319562Z",
     "iopub.status.idle": "2026-01-15T19:47:51.354878Z",
     "shell.execute_reply": "2026-01-15T19:47:51.354448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: 13 features\n",
      "DRFP: 2048 features\n",
      "Single solvent: 656 samples\n",
      "Full data: 1227 samples\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"SM\", \"Product 2\", \"Product 3\"]]\n",
    "    return X, Y\n",
    "\n",
    "# Load feature lookup tables\n",
    "spange_df = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "drfp_df = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "\n",
    "SPANGE_COLS = [c for c in spange_df.columns if c != 'solvent smiles']\n",
    "DRFP_COLS = [c for c in drfp_df.columns if str(c).isdigit() or isinstance(c, int)]\n",
    "\n",
    "print(f'Spange: {len(SPANGE_COLS)} features')\n",
    "print(f'DRFP: {len(DRFP_COLS)} features')\n",
    "\n",
    "# Load data\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "X_full, Y_full = load_data('full')\n",
    "\n",
    "print(f'Single solvent: {len(X_single)} samples')\n",
    "print(f'Full data: {len(X_full)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d289edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:47:51.356029Z",
     "iopub.status.busy": "2026-01-15T19:47:51.355927Z",
     "iopub.status.idle": "2026-01-15T19:47:51.362807Z",
     "shell.execute_reply": "2026-01-15T19:47:51.362442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced feature extraction defined\n"
     ]
    }
   ],
   "source": [
    "# Advanced feature extraction with non-linear mixture and polynomial features\n",
    "def get_advanced_features(X, data_type='single'):\n",
    "    \"\"\"Extract features with advanced engineering from gentilless kernel.\"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for idx, row in X.iterrows():\n",
    "        # Basic kinetics features\n",
    "        time_m = row['Residence Time']\n",
    "        temp_c = row['Temperature']\n",
    "        temp_k = temp_c + 273.15\n",
    "        \n",
    "        # Kinetics features (expanded)\n",
    "        kinetics = np.array([\n",
    "            time_m,\n",
    "            temp_c,\n",
    "            1.0 / temp_k,  # Arrhenius\n",
    "            np.log(time_m + 1),  # Log time\n",
    "            time_m / temp_k,  # Interaction\n",
    "            time_m * temp_c,  # T_x_RT interaction\n",
    "            np.sqrt(time_m + 1e-8),  # Sqrt time\n",
    "            temp_c ** 2,  # Polynomial temp\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        if data_type == 'single':\n",
    "            solvent = row['SOLVENT NAME']\n",
    "            spange = spange_df.loc[solvent, SPANGE_COLS].values.astype(np.float32) if solvent in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            drfp = drfp_df.loc[solvent, DRFP_COLS].values.astype(np.float32) if solvent in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            \n",
    "            # Statistical features from molecular descriptors\n",
    "            mol_stats = np.array([\n",
    "                spange.mean(),\n",
    "                spange.std(),\n",
    "                spange.max(),\n",
    "                spange.min(),\n",
    "            ], dtype=np.float32)\n",
    "            \n",
    "            features = np.concatenate([kinetics, spange, mol_stats, drfp])\n",
    "        else:\n",
    "            # Full solvent (mixture) - use NON-LINEAR mixing\n",
    "            solvent_a = row['SOLVENT A NAME']\n",
    "            solvent_b = row['SOLVENT B NAME']\n",
    "            pct_b = row['SolventB%'] / 100.0\n",
    "            pct_a = 1 - pct_b\n",
    "            \n",
    "            # Get Spange descriptors\n",
    "            sp_a = spange_df.loc[solvent_a, SPANGE_COLS].values.astype(np.float32) if solvent_a in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            sp_b = spange_df.loc[solvent_b, SPANGE_COLS].values.astype(np.float32) if solvent_b in spange_df.index else np.zeros(len(SPANGE_COLS), dtype=np.float32)\n",
    "            \n",
    "            # NON-LINEAR mixture formula from gentilless kernel:\n",
    "            # mixture = A * (1 - r) + B * r + 0.05 * A * B * r * (1 - r)\n",
    "            spange_linear = pct_a * sp_a + pct_b * sp_b\n",
    "            spange_interaction = 0.05 * sp_a * sp_b * pct_a * pct_b\n",
    "            spange = spange_linear + spange_interaction\n",
    "            \n",
    "            # Additional interaction features\n",
    "            interaction_feat = sp_a * sp_b * pct_a * pct_b * 4  # Scaled interaction\n",
    "            difference_feat = np.abs(sp_a - sp_b)  # Absolute difference\n",
    "            \n",
    "            # DRFP features (linear mixing)\n",
    "            dr_a = drfp_df.loc[solvent_a, DRFP_COLS].values.astype(np.float32) if solvent_a in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            dr_b = drfp_df.loc[solvent_b, DRFP_COLS].values.astype(np.float32) if solvent_b in drfp_df.index else np.zeros(len(DRFP_COLS), dtype=np.float32)\n",
    "            drfp = pct_a * dr_a + pct_b * dr_b\n",
    "            \n",
    "            # Statistical features\n",
    "            mol_stats = np.array([\n",
    "                spange.mean(),\n",
    "                spange.std(),\n",
    "                spange.max(),\n",
    "                spange.min(),\n",
    "            ], dtype=np.float32)\n",
    "            \n",
    "            # Mixture-specific features\n",
    "            mixture_feat = np.array([pct_b], dtype=np.float32)  # Mixture ratio\n",
    "            \n",
    "            features = np.concatenate([kinetics, spange, interaction_feat, difference_feat, mol_stats, mixture_feat, drfp])\n",
    "        \n",
    "        features_list.append(features)\n",
    "    \n",
    "    return np.array(features_list, dtype=np.float32)\n",
    "\n",
    "print('Advanced feature extraction defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5f0e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:47:51.363791Z",
     "iopub.status.busy": "2026-01-15T19:47:51.363690Z",
     "iopub.status.idle": "2026-01-15T19:47:51.367065Z",
     "shell.execute_reply": "2026-01-15T19:47:51.366706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model with optional SE attention\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print('MLPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dcf9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T19:47:51.367965Z",
     "iopub.status.busy": "2026-01-15T19:47:51.367871Z",
     "iopub.status.idle": "2026-01-15T19:47:51.376794Z",
     "shell.execute_reply": "2026-01-15T19:47:51.376428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullPipelineModel defined\n"
     ]
    }
   ],
   "source": [
    "# Full Pipeline Model with advanced features and stronger hyperparameters\n",
    "class FullPipelineModel:\n",
    "    def __init__(self, data='single', gp_weight=0.15, mlp_weight=0.35, lgbm_weight=0.25, xgb_weight=0.25):\n",
    "        self.data_type = data\n",
    "        self.gp_weight = gp_weight\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.xgb_weight = xgb_weight\n",
    "        \n",
    "        self.scaler = None\n",
    "        self.gp_models = []\n",
    "        self.mlp_models = []\n",
    "        self.lgbm_models = []\n",
    "        self.xgb_models = []\n",
    "    \n",
    "    def train_model(self, X_train, y_train, epochs=200):\n",
    "        X_feat = get_advanced_features(X_train, self.data_type)\n",
    "        y_np = y_train.values.astype(np.float32)\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Determine GP feature count (kinetics + spange + stats)\n",
    "        gp_feat_count = min(30, X_scaled.shape[1])  # Use first 30 features for GP\n",
    "        \n",
    "        # Train GP models (one per target)\n",
    "        self.gp_models = []\n",
    "        for i in range(3):\n",
    "            kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=2, random_state=42)\n",
    "            gp.fit(X_scaled[:, :gp_feat_count], y_np[:, i])\n",
    "            self.gp_models.append(gp)\n",
    "        \n",
    "        # Train MLP models (ensemble of 3) with stronger architecture\n",
    "        self.mlp_models = []\n",
    "        for _ in range(3):\n",
    "            model = MLPModel(X_scaled.shape[1], hidden_dims=[256, 128, 64], dropout=0.3).to(device)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            \n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            y_tensor = torch.tensor(y_np).to(device)\n",
    "            \n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    # Weighted loss\n",
    "                    weights = torch.tensor([1.0, 1.0, 2.0]).to(device)\n",
    "                    loss = (weights * (pred - y_batch)**2).mean()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.mlp_models.append(model)\n",
    "        \n",
    "        # Train LightGBM models with STRONGER hyperparameters\n",
    "        self.lgbm_models = []\n",
    "        for i in range(3):\n",
    "            lgbm_model = lgb.LGBMRegressor(\n",
    "                n_estimators=500,  # Increased from 100\n",
    "                max_depth=8,  # Increased from 5\n",
    "                learning_rate=0.02,  # Decreased for more iterations\n",
    "                num_leaves=63,  # Increased from 31\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            lgbm_model.fit(X_scaled, y_np[:, i])\n",
    "            self.lgbm_models.append(lgbm_model)\n",
    "        \n",
    "        # Train XGBoost models with STRONGER hyperparameters\n",
    "        self.xgb_models = []\n",
    "        for i in range(3):\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=500,  # Increased\n",
    "                max_depth=8,  # Increased\n",
    "                learning_rate=0.02,  # Decreased\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "            xgb_model.fit(X_scaled, y_np[:, i])\n",
    "            self.xgb_models.append(xgb_model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_feat = get_advanced_features(X_test, self.data_type)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        gp_feat_count = min(30, X_scaled.shape[1])\n",
    "        \n",
    "        # GP predictions\n",
    "        gp_preds = np.zeros((len(X_test), 3))\n",
    "        for i, gp in enumerate(self.gp_models):\n",
    "            gp_preds[:, i] = gp.predict(X_scaled[:, :gp_feat_count])\n",
    "        \n",
    "        # MLP predictions\n",
    "        mlp_preds = []\n",
    "        for model in self.mlp_models:\n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(X_tensor).cpu().numpy()\n",
    "            mlp_preds.append(pred)\n",
    "        mlp_preds = np.mean(mlp_preds, axis=0)\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        lgbm_preds = np.zeros((len(X_test), 3))\n",
    "        for i, lgbm_model in enumerate(self.lgbm_models):\n",
    "            lgbm_preds[:, i] = lgbm_model.predict(X_scaled)\n",
    "        \n",
    "        # XGBoost predictions\n",
    "        xgb_preds = np.zeros((len(X_test), 3))\n",
    "        for i, xgb_model in enumerate(self.xgb_models):\n",
    "            xgb_preds[:, i] = xgb_model.predict(X_scaled)\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        final_preds = (self.gp_weight * gp_preds + \n",
    "                       self.mlp_weight * mlp_preds + \n",
    "                       self.lgbm_weight * lgbm_preds +\n",
    "                       self.xgb_weight * xgb_preds)\n",
    "        \n",
    "        final_preds = np.clip(final_preds, 0, 1)\n",
    "        return torch.tensor(final_preds, dtype=torch.float32)\n",
    "\n",
    "print('FullPipelineModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e351b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on single solvent data\n",
    "print(\"Testing full pipeline on single solvent data...\")\n",
    "print()\n",
    "\n",
    "all_solvents = sorted(X_single[\"SOLVENT NAME\"].unique())\n",
    "fold_mses = []\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "    \n",
    "    model = FullPipelineModel(data='single')\n",
    "    model.train_model(X_single[mask], Y_single[mask], epochs=150)\n",
    "    preds = model.predict(X_single[~mask])\n",
    "    \n",
    "    actuals = Y_single[~mask].values\n",
    "    mse = np.mean((actuals - preds.numpy())**2)\n",
    "    fold_mses.append(mse)\n",
    "\n",
    "mean_mse = np.mean(fold_mses)\n",
    "std_mse = np.std(fold_mses)\n",
    "print(f\"Full Pipeline CV MSE: {mean_mse:.6f} +/- {std_mse:.6f}\")\n",
    "print(f\"Baseline (exp_030): CV = 0.008298\")\n",
    "if mean_mse < 0.008298:\n",
    "    print(f\"Improvement: {(0.008298 - mean_mse) / 0.008298 * 100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Degradation: {(mean_mse - 0.008298) / 0.008298 * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
