## What I Understood

The junior researcher implemented experiment 077 (074_prob_norm_final), which adds probability normalization to the GP+MLP+LGBM ensemble from exp_030. The hypothesis was that forcing predictions to sum to 1 (like the "best-work-here" kernel) might change the CV-LB relationship and potentially reduce the intercept. The result: CV worsened from 0.008298 to 0.013606 (64% worse), but predictions now sum exactly to 1.0.

## Technical Execution Assessment

**Validation**: SOUND ✓
- Uses official Leave-One-Out CV (24 folds for single solvent, 13 folds for full data)
- Correctly implements leave-one-solvent-out and leave-one-ramp-out splits
- CV calculation methodology is correct

**Leakage Risk**: None detected ✓
- Model trained fresh per fold
- Scalers fitted per fold
- No target information leaking into features

**Score Integrity**: VERIFIED ✓
- Single solvent CV: 0.013606 (verified in experiment notes)
- Full data CV: 0.013602 (verified in experiment notes)
- Overall CV: 0.013606 (weighted average)
- Predictions sum exactly to 1.0 (verified)

**Code Quality**: GOOD ✓
- Clean implementation of probability normalization
- Triple normalization for stability (from best-work-here kernel)
- Template compliance maintained
- Sigmoid output + normalization ensures valid probabilities

Verdict: **TRUSTWORTHY** - The implementation is technically sound.

## Strategic Assessment

### CRITICAL FINDING: Probability Normalization is FUNDAMENTALLY WRONG

I analyzed the actual target data:
```
Single Solvent Data:
- Row sums: min=0.0288, max=1.0000, mean=0.7955, std=0.1942
- Rows where sum != 1: 604 out of 656 (92%)

Full Data:
- Row sums: min=0.0112, max=1.1233, mean=0.8035, std=0.2091
- Rows where sum != 1: 1113 out of 1227 (91%)
```

**The actual targets (Product 2, Product 3, SM) do NOT sum to 1!** The mean sum is ~0.80, with a range from 0.01 to 1.12. This means:
1. Probability normalization is forcing an incorrect constraint
2. The "best-work-here" kernel's approach is WRONG for this problem
3. The 64% CV regression is expected because the model is being forced to predict something that doesn't match reality

### CV-LB Relationship Analysis (CRITICAL)

Based on 13 successful submissions with LB scores:
```
Linear fit: LB = 4.34 * CV + 0.052
R² = 0.96 (extremely tight fit)
Intercept = 0.052
Target LB = 0.0347
Required CV for target = (0.0347 - 0.052) / 4.34 = -0.004 (IMPOSSIBLE)
```

**Key Insight**: The intercept (0.052) is HIGHER than the target (0.0347). This means:
- Standard CV optimization CANNOT reach the target
- The intercept represents STRUCTURAL DISTRIBUTION SHIFT
- The team needs approaches that change the CV-LB relationship, not just improve CV

### Approach Fit

**FUNDAMENTALLY WRONG**: The probability normalization assumes yields sum to 1, but:
- The actual data shows yields sum to ~0.80 on average
- There are other products (Product 1) not included in the targets
- Side reactions, measurement errors, and material losses exist
- The competition description doesn't state yields must sum to 1

The "best-work-here" kernel may have achieved a good LB score despite this constraint, but that doesn't mean the constraint is correct. It may have worked by accident or for other reasons.

### Effort Allocation

**Current bottleneck**: The CV-LB intercept (0.052) is higher than the target (0.0347).

**Observation**: The team has tried many approaches:
- Different model architectures (MLP, LGBM, XGB, CatBoost, GP)
- Different features (Spange, DRFP, ACS PCA)
- Different ensemble weights
- Extrapolation detection
- Probability normalization (this experiment)

**ALL approaches fall on the same CV-LB line** (R² = 0.96). This strongly suggests:
1. The problem is STRUCTURAL distribution shift, not model choice
2. The test solvents are fundamentally different from training solvents
3. Standard ML approaches cannot bridge this gap

### Blind Spots

1. **The mixall kernel uses GroupKFold (5 splits)**: This is a different CV scheme that might have different CV-LB characteristics. The team has been using Leave-One-Out CV exclusively. Worth investigating if GroupKFold produces a different CV-LB relationship.

2. **The GNN benchmark achieved MSE 0.0039**: This is 8.9x better than the target (0.0347). What did it do differently?
   - The GNN uses graph neural networks with message-passing and attention
   - It captures molecular structure in a fundamentally different way
   - The team has not successfully implemented a GNN approach

3. **Submission budget**: Only 4 submissions remaining today. Need to be strategic.

## What's Working

1. **Best model identified**: exp_030 (GP+MLP+LGBM) with CV=0.008298, LB=0.08772
2. **Technical implementation is sound**: The code is correct and template-compliant
3. **Comprehensive experimentation**: 78 experiments have explored many approaches
4. **Good understanding of the CV-LB relationship**: The team has identified the structural distribution shift problem

## Key Concerns

### CRITICAL: Probability Normalization is WRONG

**Observation**: CV went from 0.008298 to 0.013606 (64% worse) with probability normalization.

**Why it matters**: The actual targets do NOT sum to 1 (mean=0.80, range=0.01-1.12). Forcing predictions to sum to 1 introduces a constraint that doesn't match the data.

**Suggestion**: **DO NOT SUBMIT this experiment.** The CV regression strongly suggests the LB will also be worse. Revert to exp_030 (best model).

### HIGH PRIORITY: All Approaches Fall on Same CV-LB Line

**Observation**: R² = 0.96 for the CV-LB relationship across 13 submissions with different model types.

**Why it matters**: This indicates STRUCTURAL distribution shift that no model tuning can fix. The intercept (0.052) is higher than the target (0.0347).

**Suggestion**: Focus on approaches that fundamentally change the prediction strategy:
1. **Try GroupKFold CV** (like mixall kernel) - might have different CV-LB characteristics
2. **Uncertainty-weighted predictions**: Use GP variance to blend toward conservative values when extrapolating
3. **Chemical class-specific models**: Different models for alcohols, ethers, fluorinated solvents
4. **Study the GNN benchmark**: It achieved 0.0039 MSE - what's fundamentally different?

### MEDIUM PRIORITY: Limited Submission Budget

**Observation**: Only 4 submissions remaining today.

**Why it matters**: Each submission is valuable for understanding the CV-LB relationship.

**Suggestion**: Prioritize submissions that test fundamentally different approaches:
1. Revert to exp_030 (best model) as baseline
2. Try GroupKFold CV to see if it changes the CV-LB relationship
3. Try extrapolation detection with conservative fallback
4. Save 1 submission for end-of-day best attempt

## Top Priority for Next Experiment

### DO NOT SUBMIT exp_077 (prob_norm_final)

The CV regression (0.008 → 0.014) and the fact that targets don't sum to 1 strongly suggest the LB will be worse. This would waste a submission.

### INSTEAD: Try GroupKFold CV (like mixall kernel)

The mixall kernel uses GroupKFold (5 splits) instead of Leave-One-Out CV. This is a fundamentally different validation scheme that might:
1. Have a different CV-LB relationship
2. Better simulate the test distribution
3. Provide more stable estimates

**Recommended experiment:**
1. Keep exp_030's model architecture (GP+MLP+LGBM ensemble)
2. Change CV scheme from Leave-One-Out to GroupKFold (5 splits)
3. Compare CV scores and submit to see if the CV-LB relationship changes

If GroupKFold produces a different CV-LB line (different slope or intercept), this would be a breakthrough. If it falls on the same line, we know the CV scheme isn't the issue.

### Alternative: Extrapolation Detection with Conservative Fallback

If GroupKFold doesn't help, try:
1. Compute distance of test solvent to training solvents (using Spange descriptors)
2. When distance is high (extrapolating), blend predictions toward:
   - Population mean (conservative)
   - Nearest neighbor predictions (local)
3. This should reduce variance on outlier solvents, potentially reducing the intercept

---

## Summary

| Dimension | Assessment |
|-----------|------------|
| Technical Execution | ✅ TRUSTWORTHY - Implementation is sound |
| Strategic Direction | ❌ FUNDAMENTALLY WRONG - Targets don't sum to 1 |
| CV Score | ❌ REGRESSION - 64% worse than exp_030 |
| Recommendation | **DO NOT SUBMIT** - Try GroupKFold CV instead |

## Confidence Levels

- **Very High confidence (99%)**: The targets do NOT sum to 1 (verified in data)
- **Very High confidence (99%)**: Probability normalization is wrong for this problem
- **High confidence (95%)**: The CV-LB relationship is linear with intercept 0.052 (based on 13 submissions)
- **High confidence (95%)**: The target (0.0347) requires reducing the intercept, not just improving CV
- **Moderate confidence (70%)**: GroupKFold CV might produce a different CV-LB relationship
- **High confidence (95%)**: The target IS reachable (GNN benchmark achieved 0.0039)

## THE TARGET IS REACHABLE

The GNN benchmark achieved MSE 0.0039 on this exact dataset. The target (0.0347) is 8.9x worse than the GNN result, proving it's very achievable. The key is to find an approach that changes the CV-LB relationship, not just improves CV.

**NEXT STEPS:**
1. **DO NOT SUBMIT** exp_077 (prob_norm_final) - CV regression + wrong constraint
2. **Revert to exp_030** (best model, CV=0.008298, LB=0.08772)
3. **Try GroupKFold CV** (like mixall kernel) to see if it changes the CV-LB relationship
4. **Submit** to test if this changes the CV-LB relationship
5. **Iterate** based on LB feedback
