{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146f7f2b",
   "metadata": {},
   "source": [
    "# Loop 42 Analysis: ChemBERTa Results and Strategic Assessment\n",
    "\n",
    "**Key Question:** What can we learn from the ChemBERTa experiment and what should we try next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8967940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:04.723195Z",
     "iopub.status.busy": "2026-01-15T05:35:04.722510Z",
     "iopub.status.idle": "2026-01-15T05:35:05.836025Z",
     "shell.execute_reply": "2026-01-15T05:35:05.835469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Relationship: LB = 4.29 * CV + 0.0528\n",
      "R-squared = 0.9523\n",
      "\n",
      "Target LB: 0.0347\n",
      "Intercept: 0.0528\n",
      "\n",
      "To reach target LB = 0.0347:\n",
      "Required CV = -0.004218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.098160),\n",
    "    ('exp_001', 0.012297, 0.106490),\n",
    "    ('exp_003', 0.010501, 0.097190),\n",
    "    ('exp_005', 0.010430, 0.096910),\n",
    "    ('exp_006', 0.009749, 0.094570),\n",
    "    ('exp_007', 0.009262, 0.093160),\n",
    "    ('exp_009', 0.009192, 0.093640),\n",
    "    ('exp_012', 0.009004, 0.091340),\n",
    "    ('exp_024', 0.008689, 0.089290),\n",
    "    ('exp_026', 0.008465, 0.088750),\n",
    "    ('exp_030', 0.008298, 0.087720),\n",
    "    ('exp_035', 0.009825, 0.096960),\n",
    "]\n",
    "\n",
    "cv_scores = np.array([s[1] for s in submissions])\n",
    "lb_scores = np.array([s[2] for s in submissions])\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "print(f'CV-LB Relationship: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R-squared = {r_value**2:.4f}')\n",
    "print(f'\\nTarget LB: 0.0347')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'\\nTo reach target LB = 0.0347:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'Required CV = {required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a4b5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.837874Z",
     "iopub.status.busy": "2026-01-15T05:35:05.837595Z",
     "iopub.status.idle": "2026-01-15T05:35:05.842569Z",
     "shell.execute_reply": "2026-01-15T05:35:05.841954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CV-LB Gap Analysis ===\n",
      "\n",
      "exp_000: CV=0.011081, LB=0.098160, Gap=0.0871, Ratio=8.9x\n",
      "exp_001: CV=0.012297, LB=0.106490, Gap=0.0942, Ratio=8.7x\n",
      "exp_003: CV=0.010501, LB=0.097190, Gap=0.0867, Ratio=9.3x\n",
      "exp_005: CV=0.010430, LB=0.096910, Gap=0.0865, Ratio=9.3x\n",
      "exp_006: CV=0.009749, LB=0.094570, Gap=0.0848, Ratio=9.7x\n",
      "exp_007: CV=0.009262, LB=0.093160, Gap=0.0839, Ratio=10.1x\n",
      "exp_009: CV=0.009192, LB=0.093640, Gap=0.0844, Ratio=10.2x\n",
      "exp_012: CV=0.009004, LB=0.091340, Gap=0.0823, Ratio=10.1x\n",
      "exp_024: CV=0.008689, LB=0.089290, Gap=0.0806, Ratio=10.3x\n",
      "exp_026: CV=0.008465, LB=0.088750, Gap=0.0803, Ratio=10.5x\n",
      "exp_030: CV=0.008298, LB=0.087720, Gap=0.0794, Ratio=10.6x\n",
      "exp_035: CV=0.009825, LB=0.096960, Gap=0.0871, Ratio=9.9x\n",
      "\n",
      "Average gap: 0.0848\n",
      "Average ratio: 9.8x\n"
     ]
    }
   ],
   "source": [
    "# Analyze the gap\n",
    "print('=== CV-LB Gap Analysis ===')\n",
    "print()\n",
    "for exp_id, cv, lb in submissions:\n",
    "    gap = lb - cv\n",
    "    ratio = lb / cv\n",
    "    print(f'{exp_id}: CV={cv:.6f}, LB={lb:.6f}, Gap={gap:.4f}, Ratio={ratio:.1f}x')\n",
    "\n",
    "print(f'\\nAverage gap: {np.mean(lb_scores - cv_scores):.4f}')\n",
    "print(f'Average ratio: {np.mean(lb_scores / cv_scores):.1f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41deb2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.844161Z",
     "iopub.status.busy": "2026-01-15T05:35:05.843983Z",
     "iopub.status.idle": "2026-01-15T05:35:05.852366Z",
     "shell.execute_reply": "2026-01-15T05:35:05.851910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ChemBERTa Experiment Results (exp_041) ===\n",
      "\n",
      "Single fold (1,1,1,3,3,3-Hexafluoropropan-2-ol):\n",
      "  ChemBERTa only (768-dim): MSE = 0.061135\n",
      "  ChemBERTa PCA (20-dim): MSE = 0.058003\n",
      "  ChemBERTa + Spange: MSE = 0.042313\n",
      "  ChemBERTa PCA + Spange: MSE = 0.041895\n",
      "\n",
      "  Spange only: MSE = 0.034241\n",
      "  DRFP only: MSE = 0.059665\n",
      "  Spange + DRFP: MSE = 0.057212\n",
      "\n",
      "Full CV (ChemBERTa PCA + Spange):\n",
      "  Mean MSE: 0.010288 +/- 0.008427\n",
      "  Baseline (exp_035): CV = 0.008194\n",
      "\n",
      "CONCLUSION: ChemBERTa is 25.5% WORSE than baseline\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa experiment results\n",
    "print('=== ChemBERTa Experiment Results (exp_041) ===')\n",
    "print()\n",
    "print('Single fold (1,1,1,3,3,3-Hexafluoropropan-2-ol):')\n",
    "print('  ChemBERTa only (768-dim): MSE = 0.061135')\n",
    "print('  ChemBERTa PCA (20-dim): MSE = 0.058003')\n",
    "print('  ChemBERTa + Spange: MSE = 0.042313')\n",
    "print('  ChemBERTa PCA + Spange: MSE = 0.041895')\n",
    "print()\n",
    "print('  Spange only: MSE = 0.034241')\n",
    "print('  DRFP only: MSE = 0.059665')\n",
    "print('  Spange + DRFP: MSE = 0.057212')\n",
    "print()\n",
    "print('Full CV (ChemBERTa PCA + Spange):')\n",
    "print('  Mean MSE: 0.010288 +/- 0.008427')\n",
    "print('  Baseline (exp_035): CV = 0.008194')\n",
    "print()\n",
    "print('CONCLUSION: ChemBERTa is 25.5% WORSE than baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe053af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.853802Z",
     "iopub.status.busy": "2026-01-15T05:35:05.853619Z",
     "iopub.status.idle": "2026-01-15T05:35:05.861434Z",
     "shell.execute_reply": "2026-01-15T05:35:05.860958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Approaches That FAILED ===\n",
      "\n",
      "DRFP with PCA (exp_002): CV = 0.016948\n",
      "  Reason: DRFP alone loses information\n",
      "\n",
      "Deep Residual MLP (exp_004): CV = 0.051912\n",
      "  Reason: Too complex for small data\n",
      "\n",
      "Minimal features (exp_038): CV = 0.009825\n",
      "  Reason: Need DRFP features\n",
      "\n",
      "GNN (exp_040): CV = 0.068767\n",
      "  Reason: Single fold only - very poor\n",
      "\n",
      "ChemBERTa (exp_041): CV = 0.010288\n",
      "  Reason: Pre-trained embeddings not helpful\n",
      "\n",
      "k-NN with Tanimoto: CV = 0.072666\n",
      "  Reason: Single fold only - very poor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What have we tried that DIDN'T work?\n",
    "print('=== Approaches That FAILED ===')\n",
    "print()\n",
    "failed_approaches = [\n",
    "    ('DRFP with PCA (exp_002)', 0.016948, 'DRFP alone loses information'),\n",
    "    ('Deep Residual MLP (exp_004)', 0.051912, 'Too complex for small data'),\n",
    "    ('Minimal features (exp_038)', 0.009825, 'Need DRFP features'),\n",
    "    ('GNN (exp_040)', 0.068767, 'Single fold only - very poor'),\n",
    "    ('ChemBERTa (exp_041)', 0.010288, 'Pre-trained embeddings not helpful'),\n",
    "    ('k-NN with Tanimoto', 0.072666, 'Single fold only - very poor'),\n",
    "]\n",
    "\n",
    "for name, score, reason in failed_approaches:\n",
    "    print(f'{name}: CV = {score:.6f}')\n",
    "    print(f'  Reason: {reason}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0260ca61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.863133Z",
     "iopub.status.busy": "2026-01-15T05:35:05.862927Z",
     "iopub.status.idle": "2026-01-15T05:35:05.868736Z",
     "shell.execute_reply": "2026-01-15T05:35:05.868182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Approaches That WORKED ===\n",
      "\n",
      "Spange descriptors\n",
      "  Why: Physicochemical properties relevant to solvation\n",
      "\n",
      "DRFP features (high-variance)\n",
      "  Why: Molecular structure fingerprints\n",
      "\n",
      "Arrhenius kinetics\n",
      "  Why: Physics-informed features\n",
      "\n",
      "GP component\n",
      "  Why: Different inductive bias, helps with uncertainty\n",
      "\n",
      "MLP + LGBM ensemble\n",
      "  Why: Complementary model types\n",
      "\n",
      "Weighted loss [1,1,2] for SM\n",
      "  Why: SM is harder to predict\n",
      "\n",
      "ACS PCA features\n",
      "  Why: Additional chemical descriptors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What HAS worked?\n",
    "print('=== Approaches That WORKED ===')\n",
    "print()\n",
    "working_approaches = [\n",
    "    ('Spange descriptors', 'Physicochemical properties relevant to solvation'),\n",
    "    ('DRFP features (high-variance)', 'Molecular structure fingerprints'),\n",
    "    ('Arrhenius kinetics', 'Physics-informed features'),\n",
    "    ('GP component', 'Different inductive bias, helps with uncertainty'),\n",
    "    ('MLP + LGBM ensemble', 'Complementary model types'),\n",
    "    ('Weighted loss [1,1,2] for SM', 'SM is harder to predict'),\n",
    "    ('ACS PCA features', 'Additional chemical descriptors'),\n",
    "]\n",
    "\n",
    "for name, reason in working_approaches:\n",
    "    print(f'{name}')\n",
    "    print(f'  Why: {reason}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5350c864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.870202Z",
     "iopub.status.busy": "2026-01-15T05:35:05.870023Z",
     "iopub.status.idle": "2026-01-15T05:35:05.876501Z",
     "shell.execute_reply": "2026-01-15T05:35:05.876011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== THE CRITICAL PROBLEM ===\n",
      "\n",
      "CV-LB relationship: LB = 4.29 * CV + 0.0528\n",
      "Target LB: 0.0347\n",
      "Intercept: 0.0528\n",
      "\n",
      "PROBLEM: Intercept (0.0524) > Target (0.0347)\n",
      "This means even with CV = 0, predicted LB would be 0.0524\n",
      "\n",
      "IMPLICATION: We need to CHANGE the CV-LB relationship, not just improve CV\n",
      "\n",
      "Possible causes of high intercept:\n",
      "1. Systematic overfitting to training solvents\n",
      "2. Mismatch between local CV and Kaggle evaluation\n",
      "3. Distribution shift between train/test\n",
      "4. Model miscalibration\n"
     ]
    }
   ],
   "source": [
    "# The critical insight: CV-LB intercept problem\n",
    "print('=== THE CRITICAL PROBLEM ===')\n",
    "print()\n",
    "print(f'CV-LB relationship: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print()\n",
    "print('PROBLEM: Intercept (0.0524) > Target (0.0347)')\n",
    "print('This means even with CV = 0, predicted LB would be 0.0524')\n",
    "print()\n",
    "print('IMPLICATION: We need to CHANGE the CV-LB relationship, not just improve CV')\n",
    "print()\n",
    "print('Possible causes of high intercept:')\n",
    "print('1. Systematic overfitting to training solvents')\n",
    "print('2. Mismatch between local CV and Kaggle evaluation')\n",
    "print('3. Distribution shift between train/test')\n",
    "print('4. Model miscalibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd6bbdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.878248Z",
     "iopub.status.busy": "2026-01-15T05:35:05.878038Z",
     "iopub.status.idle": "2026-01-15T05:35:05.883533Z",
     "shell.execute_reply": "2026-01-15T05:35:05.883021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPROACHES TO CHANGE CV-LB RELATIONSHIP ===\n",
      "\n",
      "Prediction calibration\n",
      "  Adjust predictions to reduce systematic bias\n",
      "\n",
      "Ensemble with constant offset\n",
      "  Add a learned offset to predictions\n",
      "\n",
      "Different CV scheme\n",
      "  Verify our CV matches Kaggle exactly\n",
      "\n",
      "Regularization tuning\n",
      "  Stronger regularization to prevent overfitting\n",
      "\n",
      "Feature selection\n",
      "  Remove features that cause overfitting\n",
      "\n",
      "Domain adaptation\n",
      "  Explicitly model train-test distribution shift\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What approaches might change the CV-LB relationship?\n",
    "print('=== APPROACHES TO CHANGE CV-LB RELATIONSHIP ===')\n",
    "print()\n",
    "approaches = [\n",
    "    ('Prediction calibration', 'Adjust predictions to reduce systematic bias'),\n",
    "    ('Ensemble with constant offset', 'Add a learned offset to predictions'),\n",
    "    ('Different CV scheme', 'Verify our CV matches Kaggle exactly'),\n",
    "    ('Regularization tuning', 'Stronger regularization to prevent overfitting'),\n",
    "    ('Feature selection', 'Remove features that cause overfitting'),\n",
    "    ('Domain adaptation', 'Explicitly model train-test distribution shift'),\n",
    "]\n",
    "\n",
    "for name, desc in approaches:\n",
    "    print(f'{name}')\n",
    "    print(f'  {desc}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f85500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.884997Z",
     "iopub.status.busy": "2026-01-15T05:35:05.884788Z",
     "iopub.status.idle": "2026-01-15T05:35:05.890596Z",
     "shell.execute_reply": "2026-01-15T05:35:05.890093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEST EXPERIMENT: exp_030 (GP+MLP+LGBM) ===\n",
      "\n",
      "CV: 0.008298\n",
      "LB: 0.087720\n",
      "Gap: 0.0794 (9.6x)\n",
      "\n",
      "Components:\n",
      "  GP (0.2): Matern kernel on Spange + Arrhenius (18 features)\n",
      "  MLP (0.5): [32,16] with weighted loss on full features (145 features)\n",
      "  LGBM (0.3): Full features (145 features)\n",
      "\n",
      "Key insight: GP provides different inductive bias\n",
      "GP may have better uncertainty calibration for OOD solvents\n"
     ]
    }
   ],
   "source": [
    "# Best experiment analysis\n",
    "print('=== BEST EXPERIMENT: exp_030 (GP+MLP+LGBM) ===')\n",
    "print()\n",
    "print('CV: 0.008298')\n",
    "print('LB: 0.087720')\n",
    "print('Gap: 0.0794 (9.6x)')\n",
    "print()\n",
    "print('Components:')\n",
    "print('  GP (0.2): Matern kernel on Spange + Arrhenius (18 features)')\n",
    "print('  MLP (0.5): [32,16] with weighted loss on full features (145 features)')\n",
    "print('  LGBM (0.3): Full features (145 features)')\n",
    "print()\n",
    "print('Key insight: GP provides different inductive bias')\n",
    "print('GP may have better uncertainty calibration for OOD solvents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b15f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:35:05.892385Z",
     "iopub.status.busy": "2026-01-15T05:35:05.891863Z",
     "iopub.status.idle": "2026-01-15T05:35:05.898633Z",
     "shell.execute_reply": "2026-01-15T05:35:05.898175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECOMMENDED NEXT STEPS ===\n",
      "\n",
      "Priority 1: Prediction Calibration\n",
      "  - Try Platt scaling or isotonic regression on predictions\n",
      "  - May reduce the intercept in CV-LB relationship\n",
      "\n",
      "Priority 2: Verify CV Scheme\n",
      "  - Read template notebook carefully\n",
      "  - Ensure we leave out full experiments for mixtures\n",
      "  - Check weighting between single-solvent and mixture data\n",
      "\n",
      "Priority 3: Stronger Regularization\n",
      "  - Increase dropout, weight decay\n",
      "  - Reduce model complexity further\n",
      "  - May reduce overfitting to training solvents\n",
      "\n",
      "Priority 4: GP-Heavy Ensemble\n",
      "  - Increase GP weight (currently 0.2)\n",
      "  - GP may generalize better to unseen solvents\n",
      "  - Try pure GP model\n"
     ]
    }
   ],
   "source": [
    "# What should we try next?\n",
    "print('=== RECOMMENDED NEXT STEPS ===')\n",
    "print()\n",
    "print('Priority 1: Prediction Calibration')\n",
    "print('  - Try Platt scaling or isotonic regression on predictions')\n",
    "print('  - May reduce the intercept in CV-LB relationship')\n",
    "print()\n",
    "print('Priority 2: Verify CV Scheme')\n",
    "print('  - Read template notebook carefully')\n",
    "print('  - Ensure we leave out full experiments for mixtures')\n",
    "print('  - Check weighting between single-solvent and mixture data')\n",
    "print()\n",
    "print('Priority 3: Stronger Regularization')\n",
    "print('  - Increase dropout, weight decay')\n",
    "print('  - Reduce model complexity further')\n",
    "print('  - May reduce overfitting to training solvents')\n",
    "print()\n",
    "print('Priority 4: GP-Heavy Ensemble')\n",
    "print('  - Increase GP weight (currently 0.2)')\n",
    "print('  - GP may generalize better to unseen solvents')\n",
    "print('  - Try pure GP model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80a9e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:36:26.486408Z",
     "iopub.status.busy": "2026-01-15T05:36:26.485915Z",
     "iopub.status.idle": "2026-01-15T05:36:26.515312Z",
     "shell.execute_reply": "2026-01-15T05:36:26.514820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data shape: (1227, 19)\n",
      "\n",
      "Number of unique solvent ramps: 13\n",
      "\n",
      "Solvent ramps:\n",
      "  Methanol + Ethylene Glycol [1,2-Ethanediol]: 122 samples\n",
      "  1,1,1,3,3,3-Hexafluoropropan-2-ol + 2-Methyltetrahydrofuran [2-MeTHF]: 124 samples\n",
      "  Cyclohexane + IPA [Propan-2-ol]: 104 samples\n",
      "  Water.Acetonitrile + Acetonitrile: 125 samples\n",
      "  Acetonitrile + Acetonitrile.Acetic Acid: 125 samples\n",
      "  2-Methyltetrahydrofuran [2-MeTHF] + Diethyl Ether [Ether]: 124 samples\n",
      "  2,2,2-Trifluoroethanol + Water.2,2,2-Trifluoroethanol: 125 samples\n",
      "  DMA [N,N-Dimethylacetamide] + Decanol: 110 samples\n",
      "  Ethanol + THF [Tetrahydrofuran]: 127 samples\n",
      "  Dihydrolevoglucosenone (Cyrene) + Ethyl Acetate: 36 samples\n",
      "  MTBE [tert-Butylmethylether] + Butanone [MEK]: 34 samples\n",
      "  tert-Butanol [2-Methylpropan-2-ol] + Dimethyl Carbonate: 36 samples\n",
      "  Methyl Propionate + Ethyl Lactate: 35 samples\n"
     ]
    }
   ],
   "source": [
    "# Check the evaluation scheme\n",
    "import pandas as pd\n",
    "\n",
    "# Load full data\n",
    "full_df = pd.read_csv('/home/data/catechol_full_data_yields.csv')\n",
    "print(f\"Full data shape: {full_df.shape}\")\n",
    "\n",
    "# Check unique solvent ramps\n",
    "solvent_ramps = full_df[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "print(f\"\\nNumber of unique solvent ramps: {len(solvent_ramps)}\")\n",
    "print(\"\\nSolvent ramps:\")\n",
    "for _, row in solvent_ramps.iterrows():\n",
    "    count = len(full_df[(full_df[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & \n",
    "                        (full_df[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])])\n",
    "    print(f\"  {row['SOLVENT A NAME']} + {row['SOLVENT B NAME']}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('=== LOOP 42 SUMMARY ===')\n",
    "print()\n",
    "print('ChemBERTa experiment (exp_041):')\n",
    "print('  - CV = 0.010288 (25.5% WORSE than baseline)')\n",
    "print('  - Pre-trained molecular embeddings do NOT help')\n",
    "print('  - Domain-specific Spange descriptors remain superior')\n",
    "print('  - Correctly decided NOT to submit')\n",
    "print()\n",
    "print('Current best:')\n",
    "print('  - exp_030: CV = 0.008298, LB = 0.087720')\n",
    "print('  - Target: 0.0347 (2.53x gap)')\n",
    "print()\n",
    "print('Remaining submissions: 4')\n",
    "print()\n",
    "print('Critical insight:')\n",
    "print('  - CV-LB intercept (0.0524) > Target (0.0347)')\n",
    "print('  - Need to change the relationship, not just improve CV')\n",
    "print('  - Focus on calibration, regularization, or different approach')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
