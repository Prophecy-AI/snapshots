{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8535d3ff",
   "metadata": {},
   "source": [
    "# Loop 86 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Situation\n",
    "- Best CV: 0.0081 (exp_049/exp_053)\n",
    "- Best LB: 0.0877 (exp_030, exp_067)\n",
    "- Target: 0.0347\n",
    "- Gap: 152.7% above target\n",
    "- Remaining submissions: 4\n",
    "\n",
    "## Critical Insight\n",
    "The CV-LB relationship is LB = 4.36*CV + 0.052 (R²=0.956)\n",
    "- Intercept (0.052) > Target (0.0347)\n",
    "- This means NO amount of CV optimization can reach the target\n",
    "\n",
    "## Analysis Goals\n",
    "1. Verify the CV-LB relationship with all 13 submissions\n",
    "2. Identify if any approach breaks the pattern\n",
    "3. Develop new strategy to reduce the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_067', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions with LB: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b55d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)')\n",
    "print(f'Required CV to hit target: ({0.0347} - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.4f}')\n",
    "print('This is NEGATIVE - mathematically impossible!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.015)\n",
    "plt.ylim(0, 0.12)\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop86.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlot saved to /home/code/exploration/cv_lb_relationship_loop86.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3308b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - are any approaches breaking the pattern?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('=== Residual Analysis ===')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].to_string())\n",
    "\n",
    "print(f'\\nMean residual: {df[\"residual\"].mean():.6f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.6f}')\n",
    "print(f'Max positive residual: {df[\"residual\"].max():.6f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')\n",
    "print(f'Max negative residual: {df[\"residual\"].min():.6f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abf072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print('\\n=== What Would It Take to Reach Target? ===')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'Current best LB: 0.0877')\n",
    "print(f'Gap: {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347) / 0.0347 * 100:.1f}% above target)')\n",
    "\n",
    "print('\\n--- Option 1: Improve CV (keeping same relationship) ---')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'Required CV: {required_cv:.4f}')\n",
    "print('This is NEGATIVE - impossible!')\n",
    "\n",
    "print('\\n--- Option 2: Reduce intercept (keeping same slope) ---')\n",
    "required_intercept = 0.0347 - slope * 0.008  # Assuming best CV of 0.008\n",
    "print(f'Required intercept: {required_intercept:.4f}')\n",
    "print(f'Current intercept: {intercept:.4f}')\n",
    "print(f'Need to reduce intercept by: {intercept - required_intercept:.4f}')\n",
    "\n",
    "print('\\n--- Option 3: Change the slope ---')\n",
    "required_slope = (0.0347 - intercept) / 0.008  # Assuming best CV of 0.008\n",
    "print(f'Required slope: {required_slope:.4f}')\n",
    "print(f'Current slope: {slope:.4f}')\n",
    "print('This would require NEGATIVE slope - impossible!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3897340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The ONLY way to reach target is to REDUCE THE INTERCEPT\n",
    "print('\\n' + '='*60)\n",
    "print('CRITICAL INSIGHT')\n",
    "print('='*60)\n",
    "print(f'''\n",
    "The ONLY way to reach the target (0.0347) is to REDUCE THE INTERCEPT.\n",
    "\n",
    "Current situation:\n",
    "- Intercept: {intercept:.4f}\n",
    "- Target: 0.0347\n",
    "- Gap: {intercept - 0.0347:.4f}\n",
    "\n",
    "The intercept represents STRUCTURAL DISTRIBUTION SHIFT:\n",
    "- It's the LB score you'd get even with perfect CV (CV=0)\n",
    "- It measures how different the test solvents are from training solvents\n",
    "- No amount of model tuning can reduce it\n",
    "\n",
    "To reduce the intercept, we need approaches that:\n",
    "1. Generalize better to unseen solvents (not just fit training data better)\n",
    "2. Use domain knowledge that holds for ALL solvents\n",
    "3. Are conservative when extrapolating (blend toward mean)\n",
    "4. Use uncertainty quantification to detect extrapolation\n",
    "\n",
    "What WON'T work:\n",
    "- Improving CV through better model tuning\n",
    "- Trying different model architectures (all fall on same line)\n",
    "- Feature engineering that only helps training data\n",
    "''')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print('\\n=== Approaches Tried (from session_state.json) ===')\n",
    "approaches = [\n",
    "    ('MLP baseline', 'exp_000', 0.0111, 0.0982),\n",
    "    ('LightGBM', 'exp_001', 0.0123, 0.1065),\n",
    "    ('Combined features', 'exp_003', 0.0105, 0.0972),\n",
    "    ('Large ensemble', 'exp_005', 0.0104, 0.0969),\n",
    "    ('Simpler model', 'exp_006', 0.0097, 0.0946),\n",
    "    ('Even simpler', 'exp_007', 0.0093, 0.0932),\n",
    "    ('Ridge regression', 'exp_009', 0.0092, 0.0936),\n",
    "    ('Simple ensemble', 'exp_012', 0.0090, 0.0913),\n",
    "    ('Per-target', 'exp_024', 0.0087, 0.0893),\n",
    "    ('Weighted loss', 'exp_026', 0.0085, 0.0887),\n",
    "    ('GP ensemble', 'exp_030', 0.0083, 0.0877),\n",
    "    ('Lower GP weight', 'exp_035', 0.0098, 0.0970),\n",
    "    ('Sigmoid output', 'exp_067', 0.0083, 0.0877),\n",
    "]\n",
    "\n",
    "print('All approaches fall on the SAME CV-LB line!')\n",
    "print('This means the distribution shift is STRUCTURAL, not model-dependent.')\n",
    "print('\\nModel types tried: MLP, LightGBM, Ridge, GP, CatBoost, XGBoost')\n",
    "print('All have the same CV-LB relationship.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851341e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches might change the intercept?\n",
    "print('\\n=== Approaches That MIGHT Change the Intercept ===')\n",
    "print('''\n",
    "1. EXTRAPOLATION DETECTION + CONSERVATIVE BLENDING\n",
    "   - Detect when test solvent is dissimilar to all training solvents\n",
    "   - Blend predictions toward population mean for dissimilar solvents\n",
    "   - Tried in exp_082 (similarity weighting) but CV was worse\n",
    "   - Need to try with LESS aggressive blending\n",
    "\n",
    "2. PHYSICS-INFORMED CONSTRAINTS\n",
    "   - Arrhenius kinetics: k = A * exp(-Ea/RT)\n",
    "   - Yields should follow certain patterns with temperature/time\n",
    "   - Enforce monotonicity constraints that hold for ALL solvents\n",
    "   - NOT tried yet in a principled way\n",
    "\n",
    "3. SOLVENT CHEMICAL CLASS FEATURES\n",
    "   - Group solvents by chemical class (alcohols, ethers, esters, etc.)\n",
    "   - Add class-level features that generalize within families\n",
    "   - Different from clustering - it's about adding informative features\n",
    "   - NOT tried yet\n",
    "\n",
    "4. UNCERTAINTY-WEIGHTED PREDICTIONS\n",
    "   - Use GP or ensemble variance to estimate uncertainty\n",
    "   - When uncertainty is high, make more conservative predictions\n",
    "   - Tried in exp_048, exp_068-071 but not optimized\n",
    "   - Need to try with better calibration\n",
    "\n",
    "5. PSEUDO-LABELING / DOMAIN ADAPTATION\n",
    "   - Use confident test predictions to augment training\n",
    "   - Adapt model to test distribution\n",
    "   - NOT tried yet\n",
    "''')\n",
    "\n",
    "print('\\n=== RECOMMENDED NEXT STEPS ===')\n",
    "print('''\n",
    "1. DO NOT SUBMIT exp_082 (CV is 78% worse than best)\n",
    "2. Try physics-informed constraints (Arrhenius, monotonicity)\n",
    "3. Try solvent chemical class features\n",
    "4. Try pseudo-labeling / domain adaptation\n",
    "5. Save submissions for fundamentally different approaches\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
