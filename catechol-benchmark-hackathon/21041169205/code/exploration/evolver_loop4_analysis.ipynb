{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8177e28b",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: CV-LB Gap Investigation\n",
    "\n",
    "The evaluator correctly identified that we need to validate exp_003 (Combined Spange + DRFP) on LB.\n",
    "\n",
    "## Key Questions:\n",
    "1. Why is there a 9x gap between CV and LB?\n",
    "2. What can we learn from the submission history?\n",
    "3. What should we try next if LB doesn't improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ff3ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:30:10.209139Z",
     "iopub.status.busy": "2026-01-08T03:30:10.208378Z",
     "iopub.status.idle": "2026-01-08T03:30:10.647659Z",
     "shell.execute_reply": "2026-01-08T03:30:10.647061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History Analysis:\n",
      "    exp                model     cv     lb  cv_lb_ratio  cv_lb_gap\n",
      "exp_000 MLP Spange+Arrhenius 0.0111 0.0982     8.846847     0.0871\n",
      "exp_001             LightGBM 0.0123 0.1065     8.658537     0.0942\n",
      "\n",
      "Average CV-LB ratio: 8.75x\n",
      "Average CV-LB gap: 0.0906\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Analyze submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'model': 'MLP Spange+Arrhenius', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'model': 'LightGBM', 'cv': 0.0123, 'lb': 0.1065},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['cv_lb_ratio'] = df['lb'] / df['cv']\n",
    "df['cv_lb_gap'] = df['lb'] - df['cv']\n",
    "print('Submission History Analysis:')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nAverage CV-LB ratio: {df[\"cv_lb_ratio\"].mean():.2f}x')\n",
    "print(f'Average CV-LB gap: {df[\"cv_lb_gap\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad3088a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:30:10.649560Z",
     "iopub.status.busy": "2026-01-08T03:30:10.649247Z",
     "iopub.status.idle": "2026-01-08T03:30:10.653962Z",
     "shell.execute_reply": "2026-01-08T03:30:10.653411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_003 CV: 0.010501\n",
      "Predicted LB (using avg ratio 8.75x): 0.0919\n",
      "\n",
      "Target: 0.0333\n",
      "Current best LB: 0.0982\n",
      "\n",
      "If CV-LB ratio holds:\n",
      "  - exp_003 would have LB ~0.0919\n",
      "  - This is still ~2.8x worse than target\n"
     ]
    }
   ],
   "source": [
    "# If the CV-LB ratio holds, what would exp_003 LB be?\n",
    "exp003_cv = 0.010501\n",
    "avg_ratio = df['cv_lb_ratio'].mean()\n",
    "predicted_lb = exp003_cv * avg_ratio\n",
    "\n",
    "print(f'exp_003 CV: {exp003_cv:.6f}')\n",
    "print(f'Predicted LB (using avg ratio {avg_ratio:.2f}x): {predicted_lb:.4f}')\n",
    "print(f'\\nTarget: 0.0333')\n",
    "print(f'Current best LB: 0.0982')\n",
    "print(f'\\nIf CV-LB ratio holds:')\n",
    "print(f'  - exp_003 would have LB ~{predicted_lb:.4f}')\n",
    "print(f'  - This is still ~{predicted_lb/0.0333:.1f}x worse than target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997cd390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:30:10.655856Z",
     "iopub.status.busy": "2026-01-08T03:30:10.655352Z",
     "iopub.status.idle": "2026-01-08T03:30:10.662880Z",
     "shell.execute_reply": "2026-01-08T03:30:10.662341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To beat target 0.0333:\n",
      "  - With avg ratio 8.75x, we need CV < 0.003805\n",
      "  - Current best CV: 0.010501\n",
      "  - Gap to close: 0.006696\n",
      "\n",
      "This suggests we need ~2.8x improvement in CV\n"
     ]
    }
   ],
   "source": [
    "# What CV would we need to beat the target?\n",
    "target = 0.0333\n",
    "required_cv = target / avg_ratio\n",
    "print(f'To beat target {target}:')\n",
    "print(f'  - With avg ratio {avg_ratio:.2f}x, we need CV < {required_cv:.6f}')\n",
    "print(f'  - Current best CV: {exp003_cv:.6f}')\n",
    "print(f'  - Gap to close: {exp003_cv - required_cv:.6f}')\n",
    "print(f'\\nThis suggests we need ~{exp003_cv/required_cv:.1f}x improvement in CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c36244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:30:10.664432Z",
     "iopub.status.busy": "2026-01-08T03:30:10.664230Z",
     "iopub.status.idle": "2026-01-08T03:30:10.670442Z",
     "shell.execute_reply": "2026-01-08T03:30:10.669944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competition Evaluation Structure:\n",
      "==================================================\n",
      "The competition runs the notebook on Kaggle servers.\n",
      "This means:\n",
      "1. Different random seeds/environment\n",
      "2. The CV score IS the LB score (no separate test set)\n",
      "3. The 9x gap is due to model variance, not data shift\n",
      "\n",
      "Key insight: The LB score IS a CV score, just with different randomness.\n",
      "Our local CV is optimistic because we use fixed seeds.\n",
      "\n",
      "Implications:\n",
      "- Reducing model variance is critical\n",
      "- More bagging/ensembling should help\n",
      "- Deterministic models should have lower gap (but LightGBM was worse)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the competition structure\n",
    "print('Competition Evaluation Structure:')\n",
    "print('='*50)\n",
    "print('The competition runs the notebook on Kaggle servers.')\n",
    "print('This means:')\n",
    "print('1. Different random seeds/environment')\n",
    "print('2. The CV score IS the LB score (no separate test set)')\n",
    "print('3. The 9x gap is due to model variance, not data shift')\n",
    "print()\n",
    "print('Key insight: The LB score IS a CV score, just with different randomness.')\n",
    "print('Our local CV is optimistic because we use fixed seeds.')\n",
    "print()\n",
    "print('Implications:')\n",
    "print('- Reducing model variance is critical')\n",
    "print('- More bagging/ensembling should help')\n",
    "print('- Deterministic models should have lower gap (but LightGBM was worse)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06d8253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:30:10.671949Z",
     "iopub.status.busy": "2026-01-08T03:30:10.671762Z",
     "iopub.status.idle": "2026-01-08T03:30:10.678169Z",
     "shell.execute_reply": "2026-01-08T03:30:10.677672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaches NOT yet tried:\n",
      "==================================================\n",
      "1. More aggressive ensembling (10+ models instead of 5)\n",
      "2. Different architectures (deeper/wider networks)\n",
      "3. Different loss functions (MSE vs Huber)\n",
      "4. Learning rate schedules (cosine annealing)\n",
      "5. Task-specific models (different features for single vs mixture)\n",
      "6. Fragprints features (2133 features available)\n",
      "7. ACS PCA descriptors (5 features available)\n",
      "8. Gaussian Process models (uncertainty quantification)\n",
      "\n",
      "Evaluator recommendation: Submit exp_003 first to validate CV improvement\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('Approaches NOT yet tried:')\n",
    "print('='*50)\n",
    "print('1. More aggressive ensembling (10+ models instead of 5)')\n",
    "print('2. Different architectures (deeper/wider networks)')\n",
    "print('3. Different loss functions (MSE vs Huber)')\n",
    "print('4. Learning rate schedules (cosine annealing)')\n",
    "print('5. Task-specific models (different features for single vs mixture)')\n",
    "print('6. Fragprints features (2133 features available)')\n",
    "print('7. ACS PCA descriptors (5 features available)')\n",
    "print('8. Gaussian Process models (uncertainty quantification)')\n",
    "print()\n",
    "print('Evaluator recommendation: Submit exp_003 first to validate CV improvement')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
