{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d2bc29",
   "metadata": {},
   "source": [
    "# Loop 51 Analysis: CV-LB Relationship and Intercept Problem\n",
    "\n",
    "**Goal:** Analyze the CV-LB relationship to understand why the intercept (0.0528) is higher than the target (0.0347).\n",
    "\n",
    "**Key Questions:**\n",
    "1. Is the CV-LB relationship truly linear?\n",
    "2. What causes the intercept?\n",
    "3. Can we identify strategies to reduce the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Number of submissions: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4806e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f\"Linear Regression: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"p-value = {p_value:.6f}\")\n",
    "print(f\"Standard error = {std_err:.4f}\")\n",
    "print()\n",
    "print(f\"CRITICAL INSIGHT:\")\n",
    "print(f\"  Intercept = {intercept:.4f}\")\n",
    "print(f\"  Target = 0.0347\")\n",
    "print(f\"  Intercept > Target? {intercept > 0.0347}\")\n",
    "print()\n",
    "print(f\"To reach target 0.0347:\")\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f\"  Required CV = (0.0347 - {intercept:.4f}) / {slope:.4f} = {required_cv:.6f}\")\n",
    "print(f\"  This is {'IMPOSSIBLE (negative)' if required_cv < 0 else 'POSSIBLE'}\")\n",
    "print()\n",
    "print(f\"Current best CV: 0.0081 (exp_050)\")\n",
    "predicted_lb = slope * 0.0081 + intercept\n",
    "print(f\"Predicted LB for CV=0.0081: {predicted_lb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec180028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df['cv'], df['lb'], s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r-', linewidth=2, label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle='--', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "# Current best CV\n",
    "plt.axvline(x=0.0081, color='purple', linestyle='-.', linewidth=1, label='Best CV (0.0081)')\n",
    "\n",
    "plt.xlabel('Cross-Validation MSE', fontsize=12)\n",
    "plt.ylabel('Leaderboard MSE', fontsize=12)\n",
    "plt.title('CV-LB Relationship Analysis', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 0.015)\n",
    "plt.ylim(0, 0.12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKEY OBSERVATION:\")\n",
    "print(f\"The intercept ({intercept:.4f}) is HIGHER than the target (0.0347).\")\n",
    "print(f\"This means even with CV=0 (perfect training), LB would be ~{intercept:.4f}.\")\n",
    "print(f\"The target is BELOW the intercept - unreachable with current approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals to check if the relationship is truly linear\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print(\"Residual Analysis:\")\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "print()\n",
    "print(f\"Mean residual: {df['residual'].mean():.6f}\")\n",
    "print(f\"Std residual: {df['residual'].std():.6f}\")\n",
    "print(f\"Max residual: {df['residual'].max():.6f}\")\n",
    "print(f\"Min residual: {df['residual'].min():.6f}\")\n",
    "\n",
    "# Check for outliers\n",
    "print(\"\\nOutliers (|residual| > 2*std):\")\n",
    "outliers = df[np.abs(df['residual']) > 2 * df['residual'].std()]\n",
    "if len(outliers) > 0:\n",
    "    print(outliers[['exp', 'cv', 'lb', 'residual']])\n",
    "else:\n",
    "    print(\"No outliers detected - relationship is very linear.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach the target?\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIES TO REACH TARGET 0.0347\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Option 1: Improve CV (current approach)\n",
    "print(\"OPTION 1: Improve CV (current approach)\")\n",
    "print(f\"  Current best CV: 0.0081\")\n",
    "print(f\"  Required CV to reach target: {required_cv:.6f}\")\n",
    "print(f\"  This is {'IMPOSSIBLE' if required_cv < 0 else 'POSSIBLE'}\")\n",
    "print()\n",
    "\n",
    "# Option 2: Reduce the intercept\n",
    "print(\"OPTION 2: Reduce the intercept\")\n",
    "print(f\"  Current intercept: {intercept:.4f}\")\n",
    "print(f\"  Target: 0.0347\")\n",
    "print(f\"  Required intercept reduction: {intercept - 0.0347:.4f}\")\n",
    "print(f\"  This requires fundamentally different strategies that change the CV-LB relationship.\")\n",
    "print()\n",
    "\n",
    "# Option 3: Change the slope\n",
    "print(\"OPTION 3: Change the slope\")\n",
    "print(f\"  Current slope: {slope:.4f}\")\n",
    "print(f\"  If intercept stays at {intercept:.4f}, required slope to reach target with CV=0.0081:\")\n",
    "required_slope = (0.0347 - intercept) / 0.0081\n",
    "print(f\"  Required slope = (0.0347 - {intercept:.4f}) / 0.0081 = {required_slope:.4f}\")\n",
    "print(f\"  This is {'IMPOSSIBLE (negative slope)' if required_slope < 0 else 'POSSIBLE'}\")\n",
    "print()\n",
    "\n",
    "# Option 4: Combined approach\n",
    "print(\"OPTION 4: Combined approach (reduce intercept AND improve CV)\")\n",
    "print(f\"  If we can reduce intercept to 0.03 and improve CV to 0.005:\")\n",
    "new_lb = slope * 0.005 + 0.03\n",
    "print(f\"  Predicted LB = {slope:.4f} * 0.005 + 0.03 = {new_lb:.4f}\")\n",
    "print(f\"  This would {'beat' if new_lb < 0.0347 else 'NOT beat'} the target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what causes the intercept\n",
    "print(\"=\"*60)\n",
    "print(\"WHAT CAUSES THE INTERCEPT?\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"The intercept represents the STRUCTURAL distribution shift between\")\n",
    "print(\"training and test data. Possible causes:\")\n",
    "print()\n",
    "print(\"1. TEST SOLVENTS ARE HARDER\")\n",
    "print(\"   - Test solvents may have more extreme properties\")\n",
    "print(\"   - Test solvents may be in different chemical classes\")\n",
    "print(\"   - The model extrapolates poorly to these solvents\")\n",
    "print()\n",
    "print(\"2. MIXTURE EFFECTS ARE DIFFERENT\")\n",
    "print(\"   - Test mixtures may have non-linear interactions\")\n",
    "print(\"   - The linear mixing assumption breaks down\")\n",
    "print()\n",
    "print(\"3. EVALUATION METHODOLOGY\")\n",
    "print(\"   - The competition may use a different evaluation scheme\")\n",
    "print(\"   - There may be hidden test data with different characteristics\")\n",
    "print()\n",
    "print(\"4. MODEL BIAS\")\n",
    "print(\"   - All models have a systematic bias in the same direction\")\n",
    "print(\"   - This suggests a fundamental limitation of the approach\")\n",
    "print()\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"The fact that ALL model types (MLP, LGBM, XGB, GP, CatBoost) fall on\")\n",
    "print(\"the same CV-LB line suggests the problem is NOT the model architecture.\")\n",
    "print(\"The problem is the FEATURES or the PREDICTION STRATEGY.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0193094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What strategies could change the intercept?\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIES TO CHANGE THE INTERCEPT\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"1. EXTRAPOLATION DETECTION\")\n",
    "print(\"   - Add features measuring distance to training distribution\")\n",
    "print(\"   - When extrapolating, blend predictions toward population mean\")\n",
    "print(\"   - This could reduce error on 'hard' test solvents\")\n",
    "print()\n",
    "print(\"2. UNCERTAINTY-WEIGHTED PREDICTIONS\")\n",
    "print(\"   - Use GP or ensemble variance as uncertainty estimate\")\n",
    "print(\"   - High uncertainty → conservative prediction (closer to mean)\")\n",
    "print(\"   - This could reduce extreme errors\")\n",
    "print()\n",
    "print(\"3. DOMAIN-SPECIFIC CONSTRAINTS\")\n",
    "print(\"   - Physics-based constraints that hold for unseen solvents\")\n",
    "print(\"   - Arrhenius kinetics, solvent polarity effects\")\n",
    "print(\"   - These constraints generalize better than learned patterns\")\n",
    "print()\n",
    "print(\"4. SOLVENT CLUSTERING\")\n",
    "print(\"   - Group solvents by chemical class\")\n",
    "print(\"   - Use class-specific models\")\n",
    "print(\"   - Detect when test solvent is in a known vs novel class\")\n",
    "print()\n",
    "print(\"5. PSEUDO-LABELING\")\n",
    "print(\"   - Use confident test predictions to augment training\")\n",
    "print(\"   - This adapts the model to the test distribution\")\n",
    "print()\n",
    "print(\"6. IMPORTANCE WEIGHTING (IWCV)\")\n",
    "print(\"   - Reweight training examples based on similarity to test\")\n",
    "print(\"   - This makes CV more representative of LB\")\n",
    "print()\n",
    "print(\"7. STUDY TOP PUBLIC KERNELS\")\n",
    "print(\"   - Top scorers have solved this problem\")\n",
    "print(\"   - Adapt what works, don't reinvent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the top public kernels achieved\n",
    "print(\"=\"*60)\n",
    "print(\"TOP PUBLIC KERNEL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"From our research:\")\n",
    "print(\"- lishellliang/mixall: Uses GroupKFold (5 splits) instead of Leave-One-Out\")\n",
    "print(\"- ens-model kernel: CatBoost + XGBoost ensemble (we implemented this in exp_050)\")\n",
    "print()\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"The top kernels may use a DIFFERENT CV scheme that has a different\")\n",
    "print(\"CV-LB relationship. GroupKFold (5 splits) may have a lower intercept\")\n",
    "print(\"because it's a harder local validation task.\")\n",
    "print()\n",
    "print(\"HYPOTHESIS:\")\n",
    "print(\"If we use GroupKFold (5 splits) instead of Leave-One-Out (24 folds),\")\n",
    "print(\"our local CV will be HIGHER (worse), but the CV-LB relationship\")\n",
    "print(\"may have a LOWER intercept, making the target reachable.\")\n",
    "print()\n",
    "print(\"This is worth testing!\")\n",
    "print()\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"1. Submit exp_050 to verify the CV-LB relationship holds\")\n",
    "print(\"2. If LB ≈ 0.0875 (as predicted), the intercept problem is confirmed\")\n",
    "print(\"3. Try GroupKFold (5 splits) to see if it changes the CV-LB relationship\")\n",
    "print(\"4. Try extrapolation detection and uncertainty weighting\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
