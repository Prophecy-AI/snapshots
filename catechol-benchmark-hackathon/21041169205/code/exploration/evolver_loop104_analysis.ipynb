{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb08e50",
   "metadata": {},
   "source": [
    "# Loop 104 Analysis: CV-LB Gap and Strategy Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the exact CV-LB relationship?\n",
    "2. What approaches have we NOT tried?\n",
    "3. What do top kernels do differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ce4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "    {'exp': 'exp_067', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print(f'\\n=== CV-LB Relationship ===')\n",
    "print(f'Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'Intercept = {intercept:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print(f'\\nIntercept ({intercept:.4f}) vs Target (0.0347):')\n",
    "if intercept > 0.0347:\n",
    "    print(f'  CRITICAL: Intercept > Target!')\n",
    "    print(f'  Even at CV=0, expected LB = {intercept:.4f} > 0.0347')\n",
    "    print(f'  Required CV to hit target: ({0.0347} - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}')\n",
    "    print(f'  This is NEGATIVE - mathematically impossible with current approach!')\n",
    "else:\n",
    "    print(f'  Target is achievable with CV = ({0.0347} - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], c='blue', s=100, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle='-', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop104.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGap between intercept and target: {intercept - 0.0347:.4f}')\n",
    "print(f'This gap represents the STRUCTURAL distribution shift that no model tuning can fix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d9c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have we tried?\n",
    "approaches_tried = [\n",
    "    'MLP (various architectures)',\n",
    "    'LightGBM',\n",
    "    'XGBoost',\n",
    "    'CatBoost',\n",
    "    'Gaussian Process',\n",
    "    'Ridge Regression',\n",
    "    'HistGradientBoosting',\n",
    "    'ExtraTreesRegressor',\n",
    "    'RandomForest',\n",
    "    'Ensemble (GP+MLP+LGBM) - BEST',\n",
    "    'Ensemble (CatBoost+XGBoost)',\n",
    "    'Per-target models',\n",
    "    'Conservative blending',\n",
    "    'Uncertainty-weighted predictions',\n",
    "    'Nonlinear mixture features',\n",
    "    'Various feature sets (Spange, ACS_PCA, DRFP, FragPrints)',\n",
    "]\n",
    "\n",
    "print('=== Approaches Tried ===')\n",
    "for i, approach in enumerate(approaches_tried, 1):\n",
    "    print(f'{i}. {approach}')\n",
    "\n",
    "print('\\n=== What We Have NOT Tried ===')\n",
    "not_tried = [\n",
    "    '1. EXACT replication of ens-model kernel (correlation filtering + feature priority)',\n",
    "    '2. Prediction clipping + renormalization (mass balance constraint)',\n",
    "    '3. Different ensemble weights for single vs full data',\n",
    "    '4. Solvent clustering by chemical class',\n",
    "    '5. Test-time adaptation / pseudo-labeling',\n",
    "    '6. Adversarial validation to detect distribution shift',\n",
    "]\n",
    "for item in not_tried:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the ens-model kernel approach\n",
    "print('=== ENS-MODEL KERNEL KEY TECHNIQUES ===')\n",
    "print('''\n",
    "1. CORRELATION FILTERING (threshold=0.90)\n",
    "   - Priority: spange > acs > drfps > frag > smiles\n",
    "   - Removes redundant features while keeping most informative\n",
    "\n",
    "2. COMBINED FEATURE TABLE\n",
    "   - Merges: spange_descriptors, acs_pca_descriptors, drfps_catechol, fragprints, smiles\n",
    "   - After filtering: ~50-100 features (vs our 140+)\n",
    "\n",
    "3. CATBOOST + XGBOOST ENSEMBLE\n",
    "   - Single data: CatBoost=7/13, XGBoost=6/13\n",
    "   - Full data: CatBoost=1/3, XGBoost=2/3\n",
    "   - Different weights for different data types!\n",
    "\n",
    "4. CLIPPING + RENORMALIZATION\n",
    "   - Clip predictions to [0, inf)\n",
    "   - Renormalize so sum <= 1 (mass balance)\n",
    "   - This enforces physics constraint!\n",
    "\n",
    "5. NO GP, NO MLP, NO LGBM\n",
    "   - Only CatBoost + XGBoost\n",
    "   - Simpler ensemble, but with physics constraints\n",
    "''')\n",
    "\n",
    "print('\\n=== WHY THIS MIGHT WORK BETTER ===')\n",
    "print('''\n",
    "1. Correlation filtering reduces overfitting to training solvents\n",
    "2. Mass balance constraint generalizes to unseen solvents\n",
    "3. Different weights for single vs full data adapts to each task\n",
    "4. Simpler ensemble may have lower variance on test\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada91de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The 1st place score (0.0347) is BELOW our intercept\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print(f'''\n",
    "Our CV-LB intercept: {intercept:.4f}\n",
    "1st place LB score:  0.0347\n",
    "Gap:                 {intercept - 0.0347:.4f}\n",
    "\n",
    "This means 1st place found a way to CHANGE the CV-LB relationship!\n",
    "They either:\n",
    "1. Reduced the intercept (better generalization to unseen solvents)\n",
    "2. Found features/constraints that extrapolate better\n",
    "3. Used a fundamentally different approach\n",
    "\n",
    "The 2nd place score is 0.0707 - much closer to our intercept.\n",
    "This suggests 1st place has a unique insight that others don't have.\n",
    "''')\n",
    "\n",
    "print('=== POSSIBLE EXPLANATIONS FOR 1ST PLACE ===')\n",
    "print('''\n",
    "1. Physics-based constraints that hold for ALL solvents\n",
    "   - Mass balance (yields sum to 1)\n",
    "   - Arrhenius kinetics (temperature dependence)\n",
    "   - Solvent polarity effects\n",
    "\n",
    "2. Better solvent representation\n",
    "   - Molecular fingerprints that capture chemical similarity\n",
    "   - Pre-trained embeddings from large chemical databases\n",
    "\n",
    "3. Domain adaptation techniques\n",
    "   - Pseudo-labeling with confident predictions\n",
    "   - Test-time adaptation\n",
    "\n",
    "4. Ensemble of diverse approaches\n",
    "   - Different models for different solvent classes\n",
    "   - Uncertainty-weighted blending\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e887c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY ===')\n",
    "print(f'''\n",
    "Best CV: 0.0083 (exp_030, exp_067)\n",
    "Best LB: 0.0877 (exp_030, exp_067)\n",
    "Target:  0.0347\n",
    "Gap:     {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347) / 0.0347 * 100:.1f}% above target)\n",
    "\n",
    "CV-LB relationship: LB = {slope:.2f} * CV + {intercept:.4f}\n",
    "Intercept ({intercept:.4f}) > Target (0.0347)\n",
    "\n",
    "STRATEGIC CONCLUSION:\n",
    "Standard CV optimization CANNOT reach the target.\n",
    "We need approaches that REDUCE THE INTERCEPT, not just improve CV.\n",
    "''')\n",
    "\n",
    "print('=== RECOMMENDED NEXT STEPS ===')\n",
    "print('''\n",
    "1. IMPLEMENT ENS-MODEL KERNEL EXACTLY\n",
    "   - Correlation filtering with feature priority\n",
    "   - CatBoost + XGBoost with task-specific weights\n",
    "   - Clipping + renormalization (mass balance)\n",
    "\n",
    "2. ADD MASS BALANCE CONSTRAINT TO BEST MODEL\n",
    "   - Take exp_030 (GP+MLP+LGBM)\n",
    "   - Add post-processing: clip to [0, inf), renormalize to sum <= 1\n",
    "   - This enforces physics constraint that generalizes\n",
    "\n",
    "3. SOLVENT SIMILARITY FEATURES\n",
    "   - Add features measuring distance to training solvents\n",
    "   - Blend toward mean when extrapolating\n",
    "\n",
    "4. SUBMIT exp_030 WITH MASS BALANCE\n",
    "   - We have 4 submissions left\n",
    "   - This is a low-risk, potentially high-reward change\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
