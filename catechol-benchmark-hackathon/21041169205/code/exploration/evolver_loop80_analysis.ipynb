{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d83496",
   "metadata": {},
   "source": [
    "# Loop 80 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the exact CV-LB relationship across all submissions?\n",
    "2. What approaches have been tried and what are their CV-LB characteristics?\n",
    "3. What fundamentally different approaches might break the CV-LB pattern?\n",
    "4. What do the top public kernels do differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5618b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'MLP'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'MLP+DRFP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'MLP Ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'Simpler MLP'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'Even Simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Ridge'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Simple Ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'ACS PCA'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'Weighted Loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP+MLP+LGBM'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'Lower GP Weight'},\n",
    "    {'exp': 'exp_067', 'cv': 0.0083, 'lb': 0.0877, 'model': 'Sigmoid Output'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "r_squared = r_value ** 2\n",
    "\n",
    "print(f\"\\n=== CV-LB Relationship ===\")\n",
    "print(f\"Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_squared:.4f}\")\n",
    "print(f\"Intercept = {intercept:.4f}\")\n",
    "print(f\"Target LB = 0.0347\")\n",
    "print(f\"\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.0347)\")\n",
    "print(f\"Required CV for target: ({0.0347} - {intercept:.4f}) / {slope:.2f} = {(0.0347 - intercept) / slope:.4f}\")\n",
    "print(f\"\\nThis means standard CV optimization CANNOT reach the target!\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], c='blue', s=100, alpha=0.7)\n",
    "plt.plot([0, 0.015], [intercept, slope * 0.015 + intercept], 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', label='Target LB = 0.0347')\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title(f'CV vs LB Relationship (R² = {r_squared:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's different about the best submissions\n",
    "print(\"\\n=== Best Submissions Analysis ===\")\n",
    "best = df.nsmallest(3, 'lb')\n",
    "print(best)\n",
    "\n",
    "print(\"\\n=== Key Observations ===\")\n",
    "print(\"1. Best LB: 0.0877 (exp_030, exp_067) - both use GP+MLP+LGBM ensemble\")\n",
    "print(\"2. Target: 0.0347\")\n",
    "print(\"3. Gap: 153% above target\")\n",
    "print(\"4. All approaches fall on the same CV-LB line (R² = 0.96)\")\n",
    "print(\"5. The intercept (0.052) represents STRUCTURAL distribution shift\")\n",
    "print(\"\\n=== What This Means ===\")\n",
    "print(\"- The test solvents are fundamentally different from training solvents\")\n",
    "print(\"- Leave-one-out CV doesn't capture this difference\")\n",
    "print(\"- No amount of CV optimization can reach the target\")\n",
    "print(\"- We need approaches that CHANGE the CV-LB relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd982088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches might change the CV-LB relationship?\n",
    "print(\"\\n=== Approaches That Might Change CV-LB Relationship ===\")\n",
    "print(\"\\n1. GNN with Molecular Structure (GNN benchmark achieved 0.0039 MSE)\")\n",
    "print(\"   - Uses graph neural networks with message-passing\")\n",
    "print(\"   - Captures molecular structure directly\")\n",
    "print(\"   - May have fundamentally different extrapolation behavior\")\n",
    "\n",
    "print(\"\\n2. ens-model Kernel Approach (CatBoost + XGBoost)\")\n",
    "print(\"   - Different weights for single vs full data (7:6 vs 1:2)\")\n",
    "print(\"   - Correlation-based feature filtering\")\n",
    "print(\"   - May have different CV-LB relationship\")\n",
    "\n",
    "print(\"\\n3. mixall Kernel Approach (GroupKFold instead of LOO)\")\n",
    "print(\"   - Uses 5-fold GroupKFold instead of 24-fold LOO\")\n",
    "print(\"   - Each fold contains multiple solvents\")\n",
    "print(\"   - May better simulate test distribution\")\n",
    "\n",
    "print(\"\\n4. Conservative Predictions for Outlier Solvents\")\n",
    "print(\"   - Identify solvents that are 'far' from training distribution\")\n",
    "print(\"   - Blend predictions toward population mean for these solvents\")\n",
    "print(\"   - May reduce extrapolation error\")\n",
    "\n",
    "print(\"\\n5. Solvent Clustering\")\n",
    "print(\"   - Group solvents by chemical class\")\n",
    "print(\"   - Use class-specific models\")\n",
    "print(\"   - May generalize better within chemical families\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc96f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What have we tried that DIDN'T work?\n",
    "print(\"\\n=== Approaches That DIDN'T Work ===\")\n",
    "print(\"\\n1. Probability Normalization (exp_074)\")\n",
    "print(\"   - CV regressed 64% (0.0083 -> 0.0136)\")\n",
    "print(\"   - Yields don't sum to 1, so normalization hurts\")\n",
    "\n",
    "print(\"\\n2. Extrapolation Detection with Adaptive Blending (exp_048, 058, 059, 068-071)\")\n",
    "print(\"   - Multiple attempts with different thresholds\")\n",
    "print(\"   - None improved LB significantly\")\n",
    "\n",
    "print(\"\\n3. Uncertainty Weighting (exp_048)\")\n",
    "print(\"   - GP uncertainty didn't help\")\n",
    "\n",
    "print(\"\\n4. Deep Residual Networks (exp_004)\")\n",
    "print(\"   - Much worse than simple MLP\")\n",
    "\n",
    "print(\"\\n5. DRFP with PCA (exp_002)\")\n",
    "print(\"   - Worse than Spange descriptors alone\")\n",
    "\n",
    "print(\"\\n6. IWCV (Importance-Weighted CV) (exp_051)\")\n",
    "print(\"   - Didn't help with distribution shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the ens-model kernel approach\n",
    "print(\"\\n=== ens-model Kernel Analysis ===\")\n",
    "print(\"\\nKey Features:\")\n",
    "print(\"1. Uses CatBoost + XGBoost ensemble (NOT MLP)\")\n",
    "print(\"2. Different weights for single vs full data:\")\n",
    "print(\"   - Single: CatBoost 7, XGBoost 6 (normalized: 0.538, 0.462)\")\n",
    "print(\"   - Full: CatBoost 1, XGBoost 2 (normalized: 0.333, 0.667)\")\n",
    "print(\"3. Correlation-based feature filtering (threshold=0.8)\")\n",
    "print(\"4. Feature priority: spange > acs > drfps > frag > smiles\")\n",
    "print(\"5. Combines multiple feature sources:\")\n",
    "print(\"   - spange_descriptors\")\n",
    "print(\"   - acs_pca_descriptors\")\n",
    "print(\"   - drfps_catechol\")\n",
    "print(\"   - fragprints\")\n",
    "print(\"   - smiles\")\n",
    "\n",
    "print(\"\\nWhy This Might Help:\")\n",
    "print(\"- CatBoost/XGBoost may have different extrapolation behavior than MLP\")\n",
    "print(\"- Asymmetric weighting suggests they found something about the data structure\")\n",
    "print(\"- Correlation filtering may remove features that hurt generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and Recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n## Current Status\")\n",
    "print(f\"- Best CV: 0.0083 (exp_030, exp_067)\")\n",
    "print(f\"- Best LB: 0.0877 (exp_030, exp_067)\")\n",
    "print(f\"- Target: 0.0347\")\n",
    "print(f\"- Gap: 153% above target\")\n",
    "print(f\"- Submissions remaining: 4\")\n",
    "\n",
    "print(\"\\n## CV-LB Relationship\")\n",
    "print(f\"- Linear fit: LB = {slope:.2f} * CV + {intercept:.4f} (R² = {r_squared:.4f})\")\n",
    "print(f\"- Intercept ({intercept:.4f}) > Target (0.0347)\")\n",
    "print(f\"- Standard CV optimization CANNOT reach the target\")\n",
    "\n",
    "print(\"\\n## RECOMMENDED NEXT STEPS (Priority Order)\")\n",
    "print(\"\\n1. IMPLEMENT ens-model Kernel Approach\")\n",
    "print(\"   - CatBoost + XGBoost with their exact hyperparameters\")\n",
    "print(\"   - Use their ensemble weights (7:6 for single, 1:2 for full)\")\n",
    "print(\"   - This is a fundamentally different model family\")\n",
    "\n",
    "print(\"\\n2. TRY Conservative Predictions\")\n",
    "print(\"   - For ALL predictions, blend toward population mean\")\n",
    "print(\"   - Use a fixed blend weight (e.g., 0.2-0.3)\")\n",
    "print(\"   - This reduces extrapolation error uniformly\")\n",
    "\n",
    "print(\"\\n3. STUDY Test Solvent Properties\")\n",
    "print(\"   - What makes test solvents different?\")\n",
    "print(\"   - Are they from different chemical families?\")\n",
    "print(\"   - Do they have extreme properties?\")\n",
    "\n",
    "print(\"\\n## WHAT NOT TO DO\")\n",
    "print(\"- Don't submit exp_074 (prob_norm) - CV regressed 64%\")\n",
    "print(\"- Don't keep optimizing CV - the intercept problem persists\")\n",
    "print(\"- Don't try more extrapolation detection - multiple attempts failed\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
