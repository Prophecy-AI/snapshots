{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3090524a",
   "metadata": {},
   "source": [
    "# Loop 93 Analysis: Critical Strategic Assessment\n",
    "\n",
    "## Situation\n",
    "- Best CV: 0.008092 (exp_049/050/051/053)\n",
    "- Best LB: 0.0877 (exp_030, exp_067)\n",
    "- Target: 0.0347\n",
    "- Submissions remaining: 4\n",
    "- Experiments: 93\n",
    "\n",
    "## Key Question\n",
    "After 93 experiments and 23 submissions, what is the path to beating 0.0347?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All verified submissions with CV and LB scores\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_035', 0.0098, 0.0970),\n",
    "    ('exp_067', 0.0083, 0.0877),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp', 'cv', 'lb'])\n",
    "print(f\"Verified submissions: {len(df)}\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Relationship Analysis\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "r_squared = r_value**2\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CV-LB RELATIONSHIP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Linear fit: LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_squared:.4f}\")\n",
    "print(f\"Intercept = {intercept:.4f}\")\n",
    "print(f\"Target LB = 0.0347\")\n",
    "print()\n",
    "print(\"CRITICAL INSIGHT:\")\n",
    "print(f\"  Intercept ({intercept:.4f}) > Target ({0.0347:.4f})\")\n",
    "print(f\"  Required CV to hit target: ({0.0347} - {intercept:.4f}) / {slope:.4f} = {(0.0347 - intercept) / slope:.6f}\")\n",
    "print()\n",
    "if intercept > 0.0347:\n",
    "    print(\"  ⚠️ IMPOSSIBLE: Even with CV=0, predicted LB would be {:.4f}\".format(intercept))\n",
    "    print(\"  The intercept represents STRUCTURAL distribution shift that no model tuning can fix.\")\n",
    "else:\n",
    "    print(\"  ✓ Target is achievable with CV improvement\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, max(cv)*1.1, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Intercept line\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept = {intercept:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship (13 verified submissions)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop93.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"\\nPlot saved to /home/code/exploration/cv_lb_relationship_loop93.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap\n",
    "print(\"=\"*60)\n",
    "print(\"GAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_cv = 0.008092\n",
    "best_lb = 0.0877\n",
    "target_lb = 0.0347\n",
    "\n",
    "print(f\"Best CV achieved: {best_cv:.6f}\")\n",
    "print(f\"Best LB achieved: {best_lb:.4f}\")\n",
    "print(f\"Target LB: {target_lb:.4f}\")\n",
    "print(f\"Gap to target: {best_lb - target_lb:.4f} ({(best_lb - target_lb)/target_lb*100:.1f}%)\")\n",
    "print()\n",
    "print(\"PREDICTED LB FROM BEST CV:\")\n",
    "predicted_lb = slope * best_cv + intercept\n",
    "print(f\"  LB = {slope:.4f} * {best_cv:.6f} + {intercept:.4f} = {predicted_lb:.4f}\")\n",
    "print(f\"  Actual best LB: {best_lb:.4f}\")\n",
    "print(f\"  Prediction error: {abs(predicted_lb - best_lb):.4f}\")\n",
    "print()\n",
    "print(\"WHAT WOULD IT TAKE TO HIT TARGET?\")\n",
    "if intercept > target_lb:\n",
    "    print(f\"  The intercept ({intercept:.4f}) is ABOVE the target ({target_lb:.4f})\")\n",
    "    print(f\"  This means we need to CHANGE THE RELATIONSHIP, not just improve CV\")\n",
    "    print()\n",
    "    print(\"  Options to change the relationship:\")\n",
    "    print(\"  1. Reduce the intercept (distribution shift mitigation)\")\n",
    "    print(\"  2. Find an approach that doesn't follow the same CV-LB line\")\n",
    "    print(\"  3. Use techniques that specifically target LB performance\")\n",
    "else:\n",
    "    required_cv = (target_lb - intercept) / slope\n",
    "    print(f\"  Required CV: {required_cv:.6f}\")\n",
    "    print(f\"  Current best CV: {best_cv:.6f}\")\n",
    "    print(f\"  CV improvement needed: {(best_cv - required_cv)/best_cv*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze neural network experiments\n",
    "print(\"=\"*60)\n",
    "print(\"NEURAL NETWORK EXPERIMENTS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nn_experiments = [\n",
    "    ('exp_085_gnn', 'GCN', 0.02013),\n",
    "    ('exp_086_gat', 'GAT', 0.018474),\n",
    "    ('exp_087_drfp_gat', 'DRFP+GAT', 0.019437),\n",
    "    ('exp_088_chemberta', 'ChemBERTa+MLP', 0.020558),\n",
    "]\n",
    "\n",
    "print(\"\\nNeural Network Results:\")\n",
    "for exp, model, cv in nn_experiments:\n",
    "    predicted_lb = slope * cv + intercept\n",
    "    print(f\"  {model}: CV={cv:.6f}, Predicted LB={predicted_lb:.4f}\")\n",
    "\n",
    "print(\"\\nComparison to best tabular:\")\n",
    "best_tabular_cv = 0.008092\n",
    "for exp, model, cv in nn_experiments:\n",
    "    ratio = cv / best_tabular_cv\n",
    "    print(f\"  {model}: {ratio:.1f}x worse than best tabular\")\n",
    "\n",
    "print(\"\\nCONCLUSION:\")\n",
    "print(\"  All neural network approaches are 2-2.5x WORSE than best tabular.\")\n",
    "print(\"  Generic pre-trained embeddings (ChemBERTa) don't help.\")\n",
    "print(\"  The benchmark's success (CV=0.0039) came from task-specific pre-training.\")\n",
    "print(\"  Without access to similar pre-training data, neural networks won't help.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62879982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES TRIED (93 experiments)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = {\n",
    "    'MLP variants': ['baseline', 'deep residual', 'simpler', 'attention', 'learned embeddings'],\n",
    "    'Tree-based': ['LightGBM', 'XGBoost', 'CatBoost', 'ensembles'],\n",
    "    'Gaussian Process': ['pure GP', 'GP+MLP ensemble', 'GP weight tuning'],\n",
    "    'Feature engineering': ['Spange descriptors', 'DRFP', 'Arrhenius kinetics', 'ACS-PCA', 'fragprints'],\n",
    "    'Neural networks': ['GCN', 'GAT', 'DRFP+GAT', 'ChemBERTa'],\n",
    "    'Distribution shift': ['extrapolation detection', 'similarity weighting', 'pseudo-labeling', 'conservative blend'],\n",
    "    'Ensembling': ['model averaging', 'weighted ensembles', 'stacking'],\n",
    "}\n",
    "\n",
    "for category, methods in approaches.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for method in methods:\n",
    "        print(f\"  - {method}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHAT HASN'T BEEN TRIED?\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. ReactionT5 (pre-trained on Open Reaction Database)\")\n",
    "print(\"   - Specifically designed for reaction yield prediction\")\n",
    "print(\"   - Encodes full reaction context, not just molecules\")\n",
    "print(\"\\n2. Rxnfp (reaction fingerprints)\")\n",
    "print(\"   - Captures reaction-specific information\")\n",
    "print(\"   - Different from molecular fingerprints\")\n",
    "print(\"\\n3. Task-specific fine-tuning on similar datasets\")\n",
    "print(\"   - Pre-train on other yield prediction datasets\")\n",
    "print(\"   - Transfer to this task\")\n",
    "print(\"\\n4. Adversarial domain adaptation\")\n",
    "print(\"   - Make representations invariant to solvent identity\")\n",
    "print(\"   - Force model to learn generalizable features\")\n",
    "print(\"\\n5. Test-time adaptation\")\n",
    "print(\"   - Adjust predictions based on test distribution\")\n",
    "print(\"   - Requires careful implementation to avoid leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's working\n",
    "print(\"=\"*60)\n",
    "print(\"WHAT'S WORKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. CatBoost + XGBoost ensemble (CV=0.008092)\")\n",
    "print(\"   - Best CV achieved\")\n",
    "print(\"   - Uses Spange descriptors + Arrhenius kinetics\")\n",
    "print(\"   - Per-target models\")\n",
    "print()\n",
    "print(\"2. GP + MLP + LGBM ensemble (LB=0.0877)\")\n",
    "print(\"   - Best LB achieved (exp_030, exp_067)\")\n",
    "print(\"   - GP provides uncertainty estimates\")\n",
    "print(\"   - Ensemble diversity helps\")\n",
    "print()\n",
    "print(\"3. Spange descriptors\")\n",
    "print(\"   - Physicochemical properties of solvents\")\n",
    "print(\"   - Consistently outperform other feature sets\")\n",
    "print()\n",
    "print(\"4. Arrhenius kinetics features\")\n",
    "print(\"   - 1/T, ln(t), interaction terms\")\n",
    "print(\"   - Physics-informed features that generalize\")\n",
    "print()\n",
    "print(\"5. Leave-one-out CV\")\n",
    "print(\"   - Simulates unseen solvent prediction\")\n",
    "print(\"   - Good correlation with LB (R²=0.96)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThe CV-LB relationship is VERY LINEAR (R²=0.96).\")\n",
    "print(\"This means:\")\n",
    "print(\"  1. Our CV is a good predictor of LB\")\n",
    "print(\"  2. All approaches fall on the same line\")\n",
    "print(\"  3. The intercept (0.052) represents structural shift\")\n",
    "print(\"  4. No approach has changed the relationship\")\n",
    "print(\"\\nThe intercept is the bottleneck, not CV optimization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f10e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final strategic assessment\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIC ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCURRENT SITUATION:\")\n",
    "print(f\"  - Best CV: 0.008092\")\n",
    "print(f\"  - Best LB: 0.0877\")\n",
    "print(f\"  - Target: 0.0347\")\n",
    "print(f\"  - Gap: {0.0877 - 0.0347:.4f} ({(0.0877 - 0.0347)/0.0347*100:.1f}%)\")\n",
    "print(f\"  - Submissions remaining: 4\")\n",
    "\n",
    "print(\"\\nTHE MATH:\")\n",
    "print(f\"  - CV-LB relationship: LB = 4.36*CV + 0.052\")\n",
    "print(f\"  - Intercept (0.052) > Target (0.0347)\")\n",
    "print(f\"  - Even CV=0 would give LB=0.052 > 0.0347\")\n",
    "print(f\"  - IMPOSSIBLE to reach target by CV optimization alone\")\n",
    "\n",
    "print(\"\\nOPTIONS:\")\n",
    "print(\"  1. ACCEPT that target may be unreachable with current approaches\")\n",
    "print(\"     - The benchmark (CV=0.0039) used task-specific pre-training\")\n",
    "print(\"     - We don't have access to similar pre-training data\")\n",
    "print(\"     - Our best is 0.0877, which is 2.5x the target\")\n",
    "print()\n",
    "print(\"  2. TRY approaches that might change the CV-LB relationship\")\n",
    "print(\"     - ReactionT5 (reaction-level pre-training)\")\n",
    "print(\"     - Adversarial domain adaptation\")\n",
    "print(\"     - Test-time adaptation\")\n",
    "print()\n",
    "print(\"  3. SUBMIT best models to verify LB performance\")\n",
    "print(\"     - exp_049/050 (CV=0.008092) haven't been submitted successfully\")\n",
    "print(\"     - Predicted LB: 4.36*0.008092 + 0.052 = 0.0873\")\n",
    "print(\"     - This would be our best LB if it works\")\n",
    "\n",
    "print(\"\\nRECOMMENDATION:\")\n",
    "print(\"  Given 4 submissions remaining, prioritize:\")\n",
    "print(\"  1. Submit exp_049/050 to verify best CV translates to best LB\")\n",
    "print(\"  2. Try ReactionT5 if available (reaction-level pre-training)\")\n",
    "print(\"  3. Try adversarial domain adaptation\")\n",
    "print(\"  4. Accept that 0.0877 may be our ceiling without task-specific pre-training\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
