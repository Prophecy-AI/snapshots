{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75b7961",
   "metadata": {},
   "source": [
    "# Loop 85 Analysis: Understanding the CV-LB Gap and Finding New Approaches\n",
    "\n",
    "**Critical Situation:**\n",
    "- Best CV: 0.0081 (exp_049/exp_053)\n",
    "- Best LB: 0.0877 (exp_030/exp_067)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.36*CV + 0.052 (R²=0.956)\n",
    "- Intercept (0.052) > Target (0.0347) → Standard CV optimization CANNOT reach target\n",
    "\n",
    "**Experiment 081 (Solvent Clustering) FAILED:**\n",
    "- CV: 0.0205 (153% worse than best 0.0081)\n",
    "- Clustering reduced training data per model\n",
    "- Didn't help with extrapolation to unseen solvents\n",
    "\n",
    "**Goal:** Find approaches that might CHANGE the CV-LB relationship, not just improve CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ced1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Submission history with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'CV': 0.0111, 'LB': 0.0982},\n",
    "    {'exp': 'exp_001', 'CV': 0.0123, 'LB': 0.1065},\n",
    "    {'exp': 'exp_003', 'CV': 0.0105, 'LB': 0.0972},\n",
    "    {'exp': 'exp_005', 'CV': 0.0104, 'LB': 0.0969},\n",
    "    {'exp': 'exp_006', 'CV': 0.0097, 'LB': 0.0946},\n",
    "    {'exp': 'exp_007', 'CV': 0.0093, 'LB': 0.0932},\n",
    "    {'exp': 'exp_009', 'CV': 0.0092, 'LB': 0.0936},\n",
    "    {'exp': 'exp_012', 'CV': 0.0090, 'LB': 0.0913},\n",
    "    {'exp': 'exp_024', 'CV': 0.0087, 'LB': 0.0893},\n",
    "    {'exp': 'exp_026', 'CV': 0.0085, 'LB': 0.0887},\n",
    "    {'exp': 'exp_030', 'CV': 0.0083, 'LB': 0.0877},\n",
    "    {'exp': 'exp_035', 'CV': 0.0098, 'LB': 0.0970},\n",
    "    {'exp': 'exp_067', 'CV': 0.0083, 'LB': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f\"Total submissions with LB: {len(df)}\")\n",
    "print(f\"Best CV: {df['CV'].min():.4f} ({df.loc[df['CV'].idxmin(), 'exp']})\")\n",
    "print(f\"Best LB: {df['LB'].min():.4f} ({df.loc[df['LB'].idxmin(), 'exp']})\")\n",
    "print(f\"Target: 0.0347\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression to understand CV-LB relationship\n",
    "X = df['CV'].values.reshape(-1, 1)\n",
    "y = df['LB'].values\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "slope = reg.coef_[0]\n",
    "intercept = reg.intercept_\n",
    "r2 = reg.score(X, y)\n",
    "\n",
    "print(f\"CV-LB Relationship:\")\n",
    "print(f\"  LB = {slope:.3f} * CV + {intercept:.4f}\")\n",
    "print(f\"  R² = {r2:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"CRITICAL ANALYSIS:\")\n",
    "print(f\"  Intercept: {intercept:.4f}\")\n",
    "print(f\"  Target: 0.0347\")\n",
    "print(f\"  Gap: {intercept - 0.0347:.4f}\")\n",
    "print(f\"\")\n",
    "if intercept > 0.0347:\n",
    "    print(f\"  ⚠️ INTERCEPT > TARGET: Even at CV=0, expected LB is {intercept:.4f}\")\n",
    "    print(f\"  ⚠️ Standard CV optimization CANNOT reach target!\")\n",
    "    required_cv = (0.0347 - intercept) / slope\n",
    "    print(f\"  ⚠️ Required CV for target: {required_cv:.4f} (IMPOSSIBLE - negative)\")\n",
    "else:\n",
    "    required_cv = (0.0347 - intercept) / slope\n",
    "    print(f\"  Required CV for target: {required_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot submissions\n",
    "plt.scatter(df['CV'], df['LB'], c='blue', s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Plot regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Plot target\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Plot intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=2, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - The Intercept Problem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop85.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey insight: The intercept ({intercept:.4f}) is ABOVE the target (0.0347).\")\n",
    "print(f\"This means we need approaches that CHANGE the relationship, not just improve CV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES TRIED AND THEIR OUTCOMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = [\n",
    "    ('MLP with Arrhenius features', 'exp_000', 0.0111, 0.0982, 'Baseline'),\n",
    "    ('LightGBM', 'exp_001', 0.0123, 0.1065, 'Worse than MLP'),\n",
    "    ('Combined Spange+DRFP', 'exp_003', 0.0105, 0.0972, 'Slight improvement'),\n",
    "    ('Large ensemble (15 models)', 'exp_005', 0.0104, 0.0969, 'Marginal improvement'),\n",
    "    ('Simpler model [64,32]', 'exp_006', 0.0097, 0.0946, 'Better - simpler is better'),\n",
    "    ('Even simpler [32,16]', 'exp_007', 0.0093, 0.0932, 'Even better'),\n",
    "    ('Ridge regression', 'exp_009', 0.0092, 0.0936, 'Comparable'),\n",
    "    ('Simple ensemble', 'exp_012', 0.0090, 0.0913, 'Best at the time'),\n",
    "    ('ACS PCA features', 'exp_024', 0.0087, 0.0893, 'Improved'),\n",
    "    ('Weighted loss', 'exp_026', 0.0085, 0.0887, 'Improved'),\n",
    "    ('GP ensemble', 'exp_030', 0.0083, 0.0877, 'Best LB'),\n",
    "    ('Lower GP weight', 'exp_035', 0.0098, 0.0970, 'Worse'),\n",
    "    ('Sigmoid output', 'exp_067', 0.0083, 0.0877, 'Same as exp_030'),\n",
    "    ('CatBoost+XGBoost', 'exp_049', 0.0081, 'pending', 'Best CV'),\n",
    "    ('Solvent clustering', 'exp_081', 0.0205, 'N/A', 'FAILED - 153% worse'),\n",
    "]\n",
    "\n",
    "for name, exp, cv, lb, outcome in approaches:\n",
    "    print(f\"{name:35s} | CV: {cv:.4f} | LB: {str(lb):8s} | {outcome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches might CHANGE the CV-LB relationship?\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES THAT MIGHT CHANGE THE CV-LB RELATIONSHIP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. UNCERTAINTY-WEIGHTED PREDICTIONS (NOT FULLY EXPLORED)\n",
    "   - Use GP or ensemble variance to estimate uncertainty\n",
    "   - When uncertainty is high (extrapolating), blend toward population mean\n",
    "   - This could reduce the intercept by making conservative predictions for hard solvents\n",
    "   - Status: Tried in exp_048, exp_068-071 but not optimized\n",
    "\n",
    "2. SOLVENT SIMILARITY WEIGHTING (NOT TRIED)\n",
    "   - Instead of clustering, compute similarity to training solvents\n",
    "   - Weight predictions by similarity (more similar = more confident)\n",
    "   - Blend with population mean for dissimilar solvents\n",
    "   - Different from clustering: uses continuous similarity, not discrete clusters\n",
    "\n",
    "3. TARGET-SPECIFIC HANDLING (PARTIALLY TRIED)\n",
    "   - The SM target is hardest (highest variance)\n",
    "   - Consider different strategies for SM vs Product 2/3\n",
    "   - SM model should be more conservative (blend toward mean)\n",
    "   - Status: Tried per-target models but not conservative blending\n",
    "\n",
    "4. PSEUDO-LABELING (NOT TRIED)\n",
    "   - Use confident test predictions to augment training\n",
    "   - This adapts the model to the test distribution\n",
    "   - Risk: Could overfit to test set if not done carefully\n",
    "\n",
    "5. DOMAIN-SPECIFIC CONSTRAINTS (NOT TRIED)\n",
    "   - Physics/chemistry constraints that hold even on unseen data\n",
    "   - E.g., yields must sum to <= 1, certain relationships between targets\n",
    "   - Could improve generalization to unseen solvents\n",
    "\n",
    "6. STUDY TOP KERNELS MORE CAREFULLY\n",
    "   - The mixall kernel achieves good CV/LB with GroupKFold(5)\n",
    "   - The ens-model kernel uses specific feature combinations\n",
    "   - What do they do differently that we're missing?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what experiments have best CV but haven't been submitted\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENTS WITH GOOD CV BUT NOT SUBMITTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# From session_state, experiments with pending LB\n",
    "pending = [\n",
    "    ('exp_049', 0.0081, 'CatBoost+XGBoost'),\n",
    "    ('exp_050', 0.0081, 'CatBoost+XGBoost fixed'),\n",
    "    ('exp_052', 0.0109, 'CatBoost+XGBoost clipped'),\n",
    "    ('exp_053', 0.0081, 'Exact template'),\n",
    "    ('exp_054', 0.0085, 'Mixall approach'),\n",
    "    ('exp_055', 0.0085, 'Minimal submission'),\n",
    "    ('exp_057', 0.0093, 'Ens-model all features'),\n",
    "    ('exp_063', 0.0112, 'Correct final cell'),\n",
    "    ('exp_064', 0.0092, 'Revert exp030'),\n",
    "    ('exp_065', 0.0088, 'Clean submission'),\n",
    "]\n",
    "\n",
    "print(\"\\nExperiments with pending LB:\")\n",
    "for exp, cv, desc in sorted(pending, key=lambda x: x[1]):\n",
    "    predicted_lb = slope * cv + intercept\n",
    "    print(f\"{exp}: CV={cv:.4f}, Predicted LB={predicted_lb:.4f} | {desc}\")\n",
    "\n",
    "print(f\"\\nBest pending: exp_049/exp_050/exp_053 with CV=0.0081\")\n",
    "print(f\"Predicted LB: {slope * 0.0081 + intercept:.4f}\")\n",
    "print(f\"This is still above target (0.0347) by {slope * 0.0081 + intercept - 0.0347:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd10777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the top kernels do differently\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS OF TOP KERNELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. MIXALL KERNEL (lishellliang)\n",
    "   - Uses GroupKFold(5) instead of Leave-One-Out\n",
    "   - Achieves good CV/LB with simple approach\n",
    "   - Key: Different CV scheme may have different CV-LB relationship\n",
    "   - Status: Tried in exp_078 (CV=0.0150) but not submitted\n",
    "\n",
    "2. ENS-MODEL KERNEL (matthewmaree)\n",
    "   - Uses specific feature combinations\n",
    "   - Ensemble of multiple models\n",
    "   - Status: Tried in exp_080 (CV=0.0103) but not submitted\n",
    "\n",
    "3. BEST-WORK-HERE KERNEL (gentilless)\n",
    "   - Normalizes predictions to probabilities (row sums = 1)\n",
    "   - Triple normalization: clip, normalize, clip again\n",
    "   - Status: Tried in exp_079 (CV=0.0085) but not submitted\n",
    "\n",
    "KEY INSIGHT: All these kernels still fall on the same CV-LB line!\n",
    "The intercept problem persists regardless of the approach.\n",
    "\n",
    "WHAT WE HAVEN'T TRIED:\n",
    "- Uncertainty-weighted predictions with proper calibration\n",
    "- Solvent similarity weighting (continuous, not discrete clustering)\n",
    "- Conservative predictions for outlier solvents\n",
    "- Pseudo-labeling to adapt to test distribution\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what CV we need to reach target\n",
    "print(\"=\"*60)\n",
    "print(\"MATHEMATICAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target = 0.0347\n",
    "best_cv = 0.0081\n",
    "best_lb = 0.0877\n",
    "\n",
    "print(f\"Current best CV: {best_cv:.4f}\")\n",
    "print(f\"Current best LB: {best_lb:.4f}\")\n",
    "print(f\"Target LB: {target:.4f}\")\n",
    "print(f\"Gap to target: {best_lb - target:.4f} ({(best_lb - target) / target * 100:.1f}%)\")\n",
    "print(f\"\")\n",
    "print(f\"CV-LB relationship: LB = {slope:.3f} * CV + {intercept:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"To reach target {target:.4f}:\")\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f\"  Required CV: {required_cv:.4f}\")\n",
    "if required_cv < 0:\n",
    "    print(f\"  ⚠️ IMPOSSIBLE: Required CV is negative!\")\n",
    "    print(f\"  ⚠️ The intercept ({intercept:.4f}) alone exceeds the target ({target:.4f})\")\n",
    "    print(f\"\")\n",
    "    print(f\"CONCLUSION: We MUST find approaches that REDUCE THE INTERCEPT.\")\n",
    "    print(f\"\")\n",
    "    print(f\"To reach target with current slope ({slope:.3f}):\")\n",
    "    required_intercept = target - slope * best_cv\n",
    "    print(f\"  Required intercept: {required_intercept:.4f}\")\n",
    "    print(f\"  Current intercept: {intercept:.4f}\")\n",
    "    print(f\"  Intercept reduction needed: {intercept - required_intercept:.4f}\")\n",
    "else:\n",
    "    print(f\"  Required CV: {required_cv:.4f}\")\n",
    "    print(f\"  Current best CV: {best_cv:.4f}\")\n",
    "    print(f\"  CV improvement needed: {best_cv - required_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b43dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. DO NOT SUBMIT exp_081 (Solvent Clustering)\n",
    "   - CV is 153% worse than best (0.0205 vs 0.0081)\n",
    "   - Would waste a submission\n",
    "\n",
    "2. CONSIDER SUBMITTING exp_049 (CatBoost+XGBoost)\n",
    "   - Best CV (0.0081)\n",
    "   - Predicted LB: ~0.087 (same as current best)\n",
    "   - Validates that CatBoost/XGBoost doesn't change the relationship\n",
    "\n",
    "3. FOCUS ON APPROACHES THAT MIGHT REDUCE THE INTERCEPT:\n",
    "   a) Uncertainty-weighted predictions with conservative blending\n",
    "   b) Solvent similarity weighting (continuous, not clustering)\n",
    "   c) Per-target conservative blending for SM (hardest target)\n",
    "   d) Pseudo-labeling to adapt to test distribution\n",
    "\n",
    "4. WITH 4 SUBMISSIONS REMAINING:\n",
    "   - Save 1-2 for final attempts\n",
    "   - Use 1-2 to test fundamentally different approaches\n",
    "   - Don't waste on variations of the same approach\n",
    "\n",
    "5. THE TARGET IS REACHABLE:\n",
    "   - The GNN benchmark achieved 0.0039 MSE\n",
    "   - Top Kaggle competitors have achieved sub-0.07\n",
    "   - We need to find what they do differently\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
