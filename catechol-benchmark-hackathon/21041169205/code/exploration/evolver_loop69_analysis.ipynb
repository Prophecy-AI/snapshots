{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d22df9",
   "metadata": {},
   "source": [
    "# Loop 69 Analysis: Submission Error Investigation\n",
    "\n",
    "The submission failed with \"Evaluation metric raised an unexpected error\". Let me investigate the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36069385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:01:58.879364Z",
     "iopub.status.busy": "2026-01-16T05:01:58.878775Z",
     "iopub.status.idle": "2026-01-16T05:01:59.200566Z",
     "shell.execute_reply": "2026-01-16T05:01:59.200166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submissions: 22\n",
      "\n",
      "Submission history:\n",
      "  exp_000: CV=0.011081, LB=0.09816\n",
      "  exp_001: CV=0.012297, LB=0.10649\n",
      "  exp_003: CV=0.010501, LB=0.09719\n",
      "  exp_005: CV=0.01043, LB=0.09691\n",
      "  exp_006: CV=0.009749, LB=0.09457\n",
      "  exp_007: CV=0.009262, LB=0.09316\n",
      "  exp_009: CV=0.009192, LB=0.09364\n",
      "  exp_012: CV=0.009004, LB=0.09134\n",
      "  exp_024: CV=0.008689, LB=0.08929\n",
      "  exp_026: CV=0.008465, LB=0.08875\n",
      "  exp_030: CV=0.008298, LB=0.08772\n",
      "  exp_035: CV=0.009825, LB=0.09696\n",
      "  exp_049: CV=0.008092, LB=\n",
      "  exp_050: CV=0.008092, LB=\n",
      "  exp_052: CV=0.01088, LB=\n",
      "  exp_053: CV=0.008092, LB=\n",
      "  exp_054: CV=0.008504, LB=\n",
      "  exp_055: CV=0.008504, LB=\n",
      "  exp_057: CV=0.009263, LB=\n",
      "  exp_063: CV=0.011171, LB=\n",
      "  exp_064: CV=0.009227, LB=\n",
      "  exp_065: CV=0.008811, LB=\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Check submission history\n",
    "submissions = state.get('submissions', [])\n",
    "print(f'Total submissions: {len(submissions)}')\n",
    "print('\\nSubmission history:')\n",
    "for s in submissions:\n",
    "    print(f\"  {s.get('experiment_id', 'N/A')}: CV={s.get('cv_score', 'N/A')}, LB={s.get('lb_score', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416d5298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:01:59.201692Z",
     "iopub.status.busy": "2026-01-16T05:01:59.201553Z",
     "iopub.status.idle": "2026-01-16T05:01:59.542187Z",
     "shell.execute_reply": "2026-01-16T05:01:59.541771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-LB Linear Fit: LB = 4.31 * CV + 0.0525\n",
      "R-squared = 0.9505\n",
      "\n",
      "Intercept: 0.0525\n",
      "Target: 0.0347\n",
      "\n",
      "To reach target LB 0.0347:\n",
      "Required CV = (0.0347 - 0.0525) / 4.31 = -0.0041\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV-LB relationship from successful submissions\n",
    "successful = [(0.0111, 0.0982), (0.0123, 0.1065), (0.0105, 0.0972), (0.0104, 0.0969),\n",
    "              (0.0097, 0.0946), (0.0093, 0.0932), (0.0092, 0.0936), (0.0090, 0.0913),\n",
    "              (0.0087, 0.0893), (0.0085, 0.0887), (0.0083, 0.0877), (0.0098, 0.0970)]\n",
    "\n",
    "cv_scores = [x[0] for x in successful]\n",
    "lb_scores = [x[1] for x in successful]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array(cv_scores).reshape(-1, 1)\n",
    "y = np.array(lb_scores)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "print(f'CV-LB Linear Fit: LB = {reg.coef_[0]:.2f} * CV + {reg.intercept_:.4f}')\n",
    "print(f'R-squared = {reg.score(X, y):.4f}')\n",
    "print(f'\\nIntercept: {reg.intercept_:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'\\nTo reach target LB 0.0347:')\n",
    "required_cv = (0.0347 - reg.intercept_) / reg.coef_[0]\n",
    "print(f'Required CV = (0.0347 - {reg.intercept_:.4f}) / {reg.coef_[0]:.2f} = {required_cv:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f521a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:01:59.543344Z",
     "iopub.status.busy": "2026-01-16T05:01:59.543197Z",
     "iopub.status.idle": "2026-01-16T05:01:59.552844Z",
     "shell.execute_reply": "2026-01-16T05:01:59.552417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1883, 8)\n",
      "Columns: ['id', 'index', 'task', 'fold', 'row', 'target_1', 'target_2', 'target_3']\n",
      "\n",
      "Task 0 (single solvent):\n",
      "  Folds: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "  Total rows: 656\n",
      "\n",
      "Task 1 (full data):\n",
      "  Folds: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  Total rows: 1227\n"
     ]
    }
   ],
   "source": [
    "# Check the submission file format\n",
    "sub = pd.read_csv('/home/submission/submission.csv')\n",
    "print('Submission shape:', sub.shape)\n",
    "print('Columns:', sub.columns.tolist())\n",
    "print('\\nTask 0 (single solvent):')\n",
    "print(f'  Folds: {sorted(sub[sub[\"task\"]==0][\"fold\"].unique())}')\n",
    "print(f'  Total rows: {len(sub[sub[\"task\"]==0])}')\n",
    "print('\\nTask 1 (full data):')\n",
    "print(f'  Folds: {sorted(sub[sub[\"task\"]==1][\"fold\"].unique())}')\n",
    "print(f'  Total rows: {len(sub[sub[\"task\"]==1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8cf7b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:01:59.553930Z",
     "iopub.status.busy": "2026-01-16T05:01:59.553813Z",
     "iopub.status.idle": "2026-01-16T05:01:59.560883Z",
     "shell.execute_reply": "2026-01-16T05:01:59.560474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value ranges:\n",
      "  target_1: [0.000000, 0.412037]\n",
      "  target_2: [0.000000, 0.414972]\n",
      "  target_3: [0.000000, 0.995417]\n",
      "\n",
      "Any NaN: 0\n",
      "Any Inf: 0\n",
      "Any negative: 0\n",
      "Any > 1: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for any issues with the predictions\n",
    "print('Target value ranges:')\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    print(f'  {col}: [{sub[col].min():.6f}, {sub[col].max():.6f}]')\n",
    "\n",
    "print('\\nAny NaN:', sub.isna().sum().sum())\n",
    "print('Any Inf:', (sub.select_dtypes(include='number').abs() == float('inf')).sum().sum())\n",
    "print('Any negative:', (sub[['target_1', 'target_2', 'target_3']] < 0).sum().sum())\n",
    "print('Any > 1:', (sub[['target_1', 'target_2', 'target_3']] > 1).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e53d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T05:01:59.562015Z",
     "iopub.status.busy": "2026-01-16T05:01:59.561902Z",
     "iopub.status.idle": "2026-01-16T05:01:59.564892Z",
     "shell.execute_reply": "2026-01-16T05:01:59.564490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: The submission format is correct.\n",
      "The error is likely from Kaggle's evaluation system, not our submission format.\n",
      "\n",
      "Possible causes:\n",
      "1. Kaggle evaluation system issue (temporary)\n",
      "2. Notebook structure issue (extra cells after final cell)\n",
      "3. Model definition issue (complex ensemble not compatible)\n",
      "\n",
      "Recommendation: Try a simpler model that matches the template exactly.\n"
     ]
    }
   ],
   "source": [
    "# The submission format looks correct. The error might be from Kaggle's evaluation system.\n",
    "# Let me check if there's a pattern in the failed submissions.\n",
    "\n",
    "# Failed submissions: exp_049, exp_050, exp_052, exp_053, exp_054, exp_055, exp_057, exp_063, exp_064, exp_065\n",
    "# All of these had \"Evaluation metric raised an unexpected error\"\n",
    "\n",
    "# Successful submissions: exp_000 through exp_035 (except some)\n",
    "# The last successful submission was exp_035 with LB 0.0970\n",
    "\n",
    "# What changed between exp_035 and exp_049?\n",
    "# - exp_035 was a simple MLP with Spange features\n",
    "# - exp_049+ were more complex ensembles\n",
    "\n",
    "print('Analysis: The submission format is correct.')\n",
    "print('The error is likely from Kaggle\\'s evaluation system, not our submission format.')\n",
    "print('\\nPossible causes:')\n",
    "print('1. Kaggle evaluation system issue (temporary)')\n",
    "print('2. Notebook structure issue (extra cells after final cell)')\n",
    "print('3. Model definition issue (complex ensemble not compatible)')\n",
    "print('\\nRecommendation: Try a simpler model that matches the template exactly.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
