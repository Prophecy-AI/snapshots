{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db38a040",
   "metadata": {},
   "source": [
    "# Loop 56 Analysis: Submission Failure Investigation\n",
    "\n",
    "**Goal:** Understand why the last submission failed with 'Evaluation metric raised an unexpected error'\n",
    "\n",
    "**Key Questions:**\n",
    "1. What's different about the failed submissions?\n",
    "2. Is there a format issue we're missing?\n",
    "3. What can we learn from successful submissions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the current submission\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "print('=== Current Submission Analysis ===')\n",
    "print(f'Total rows: {len(df)}')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "print()\n",
    "\n",
    "# Check fold distribution\n",
    "print('Task 0 (single solvent):')\n",
    "task0 = df[df['task'] == 0]\n",
    "print(f'  Total rows: {len(task0)}')\n",
    "print(f'  Unique folds: {task0[\"fold\"].nunique()}')\n",
    "print(f'  Fold range: {task0[\"fold\"].min()} to {task0[\"fold\"].max()}')\n",
    "print()\n",
    "\n",
    "print('Task 1 (full data):')\n",
    "task1 = df[df['task'] == 1]\n",
    "print(f'  Total rows: {len(task1)}')\n",
    "print(f'  Unique folds: {task1[\"fold\"].nunique()}')\n",
    "print(f'  Fold range: {task1[\"fold\"].min()} to {task1[\"fold\"].max()}')\n",
    "print()\n",
    "\n",
    "# Check for any issues\n",
    "print('Data quality check:')\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    nan_count = df[col].isna().sum()\n",
    "    inf_count = ((df[col] == float('inf')) | (df[col] == float('-inf'))).sum()\n",
    "    neg_count = (df[col] < 0).sum()\n",
    "    gt1_count = (df[col] > 1).sum()\n",
    "    print(f'  {col}: NaN={nan_count}, Inf={inf_count}, <0={neg_count}, >1={gt1_count}')\n",
    "    print(f'    min={df[col].min():.6f}, max={df[col].max():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Relationship Analysis\n",
    "# Based on 12 successful submissions\n",
    "\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_035', 0.0098, 0.0970),\n",
    "]\n",
    "\n",
    "cv_scores = [s[1] for s in submissions]\n",
    "lb_scores = [s[2] for s in submissions]\n",
    "\n",
    "# Fit linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array(cv_scores).reshape(-1, 1)\n",
    "y = np.array(lb_scores)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "print('=== CV-LB Relationship ===')\n",
    "print(f'Linear fit: LB = {reg.coef_[0]:.2f} * CV + {reg.intercept_:.4f}')\n",
    "print(f'R-squared = {reg.score(X, y):.4f}')\n",
    "print(f'Intercept = {reg.intercept_:.4f}')\n",
    "print(f'Target = 0.0347')\n",
    "print()\n",
    "\n",
    "# Calculate required CV to hit target\n",
    "if reg.coef_[0] > 0:\n",
    "    required_cv = (0.0347 - reg.intercept_) / reg.coef_[0]\n",
    "    print(f'Required CV to hit target: {required_cv:.6f}')\n",
    "    if required_cv < 0:\n",
    "        print('  WARNING: Required CV is NEGATIVE - target is UNREACHABLE with current approach!')\n",
    "print()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv_scores, lb_scores, c='blue', s=100, label='Submissions')\n",
    "plt.plot([0, 0.015], [reg.intercept_, reg.intercept_ + reg.coef_[0] * 0.015], 'r--', label=f'Fit: LB = {reg.coef_[0]:.2f}*CV + {reg.intercept_:.4f}')\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', label='Target (0.0347)')\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Plot saved to /home/code/exploration/cv_lb_relationship.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: The intercept (0.0528) is higher than the target (0.0347)\n",
    "# This means even with CV=0 (perfect training), the expected LB would be 0.0528\n",
    "# The target is MATHEMATICALLY UNREACHABLE with the current approach\n",
    "\n",
    "# However, the evolver says 'NEVER GIVE UP' - so we need to find a way to CHANGE the CV-LB relationship\n",
    "# This requires fundamentally different strategies that reduce the intercept\n",
    "\n",
    "print('=== CRITICAL ANALYSIS ===')\n",
    "print(f'Intercept: {reg.intercept_:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: {reg.intercept_ - 0.0347:.4f}')\n",
    "print()\n",
    "print('The intercept represents STRUCTURAL DISTRIBUTION SHIFT.')\n",
    "print('All model types (MLP, LGBM, XGB, GP, CatBoost) fall on the same line.')\n",
    "print('This means the gap is NOT due to model choice - it is due to extrapolation error.')\n",
    "print()\n",
    "print('To reach the target, we need to CHANGE the CV-LB relationship, not just improve CV.')\n",
    "print()\n",
    "print('Strategies to reduce the intercept:')\n",
    "print('1. Extrapolation detection features')\n",
    "print('2. Uncertainty-weighted predictions')\n",
    "print('3. Physics-informed constraints')\n",
    "print('4. Solvent clustering')\n",
    "print('5. Conservative predictions for outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91701f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check what the top public kernels are doing\n",
    "# The 'mixall' kernel uses GroupKFold (5 splits) instead of Leave-One-Out\n",
    "# This is a DIFFERENT CV scheme that may have a DIFFERENT CV-LB relationship\n",
    "\n",
    "# However, the evaluator says the last submission failed with 'Evaluation metric raised an unexpected error'\n",
    "# This suggests there's something wrong with the submission format, not just the CV scheme\n",
    "\n",
    "# Let me check if there's a pattern in the row counts per fold\n",
    "print('=== Row Counts Analysis ===')\n",
    "print('\\nTask 0 (single solvent) - Expected: 24 folds with varying row counts')\n",
    "for fold in sorted(task0['fold'].unique()):\n",
    "    fold_data = task0[task0['fold'] == fold]\n",
    "    print(f'  Fold {fold}: {len(fold_data)} rows')\n",
    "\n",
    "print('\\nTask 1 (full data) - Expected: 13 folds with varying row counts')\n",
    "for fold in sorted(task1['fold'].unique()):\n",
    "    fold_data = task1[task1['fold'] == fold]\n",
    "    print(f'  Fold {fold}: {len(fold_data)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify the submission format matches the official template exactly\n",
    "# The template produces:\n",
    "# - id: 0, 1, 2, ... (row index)\n",
    "# - index: 0, 1, 2, ... (original index before reset)\n",
    "# - task: 0 for single solvent, 1 for full data\n",
    "# - fold: fold index\n",
    "# - row: row index within the fold\n",
    "# - target_1, target_2, target_3: predictions\n",
    "\n",
    "print('=== Format Verification ===')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "print(f'Expected: [id, index, task, fold, row, target_1, target_2, target_3]')\n",
    "print()\n",
    "\n",
    "# Check if id is sequential\n",
    "print('ID check:')\n",
    "print(f'  id range: {df[\"id\"].min()} to {df[\"id\"].max()}')\n",
    "print(f'  id is sequential: {(df[\"id\"] == range(len(df))).all()}')\n",
    "print()\n",
    "\n",
    "# Check if index is correct\n",
    "print('Index check:')\n",
    "print(f'  Task 0 index range: {task0[\"index\"].min()} to {task0[\"index\"].max()}')\n",
    "print(f'  Task 1 index range: {task1[\"index\"].min()} to {task1[\"index\"].max()}')\n",
    "print()\n",
    "\n",
    "# Check if row is correct (should be 0, 1, 2, ... within each fold)\n",
    "print('Row check:')\n",
    "for task in [0, 1]:\n",
    "    task_data = df[df['task'] == task]\n",
    "    for fold in sorted(task_data['fold'].unique())[:3]:  # Check first 3 folds\n",
    "        fold_data = task_data[task_data['fold'] == fold]\n",
    "        expected_rows = list(range(len(fold_data)))\n",
    "        actual_rows = fold_data['row'].tolist()\n",
    "        if expected_rows == actual_rows:\n",
    "            print(f'  Task {task}, Fold {fold}: OK ({len(fold_data)} rows)')\n",
    "        else:\n",
    "            print(f'  Task {task}, Fold {fold}: MISMATCH!')\n",
    "            print(f'    Expected: {expected_rows[:5]}...')\n",
    "            print(f'    Actual: {actual_rows[:5]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26925f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and next steps\n",
    "print('=== SUMMARY ===')\n",
    "print()\n",
    "print('1. Submission format appears correct:')\n",
    "print('   - 1883 total rows (656 single + 1227 full)')\n",
    "print('   - 24 folds for task 0, 13 folds for task 1')\n",
    "print('   - All targets in [0, 1] range')\n",
    "print('   - No NaN or Inf values')\n",
    "print()\n",
    "print('2. CV-LB relationship:')\n",
    "print(f'   - LB = {reg.coef_[0]:.2f} * CV + {reg.intercept_:.4f}')\n",
    "print(f'   - Intercept ({reg.intercept_:.4f}) > Target (0.0347)')\n",
    "print('   - Target is UNREACHABLE with current approach')\n",
    "print()\n",
    "print('3. The submission failure may be due to:')\n",
    "print('   - Evaluation system issue (not our fault)')\n",
    "print('   - Some subtle format difference we are missing')\n",
    "print('   - The evaluation expects something specific we do not know about')\n",
    "print()\n",
    "print('4. Next steps:')\n",
    "print('   - Try submitting a known-working approach (e.g., from a public kernel)')\n",
    "print('   - Focus on strategies that CHANGE the CV-LB relationship')\n",
    "print('   - Do not just optimize CV - need to reduce the intercept')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
