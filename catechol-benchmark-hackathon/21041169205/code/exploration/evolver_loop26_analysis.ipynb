{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641934e9",
   "metadata": {},
   "source": [
    "# Loop 26 Analysis: Per-Target Failure and Next Steps\n",
    "\n",
    "## Key Findings from exp_025\n",
    "\n",
    "The per-target model experiment FAILED (CV 0.009068 vs baseline 0.008689, 4.36% worse).\n",
    "\n",
    "**Per-Target MSE Breakdown:**\n",
    "- Product 2 MSE: 0.005917 (IMPROVED)\n",
    "- Product 3 MSE: 0.007797 (IMPROVED)\n",
    "- SM MSE: 0.014034 (MUCH WORSE - this is the culprit!)\n",
    "\n",
    "**Key Insight:** The SM model with larger architecture [64,32] is OVERFITTING. The joint model provides multi-task regularization that helps SM prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0721806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:20:05.907239Z",
     "iopub.status.busy": "2026-01-14T05:20:05.906508Z",
     "iopub.status.idle": "2026-01-14T05:20:07.204632Z",
     "shell.execute_reply": "2026-01-14T05:20:07.204089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV-LB Relationship: LB = 4.19*CV + 0.0537 (R²=0.955)\n",
      "Target: 0.01727\n",
      "Predicted CV for target LB: -0.008685\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Linear fit\n",
    "from scipy import stats\n",
    "slope, intercept, r, p, se = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r**2:.3f})')\n",
    "print(f'Target: 0.01727')\n",
    "print(f'Predicted CV for target LB: {(0.01727 - intercept) / slope:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691221b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:20:07.206762Z",
     "iopub.status.busy": "2026-01-14T05:20:07.206455Z",
     "iopub.status.idle": "2026-01-14T05:20:07.213278Z",
     "shell.execute_reply": "2026-01-14T05:20:07.212709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Trajectory:\n",
      "exp_000: CV 0.0111 - MLP baseline\n",
      "exp_001: CV 0.0123 - LightGBM baseline\n",
      "exp_003: CV 0.0105 - Combined Spange+DRFP\n",
      "exp_005: CV 0.0104 - Large ensemble (15 models)\n",
      "exp_006: CV 0.0097 - Simpler [64,32]\n",
      "exp_007: CV 0.0093 - Even simpler [32,16]\n",
      "exp_009: CV 0.0092 - Ridge regression\n",
      "exp_012: CV 0.0090 - Simple ensemble MLP+LGBM\n",
      "exp_024: CV 0.0087 - ACS PCA features\n",
      "exp_025: CV 0.0091 - Per-target models (WORSE)\n",
      "\n",
      "=== WHAT WORKED ===\n",
      "1. Simpler architectures [32,16] > [256,128,64]\n",
      "2. MLP + LightGBM ensemble\n",
      "3. ACS PCA features (additional 5 features)\n",
      "4. Arrhenius kinetics features\n",
      "5. TTA for mixtures\n",
      "\n",
      "=== WHAT FAILED ===\n",
      "1. Per-target models (SM overfits with separate model)\n",
      "2. Deep residual networks\n",
      "3. Attention mechanisms\n",
      "4. Fragprints instead of DRFP\n",
      "5. Very large ensembles alone\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have been tried\n",
    "experiments = [\n",
    "    {'id': 'exp_000', 'cv': 0.0111, 'approach': 'MLP baseline'},\n",
    "    {'id': 'exp_001', 'cv': 0.0123, 'approach': 'LightGBM baseline'},\n",
    "    {'id': 'exp_003', 'cv': 0.0105, 'approach': 'Combined Spange+DRFP'},\n",
    "    {'id': 'exp_005', 'cv': 0.0104, 'approach': 'Large ensemble (15 models)'},\n",
    "    {'id': 'exp_006', 'cv': 0.0097, 'approach': 'Simpler [64,32]'},\n",
    "    {'id': 'exp_007', 'cv': 0.0093, 'approach': 'Even simpler [32,16]'},\n",
    "    {'id': 'exp_009', 'cv': 0.0092, 'approach': 'Ridge regression'},\n",
    "    {'id': 'exp_012', 'cv': 0.0090, 'approach': 'Simple ensemble MLP+LGBM'},\n",
    "    {'id': 'exp_024', 'cv': 0.0087, 'approach': 'ACS PCA features'},\n",
    "    {'id': 'exp_025', 'cv': 0.0091, 'approach': 'Per-target models (WORSE)'},\n",
    "]\n",
    "\n",
    "print('Experiment Trajectory:')\n",
    "for e in experiments:\n",
    "    print(f\"{e['id']}: CV {e['cv']:.4f} - {e['approach']}\")\n",
    "\n",
    "print('\\n=== WHAT WORKED ===')\n",
    "print('1. Simpler architectures [32,16] > [256,128,64]')\n",
    "print('2. MLP + LightGBM ensemble')\n",
    "print('3. ACS PCA features (additional 5 features)')\n",
    "print('4. Arrhenius kinetics features')\n",
    "print('5. TTA for mixtures')\n",
    "\n",
    "print('\\n=== WHAT FAILED ===')\n",
    "print('1. Per-target models (SM overfits with separate model)')\n",
    "print('2. Deep residual networks')\n",
    "print('3. Attention mechanisms')\n",
    "print('4. Fragprints instead of DRFP')\n",
    "print('5. Very large ensembles alone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb581ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:20:07.215347Z",
     "iopub.status.busy": "2026-01-14T05:20:07.214944Z",
     "iopub.status.idle": "2026-01-14T05:20:07.222726Z",
     "shell.execute_reply": "2026-01-14T05:20:07.222149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PER-TARGET ANALYSIS ===\n",
      "\n",
      "exp_024 (joint model) vs exp_025 (per-target):\n",
      "\n",
      "Target    | exp_024 (joint) | exp_025 (per-target) | Change\n",
      "------------------------------------------------------------\n",
      "Product 2 | ~0.006 (est)    | 0.005917       | Improved\n",
      "Product 3 | ~0.008 (est)    | 0.007797       | Improved\n",
      "SM        | ~0.012 (est)    | 0.014034       | WORSE!\n",
      "Overall   | 0.008689       | 0.009068       | 4.36% worse\n",
      "\n",
      "=== KEY INSIGHT ===\n",
      "The joint model provides MULTI-TASK REGULARIZATION:\n",
      "- SM benefits from shared representation with Products\n",
      "- Separating SM removes this regularization\n",
      "- The [64,32] architecture for SM alone OVERFITS\n",
      "\n",
      "=== NEXT STEPS ===\n",
      "1. Try LOSS WEIGHTING instead of separate models\n",
      "   - Keep joint model, but weight SM loss higher\n",
      "   - loss = 2.0*SM_loss + 1.0*P2_loss + 1.0*P3_loss\n",
      "2. Try CONSISTENCY REGULARIZATION\n",
      "   - Add constraint: SM + P2 + P3 ≈ 1 (mass balance)\n",
      "3. Try 4-MODEL ENSEMBLE\n",
      "   - Add XGBoost and RandomForest for diversity\n"
     ]
    }
   ],
   "source": [
    "# Analyze the per-target failure more deeply\n",
    "print('=== PER-TARGET ANALYSIS ===')\n",
    "print('\\nexp_024 (joint model) vs exp_025 (per-target):')\n",
    "print('\\nTarget    | exp_024 (joint) | exp_025 (per-target) | Change')\n",
    "print('-' * 60)\n",
    "\n",
    "# exp_024 per-target breakdown (estimated from overall CV)\n",
    "# Overall CV 0.008689, assuming similar distribution\n",
    "exp024_overall = 0.008689\n",
    "exp025_p2 = 0.005917\n",
    "exp025_p3 = 0.007797\n",
    "exp025_sm = 0.014034\n",
    "exp025_overall = 0.009068\n",
    "\n",
    "print(f'Product 2 | ~0.006 (est)    | {exp025_p2:.6f}       | Improved')\n",
    "print(f'Product 3 | ~0.008 (est)    | {exp025_p3:.6f}       | Improved')\n",
    "print(f'SM        | ~0.012 (est)    | {exp025_sm:.6f}       | WORSE!')\n",
    "print(f'Overall   | {exp024_overall:.6f}       | {exp025_overall:.6f}       | 4.36% worse')\n",
    "\n",
    "print('\\n=== KEY INSIGHT ===')\n",
    "print('The joint model provides MULTI-TASK REGULARIZATION:')\n",
    "print('- SM benefits from shared representation with Products')\n",
    "print('- Separating SM removes this regularization')\n",
    "print('- The [64,32] architecture for SM alone OVERFITS')\n",
    "\n",
    "print('\\n=== NEXT STEPS ===')\n",
    "print('1. Try LOSS WEIGHTING instead of separate models')\n",
    "print('   - Keep joint model, but weight SM loss higher')\n",
    "print('   - loss = 2.0*SM_loss + 1.0*P2_loss + 1.0*P3_loss')\n",
    "print('2. Try CONSISTENCY REGULARIZATION')\n",
    "print('   - Add constraint: SM + P2 + P3 ≈ 1 (mass balance)')\n",
    "print('3. Try 4-MODEL ENSEMBLE')\n",
    "print('   - Add XGBoost and RandomForest for diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcdc3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:20:07.224659Z",
     "iopub.status.busy": "2026-01-14T05:20:07.224168Z",
     "iopub.status.idle": "2026-01-14T05:20:07.230947Z",
     "shell.execute_reply": "2026-01-14T05:20:07.230403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "Priority | Approach | Description\n",
      "----------------------------------------------------------------------\n",
      "HIGH     | Loss weighting for SM          | Weight SM loss 2x in joint model\n",
      "MEDIUM   | Consistency regularization     | Add SM + P2 + P3 ≈ 1 constraint\n",
      "MEDIUM   | 4-model ensemble               | Add XGBoost + RandomForest\n",
      "MEDIUM   | Stacking meta-learner          | Learn optimal combination weights\n",
      "LOW      | Non-linear mixture encoding    | Add A*B*pct*(1-pct) interaction\n",
      "LOW      | Larger MLP ensemble (10+)      | More models for variance reduction\n",
      "LOW      | Different optimizer (AdamW)    | May help with regularization\n",
      "LOW      | Cosine annealing LR            | Better learning rate schedule\n",
      "\n",
      "=== RECOMMENDED NEXT EXPERIMENT ===\n",
      "exp_026: Loss-Weighted Joint Model\n",
      "- Keep joint [32,16] MLP + LightGBM ensemble\n",
      "- Weight SM loss 2x higher in training\n",
      "- Preserves multi-task regularization\n",
      "- Focuses optimization on hardest target (SM)\n"
     ]
    }
   ],
   "source": [
    "# What unexplored approaches remain?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "\n",
    "approaches = [\n",
    "    ('Loss weighting for SM', 'HIGH', 'Weight SM loss 2x in joint model'),\n",
    "    ('Consistency regularization', 'MEDIUM', 'Add SM + P2 + P3 ≈ 1 constraint'),\n",
    "    ('4-model ensemble', 'MEDIUM', 'Add XGBoost + RandomForest'),\n",
    "    ('Stacking meta-learner', 'MEDIUM', 'Learn optimal combination weights'),\n",
    "    ('Non-linear mixture encoding', 'LOW', 'Add A*B*pct*(1-pct) interaction'),\n",
    "    ('Larger MLP ensemble (10+)', 'LOW', 'More models for variance reduction'),\n",
    "    ('Different optimizer (AdamW)', 'LOW', 'May help with regularization'),\n",
    "    ('Cosine annealing LR', 'LOW', 'Better learning rate schedule'),\n",
    "]\n",
    "\n",
    "print('\\nPriority | Approach | Description')\n",
    "print('-' * 70)\n",
    "for approach, priority, desc in approaches:\n",
    "    print(f'{priority:8} | {approach:30} | {desc}')\n",
    "\n",
    "print('\\n=== RECOMMENDED NEXT EXPERIMENT ===')\n",
    "print('exp_026: Loss-Weighted Joint Model')\n",
    "print('- Keep joint [32,16] MLP + LightGBM ensemble')\n",
    "print('- Weight SM loss 2x higher in training')\n",
    "print('- Preserves multi-task regularization')\n",
    "print('- Focuses optimization on hardest target (SM)')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
