{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e70841",
   "metadata": {},
   "source": [
    "# Loop 47 Analysis: CV-LB Relationship and Next Steps\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the current CV-LB relationship?\n",
    "2. What techniques from top kernels haven't been tried?\n",
    "3. What is the most promising path forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290dfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'CV': 0.0111, 'LB': 0.0982},\n",
    "    {'exp': 'exp_001', 'CV': 0.0123, 'LB': 0.1065},\n",
    "    {'exp': 'exp_003', 'CV': 0.0105, 'LB': 0.0972},\n",
    "    {'exp': 'exp_005', 'CV': 0.0104, 'LB': 0.0969},\n",
    "    {'exp': 'exp_006', 'CV': 0.0097, 'LB': 0.0946},\n",
    "    {'exp': 'exp_007', 'CV': 0.0093, 'LB': 0.0932},\n",
    "    {'exp': 'exp_009', 'CV': 0.0092, 'LB': 0.0936},\n",
    "    {'exp': 'exp_012', 'CV': 0.0090, 'LB': 0.0913},\n",
    "    {'exp': 'exp_024', 'CV': 0.0087, 'LB': 0.0893},\n",
    "    {'exp': 'exp_026', 'CV': 0.0085, 'LB': 0.0887},\n",
    "    {'exp': 'exp_030', 'CV': 0.0083, 'LB': 0.0877},\n",
    "    {'exp': 'exp_035', 'CV': 0.0098, 'LB': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nBest CV: {df['CV'].min():.4f} (exp_030)\")\n",
    "print(f\"Best LB: {df['LB'].min():.4f} (exp_030)\")\n",
    "print(f\"Target: 0.0347\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Relationship Analysis\n",
    "cv = df['CV'].values\n",
    "lb = df['LB'].values\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(\"CV-LB Linear Regression:\")\n",
    "print(f\"  LB = {slope:.4f} * CV + {intercept:.4f}\")\n",
    "print(f\"  R² = {r_value**2:.4f}\")\n",
    "print(f\"  Intercept = {intercept:.4f}\")\n",
    "print(f\"  Target = 0.0347\")\n",
    "print(f\"  Gap: Intercept - Target = {intercept - 0.0347:.4f}\")\n",
    "print()\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f\"Required CV to reach target: {required_cv:.4f}\")\n",
    "if required_cv < 0:\n",
    "    print(\"  -> IMPOSSIBLE with current approach (negative CV required)\")\n",
    "else:\n",
    "    print(f\"  -> Need to improve CV from {df['CV'].min():.4f} to {required_cv:.4f}\")\n",
    "    print(f\"  -> Improvement needed: {(df['CV'].min() - required_cv) / df['CV'].min() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV-LB relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cv, lb, s=100, c='blue', alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.2f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='green', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept point\n",
    "plt.scatter([0], [intercept], s=200, c='red', marker='x', label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score (MSE)')\n",
    "plt.ylabel('LB Score (MSE)')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop47.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(f\"  Intercept ({intercept:.4f}) > Target ({0.0347})\")\n",
    "print(f\"  This means even with CV=0, we'd still be {(intercept - 0.0347) / 0.0347 * 100:.1f}% above target\")\n",
    "print(f\"  We need to CHANGE THE RELATIONSHIP, not just improve CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76736efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: What techniques from top kernels haven't been tried?\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TECHNIQUES FROM TOP KERNELS NOT YET FULLY IMPLEMENTED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. NON-LINEAR MIXTURE FORMULA (gentilless kernel)\")\n",
    "print(\"   Current: mixture = (1 - r) * A + r * B\")\n",
    "print(\"   Better:  mixture = A * (1 - r) + B * r + 0.05 * A * B * r * (1 - r)\")\n",
    "print(\"   Status: Partially tried in exp_043, but not with full feature engineering\")\n",
    "\n",
    "print(\"\\n2. ADVANCED FEATURE ENGINEERING (gentilless kernel)\")\n",
    "print(\"   - Polynomial features: X^2, sqrt(|X|)\")\n",
    "print(\"   - Interaction terms: X1*X2, X1*X3, X2*X3\")\n",
    "print(\"   - Statistical features from molecular descriptors: mean, std, max, min\")\n",
    "print(\"   Status: NOT IMPLEMENTED\")\n",
    "\n",
    "print(\"\\n3. STRONGER HYPERPARAMETERS (gentilless kernel)\")\n",
    "print(\"   - CatBoost: 12000 iterations, depth=9, early_stop=250\")\n",
    "print(\"   - XGBoost: 12000 rounds, eta=0.02, depth=9\")\n",
    "print(\"   - LightGBM: 12000 rounds, lr=0.015, leaves=127\")\n",
    "print(\"   - Neural Network: 800 epochs, hidden=[768, 512, 384, 256, 128]\")\n",
    "print(\"   Status: NOT IMPLEMENTED (we used 200 estimators, 100 epochs)\")\n",
    "\n",
    "print(\"\\n4. SE ATTENTION BLOCKS (gentilless kernel)\")\n",
    "print(\"   - Squeeze-and-Excitation blocks for feature recalibration\")\n",
    "print(\"   - Residual blocks with LayerNorm and GELU\")\n",
    "print(\"   Status: NOT IMPLEMENTED\")\n",
    "\n",
    "print(\"\\n5. ADAPTIVE ENSEMBLE WEIGHTING (gentilless kernel)\")\n",
    "print(\"   - Weight models inversely proportional to validation MSE^2.5\")\n",
    "print(\"   - Boost NN importance by 1.15x\")\n",
    "print(\"   Status: NOT IMPLEMENTED (we used fixed weights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5409c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the most promising path forward?\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RECOMMENDED NEXT STEPS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nPRIORITY 1: Full Implementation of gentilless Kernel Techniques\")\n",
    "print(\"-\" * 50)\n",
    "print(\"The gentilless kernel has several techniques we haven't tried:\")\n",
    "print(\"  1. Non-linear mixture formula with interaction term\")\n",
    "print(\"  2. Advanced feature engineering (polynomial, interaction, statistical)\")\n",
    "print(\"  3. Much stronger hyperparameters (60x more iterations)\")\n",
    "print(\"  4. SE attention blocks in neural networks\")\n",
    "print(\"  5. Adaptive ensemble weighting\")\n",
    "print()\n",
    "print(\"HYPOTHESIS: These techniques may CHANGE the CV-LB relationship,\")\n",
    "print(\"            not just improve CV. The intercept may decrease.\")\n",
    "\n",
    "print(\"\\nPRIORITY 2: CatBoost (Not Yet Tried)\")\n",
    "print(\"-\" * 50)\n",
    "print(\"The gentilless kernel uses CatBoost as one of its models.\")\n",
    "print(\"We haven't tried CatBoost yet. It may have different behavior.\")\n",
    "\n",
    "print(\"\\nPRIORITY 3: Uncertainty-Weighted Predictions\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Use ensemble variance as uncertainty proxy.\")\n",
    "print(\"When uncertainty is high, blend toward population mean.\")\n",
    "print(\"This may help with extrapolation to unseen solvents.\")\n",
    "\n",
    "print(\"\\nWHAT NOT TO TRY:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"  - Simple model diversity (exp_046 showed this doesn't help)\")\n",
    "print(\"  - Mean reversion (exp_045 showed this hurts CV)\")\n",
    "print(\"  - GNN (exp_040 failed with 8.4x worse MSE)\")\n",
    "print(\"  - ChemBERTa embeddings (exp_041 failed)\")\n",
    "print(\"  - Learned embeddings (exp_039 failed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nCurrent State:\")\n",
    "print(f\"  Best CV: {df['CV'].min():.4f} (exp_030)\")\n",
    "print(f\"  Best LB: {df['LB'].min():.4f} (exp_030)\")\n",
    "print(f\"  Target: 0.0347\")\n",
    "print(f\"  Gap: {(df['LB'].min() - 0.0347) / 0.0347 * 100:.1f}% above target\")\n",
    "\n",
    "print(f\"\\nCV-LB Relationship:\")\n",
    "print(f\"  LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"  Intercept ({intercept:.4f}) > Target (0.0347)\")\n",
    "print(f\"  -> Current approach CANNOT reach target\")\n",
    "\n",
    "print(f\"\\nKey Insight:\")\n",
    "print(f\"  The sophisticated ensemble (exp_046) was 17.82% WORSE than baseline.\")\n",
    "print(f\"  Simply adding more model types doesn't help.\")\n",
    "print(f\"  We need to implement the FULL pipeline from top kernels:\")\n",
    "print(f\"    - Advanced feature engineering\")\n",
    "print(f\"    - Stronger hyperparameters\")\n",
    "print(f\"    - SE attention blocks\")\n",
    "print(f\"    - Adaptive ensemble weighting\")\n",
    "\n",
    "print(f\"\\nSubmissions Remaining: 5\")\n",
    "print(f\"  -> Use wisely for high-leverage experiments\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
