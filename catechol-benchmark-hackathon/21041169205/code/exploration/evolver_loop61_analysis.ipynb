{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8506056b",
   "metadata": {},
   "source": [
    "# Loop 61 Analysis: CV-LB Relationship and Strategy Review\n",
    "\n",
    "**Critical Situation:**\n",
    "- 7 consecutive submissions have failed with 'Evaluation metric raised an unexpected error'\n",
    "- Best LB: 0.0877 (exp_030), Target: 0.0347\n",
    "- Gap to target: 153%\n",
    "- Only 5 submissions remaining today\n",
    "\n",
    "**Key Questions:**\n",
    "1. Why are recent submissions failing?\n",
    "2. What's the CV-LB relationship?\n",
    "3. What strategies can change the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history with confirmed LB scores\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.09816),\n",
    "    ('exp_001', 0.012297, 0.10649),\n",
    "    ('exp_003', 0.010501, 0.09719),\n",
    "    ('exp_005', 0.010430, 0.09691),\n",
    "    ('exp_006', 0.009749, 0.09457),\n",
    "    ('exp_007', 0.009262, 0.09316),\n",
    "    ('exp_009', 0.009192, 0.09364),\n",
    "    ('exp_012', 0.009004, 0.09134),\n",
    "    ('exp_024', 0.008689, 0.08929),\n",
    "    ('exp_026', 0.008465, 0.08875),\n",
    "    ('exp_030', 0.008298, 0.08772),\n",
    "    ('exp_035', 0.009825, 0.09696),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp', 'cv', 'lb'])\n",
    "print('Successful submissions with LB scores:')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.6f} ({df.loc[df[\"cv\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.6f} ({df.loc[df[\"lb\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB Linear Regression Analysis\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "\n",
    "print('='*60)\n",
    "print('CV-LB RELATIONSHIP ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'\\nLinear fit: LB = {slope:.4f} * CV + {intercept:.6f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.6f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "print(f'\\nCRITICAL: Intercept ({intercept:.6f}) > Target ({0.0347:.6f})?', intercept > 0.0347)\n",
    "\n",
    "# Required CV to hit target\n",
    "if slope > 0:\n",
    "    required_cv = (0.0347 - intercept) / slope\n",
    "    print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "    if required_cv < 0:\n",
    "        print('  --> NEGATIVE! Target is mathematically unreachable with current approach!')\n",
    "    else:\n",
    "        print(f'  --> Need to reduce CV from {df[\"cv\"].min():.6f} to {required_cv:.6f}')\n",
    "        print(f'  --> That\\'s a {(df[\"cv\"].min() - required_cv) / df[\"cv\"].min() * 100:.1f}% improvement needed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad24111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['cv'], df['lb'], s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, df['cv'].max() * 1.1, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Intercept\n",
    "plt.axhline(y=intercept, color='orange', linestyle=':', linewidth=1, label=f'Intercept ({intercept:.4f})')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop61.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print('\\nPlot saved to /home/code/exploration/cv_lb_relationship_loop61.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the failed submissions\n",
    "print('='*60)\n",
    "print('FAILED SUBMISSIONS ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "failed_submissions = [\n",
    "    ('exp_049', 0.008092, 'CatBoost+XGBoost'),\n",
    "    ('exp_050', 0.008092, 'CatBoost+XGBoost fixed'),\n",
    "    ('exp_052', 0.010880, 'CatBoost+XGBoost clipped'),\n",
    "    ('exp_053', 0.008092, 'Exact template'),\n",
    "    ('exp_054', 0.008504, 'Mixall approach'),\n",
    "    ('exp_055', 0.008504, 'Minimal submission'),\n",
    "    ('exp_057', 0.009263, 'Ens-model all features'),\n",
    "]\n",
    "\n",
    "print('\\nAll 7 failed with: \"Evaluation metric raised an unexpected error\"')\n",
    "print('\\nFailed experiments:')\n",
    "for exp, cv, desc in failed_submissions:\n",
    "    print(f'  {exp}: CV={cv:.6f} - {desc}')\n",
    "\n",
    "print('\\nPossible causes:')\n",
    "print('  1. Submission format mismatch')\n",
    "print('  2. NaN or Inf values in predictions')\n",
    "print('  3. Wrong number of rows/folds')\n",
    "print('  4. Data type issues (float32 vs float64)')\n",
    "print('  5. Kaggle platform issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010516b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last successful submission (exp_030) vs recent failed ones\n",
    "import os\n",
    "\n",
    "print('='*60)\n",
    "print('COMPARING SUBMISSION FILES')\n",
    "print('='*60)\n",
    "\n",
    "# Check if we have the submission file\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "if os.path.exists(submission_path):\n",
    "    sub = pd.read_csv(submission_path)\n",
    "    print(f'\\nCurrent submission file:')\n",
    "    print(f'  Shape: {sub.shape}')\n",
    "    print(f'  Columns: {sub.columns.tolist()}')\n",
    "    print(f'  Task 0 (single solvent) rows: {len(sub[sub[\"task\"]==0])}')\n",
    "    print(f'  Task 1 (full data) rows: {len(sub[sub[\"task\"]==1])}')\n",
    "    print(f'  Unique folds task 0: {sub[sub[\"task\"]==0][\"fold\"].nunique()}')\n",
    "    print(f'  Unique folds task 1: {sub[sub[\"task\"]==1][\"fold\"].nunique()}')\n",
    "    print(f'\\n  Target columns:')\n",
    "    for col in ['target_1', 'target_2', 'target_3']:\n",
    "        print(f'    {col}: min={sub[col].min():.6f}, max={sub[col].max():.6f}, NaN={sub[col].isna().sum()}')\n",
    "    print(f'\\n  First few rows:')\n",
    "    print(sub.head(10).to_string())\n",
    "else:\n",
    "    print('No submission file found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check exp_030 submission (last successful one)\n",
    "exp030_path = '/home/code/experiments/030_gp_ensemble'\n",
    "print('='*60)\n",
    "print('EXP_030 (LAST SUCCESSFUL SUBMISSION) ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "if os.path.exists(exp030_path):\n",
    "    files = os.listdir(exp030_path)\n",
    "    print(f'\\nFiles in exp_030: {files}')\n",
    "    \n",
    "    # Check if there's a submission file\n",
    "    for f in files:\n",
    "        if 'submission' in f.lower() or f.endswith('.csv'):\n",
    "            fpath = os.path.join(exp030_path, f)\n",
    "            df_exp030 = pd.read_csv(fpath)\n",
    "            print(f'\\n{f}:')\n",
    "            print(f'  Shape: {df_exp030.shape}')\n",
    "            print(f'  Columns: {df_exp030.columns.tolist()}')\n",
    "else:\n",
    "    print('exp_030 folder not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What's different about exp_030?\n",
    "print('='*60)\n",
    "print('KEY DIFFERENCES BETWEEN SUCCESSFUL AND FAILED SUBMISSIONS')\n",
    "print('='*60)\n",
    "\n",
    "print('\\nexp_030 (SUCCESSFUL - LB 0.0877):')\n",
    "print('  - GP + MLP + LGBM ensemble')\n",
    "print('  - CV: 0.008298')\n",
    "print('  - Used official template structure')\n",
    "print('  - Spange + Arrhenius features')\n",
    "\n",
    "print('\\nexp_049-057 (ALL FAILED):')\n",
    "print('  - Various models (CatBoost, XGBoost, etc.)')\n",
    "print('  - CV: 0.008092-0.010880')\n",
    "print('  - All failed with same error')\n",
    "\n",
    "print('\\nHYPOTHESIS:')\n",
    "print('  The submission format appears correct (1883 rows, correct folds).')\n",
    "print('  The error might be related to:')\n",
    "print('  1. Notebook structure changes (cells modified beyond allowed)')\n",
    "print('  2. Some subtle format issue in the CSV')\n",
    "print('  3. Kaggle platform issue (unlikely for 7 consecutive)')\n",
    "\n",
    "print('\\nRECOMMENDATION:')\n",
    "print('  1. Use exp_030 notebook as base (known working)')\n",
    "print('  2. Only change the model definition line')\n",
    "print('  3. Do NOT modify any other cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's needed to reach target\n",
    "print('='*60)\n",
    "print('PATH TO TARGET ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "target = 0.0347\n",
    "best_lb = 0.0877\n",
    "gap = best_lb - target\n",
    "gap_pct = gap / target * 100\n",
    "\n",
    "print(f'\\nTarget: {target}')\n",
    "print(f'Best LB: {best_lb}')\n",
    "print(f'Gap: {gap:.4f} ({gap_pct:.1f}%)')\n",
    "\n",
    "print(f'\\nCV-LB Relationship: LB = {slope:.4f} * CV + {intercept:.6f}')\n",
    "print(f'Intercept: {intercept:.6f}')\n",
    "\n",
    "print('\\nTwo paths to target:')\n",
    "print('\\n1. IMPROVE CV (keep same relationship):')\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'   Required CV: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('   --> IMPOSSIBLE: Would need negative CV!')\n",
    "else:\n",
    "    print(f'   --> Need {(df[\"cv\"].min() - required_cv) / df[\"cv\"].min() * 100:.1f}% CV improvement')\n",
    "\n",
    "print('\\n2. REDUCE INTERCEPT (change the relationship):')\n",
    "print(f'   Current intercept: {intercept:.6f}')\n",
    "print(f'   If intercept = 0, with best CV ({df[\"cv\"].min():.6f}):')\n",
    "print(f'   --> Predicted LB = {slope * df[\"cv\"].min():.6f}')\n",
    "print(f'   --> Still above target ({target})')\n",
    "\n",
    "print('\\n3. BOTH: Reduce intercept AND improve CV:')\n",
    "print('   Need to fundamentally change the approach')\n",
    "print('   - Extrapolation detection (tried, not working well)')\n",
    "print('   - Uncertainty-weighted predictions')\n",
    "print('   - Domain constraints')\n",
    "print('   - Study what top public kernels do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check public kernel scores\n",
    "print('='*60)\n",
    "print('PUBLIC KERNEL ANALYSIS')\n",
    "print('='*60)\n",
    "\n",
    "kernels = [\n",
    "    ('mixall', 'lishellliang', 'GroupKFold(5) instead of LOO'),\n",
    "    ('ens-model', 'matthewmaree', 'CatBoost+XGBoost, all features'),\n",
    "    ('catechol-strategy', 'dabansherwani', 'Strategy to get 0.11161'),\n",
    "    ('arrhenius-kinetics', 'sanidhyavijay24', 'Arrhenius kinetics + TTA'),\n",
    "]\n",
    "\n",
    "print('\\nTop public kernels:')\n",
    "for name, author, desc in kernels:\n",
    "    print(f'  {name} ({author}): {desc}')\n",
    "\n",
    "print('\\nKey insights from public kernels:')\n",
    "print('  1. mixall uses GroupKFold(5) - different CV scheme')\n",
    "print('  2. ens-model combines ALL feature sets with correlation filtering')\n",
    "print('  3. Both use CatBoost + XGBoost ensemble')\n",
    "print('  4. Neither has achieved sub-0.07 LB')\n",
    "\n",
    "print('\\nIMPORTANT: The target (0.0347) may be based on:')\n",
    "print('  - A different evaluation metric')\n",
    "print('  - A different test set')\n",
    "print('  - An internal benchmark not achievable by public methods')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
