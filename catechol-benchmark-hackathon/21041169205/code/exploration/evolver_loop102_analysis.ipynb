{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45f35db",
   "metadata": {},
   "source": [
    "# Loop 102 Analysis: CV-LB Relationship and Strategy Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the exact CV-LB relationship from all submissions?\n",
    "2. What approaches have been tried and what patterns emerge?\n",
    "3. What is the gap to target and what would it take to close it?\n",
    "4. What approaches have NOT been tried that could change the CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'CV': 0.0111, 'LB': 0.0982},\n",
    "    {'exp': 'exp_001', 'CV': 0.0123, 'LB': 0.1065},\n",
    "    {'exp': 'exp_003', 'CV': 0.0105, 'LB': 0.0972},\n",
    "    {'exp': 'exp_005', 'CV': 0.0104, 'LB': 0.0969},\n",
    "    {'exp': 'exp_006', 'CV': 0.0097, 'LB': 0.0946},\n",
    "    {'exp': 'exp_007', 'CV': 0.0093, 'LB': 0.0932},\n",
    "    {'exp': 'exp_009', 'CV': 0.0092, 'LB': 0.0936},\n",
    "    {'exp': 'exp_012', 'CV': 0.0090, 'LB': 0.0913},\n",
    "    {'exp': 'exp_024', 'CV': 0.0087, 'LB': 0.0893},\n",
    "    {'exp': 'exp_026', 'CV': 0.0085, 'LB': 0.0887},\n",
    "    {'exp': 'exp_030', 'CV': 0.0083, 'LB': 0.0877},\n",
    "    {'exp': 'exp_035', 'CV': 0.0098, 'LB': 0.0970},\n",
    "    {'exp': 'exp_067', 'CV': 0.0083, 'LB': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submissions with LB scores:')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nTotal submissions with LB: {len(df)}')\n",
    "print(f'Best CV: {df[\"CV\"].min():.6f} ({df.loc[df[\"CV\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"LB\"].min():.6f} ({df.loc[df[\"LB\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: LB = slope * CV + intercept\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['CV'], df['LB'])\n",
    "\n",
    "print('=== CV-LB LINEAR REGRESSION ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.6f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Standard Error: {std_err:.4f}')\n",
    "print(f'\\nInterpretation:')\n",
    "print(f'  - Intercept ({intercept:.6f}) represents the STRUCTURAL GAP')\n",
    "print(f'  - Even at CV=0, expected LB would be {intercept:.6f}')\n",
    "print(f'  - Target is 0.0347')\n",
    "print(f'  - Intercept ({intercept:.6f}) > Target (0.0347)? {intercept > 0.0347}')\n",
    "\n",
    "# Required CV to hit target\n",
    "if slope > 0:\n",
    "    required_cv = (0.0347 - intercept) / slope\n",
    "    print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "    if required_cv < 0:\n",
    "        print('  -> IMPOSSIBLE with current CV-LB relationship!')\n",
    "    else:\n",
    "        print(f'  -> Need to reduce CV from {df[\"CV\"].min():.6f} to {required_cv:.6f}')\n",
    "        print(f'  -> Improvement needed: {(df[\"CV\"].min() - required_cv) / df[\"CV\"].min() * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4037060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['CV'], df['LB'], s=100, alpha=0.7, label='Submissions')\n",
    "\n",
    "# Regression line\n",
    "cv_range = np.linspace(0, df['CV'].max() * 1.1, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target (0.0347)')\n",
    "\n",
    "# Best LB point\n",
    "best_idx = df['LB'].idxmin()\n",
    "plt.scatter(df.loc[best_idx, 'CV'], df.loc[best_idx, 'LB'], s=200, c='red', marker='*', label=f'Best LB: {df.loc[best_idx, \"LB\"]:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score')\n",
    "plt.ylabel('LB Score')\n",
    "plt.title('CV vs LB Relationship - All Submissions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/cv_lb_relationship_loop102.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nGap Analysis:')\n",
    "print(f'  Best LB: {df[\"LB\"].min():.4f}')\n",
    "print(f'  Target: 0.0347')\n",
    "print(f'  Gap: {df[\"LB\"].min() - 0.0347:.4f} ({(df[\"LB\"].min() - 0.0347) / 0.0347 * 100:.1f}% above target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b601c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - are there any outliers that beat the line?\n",
    "df['predicted_LB'] = slope * df['CV'] + intercept\n",
    "df['residual'] = df['LB'] - df['predicted_LB']\n",
    "\n",
    "print('=== RESIDUAL ANALYSIS ===')\n",
    "print('Looking for experiments that beat the CV-LB line (negative residuals):')\n",
    "print(df[['exp', 'CV', 'LB', 'predicted_LB', 'residual']].sort_values('residual').to_string(index=False))\n",
    "\n",
    "print(f'\\nMean residual: {df[\"residual\"].mean():.6f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.6f}')\n",
    "\n",
    "# Any experiments significantly below the line?\n",
    "below_line = df[df['residual'] < -df['residual'].std()]\n",
    "if len(below_line) > 0:\n",
    "    print(f'\\nExperiments significantly below the line (residual < -1 std):')\n",
    "    print(below_line[['exp', 'CV', 'LB', 'residual']].to_string(index=False))\n",
    "else:\n",
    "    print('\\nNo experiments significantly below the line - all follow the same CV-LB relationship.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to beat the target?\n",
    "print('=== STRATEGIES TO BEAT TARGET ===')\n",
    "print(f'\\nTarget: 0.0347')\n",
    "print(f'Current best LB: {df[\"LB\"].min():.4f}')\n",
    "print(f'Gap: {df[\"LB\"].min() - 0.0347:.4f} ({(df[\"LB\"].min() / 0.0347 - 1) * 100:.1f}% above target)')\n",
    "\n",
    "print(f'\\n1. REDUCE CV (stay on same line):')\n",
    "print(f'   Required CV: {(0.0347 - intercept) / slope:.6f}')\n",
    "print(f'   This is IMPOSSIBLE (negative CV)')\n",
    "\n",
    "print(f'\\n2. REDUCE INTERCEPT (change the CV-LB relationship):')\n",
    "print(f'   Current intercept: {intercept:.6f}')\n",
    "print(f'   Required intercept (at best CV {df[\"CV\"].min():.6f}): {0.0347 - slope * df[\"CV\"].min():.6f}')\n",
    "print(f'   Intercept reduction needed: {intercept - (0.0347 - slope * df[\"CV\"].min()):.6f}')\n",
    "\n",
    "print(f'\\n3. REDUCE SLOPE (make CV improvements more impactful):')\n",
    "print(f'   Current slope: {slope:.4f}')\n",
    "print(f'   At current intercept, even CV=0 gives LB={intercept:.4f}')\n",
    "print(f'   Slope reduction alone cannot help if intercept > target')\n",
    "\n",
    "print(f'\\n4. COMBINATION: Reduce both intercept AND improve CV')\n",
    "print(f'   This is the most realistic path forward')\n",
    "print(f'   Need approaches that CHANGE the CV-LB relationship, not just optimize CV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "print('=== APPROACHES TRIED (from session_state) ===')\n",
    "approaches = [\n",
    "    ('MLP with Arrhenius kinetics', 'exp_000', 0.0111, 0.0982),\n",
    "    ('LightGBM', 'exp_001', 0.0123, 0.1065),\n",
    "    ('Combined Spange+DRFP', 'exp_003', 0.0105, 0.0972),\n",
    "    ('Large ensemble (15 models)', 'exp_005', 0.0104, 0.0969),\n",
    "    ('Simpler model [64,32]', 'exp_006', 0.0097, 0.0946),\n",
    "    ('Even simpler [32,16]', 'exp_007', 0.0093, 0.0932),\n",
    "    ('Ridge regression', 'exp_009', 0.0092, 0.0936),\n",
    "    ('Simple ensemble', 'exp_012', 0.0090, 0.0913),\n",
    "    ('ACS PCA features', 'exp_024', 0.0087, 0.0893),\n",
    "    ('Weighted loss', 'exp_026', 0.0085, 0.0887),\n",
    "    ('GP+MLP+LGBM ensemble', 'exp_030', 0.0083, 0.0877),\n",
    "    ('Lower GP weight', 'exp_035', 0.0098, 0.0970),\n",
    "    ('Sigmoid output', 'exp_067', 0.0083, 0.0877),\n",
    "]\n",
    "\n",
    "for name, exp, cv, lb in approaches:\n",
    "    print(f'{exp}: {name} - CV={cv:.4f}, LB={lb:.4f}')\n",
    "\n",
    "print(f'\\nAll approaches fall on the SAME CV-LB line (R²={r_value**2:.4f})')\n",
    "print('This confirms the problem is DISTRIBUTION SHIFT, not model choice.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9de92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have NOT been tried that could change the CV-LB relationship?\n",
    "print('=== APPROACHES THAT COULD CHANGE CV-LB RELATIONSHIP ===')\n",
    "print('''\n",
    "1. EXTRAPOLATION DETECTION + CONSERVATIVE BLENDING\n",
    "   - Tried in exp_096, exp_097 but CV degraded significantly\n",
    "   - exp_096: CV=0.0111 (34% worse than exp_030)\n",
    "   - exp_097: CV=0.0089 (7.6% worse than exp_030)\n",
    "   - The blending hurts CV without clear LB benefit\n",
    "   - VERDICT: Not working as hoped\n",
    "\n",
    "2. PSEUDO-LABELING\n",
    "   - Use confident test predictions to augment training\n",
    "   - NOT TRIED YET\n",
    "   - Could help adapt to test distribution\n",
    "\n",
    "3. ADVERSARIAL VALIDATION\n",
    "   - Identify features that distinguish train/test\n",
    "   - Use these to guide prediction calibration\n",
    "   - NOT TRIED YET\n",
    "\n",
    "4. DOMAIN-SPECIFIC CONSTRAINTS\n",
    "   - Physics/chemistry constraints that hold for unseen solvents\n",
    "   - Arrhenius kinetics already used\n",
    "   - Could try more sophisticated constraints\n",
    "\n",
    "5. SOLVENT CLUSTERING\n",
    "   - Group solvents by chemical class\n",
    "   - Use class-specific models\n",
    "   - Tried in exp_081 but didn't submit\n",
    "\n",
    "6. STUDY TOP PUBLIC KERNELS MORE CAREFULLY\n",
    "   - ens-model kernel uses specific feature selection\n",
    "   - mixall kernel uses GroupKFold differently\n",
    "   - May have insights we missed\n",
    "''')\n",
    "\n",
    "print('\\nKEY INSIGHT: The 1st place score (0.0347) is 103.9% better than 2nd place (0.0707).')\n",
    "print('This HUGE gap suggests 1st place found a fundamentally different approach.')\n",
    "print('2nd place (0.0707) is only 24% better than our best (0.0877).')\n",
    "print('\\nWe are competitive with 2nd place, but 1st place is in a different league.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1197fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the leaderboard gap\n",
    "print('=== LEADERBOARD GAP ANALYSIS ===')\n",
    "print(f'1st place: 0.0347')\n",
    "print(f'2nd place: 0.0707')\n",
    "print(f'Our best: 0.0877')\n",
    "print(f'\\nGap 1st to 2nd: {(0.0707 - 0.0347) / 0.0347 * 100:.1f}% (HUGE)')\n",
    "print(f'Gap 2nd to us: {(0.0877 - 0.0707) / 0.0707 * 100:.1f}% (moderate)')\n",
    "\n",
    "print(f'\\nWhat does this tell us?')\n",
    "print('1. 1st place found something FUNDAMENTALLY DIFFERENT')\n",
    "print('2. 2nd place is using similar approaches to us (just slightly better)')\n",
    "print('3. To beat 1st place, we need a paradigm shift, not incremental improvement')\n",
    "\n",
    "print(f'\\nPossible explanations for 1st place:')\n",
    "print('1. They found a way to reduce the CV-LB intercept significantly')\n",
    "print('2. They have domain knowledge we lack (chemistry expertise)')\n",
    "print('3. They use a completely different modeling approach (e.g., physics-based)')\n",
    "print('4. They have access to external data or pre-trained models')\n",
    "print('5. They found a bug/exploit in the evaluation (unlikely)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print('=== SUMMARY AND RECOMMENDATIONS ===')\n",
    "print(f'''\n",
    "CURRENT STATUS:\n",
    "- Best CV: 0.0083 (exp_030, exp_067)\n",
    "- Best LB: 0.0877 (exp_030, exp_067)\n",
    "- Target: 0.0347\n",
    "- Gap: 152.7% above target\n",
    "\n",
    "CV-LB RELATIONSHIP:\n",
    "- LB = {slope:.4f} * CV + {intercept:.6f} (R²={r_value**2:.4f})\n",
    "- Intercept ({intercept:.6f}) > Target (0.0347)\n",
    "- Required CV to hit target: {(0.0347 - intercept) / slope:.6f} (IMPOSSIBLE)\n",
    "\n",
    "WHAT WE'VE TRIED:\n",
    "- MLP, LightGBM, XGBoost, CatBoost, GP, Ridge\n",
    "- Various feature sets (Spange, DRFP, ACS PCA)\n",
    "- Ensembles of different sizes and compositions\n",
    "- Conservative blending with uncertainty\n",
    "- All approaches fall on the SAME CV-LB line\n",
    "\n",
    "WHAT HASN'T WORKED:\n",
    "- Conservative blending (hurts CV without clear LB benefit)\n",
    "- GNN/ChemBERTa (worse than simple models)\n",
    "- Deep/complex architectures (overfit)\n",
    "\n",
    "REMAINING SUBMISSIONS: 4\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "1. DO NOT submit exp_097 (CV=0.0089, worse than best)\n",
    "2. Focus on approaches that could CHANGE the CV-LB relationship\n",
    "3. Consider pseudo-labeling or adversarial validation\n",
    "4. Study top kernels more carefully for insights\n",
    "5. Accept that 1st place may have found something we can't replicate\n",
    "6. Aim for 2nd place (0.0707) as a more realistic target\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would it take to reach 2nd place (0.0707)?\n",
    "print('=== PATH TO 2ND PLACE (0.0707) ===')\n",
    "required_cv_2nd = (0.0707 - intercept) / slope\n",
    "print(f'Required CV to reach 0.0707: {required_cv_2nd:.6f}')\n",
    "print(f'Current best CV: {df[\"CV\"].min():.6f}')\n",
    "print(f'Improvement needed: {(df[\"CV\"].min() - required_cv_2nd) / df[\"CV\"].min() * 100:.1f}%')\n",
    "\n",
    "if required_cv_2nd > 0:\n",
    "    print(f'\\nThis is ACHIEVABLE!')\n",
    "    print(f'We need to reduce CV from {df[\"CV\"].min():.6f} to {required_cv_2nd:.6f}')\n",
    "    print(f'This is a {(df[\"CV\"].min() - required_cv_2nd) / df[\"CV\"].min() * 100:.1f}% improvement')\n",
    "else:\n",
    "    print(f'\\nEven 2nd place requires changing the CV-LB relationship.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
