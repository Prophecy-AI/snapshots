## Current Status
- Best CV score: 0.008092 from exp_050 (CatBoost+XGBoost, single solvent only)
- Best LB score: 0.0877 from exp_030/exp_067 (GP+MLP+LGBM)
- Target: 0.0347 | Gap to target: 152.7%
- Submissions remaining: 4

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.36 * CV + 0.052 (R² = 0.956)
- Intercept interpretation: Even at CV=0, expected LB is 0.052
- **Intercept (0.052) > Target (0.0347)** - THIS IS THE FUNDAMENTAL PROBLEM
- Required CV for target: (0.0347 - 0.052) / 4.36 = -0.004 (IMPOSSIBLE)
- All 13 submissions with LB scores fall on the same line

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The bug fix in exp_093 was successful.
- Evaluator's top priority: Investigate what top competitors do differently. **AGREE.**
- Key concerns: exp_093 (CV=0.010767) should NOT be submitted. **AGREE - it's 29.75% worse than best.**
- Evaluator correctly identified that non-linear mixture features HURT performance.

## Key Insight from Leaderboard
- 1st place: 0.0347 (target)
- 2nd place: 0.0707 (103.9% worse than 1st!)
- Our best: 0.0877 (24% worse than 2nd)

**The HUGE gap between 1st and 2nd suggests 1st place found a fundamentally different approach.**
2nd place is using similar methods to us. 1st place is doing something completely different.

## Data Understanding
- Reference notebooks: `exploration/evolver_loop98_analysis.ipynb`
- Key patterns:
  1. CV-LB intercept (0.052) represents structural distribution shift
  2. All model types (MLP, LGBM, XGB, GP, CatBoost) fall on same CV-LB line
  3. Non-linear mixture features HURT performance (exp_093 vs exp_030)
  4. ens-model kernel uses correlation filtering (threshold=0.90) and different weights for single vs full

## Recommended Approaches (PRIORITY ORDER)

### 1. REGENERATE SUBMISSION FROM BEST MODEL (IMMEDIATE)
The current submission file is from exp_093 (CV=0.010767, WORSE).
**MUST regenerate from exp_030 (CV=0.0083, LB=0.0877) or exp_050 (CV=0.0081).**

### 2. EXACT REPLICATION OF ens-model KERNEL
The ens-model kernel has specific techniques we haven't fully replicated:
- Correlation filtering with threshold=0.90
- Feature priority: spange > acs > drfps > frag > smiles
- Different ensemble weights: Single (CatBoost=7/13, XGB=6/13), Full (CatBoost=1/3, XGB=2/3)
- Numeric features: T_x_RT, RT_log, T_inv, RT_scaled (different from our Arrhenius features)

### 3. SIMPLER MODELS FOR BETTER GENERALIZATION
Complex models may overfit to training distribution. Try:
- Ridge regression with good features
- Linear models with regularization
- Simpler ensembles with fewer components

### 4. APPROACHES THAT CHANGE THE CV-LB RELATIONSHIP
The intercept (0.052) is the bottleneck, not CV. Try:
- Uncertainty-weighted predictions (blend toward mean when extrapolating)
- Conservative predictions for outlier solvents (Water, HFIP)
- Solvent clustering with class-specific models

### 5. INVESTIGATE WHAT 1ST PLACE MIGHT BE DOING
The 103.9% gap between 1st and 2nd is HUGE. Possible approaches:
- Pre-trained molecular embeddings (ChemBERTa, MolBERT)
- Graph neural networks with proper architecture
- Transfer learning from related datasets
- Physics-informed constraints that generalize

## What NOT to Try
- Non-linear mixture features (exp_093 proved they hurt)
- More complex ensemble architectures (all fall on same CV-LB line)
- GNN/GAT approaches (exp_085-087 all performed worse)
- ChemBERTa embeddings (exp_088 performed worse)

## Validation Notes
- Use official Leave-One-Out CV (24 folds for single, 13 folds for full)
- DO NOT use GroupKFold - the mixall kernel's CV is not comparable
- CV-LB relationship: expect LB ≈ 4.36 * CV + 0.052

## CRITICAL REMINDERS
1. **DO NOT SUBMIT exp_093** - it's 29.75% worse than best
2. **Regenerate submission from exp_030 or exp_050** before any submission
3. **With only 4 submissions left, every submission must count**
4. **The target IS reachable** - 1st place achieved it. We need to find their approach.

## Next Experiment Priority
1. Regenerate submission from best model (exp_030 or exp_050)
2. Try exact ens-model replication with their specific techniques
3. Try simpler models (Ridge regression) for better generalization
4. Consider submitting exp_050 (best CV) to verify CV-LB relationship