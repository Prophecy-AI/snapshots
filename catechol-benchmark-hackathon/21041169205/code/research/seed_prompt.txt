## Current Status
- Best CV score: 0.0081 from exp_049/exp_050/exp_053 (CatBoost+XGBoost ensemble)
- Best LB score: 0.0877 (exp_030, exp_067)
- Target: 0.0347 | Gap to target: 0.0530 (152.7% above target)

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.36 * CV + 0.052 (R² = 0.956)
- Intercept interpretation: Even at CV=0, expected LB is 0.052
- Are all approaches on the same line? YES
- **CRITICAL: Intercept (0.052) > Target (0.0347)**
- Required CV for target: (0.0347 - 0.052) / 4.36 = -0.004 (IMPOSSIBLE)

## Response to Evaluator
- Technical verdict was UNRELIABLE due to critical bug in exp_092
- Evaluator correctly identified the `/100` bug - SolventB% is already in [0, 1], not [0, 100]
- Evaluator's top priority: FIX THE BUG AND RE-RUN. **AGREED - this is the immediate action.**
- Key concerns raised: The bug caused catastrophic failure (CV=0.137 vs baseline 0.008). The non-linear mixture hypothesis is still valid but needs correct implementation.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop97_analysis.ipynb` for bug verification
- **SolventB% is in [0, 1] range** (values: 0.0, 0.0007, ..., 1.0)
- The best-work-here kernel uses `r = row["SolventB%"]` directly WITHOUT dividing by 100
- Non-linear mixture formula: `A * (1 - r) + B * r + 0.05 * A * B * r * (1 - r)`

## Recommended Approaches

### PRIORITY 1: FIX THE BUG IN exp_092 AND RE-RUN
The non-linear mixture features experiment failed due to a critical bug. Fix it:

```python
# WRONG (exp_092):
r = X["SolventB%"].values.reshape(-1, 1) / 100.0  # BUG!

# CORRECT:
r = X["SolventB%"].values.reshape(-1, 1)  # Already in [0, 1]
```

Apply the corrected non-linear mixture features to the GP+MLP+LGBM ensemble:
- Linear: `A * (1 - r) + B * r`
- Non-linear: `+ 0.05 * A * B * r * (1 - r)`

This is the most promising approach because:
1. The best-work-here kernel uses this exact formula
2. It captures solvent-solvent interactions
3. It could CHANGE the CV-LB relationship (reduce intercept)

### PRIORITY 2: If non-linear mixture doesn't help, try best-work-here kernel approach
The best-work-here kernel uses:
1. Only Spange descriptors (13 features) - NOT DRFP or ACS_PCA
2. Advanced feature engineering: polynomial features, interaction terms, statistical features
3. 4-model ensemble: CatBoost + XGBoost + LightGBM + Neural Network
4. Adaptive ensemble weighting based on validation MSE
5. Non-linear mixture features

Consider implementing this full approach if the simple bug fix doesn't help.

### PRIORITY 3: Ensemble diversity with different mixture handling
- Model A: Linear mixture features (current best)
- Model B: Non-linear mixture features (after bug fix)
- Model C: Per-target models with different weights
- Blend predictions based on uncertainty or validation performance

### PRIORITY 4: Conservative predictions for extrapolation
- Detect when a test solvent is far from training distribution
- Blend toward population mean for high-uncertainty predictions
- This could reduce the intercept by being more conservative on hard cases

## What NOT to Try
- **DO NOT submit exp_092** - CV=0.137 is 1590% worse than best
- **DO NOT divide SolventB% by 100** - data is already in [0, 1]
- **DO NOT try more GNN/GAT/ChemBERTa approaches** - all failed (exp_085-088)
- **DO NOT try per-target models without careful tuning** - exp_091 was 76% worse
- **DO NOT try uncertainty-weighted predictions without proper implementation** - exp_089 was 97% worse

## Validation Notes
- CV scheme: Official Leave-One-Out CV (24 folds for single, 13 folds for full)
- CV-LB gap: ~4.36x multiplier + 0.052 intercept
- The intercept (0.052) is the main problem - it exceeds the target (0.0347)
- We need approaches that CHANGE the CV-LB relationship, not just improve CV

## Key Insight
The target IS reachable - top competitors have achieved it. The key is to:
1. Fix the bug in exp_092 and test non-linear mixture features properly
2. If that doesn't work, implement the full best-work-here kernel approach
3. Focus on approaches that could reduce the intercept (0.052 → <0.0347)

## Remaining Submissions: 4
Use submissions wisely:
- Submit the bug-fixed non-linear mixture experiment if CV improves
- Don't submit anything with CV worse than 0.0081
