## Current Status
- Best CV score: 0.0081 from exp_049/050/053 (CatBoost+XGBoost ensemble)
- Best LB score: 0.0877 from exp_030 (GP+MLP+LGBM ensemble)
- Target: 0.0347 | Gap to target: 0.0530 (153% above target)
- Remaining submissions: 5

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (RÂ² = 0.95)
- Intercept (0.0525) > Target (0.0347) - THIS IS THE CORE PROBLEM
- All 12 submissions with LB feedback fall on the SAME LINE
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (IMPOSSIBLE)

**CRITICAL INSIGHT:** The intercept represents EXTRAPOLATION ERROR that cannot be fixed by improving CV. We must CHANGE THE RELATIONSHIP, not just improve CV.

## Response to Evaluator
- Technical verdict was TRUSTWORTHY for exp_058 (extrapolation detection)
- Evaluator's top priority: Don't submit exp_058 yet - CV is worse (0.0115 vs 0.0081)
- Key concerns: The blending parameters (threshold=0.5, strength=0.3) are too aggressive
- **I AGREE** - the extrapolation detection approach hurt CV without guaranteed intercept improvement
- **HOWEVER**, the evaluator's suggestion to tune blending parameters is still within the same CV-LB line

## Key Discovery from Public Kernels
The "mixall" kernel (9 votes) uses **GroupKFold (5 splits)** instead of Leave-One-Out CV!
- This is a FUNDAMENTALLY DIFFERENT validation scheme
- It may have a DIFFERENT CV-LB relationship
- The kernel claims "good CV/LB" in the title
- Uses MLP + XGBoost + RandomForest + LightGBM ensemble

**THIS IS THE KEY INSIGHT:** Our Leave-One-Out CV may be overly optimistic because it trains on 23/24 solvents. GroupKFold with 5 splits trains on ~80% of solvents, which may better simulate the test distribution.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop60_analysis.ipynb` for CV-LB analysis
- Key patterns: All model types (MLP, LGBM, XGB, GP, CatBoost) fall on the SAME CV-LB line
- The intercept (0.0525) is the structural gap from predicting on UNSEEN SOLVENTS

## Recommended Approaches (PRIORITY ORDER)

### Priority 1: Try GroupKFold CV Scheme (NEW APPROACH)
**Rationale:** The "mixall" kernel uses GroupKFold instead of Leave-One-Out. This may have a different CV-LB relationship because:
- Leave-One-Out trains on 23/24 solvents (96%) - very optimistic
- GroupKFold (5 splits) trains on ~80% of solvents - more realistic
- The test set may be evaluated similarly to GroupKFold

**Implementation:**
1. Use GroupKFold with 5 splits (like the mixall kernel)
2. Use our best model (CatBoost + XGBoost ensemble)
3. Compare the CV score to see if it's more realistic
4. If CV is higher but LB is similar, the intercept would be lower!

### Priority 2: Regenerate Best LB Model (exp_030)
**Rationale:** exp_030 achieved our best LB (0.0877) with GP+MLP+LGBM ensemble
- We have 7 pending submissions that haven't been evaluated
- We should submit exp_030 to confirm it still works
- This gives us a reliable baseline for comparison

### Priority 3: Ensemble Diversity with Different CV Schemes
**Rationale:** If GroupKFold has a different CV-LB relationship, we could:
- Train models with Leave-One-Out CV (optimized for CV)
- Train models with GroupKFold CV (optimized for LB)
- Blend predictions from both

### Priority 4: Lighter Extrapolation Detection
**Rationale:** The evaluator correctly identified that blend_strength=0.3 is too aggressive
- Try blend_strength=0.1 or 0.15
- Try higher threshold (0.6 or 0.7) to be more selective
- Use Spange-based similarity instead of fragprint Tanimoto

## What NOT to Try
- More CV optimization with Leave-One-Out - we're at the ceiling (0.0081)
- Different model architectures without changing the CV-LB relationship
- Aggressive extrapolation blending (already tried, hurt CV too much)

## Validation Notes
- Current CV scheme: Leave-One-Out (24 folds for single solvent, 13 for full)
- Alternative: GroupKFold (5 splits) - may have different CV-LB relationship
- The key is to find an approach that CHANGES THE INTERCEPT, not just improves CV

## CRITICAL ACTION ITEMS
1. **FIRST:** Implement GroupKFold CV scheme with our best model
2. **SECOND:** Compare CV scores - if GroupKFold CV is higher, the intercept may be lower
3. **THIRD:** Submit to verify the CV-LB relationship is different
4. **FOURTH:** If successful, optimize within the new CV-LB relationship

## Why This Could Work
The target (0.0347) IS achievable because:
1. Top competitors have achieved it
2. The intercept is an artifact of our validation scheme, not the problem
3. GroupKFold may better simulate the test evaluation
4. The "mixall" kernel claims good CV/LB with this approach

**THE TARGET IS REACHABLE** - we just need to find the right validation scheme that aligns with the test evaluation.
