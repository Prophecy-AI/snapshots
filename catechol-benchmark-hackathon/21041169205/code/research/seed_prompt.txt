## Current Status
- Best CV score: 0.0081 from exp_049/050/053 (CatBoost + XGBoost ensemble)
- Best LB score: 0.0877 from exp_030 (GP + MLP + LGBM ensemble)
- Target: 0.0347 | Gap to target: 0.0530 (LB - Target)
- **CRITICAL: exp_055 is a minimal submission (mean predictor) ready for testing**

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (R² = 0.9505)
- Intercept = 0.0525
- Target = 0.0347
- **CRITICAL: Intercept (0.0525) > Target (0.0347)**
- Required CV to hit target: -0.0041 (NEGATIVE - IMPOSSIBLE with current approach)
- Even with CV = 0, predicted LB would be 0.0525
- **ALL model types fall on the same CV-LB line - this is STRUCTURAL DISTRIBUTION SHIFT**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY for exp_055 (minimal submission)
- Evaluator's top priority: Submit exp_055 to verify format, then implement per-target model selection
- Evaluator correctly identified that the submission format is now correct (24/13 folds)
- **AGREE:** We should submit exp_055 first to verify the format works
- **AGREE:** Per-target model selection is a promising approach not yet tried

## CRITICAL INSIGHT: The Intercept Problem

The CV-LB analysis reveals a fundamental issue:
- **Intercept (0.0525) > Target (0.0347)**
- This means the target is MATHEMATICALLY UNREACHABLE with current approaches
- All model types (MLP, LGBM, XGB, GP, Ridge, CatBoost) fall on the same line
- Improving CV alone will NOT reach the target

**To reach the target, we must CHANGE THE CV-LB RELATIONSHIP:**
1. Reduce the intercept (address distribution shift)
2. Or find an approach that doesn't follow this linear pattern

## Data Understanding
- Reference notebooks: See `exploration/eda.ipynb` for feature analysis
- Key patterns:
  - Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV
  - Full data: 1227 samples, 13 solvent pairs, leave-one-pair-out CV
  - Targets: Product 2, Product 3, SM (starting material)
  - Features: Spange (13), ACS PCA (5), DRFP filtered (122), Arrhenius kinetics (5) = 145 total

## Recommended Approaches

### PRIORITY 1: Submit exp_055 to Verify Format
exp_055 is a minimal submission (mean predictor) with:
- Correct CV scheme: 24 folds for single, 13 folds for full
- Correct format: 1883 rows, proper columns
- All targets in [0, 1] range

**ACTION:** Submit exp_055 to verify the format is accepted. If it works, we know the format is correct.

### PRIORITY 2: Per-Target Model Selection (NEW APPROACH)
The public kernel "catechol-strategy-to-get-0-11161" achieved LB 0.11161 using:
- Different model types for different targets (HGB for SM, ETR for Products)
- Weighted ensemble of two feature sets (0.65 * ACS + 0.35 * Spange)

**This approach has NOT been tried yet and could potentially change the CV-LB relationship.**

Implementation:
```python
class PerTargetEnsembleModel:
    def __init__(self):
        self.targets = ["Product 2", "Product 3", "SM"]
        self.models = {}
        for t in self.targets:
            if t == "SM":
                # SM is hardest - use HistGradientBoostingRegressor
                self.models[t] = HistGradientBoostingRegressor(max_iter=500, max_depth=5)
            else:
                # Products are easier - use ExtraTreesRegressor
                self.models[t] = ExtraTreesRegressor(n_estimators=200, max_depth=10)
```

### PRIORITY 3: Intercept Reduction Strategies
To reduce the intercept (0.0525 → <0.0347):

1. **Extrapolation Detection:**
   - Add features measuring solvent distance to training distribution
   - When extrapolating, blend predictions toward population mean
   
2. **Per-Solvent Error Analysis:**
   - Identify which solvents cause the most error
   - Handle outlier solvents differently (e.g., Water)
   
3. **Uncertainty-Weighted Predictions:**
   - Use GP with uncertainty estimates
   - High uncertainty → conservative prediction (closer to mean)

4. **Solvent Clustering:**
   - Group solvents by chemical class (alcohols, ethers, esters)
   - Use class-specific models

### PRIORITY 4: Study Top Public Kernels
Top kernels that work:
- "Arrhenius Kinetics + TTA" (LB 0.09831) - uses MLP with Arrhenius features
- "mixall" - uses GroupKFold (5 splits) instead of Leave-One-Out
- "System Malfunction V1" - simple MLP approach

**Key insight:** The "mixall" kernel uses GroupKFold which produces DIFFERENT fold structure. This might produce a different CV-LB relationship.

## What NOT to Try
- More complex models without first verifying submission format
- Approaches that just improve CV without addressing the intercept
- Any variation that falls on the same CV-LB line

## Validation Notes
- CV scheme: Leave-one-solvent-out for single (24 folds), leave-one-pair-out for full (13 folds)
- The CV-LB relationship is very strong (R² = 0.95)
- The intercept (0.0525) is higher than the target (0.0347)

## Submission Strategy (5 remaining today)
1. **SUBMIT exp_055** - Verify format is accepted (mean predictor, CV ~0.054)
2. **If accepted:** Implement per-target model selection
3. **If rejected:** Debug format issue further

## THE TARGET IS REACHABLE

The target (0.0347) IS reachable, but NOT through incremental CV improvements.

**The path forward requires:**
1. Verify submission format works (exp_055)
2. Find approaches that CHANGE the CV-LB relationship
3. Reduce the intercept through:
   - Per-target model selection
   - Extrapolation detection
   - Uncertainty weighting
   - Solvent clustering

**The solution exists - we just need to find an approach that breaks the current CV-LB pattern!**

## IMPORTANT: The Intercept is the Bottleneck

DO NOT keep optimizing CV if all approaches fall on the same CV-LB line.
The intercept (0.0525) represents extrapolation error that no amount of model tuning can fix.

**Focus on strategies that could REDUCE THE INTERCEPT:**
1. Per-target model selection (different models for different targets)
2. Extrapolation detection + conservative predictions
3. Solvent clustering + class-specific models
4. Physics-informed constraints that generalize to unseen solvents
