## Current Status
- Best CV score: 0.008092 from exp_049/exp_050 (CatBoost+XGBoost)
- Best LB score: 0.0877 from exp_030/exp_067 (GP+MLP+LGBM)
- Target: 0.0347 | Gap to target: 0.0530 (152.7% above target)
- Submissions remaining: 4

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.36 * CV + 0.0520 (RÂ² = 0.9558)
- Intercept interpretation: Even at CV=0, expected LB is 0.0520
- Are all approaches on the same line? YES
- **CRITICAL**: Intercept (0.0520) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0520) / 4.36 = -0.004 (IMPOSSIBLE)

**This is a STRUCTURAL DISTRIBUTION SHIFT problem. Standard CV optimization CANNOT reach the target.**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The exp_090 implementation was correct but performed poorly.
- Evaluator's top priority: Try per-target heterogeneous ensemble. **STRONGLY AGREE** - this is fundamentally different from all 90+ experiments.
- Key concerns raised: 
  1. DO NOT submit exp_090 (CV=0.0109, predicted LB=0.0995) - **AGREED, will not submit**
  2. Correlation filtering removed useful features - **AGREED, 70% feature reduction was too aggressive**
  3. The intercept problem requires fundamentally different strategy - **AGREED, this is the core issue**

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop95_analysis.ipynb` for CV-LB analysis
- Key patterns to exploit:
  1. **SM target behaves differently** - The strategy-to-get-0-11161 kernel uses different model types for SM vs Products
  2. **Feature sets matter** - ACS_PCA and Spange descriptors have different strengths
  3. **Ensemble weights vary by data type** - Single solvent vs full data may need different weights

## Recommended Approaches

### PRIORITY 1: Per-Target Heterogeneous Ensemble (HIGH PRIORITY - UNTRIED)
**Rationale**: The strategy-to-get-0-11161 kernel (LB=0.11161) uses DIFFERENT model types for different targets:
- SM target: HistGradientBoostingRegressor (HGB) - gradient boosting
- Product 2 & 3: ExtraTreesRegressor (ETR) - random forest variant
- Ensemble: 0.65 * ACS_PCA + 0.35 * Spange

**Why this could change the CV-LB relationship**:
1. Different targets may have different optimal model types
2. SM (starting material) may behave differently than products
3. This is fundamentally different from using the same model for all targets

**Implementation**:
```python
from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.multioutput import MultiOutputRegressor

class BetterCatecholModel:
    def __init__(self, feature_table="spange_descriptors", base_type="hgb"):
        self.base_type = base_type
        self.lookup = pd.read_csv(f'/home/data/{feature_table}_lookup.csv', index_col=0)
        self.model = None

    def _build_X(self, X):
        rt = X["Residence Time"].values.reshape(-1, 1)
        temp = X["Temperature"].values.reshape(-1, 1)
        if "SOLVENT NAME" in X.columns:
            S = np.vstack([self.lookup.loc[s].values for s in X["SOLVENT NAME"]])
            return np.hstack([rt, temp, S])
        frac_b = X["SolventB%"].values.reshape(-1, 1) / 100.0
        A = np.vstack([self.lookup.loc[s].values for s in X["SOLVENT A NAME"]])
        B = np.vstack([self.lookup.loc[s].values for s in X["SOLVENT B NAME"]])
        mix = (1 - frac_b) * A + frac_b * B
        return np.hstack([rt, temp, frac_b, mix])

    def train_model(self, X, Y):
        Xf = self._build_X(X)
        y = Y.values
        if self.base_type == "hgb":
            base = HistGradientBoostingRegressor(max_depth=7, max_iter=700, learning_rate=0.04)
        else:
            base = ExtraTreesRegressor(n_estimators=900, min_samples_leaf=2, random_state=42, n_jobs=-1)
        self.model = Pipeline([("scaler", StandardScaler()), ("reg", MultiOutputRegressor(base))])
        self.model.fit(Xf, y)

class PerTargetEnsembleModel:
    def __init__(self):
        self.targets = ["Product 2", "Product 3", "SM"]
        self.models = {}
        for t in self.targets:
            if t == "SM":
                self.models[t] = [
                    BetterCatecholModel("acs_pca_descriptors", "hgb"),
                    BetterCatecholModel("spange_descriptors", "hgb"),
                ]
            else:
                self.models[t] = [
                    BetterCatecholModel("acs_pca_descriptors", "etr"),
                    BetterCatecholModel("spange_descriptors", "etr"),
                ]

    def train_model(self, X, Y):
        for t in self.targets:
            y_single = Y[[t]]
            for m in self.models[t]:
                m.train_model(X, y_single)

    def predict(self, X):
        preds = []
        for t in self.targets:
            p1 = self.models[t][0].model.predict(self.models[t][0]._build_X(X))
            p2 = self.models[t][1].model.predict(self.models[t][1]._build_X(X))
            pred_t = 0.65 * p1 + 0.35 * p2
            preds.append(pred_t.reshape(-1, 1))
        pred = np.clip(np.hstack(preds), 0, 1)
        return torch.tensor(pred, dtype=torch.double)
```

### PRIORITY 2: Combine Best Approaches with Per-Target Logic
If per-target heterogeneous ensemble shows promise, combine with our best techniques:
- Add Arrhenius kinetics features (1/T, ln(t), T*t)
- Use CatBoost/XGBoost for some targets, GP for others
- Experiment with different feature combinations per target

### PRIORITY 3: Solvent Similarity-Based Prediction Adjustment
**Rationale**: The intercept represents extrapolation error to unseen solvents.
- Calculate similarity of test solvent to training solvents
- When test solvent is dissimilar (extrapolating), blend toward population mean
- This could reduce the intercept

## What NOT to Try
1. **Neural network architectures** (GNN, GAT, ChemBERTa) - 5 consecutive failures, all 100%+ worse than best
2. **Aggressive correlation filtering** - exp_090 showed 70% feature reduction hurts performance
3. **Standard CV optimization** - All approaches fall on the same CV-LB line, intercept > target
4. **Complex deep learning** - Small dataset (656 single, 1227 full samples) doesn't support complex models

## Validation Notes
- CV scheme: Leave-One-Out for single solvent, Leave-One-Ramp-Out for full data
- CV-LB gap: ~4.36x multiplier + 0.052 intercept
- **Key insight**: The intercept (0.052) > target (0.0347) means we need to CHANGE the relationship, not just improve CV
- Submit only if CV < 0.0081 AND approach is fundamentally different (could change intercept)

## Submission Strategy (4 remaining)
1. **DO NOT submit exp_090** - CV=0.0109 is 34% worse than best
2. **Submit per-target heterogeneous ensemble** if CV < 0.0085 - fundamentally different approach
3. **Save submissions** for approaches that could change the CV-LB relationship
4. **Final submission**: Best performing approach with lowest predicted LB

## Key Insight
The target (0.0347) IS achievable - top competitors have achieved it. The key is to find an approach that:
1. Changes the CV-LB relationship (reduces the intercept)
2. Or achieves CV so low that even with the current relationship, LB < 0.0347

The per-target heterogeneous ensemble is the most promising untried approach because it's fundamentally different from all 90+ experiments we've run.