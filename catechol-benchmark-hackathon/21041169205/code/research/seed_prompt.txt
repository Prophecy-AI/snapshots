## Current Status
- Best CV score: 0.0081 from exp_049/050
- Best LB score: 0.0877 from exp_030
- Target: 0.0347 | Gap to target: 0.0530 (152.7% above)
- Last submission (exp_064) FAILED with "Evaluation metric raised an unexpected error"

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- Are all approaches on the same line? YES
- **CRITICAL**: Intercept (0.0525) > Target (0.0347) - IMPOSSIBLE to reach target by CV optimization alone!
- Required CV to hit target: (0.0347 - 0.0525) / 4.31 = -0.0041 (NEGATIVE - IMPOSSIBLE)

## Response to Evaluator
- Technical verdict was TRUSTWORTHY - the notebook is a faithful replication of exp_030
- Evaluator's top priority: Submit exp_067 to verify pipeline, then pivot to GNN or distribution-shift strategies
- Key concerns raised: The 0.087 floor cannot be broken by CV optimization. R² of 0.0131 between CV and LB proves CV improvements don't translate to LB improvements.
- **My response**: The evaluator's R² calculation seems incorrect (I calculated R²=0.95 with strong correlation). However, the INTERCEPT problem is real - even with perfect CV, we can't reach the target. The evaluator is RIGHT that we need fundamentally different approaches.

## Submission Failure Analysis
The exp_064 submission failed with "Evaluation metric raised an unexpected error". Investigation shows:
- Submission file format is CORRECT (1883 rows, correct columns, no NaN/inf)
- Predictions are in valid ranges [0, 1]
- Notebook structure matches exp_030 which worked

**Possible causes:**
1. Transient evaluation system error
2. Cell 14 after "FINAL CELL" (but exp_030 had same structure and worked)
3. Unknown issue with the evaluation metric

**Recommendation**: Create a new experiment with ONLY the required cells (no Cell 14 after final cell) and submit again.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop68_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. CV-LB relationship is highly linear (R²=0.95) with slope 4.31
  2. Intercept (0.0525) is HIGHER than target (0.0347)
  3. All model types (MLP, LGBM, XGB, GP) fall on the same line
  4. This is a DISTRIBUTION SHIFT problem, not a modeling problem

## Recommended Approaches

### IMMEDIATE PRIORITY: Fix Submission Issue
1. **Create a clean notebook** - Remove Cell 14 (CV verification) from the notebook
2. **Use exact template structure** - Only the 3 required cells at the end
3. **Submit exp_030 approach** - This achieved our best LB (0.0877)

### STRATEGIC PRIORITY: Break the 0.087 Floor
Since the intercept (0.0525) > target (0.0347), we CANNOT reach the target by CV optimization alone. We need approaches that REDUCE THE INTERCEPT:

1. **Extrapolation Detection + Conservative Predictions** (HIGH PRIORITY)
   - Add features measuring solvent distance to training distribution
   - When extrapolating (far from training solvents), blend predictions toward population mean
   - This should reduce error on "hard" test solvents

2. **Uncertainty-Weighted Predictions** (HIGH PRIORITY)
   - Use GP uncertainty estimates
   - High uncertainty → conservative prediction (closer to mean)
   - This naturally handles extrapolation

3. **Physics-Informed Constraints** (MEDIUM PRIORITY)
   - Arrhenius kinetics features (already implemented)
   - Mass balance constraint: Product 2 + Product 3 + SM ≈ 1
   - Enforce this constraint in predictions

4. **Solvent Clustering** (MEDIUM PRIORITY)
   - Group solvents by chemical class (alcohols, ethers, esters, etc.)
   - Use class-specific models
   - Detect when test solvent is in a known vs novel class

5. **Study Top Public Kernels** (LOW PRIORITY)
   - Our best LB (0.0877) is BETTER than the top public kernel (0.09831)
   - We're already competitive, but need to break the 0.087 floor

## What NOT to Try
- **Standard CV optimization** - All approaches fall on the same CV-LB line. Improving CV won't help.
- **More ensemble diversity** - We've tried GP, MLP, LGBM, XGB. All on same line.
- **Hyperparameter tuning** - Diminishing returns, won't change the intercept.

## Validation Notes
- CV scheme: Leave-One-Solvent-Out (24 folds for single, 13 folds for full)
- CV-LB gap: ~10x (CV 0.008 → LB 0.087)
- The gap is STRUCTURAL - it's the intercept, not the slope

## Specific Next Steps

### Step 1: Fix Submission (IMMEDIATE)
Create a new experiment that:
1. Uses the exp_030 GP+MLP+LGBM ensemble approach
2. Has ONLY the 3 required cells at the end (no Cell 14)
3. Writes to `submission.csv` (not `/home/submission/submission.csv`)

### Step 2: Implement Extrapolation Detection (NEXT)
After fixing submission, implement:
1. Calculate solvent similarity to training set (using Spange descriptors)
2. For each test prediction, compute "extrapolation score"
3. Blend prediction toward population mean based on extrapolation score
4. This should reduce error on "hard" test solvents and lower the intercept

### Step 3: Uncertainty-Weighted Predictions (AFTER)
Use GP uncertainty to weight predictions:
1. Train GP with uncertainty estimates
2. For high-uncertainty predictions, blend toward mean
3. This naturally handles extrapolation

## Key Insight
The target (0.0347) is BELOW the intercept (0.0525). This means:
- No amount of CV optimization can reach the target
- We need to CHANGE THE CV-LB RELATIONSHIP, not just improve CV
- The solution is to reduce error on "hard" test solvents (extrapolation)
- Conservative predictions when extrapolating should lower the intercept
