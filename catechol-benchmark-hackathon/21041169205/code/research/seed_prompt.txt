## Current Status
- Best CV score: 0.0083 from exp_030
- Best LB score: 0.0877 from exp_030
- Target: 0.0347 | Gap to target: 0.0530 (152.7% above target)
- Remaining submissions: 5

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- **CRITICAL: Intercept (0.0525) > Target (0.0347)**
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (NEGATIVE = IMPOSSIBLE)
- **CONCLUSION: Improving CV alone CANNOT reach the target**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The submission format is correct.
- Evaluator's top priority: Submit exp_057 to get LB feedback, then revisit best approach (GP+MLP+LGBM from exp_032).
- Key concerns raised: CV (0.009263) is 14% worse than best CV (0.008092). The public kernel achieved LB 0.11161, worse than our best 0.0877.
- **My response**: I AGREE that exp_056 is unlikely to improve LB. However, the evaluator's suggestion to "revisit exp_032" misses the fundamental problem: ALL approaches fall on the SAME CV-LB line. The intercept (0.0525) is higher than the target (0.0347). We need approaches that CHANGE the relationship, not just improve CV.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop58_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. All 12 submissions with LB feedback fall on the same linear CV-LB relationship (R²=0.95)
  2. The intercept (0.0525) represents STRUCTURAL distribution shift
  3. Test solvents are fundamentally different from training solvents
  4. SM target is hardest (highest variance, most outliers)

## THE FUNDAMENTAL PROBLEM

The target (0.0347) is BELOW the intercept (0.0525) of our CV-LB relationship. This means:
- Even with PERFECT CV (CV=0), we'd still get LB=0.0525
- No amount of model tuning can reach the target
- We need to CHANGE the CV-LB relationship itself

## Recommended Approaches (PRIORITY ORDER)

### PRIORITY 1: Study What Top Competitors Actually Do
The top leaderboard scores are much better than ours. They've solved this problem. We need to:
1. **Implement the 'ens-model' kernel approach** (matthewmaree):
   - Combines ALL feature sources (spange, acs_pca, drfps, fragprints, smiles)
   - Uses correlation-based feature filtering with priority
   - CatBoost + XGBoost ensemble with different weights for single vs full
   - Numeric feature engineering (T_x_RT, RT_log, T_inv, RT_scaled)
   
2. **Key insight from ens-model**: It uses ALL 5 feature sources combined, not just 2-3. This may provide better generalization to unseen solvents.

### PRIORITY 2: Extrapolation Detection + Conservative Predictions
When predicting for solvents that are "far" from training distribution:
1. Compute Tanimoto similarity to nearest training solvents using fingerprints
2. When similarity is low (extrapolating), blend predictions toward population mean
3. This could REDUCE the intercept by being conservative on hard cases

### PRIORITY 3: Solvent Clustering + Class-Specific Models
1. Group solvents by chemical class (alcohols, ethers, esters, halogenated, etc.)
2. Train class-specific models that generalize within chemical families
3. For test solvents, identify their class and use appropriate model

### PRIORITY 4: Uncertainty-Weighted Predictions
1. Use GP or ensemble variance to estimate prediction uncertainty
2. High uncertainty → blend toward population mean
3. This is similar to extrapolation detection but uses model uncertainty

## What NOT to Try
- ❌ More hyperparameter tuning on existing models (won't change intercept)
- ❌ Different ensemble weights (won't change intercept)
- ❌ Per-target model selection (exp_056 showed worse CV)
- ❌ Normalizing predictions to sum to 1 (WRONG - yields don't sum to 1)

## Validation Notes
- Use official Leave-One-Out CV (24 folds for single, 13 folds for full)
- Track both CV and predicted LB (using the linear relationship)
- Look for approaches that give LOWER predicted LB for same CV (changing the relationship)

## Concrete Next Experiment: exp_057

**Implement the 'ens-model' kernel approach with ALL 5 feature sources:**

1. Load ALL feature sources:
   - spange_descriptors (13 features)
   - acs_pca_descriptors (10 features)
   - drfps_catechol (2048 sparse features)
   - fragprints (sparse features)
   - smiles (SMILES strings - need to featurize)

2. Apply correlation-based feature filtering:
   - Remove constant columns
   - Remove highly correlated features (threshold 0.8-0.9)
   - Keep features with priority: spange > acs > drfps > frag > smiles

3. Add numeric feature engineering:
   - T_x_RT (temperature * residence time)
   - RT_log (log of residence time)
   - T_inv (1/temperature in Kelvin)
   - RT_scaled (residence time / mean)

4. Train CatBoost + XGBoost ensemble:
   - Single solvent: weights 7:6 (CatBoost:XGBoost)
   - Full data: weights 1:2 (CatBoost:XGBoost)

5. Clip predictions to [0, 1] (DO NOT normalize to sum to 1)

**Hypothesis**: Combining ALL feature sources may provide better generalization to unseen solvents, potentially changing the CV-LB relationship.

## CRITICAL REMINDER

The target IS reachable. Top competitors have achieved it. We need to find what they're doing differently. The key is NOT improving CV - it's changing the CV-LB relationship by:
1. Using better features that generalize to unseen solvents
2. Being conservative when extrapolating
3. Using domain knowledge that holds for all solvents
