## Current Status
- Best CV score: 0.0083 from exp_030 (GP+MLP+LGBM ensemble)
- Best LB score: 0.0877 from exp_030 and exp_067
- Target: 0.0347 | Gap to target: 0.0530

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.36 * CV + 0.0520 (R² = 0.96)
- Intercept interpretation: Even at CV=0, expected LB is 0.0520
- Are all approaches on the same line? YES - extremely tight fit
- **CRITICAL**: Intercept (0.0520) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0520) / 4.36 = -0.0040 (IMPOSSIBLE)

**THIS IS A DISTRIBUTION SHIFT PROBLEM, NOT A MODEL OPTIMIZATION PROBLEM**
Standard CV optimization CANNOT reach the target. We must change the CV-LB relationship.

## Response to Evaluator
- Technical verdict: TRUSTWORTHY - exp_070 implementation is sound
- Evaluator's top priority: **Combine best model (exp_030) with extrapolation detection**
- Key concerns raised:
  1. exp_070 uses simple MLP [64,64] instead of best model (GP+MLP+LGBM)
  2. CV=0.01536 is almost 2x worse than best CV=0.0083
  3. Need to verify if extrapolation detection actually changes the CV-LB relationship

**I AGREE with the evaluator's assessment.** The extrapolation detection approach is strategically correct (trying to reduce the intercept), but it needs to be combined with the best base model.

## Data Understanding
- Reference notebooks: `exploration/evolver_loop73_analysis.ipynb` for CV-LB analysis
- Key patterns:
  - Outlier solvents (HFIP, Cyclohexane, Water, Ethylene Glycol, TFE) have high outlier scores
  - These solvents are far from others in Spange descriptor space
  - Blending predictions toward mean for outliers may help on unseen test solvents

## Recommended Approaches (Priority Order)

### PRIORITY 1: Combine exp_030 (Best Model) with Extrapolation Detection
**Rationale**: exp_030 has best CV (0.0083) and best LB (0.0877). Adding extrapolation detection on top may reduce the intercept without sacrificing CV too much.

Implementation:
```python
class ExtrapolationAwareEnsemble(BaseModel):
    def __init__(self, blend_threshold=1.0):
        # Use GP+MLP+LGBM ensemble from exp_030
        self.gp_model = GPWrapper(...)
        self.mlp_model = MLPModel(...)
        self.lgbm_model = LGBMModel(...)
        
        # Pre-computed outlier scores
        self.outlier_scores = {
            'HFIP': 4.57, 'Cyclohexane': 4.18, 'Water': 3.70,
            'Ethylene Glycol': 3.69, 'TFE': 3.59, ...
        }
        self.mean_score = 2.24
        self.std_score = 1.04
        
    def predict(self, X):
        # Get ensemble predictions (same as exp_030)
        gp_pred = self.gp_model.predict(X)
        mlp_pred = self.mlp_model.predict(X)
        lgbm_pred = self.lgbm_model.predict(X)
        raw_pred = 0.15 * gp_pred + 0.55 * mlp_pred + 0.30 * lgbm_pred
        
        # Apply extrapolation detection
        blend_weights = self.get_blend_weights(X)  # Based on outlier scores
        mean_pred = self.train_Y.mean(axis=0)
        blended = (1 - blend_weights) * raw_pred + blend_weights * mean_pred
        return np.clip(blended, 0, 1)
```

### PRIORITY 2: Try Different Blend Thresholds
- blend_threshold=0.5: More aggressive blending (more solvents affected)
- blend_threshold=1.0: Moderate blending (4 solvents affected)
- blend_threshold=1.5: Less aggressive blending (fewer solvents affected)

### PRIORITY 3: Use GP Uncertainty for Extrapolation Detection
Instead of distance-based outlier scores, use GP's uncertainty estimates:
```python
mean, var = gp.predict(X, return_var=True)
uncertainty = np.sqrt(var)
blend_weight = np.clip(uncertainty / threshold, 0, 1)
conservative_pred = (1 - blend_weight) * mean + blend_weight * population_mean
```

### PRIORITY 4: 4-Model Ensemble (like mixall kernel)
Add XGBoost and RandomForest to the ensemble:
- MLP (40%), XGBoost (20%), RF (20%), LightGBM (20%)
- Different models may extrapolate differently
- More diversity may help on unseen solvents

### PRIORITY 5: Mass Balance Constraint
Yields should sum to ~1 (Product 2 + Product 3 + SM ≈ 1):
```python
# After prediction
total = pred[:, 0] + pred[:, 1] + pred[:, 2]
pred = pred / total.reshape(-1, 1)  # Normalize to sum to 1
```

## What NOT to Try
- ❌ Simple MLP without ensemble (already tried, CV worse)
- ❌ DRFP-only features (exp_002 showed they're worse than Spange)
- ❌ Deep residual networks (exp_004 failed badly)
- ❌ Pure GP (exp_032 showed it's worse than ensemble)
- ❌ Standard CV optimization without addressing intercept

## Validation Notes
- Use official Leave-One-Out CV (24 folds for single, 13 for full)
- Ensure predictions are in [0, 1] range (use sigmoid or clip)
- Follow exact template structure (last 3 cells unchanged)
- CV will likely be worse with extrapolation detection, but LB may improve

## Key Insight
The target (0.0347) is BELOW the intercept (0.0520) of the CV-LB line. This means:
1. No amount of CV improvement can reach the target
2. We must change the CV-LB relationship
3. Extrapolation detection is designed to do exactly this
4. But it must be combined with the best base model (exp_030)

## Submission Strategy
- 4 submissions remaining
- Submit the extrapolation-aware ensemble (exp_030 + extrapolation detection)
- If LB improves relative to CV, the approach is working
- If LB doesn't improve, try different blend thresholds or GP uncertainty
