## Current Status
- Best CV score: 0.0083 from exp_030 (GP+MLP+LGBM ensemble)
- Best LB score: 0.0877 (exp_030)
- Target: 0.0347 | Gap to target: 153%
- Submissions remaining: 5

## CV-LB Relationship Analysis (CRITICAL)
- Linear fit: LB = 4.31 * CV + 0.0525 (R² = 0.95)
- Intercept interpretation: Even at CV=0, expected LB is 0.0525
- Are all approaches on the same line? YES
- CRITICAL: Intercept (0.0525) > Target (0.0347)
- Required CV for target: (0.0347 - 0.0525) / 4.31 = -0.0041 (NEGATIVE - IMPOSSIBLE)

**This means standard approaches CANNOT reach the target. We need approaches that CHANGE the CV-LB relationship.**

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The implementation is correct.
- Evaluator's top priority: STOP AND INVESTIGATE SUBMISSION ERRORS. Agreed - 7 consecutive failures is critical.
- Key concerns raised: 
  1. CV regression (0.011171 vs best 0.008298) - Agreed, exp_060 is worse than best
  2. Intercept problem unsolved - Agreed, this is the core issue
  3. ens-model kernel not fully replicated - This is a key gap to address

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop63_analysis.ipynb` for CV-LB analysis
- Key patterns:
  1. All model types (MLP, LGBM, XGB, GP, CatBoost) fall on the SAME CV-LB line
  2. The intercept (0.0525) represents structural extrapolation error
  3. Test solvents are fundamentally different from training solvents
  4. The ens-model kernel uses ALL features with correlation filtering - we haven't fully replicated this

## Recommended Approaches (Priority Order)

### PRIORITY 1: Fully Replicate ens-model Kernel
The ens-model kernel (matthewmaree) is a top public kernel that we haven't fully replicated. Key differences:
1. **ALL feature sources**: spange + acs_pca + drfps + fragprints + smiles
2. **Correlation filtering**: threshold=0.90, priority-based (spange > acs > drfps > frag > smiles)
3. **Different ensemble weights**: Single (7:6 CatBoost:XGB), Full (1:2 CatBoost:XGB)
4. **Tuned hyperparameters**: depth=3, n_estimators=1050, lr=0.05

**Action**: Create a notebook that EXACTLY replicates the ens-model kernel code, including:
- `build_solvent_feature_table()` function with all feature sources
- `filter_correlated_features()` with priority-based filtering
- `CatBoostModel` and `XGBModel` with exact hyperparameters
- `EnsembleModel` with correct weights

### PRIORITY 2: Test-Time Refinement for Distribution Shift
Research suggests test-time refinement can reduce distribution shift error:
1. **Extrapolation detection**: Measure distance from test solvent to training distribution
2. **Conservative predictions**: When extrapolating, blend toward population mean
3. **Uncertainty weighting**: Use GP uncertainty to weight predictions

**Action**: Add extrapolation detection features:
- Compute Tanimoto similarity of test solvent fingerprints to nearest training solvents
- Add feature: `min_train_similarity`, `mean_train_similarity`
- When similarity is low (extrapolating), blend predictions toward mean

### PRIORITY 3: Physics-Informed Features
The Catechol benchmark paper mentions that transfer learning and active learning achieved best scores. Physics-informed features can help:
1. **Arrhenius kinetics**: Already implemented (1/T, ln(t), T*t)
2. **Solvent polarity features**: Dielectric constant, hydrogen bonding capacity
3. **Chemical class features**: Is alcohol, ether, ester, etc.

**Action**: Add solvent chemical class as categorical feature:
- Classify solvents by functional group (alcohol, ether, ester, ketone, etc.)
- Use class-specific model weights or separate models per class

### PRIORITY 4: Pseudo-Labeling
Use confident predictions on test data to augment training:
1. Make predictions on all test samples
2. Select samples with high confidence (low uncertainty)
3. Add these pseudo-labeled samples to training
4. Retrain model

**Action**: Implement pseudo-labeling with GP uncertainty:
- Train GP model, get predictions + uncertainties
- Select test samples with uncertainty < threshold
- Add to training set and retrain

## What NOT to Try
- ❌ Simple hyperparameter tuning (stays on same CV-LB line)
- ❌ More ensemble members without diversity (diminishing returns)
- ❌ Different random seeds (doesn't change intercept)
- ❌ Extrapolation detection that HURTS CV (exp_058, exp_059 showed this)

## Validation Notes
- Use official Leave-One-Out CV (24 folds for single, 13 folds for full)
- The last 3 cells MUST be exactly as in official template
- Only change allowed: model definition line
- Ensure submission.csv has correct format: id, index, task, fold, row, target_1, target_2, target_3

## CRITICAL: Submission Format
Recent submissions (exp_049-057) failed with "Evaluation metric raised an unexpected error".
The submission format appears correct (1883 rows, correct columns, values in [0,1]).
Possible causes:
1. Notebook cell structure issue
2. Model definition not following template exactly
3. Kaggle platform intermittent issues

**RECOMMENDATION**: 
1. Create notebook that EXACTLY copies ens-model kernel structure
2. Only modify the model class definition
3. Ensure last 3 cells are UNCHANGED from official template

## Experiment Plan for This Loop

### Experiment 061: Exact ens-model Kernel Replication
1. Copy the ENTIRE ens-model kernel code
2. Use ALL feature sources with correlation filtering
3. Use exact hyperparameters and ensemble weights
4. Ensure notebook structure matches official template exactly

Expected outcome: CV ~0.008, LB ~0.087 (similar to exp_030)
This establishes a baseline that we KNOW works on Kaggle.

### Experiment 062: ens-model + Extrapolation Detection (Conservative)
1. Start with ens-model kernel
2. Add extrapolation detection features (similarity to training)
3. When extrapolating, blend predictions toward population mean
4. Use GP uncertainty to weight the blending

Expected outcome: Potentially lower LB if extrapolation detection helps

### Experiment 063: ens-model + Solvent Clustering
1. Cluster solvents by chemical class
2. Use class-specific ensemble weights
3. For novel classes, use more conservative predictions

Expected outcome: Better generalization to unseen solvent types

## THE TARGET IS REACHABLE
The target (0.0347) is below our current intercept (0.0525), but this doesn't mean it's impossible.
The benchmark achieved MSE 0.0039 on this exact dataset using transfer learning and active learning.
Top public kernels have achieved scores close to the target.
The solution exists - we need to find what they're doing differently.

**Key insight**: The ens-model kernel uses ALL features with correlation filtering. We've been using only Spange descriptors. This could be the missing piece.

DO NOT GIVE UP. The target IS reachable. Focus on approaches that CHANGE the CV-LB relationship.