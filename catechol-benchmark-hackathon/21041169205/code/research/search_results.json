{
  "query": "What machine learning techniques achieve the best performance for predicting chemical reaction yields with unseen solvents using molecular descriptors?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields for solvents that were not present in the training set works best when the model can capture non\u2011linear relationships between rich molecular descriptors and the outcome while remaining robust to the limited solvent\u2011specific data.  Benchmarking on a curated set of\u202f\u2248\u202f41\u202fk amide\u2011coupling reactions showed that **ensemble methods (random\u2011forest, gradient\u2011boosted trees) and deep\u2011learning architectures (feed\u2011forward neural nets and graph\u2011based networks) consistently outperformed linear or simple kernel regressors**, achieving the highest R\u00b2 and lowest mean absolute error on held\u2011out solvents\u202f\u3010Result\u202f3\u3011.  Adding attention mechanisms to a random\u2011forest (the \u201cMetaRF\u201d approach) further improved performance when only a few solvent\u2011reaction datapoints were available, demonstrating that **attention\u2011augmented ensembles can extract the most relevant descriptor information for unseen solvents**\u202f\u3010Result\u202f10\u3011.  \n\nMore recent work combines the strengths of Gaussian\u2011process (GP) uncertainty quantification with deep feature extractors.  **Deep Kernel Learning (DKL)**\u2014a GP whose kernel is parameterised by a neural network\u2014has been reported to give state\u2011of\u2011the\u2011art accuracy for reaction\u2011outcome prediction and to guide solvent optimisation with few experimental trials\u202f\u3010Result\u202f7\u3011.  Earlier studies on asymmetric catalysis also found that **Gaussian\u2011process surrogate models trained on \u03c3\u2011profile and other physicochemical descriptors can reach excellent predictive performance after a small amount of iterative retraining on newly screened solvents**\u202f\u3010Result\u202f1\u3011.  Across these studies, the common recipe for the best results is: (i) compute a diverse set of 2\u2011D/3\u2011D molecular descriptors (e.g., \u03c3\u2011profiles, electronic and steric parameters), (ii) feed them into a non\u2011linear ensemble or deep\u2011kernel model, and (iii) use the model\u2019s uncertainty estimates to iteratively augment the training set for solvents that were previously unseen.",
      "url": ""
    },
    {
      "title": "Machine learning and molecular descriptors enable rational solvent selection in asymmetric catalysis",
      "text": "Yehia Amar \nDepartment of Chemical Engineering and Biotechnology\nUniversity of Cambridge\nPhilippa Fawcett DriveCB3 0ASCambridgeUnited Kingdom\n\nArtur M Schweidtmann \nAachener Verfahrenstechnik -Process Systems Engineering\nRWTH Aachen University\nAachenGermany\n\nLiwei Cao \nDepartment of Chemical Engineering and Biotechnology\nUniversity of Cambridge\nPhilippa Fawcett DriveCB3 0ASCambridgeUnited Kingdom\n\nPaul Deutsch \nUCB Pharma S.A. All\u00e9e de la Recherche\n60 1070BrusselsBelgium\n\nAlexei Lapkin \nDepartment of Chemical Engineering and Biotechnology\nUniversity of Cambridge\nPhilippa Fawcett DriveCB3 0ASCambridgeUnited Kingdom\n\nCREATE Tower\nCambridge Centre for Advanced Research and Education in Singapore Ltd\n1 Create Way#05-05, 138602Singapore\n\nMachine learning and molecular descriptors enable rational solvent selection in asymmetric catalysis Supporting Information\nCONFIDENTIAL S1 Contents:\n\n\nTest set of GP models for conversion and d.e.\n\nThe developed surrogate model, trained on reaction outcomes of the 25 solvents shown in Figure 2, and using descriptors of model 1 (see Table 1), was used to predict outcomes on a test set of 9 separate solvents selected at random from the initial human-selected set, see Figure S1.\n\nThen a new surrogate model was trained on further data -the outcomes of the algorithmidentified experimentally tested solvents dibutyl amine, methyl octanoate, eucalyptol, and ethyl acetate -showing that the predictive performance has gone from poor ( Figure S1, test set of algorithm trained on 25 initial data) to excellent ( Figure S2, model trained on 29 data, 25 initial + first suggested 4) through retraining on the new data suggested.  showing that the model is better than the initial model predictions using Model 1. Figure S4 shows model predictions using Model 4.    Figure S5. Leave-one-out cross-validation using Model 1.    Figure S9. \u03c3-profiles of the mixtures as a linear combination of pure component profiles. Figure S10. Visualisation of conversion (%) in different solvents (data points) vs. t1 and t2. CONFIDENTIAL S10 \n\n\nNew solvents identified using TS-EMO, and outcomes\n\n\nCross validations using different models\n\n\nTPOT suggested recipes and outcomes\n\nFigure S1 .Figure S2 .\nS1S2Results on test set using initial model using Model 1. Model after first four suggested solvents are included in training (using Model 1).\n\nFigure\nS3 shows the model predictions using model 2, trained on the initial 25 solvents,\n\nFigure S3 .\nS3Initial model predictions (Model 2).\n\nFigure S4 .\nS4Initial model predictions (Model 3).\n\nFigure S6 .Figure S7 .\nS6S7Leave-one-out cross-validation using Model 2. Leave-one-out cross-validation using Model 3.4. Experimental set-up illustration.\n\nFigure S8 .\nS8Illustration of experimental kit.\n\nTable S1 .\nS1New solvents selected using Model 1 DoE approach. Table S3. New solvents selected using Model 3 DoE approach.Entry \nSolvent \nMeasured conversion (%) \nMeasured d.e. (%) \n1 \ndibutyl amine \n90 \n68 \n2 \nethyl acetate \n55 \n55 \n3 \neucalyptol \n96 \n56 \n4 \nmethyl octanoate \n92 \n58 \n5 \naniline \n69 \n67 \n6 \nmethyl pentanoate \n87 \n60 \n7 \npropyl propanoate \n68 \n59 \n8 \nbutyronitrile \n68 \n51 \n\nTable S2. New solvents selected using Model 2 DoE approach. \n\nEntry \nSolvent \nMeasured conversion (%) \nMeasured d.e. (%) \n1 \nmethyl pentanoate \n87 \n60 \n2 \npropyl propanoate \n68 \n59 \n3 \n5-nonanone \n90 \n56 \n4 \n1-nonanol \n96 \n70 \n5 \nbutyronitrile \n68 \n51 \n6 \ntert-butylamine \n75 \n62 \n\nEntry \nSolvent \nMeasured conversion (%) \nMeasured d.e. (%) \n1 \npropyl propanoate \n68 \n59 \n2 \n2,6-dimethyl-4-heptanone \n92 \n57 \n3 \nbutyronitrile \n68 \n51 \n4 \n2,4-dimethyl pentane \n94 \n64 \n5 \n2,3-dimethyl pentane \n93 \n60 \n6 \npropyl benzene \n95 \n60 \n7 \ncumene \n95 \n59 \n8 \nmesitylene \n92 \n60 \n9 \ntributyl amine \n98 \n66 \n\nCONFIDENTIAL \n\nS6 \n\n\n\nTable S4 .\nS4Solvents mixing recipes and outcomes. Pareto front in green. x1 = triethyl amine, x2= 1-octanol, x3 = tributyl amine, x4 = 1-nonanol. * algorithm-determined. \n\nEntry T (\u00b0C) x1 \nx2 \nx3 \nx4 conv. (%) d.e. (%) \n1 \n70 \n1.00 \n-\n-\n-\n97 \n61 \n2 \n70 \n0.80 0.20 \n-\n-\n96 \n65 \n3 \n70 \n0.50 0.50 \n-\n-\n97 \n67 \n4 \n70 \n0.20 0.80 \n-\n-\n98 \n69 \n5 \n70 \n0.10 0.90 \n-\n-\n96 \n69 \n6 \n70 \n-\n1.00 \n-\n-\n87 \n69 \n7 \n70 \n-\n-\n1.00 \n-\n98 \n66 \n8 \n70 \n-\n-\n-\n1.00 \n96 \n70 \n9 \n90 \n-\n-\n1.00 \n-\n>99 \n57 \n10 \n90 \n-\n-\n0.50 0.50 \n>99 \n62 \n11 \n90 \n-\n-\n-\n1.00 \n>99 \n62 \n12 \n90 \n1.00 \n-\n-\n-\n>99 \n53 \n13 \n90 \n-\n1.00 \n-\n-\n>99 \n63 \n14 \n50 \n0.80 0.20 \n-\n-\n64 \n70 \n15 \n50 \n0.20 0.80 \n-\n-\n69 \n74 \n16 \n50 \n1.00 \n-\n-\n-\n57 \n68 \n17 \n50 \n-\n1.00 \n-\n-\n54 \n74 \n18* \n82 \n0.81 0.13 0.06 \n-\n>99 \n59 \n19* \n82 \n-\n0.65 0.25 0.10 \n>99 \n65 \n20* \n82 \n-\n0.58 0.30 0.12 \n>99 \n66 \n21* \n82 \n0.01 0.66 0.19 0.14 \n>99 \n65 \n22* \n82 \n-\n0.56 0.30 0.14 \n>99 \n64 \n23* \n65 \n0.99 \n-\n0.01 \n-\n90 \n63 \n24* \n65 \n0.64 0.30 0.01 0.05 \n90 \n67 \n25* \n65 \n0.21 0.56 0.22 0.01 \n96 \n70 \n26* \n65 \n0.69 0.26 0.05 \n-\n91 \n66 \n27* \n65 \n0.17 0.50 0.24 0.09 \n94 \n69 \n28* \n52 \n0.08 0.07 0.86 0.03 \n76 \n73 \n29* \n52 \n0.93 0.01 0.05 0.01 \n55 \n67 \n30* \n52 \n0.67 0.01 0.25 0.07 \n58 \n68 \n31* \n52 \n-\n0.12 0.07 0.81 \n69 \n75 \n32* \n52 \n0.81 \n-\n0.14 0.05 \n52 \n68 \n\nCONFIDENTIAL \n\nS9 \n\n\n\nTable S5 .Table S9 .\nS5S9TPOT suggestion solvents method results. * simulated.Table S7. TPOT iteration 2 hyperparameters of conversion and d.e. models after training on 15 experimental data for amplification (prediction of 90 new data points). Classification accuracy based on 10-fold cross validation: 0.81 Table S8. TPOT iteration 3 hyperparameters of conversion and d.e. models after training on 22 experimental data for amplification (prediction of 90 new data points). min_samples_split=15, n_estimators=100, subsample=0.75) \u2022 Classification accuracy based on 10-fold cross validation: 0.94 Hyperparameters of conversion and d.e. models based on 58 data to create highestfidelity models for simulation of all data points in iteration 4.Entry Iteration Solvent \nOutcome (conv), % \nOutcome (d.e.), % \n1 \n1 \n2-butanol \n61.0 \n71.0 \n2 \n1 \n2-pentanone \n66.0 \n56.0 \n3 \n1 \n4-methyl-2-pentanone \n71.0 \n56.0 \n4 \n1 \n2-propanone \n62.0 \n56.0 \n5 \n1 \ncyclohexanone \n59.5 \n55.5 \n6 \n1 \n2-butanone \n67.0 \n56.0 \n7 \n1 \ntoluene \n88.0 \n56.5 \n8 \n1 \nacetonitrile \n38.5 \n52.0 \n9 \n1 \ndiethyl carbonate \n63.5 \n60.5 \n10 \n1 \ndimethyl sulfoxide \n35.0 \n72.0 \n11 \n2 \ndiethyl ether \n82.0 \n57.5 \n12 \n2 \nbutyronitrile \n68.0 \n51.0 \n13 \n2 \noctylamine \n88.0 \n58.0 \n14 \n2 \n2-methyl-2-\npropanamine \n\n75.0 \n62.0 \n\n15 \n2 \ndimethyl carbonate \n58.0 \n58.0 \n16 \n3 \n1-nonanol \n95.0 \n69.0 \n17 \n3 \nundecanol \n98.0 \n69.0 \n18 \n3 \noctanol \n88.0 \n69.0 \n19 \n3 \n4-methylanisole \n96.0 \n60.0 \n20 \n3 \n1-methoxy-2-\nmethylbenzene \n\n87.0 \n59.0 \n\n21 \n3 \nN,N-dimethylaniline \n87.0 \n58.0 \n22 \n3 \nmethyl dodecanoate \n82.0 \n55.0 \n23* \n4 \n1-dodecanol \n95.58 \n69.66 \n24* \n4 \n2-methyl-1-heptanol \n88.62 \n68.98 \n25* \n4 \n2-methyl-3-heptanol \n89.03 \n68.16 \n26* \n4 \n2-octanol \n87.96 \n69.73 \n27* \n4 \n3-heptanol \n83.28 \n69.16 \n28* \n4 \n3-octanol \n88.41 \n69.01 \n29* \n4 \n4-heptanol \n83.28 \n69.08 \n30* \n4 \n4-octanol \n89.12 \n68.97 \n31* \n4 \ndecanol \n94.95 \n69.44 \n32* \n4 \nheptanol \n79.51 \n68.59 \n33* \n4 \n4-methyl-3-heptanol \n89.45 \n69.48 \nTable S6. TPOT iteration 1 hyperparameters of conversion and d.e. models after training on \n\n10 experimental data for amplification (prediction of 90 new data points). \n\nDescriptors model \nVariable \nGP1 \nGP2 \nModel 4 \nt1 (\u03c32', R, vM, lnP) \n2.09 \n-\nModel 4 \nt2 (TB, TM) \n1.72 \n-\nModel 4 \nt3 (\u03c1, \u03c33') \n1.64 \n-\nModel 1 \n\n\" \n\n-\n11.70 \nModel 1 \n\n# \n\n-\n15.52 \nModel 1 \n\n$ \n\n-\n19.52 \nModel 1 \n\n% \n\n-\n0.34 \nModel 1 \n\n& \n\n-\n8.46 \n\nTPOT result: \n\n\u2022 Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.1, \nmax_depth=3, max_features=0.35, min_samples_leaf=9, min_samples_split=4, \nn_estimators=100, subsample=1.0). \n\u2022 Classification accuracy based on 10-fold cross validation: 0.73 \n\nDescriptors model \nVariable \nGP1 \nGP2 \nModel 4 \nt1 (\u03c32', R, vM, lnP) \n1.53 \n-\nModel 4 \nt2 (TB, TM) \n2.34 \n-\nModel 4 \nt3 (\u03c1, \u03c33') \n4.28 \n-\nModel 1 \n\n\" \n\n-\n0.98 \nModel 1 \n\n# \n\n-\n13.06 \nModel 1 \n\n$ \n\n-\n10.39 \nModel 1 \n\n% \n\n-\n1.62 \nModel 1 \n\n& \n\n-\n1.20 \n\nTPOT result: \n\n\u2022 Best pip...",
      "url": "https://pubs.rsc.org/en/content/articlepdf/2019/sc/c9sc01844a"
    },
    {
      "title": "A unified ML framework for solubility prediction across organic solvents - Digital Discovery (RSC Publishing)",
      "text": "A unified ML framework for solubility prediction across organic solvents - Digital Discovery (RSC Publishing)\n[\nJump to main content![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)\n](#maincontent)[\nJump to site search![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)\n](#SearchText)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/menu-light.png)](#)\n[Publishing](https://pubs.rsc.org/)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/search-light.png)](#)\nSearch\n![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right.png)[Advanced](https://pubs.rsc.org/en/search/advancedsearch)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/user-light.png)](https://pubs.rsc.org/en/account/logon)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/trolley-light.png)](https://www.rsc.org/basket/shoppingcart/orderitems?returnurl=https://pubs.rsc.org/en/content/articlelanding/2023/dd/d2dd00024e)\n[![Royal Society of Chemistry homepage](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/rsc-logo-rev-pubs.svg)](https://www.rsc.org)\nSearch\n**![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right.png)\nYou must enter a search term\n[Advanced search](https://pubs.rsc.org/en/search/advancedsearch)\n[Issue 2, 2023](https://pubs.rsc.org/en/journals/journal/dd?issueid=dd002002&amp;type=current)\n[\n![](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=CoverIssue&amp;imageInfo.ImageIdentifier.SerCode=DD&amp;imageInfo.ImageIdentifier.IssueId=DD002002)\nFrom the journal:### Digital Discovery\n](https://pubs.rsc.org/en/journals/journal/dd)\n## A unified ML framework for solubility prediction across organic solvents[&#8224;](#fn1)\n![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg)\n[Antony D.\rVassileiou](https://pubs.rsc.org/en/results?searchtext=Author:Antony%20D.%20Vassileiou),[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0001-8146-8972)\\**a*[Murray N.\rRobertson](https://pubs.rsc.org/en/results?searchtext=Author:Murray%20N.%20Robertson),[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0001-9543-7667)*b*[Bruce G.\rWareham](https://pubs.rsc.org/en/results?searchtext=Author:Bruce%20G.%20Wareham),*c*[Mithushan\rSoundaranathan](https://pubs.rsc.org/en/results?searchtext=Author:Mithushan%20Soundaranathan),*c*[Sara\rOttoboni](https://pubs.rsc.org/en/results?searchtext=Author:Sara%20Ottoboni),*b*[Alastair J.\rFlorence](https://pubs.rsc.org/en/results?searchtext=Author:Alastair%20J.%20Florence),*b*[Thoralf\rHartwig](https://pubs.rsc.org/en/results?searchtext=Author:Thoralf%20Hartwig)*d*and[Blair F.\rJohnston](https://pubs.rsc.org/en/results?searchtext=Author:Blair%20F.%20Johnston)[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0001-9785-6822)\\**abe*\n[Author affiliations](#)\n\\*Corresponding authors\naEPSRC ARTICULAR, University of Strathclyde, Glasgow, UK\n**E-mail:**[antony.vassileiou@strath.ac.uk](mailto:antony.vassileiou@strath.ac.uk),[blair.johnston@strath.ac.uk](mailto:blair.johnston@strath.ac.uk)\nbEPSRC CMAC Future Manufacturing Hub, University of Strathclyde, Glasgow, UK\ncDoctoral Training Centre in Continuous Manufacturing and Crystallisation, University of Strathclyde, Glasgow, UK\ndGlaxoSmithKline, GSK Medicines Research Centre, Gunnels Wood Road, Stevenage, UK\neNational Physical Laboratory, Teddington, UK\n### Abstract\nWe report a single machine learning (ML)-based model to predict the solubility of drug/drug-like compounds across 49 organic solvents, extensible to more. By adopting a cross-solvent data structure, we enable the exploitation of valuable relational information between systems. The effect is major, with even a single experimental measurement of a solute in a different solvent being enough to significantly improve predictions on it, and successive ones improving them further. Working with a sparse dataset of only 714 experimental data points spanning 75 solutes and 49 solvents (81% sparsity), a ML-based model with a prediction RMSE of 0.75\u2006log*S*(g/100 g) for unseen solutes was produced. This compares favourably with conductor-like screening model for real solvents (COSMO-RS), an industry-standard model based on thermodynamic laws, which yielded a prediction RMSE of 0.97 for the same dataset. The error for our method reduced to a mean RMSE of 0.65 when one instance of the solute (in a different solvent) was included in the training data; this iteratively reduced further to 0.60, 0.57 and 0.56 when two, three and four instances were available, respectively. This standard of performance not only meets or exceeds those of alternative ML-based solubility models insofar as they can be compared but reaches the perceived ceiling for solubility prediction models of this type. In parallel, we assess the performance of the model with and without the addition of COSMO-RS output as an additional descriptor. We find that a significant benefit is gained from its addition, indicating that mechanistic methods can bring insight that simple molecular descriptors cannot and should be incorporated into a data-driven prediction of molecular properties where possible.\n![Graphical abstract: A unified ML framework for solubility prediction across organic solvents](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=GA&amp;imageInfo.ImageIdentifier.ManuscriptID=D2DD00024E&amp;imageInfo.ImageIdentifier.Year=2023)\nThis article is Open Access\n![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/Ajax-GA-Loader.gif)Please wait while we load your content...Something went wrong.[Try again?](#)\n[About](#pnlAbstract)\n[Cited by](#pnlCitation)\n[Related](#pnlRelatedContent)\n[Download optionsPlease wait...](#)\n## Supplementary files\n* [Supplementary informationPDF (894K)](https://www.rsc.org/suppdata/d2/dd/d2dd00024e/d2dd00024e1.pdf)\n## Transparent peer review\nTo support increased transparency, we offer authors the option to publish the peer review history alongside their article.\n[View this article\u2019s peer review history](https://www.webofscience.com/api/gateway/wos/peer-review/10.1039/D2DD00024E)\n## Article information\nDOI[https://doi.org/10.1039/D2DD00024E](https://doi.org/10.1039/D2DD00024E)\n**Article type**Paper\nSubmitted29 Mar 2022\nAccepted08 Dec 2022\nFirst published19 Jan 2023\n![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/open-access-icon-orange.png)\n**This article is Open Access**[![Creative Commons BY license](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/CCBY.svg)](http://creativecommons.org/licenses/by/3.0/)\n### DownloadCitation\n***Digital Discovery***, 2023,**2**, 356-367\nBibTexEndNoteMEDLINEProCiteReferenceManagerRefWorksRIS\n### Permissions\n[Request permissions](#)\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](#)### A unified ML framework for solubility prediction across organic solvents\nA. D. Vassileiou, M. N. Robertson, B. G. Wareham, M. Soundaranathan, S. Ottoboni, A. J. Florence, T. Hartwig and B. F. Johnston,*Digital Discovery*, 2023,**2**, 356**DOI:**10.1039/D2DD00024E\nThis article is licensed under a[Creative Commons Attribution 3.0 Unported Licence](https://creativecommons.org/licenses/by/3.0/).**You can use material from this article in other publications without requesting further permissions**from the RSC, provided that the correct acknowledgement is given.\nRead more about[how to correctly acknowledge RSC content](https://www.rsc.org/journals-books-databases/journal-authors-reviewers/licences-copyright-permissions/#acknowledgements).\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](#)\n### Social activity\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.191/content/NewImages/twitter.svg)Tweet](https://twitter.com/intent/tweet/?text=A+unified+ML+framework+for+solubility+prediction+across+organic...",
      "url": "https://pubs.rsc.org/en/content/articlelanding/2023/dd/d2dd00024e"
    },
    {
      "title": "The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions",
      "text": "[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2023/sc/d3sc03902a)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03539e)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03641c)\n\nOpen Access Article\nThis Open Access Article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D3SC03902A](https://doi.org/10.1039/D3SC03902A)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2023, **14**, 10835-10846\n\n# The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions [\u2020](https://pubs.rsc.org/pubs.rsc.org\\#fn1)\n\nZhen\nLiu\na,\nYurii S.\nMoroz\nbcd and Olexandr\nIsayev\n\\*aaDepartment of Chemistry, Mellon College of Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA. E-mail: [olexandr@olexandrisayev.com](mailto:olexandr@olexandrisayev.com)bEnamine Ltd, Ky\u00efv, 02660, UkrainecChemspace LLC, Ky\u00efv, 02094, UkrainedTaras Shevchenko National University of Ky\u00efv, Ky\u00efv, 01601, Ukraine\n\nReceived\n27th July 2023\n, Accepted 12th September 2023\n\nFirst published on 13th September 2023\n\n## Abstract\n\nAccurate prediction of reaction yield is the holy grail for computer-assisted synthesis prediction, but current models have failed to generalize to large literature datasets. To understand the causes and inspire future design, we systematically benchmarked the yield prediction task. We carefully curated and augmented a literature dataset of 41239 amide coupling reactions, each with information on reactants, products, intermediates, yields, and reaction contexts, and provided 3D structures for the molecules. We calculated molecular features related to 2D and 3D structure information, as well as physical and electronic properties. These descriptors were paired with 4 categories of machine learning methods (linear, kernel, ensemble, and neural network), yielding valuable benchmarks about feature and model performance. Despite the excellent performance on a high-throughput experiment (HTE) dataset (R2 around 0.9), no method gave satisfactory results on the literature data. The best performance was an R2 of 0.395 \u00b1 0.020 using the stack technique. Error analysis revealed that reactivity cliff and yield uncertainty are among the main reasons for incorrect predictions. Removing reactivity cliffs and uncertain reactions boosted the R2 to 0.457 \u00b1 0.006. These results highlight that yield prediction models must be sensitive to the reactivity change due to the subtle structure variance, as well as be robust to the uncertainty associated with yield measurements.\n\n## Introduction\n\nComputer-assisted synthesis prediction (CASP) is a field of computational chemistry that aims to develop algorithms and software tools to assist chemists in predicting the outcomes of chemical reactions. CASP uses machine learning (ML) and artificial intelligence (AI) techniques to predict the feasibility, yield, and optimal conditions for a chemical reaction. Recent exploratory studies in the field of reaction predictions, show applications in retrosynthesis, [1,2](https://pubs.rsc.org/pubs.rsc.org#cit1) product prediction, [3\u20135](https://pubs.rsc.org/pubs.rsc.org#cit3) selectivity, [6](https://pubs.rsc.org/pubs.rsc.org#cit6) and other relevant tasks. [7,8](https://pubs.rsc.org/pubs.rsc.org#cit7) Accurately predicting reaction yields is one of the key objectives in CASP as many reaction-related tasks can be framed as yield optimization problems. Yield serves as the ultimate metric for selecting reagents in a single reaction or planning a synthesis pathway. However, despite its importance, predicting the theoretical yield remains challenging because the yield depends on many observable and unobservable factors throughout the reaction process, including the interaction between molecules, environment conditions, and human operations.\n\nWhile impressive yield prediction performance (R2 is around 0.9) has been achieved in many high-throughput experiment (HTE) datasets, the yield prediction R2 score on large literature datasets is usually unsatisfactory. [9\u201316](https://pubs.rsc.org/pubs.rsc.org#cit9) For example, the Doyle group reported an example of predicting reaction yields with a random forest model on the Buchwald\u2013Hartwig HTE dataset. [9](https://pubs.rsc.org/pubs.rsc.org#cit9) The dataset contains 4608 C\u2013N cross-coupling reactions and the R2 score and mean absolute error (MAE) were 0.92 and 7.8%, respectively. Since then, the dataset has become a standard benchmark dataset for many yield prediction models. Schwaller et al. reported a Yield-BERT model for reaction yield predictions. [10](https://pubs.rsc.org/pubs.rsc.org#cit10) Although the R2 score for the yield prediction task was as high as 0.94 on the Buchwald\u2013Hartwig dataset, [9](https://pubs.rsc.org/pubs.rsc.org#cit9) the performance dropped sharply (i.e., R2 around 0.2) on the literature dataset. [17,18](https://pubs.rsc.org/pubs.rsc.org#cit17) The staggering performance difference of yield prediction on the HTE dataset and the literature dataset is widespread. Recently, Grzybowski [11](https://pubs.rsc.org/pubs.rsc.org#cit11) and Glorius [15](https://pubs.rsc.org/pubs.rsc.org#cit15) studied this phenomenon, suggesting that the unsatisfactory ML performance may be due to the popular trend in the literature dataset induced by human bias in experiment design and result reporting. However, augmenting the dataset with zero or low-yield reactions did not significantly improve the performance, indicating that additional factors might degrade the model performance.\n\nTo understand the causes for failures in a large literature dataset, we systematically investigated the yield prediction task. We tested 4 categories of ML models (i.e., linear methods, kernel methods, ensemble methods, and neural networks) on an HTE yield dataset and a large literature yield dataset. We utilized a set of 4608 Buchwald\u2013Hartwig reactions from Doyle [9](https://pubs.rsc.org/pubs.rsc.org#cit9) et al. to represent the HTE dataset, given its extensive prior modeling. We curated 41239 amide coupling reactions from Reaxys [19](https://pubs.rsc.org/pubs.rsc.org#cit19) to represent the literature dataset. These reactions were chosen due to their significance in medicinal chemistry and the substantial volume of available data. While the Buchwald\u2013Hartwig reactions and the amide coupling reactions are very different, they possess characteristics inherent to the HTE and large literature datasets, respectively. The phenomena observed in the context of Buchwald\u2013Hartwig reactions and amide coupling reactions can be extrapolated to typical HTE datasets and large literature datasets, respectively. Besides the SMILES of reactants and products, the reaction context (i.e., time, temperature, reagents, condition, and solvent) was also extracted where possible from Reaxys to construct the amide coupling dataset. Please note that the reaction yields were extracted as they appeared in the Reaxys database, regardless of the reaction scale. Also, we augmented the literature dataset with reaction intermediates, optimized 3D structures of the molecules, and 2D/3D descriptors derived from the SMILES and conformers. All amide coupling reactions were catalyzed by carbodiimides to minimize irrelevant variables in this investigation. The carbodiimides include 1-ethyl-3-(3-dimethylaminopropyl)carbodiimide (EDC), N,N\u2032-dicyclohexylcarbodiimide (DCC), and N,N\u2032-diisopropylcarbodiimide (DIC). The combination of different reaction descriptors and model categories enabled a systematic yield prediction benchmark, providing insights into the key factors that influence the reaction yield prediction challenge.\n\nOur results demonstrated that most models gave unsatisfactory predictions (R2 < 0.5) in a large and diverse literature dataset even if they achieved excellent predictions (R2 \\> 0.9) on a caref...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03902a"
    },
    {
      "title": "",
      "text": "Machine learning from quantum chemistry to\npredict experimental solvent effects on reaction\nrates\nYunsie Chung and William H. Green\u2217\nDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge,\nMA, 02139, U.S.A\nE-mail: whgreen@mit.edu\nAbstract\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic\nmodeling, chemical process design, and high-throughput solvent screening. Despite the\nrecent advance in machine learning, a scarcity of reliable data has hindered the devel\u0002opment of predictive models that are generalizable for diverse reactions and solvents.\nIn this work, we generate a large set of data with the COSMO-RS method for over\n28,000 neutral reactions and 295 solvents and train a machine learning model to pre\u0002dict the solvation free energy and solvation enthalpy of activation (\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv)\nfor a solution phase reaction. On unseen reactions, the model achieves mean absolute\nerrors of 0.71 and 1.03 kcal/mol for \u2206\u2206G\n\u2021\nsolv and \u2206\u2206H\n\u2021\nsolv, respectively, relative to the\nCOSMO-RS calculations. The model also provides reliable predictions of relative rate\nconstants within a factor of 4 when tested on experimental data. The presented model\ncan provide nearly instantaneous predictions of kinetic solvent effects or relative rate\nconstants for a broad range of neutral closed-shell or free radical reactions and solvents\nonly based on atom-mapped reaction SMILES and solvent SMILES strings.\n1\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\n1 Introduction\nAccurate prediction of reaction rates is essential for modeling a variety of chemical kinetic sys\u0002tems such as pyrolysis, 1,2 polymerization,3 oxidative degradation, 4,5 and atmospheric chem\u0002istry.6 Detailed kinetic models enable one to predict key products, identify major kinetic\npathways, and optimize reaction conditions for complex chemical systems. Kinetic mech\u0002anisms often involve hundreds to tens of thousands of elementary reactions, 7 and a fast,\nhigh-throughput method to estimate reaction rates is thus needed. Ab initio methods like\nquantum mechanics/molecular mechanics (QM/MM) can provide accurate predictions of rate\nconstants, but their high computational cost has been a major limiting factor for large-scale,\nautomated predictions. As more kinetic data become available, data-driven approaches such\nas linear group contribution, 8\u201310 decision tree based rate rules, 11,12 and machine learning\n(ML) models13\u201319 have emerged as more popular choices for estimating kinetic parameters.\nSeveral ML models15\u201317 have successfully predicted barrier heights and rate constants of\ndiverse gas phase reactions only based on readily available 2D information (e.g. SMILES\nstrings) of reactants and products. However, such predictive models for liquid/solution phase\nreactions have been lightly investigated with limited applicability. 20\nSolvents can have significant impacts on reaction rates and outcomes, and it is crucial to\naccurately predict these kinetic solvent effects. Recent research efforts have been devoted\nto employing ML (e.g. deep neural network) for free energy predictions of condensed phase\nreactions.15,18,19,21\u201326 Many of these studies 18,19,21\u201323,26 combine the ML models with semi\u0002empirical or lower-level QM/MM methods to obtain the energy predictions that match the\naccuracy of higher-level QM/MM methods. For example, G\u00b4omez-Flores et al. 19 used a ML\napproach to predict the energy difference between the density functional tight-binding model\nand other higher level QM methods for a thiol-disulfide exchange reaction in water. In a\nstudy by Pan et al.,18 a ML model was trained to reproduce ab initio QM/MM poten\u0002tials in free energy simulations for the aqueous Menshutkin reaction between ammonia and\nchloromethane. Farrar and Grayson26 employed ML models to predict DFT-quality activa\u0002tion barriers for various nitro-Michael addition reactions in toluene based on the features\ngenerated from semi-empirical methods. These approaches, however, require semi-empirical\nQM/MM steps that are less suitable for instantaneous, automatic rate predictions. Fur\u0002thermore, their models are limited to a single solvent and need the 3D coordinates or QM\nfeatures of reactants and transition states as inputs, which are not readily available.\nThe ML models by Jorner et al. 24 and by Heid and Green15 are the few cases that can\npredict reaction properties in multiple solvents only based on the 2D structural information\nof molecules. Jorner et al. 24 employed a Gaussian process regression model and compared\nseveral 2D structural features to predict the barrier height of 443 SNAr reactions in different\nsolvents. In their work, the best accuracy was reached by adopting the BERT27 reaction fin\u0002gerprint. Heid and Green, 15 on the other hand, used the condensed graph of reaction (CGR)\nas an input reaction representation for a graph convolutional neural network (GCNN). They\napplied the CGR GCNN model to the same SNAr data set and were able to achieve better\n2\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nbarrier height predictions compared to the other models that used the BERT fingerprint or\ndifferent reaction representations. While these models can provide fast kinetic estimations\nfor solution-phase reactions at a low computational cost, only one reaction family was con\u0002sidered with a relatively small training set. A larger data set that contains more diverse\ntypes of reactions and solvents is needed in order to train a more generalized model for\nkinetic solvent effect predictions. Moreover, both models used fixed descriptors to represent\nsolvents, but prior studies 15,28,29 revealed that the learned molecular representations based\non a graph convolutional approach outperform fixed molecular descriptors in many property\nprediction tasks.\nIn this study, we present a ML model that can predict kinetic solvent effects for a wide range\nof neutral reactions and solvents only based on atom-mapped reaction SMILES and solvent\nSMILES strings. More precisely, the model predicts the solvation free energy and solvation\nenthalpy of activation (\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv) for a reaction-solvent pair, which can be used\nto estimate a relative rate constant between a solution phase and a gas phase reaction or\nbetween the reaction in different solvents. Our model adopts a CGR GCNN architecture with\nseparate GCNN layers for solvent molecular encoding. A large, diverse set of training data\ncontaining over 28,000 reactions and 295 solvents is generated in this work by performing\nab initio COSMO-RS30 calculations. The performance of the model on unseen reactions is\nrigorously assessed by comparing the ML predictions with both COSMO-RS calculations\nand experimental data. A transfer learning approach and various additional features are\nexplored to further improve the model. Our ML model can provide accurate predictions of\nrelative rate constants, and together with the existing predictive models or databases for gas\nphase rate constants (e.g. RMG database 12), it can provide the estimates of absolute rate\nconstants for many different liquid phase reactions.\n2 Background on the prediction targets\nFigure 1: Potential energy diagram of a reaction in a gas phase and a solution phase.\n3\nhttps://doi.org/10.26434/chemrxiv-2023-f20bg-v2 ORCID: https://orcid.org/0000-0002-3097-010X Content not peer-reviewed by ChemRxiv. License: CC BY 4.0\nOur ML model aims to predict the solvation free energy and solvation enthalpy of activation\n(\u2206\u2206G\n\u2021\nsolv, \u2206\u2206H\n\u2021\nsolv) at 298 K for a reaction in a solvent. Solvation free energy (\u2206Gsolv)\nand solvation enthalpy (\u2206Hsolv) are the changes in Gibbs free energy and enthalpy when a\nmolecule is transferred from an ideal gas to a solvent at a fixed condition. The \u2206\u2206G\n\u2021\nsolv\nand \u2206\u2206...",
      "url": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6524d5a4bda59ceb9a38ccec/original/machine-learning-from-quantum-chemistry-to-predict-experimental-solvent-effects-on-reaction-rates.pdf"
    },
    {
      "title": "Predicting Reaction Yields via Supervised Learning - PubMed",
      "text": "Clipboard, Search History, and several other advanced features are temporarily unavailable.\n\n [Skip to main page content](https://pubmed.ncbi.nlm.nih.gov/33788552/#article-details)\n\n![Dot gov](https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-dot-gov.svg)\n\n**The .gov means it\u2019s official.**\n\nFederal government websites often end in .gov or .mil. Before\nsharing sensitive information, make sure you\u2019re on a federal\ngovernment site.\n\n![Https](https://www.ncbi.nlm.nih.gov/coreutils/uswds/img/icon-https.svg)\n\n**The site is secure.**\n\nThe **https://** ensures that you are connecting to the\nofficial website and that any information you provide is encrypted\nand transmitted securely.\n\n[Access keys](https://www.ncbi.nlm.nih.gov/guide/browsers/#ncbi_accesskeys) [NCBI Homepage](https://www.ncbi.nlm.nih.gov) [MyNCBI Homepage](https://pubmed.ncbi.nlm.nih.gov/myncbi/) [Main Content](https://pubmed.ncbi.nlm.nih.gov/33788552/#maincontent) [Main Navigation](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n\n[![pubmed logo](https://cdn.ncbi.nlm.nih.gov/pubmed/de3675f9-e3b3-4656-8215-6fc84d4c88ab/core/images/pubmed-logo-blue.svg)](https://pubmed.ncbi.nlm.nih.gov/)\n\nSearch:\nSearch\n\n[Advanced](https://pubmed.ncbi.nlm.nih.gov/advanced/) [Clipboard](https://pubmed.ncbi.nlm.nih.gov/clipboard/)\n\n[User Guide](https://pubmed.ncbi.nlm.nih.gov/help/)\n\nSave\n\nEmail\n\nSend to\n\n- [Clipboard](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n- [My Bibliography](https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpubmed.ncbi.nlm.nih.gov%2F33788552%2F%23open-bibliography-panel)\n- [Collections](https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpubmed.ncbi.nlm.nih.gov%2F33788552%2F%23open-collections-panel)\n- [Citation manager](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n\nDisplay options\n\nDisplay options\n\nFormat\nAbstractPubMedPMID\n\n## Save citation to file\n\nFormat:\nSummary (text)PubMedPMIDAbstract (text)CSV\n\nCreate file\n\nCancel\n\n## Email citation\n\nSubject:\n1 selected item: 33788552 - PubMed\n\nTo:\n\nFrom:\n\nFormat:\nSummarySummary (text)AbstractAbstract (text)\n\nMeSH and other data\n\nSend email\n\nCancel\n\n### Add to Collections\n\n- Create a new collection\n- Add to an existing collection\n\nName your collection:\n\nName must be less than 100 characters\n\nChoose a collection:\n\nUnable to load your collection due to an error\n\n[Please try again](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n\nAdd\n\nCancel\n\n### Add to My Bibliography\n\n- My Bibliography\n\nUnable to load your delegates due to an error\n\n[Please try again](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n\nAdd\n\nCancel\n\n## Your saved search\n\nName of saved search:\n\nSearch terms:\n\n[Test search terms](https://pubmed.ncbi.nlm.nih.gov/33788552/)\n\nWould you like email updates of new search results?Saved Search Alert Radio Buttons\n\n- Yes\n- No\n\nEmail:\n( [change](https://www.ncbi.nlm.nih.gov/account/settings/))\n\nFrequency:\nMonthlyWeeklyDaily\n\nWhich day?\nThe first SundayThe first MondayThe first TuesdayThe first WednesdayThe first ThursdayThe first FridayThe first SaturdayThe first dayThe first weekday\n\nWhich day?\nSundayMondayTuesdayWednesdayThursdayFridaySaturday\n\nReport format:\nSummarySummary (text)AbstractAbstract (text)PubMed\n\nSend at most:\n1 item5 items10 items20 items50 items100 items200 items\n\nSend even when there aren't any new results\n\nOptional text in email:\n\nSave\n\nCancel\n\n## Create a file for external citation management software\n\nCreate file\n\nCancel\n\n## Your RSS Feed\n\nName of RSS Feed:\n\nNumber of items displayed:\n510152050100\n\nCreate RSS\n\nCancel\n\nRSS Link\nCopy\n\nFull text links\nCite\n\nDisplay options\n\nDisplay options\n\nFormat\nAbstractPubMedPMID\n\n## Abstract\n\nNumerous disciplines, such as image recognition and language translation, have been revolutionized by using machine learning (ML) to leverage big data. In organic synthesis, providing accurate chemical reactivity predictions with supervised ML could assist chemists with reaction prediction, optimization, and mechanistic interrogation.To apply supervised ML to chemical reactions, one needs to define the object of prediction (e.g., yield, enantioselectivity, solubility, or a recommendation) and represent reactions with descriptive data. Our group's effort has focused on representing chemical reactions using DFT-derived physical features of the reacting molecules and conditions, which serve as features for building supervised ML models.In this Account, we present a review and perspective on three studies conducted by our group where ML models have been employed to predict reaction yield. First, we focus on a small reaction data set where 16 phosphine ligands were evaluated in a single Ni-catalyzed Suzuki-Miyaura cross-coupling reaction, and the reaction yield was modeled with linear regression. In this setting, where the regression complexity is strongly limited by the amount of available data, we emphasize the importance of identifying single features that are directly relevant to reactivity. Next, we focus on models trained on two larger data sets obtained with high-throughput experimentation (HTE). With hundreds to thousands of reactions available, more complex models can be explored, for example, models that algorithmically perform feature selection from a broad set of candidate features. We examine how a variety of ML algorithms model these data sets and how well these models generalize to out-of-sample substrates. Specifically, we compare the ML models that use DFT-based featurization to a baseline model that is obtained with features that carry no physical information, that is, random features, and to a naive non-ML model that averages yields of reactions that share the same conditions and substrate combinations. We find that for only one of the two data sets, DFT-based featurization leads to a significant, although moderate, out-of-sample prediction improvement. The source of this improvement was further isolated to specific features which allowed us to formulate a testable mechanistic hypothesis that was validated experimentally. Finally, we offer remarks on supervised ML model building on HTE data sets focusing on algorithmic improvements in model training.Statistical methods in chemistry have a rich history, but only recently has ML gained widespread attention in reaction development. As the untapped potential of ML is explored, novel tools are likely to arise from future research. Our studies suggest that supervised ML can lead to improved predictions of reaction yield over simpler modeling methods and facilitate mechanistic understanding of reaction dynamics. However, further research and development is required to establish ML as an indispensable tool in reactivity modeling.\n\n[PubMed Disclaimer](https://pubmed.ncbi.nlm.nih.gov/disclaimer/)\n\n## Similar articles\n\n- [Molecular Machine Learning for Chemical Catalysis: Prospects and Challenges.](https://pubmed.ncbi.nlm.nih.gov/36715248/)\n\nSingh S, Sunoj RB.Singh S, et al.Acc Chem Res. 2023 Feb 7;56(3):402-412. doi: 10.1021/acs.accounts.2c00801. Epub 2023 Jan 30.Acc Chem Res. 2023.PMID: 36715248\n\n- [Ultrahigh-Throughput Experimentation for Information-Rich Chemical Synthesis.](https://pubmed.ncbi.nlm.nih.gov/33891404/)\n\nMahjour B, Shen Y, Cernak T.Mahjour B, et al.Acc Chem Res. 2021 May 18;54(10):2337-2346. doi: 10.1021/acs.accounts.1c00119. Epub 2021 Apr 23.Acc Chem Res. 2021.PMID: 33891404\n\n- [Importance of Engineered and Learned Molecular Representations in Predicting Organic Reactivity, Selectivity, and Chemical Properties.](https://pubmed.ncbi.nlm.nih.gov/33534534/)\n\nGallegos LC, Luchini G, St John PC, Kim S, Paton RS.Gallegos LC, et al.Acc Chem Res. 2021 Feb 16;54(4):827-836. doi: 10.1021/acs.accounts.0c00745. Epub 2021 Feb 3.Acc Chem Res. 2021.PMID: 33534534\n\n- [Translational Metabolomics of Head Injury: Exploring Dysfunctional Cerebral Metabolism with Ex Vivo NMR Spectroscopy-Based Metabolite Quantification.](https://pubmed.ncbi.nlm.nih.gov/26269925/)\n\nWolahan SM, Hirt D, Glenn TC.Wolahan SM, et al.In: Kobeissy FH, editor. Brain Neurotrauma: Mo...",
      "url": "https://pubmed.ncbi.nlm.nih.gov/33788552"
    },
    {
      "title": "Predicting the outcomes of organic reactions via machine learning: are current descriptors sufficient?",
      "text": "Scientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 1\nwww.nature.com/scientificreports\nPredicting the outcomes of organic \nreactions via machine learning: are \ncurrent descriptors sufficient?\nG. Skoraczy\u0144ski1, P. Dittwald2, B. Miasojedow1, S. Szymku\u01072, E. P. Gajewska2, \nB. A. Grzybowski2,3 & A. Gambin1\nAs machine learning/artificial intelligence algorithms are defeating chess masters and, most recently, \nGO champions, there is interest \u2013 and hope \u2013 that they will prove equally useful in assisting chemists \nin predicting outcomes of organic reactions. This paper demonstrates, however, that the applicability \nof machine learning to the problems of chemical reactivity over diverse types of chemistries remains \nlimited \u2013 in particular, with the currently available chemical descriptors, fundamental mathematical \ntheorems impose upper bounds on the accuracy with which raction yields and times can be predicted. \nImproving the performance of machine-learning methods calls for the development of fundamentally \nnew chemical descriptors.\nWith the dawn of the big-data era1\u20134\n, high hopes have been pinned at the ability of machine learning, ML, algo\u0002rithms5\n to analyze the large body of existing chemical data, and to derive from it models predictive of various \naspects of chemical reactivity. ML methods have already proven very successful in applications ranging from \nspeech or image recognition6\n, to medical diagnostics7, bioinformatics8, and economics9. There have also been \nsome encouraging examples of using ML to predict biological activities of small molecules10\u201312, solubilities13, \ncrystal structures14, properties of organic photovoltaics15 and, recently, compositions of reaction mixtures and/\nor reaction conditions leading to templated vanadium selenites16. This last example is quite spectacular in that \nmachine-learning performed better than the collective knowledge and intuition of chemists who had previously \nworked on the problem. On the other hand, demonstrations in organic synthetic chemistry are few in number \nand limited to narrow datasets of similar and/or very simple reaction classes17\u201321. What is largely missing are \nstudies that would quantify the general applicability of ML methods to diverse chemistries.\nThe main objective of this work is therefore to assess in a quantitative manner whether ML methods can pre\u0002dict the outcomes of diverse organic reaction with practically-relevant accuracy. In particular, we use a wide range \nof currently available chemical descriptors and various ML algorithms to examine whether they can predictively \ncategorize two quantities which are important in organic-synthetic practice and for which ample training exam\u0002ples are available (here, close to 0.5 million reactions each): (i) reaction yields (binary classification high vs. low) \nand (ii) reaction times (binary classification rapid vs. slow). It is important to note that the training set we use \ncomprises reactions not necessarily accounting for full stoichiometry (i.e., no atomically balanced; see examples \nin Fig.\u00a01). For reactions with manually curated full stoichiometry, thermodynamic models have recently been \nshown22 to achieve\u00b115% accuracy of yield prediction, However, organic reactions are typically drawn by chem\u0002ists without accounting for all small reagents or side-products \u2013 in this light, the current work is a real-world test \nfor the machine learning methods to extract reactivity trends from reactions as they are deposited in the chemical \nliterature or in reaction databases.\nThe results of our work are somewhat negative but, we believe, thought-provoking. Irrespective of the spe\u0002cific ML method applied, the number of molecules in the training set, or the nature and the number of features/\ndescriptors used to train the model, the accuracy of binary yield prediction is only c.a. 65\u00b15% (i.e., error ~35%) \nand that of reaction-time prediction, c.a. 75\u00b15% (error ~25%). Another important conclusion of this work is \n1Faculty of Mathematics, Informatics, and Mechanics, University of Warsaw, 02-097, Warsaw, Poland. 2DARPA \nMake-It Program & the Institute of Organic Chemistry, Polish Academy of Sciences, Warsaw, Poland. 3\nCenter for \nSoft and Living Matter of Korea\u2019s Institute for Basic Science (IBS), Department of Chemistry, Ulsan National Institute \nof Science and Technology, Ulsan, South Korea. G. Skoraczy\u0144ski and P. Dittwald contributed equally to this work. \nCorrespondence and requests for materials should be addressed to B.A.G. (email: grzybor72@unist.ac.kr) or A.G. \n(email: aniag@mimuw.edu.pl)\nReceived: 16 December 2016\nAccepted: 6 April 2017\nPublished: xx xx xxxx\nOPEN\nwww.nature.com/scientificreports/\nScientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 2\nthat it can be proven rigorously \u2013 by the so-called Bayes classifier error estimates \u2013 that with the currently avail\u0002able representations of molecules, (i.e., chemical descriptors), these outcomes cannot be significantly improved. \nNaturally, it can always be argued that \u201cbetter\u201d representations of molecules can be developed, though it is some\u0002what unclear how to account for the immense structural and mechanistic diversity of organic reactions23, their \noften-encountered sensitivity to reaction conditions, or even inherent day-to-day irreproducibilities in reaction \noutcomes. We will touch upon these interesting issues in the last part of the paper. In the meantime, we see the \nmain virtue of our work in potentially stimulating new research on molecular representations and their use in \nchemical machine-learning24.\nMethods\nDatasets. The initial datasets, courtesy of GSI and Reaxys, comprised ~1,000,000 reactions for which the \nyields were reported and ~600,000 reactions reporting reaction times. These sets were pruned for incomplete \nentries and duplicate reactions. When the same reaction was reported with multiple yields, the highest value \nwas taken; if the same reaction was reported with multiple times, the shortest one was chosen. Ultimately, each \nset comprised ~450,000 reaction entries of which 325,000 had both the yields and times reported (within this \ncommon subset, the values of yields and times had a nearly zero correlation, see Supplementary Information, SI, \nFigure\u00a0S5).\nML methods. Various ML methods were implemented and tested including logistic regression25, support \nvector machines (SVM)26, neural networks27, 28, extremely randomized trees (ERT)29 and random forests (RF)30, 31. \nOf these, RF and ERT gave the best \u2013 and similar \u2013 results (i.e., highest accuracy of classification). For clarity and \nconsistency, RF is described in detail in the discussion that follows (for the results obtained with other methods, \nsee SI).\nDescriptors and fingerprints. In most calculations, two distinct and commonly accepted types of features \nwere used to train the models: (1) Molecular descriptors, summarized in RDKit32 and capturing various charac\u0002teristics of individual molecules (from molecular weight, to the numbers of specific atoms, rings and structural \nmotifs, to various topological indices, etc.; see list at the end of the SI) along with experimental parameters such \nFigure 1. Illustrative reactions from the training set. A small sample of eleven reactions chosen at random \nfrom the set of 450,000 reactions analyzed by machine learning methods. The reactions are diverse and span \ndifferent types of chemistries. Shown here are: cycloaddition, synthesis of guanidines, alkylation of ketones, \nalpha-bromination of nitriles, substitution of primary alkyl chlorides with thiocyanate anion via SN2, synthesis \nof isatins, ester hydrolysis (in two reactions), fluorination of primary alcohols, reduction of nitro compounds, \nand esterification of carboxylic acids).\nwww.nature.com/scientificreports/\nScientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 3\nas solvents and temperature. Models up to almost 400 RDKit descriptors (~200 for substrates and ~200 for prod\u0002ucts) were c...",
      "url": "https://www.nature.com/articles/s41598-017-02303-0.pdf?error=cookies_not_supported&code=796c30e4-926f-4707-8dfd-649650f14832"
    },
    {
      "title": "Deep Kernel learning for reaction outcome prediction and optimization",
      "text": "Deep Kernel learning for reaction outcome prediction and optimization | Communications Chemistry\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Communications Chemistry](https://media.springernature.com/full/nature-cms/uploads/product/commschem/header-3dc28429486e0d2c8f49fd9baf5afa40.svg)](https://www.nature.com/commschem)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s42004-024-01219-x?error=cookies_not_supported&code=339c684d-2df4-42bb-a10b-c18beba44b3d)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;42004)\n* [RSS feed](https://www.nature.com/commschem.rss)\nDeep Kernel learning for reaction outcome prediction and optimization\n[Download PDF](https://www.nature.com/articles/s42004-024-01219-x.pdf)\n[Download PDF](https://www.nature.com/articles/s42004-024-01219-x.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:14 June 2024# Deep Kernel learning for reaction outcome prediction and optimization\n* [Sukriti Singh](#auth-Sukriti-Singh-Aff1)[ORCID:orcid.org/0000-0003-2286-2974](https://orcid.org/0000-0003-2286-2974)[1](#Aff1)&amp;\n* [Jos\u00e9 Miguel Hern\u00e1ndez-Lobato](#auth-Jos__Miguel-Hern_ndez_Lobato-Aff1)[ORCID:orcid.org/0000-0001-7610-949X](https://orcid.org/0000-0001-7610-949X)[1](#Aff1)\n[*Communications Chemistry*](https://www.nature.com/commschem)**volume7**, Article\u00a0number:136(2024)[Cite this article](#citeas)\n* 7809Accesses\n* 14Citations\n* 8Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s42004-024-01219-x/metrics)\n### Subjects\n* [Catalysis](https://www.nature.com/subjects/catalysis)\n* [Computational chemistry](https://www.nature.com/subjects/computational-chemistry)\n* [Method development](https://www.nature.com/subjects/method-development)\n* [Synthetic chemistry methodology](https://www.nature.com/subjects/methodology)\n* [Structure prediction](https://www.nature.com/subjects/structure-prediction)\n## Abstract\nRecent years have seen a rapid growth in the application of various machine learning methods for reaction outcome prediction. Deep learning models have gained popularity due to their ability to learn representations directly from the molecular structure. Gaussian processes (GPs), on the other hand, provide reliable uncertainty estimates but are unable to learn representations from the data. We combine the feature learning ability of neural networks (NNs) with uncertainty quantification of GPs in a deep kernel learning (DKL) framework to predict the reaction outcome. The DKL model is observed to obtain very good predictive performance across different input representations. It significantly outperforms standard GPs and provides comparable performance to graph neural networks, but with uncertainty estimation. Additionally, the uncertainty estimates on predictions provided by the DKL model facilitated its incorporation as a surrogate model for Bayesian optimization (BO). The proposed method, therefore, has a great potential towards accelerating reaction discovery by integrating accurate predictive models that provide reliable uncertainty estimates with BO.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-00144-6/MediaObjects/41598_2021_144_Fig1_HTML.png)\n### [Deep Bayesian Gaussian processes for uncertainty estimation in electronic health records](https://www.nature.com/articles/s41598-021-00144-6?fromPaywallRec=false)\nArticleOpen access19 October 2021\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-024-57135-6/MediaObjects/41598_2024_57135_Fig1_HTML.png)\n### [Relationship between prediction accuracy and uncertainty in compound potency prediction using deep neural networks and control models](https://www.nature.com/articles/s41598-024-57135-6?fromPaywallRec=false)\nArticleOpen access19 March 2024\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-88939-5/MediaObjects/41598_2021_88939_Fig1_HTML.png)\n### [GPCR\\_LigandClassify.py; a rigorous machine learning classifier for GPCR targeting compounds](https://www.nature.com/articles/s41598-021-88939-5?fromPaywallRec=false)\nArticleOpen access04 May 2021\n## Introduction\nChemical reaction optimization is central to organic synthesis and has largely been based on chemical intuition[1](https://www.nature.com/articles/s42004-024-01219-x#ref-CR1). During optimization, the aim is to maximize the reaction outcome (e.g., yield and/or enantiomeric excess) by identifying suitable experimental conditions[2](https://www.nature.com/articles/s42004-024-01219-x#ref-CR2). This involves evaluating a multidimensional chemical space comprising of reaction variables such as catalyst, solvent, substrate, additive, time, temperature, concentration, etc.[3](https://www.nature.com/articles/s42004-024-01219-x#ref-CR3),[4](https://www.nature.com/articles/s42004-024-01219-x#ref-CR4). Owing to the complexity of this problem, several data-driven approaches have been employed for efficient exploration of the chemical space[5](#ref-CR5),[6](#ref-CR6),[7](https://www.nature.com/articles/s42004-024-01219-x#ref-CR7).\nThe estimation of reaction outcome is of great importance in reaction development. It could enable chemists to identify, for instance, low-yield reactions prior to wet-lab experiments, thereby saving time and resources. Machine learning (ML) has shown an impressive degree of success in many areas of chemistry[8](#ref-CR8),[9](#ref-CR9),[10](#ref-CR10),[11](https://www.nature.com/articles/s42004-024-01219-x#ref-CR11). Earlier efforts toward reaction outcome prediction use hand-crafted features such as physical organic descriptors and molecular fingerprints[12](https://www.nature.com/articles/s42004-024-01219-x#ref-CR12),[13](https://www.nature.com/articles/s42004-024-01219-x#ref-CR13). Conventional ML methods, particularly random forests, perform extremely well with these non-learned representations. Recently, the advances in deep learning (DL) have led to the development of new molecular representations[14](https://www.nature.com/articles/s42004-024-01219-x#ref-CR14). These are learned directly from molecular structures like simplified molecular input line entry specifications (SMILES) and molecular graphs. The chemical language models (LMs) and graph neural networks (GNNs) trained using these string or graph-based representations have displayed great potential in reaction outcome prediction[15](#ref-CR15),[16](#ref-CR16),[17](#ref-CR17),[18](https://www.nature.com/articles/s42004-024-01219-x#ref-CR18).\nThe reaction outcome prediction augmented with uncertainty quantification is expected to find superior utility during reaction optimization[19](https://www.nature.com/articles/s42004-024-01219-x#ref-CR19). As an example, Bayesian optimization (BO) works with the uncertainty estimates to suggest new experiments in a search for optimal reaction conditions[20](https://www.nature.com/articles/s42004-024-01219-x#ref-CR20). While the quantification of uncertainty using the above-mentioned ML methods might not be straightforward, the uncertainty-awareness of Gaussian processes (GPs) is well-known[21](https://www.nature.com/articles/s42004-024-01219-x#ref-CR21),[22](https://www.nature.com/articles/s42004-024-01219-x#ref-CR22). G...",
      "url": "https://www.nature.com/articles/s42004-024-01219-x"
    },
    {
      "title": "Using Machine Learning To Predict Suitable Conditions\nfor Organic Reactions",
      "text": "Using Machine Learning To Predict Suitable Conditions for Organic Reactions - PMC[Skip to main content](#main-content)\n![](https://ncbi.nlm.nih.gov/static/img/us_flag.svg)\nAn official website of the United States government\nHere's how you know\nHere's how you know\n![](https://ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n**Official websites use .gov**\nA**.gov**website belongs to an official\ngovernment organization in the United States.\n![](https://ncbi.nlm.nih.gov/static/img/icon-https.svg)\n**Secure .gov websites use HTTPS**\nA**lock**(LockLocked padlock icon) or**https://**means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n[![NCBI home page](https://ncbi.nlm.nih.gov/static/img/ncbi-logos/nih-nlm-ncbi--white.svg)](https://www.ncbi.nlm.nih.gov/)\nSearch\nLog in\n* [Dashboard](https://www.ncbi.nlm.nih.gov/myncbi/)\n* [Publications](https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/)\n* [Account settings](https://www.ncbi.nlm.nih.gov/account/settings/)\n* Log out\nSearch\u2026Search NCBI\n[](https://ncbi.nlm.nih.gov/)\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n* [Journal List](https://ncbi.nlm.nih.gov/journals/)\n* [User Guide](https://ncbi.nlm.nih.gov/about/userguide/)\n* * [](https://doi.org/10.1021/acscentsci.8b00357)\n* [](pdf/oc8b00357.pdf)\n* * * ## PERMALINK\nCopy\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:[PMC Disclaimer](https://ncbi.nlm.nih.gov/about/disclaimer/)|[PMC Copyright Notice](https://ncbi.nlm.nih.gov/about/copyright/)\n![ACS Central Science logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-acscentsci.gif)\nACS Cent Sci\n. 2018 Nov 16;4(11):1465\u20131476. doi:[10.1021/acscentsci.8b00357](https://doi.org/10.1021/acscentsci.8b00357)\n# Using Machine Learning To Predict Suitable Conditions\nfor Organic Reactions\n[Hanyu Gao](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Gao H\"[Author]>)\n### Hanyu Gao\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[Hanyu Gao](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Gao H\"[Author]>)\n1,[Thomas J Struble](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Struble TJ\"[Author]>)\n### Thomas J Struble\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[Thomas J Struble](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Struble TJ\"[Author]>)\n1,[Connor W Coley](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Coley CW\"[Author]>)\n### Connor W Coley\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[Connor W Coley](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Coley CW\"[Author]>)\n1,[Yuran Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang Y\"[Author]>)\n### Yuran Wang\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[Yuran Wang](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Wang Y\"[Author]>)\n1,[William H Green](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Green WH\"[Author]>)\n### William H Green\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[William H Green](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Green WH\"[Author]>)\n1,[Klavs F Jensen](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Jensen KF\"[Author]>)\n### Klavs F Jensen\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\nFind articles by[Klavs F Jensen](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Jensen KF\"[Author]>)\n1,\\*\n* Author information\n* Article notes\n* Copyright and License information\n1Department of Chemical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, United States\n\\*\nE-mail:kfjensen@mit.edu.\nReceived 2018 Jun 5; Issue date 2018 Nov 28.\nCopyright \u00a92018 American Chemical Society\nThis is an open access article published under an ACS AuthorChoice[License](http://pubs.acs.org/page/policy/authorchoice_termsofuse.html), which permits copying and redistribution of the article or any adaptations for non-commercial purposes.\n[PMC Copyright notice](https://ncbi.nlm.nih.gov/about/copyright/)\nPMCID: PMC6276053\u00a0\u00a0PMID:[30555898](https://pubmed.ncbi.nlm.nih.gov/30555898/)\n## Abstract\n![graphic file with name oc-2018-00357g_0007.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4c63/6276053/1422e5a686aa/oc-2018-00357g_0007.jpg)\nReaction\ncondition recommendation is an essential element for the\nrealization of computer-assisted synthetic planning. Accurate suggestions\nof reaction conditions are required for experimental validation and\ncan have a significant effect on the success or failure of an attempted\ntransformation. However, de novo condition recommendation remains\na challenging and under-explored problem and relies heavily on chemists\u2019\nknowledge and experience. In this work, we develop a neural-network\nmodel to predict the chemical context (catalyst(s), solvent(s), reagent(s)),\nas well as the\u00a0temperature most suitable for any particular organic\nreaction. Trained on \u223c10 million examples from Reaxys, the\nmodel is able to propose conditions where a close match to the recorded\ncatalyst, solvent, and reagent is found within the top-10 predictions\n69.6% of the time, with top-10 accuracies for individual species reaching\n80\u201390%. Temperature is accurately predicted within \u00b120\n\u00b0C from the recorded temperature in 60\u201370% of test cases,\nwith higher accuracy for cases with correct chemical context predictions.\nThe utility of the model is illustrated through several examples spanning\na range of common reaction classes. We also demonstrate that the model\nimplicitly learns a continuous numerical embedding of solvent and\nreagent species that captures their functional similarity.\n## Short abstract\nMachine learning model predicts conditions for organic synthesis\nreactions and quantifies solvent and reagent similarity.\n## Introduction\nRetrosynthetic planning\nis the process of proposing pathways to\nsynthesize target molecules from available starting chemicals, and\nhas demonstrated its importance and success in the chemical industry.[1](#ref1),[2](#ref2)While retrosynthesis traditionally requires extensive training and\nexpertise of a chemist, recent years have seen renewed interest in\ncomputer-assisted synthetic planning (CASP).[3](#ref3)\u2212[7](#ref7)With the application of powerful machine learning\ntechniques to large data sets of organic reactions like Reaxys[8](#ref8)and the USPTO database,[9](#ref9)there have been major advances both in searching for possible retrosynthetic\npathways[10](#ref10)\u2212[16](#ref16)and in evaluating the feasibility of the proposed reactions.[5](#ref5),[17](#ref17)\u2212[22](#ref22)\nWhile existing tools have been demonstrated to predict the\nlikelihood\nof success of reactions with good accuracy,[20](#ref20)one obstacle to experimentally validating computer-proposed reactions\nis the specification of reaction conditions, including chemical context\n(catalyst, reagent, solvent) and other operating conditions (e.g.,\ntemperature, pressure). In some cases, small changes in reaction conditions\ncan lead to drastically different reaction outcomes. Therefore, recent\nwork on reaction outcome prediction has started to include reaction\nconditions to improve the accuracy and specificity of predictions.[20](#ref20),[21](#ref21)More importantly, reaction conditions are necessary to evaluate\nopportunities for one-pot synthesis, telescoping in flow, and amenab...",
      "url": "https://ncbi.nlm.nih.gov/pmc/articles/PMC6276053"
    }
  ]
}