For this competiton YOU MUST FOLLOW THE STRUCTURE OF the following notebook described below (public notebook) to generate your submissions.

Submissions will be evaluated according to a cross-validation procedure. This public notebook (https://www.kaggle.com/code/josepablofolch/catechol-benchmark-hackathon-template) shows the structure any submitted notebook must follow. In order to ensure fair participation among all competitors, the submission must have the same last three cells as in the notebook template, with the only allowed change being the line where the model is defined. For the avoidance of doubt, the line model = MLPModel() can be replaced with a new model definition in the third to last and second to last cells, but everything else must remain the same.

As a clarification, pre-training on any of the solvent mixture data to predict the full solvent data does count as data contamination.

Hyper-parameter optimisation of the models across the whole task is allowed, however the same hyper-parameters must be used across every fold, unless there is a clear explainable rationale behind changing them. For example, using a different model for alcohols vs esters is allowed, but arbitrarily changing the hyper-parameters based on the best fit per fold counts as data contamination. If you are wondering if your method is allowed, ask yourself the question: if I had to select the model hyper-parameters for a new solvent, would the method I used be able to without knowing the experiment results?

The use of different hyper-parameters for different tasks (e.g. for the full solvent predictions vs mixed solvent prediction) and for different objectives (e.g. for SM vs Product 1) is allowed, since they still count as hyper-parameters for the whole dataset and they could be used to predict a new unseen solvent.

## ⚠️ CRITICAL: DISTRIBUTION SHIFT PROBLEM

This competition has a STRUCTURAL distribution shift: you're predicting for UNSEEN SOLVENTS.
GroupKFold by solvent simulates this, but test solvents may be "harder" (more extreme properties).

**Observed pattern:** All model types (MLP, LGBM, XGB, GP) fall on the same CV-LB line:
- LB ≈ 4.2 * CV + 0.053 (intercept = 0.053)
- The intercept represents EXTRAPOLATION ERROR that no model tuning can fix

**Target:** Sub 0.07 LB requires CV ≈ 0.004 OR reducing the intercept

**STRATEGIES TO REDUCE THE INTERCEPT (not just improve CV):**

1. **Extrapolation Detection Features:**
   - Add features measuring solvent distance to training distribution
   - Use molecular fingerprint similarity (Tanimoto) to nearest training solvents
   - When extrapolating, blend predictions toward population mean

2. **Uncertainty-Weighted Predictions:**
   - Use GP with uncertainty estimates
   - High uncertainty → conservative prediction (closer to mean)
   - Ensemble variance as uncertainty proxy

3. **Physics-Informed Features:**
   - Arrhenius kinetics features (activation energy, temperature relationships)
   - Solvent polarity, dielectric constant, hydrogen bonding capacity
   - These constraints hold even for unseen solvents

4. **Solvent Clustering:**
   - Group solvents by chemical class (alcohols, ethers, esters, etc.)
   - Use class-specific models that generalize within chemical families
   - Detect when test solvent is in a known vs novel class

5. **Robust Prediction Strategies:**
   - For outlier solvents (Water, extreme polarity), use simpler models
   - Blend complex model with simple baseline based on extrapolation degree
   - Target weighting: SM target is hardest, consider 2-3x weight

6. **Study Top Public Kernels:**
   - Top scorers have solved this problem - study their approaches
   - Don't reinvent - adapt what works

**DO NOT keep optimizing standard ML if all approaches fall on the same CV-LB line!**
The intercept won't change. You must try fundamentally different strategies.