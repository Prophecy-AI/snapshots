{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b606ce29",
   "metadata": {},
   "source": [
    "# Competition-Compliant ACS PCA Ensemble - FIXED\n",
    "\n",
    "**CRITICAL**: This notebook follows the EXACT template structure required by the competition.\n",
    "- Last 3 cells are IDENTICAL to the template\n",
    "- Only the model definition line is changed\n",
    "\n",
    "**FIXES from exp_023:**\n",
    "1. HuberLoss instead of MSELoss\n",
    "2. ReduceLROnPlateau scheduler added\n",
    "3. Seed pattern fixed to 42 + i * 13\n",
    "\n",
    "**Expected CV**: 0.008601 (matching exp_022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee56b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:41.932493Z",
     "iopub.status.busy": "2026-01-14T02:17:41.932226Z",
     "iopub.status.idle": "2026-01-14T02:17:44.482788Z",
     "shell.execute_reply": "2026-01-14T02:17:44.482202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa65a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.485140Z",
     "iopub.status.busy": "2026-01-14T02:17:44.484593Z",
     "iopub.status.idle": "2026-01-14T02:17:44.491671Z",
     "shell.execute_reply": "2026-01-14T02:17:44.491157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions (matching template)\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1495802a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.493784Z",
     "iopub.status.busy": "2026-01-14T02:17:44.493383Z",
     "iopub.status.idle": "2026-01-14T02:17:44.545486Z",
     "shell.execute_reply": "2026-01-14T02:17:44.544960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n",
      "Total features: 5 (kinetic) + 13 (Spange) + 122 (DRFP) + 5 (ACS PCA) = 145\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups INCLUDING ACS PCA\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'Total features: 5 (kinetic) + {SPANGE_DF.shape[1]} (Spange) + {DRFP_FILTERED.shape[1]} (DRFP) + {ACS_PCA_DF.shape[1]} (ACS PCA) = {5 + SPANGE_DF.shape[1] + DRFP_FILTERED.shape[1] + ACS_PCA_DF.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7556bad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.547399Z",
     "iopub.status.busy": "2026-01-14T02:17:44.547230Z",
     "iopub.status.idle": "2026-01-14T02:17:44.555697Z",
     "shell.execute_reply": "2026-01-14T02:17:44.555198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Combined Featurizer with Arrhenius kinetics AND ACS PCA\n",
    "class ACSPCAFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'Feature dimension: {ACSPCAFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd93eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.557198Z",
     "iopub.status.busy": "2026-01-14T02:17:44.557025Z",
     "iopub.status.idle": "2026-01-14T02:17:44.564076Z",
     "shell.execute_reply": "2026-01-14T02:17:44.563578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModelInternal defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model [32,16] with BatchNorm\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('MLPModelInternal defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4106cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.565773Z",
     "iopub.status.busy": "2026-01-14T02:17:44.565585Z",
     "iopub.status.idle": "2026-01-14T02:17:44.576397Z",
     "shell.execute_reply": "2026-01-14T02:17:44.575909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPEnsemble defined (FIXED: HuberLoss + scheduler + seed pattern)\n"
     ]
    }
   ],
   "source": [
    "# MLP Ensemble (5 models with different seeds) - FIXED VERSION\n",
    "# Fixes: 1) HuberLoss, 2) ReduceLROnPlateau scheduler, 3) seed pattern 42 + i * 13\n",
    "class MLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=5, data='single'):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize_torch(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):  # FIX 3: use 'i' not 'seed'\n",
    "            torch.manual_seed(42 + i * 13)  # FIX 3: seed pattern 42 + i * 13\n",
    "            np.random.seed(42 + i * 13)\n",
    "            \n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims).to(device).double()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)  # FIX 2: Add scheduler\n",
    "            criterion = nn.HuberLoss()  # FIX 1: HuberLoss instead of MSELoss\n",
    "            \n",
    "            dataset = TensorDataset(X_all.to(device), y_all.to(device))\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_X, batch_y in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(batch_X)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                scheduler.step(epoch_loss / len(loader))  # FIX 2: Step scheduler\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize_torch(X_test, flip=False).to(device)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_test, flip=True).to(device)\n",
    "        \n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                pred = model(X_feat)\n",
    "                if self.data_type == 'full':\n",
    "                    pred_flip = model(X_flip)\n",
    "                    pred = (pred + pred_flip) / 2\n",
    "                all_preds.append(pred)\n",
    "        \n",
    "        return torch.stack(all_preds).mean(dim=0).cpu()\n",
    "\n",
    "print('MLPEnsemble defined (FIXED: HuberLoss + scheduler + seed pattern)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83df9605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.577986Z",
     "iopub.status.busy": "2026-01-14T02:17:44.577822Z",
     "iopub.status.idle": "2026-01-14T02:17:44.585395Z",
     "shell.execute_reply": "2026-01-14T02:17:44.584845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Wrapper\n",
    "class LGBMWrapper:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.models = []\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        for i in range(3):  # 3 targets\n",
    "            train_data = lgb.Dataset(X_all, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize(X_test, flip=False)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_test, flip=True)\n",
    "        \n",
    "        preds = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred = model.predict(X_feat)\n",
    "            if self.data_type == 'full':\n",
    "                pred_flip = model.predict(X_flip)\n",
    "                pred = (pred + pred_flip) / 2\n",
    "            preds.append(pred)\n",
    "        \n",
    "        return torch.tensor(np.column_stack(preds))\n",
    "\n",
    "print('LGBMWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524a9ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:44.586944Z",
     "iopub.status.busy": "2026-01-14T02:17:44.586779Z",
     "iopub.status.idle": "2026-01-14T02:17:44.592302Z",
     "shell.execute_reply": "2026-01-14T02:17:44.591840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSPCAEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# ACS PCA Ensemble: MLP (0.6) + LightGBM (0.4)\n",
    "class ACSPCAEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mlp = MLPEnsemble(hidden_dims=[32, 16], n_models=5, data=data)\n",
    "        self.lgbm = LGBMWrapper(data=data)\n",
    "        self.mlp_weight = 0.6\n",
    "        self.lgbm_weight = 0.4\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        self.lgbm.train_model(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        mlp_pred = self.mlp.predict(X_test)\n",
    "        lgbm_pred = self.lgbm.predict(X_test)\n",
    "        return self.mlp_weight * mlp_pred + self.lgbm_weight * lgbm_pred\n",
    "\n",
    "print('ACSPCAEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13d7351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:17:57.232230Z",
     "iopub.status.busy": "2026-01-14T02:17:57.231744Z",
     "iopub.status.idle": "2026-01-14T02:36:20.047125Z",
     "shell.execute_reply": "2026-01-14T02:36:20.046536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:47, 47.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:33, 46.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:17, 45.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [03:00, 44.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [03:47, 45.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [04:33, 45.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [05:18, 45.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [06:04, 45.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [06:50, 45.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [07:36, 45.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [08:22, 45.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [09:09, 46.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [09:54, 45.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [10:40, 45.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [11:26, 45.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [12:12, 45.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [13:00, 46.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [13:45, 46.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [14:31, 46.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [15:17, 46.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [16:03, 46.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [16:50, 46.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [17:36, 46.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [18:22, 46.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [18:22, 45.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ACSPCAEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ec21ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T02:36:32.973602Z",
     "iopub.status.busy": "2026-01-14T02:36:32.973203Z",
     "iopub.status.idle": "2026-01-14T03:11:54.036228Z",
     "shell.execute_reply": "2026-01-14T03:11:54.035690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:40, 160.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [05:18, 159.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [08:00, 160.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [10:38, 159.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [13:16, 159.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [15:55, 158.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [18:33, 158.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [21:13, 159.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [23:53, 159.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [26:44, 163.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [29:36, 165.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [32:28, 167.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [35:21, 169.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [35:21, 163.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ACSPCAEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce50e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:06.904884Z",
     "iopub.status.busy": "2026-01-14T03:12:06.904330Z",
     "iopub.status.idle": "2026-01-14T03:12:06.926841Z",
     "shell.execute_reply": "2026-01-14T03:12:06.926319Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d2f92e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:12:06.928585Z",
     "iopub.status.busy": "2026-01-14T03:12:06.928412Z",
     "iopub.status.idle": "2026-01-14T03:12:06.965953Z",
     "shell.execute_reply": "2026-01-14T03:12:06.965461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV SCORE VERIFICATION ===\n",
      "Single Solvent MSE: 0.008497 (n=656)\n",
      "Full Data MSE: 0.008791 (n=1227)\n",
      "Overall MSE: 0.008689\n",
      "\n",
      "Expected from exp_022: 0.008601\n",
      "exp_023 (unfixed): 0.008964\n",
      "Submission shape: (1883, 7)\n",
      "\n",
      "✓ IMPROVEMENT: 3.07% better than exp_023!\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV score (for verification only - not part of template)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nExpected from exp_022: 0.008601')\n",
    "print(f'exp_023 (unfixed): 0.008964')\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "\n",
    "if overall_mse < 0.008964:\n",
    "    improvement = (0.008964 - overall_mse) / 0.008964 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than exp_023!')\n",
    "else:\n",
    "    print(f'\\n✗ No improvement over exp_023')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
