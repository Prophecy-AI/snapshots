{
  "query": "What are the best techniques for improving out-of-distribution generalization in molecular property prediction when training on limited solvents?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Out\u2011of\u2011distribution (OOD) generalization is a major bottleneck for molecular property models trained on a handful of solvents, because the covariate shift between the limited training environment and the chemically diverse space of new solvents can cause unstable predictions.  Recent work shows that the most effective ways to mitigate this shift combine **data\u2011centric tricks that enrich the scarce labeled set** with **model\u2011centric strategies that enforce solvent\u2011invariant or environment\u2011invariant representations**.\n\n* **Meta\u2011learning and unlabeled interpolation** \u2013 Kim\u202fet\u202fal. propose a meta\u2011learning framework that \u201cdensifies\u201d scarce labeled data by leveraging large pools of unlabeled molecules to interpolate between in\u2011distribution (ID) and OOD samples, allowing the model to learn how to generalize beyond the observed solvents ([arxiv.org](https://arxiv.org/abs/2506.11877)).  A parallel OpenReview version confirms the same gains on real\u2011world covariate\u2011shift benchmarks ([openreview.net](https://openreview.net/pdf/70bee4e7da17329c1a51ab89274f7974d10cc74d.pdf)).  \n\n* **Solvent\u2011aware augmentation & contrastive multi\u2011task learning** \u2013 Lan\u202fet\u202fal. generate conformational ensembles under diverse solvent conditions and feed them to a contrastive pre\u2011training pipeline that jointly learns reconstruction, distance prediction, and a solvent\u2011invariant embedding space.  This augmentation yields a 3.7\u202f% boost in binding\u2011affinity prediction and markedly improves OOD docking performance ([arxiv.org](https://arxiv.org/html/2508.01799v2)).  \n\n* **Probabilistic calibration for ultra\u2011low data** \u2013 The DIONYSUS framework treats molecular property prediction as a Bayesian inference problem, calibrating uncertainty on tiny solvent\u2011specific datasets and thereby improving both reliability and OOD transferability ([rsc.org](https://pubs.rsc.org/en/content/articlehtml/2023/dd/d2dd00146b)).  \n\n* **Auxiliary learning & task\u2011specific adapters** \u2013 Fine\u2011tuning pretrained graph neural networks (GNNs) with auxiliary heads and adapter modules helps retain the broad chemical knowledge acquired during pre\u2011training while adapting to the limited solvent task, reducing over\u2011fitting to the narrow training distribution ([jcheminf.biomedcentral.com](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7)).  \n\n* **Invariant learning & mixup** \u2013 Relational Invariant Learning (RIL) mixes environments via conditional mixup and refines multi\u2011granular interaction representations, explicitly capturing patterns that remain stable across solvents and other experimental conditions ([openreview.net](https://openreview.net/pdf?id=etrY4TegYb)).  \n\n* **Benchmark\u2011driven design choices** \u2013 The BOOM benchmark highlights that models with strong inductive bias (e.g., physics\u2011informed GNNs), careful molecular representations, and thorough hyper\u2011parameter search consistently outperform generic foundation models on OOD tasks ([openreview.net](https://openreview.net/pdf/80574b0cbe412a64f9a63884b631eb51505762e6.pdf)).  \n\nIn practice, the best pipeline for limited\u2011solvent scenarios stacks these ideas: start from a large\u2011scale pretrained GNN (or a foundation model like MolE), apply solvent\u2011aware augmentation and contrastive pre\u2011training, fine\u2011tune with auxiliary adapters and Bayesian calibration (DIONYSUS), and finally employ meta\u2011learning or invariant\u2011mixup to bridge the gap to unseen solvents.  This combination has been shown to deliver the most robust OOD generalization on current benchmarks.",
      "url": ""
    },
    {
      "title": "Robust Molecular Property Prediction via Densifying Scarce Labeled Data",
      "text": "[View PDF](https://arxiv.org/pdf/2506.11877) [HTML (experimental)](https://arxiv.org/html/2506.11877v1)\n\n> Abstract:A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial covariate shift, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data, stemming from the onerous and costly nature of experimental validation, further exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel meta-learning-based approach that leverages unlabeled data to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.\n\n## Submission history\n\nFrom: Jina Kim \\[ [view email](https://arxiv.org/show-email/96b77896/2506.11877)\\]\n\n**\\[v1\\]**\nFri, 13 Jun 2025 15:27:40 UTC (10,933 KB)",
      "url": "https://arxiv.org/abs/2506.11877"
    },
    {
      "title": "Contrastive Multi-Task Learning with Solvent-Aware Augmentation for Drug Discovery",
      "text": "Contrastive Multi-Task Learning with Solvent-Aware Augmentation for Drug Discovery\n# Contrastive Multi-Task Learning with Solvent-Aware Augmentation for Drug Discovery\nJing Lan\\*1,\nHexiao Ding\\*1,\nHongzhao Chen1,\nYufeng Jiang1,\nNga-Chun Ng1,2\nGerald W.Y. Cheng1,\nZongxi Li3,\nJing Cai1,\nLiang-ting Lin1,\nJung Sun Yoo#1\\*Co-first author#Corresponding author1Department of Health Technology and Informatics, The Hong Kong Polytechnic University, Hong Kong SAR, China\n2Department of Nuclear Medicine and PET, Hong Kong Sanatorium and Hospital, Hong Kong SAR, China\n3School of Data Science, Lingnan University, Hong Kong SAR, China\nEmails: {jing-hti.lan, hexiao.ding, hongzhao.chen, yufeng.jiang}@connect.polyu.hk\n{wai-yeung.cheng, jing.cai, ltlin, jungsun.yoo}@polyu.edu.hk\n{sam.nc.ng}@hksh.com, {zongxili}@ln.edu.hk\n###### Abstract\nAccurate prediction of protein\u2013ligand interactions is essential for computer-aided drug discovery. However, existing methods often fail to capture solvent-dependent conformational changes and lack the ability to jointly learn multiple related tasks. To address these limitations, we introduce a pre-training method that incorporates ligand conformational ensembles generated under diverse solvent conditions as augmented input. This design enables the model to learn both structural flexibility and environmental context in a unified manner. The training process integrates molecular reconstruction to capture local geometry, interatomic distance prediction to model spatial relationships, and contrastive learning to build solvent-invariant molecular representations. Together, these components lead to significant improvements, including a 3.7% gain in binding affinity prediction, an 82% success rate on the PoseBusters Astex docking benchmarks, and an area under the curve of 97.1% in virtual screening. The framework supports solvent-aware, multi-task modeling and produces consistent results across benchmarks. A case study further demonstrates sub-angstrom docking accuracy with a root-mean-square deviation of 0.157 angstroms, offering atomic-level insight into binding mechanisms and advancing structure-based drug design.\nCode is available at[https://github.com/1anj/SolvCLIP](https://github.com/1anj/SolvCLIP).\n###### Index Terms:\nDrug discovery, Protein-ligand binding representation, Self-supervised learning, Multi-task, Contrastive learning\n## IIntroducion\nAccurate prediction of protein\u2013ligand interactions is a fundamental objective in computer-aided drug discovery, particularly in virtual screening.\nThe primary task is to determine whether a small molecule binds to a specific protein target, commonly referred to as the binary classification problem of \u201cbind or not\u201d> [\n[> 1\n](https://arxiv.org/html/2508.01799v2#bib.bib1)> ]\n.\nIn addition to this, two other tasks are essential for evaluating molecular efficacy.\nOne involves predicting the binding affinity, which is formulated as a regression problem> [\n[> 2\n](https://arxiv.org/html/2508.01799v2#bib.bib2)> ]\n. The other focuses on estimating the docking pose of both the protein and the ligand, treated as a reconstruction problem> [\n[> 3\n](https://arxiv.org/html/2508.01799v2#bib.bib3)> ]\n.\nTogether, these tasks form the computational foundation for an effective virtual screening. Traditional molecular docking methods, which often rely on rigid-body approximations and empirical scoring functions, have provided valuable insights> [\n[> 4\n](https://arxiv.org/html/2508.01799v2#bib.bib4)> , [> 5\n](https://arxiv.org/html/2508.01799v2#bib.bib5)> ]\n. However, these approaches are frequently limited in their ability to model the full complexity of biochemical interactions, especially when faced with flexible ligands, induced fit effects, and solvent-dependent conformational dynamics> [\n[> 6\n](https://arxiv.org/html/2508.01799v2#bib.bib6)> , [> 7\n](https://arxiv.org/html/2508.01799v2#bib.bib7)> ]\n.\nIn recent years, the integration of deep learning into molecular modeling has introduced transformative potential.\nThe molecular-docking landscape has undergone a transformative computational revolution, epitomized by advanced deep learning models such as Uni-Mol> [\n[> 8\n](https://arxiv.org/html/2508.01799v2#bib.bib8)> ]\n, EquiBind> [\n[> 9\n](https://arxiv.org/html/2508.01799v2#bib.bib9)> ]\n, E3Bind> [\n[> 10\n](https://arxiv.org/html/2508.01799v2#bib.bib10)> ]\n, TANKBind> [\n[> 11\n](https://arxiv.org/html/2508.01799v2#bib.bib11)> ]\n, and KarmaDock> [\n[> 12\n](https://arxiv.org/html/2508.01799v2#bib.bib12)> ]\n, which collectively challenge traditional interaction-prediction paradigms by introducing geometric learning and molecular representation strategies.\nUni-Mol introduces a unified molecular representation framework that overcomes domain-specific limitations by using graph neural networks to capture intrinsic geometric and chemical features> [\n[> 8\n](https://arxiv.org/html/2508.01799v2#bib.bib8)> ]\n.\nBuilding on this, EquiBind employs an equivariant neural architecture that rigorously enforces physical symmetries, resulting in more accurate binding-pose predictions that reflect the complex spatial nature of molecular interactions> [\n[> 9\n](https://arxiv.org/html/2508.01799v2#bib.bib9)> ]\n.\nFurther developments are exemplified by E3Bind and TANKBind, which push the boundaries of molecular modeling through integration with probabilistic reasoning and enhanced graph-based representations.\nE3Bind incorporates uncertainty quantification in its predictions, offering a transparent and interpretable approach to molecular interaction analysis> [\n[> 10\n](https://arxiv.org/html/2508.01799v2#bib.bib10)> ]\n.\nIn parallel, TANKBind excels in identifying intricate interaction patterns, particularly within challenging binding-site geometries> [\n[> 11\n](https://arxiv.org/html/2508.01799v2#bib.bib11)> ]\n.\nComplementing these frameworks, KarmaDock combines geometric learning with sophisticated scoring strategies to improve binding-affinity predictions across a range of protein families> [\n[> 12\n](https://arxiv.org/html/2508.01799v2#bib.bib12)> ]\n.\nTogether, these methods represent an evolution in deep learning-based molecular representation and binding analysis, facilitating more precise and insightful modeling of molecular behavior.\nAmong existing methodologies, contrastive learning has shown considerable promise in modeling relational patterns between chemical and biological entities.\nCo-supervised Pre-training of Pocket and Ligand (CoSP) advances the field by applying contrastive learning to jointly embed pockets and ligands> [\n[> 13\n](https://arxiv.org/html/2508.01799v2#bib.bib13)> ]\n.\nIn addition to this, DrugCLIP reformulates interaction prediction as a binary classification task by using matched and mismatched protein-ligand pairs to differentiate binders from non-binders> [\n[> 1\n](https://arxiv.org/html/2508.01799v2#bib.bib1)> ]\n.\nHowever, despite its strengths, DrugCLIP and similar contrastive models often fall short in capturing nuanced biophysical interactions> [\n[> 14\n](https://arxiv.org/html/2508.01799v2#bib.bib14)> ]\n.\nFurthermore, in pursuit of screening efficiency, DrugCLIP adopts a conservative model configuration that leads to a higher false negative rate> [\n[> 1\n](https://arxiv.org/html/2508.01799v2#bib.bib1)> ]\n.\nIts single-task design further limits practical utility, as chemists must invest additional time in downstream affinity quantification and chemical-structure characterization.\nThese constraints underscore the necessity for a more comprehensive, end-to-end solution that integrates multiple predictive tasks into a unified model.\nSuch a framework would combine binding-pose estimation, affinity prediction, and interaction classification, thereby enabling faster and more accurate virtual screening while minimizing the need for manual post-processing.\nMoreover, a critical limitation in most current predictive models lies in the inadequate consideration of solvent environments.\nSolvent effects play an important rol...",
      "url": "https://arxiv.org/html/2508.01799v2"
    },
    {
      "title": "Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS \u2020",
      "text": "Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS - Digital Discovery (RSC Publishing) DOI:10.1039/D2DD00146B\n[![Royal Society of Chemistry](/content/NewImages/royal-society-of-chemistry-logo.png)](/)\n[View\u00a0PDF\u00a0Version](/en/content/articlepdf/2023/dd/d2dd00146b)[Previous\u00a0Article](/en/content/articlehtml/2023/dd/d3dd00012e)[Next\u00a0Article](/en/content/articlehtml/2023/dd/d3dd00061c)\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](#)\n![](/content/newimages/open_access_blue.png)Open Access Article\n![](/content/newimages/CCBY-NC.svg)This Open Access Article is licensed under a[Creative Commons Attribution-Non Commercial 3.0 Unported Licence](http://creativecommons.org/licenses/by-nc/3.0/)\nDOI:[10.1039/D2DD00146B](https://doi.org/10.1039/D2DD00146B)(Paper)[Digital Discovery](https://doi.org/10.1039/2635-098X/2022), 2023,**2**, 759-774\n# Calibration and generalizability of probabilistic models on low-data chemical datasets with DIONYSUS[\u2020](#fn1)\nGary Tom[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-8470-6515)abc,Riley J. Hickman[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-5762-1006)abc,Aniket Zinzuwadiad,Afshan Mohajeri[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-3858-3024)e,Benjamin Sanchez-Lengeling[![ORCID logo](/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-1116-1745)fandAl\u00e1n Aspuru-Guzik\\*abcghi\naChemical Physics Theory Group, Department of Chemistry, University of Toronto, Toronto, ON, Canada. E-mail:[alan@aspuru.com](mailto:alan@aspuru.com)\nbDepartment of Computer Science, University of Toronto, Toronto, ON, Canada\ncVector Institute for Artificial Intelligence, Toronto, ON, Canada\ndHarvard Medical School, Harvard University, Boston, MA, USA\neDepartment of Chemistry, Shiraz University, Shiraz, Iran\nfGoogle Research, Brain Team, USA\ngDepartment of Chemical Engineering &amp; Applied Chemistry, University of Toronto, Toronto, ON, Canada\nhDepartment of Materials Science &amp; Engineering, University of Toronto, Toronto, ON, Canada\niLebovic Fellow, Canadian Institute for Advanced Research, Toronto, ON, Canada\nReceived 21st December 2022, Accepted 21st April 2023\nFirst published on 2nd May 2023\n## Abstract\nDeep learning models that leverage large datasets are often the state of the art for modelling molecular properties. When the datasets are smaller (&lt;2000 molecules), it is not clear that deep learning approaches are the right modelling tool. In this work we perform an extensive study of the calibration and generalizability of probabilistic machine learning models on small chemical datasets. Using different molecular representations and models, we analyse the quality of their predictions and uncertainties in a variety of tasks (regression or binary classification) and datasets. We also introduce two simulated experiments that evaluate their performance: (1) Bayesian optimization guided molecular design, (2) inference on out-of-distribution dataviaablated cluster splits. We offer practical insights into model and feature choice for modelling small chemical datasets, a common scenario in new chemical experiments. We have packaged our analysis into the DIONYSUS repository, which is open sourced to aid in reproducibility and extension to new datasets.\n## 1. Introduction\nThe design and discovery of molecular materials routinely enables technologies which have crucial societal consequences. Given a library of compounds, prediction of molecular functionality from its structure enables ranking and selection of promising candidates prior to experimental validation or other screening filters. Therefore, building accurate quantitative structure\u2013activity relationship models (QSAR) is key to accelerated chemical design and efficient experimental decision-making.[1](#cit1)Models that leverage statistical patterns in data are now often the state of the art on such tasks. Specifically, data science and machine learning (ML) have played critical roles in modern science in general,[2](#cit2)enabling the utilization of data at unprecedented scales. Deep learning (DL) models are able to extract statistical patterns in dataset features and give accurate QSAR predictions and classifications.[3](#cit3)When compared to traditionalab initiotechniques, such as density functional theory (DFT), ML models are less computationally demanding, and can learn statistical patterns directly from experimental data. However, the quality of such models is determined by the quality of the original datasets they are trained on, and thus the models are still affected by the cost of accurate data generation.\nTo date, many studies consider molecular property prediction tasks where training data is plentiful.[4,5](#cit4)In real-world molecular design campaigns, particularly in the initial stages, only small molecular datasets (&lt;2000 data points) are available due to the expense (monetary, resource, or labour) associated with the design, synthesis, and characterization of chemicals. In addition to the datasets examined in this work, examples of applications in the low-data regime include design of optoelectronic materials (i.e.organic photovoltaics,[6](#cit6)or photoswitching molecules[7](#cit7)), prediction of biochemical properties (i.e.olfactory response,[8,9](#cit8)or mosquito repellency[10](#cit10)), and drug discovery.[11,12](#cit11)Despite the practical importance of this regime, molecular property prediction using ML with limited data instances has been relatively under-explored, and remains a challenging task, especially for deep learning models which often require large amounts of training instances due to large number of model parameters.\nIn the low-data setting, understanding a ML model's performance is important since predictions inform decisions about further research directions, or, in a sequential learning setting, promote molecules to be subject to property measurement. In particular, we place emphasis on (1) the generalizability, the ability of a model to predict accurately on new chemical data, and (2) uncertainty calibration, the ability of a model to estimate the confidence of its predictions ([Fig. 1](#imgfig1)).\n[![image file: d2dd00146b-f1.tif](/image/article/2023/DD/d2dd00146b/d2dd00146b-f1.gif)](/image/article/2023/DD/d2dd00146b/d2dd00146b-f1_hi-res.gif)|\n|**Fig. 1**Schematic of the evaluation of probabilistic model on small molecular datasets with DIONYSUS. We study the performance and calibration of probabilistic models with different molecular representations when applied to small molecular datasets. The models are then evaluated on their performance in a simulated optimization campaign and their ability to generalize to out-of-distribution molecules.||\nAdequate generalizability, the ability for a model to make accurate predictions on out-of-distribution (OOD) data, is paramount for many learning tasks, such as in the hit-to-lead and early lead optimization phases of drug discovery.[12,13](#cit12)After identification of a biological target (usually a protein or nucleic acid), initial molecular hits are optimized in an expensive and time-consuming make-design-test cycle. Using ML to predict molecular properties has indeed been shown to reduce the number of syntheses and measurements required.[14\u201316](#cit14)Commonly, drug discovery project permit the synthesis and measurement of hundreds of candidate molecules due to constraints in expense, and typically involve functionalizations of a common molecular core or scaffold. Model generalization is therefore critical for the reuse of QSAR models for unstudied molecular scaffolds.[17,18](#cit17)\nUncertainty calibration is the ability of a probabilistic model to produce accurate estimates of its confidence, and is also a crucial aspect of the molecular design process and high-risk decision making.[19](#c...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/dd/d2dd00146b"
    },
    {
      "title": "Enhancing molecular property prediction with auxiliary learning and task-specific adaptation",
      "text": "Search all BMC articles\n\nSearch\n\nEnhancing molecular property prediction with auxiliary learning and task-specific adaptation\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-024-00880-7.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-024-00880-7.epub)\n\n[Download PDF](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-024-00880-7.pdf)\n\n[Download ePub](https://jcheminf.biomedcentral.com/counter/epub/10.1186/s13321-024-00880-7.epub)\n\n- Research\n- [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n- Published: 24 July 2024\n\n# Enhancing molecular property prediction with auxiliary learning and task-specific adaptation\n\n- [Vishal Dey](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#auth-Vishal-Dey-Aff1) [1](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#Aff1) &\n- [Xia Ning](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#auth-Xia-Ning-Aff1-Aff2-Aff3) [1](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#Aff1), [2](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#Aff2), [3](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#Aff3)\n\n[_Journal of Cheminformatics_](https://jcheminf.biomedcentral.com/) **volume\u00a016**, Article\u00a0number:\u00a085 (2024)\n[Cite this article](https://jcheminf.biomedcentral.com/jcheminf.biomedcentral.com#citeas)\n\n- 1535 Accesses\n\n- 2 Citations\n\n- 1 Altmetric\n\n- [Metrics details](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7/metrics)\n\n\n## Abstract\n\nPretrained Graph Neural Networks have been widely adopted for various molecular property prediction tasks. Despite their ability to encode structural and relational features of molecules, traditional fine-tuning of such pretrained GNNs on the target task can lead to poor generalization. To address this, we explore the adaptation of pretrained GNNs to the target task by jointly training them with multiple auxiliary tasks. This could enable the GNNs to learn both general and task-specific features, which may benefit the target task. However, a major challenge is to determine the relatedness of auxiliary tasks with the target task. To address this, we investigate multiple strategies to measure the relevance of auxiliary tasks and integrate such tasks by adaptively combining task gradients or by learning task weights via bi-level optimization. Additionally, we propose a novel gradient surgery-based approach, Rotation of Conflicting Gradients (\\\\(\\\\mathop {\\\\texttt{RCGrad}}\\\\limits\\\\)), that learns to align conflicting auxiliary task gradients through rotation. Our experiments with state-of-the-art pretrained GNNs demonstrate the efficacy of our proposed methods, with improvements of up to 7.7% over fine-tuning. This suggests that incorporating auxiliary tasks along with target task fine-tuning can be an effective way to improve the generalizability of pretrained GNNs for molecular property prediction.\n\n**Scientific contribution**\n\nWe introduce a novel framework for adapting pretrained GNNs to molecular tasks using auxiliary learning to address the critical issue of negative transfer. Leveraging novel gradient surgery techniques such as \\\\(\\\\mathop {\\\\texttt{RCGrad}}\\\\limits\\\\), the proposed adaptation framework represents a significant departure from the dominant pretraining fine-tuning approach for molecular GNNs. Our contributions are significant for drug discovery research, especially for tasks with limited data, filling a notable gap in the efficient adaptation of pretrained models for molecular GNNs.\n\n## Introduction\n\nAccurate prediction of molecular properties is pivotal in drug discovery \\[ [39](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR39)\\], as it accelerates the identification of potential molecules with desired properties. Developing computational models for property prediction relies on learning effective representations of molecules \\[ [5](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR5)\\]. In this regard, Graph Neural Networks (GNNs) have shown impressive results in learning effective representations for molecular property prediction tasks \\[ [11](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR11), [12](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR12), [37](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR37)\\]. Inspired by the paradigm of pretraining followed by fine-tuning, widely recognized for its impact in natural language understanding \\[ [27](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR27), [38](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR38)\\], molecular GNNs are often pretrained \\[ [17](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR17)\\] on a large corpus of molecules. Such a corpus might encompass irrelevant data for the target property prediction task. This can lead the GNNs to learn features that do not benefit the target task. Consequently, pretrained GNNs are fine-tuned with the target task to encode task-specific features. However, vanilla fine-tuning can potentially lead to poor generalization, particularly when dealing with diverse downstream tasks, limited data, and the need to generalize across varying scaffolds \\[ [40](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR40)\\].\n\nTo improve generalization, auxiliary learning has recently garnered attention \\[ [8](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR8), [20](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR20), [21](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR21)\\]. Auxiliary learning leverages informative signals from self-supervised tasks on unlabeled data, to improve the performance of the target tasks. However, its application in the context of molecular graphs, specifically for molecular property prediction, remains largely unexplored. Following this line of work, in this paper, we explore how to adapt pretrained molecular GNNs by combining widely-used self-supervised tasks with the target task using respective task-specific data (with self-supervised and target task labels). However, a critical challenge in such an adaptation is caused by negative transfer \\[ [29](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR29)\\], where auxiliary tasks might impede rather than aid the target task \\[ [9](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR9), [30](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR30)\\].\n\nTo address this challenge, we develop novel gradient surgery-based adaptation strategies, referred to as Rotation of Conflicting Gradients (\\\\(\\\\mathop {\\\\texttt{RCGrad}}\\\\limits\\\\)) and Bi-level Optimization with Gradient Rotation (\\\\(\\\\mathop {\\\\texttt{BLO}\\\\text {+}\\\\texttt{RCGrad}}\\\\limits\\\\)). Such strategies mitigate negative transfer from auxiliary tasks by learning to align conflicting gradients. Overall, our adaptation strategies improved the target task performance by as much as 7.7% over vanilla fine-tuning. Moreover, our findings indicate that the developed adaptation strategies are particularly effective in tasks with limited labeled data, which is a common challenge in molecular property prediction tasks. Our comprehensive investigation of multiple adaptation strategies for pretrained molecular GNNs represents a notable contribution in addressing the limited benefit of pretrained GNNs \\[ [34](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7#ref-CR34)\\], and in improving generalizability across a diverse set of downstream tasks with limited data.\n\n## Related work\n\n### Pretraining an...",
      "url": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-024-00880-7"
    },
    {
      "title": "Robust Molecular Property Prediction via  Densifying Scarce Labeled Data",
      "text": "Robust Molecular Property Prediction via\nDensifying Scarce Labeled Data\nJina Kim * 1 Jeffrey Willette * 1 Bruno Andreis * 1 Sung Ju Hwang 1 2\nAbstract\nA widely recognized limitation of molecular pre\u0002diction models is their reliance on structures ob\u0002served in the training data, resulting in poor gener\u0002alization to out-of-distribution compounds. Yet in\ndrug discovery, the compounds most critical for\nadvancing research often lie beyond the training\nset, making the bias toward the training data par\u0002ticularly problematic. This mismatch introduces\nsubstantial covariate shift, under which standard\ndeep learning models produce unstable and in\u0002accurate predictions. Furthermore, the scarcity\nof labeled data\u2014stemming from the onerous and\ncostly nature of experimental validation\u2014further\nexacerbates the difficulty of achieving reliable\ngeneralization. To address these limitations, we\npropose a novel meta-learning-based approach\nthat leverages unlabeled data to interpolate be\u0002tween in-distribution (ID) and out-of-distribution\n(OOD) data, enabling the model to meta-learn\nhow to generalize beyond the training distribution.\nWe demonstrate significant performance gains on\nchallenging real-world datasets with substantial\ncovariate shift, supported by t-SNE visualizations\nhighlighting our interpolation method.\n1. Introduction\nMolecular property prediction plays a central role in drug\ndiscovery pipelines, enabling researchers to prioritize com\u0002pounds for costly and time-consuming experimental valida\u0002tion. Accurate computational models have the potential to\ndramatically accelerate early-stage discovery by predicting\ncritical attributes such as bioactivity, toxicity, and solubility\n*Equal contribution 1Korea Advanced Institute of Sci\u0002ence and Technology (KAIST), South Korea 2Deepauto.ai,\nSouth Korea. Correspondence to: Jina Kim <ji\u0002nakim@kaist.ac.kr>, Jeffrey Willette <jwillette@kaist.ac.kr>,\nBruno Andreis <andries@kaist.ac.kr>, Sung Ju Hwang\n<sungju.hwang@kaist.ac.kr>.\nProceedings of the Workshop on Generative AI for Biology at the\n42 nd International Conference on Machine Learning, Vancouver,\nCanada. PMLR 267, 2025. Copyright 2025 by the author(s).\nIn-Distribution Out-Of-Distribution\nGeneralizing OOD\ntrain point\n, \nContext guided Interpolation\ncontext point\nRobust\nPrediction\nCovariate Shift\nOOD data point\nlogP: 1.2 | Tox: low logP: 4.2 | Tox: high\nlogP: 2.5 | Tox: medium\nFigure 1. Concept. We densify the train dataset using external\nunlabeled data (context point) for robust generalization across\ncovariate shift. Notation details are provided in Section 4.\nbefore synthesis (Schneider, 2018; Vamathevan et al., 2019).\nHowever, building reliable predictive models generalizing to\nnovel, unseen compounds remains a fundamental challenge.\nStandard molecular property prediction models tend to rely\nheavily on patterns observed within the training distribution,\nresulting in poor generalization to out-of-distribution com\u0002pounds (Klarner et al., 2023; Ovadia et al., 2019; Koh et al.,\n2021). In drug discovery, this limitation is particularly prob\u0002lematic, since the compounds most crucial for advancing re\u0002search often lie far beyond the chemical spaces represented\nduring training (Lee et al., 2023). The resulting covariate\nshift introduces significant obstacles to reliable prediction,\nwith models frequently producing unstable outputs when\nextrapolating to new regions of chemical space. Further\ncompounding these challenges, experimental validation of\nmolecular properties is both costly and resource-intensive,\nleading to a scarcity of labeled data and increasing reliance\non computational exploration (Altae-Tran et al., 2017). Also,\navailable labeled data is typically concentrated in narrow\nregions of chemical space, introducing bias that hampers\ngeneralization to unseen compounds (Klarner et al., 2023).\nWhile vast collections of unlabeled molecular structures\nare readily available (Sterling & Irwin, 2015; Kim et al.,\n2021), offering rich information about the structure of\nchemical space, existing methods often fail to fully ex\u0002ploit this resource to improve generalization (Klarner et al.,\n1\nRobust Molecular Property Prediction via Densifying Scarce Labeled Data\n2023). Therefore, we propose a novel meta-learning based\nmethod that leverages unlabeled data to densify the scarce\ntrain dataset and guide the model toward sensible behav\u0002ior in unexplored regions of chemical space. Our code\ncan be found at https://github.com/JinA0218/\ndrugood-densify.\n2. Methodology\nPreliminaries. We consider the problem of molecular\nproperty prediction under covariate shift. Given a small\nlabeled dataset Dtrain = {(xi, yi)}\nn\ni=1 and abundant unla\u0002beled molecules Dunlabeled = {xj}\nm\nj=1, the goal is to learn a\npredictive model f : X \u2192 Y that reliably generalizes to a\ndistributionally shifted test set Dtest.\nScarce Data Densification with Unlabeled Data To ad\u0002dress this, we propose a meta-learning based framework that\ninterpolates the training distribution Dtrain with an exoge\u0002nous distribution Dunlabeled. Our objective is to leverage the\ncheaper and more abundant distribution Dunlabeled to densify\nthe scarce labeled distribution Dtrain in a way that encour\u0002ages the model to generalize robustly under covariate shift,\nparticularly in out-of-distribution scenarios where we have\nno label information and therefore high uncertainty. For this,\nwe utilize subsets of Dunlabeled as Dcontext and Dmvalid, where\nDcontext is a domain-informed external task distribution for\ninterpolating to Dtrain, and Dmvalid is a meta-validation set\nused to guide the interpolation function. Inspired by (Lee\net al., 2024), we introduce a permutation invariant learnable\nset function (Zaheer et al., 2017; Lee et al., 2019) \u00b5\u03bb as a\nmixer (interpolator), which learns to mix each point from\nxi \u223c Dtrain with the context points {cij}\nmi\nj=1 in a way that\ndensifies Dtrain, where\n(xi, yi) \u223c Dtrain, {cij}\nmi\nj=1 \u223c Dcontext, i \u2208 {1, . . . , B}\nand B denotes the minibatch size, mi \u223c Uint(0, M) where\nM controls the maximum number of context samples drawn\nfrom Dcontext for each minibatch. Given a feature dimen\u0002sion D, for each i, the input consists of, xi \u2208 R\nB\u00d71\u00d7D\nand {cij}\nmi\nj=1 \u2208 R\nB\u00d71\u00d7D, where the set {cij}\nmi\nj=1 can be\norganized into a tensor Ci \u2208 R\nB\u00d7mi\u00d7D.\nOverall, our model has two main components: (1) a meta\u0002learner f\u03b8l\n, which is a standard MLP at the l\nth layer, that\nmaps input data x\n(l\u22121)\ni \u2208 R\nB\u00d71\u00d7D to the feature space of\nthe (l + 1)th layer, producing x\n(l)\ni = f\u03b8l\n(x\n(l\u22121)\ni\n), and (2) a\nlearnable set function \u00b5\u03bb which mixes x\n(lmix)\ni\nand C\n(lmix)\ni\nas\na set and outputs a single pooled representation x\u02dc\n(lmix)\ni =\n\u00b5\u03bb({x\n(lmix)\ni\n, C(lmix)\ni\n}) \u2208 R\nB\u00d71\u00d7H, where H is the hidden\ndimension and lmix is the layer where the mixing happens.\nThe full model structure with L layers can be expressed as\n\u02c6f\u03b8,\u03bb := f\u03b8L\n\u25e6 \u00b7 \u00b7 \u00b7 \u25e6 f\u03b8lmix+1 \u25e6 \u00b5\u03bb \u25e6 f\u03b8lmix\u22121\n\u25e6 \u00b7 \u00b7 \u00b7 \u25e6 f\u03b81.\nWe utilize bilevel optimization for training meta-learner f\u03b8l,\nand treat the set function parameter \u00b5\u03bb as a hyperparameter\nto be optimized in the outer loop (Lorraine et al., 2019). As\nshown in Table 2 (w/o bilevel optimization), simply opti\u0002mizing the meta-learner parameters \u03b8 and the set function\nparameters \u03bb jointly can lead to overfitting to the task dis\u0002tribution and harms test-time generalization. Following the\nsetting of (Lorraine et al., 2019), during training, we only\nupdate the parameter \u03b8 in the inner loop and we only update\nthe parameter \u03bb in the outer loop (see Figure 9b for the\ndetailed model structure of the bilevel optimization).\nIn the inner loop, the model accepts xi \u2208 R\nB\u00d71\u00d7H\nand Ci \u2208 R\nB\u00d7mi\u00d7H and the set encoder \u00b5\u03bb mixes\n{x\n(lmix)\ni\n, C(lmix)\ni\n} and outputs x\u02dc\n(lmix)\ni \u2208 R\nB\u00d71\u00d7H. Since Ci\nis used to introduce a domain-informed external context to\ndensify Dtrain, we utilize the original label yi from Dtrain to\ntrain the task learner parameters f\u03b8l, with the mixed x\u02dc\n(lmix)\ni\n.\nIn the outer loop, we train the set encoder using hypergra\u0002dient (Lorraine et al., 2019), w...",
      "url": "https://openreview.net/pdf/70bee4e7da17329c1a51ab89274f7974d10cc74d.pdf"
    },
    {
      "title": "",
      "text": "BOOM: Benchmarking Out-Of-distribution Molecular\nProperty Predictions of Machine Learning Models\nEvan R. Antoniuk\u2020\u2217 Shehtab Zaman\u2021\u2217 Tal Ben-Nun\u2020 Peggy Li\u2020\nJames Diffenderfer\u2020 Busra Demirci\u2021 Obadiah Smolenski\u2021 Tim Hsu\u2020\nAnna M. Hiszpanski\u2020 Kenneth Chiu\u2021 Bhavya Kailkhura\u2020\nBrian Van Essen\u2020\n\u2020 Lawrence Livermore National Laboratory, Livermore, CA\n\u2021 Binghamton University, Binghamton, NY\nAbstract\nData-driven molecular discovery leverages artificial intelligence/machine learning (AI/ML)\nand generative modeling to filter and design novel molecules. Discovering novel molecules\nrequires accurate out-of-distribution (OOD) predictions, but ML models struggle to general\u0002ize OOD. Currently, no systematic benchmarks exist for molecular OOD prediction tasks.\nWe present BOOM, benchmarks for out-of-distribution molecular property predictions: a\nchemically-informed benchmark for OOD performance on common molecular property\nprediction tasks. We evaluate over 150 model-task combinations to benchmark deep learning\nmodels on OOD performance. Overall, we find that no existing model achieves strong gener\u0002alization across all tasks: even the top-performing model exhibited an average OOD error 3\u00d7\nhigher than in-distribution. Current chemical foundation models do not show strong OOD ex\u0002trapolation, while models with high inductive bias can perform well on OOD tasks with sim\u0002ple, specific properties. We perform extensive ablation experiments, highlighting how data\ngeneration, pre-training, hyperparameter optimization, model architecture, and molecular\nrepresentation impact OOD performance. Developing models with strong out-of-distribution\n(OOD) generalization is a new frontier challenge in chemical machine learning (ML). This\nopen-source benchmark is available at https://github.com/FLASK-LLNL/BOOM.\n1 Introduction\nMolecular discovery pipelines have increasingly relied upon machine learning (ML) models [Bohacek\net al., 1996, Reymond, 2015, Kailkhura et al., 2019]. These models discover new molecules by\neither screening a list of enumerated molecules or by guiding a generative model towards molecules\nof interest [Wang et al., 2023a]. Molecular discovery is inherently an out-of-distribution (OOD)\nprediction problem, since the molecules need to either (i) exhibit properties that extrapolate beyond\nthe training dataset, or (ii) possess a previously unconsidered chemical substructure. In either case,\nsuccess depends on the learned model\u2019s ability to make accurate predictions on samples that are not\nin the same distribution as the training data.\nDespite the importance of OOD performance to real-world molecular discovery, the OOD per\u0002formance of common ML models for molecular property prediction has yet to be systematically\nexplored. Due to the lack of standardized splits for testing models, especially splits based on the\ndata distribution, we believe that current ML models are optimizing in-distribution performance on\n\u2217Equal Contribution\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\ninsufficiently challenging datasets that do not adequately measure real-world performance. Currently,\nlittle empirical knowledge exists about how choices regarding the pretraining task, model architecture,\nand/or dataset diversity impact the generalization performance of chemistry foundation models that\nare expected to generalize across all chemical systems.\nIn this work, we develop BOOM, benchmarks for out-of-distribution molecular property predictions,\na standardized benchmark for assessing the OOD generalization performance of molecule property\nprediction models. Our work consists of the following main contributions:\n\u2022 We develop a general and robust methodology for evaluating the performance of chemical\nproperty prediction models for property values beyond their training distribution. We intro\u0002duce OOD-specific metrics such as binned R2\nto allow comparisons of OOD performance\nacross all models.\n\u2022 We perform the first large-scale OOD performance benchmarking of state-of-the-art ML\nchemical property prediction models. Across 10 diverse OOD tasks and 15 models, we\ndo not find any existing models that show strong OOD generalization across all tasks. We\ntherefore put forth BOOM OOD property prediction as a frontier challenge for chemical\nfoundation models.\n\u2022 Our work highlights insights into how pretraining strategies, model architecture, molecular\nrepresentation, and data augmentation impact OOD performance. These findings point\ntowards strategies for the chemistry community to achieve chemical foundation models with\nstrong OOD generalization across all chemical systems.\n2 BOOM\nDefining Out-of-distribution. Consider a supervised dataset D with N molecules M \u2208\n{M1,M2, ...,MN } and associated labels or properties y \u2208 {y1, y2, ..., yN }. The problem of\nout-of-distribution prediction can be defined as the mismatch in the probability distribution, P of the\ntraining and test sets, Dtrain and Dtest such that,\nP(M, y|Dtest) \u0338= P(M, y|Dtrain) (1)\nThe key question is defining the density function P(M, y) over a set of molecules and their respective\nproperties. The density can be defined over the chemical structure or molecule features, or over the\nproperties. Formally, we define out-of-distribution as low-density regions over the property space,\nsuch that:\n0 < P(ytest) \u2264 P(ytrain) (2)\nFarquhar and Gal [2022] define this as a complement distribution conditioned on the targets. This is\nknown as concept or label shift as well [Liu et al., 2024]. While we focus on designing splits with a\nconcept shift, it is important to note that depending on the property, this may result in a covariate shit,\nresulting in a structural or chemical imbalance. The probability density over the labels is determined\nusing kernel density estimation (KDE), allowing us to generalize to multimodal distributions. The\nsplit strategy algorithm for each dataset is detailed in Appendix A.1. The lowest probability samples\nfrom the KDE estimated distribution are held-out (see Fig. 1) to evaluate the consistency of ML\nmodels to discover molecules with state-of-the-art properties that extrapolate beyond the training\ndata.\nDatasets. BOOM consists of 10 quantum chemical molecular property datasets derived from\nQM9 [Ramakrishnan et al., 2014] and the 10k Dataset [Antoniuk et al., 2025], derived from the Cam\u0002bridge Structural Database. The 10k Dataset was sourced from 10,206 experimentally synthesized,\nsmall organic molecules and contains the density functional theory calculated values of their molecu\u0002lar density and solid heat of formation (HoF). We collect 8 molecular property datasets from the QM9\nDataset: isotropic polarizability (\u03b1), heat capacity (Cv), highest occupied molecular orbital (HOMO)\nenergy, lowest unoccupied molecular orbital (LUMO) energy, HOMO-LUMO gap, dipole moment\n(\u00b5), electronic spatial extent (\nR2\n\u000b\n), and zero point vibrational energy (ZPVE). We also select a\nrandom subset of the dataset to serve as the ID test set, detailed in Appendix A. To further expand the\napplication space of BOOM, we also perform benchmarking on the Lipophilicity dataset[Wu et al.,\n2018] of 4,200 experimental measurements of the octanol/water distribution coefficient, which is of\nrelevance for drug compounds. The inclusion of the Lipophilicity dataset serves as an exemplary\n2\nFigure 1: (Left) An example OOD dataset included in the BOOM benchmark. To assess OOD\nperformance, we split each chemical property dataset into an out-of-distribution (OOD) Test Set\n(blue), an in-distribution (ID) Test Set (orange) and a Train Set (green), as described in Section 2.\n(Right) Example model predictions on this task exhibiting weak correlation on the OOD samples.\ndataset for performing OOD evaluations on experimentally measured properties, rather than only\ncomputed physicochemical properties (See Table 9).\nMetrics. We also propose standardized metrics over the ID and OOD to compare models. We\nuse root mean square error (RMSE) over respective data spli...",
      "url": "https://openreview.net/pdf/80574b0cbe412a64f9a63884b631eb51505762e6.pdf"
    },
    {
      "title": "",
      "text": "000\n001\n002\n003\n004\n005\n006\n007\n008\n009\n010\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n050\n051\n052\n053\nUnder review as a conference paper at ICLR 2025\nLEARNING RELATIONAL INVARIANCE FOR OUT-OF\u0002DISTRIBUTION MOLECULAR RELATIONAL LEARNING\nAnonymous authors\nPaper under double-blind review\nABSTRACT\nMolecular Relational Learning (MRL) expands the scope of molecular represen\u0002tation learning by incorporating additional molecules, aiming to understand the\ninteractions between pairs of molecules. While MRL has shown promising results,\nthe existing methods have not been able to generalise to real world scenarios. In\u0002variant learning is pivotal in addressing Out-of-Distribution (OOD) generalization\nchallenges. However, two major obstacles impede the progress of invariant learn\u0002ing in MRL: (1) Unlike single-molecular cases, interactions between molecules\nintroduce added complexity, with a heavy reliance on molecular substructure recog\u0002nition, often leading to the misspecification of invariant patterns. (2) Accurate\nmodeling of interactions can effectively improve generalizations. However, previ\u0002ous methods focus on node interactions, which is limited by the expressiveness of\nGNN, and long-range interactions cannot be captured. To address these, we propose\na novel Relational Invariant Learning (RIL) framework that uses a multi-granularity\ninteraction approach to improve OOD generalization for MRL, and the framework\nis denoted as RILOOD. Specifically, we model the environment diversity distri\u0002bution of molecules by mixup-based Conditional Modeling. Then, we employ a\nmulti-granularity refinement strategy to learn the Context-Aware Representation,\nwhich is essential for capturing multi-level interaction. We further design an in\u0002variant learning module to capture the invariant patterns that robustly generalize\nacross unseen environments. Extensive experiments on molecular datasets show\nthat our method achieves stronger generalization against state-of-the-art methods\nin the presence of various distribution shifts. Our code will be released after our\npaper is accepted.\n1 INTRODUCTION\nPredicting molecular properties in solvent is crucial, given that most chemical and biological processes\noccur in solution. Solvent-based molecular property prediction, also referred to as Solute-Solvent\nInteraction in Molecule Relational Learning (MRL)(Lim & Jung, 2019; Subramanian et al., 2020;\nPanwar et al., 2021; Low et al., 2022; Zhang et al., 2022; Lee et al., 2023a;b), has played a pivotal\nrole in chemical and biological research, including battery manufacture, pharmaceutical industry\n(Chung et al., 2022; Varghese & Mushrif, 2019). It is an evolving field that aims to understand\ninteractions between solutes and solvents at the molecular-level, allowing for predicting molecular\nproperty through a prior. More importantly, it significantly extends the conventional molecular\nproperty prediction practices by taking solvent molecular as additional inputs, thereby achieving\npromising performance and chemical interpretability.\nDespite their notable success, existing methods are based on the assumption that training and test\ndata are sampled from an independent and identical distribution (I.I.D.). However, the real world\nis open, diverse, and uncertain. Out-of-Distribution (OOD) refers to scenarios where the test data\nor new data encountered by a model significantly differ from the training data. For single molecule,\nOOD can occur not only in the molecule structure itself\u2014such as differences in size or scaffold\u2014but\nalso in the target properties. OOD generalization(Krueger et al., 2021), which seeks to address this\nchallenge by learning invariant representations across multiple environments (e.g., scaffolds, sizes),\nhas garnered significant attention. Typically, the privileged substructure remains invariant concerning\na molecular\u2019s properties. However, one important nature of solvated molecules is the non-stationary\nproperty, indicating that its statistical features are changing over solvent. As shown in Fig.1, previous\n1\n054\n055\n056\n057\n058\n059\n060\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099\n100\n101\n102\n103\n104\n105\n106\n107\nUnder review as a conference paper at ICLR 2025\n17\n100 O O\nScaffold\n0\nPrivilege \nsubstructure\nSpurious correlation\n\u2026 Size\nOur method Previous methods\nC\nH\nC O\nH\nC O\nH\nC\nH\nC O\nH\nC O\nH\nThe color bar of the interactions\nO\nH H\nC O\nH\nC O\nH\nC O\nH\nC O\nH\nC O\nH\nSolvent \nInvariance Environment-Aware\nSpurious feature Invariant feature\nMolecular\nMolecular\u0002Pairs (Ours)\nC O\nH\nC O\nH\n\u2611\n\u2611\nMolecular\u0002Pairs\n(Previous)\n\u274c\nScaffold,\nSize\nProperty\nProperty\nSubstructure \nFunctional \ngroup\nSolute feature \nSubstructure \u274c\nH2O\nSolvent Gap\nFigure 1: A toy example shows the \u2019solute-solvent interactions\u2019 with distribution shifts when the\nunderlying environments change (e.g., solvent). A model could mistakenly predict that strong polar\nmolecules are easily soluble in polar solvents and not true for low polar molecules if it fails to capture\ninteraction invariant patterns among spurious correlations.\nmethods would spuriously correlate non-causal factors (\u2018substructure\u2019) and produce undesired results\nunder a new environment. Scaffolds and size, etc., are often considered to be irrelevant patterns to\nmolecular properties, which can be seen as spurious correlations.\nExisting works mainly attempt to build effective methods for distribution shifts, from invariant\nlearning(Wu et al., 2022a), feature disentanglement(Liu et al., 2021), to data augmentation(Sui et al.,\n2024; Jia et al., 2024). Thus far, few previous works focus on OOD generalization on MRL. A typical\nwork(Lee et al., 2023b) is devised to solve the distribution shift problem relies on the identification of\nmolecule substructure by causal inference. Nevertheless, the complicated molecular pairs interaction,\nwhich are largely underexplored in graph invariant representations, makes it challenging to accurately\ndistinguish the invariant causal parts from diverse spurious correlations. On the other hand, mis\u0002specification refers to variant or spurious correlations that cannot be invariant of the any available\nenvironments(e.g., a toy example in Fig. 1). It is hoped that a new approach will be developed to\nfacilitate the generalization of molecular properties toward open-scenario.\nTo address these limitations, in this work, we propose a novel Relational Invariant Learning framework\nagainst Out-of-Distribution Generalization in MRL. In contrast to the traditional methods, we present a\nnovelty framework to capture the invariance in molecular pairs and achieve generalized representation.\nSpecifically, we first employ GNN to encode molecular, following by the cross-attention module to\nmap atom-level interaction. Then, we utilize mixup-enhanced Conditional Variational Modeling. We\nembrace the strengths of cross-environment invariance by considering a multi-granularity context\u0002aware interaction and environment diversity inference. Learn interaction invariance(Xie et al., 2024),\nwhich helps to uncover the underlying relationships between molecules in a chemically interpretable\nway in latent space.\nOur main contributions can be summarized as follows: (1) We propose a novel Relational Invariant\nLearning framework, call RILOOD, to solve the OOD generalization on molecular relational learning.\n(2) Our method not only preserves the fine-grained interactions between molecules at the molecular\u0002level, but also captures the global interaction information through multi-granularity context-aware\nrefinement. (3) We formulate the OOD generalization problem on MRL. Focusing on both invariant\ninteraction learning and conditional modeling, capturing associations between different distributions\nthrough domain shift. It exhibit robustness and transferability ...",
      "url": "https://openreview.net/pdf?id=etrY4TegYb"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2505.01912] BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2505.01912\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2505.01912**(cs)\n[Submitted on 3 May 2025 ([v1](https://arxiv.org/abs/2505.01912v1)), last revised 19 Dec 2025 (this version, v2)]\n# Title:BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models\nAuthors:[Evan R. Antoniuk](https://arxiv.org/search/cs?searchtype=author&amp;query=Antoniuk,+E+R),[Shehtab Zaman](https://arxiv.org/search/cs?searchtype=author&amp;query=Zaman,+S),[Tal Ben-Nun](https://arxiv.org/search/cs?searchtype=author&amp;query=Ben-Nun,+T),[Peggy Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+P),[James Diffenderfer](https://arxiv.org/search/cs?searchtype=author&amp;query=Diffenderfer,+J),[Busra Sahin](https://arxiv.org/search/cs?searchtype=author&amp;query=Sahin,+B),[Obadiah Smolenski](https://arxiv.org/search/cs?searchtype=author&amp;query=Smolenski,+O),[Tim Hsu](https://arxiv.org/search/cs?searchtype=author&amp;query=Hsu,+T),[Anna M. Hiszpanski](https://arxiv.org/search/cs?searchtype=author&amp;query=Hiszpanski,+A+M),[Kenneth Chiu](https://arxiv.org/search/cs?searchtype=author&amp;query=Chiu,+K),[Bhavya Kailkhura](https://arxiv.org/search/cs?searchtype=author&amp;query=Kailkhura,+B),[Brian Van Essen](https://arxiv.org/search/cs?searchtype=author&amp;query=Van+Essen,+B)\nView a PDF of the paper titled BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models, by Evan R. Antoniuk and 11 other authors\n[View PDF](https://arxiv.org/pdf/2505.01912)[HTML (experimental)](https://arxiv.org/html/2505.01912v2)> > Abstract:\n> Data-driven molecular discovery leverages artificial intelligence/machine learning (AI/ML) and generative modeling to filter and design novel molecules. Discovering novel molecules requires accurate out-of-distribution (OOD) predictions, but ML models struggle to generalize OOD. Currently, no systematic benchmarks exist for molecular OOD prediction tasks. We present $\\mathbf{BOOM}$, $\\mathbf{b}$enchmarks for $\\mathbf{o}$ut-$\\mathbf{o}$f-distribution $\\mathbf{m}$olecular property predictions: a chemically-informed benchmark for OOD performance on common molecular property prediction tasks. We evaluate over 150 model-task combinations to benchmark deep learning models on OOD performance. Overall, we find that no existing model achieves strong generalization across all tasks: even the top-performing model exhibited an average OOD error 3x higher than in-distribution. Current chemical foundation models do not show strong OOD extrapolation, while models with high inductive bias can perform well on OOD tasks with simple, specific properties. We perform extensive ablation experiments, highlighting how data generation, pre-training, hyperparameter optimization, model architecture, and molecular representation impact OOD performance. Developing models with strong OOD generalization is a new frontier challenge in chemical ML. This open-source benchmark is available at [> this https URL\n](https://github.com/FLASK-LLNL/BOOM)> Subjects:|Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI)|\nCite as:|[arXiv:2505.01912](https://arxiv.org/abs/2505.01912)[cs.LG]|\n|(or[arXiv:2505.01912v2](https://arxiv.org/abs/2505.01912v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2505.01912](https://doi.org/10.48550/arXiv.2505.01912)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Evan Antoniuk [[view email](https://arxiv.org/show-email/6abb5e36/2505.01912)]\n**[[v1]](https://arxiv.org/abs/2505.01912v1)**Sat, 3 May 2025 19:51:23 UTC (35,134 KB)\n**[v2]**Fri, 19 Dec 2025 23:00:10 UTC (16,070 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models, by Evan R. Antoniuk and 11 other authors\n* [View PDF](https://arxiv.org/pdf/2505.01912)\n* [HTML (experimental)](https://arxiv.org/html/2505.01912v2)\n* [TeX Source](https://arxiv.org/src/2505.01912)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2505.01912&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2505.01912&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-05](https://arxiv.org/list/cs.LG/2025-05)\nChange to browse by:\n[cond-mat](https://arxiv.org/abs/2505.01912?context=cond-mat)\n[cond-mat.mtrl-sci](https://arxiv.org/abs/2505.01912?context=cond-mat.mtrl-sci)\n[cs](https://arxiv.org/abs/2505.01912?context=cs)\n[cs.AI](https://arxiv.org/abs/2505.01912?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2505.01912)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2505.01912)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2505.01912)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2505.01912&amp;description=BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2505.01912&amp;title=BOOM: Benchmarking Out-Of-distribution Molecular Property Predictions of Machine Learning Models>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*...",
      "url": "https://arxiv.org/abs/2505.01912"
    }
  ]
}