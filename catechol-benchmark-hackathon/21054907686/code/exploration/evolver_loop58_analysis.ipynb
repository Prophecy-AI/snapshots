{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0883a612",
   "metadata": {},
   "source": [
    "# Loop 58 Analysis: Post-Simpler Model Assessment\n",
    "\n",
    "**Situation:**\n",
    "- 58 experiments completed, 27 consecutive failures since exp_030\n",
    "- Best LB: 0.0877 (exp_030), Target: 0.0707\n",
    "- Gap: 1.24x (0.0877 / 0.0707) = 19.4% improvement needed\n",
    "- 5 submissions remaining\n",
    "- exp_057 (Simpler Model with Spange Only) FAILED - CV 0.023017 (177.4% worse)\n",
    "\n",
    "**Critical Evaluator Insight:**\n",
    "- The target IS reachable! Intercept (0.0525) < Target (0.0707)\n",
    "- Required CV to hit target: 0.00422 (49% improvement from current best 0.008298)\n",
    "- The 'mixall' kernel uses GroupKFold(5) instead of Leave-One-Out(24)\n",
    "\n",
    "**Questions:**\n",
    "1. What approaches haven't been tried?\n",
    "2. How can we reduce CV by 49%?\n",
    "3. What's the path to LB 0.0707?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nTarget LB: 0.0707\")\n",
    "print(f\"Best LB: {df['lb'].min():.4f} ({df.loc[df['lb'].idxmin(), 'exp']})\")\n",
    "print(f\"Gap to target: {df['lb'].min() / 0.0707:.2f}x ({(df['lb'].min() - 0.0707) / 0.0707 * 100:.1f}% improvement needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV-LB relationship analysis\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "\n",
    "print(f\"CV-LB Linear Relationship:\")\n",
    "print(f\"  LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"  R² = {r_value**2:.4f}\")\n",
    "print(f\"  Intercept = {intercept:.4f}\")\n",
    "print(f\"  Target LB = 0.0707\")\n",
    "print(f\"\")\n",
    "print(f\"CRITICAL INSIGHT:\")\n",
    "print(f\"  Intercept ({intercept:.4f}) < Target ({0.0707})\")\n",
    "print(f\"  This means the target IS REACHABLE!\")\n",
    "print(f\"\")\n",
    "print(f\"Required CV to hit target:\")\n",
    "required_cv = (0.0707 - intercept) / slope\n",
    "print(f\"  CV = (0.0707 - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}\")\n",
    "print(f\"  Current best CV: 0.008298\")\n",
    "print(f\"  Required improvement: {(0.008298 - required_cv) / 0.008298 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734120b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals - which experiments performed better/worse than expected?\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print(\"CV-LB Residual Analysis:\")\n",
    "print(\"(Negative residual = performed BETTER on LB than expected from CV)\")\n",
    "print(\"\")\n",
    "for _, row in df.sort_values('residual').iterrows():\n",
    "    print(f\"  {row['exp']}: CV={row['cv']:.4f}, LB={row['lb']:.4f}, Predicted={row['predicted_lb']:.4f}, Residual={row['residual']:+.4f}\")\n",
    "\n",
    "print(f\"\\nBest residual: {df.loc[df['residual'].idxmin(), 'exp']} ({df['residual'].min():.4f})\")\n",
    "print(f\"Worst residual: {df.loc[df['residual'].idxmax(), 'exp']} ({df['residual'].max():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have been tried?\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES TRIED (58 experiments)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = [\n",
    "    \"MLP with Arrhenius kinetics (exp_000, exp_006, exp_007)\",\n",
    "    \"LightGBM (exp_001)\",\n",
    "    \"DRFP features with PCA (exp_002)\",\n",
    "    \"Combined Spange + DRFP (exp_003, exp_005)\",\n",
    "    \"Deep Residual MLP (exp_004) - FAILED\",\n",
    "    \"Large Ensemble 15 models (exp_005)\",\n",
    "    \"Simpler models [64,32] (exp_006, exp_007, exp_008)\",\n",
    "    \"Ridge Regression (exp_009, exp_033)\",\n",
    "    \"Single layer 16 (exp_010)\",\n",
    "    \"Diverse Ensemble (exp_011, exp_047)\",\n",
    "    \"Simple Ensemble (exp_012)\",\n",
    "    \"Compliant Ensemble (exp_013)\",\n",
    "    \"Ensemble weight tuning (exp_014, exp_031, exp_035, exp_036)\",\n",
    "    \"Three model ensemble (exp_015)\",\n",
    "    \"Attention model (exp_017)\",\n",
    "    \"Fragprints (exp_018)\",\n",
    "    \"ACS PCA features (exp_019, exp_023, exp_024)\",\n",
    "    \"Per-target models (exp_025)\",\n",
    "    \"Weighted loss (exp_026)\",\n",
    "    \"Simple features (exp_027)\",\n",
    "    \"Four model ensemble (exp_028)\",\n",
    "    \"Normalization (exp_029)\",\n",
    "    \"GP Ensemble (exp_030) - BEST\",\n",
    "    \"Higher GP weight (exp_031, exp_035)\",\n",
    "    \"Pure GP (exp_032)\",\n",
    "    \"Kernel Ridge (exp_034)\",\n",
    "    \"Similarity weighting (exp_037)\",\n",
    "    \"Minimal features (exp_038)\",\n",
    "    \"Learned embeddings (exp_039)\",\n",
    "    \"GNN architectures (exp_040, exp_052)\",\n",
    "    \"ChemBERTa (exp_041)\",\n",
    "    \"Calibration (exp_042)\",\n",
    "    \"Nonlinear mixture (exp_043)\",\n",
    "    \"Hybrid model (exp_044)\",\n",
    "    \"Mean reversion (exp_045)\",\n",
    "    \"Adaptive weighting (exp_046)\",\n",
    "    \"Hybrid features (exp_048)\",\n",
    "    \"Manual OOD handling (exp_049)\",\n",
    "    \"LISA/REX (exp_050)\",\n",
    "    \"Simpler model (exp_051, exp_054)\",\n",
    "    \"mixall full features (exp_053)\",\n",
    "    \"Chemical constraints (exp_055)\",\n",
    "    \"XGBoost + RF Ensemble (exp_056)\",\n",
    "    \"Simpler Spange Only (exp_057)\",\n",
    "]\n",
    "\n",
    "for i, approach in enumerate(approaches, 1):\n",
    "    print(f\"  {i}. {approach}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e69409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches HAVEN'T been tried?\n",
    "print(\"=\"*60)\n",
    "print(\"APPROACHES NOT YET TRIED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "untried = [\n",
    "    \"1. PREDICTION CALIBRATION (Isotonic Regression)\",\n",
    "    \"   - Train best model (exp_030)\",\n",
    "    \"   - Use CV predictions to fit isotonic regression\",\n",
    "    \"   - Apply calibration to test predictions\",\n",
    "    \"   - Explicitly corrects systematic bias\",\n",
    "    \"\",\n",
    "    \"2. IMPORTANCE WEIGHTING\",\n",
    "    \"   - Weight training samples by similarity to test distribution\",\n",
    "    \"   - Use adversarial validation to identify drifting features\",\n",
    "    \"   - Down-weight samples that are far from test distribution\",\n",
    "    \"\",\n",
    "    \"3. DOMAIN ADAPTATION\",\n",
    "    \"   - Adapt model to test distribution at inference time\",\n",
    "    \"   - Use test-time training (TTT) or transductive learning\",\n",
    "    \"   - Fine-tune on test data without labels\",\n",
    "    \"\",\n",
    "    \"4. CATBOOST\",\n",
    "    \"   - Different gradient boosting implementation\",\n",
    "    \"   - Handles categorical features natively\",\n",
    "    \"   - May have different inductive biases\",\n",
    "    \"\",\n",
    "    \"5. NEURAL NETWORK ENSEMBLES WITH DIFFERENT ARCHITECTURES\",\n",
    "    \"   - Train multiple MLPs with different architectures\",\n",
    "    \"   - Use different activation functions (GELU, SiLU)\",\n",
    "    \"   - Use different regularization (LayerNorm, GroupNorm)\",\n",
    "    \"\",\n",
    "    \"6. QUANTILE REGRESSION\",\n",
    "    \"   - Train model with quantile loss (median)\",\n",
    "    \"   - May produce more robust predictions\",\n",
    "    \"   - Different loss function could change CV-LB relationship\",\n",
    "]\n",
    "\n",
    "for line in untried:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the mixall kernel approach\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS: The 'mixall' Kernel Approach\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "The 'mixall' kernel achieves good LB scores using:\n",
    "\n",
    "1. ENSEMBLE: MLP (0.4) + XGBoost (0.2) + RandomForest (0.2) + LightGBM (0.2)\n",
    "   - Our exp_056 tried XGBoost + RF but FAILED\n",
    "   - Key difference: mixall uses different weights and architecture\n",
    "\n",
    "2. FEATURES: Spange descriptors + Residence Time + Temperature\n",
    "   - Simple features, no DRFP\n",
    "   - Our exp_057 tried this but FAILED\n",
    "\n",
    "3. CV SCHEME: GroupKFold(5) instead of Leave-One-Out(24)\n",
    "   - This is a GRAY AREA in competition rules\n",
    "   - Their local CV is not comparable to ours\n",
    "   - But their model may still generalize better\n",
    "\n",
    "4. ARCHITECTURE: MLP [128, 64, 32] with dropout 0.1\n",
    "   - Similar to our exp_006, exp_007\n",
    "   - Not fundamentally different\n",
    "\n",
    "KEY INSIGHT:\n",
    "The mixall kernel's success is NOT due to a fundamentally different approach.\n",
    "It's likely due to:\n",
    "  a) Different hyperparameters\n",
    "  b) Different random seeds\n",
    "  c) Different training dynamics\n",
    "  d) Luck in the CV-LB relationship\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nOur best model (exp_030) uses:\")\n",
    "print(\"  - GP (0.15) + MLP (0.55) + LGBM (0.30)\")\n",
    "print(\"  - Spange + DRFP + Arrhenius features\")\n",
    "print(\"  - CV: 0.008298, LB: 0.0877\")\n",
    "print(\"\\nTo reach target LB 0.0707, we need:\")\n",
    "print(f\"  - CV: {required_cv:.6f} (49% improvement)\")\n",
    "print(f\"  - Or change the CV-LB relationship (reduce intercept)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic analysis\n",
    "print(\"=\"*60)\n",
    "print(\"STRATEGIC ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "CURRENT SITUATION:\n",
    "- 27 consecutive failures since exp_030\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0707 (19.4% improvement needed)\n",
    "- 5 submissions remaining\n",
    "\n",
    "THE PROBLEM:\n",
    "- We've tried many approaches but none beat exp_030\n",
    "- The CV-LB relationship is: LB = 4.31*CV + 0.0525\n",
    "- To reach target, we need CV = 0.00422 (49% improvement)\n",
    "\n",
    "THE PATH FORWARD:\n",
    "\n",
    "1. FOCUS ON CV IMPROVEMENT\n",
    "   - Current best CV: 0.008298\n",
    "   - Required CV: 0.00422\n",
    "   - This is a 49% improvement - very aggressive\n",
    "   - Need fundamentally better features or models\n",
    "\n",
    "2. FOCUS ON CV-LB RELATIONSHIP\n",
    "   - The intercept (0.0525) is the systematic bias\n",
    "   - Prediction calibration could reduce this\n",
    "   - Importance weighting could reduce this\n",
    "\n",
    "3. SUBMISSION STRATEGY\n",
    "   - 5 submissions remaining\n",
    "   - Use 2-3 for experiments that might change CV-LB relationship\n",
    "   - Save 2 for final attempts\n",
    "\n",
    "RECOMMENDED PRIORITIES:\n",
    "1. Prediction Calibration (Isotonic Regression) - directly addresses intercept\n",
    "2. Importance Weighting - addresses distribution shift\n",
    "3. CatBoost - different inductive biases\n",
    "4. Quantile Regression - different loss function\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNOTE: The evaluator says the target IS reachable.\")\n",
    "print(\"The intercept (0.0525) < Target (0.0707) means we CAN reach it.\")\n",
    "print(\"We just need to improve CV by 49% or reduce the intercept.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eadec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"LOOP 58 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Current Status:\n",
    "  - Best CV: 0.008298 (exp_030)\n",
    "  - Best LB: 0.0877 (exp_030)\n",
    "  - Target LB: 0.0707\n",
    "  - Gap: 19.4% improvement needed\n",
    "  - Submissions remaining: 5\n",
    "  - Consecutive failures: 27\n",
    "\n",
    "Key Findings:\n",
    "  1. CV-LB relationship: LB = 4.31*CV + 0.0525 (R²=0.95)\n",
    "  2. Intercept (0.0525) < Target (0.0707) - target IS reachable\n",
    "  3. Required CV to hit target: 0.00422 (49% improvement)\n",
    "  4. exp_057 (Simpler Spange Only) FAILED - CV 0.023017 (177.4% worse)\n",
    "  5. The 'mixall' kernel uses GroupKFold(5) - not directly comparable\n",
    "\n",
    "Recommended Next Steps:\n",
    "  1. Prediction Calibration (Isotonic Regression) - directly addresses intercept\n",
    "  2. Importance Weighting - addresses distribution shift\n",
    "  3. CatBoost - different inductive biases\n",
    "  4. Quantile Regression - different loss function\n",
    "\n",
    "Submission Strategy:\n",
    "  - Use 2-3 submissions for experiments that might change CV-LB relationship\n",
    "  - Save 2 submissions for final attempts\n",
    "  - Focus on approaches that reduce the intercept, not just CV\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
