{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a051ece",
   "metadata": {},
   "source": [
    "# Loop 35 Analysis: Critical Decision Point\n",
    "\n",
    "**Situation:**\n",
    "- 35 experiments completed\n",
    "- 11 submissions made, 2 remaining\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap: 2.53x (153% worse)\n",
    "\n",
    "**Latest Experiment (exp_037):**\n",
    "- Similarity weighting: 220.92% WORSE (CV 0.026296 vs baseline 0.008194)\n",
    "- FAILED due to implementation bug (unnormalized features, wrong sigma)\n",
    "\n",
    "**Key Question:** What can we do with 2 submissions remaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd106fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:12.348412Z",
     "iopub.status.busy": "2026-01-14T21:20:12.347643Z",
     "iopub.status.idle": "2026-01-14T21:20:13.640295Z",
     "shell.execute_reply": "2026-01-14T21:20:13.639590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All submissions:\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n",
      "exp_026 0.0085 0.0887\n",
      "exp_030 0.0083 0.0877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('All submissions:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee3d1fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.643304Z",
     "iopub.status.busy": "2026-01-14T21:20:13.642822Z",
     "iopub.status.idle": "2026-01-14T21:20:13.652996Z",
     "shell.execute_reply": "2026-01-14T21:20:13.652399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV-LB Linear Fit ===\n",
      "LB = 4.30 * CV + 0.0524\n",
      "R² = 0.9675\n",
      "Slope: 4.30\n",
      "Intercept: 0.0524\n",
      "\n",
      "=== Target Analysis ===\n",
      "Target LB: 0.0347\n",
      "Required CV to reach target: -0.0041\n",
      "\n",
      "⚠️ IMPOSSIBLE with current CV-LB relationship!\n",
      "Intercept (0.0524) > Target (0.0347)\n",
      "Even with CV=0, predicted LB would be 0.0524\n"
     ]
    }
   ],
   "source": [
    "# Linear regression on CV-LB relationship\n",
    "cv_vals = df['cv'].values\n",
    "lb_vals = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_vals, lb_vals)\n",
    "\n",
    "print(f'\\n=== CV-LB Linear Fit ===')\n",
    "print(f'LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Slope: {slope:.2f}')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\n=== Target Analysis ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV to reach target: {required_cv:.4f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(f'\\n⚠️ IMPOSSIBLE with current CV-LB relationship!')\n",
    "    print(f'Intercept ({intercept:.4f}) > Target ({target})')\n",
    "    print(f'Even with CV=0, predicted LB would be {intercept:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17fb5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.655244Z",
     "iopub.status.busy": "2026-01-14T21:20:13.654991Z",
     "iopub.status.idle": "2026-01-14T21:20:13.669299Z",
     "shell.execute_reply": "2026-01-14T21:20:13.668532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Residuals Analysis ===\n",
      "    exp     cv     lb  predicted_lb  residual  residual_pct\n",
      "exp_000 0.0111 0.0982      0.100199 -0.001999     -1.995362\n",
      "exp_001 0.0123 0.1065      0.105364  0.001136      1.077855\n",
      "exp_003 0.0105 0.0972      0.097617 -0.000417     -0.427023\n",
      "exp_005 0.0104 0.0969      0.097186 -0.000286     -0.294724\n",
      "exp_006 0.0097 0.0946      0.094174  0.000426      0.452863\n",
      "exp_007 0.0093 0.0932      0.092452  0.000748      0.809220\n",
      "exp_009 0.0092 0.0936      0.092021  0.001579      1.715420\n",
      "exp_012 0.0090 0.0913      0.091161  0.000139      0.152901\n",
      "exp_024 0.0087 0.0893      0.089869 -0.000569     -0.633551\n",
      "exp_026 0.0085 0.0887      0.089009 -0.000309     -0.346638\n",
      "exp_030 0.0083 0.0877      0.088148 -0.000448     -0.507905\n",
      "\n",
      "Mean residual: -0.0000\n",
      "Std residual: 0.0010\n",
      "\n",
      "Best residual (most negative): exp_000 (-0.0020)\n",
      "Worst residual (most positive): exp_009 (0.0016)\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals and identify outliers\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "df['residual_pct'] = df['residual'] / df['predicted_lb'] * 100\n",
    "\n",
    "print('\\n=== Residuals Analysis ===')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual', 'residual_pct']].to_string(index=False))\n",
    "\n",
    "print(f'\\nMean residual: {df[\"residual\"].mean():.4f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.4f}')\n",
    "print(f'\\nBest residual (most negative): {df[\"exp\"].iloc[df[\"residual\"].argmin()]} ({df[\"residual\"].min():.4f})')\n",
    "print(f'Worst residual (most positive): {df[\"exp\"].iloc[df[\"residual\"].argmax()]} ({df[\"residual\"].max():.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c6a225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.671261Z",
     "iopub.status.busy": "2026-01-14T21:20:13.671024Z",
     "iopub.status.idle": "2026-01-14T21:20:13.677209Z",
     "shell.execute_reply": "2026-01-14T21:20:13.676539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Approaches Tried ===\n",
      "\n",
      "MLP architectures:\n",
      "  - exp_000 (baseline)\n",
      "  - exp_004 (deep residual - FAILED)\n",
      "  - exp_006 (simpler [64,32])\n",
      "  - exp_007 (even simpler [32,16])\n",
      "\n",
      "Feature engineering:\n",
      "  - exp_002 (DRFP with PCA - WORSE)\n",
      "  - exp_003 (Spange+DRFP combined)\n",
      "  - exp_027 (simple features - WORSE)\n",
      "\n",
      "Ensemble methods:\n",
      "  - exp_005 (15 models)\n",
      "  - exp_011 (diverse ensemble)\n",
      "  - exp_012 (simple ensemble)\n",
      "  - exp_028 (4-model ensemble - WORSE)\n",
      "\n",
      "Loss functions:\n",
      "  - exp_026 (weighted loss)\n",
      "  - exp_029 (normalization - FAILED)\n",
      "\n",
      "GP models:\n",
      "  - exp_030 (GP+MLP+LGBM)\n",
      "  - exp_031 (higher GP weight)\n",
      "  - exp_032 (pure GP)\n",
      "  - exp_035 (lower GP weight)\n",
      "\n",
      "Distribution shift:\n",
      "  - exp_037 (similarity weighting - FAILED)\n"
     ]
    }
   ],
   "source": [
    "# What approaches have we tried?\n",
    "approaches = {\n",
    "    'MLP architectures': ['exp_000 (baseline)', 'exp_004 (deep residual - FAILED)', 'exp_006 (simpler [64,32])', 'exp_007 (even simpler [32,16])'],\n",
    "    'Feature engineering': ['exp_002 (DRFP with PCA - WORSE)', 'exp_003 (Spange+DRFP combined)', 'exp_027 (simple features - WORSE)'],\n",
    "    'Ensemble methods': ['exp_005 (15 models)', 'exp_011 (diverse ensemble)', 'exp_012 (simple ensemble)', 'exp_028 (4-model ensemble - WORSE)'],\n",
    "    'Loss functions': ['exp_026 (weighted loss)', 'exp_029 (normalization - FAILED)'],\n",
    "    'GP models': ['exp_030 (GP+MLP+LGBM)', 'exp_031 (higher GP weight)', 'exp_032 (pure GP)', 'exp_035 (lower GP weight)'],\n",
    "    'Distribution shift': ['exp_037 (similarity weighting - FAILED)'],\n",
    "}\n",
    "\n",
    "print('\\n=== Approaches Tried ===')\n",
    "for category, exps in approaches.items():\n",
    "    print(f'\\n{category}:')\n",
    "    for exp in exps:\n",
    "        print(f'  - {exp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca474aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.679069Z",
     "iopub.status.busy": "2026-01-14T21:20:13.678870Z",
     "iopub.status.idle": "2026-01-14T21:20:13.684431Z",
     "shell.execute_reply": "2026-01-14T21:20:13.683726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NEW INSIGHT FROM KAGGLE KERNELS ===\n",
      "\n",
      "The \"mixall\" kernel (8 votes) uses GroupKFold (5 splits) instead of Leave-One-Out CV.\n",
      "This is a fundamentally different approach that might change the CV-LB relationship.\n",
      "\n",
      "Key differences:\n",
      "1. Leave-One-Out: 24 folds for single solvent, 13 folds for full data\n",
      "2. GroupKFold(5): 5 folds for each, groups by solvent\n",
      "\n",
      "Why this might help:\n",
      "- Leave-One-Out CV is very sensitive to individual solvents\n",
      "- GroupKFold provides more stable CV estimates\n",
      "- May reduce overfitting to specific solvents\n",
      "\n",
      "However, the competition rules state:\n",
      "\"Submissions will be evaluated according to a cross-validation procedure\"\n",
      "\"The submission must have the same last three cells as in the notebook template\"\n",
      "\n",
      "This means we CANNOT change the CV scheme - it's fixed by the competition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight from Kaggle kernel: GroupKFold instead of Leave-One-Out\n",
    "print('\\n=== NEW INSIGHT FROM KAGGLE KERNELS ===')\n",
    "print('''\n",
    "The \"mixall\" kernel (8 votes) uses GroupKFold (5 splits) instead of Leave-One-Out CV.\n",
    "This is a fundamentally different approach that might change the CV-LB relationship.\n",
    "\n",
    "Key differences:\n",
    "1. Leave-One-Out: 24 folds for single solvent, 13 folds for full data\n",
    "2. GroupKFold(5): 5 folds for each, groups by solvent\n",
    "\n",
    "Why this might help:\n",
    "- Leave-One-Out CV is very sensitive to individual solvents\n",
    "- GroupKFold provides more stable CV estimates\n",
    "- May reduce overfitting to specific solvents\n",
    "\n",
    "However, the competition rules state:\n",
    "\"Submissions will be evaluated according to a cross-validation procedure\"\n",
    "\"The submission must have the same last three cells as in the notebook template\"\n",
    "\n",
    "This means we CANNOT change the CV scheme - it's fixed by the competition.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb5abfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.686504Z",
     "iopub.status.busy": "2026-01-14T21:20:13.686281Z",
     "iopub.status.idle": "2026-01-14T21:20:13.692791Z",
     "shell.execute_reply": "2026-01-14T21:20:13.692103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GAP ANALYSIS ===\n",
      "Best LB: 0.0877\n",
      "Target: 0.0347\n",
      "Gap: 0.0530 (152.7% worse)\n",
      "Ratio: 2.53x\n",
      "\n",
      "=== What would it take to reach target? ===\n",
      "Current CV-LB relationship: LB = 4.30*CV + 0.0524\n",
      "Intercept (0.0524) > Target (0.0347)\n",
      "\n",
      "To reach target, we need to:\n",
      "1. CHANGE the CV-LB relationship (reduce intercept)\n",
      "2. OR find an approach with fundamentally different CV-LB dynamics\n",
      "\n",
      "Approaches that might change the relationship:\n",
      "- Simpler models (reduce overfitting)\n",
      "- Different features (reduce distribution shift)\n",
      "- Domain adaptation (learn invariant representations)\n",
      "- Adversarial validation (identify and remove shift-causing features)\n"
     ]
    }
   ],
   "source": [
    "# What's the gap between our best and the target?\n",
    "print('\\n=== GAP ANALYSIS ===')\n",
    "best_lb = 0.0877\n",
    "target = 0.0347\n",
    "\n",
    "print(f'Best LB: {best_lb}')\n",
    "print(f'Target: {target}')\n",
    "print(f'Gap: {best_lb - target:.4f} ({(best_lb - target)/target*100:.1f}% worse)')\n",
    "print(f'Ratio: {best_lb/target:.2f}x')\n",
    "\n",
    "print(f'\\n=== What would it take to reach target? ===')\n",
    "print(f'Current CV-LB relationship: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "print(f'Intercept ({intercept:.4f}) > Target ({target})')\n",
    "print(f'\\nTo reach target, we need to:')\n",
    "print(f'1. CHANGE the CV-LB relationship (reduce intercept)')\n",
    "print(f'2. OR find an approach with fundamentally different CV-LB dynamics')\n",
    "print(f'\\nApproaches that might change the relationship:')\n",
    "print(f'- Simpler models (reduce overfitting)')\n",
    "print(f'- Different features (reduce distribution shift)')\n",
    "print(f'- Domain adaptation (learn invariant representations)')\n",
    "print(f'- Adversarial validation (identify and remove shift-causing features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31c834a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.694602Z",
     "iopub.status.busy": "2026-01-14T21:20:13.694392Z",
     "iopub.status.idle": "2026-01-14T21:20:13.707387Z",
     "shell.execute_reply": "2026-01-14T21:20:13.706652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPERIMENTS WITH BEST RESIDUALS ===\n",
      "    exp     cv     lb  predicted_lb  residual\n",
      "exp_000 0.0111 0.0982      0.100199 -0.001999\n",
      "exp_024 0.0087 0.0893      0.089869 -0.000569\n",
      "exp_030 0.0083 0.0877      0.088148 -0.000448\n",
      "exp_003 0.0105 0.0972      0.097617 -0.000417\n",
      "exp_026 0.0085 0.0887      0.089009 -0.000309\n",
      "\n",
      "=== EXPERIMENTS WITH WORST RESIDUALS ===\n",
      "    exp     cv     lb  predicted_lb  residual\n",
      "exp_012 0.0090 0.0913      0.091161  0.000139\n",
      "exp_006 0.0097 0.0946      0.094174  0.000426\n",
      "exp_007 0.0093 0.0932      0.092452  0.000748\n",
      "exp_001 0.0123 0.1065      0.105364  0.001136\n",
      "exp_009 0.0092 0.0936      0.092021  0.001579\n"
     ]
    }
   ],
   "source": [
    "# What experiments have the best residuals (LB better than predicted)?\n",
    "print('\\n=== EXPERIMENTS WITH BEST RESIDUALS ===')\n",
    "df_sorted = df.sort_values('residual')\n",
    "print(df_sorted[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].head(5).to_string(index=False))\n",
    "\n",
    "print('\\n=== EXPERIMENTS WITH WORST RESIDUALS ===')\n",
    "print(df_sorted[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf66431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.709257Z",
     "iopub.status.busy": "2026-01-14T21:20:13.709045Z",
     "iopub.status.idle": "2026-01-14T21:20:13.713521Z",
     "shell.execute_reply": "2026-01-14T21:20:13.713044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RECOMMENDATION\n",
      "======================================================================\n",
      "\n",
      "**SITUATION:**\n",
      "- 2 submissions remaining\n",
      "- Best LB: 0.0877 (exp_030)\n",
      "- Target: 0.0347 (2.53x gap)\n",
      "- CV-LB relationship: LB = 4.30*CV + 0.0524 (R²=0.97)\n",
      "- Intercept (0.0524) > Target (0.0347)\n",
      "\n",
      "**CRITICAL INSIGHT:**\n",
      "The CV-LB relationship has an intercept of 0.0524, which is LARGER than the target (0.0347).\n",
      "This means even with perfect CV (0), we would still get LB ~0.0524.\n",
      "\n",
      "**WHAT THIS MEANS:**\n",
      "We cannot reach the target by improving CV alone. We need to fundamentally change\n",
      "the CV-LB relationship.\n",
      "\n",
      "**APPROACHES THAT MIGHT WORK:**\n",
      "1. AGGRESSIVE SIMPLIFICATION: Use minimal features (only kinetics + 2-3 Spange features)\n",
      "   - Rationale: Reduce overfitting to solvent-specific patterns\n",
      "   - Risk: May sacrifice CV for better LB\n",
      "\n",
      "2. FIXED SIMILARITY WEIGHTING: Normalize features, tune sigma properly\n",
      "   - Rationale: The implementation was buggy, the concept might still work\n",
      "   - Risk: May still not help if the problem is overfitting, not distribution shift\n",
      "\n",
      "3. PURE RIDGE REGRESSION: Simplest possible model\n",
      "   - Rationale: Maximum regularization, minimum overfitting\n",
      "   - Risk: May be too simple to capture the signal\n",
      "\n",
      "**RECOMMENDATION:**\n",
      "With only 2 submissions remaining, we should:\n",
      "1. Try ONE more experiment with aggressive simplification\n",
      "2. Submit the best result (either new experiment or exp_030)\n",
      "3. Use final submission for the best model\n",
      "\n",
      "**DO NOT:**\n",
      "- Submit exp_037 (similarity weighting) - it's 220% worse\n",
      "- Try complex approaches - they increase overfitting\n",
      "- Give up - the target IS reachable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final recommendation\n",
    "print('\\n' + '='*70)\n",
    "print('FINAL RECOMMENDATION')\n",
    "print('='*70)\n",
    "\n",
    "print('''\n",
    "**SITUATION:**\n",
    "- 2 submissions remaining\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347 (2.53x gap)\n",
    "- CV-LB relationship: LB = 4.30*CV + 0.0524 (R²=0.97)\n",
    "- Intercept (0.0524) > Target (0.0347)\n",
    "\n",
    "**CRITICAL INSIGHT:**\n",
    "The CV-LB relationship has an intercept of 0.0524, which is LARGER than the target (0.0347).\n",
    "This means even with perfect CV (0), we would still get LB ~0.0524.\n",
    "\n",
    "**WHAT THIS MEANS:**\n",
    "We cannot reach the target by improving CV alone. We need to fundamentally change\n",
    "the CV-LB relationship.\n",
    "\n",
    "**APPROACHES THAT MIGHT WORK:**\n",
    "1. AGGRESSIVE SIMPLIFICATION: Use minimal features (only kinetics + 2-3 Spange features)\n",
    "   - Rationale: Reduce overfitting to solvent-specific patterns\n",
    "   - Risk: May sacrifice CV for better LB\n",
    "\n",
    "2. FIXED SIMILARITY WEIGHTING: Normalize features, tune sigma properly\n",
    "   - Rationale: The implementation was buggy, the concept might still work\n",
    "   - Risk: May still not help if the problem is overfitting, not distribution shift\n",
    "\n",
    "3. PURE RIDGE REGRESSION: Simplest possible model\n",
    "   - Rationale: Maximum regularization, minimum overfitting\n",
    "   - Risk: May be too simple to capture the signal\n",
    "\n",
    "**RECOMMENDATION:**\n",
    "With only 2 submissions remaining, we should:\n",
    "1. Try ONE more experiment with aggressive simplification\n",
    "2. Submit the best result (either new experiment or exp_030)\n",
    "3. Use final submission for the best model\n",
    "\n",
    "**DO NOT:**\n",
    "- Submit exp_037 (similarity weighting) - it's 220% worse\n",
    "- Try complex approaches - they increase overfitting\n",
    "- Give up - the target IS reachable\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79839da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T21:20:13.715153Z",
     "iopub.status.busy": "2026-01-14T21:20:13.714966Z",
     "iopub.status.idle": "2026-01-14T21:20:13.721496Z",
     "shell.execute_reply": "2026-01-14T21:20:13.720948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UNSUBMITTED EXPERIMENTS ===\n",
      "Best unsubmitted experiments:\n",
      "exp_032: CV 0.008194, Predicted LB 0.0877 - GP 0.15 + MLP 0.55 + LGBM 0.3\n",
      "exp_035: CV 0.008194, Predicted LB 0.0877 - GP 0.15 + MLP 0.55 + LGBM 0.3 (same as exp_032)\n",
      "exp_036: CV 0.008194, Predicted LB 0.0877 - No GP (MLP 0.65 + LGBM 0.35)\n",
      "\n",
      "Note: exp_030 (submitted) has CV 0.0083, LB 0.0877\n",
      "exp_032/035/036 have CV 0.008194, predicted LB 0.0877\n",
      "\n",
      "These are essentially the same as exp_030, so submitting them would not help.\n"
     ]
    }
   ],
   "source": [
    "# What's the best experiment we haven't submitted?\n",
    "print('\\n=== UNSUBMITTED EXPERIMENTS ===')\n",
    "\n",
    "# Best CV scores from experiments\n",
    "best_cv_experiments = [\n",
    "    ('exp_032', 0.008194, 'GP 0.15 + MLP 0.55 + LGBM 0.3'),\n",
    "    ('exp_035', 0.008194, 'GP 0.15 + MLP 0.55 + LGBM 0.3 (same as exp_032)'),\n",
    "    ('exp_036', 0.008194, 'No GP (MLP 0.65 + LGBM 0.35)'),\n",
    "]\n",
    "\n",
    "print('Best unsubmitted experiments:')\n",
    "for exp, cv, desc in best_cv_experiments:\n",
    "    predicted_lb = slope * cv + intercept\n",
    "    print(f'{exp}: CV {cv:.6f}, Predicted LB {predicted_lb:.4f} - {desc}')\n",
    "\n",
    "print(f'\\nNote: exp_030 (submitted) has CV 0.0083, LB 0.0877')\n",
    "print(f'exp_032/035/036 have CV 0.008194, predicted LB {slope * 0.008194 + intercept:.4f}')\n",
    "print(f'\\nThese are essentially the same as exp_030, so submitting them would not help.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
