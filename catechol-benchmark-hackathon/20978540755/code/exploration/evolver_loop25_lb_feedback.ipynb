{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29aa293d",
   "metadata": {},
   "source": [
    "# Loop 25 LB Feedback Analysis\n",
    "\n",
    "**exp_024 submitted**: CV 0.0087 → LB 0.0893 (gap: -0.0806)\n",
    "\n",
    "This is our BEST LB score yet! Let's analyze the trajectory and plan next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},  # NEW!\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== SUBMISSION HISTORY ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nBest CV: {df[\"cv\"].min():.4f} ({df.loc[df[\"cv\"].idxmin(), \"exp\"]})')\n",
    "print(f'Best LB: {df[\"lb\"].min():.4f} ({df.loc[df[\"lb\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated CV-LB linear fit with new data point\n",
    "cv_scores = df['cv'].values\n",
    "lb_scores = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print('=== UPDATED CV-LB LINEAR FIT ===')\n",
    "print(f'LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Slope std error: {std_err:.4f}')\n",
    "\n",
    "# Prediction for various CV scores\n",
    "for cv in [0.008, 0.007, 0.006, 0.005, 0.004, 0.003]:\n",
    "    pred_lb = slope * cv + intercept\n",
    "    print(f'CV {cv:.3f} → Predicted LB {pred_lb:.4f}')\n",
    "\n",
    "# What CV do we need to beat target 0.01727?\n",
    "target = 0.01727\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\nTo beat target {target}: need CV < {required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals for the linear fit\n",
    "n = len(cv_scores)\n",
    "mean_cv = np.mean(cv_scores)\n",
    "ss_cv = np.sum((cv_scores - mean_cv)**2)\n",
    "\n",
    "# Standard error of the estimate\n",
    "residuals = lb_scores - (slope * cv_scores + intercept)\n",
    "mse_residuals = np.sum(residuals**2) / (n - 2)\n",
    "se_estimate = np.sqrt(mse_residuals)\n",
    "\n",
    "print('=== CONFIDENCE INTERVALS ===')\n",
    "print(f'Standard error of estimate: {se_estimate:.6f}')\n",
    "print(f'Mean CV: {mean_cv:.6f}')\n",
    "print(f'SS_CV: {ss_cv:.10f}')\n",
    "\n",
    "# 95% CI for intercept\n",
    "t_crit = stats.t.ppf(0.975, n - 2)\n",
    "se_intercept = se_estimate * np.sqrt(1/n + mean_cv**2/ss_cv)\n",
    "ci_intercept = (intercept - t_crit * se_intercept, intercept + t_crit * se_intercept)\n",
    "print(f'\\nIntercept 95% CI: [{ci_intercept[0]:.4f}, {ci_intercept[1]:.4f}]')\n",
    "\n",
    "# 95% CI for slope\n",
    "se_slope = se_estimate / np.sqrt(ss_cv)\n",
    "ci_slope = (slope - t_crit * se_slope, slope + t_crit * se_slope)\n",
    "print(f'Slope 95% CI: [{ci_slope[0]:.2f}, {ci_slope[1]:.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze improvement trajectory\n",
    "print('=== IMPROVEMENT TRAJECTORY ===')\n",
    "for i in range(1, len(df)):\n",
    "    prev = df.iloc[i-1]\n",
    "    curr = df.iloc[i]\n",
    "    cv_change = (curr['cv'] - prev['cv']) / prev['cv'] * 100\n",
    "    lb_change = (curr['lb'] - prev['lb']) / prev['lb'] * 100\n",
    "    print(f\"{prev['exp']} → {curr['exp']}: CV {cv_change:+.2f}%, LB {lb_change:+.2f}%\")\n",
    "\n",
    "# Overall improvement\n",
    "first = df.iloc[0]\n",
    "last = df.iloc[-1]\n",
    "print(f\"\\nOverall: CV {(last['cv']-first['cv'])/first['cv']*100:+.1f}%, LB {(last['lb']-first['lb'])/first['lb']*100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gap to target analysis\n",
    "print('=== GAP TO TARGET ===')\n",
    "target = 0.01727\n",
    "best_lb = df['lb'].min()\n",
    "gap = best_lb - target\n",
    "gap_pct = gap / target * 100\n",
    "\n",
    "print(f'Target: {target}')\n",
    "print(f'Best LB: {best_lb:.4f}')\n",
    "print(f'Gap: {gap:.4f} ({gap_pct:.1f}% above target)')\n",
    "print(f'Ratio: {best_lb/target:.2f}x')\n",
    "\n",
    "# How much improvement needed?\n",
    "improvement_needed = (best_lb - target) / best_lb * 100\n",
    "print(f'\\nNeed to improve LB by {improvement_needed:.1f}% to reach target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('''\n",
    "1. 4-Model Ensemble (MLP + XGB + RF + LGBM)\n",
    "   - Current: MLP + LGBM only\n",
    "   - Potential: More diversity in ensemble\n",
    "\n",
    "2. Per-Target Models\n",
    "   - SM has different characteristics (mean 0.52) vs Products (mean 0.13)\n",
    "   - Competition explicitly allows different hyperparameters per target\n",
    "\n",
    "3. Stacking Meta-Learner\n",
    "   - Current: Fixed weights (0.6 MLP + 0.4 LGBM)\n",
    "   - Potential: Learn optimal weights from OOF predictions\n",
    "\n",
    "4. Non-linear Mixture Encoding\n",
    "   - Current: Linear interpolation A*(1-pct) + B*pct\n",
    "   - Potential: Add interaction term A*B*pct*(1-pct)\n",
    "\n",
    "5. Larger MLP Ensemble\n",
    "   - Current: 5 MLPs\n",
    "   - Potential: 10-15 MLPs for variance reduction\n",
    "\n",
    "6. Different Feature Subsets\n",
    "   - Try DRFP-only, Spange-only, ACS-only models\n",
    "   - Ensemble models trained on different feature sets\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa75a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority ranking based on expected impact\n",
    "print('=== PRIORITY RANKING ===')\n",
    "print('''\n",
    "HIGH IMPACT (try first):\n",
    "1. 4-Model Ensemble - More model diversity typically helps\n",
    "2. Per-Target Models - Exploit target-specific patterns\n",
    "3. Stacking Meta-Learner - Learn optimal combination\n",
    "\n",
    "MEDIUM IMPACT:\n",
    "4. Non-linear Mixture Encoding - May capture interaction effects\n",
    "5. Larger MLP Ensemble - Variance reduction\n",
    "\n",
    "LOW IMPACT (already tried variations):\n",
    "6. Different architectures - Already optimized\n",
    "7. Different features - ACS PCA already added\n",
    "''')\n",
    "\n",
    "print('\\n=== RECOMMENDED NEXT EXPERIMENT ===')\n",
    "print('''\n",
    "exp_025: 4-Model Ensemble with ACS PCA Features\n",
    "- MLP (5 models, [32,16])\n",
    "- LightGBM\n",
    "- XGBoost\n",
    "- Random Forest\n",
    "- Weights: MLP 0.4, XGB 0.2, RF 0.2, LGBM 0.2\n",
    "- Expected CV improvement: 2-5%\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
