{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b23b77",
   "metadata": {},
   "source": [
    "# Loop 34 Analysis: Final Strategic Assessment\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008194 (exp_035: GP 0.15 + MLP 0.55 + LGBM 0.3)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap to target: 2.53x\n",
    "- Submissions remaining: 2\n",
    "\n",
    "**Latest experiment (exp_036):**\n",
    "- Removed GP entirely: MLP 0.6 + LGBM 0.4\n",
    "- CV: 0.008463 (3.29% WORSE than exp_035)\n",
    "- Confirms GP provides value at 0.15 weight\n",
    "\n",
    "**Key Question:** With 2 submissions remaining, what's the optimal strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Complete submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df)\n",
    "print(f'\\nCV-LB Ratio: {df[\"lb\"].mean() / df[\"cv\"].mean():.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabaf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression to understand CV-LB relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'Linear fit: LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target LB: 0.0347')\n",
    "\n",
    "# Predict LB for our best CV models\n",
    "best_cv = 0.008194  # exp_035\n",
    "predicted_lb = slope * best_cv + intercept\n",
    "print(f'\\nPredicted LB for exp_035 (CV={best_cv}): {predicted_lb:.4f}')\n",
    "\n",
    "# What CV would we need to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f'\\nTo reach target LB = {target_lb}:')\n",
    "print(f'  Required CV = ({target_lb} - {intercept:.4f}) / {slope:.2f} = {required_cv:.6f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print('\\n⚠️ IMPOSSIBLE with current CV-LB relationship!')\n",
    "    print(f'The intercept alone ({intercept:.4f}) is {intercept/target_lb:.2f}x higher than target ({target_lb})')\n",
    "else:\n",
    "    print(f'\\n✓ Achievable with CV = {required_cv:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f143107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV vs LB with predictions\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Scatter plot of submissions\n",
    "plt.scatter(df['cv'], df['lb'], s=100, alpha=0.7, label='Submissions', c='blue')\n",
    "\n",
    "# Fit line\n",
    "cv_range = np.linspace(0, 0.015, 100)\n",
    "lb_pred = slope * cv_range + intercept\n",
    "plt.plot(cv_range, lb_pred, 'r--', label=f'Fit: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "\n",
    "# Target line\n",
    "plt.axhline(y=0.0347, color='g', linestyle=':', linewidth=2, label='Target LB = 0.0347')\n",
    "\n",
    "# Mark exp_035 prediction\n",
    "plt.scatter([0.008194], [predicted_lb], s=200, marker='*', c='orange', label=f'exp_035 predicted: LB={predicted_lb:.4f}')\n",
    "\n",
    "plt.xlabel('CV Score', fontsize=12)\n",
    "plt.ylabel('LB Score', fontsize=12)\n",
    "plt.title('CV vs LB Relationship - 11 Submissions', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop34_cv_lb.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7992de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap between our CV and target\n",
    "print('=== Gap Analysis ===')\n",
    "print(f'\\nOur best CV: {best_cv:.6f}')\n",
    "print(f'Target LB: {target_lb}')\n",
    "print(f'\\nOur CV is {target_lb/best_cv:.2f}x WORSE than target LB')\n",
    "print(f'But our predicted LB ({predicted_lb:.4f}) is {predicted_lb/target_lb:.2f}x WORSE than target')\n",
    "print(f'\\nThe CV-LB gap is the problem, not our model quality!')\n",
    "\n",
    "# Check if there's any non-linearity we can exploit\n",
    "print('\\n=== Residual Analysis ===')\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']])\n",
    "print(f'\\nMean residual: {df[\"residual\"].mean():.6f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.6f}')\n",
    "print(f'Max positive residual: {df[\"residual\"].max():.6f} ({df.loc[df[\"residual\"].idxmax(), \"exp\"]})')\n",
    "print(f'Max negative residual: {df[\"residual\"].min():.6f} ({df.loc[df[\"residual\"].idxmin(), \"exp\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e140d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What experiments have we tried?\n",
    "print('=== Experiment Summary (36 experiments) ===')\n",
    "print()\n",
    "print('MODELS TRIED:')\n",
    "print('  ✓ MLP (various architectures: [256,128,64], [128,64], [64,32], [32,16])')\n",
    "print('  ✓ LightGBM')\n",
    "print('  ✓ XGBoost')\n",
    "print('  ✓ CatBoost')\n",
    "print('  ✓ Gaussian Process (Matern kernel)')\n",
    "print('  ✓ Ridge Regression')\n",
    "print('  ✓ Kernel Ridge Regression')\n",
    "print('  ✓ Ensembles (GP + MLP + LGBM with various weights)')\n",
    "print()\n",
    "print('FEATURES TRIED:')\n",
    "print('  ✓ Spange descriptors (13 features)')\n",
    "print('  ✓ DRFP fingerprints (122 high-variance features)')\n",
    "print('  ✓ ACS PCA descriptors (5 features)')\n",
    "print('  ✓ Arrhenius kinetics (1/T, ln(t), interaction)')\n",
    "print('  ✓ Combined features (145 total)')\n",
    "print()\n",
    "print('TECHNIQUES TRIED:')\n",
    "print('  ✓ Data augmentation (TTA for mixtures)')\n",
    "print('  ✓ Weighted loss (higher weight for SM)')\n",
    "print('  ✓ Ensemble weight optimization')\n",
    "print('  ✓ Normalization post-processing (FAILED)')\n",
    "print('  ✓ Per-target models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42651b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The CV-LB relationship is highly linear\n",
    "# This means the gap is STRUCTURAL, not due to overfitting\n",
    "\n",
    "print('=== KEY INSIGHT ===')\n",
    "print()\n",
    "print('The CV-LB relationship is highly linear (R² = 0.97)')\n",
    "print('This means:')\n",
    "print('  1. The gap is STRUCTURAL, not random')\n",
    "print('  2. Improving CV will improve LB proportionally')\n",
    "print('  3. But the intercept (0.052) limits how low we can go')\n",
    "print()\n",
    "print('To reach target LB = 0.0347:')\n",
    "print(f'  - Current approach: IMPOSSIBLE (intercept > target)')\n",
    "print(f'  - Need to change the CV-LB relationship itself')\n",
    "print()\n",
    "print('WHAT COULD CHANGE THE RELATIONSHIP?')\n",
    "print('  1. Different model architecture (e.g., attention, transformers)')\n",
    "print('  2. Different feature representation')\n",
    "print('  3. Domain adaptation techniques')\n",
    "print('  4. Training on different data distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final strategic assessment\n",
    "print('=== FINAL STRATEGIC ASSESSMENT ===')\n",
    "print()\n",
    "print('With 2 submissions remaining and target = 0.0347:')\n",
    "print()\n",
    "print('OPTION 1: Submit exp_035 (best CV = 0.008194)')\n",
    "print(f'  - Predicted LB: {predicted_lb:.4f}')\n",
    "print(f'  - Gap to target: {predicted_lb/target_lb:.2f}x')\n",
    "print('  - Pro: Best CV we have')\n",
    "print('  - Con: Predicted LB is still 2.5x worse than target')\n",
    "print()\n",
    "print('OPTION 2: Try a fundamentally different approach')\n",
    "print('  - Solvent similarity weighting')\n",
    "print('  - Feature selection (reduce to top 20-30 features)')\n",
    "print('  - Different kernel for GP (Tanimoto for chemical similarity)')\n",
    "print()\n",
    "print('RECOMMENDATION:')\n",
    "print('  Given the structural CV-LB gap, submitting exp_035 is unlikely to reach target.')\n",
    "print('  However, with only 2 submissions left, we should:')\n",
    "print('  1. Submit exp_035 to verify the CV-LB relationship holds')\n",
    "print('  2. Use the remaining submission for a fundamentally different approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the top LB score is\n",
    "print('=== LEADERBOARD CONTEXT ===')\n",
    "print()\n",
    "print('Our best LB: 0.0877 (exp_030)')\n",
    "print('Target: 0.0347')\n",
    "print()\n",
    "print('The target (0.0347) is achievable - it\\'s the benchmark we need to beat.')\n",
    "print('The question is: what approach can get us there?')\n",
    "print()\n",
    "print('Our CV (0.008194) is actually VERY GOOD - it\\'s 4.2x better than target!')\n",
    "print('The problem is the CV-LB gap, not our model quality.')\n",
    "print()\n",
    "print('This suggests the test distribution is fundamentally different from CV.')\n",
    "print('We need approaches that generalize better to unseen solvents.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
