{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce133d7",
   "metadata": {},
   "source": [
    "# Loop 29 Analysis: Critical Assessment After 28 Experiments\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.01727\n",
    "- CV-LB ratio: ~10.5x\n",
    "- Linear fit: LB = 4.22*CV + 0.0533 (R²=0.96)\n",
    "- Submissions remaining: 3\n",
    "\n",
    "**Latest Experiment (exp_028):**\n",
    "- Four-model ensemble (MLP+LGBM+XGB+CatBoost)\n",
    "- CV 0.008674 (2.47% WORSE than exp_026)\n",
    "- Adding more tree models did NOT help\n",
    "\n",
    "**Critical Question:**\n",
    "What approaches remain unexplored that could break the CV-LB pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All 10 submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'id': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'id': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'id': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'id': 'exp_005', 'cv': 0.01043, 'lb': 0.09691},\n",
    "    {'id': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'id': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'id': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'id': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'id': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'id': 'exp_026', 'cv': 0.008465, 'lb': 0.08875},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('All submissions:')\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Linear fit\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'\\nLinear fit: LB = {slope:.4f} * CV + {intercept:.5f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nTarget: 0.01727')\n",
    "print(f'Best LB: {df[\"lb\"].min():.5f}')\n",
    "print(f'Gap to target: {df[\"lb\"].min() / 0.01727:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598974c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What CV would we need to reach the target?\n",
    "target = 0.01727\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'=== Target Analysis ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV (from linear fit): {required_cv:.6f}')\n",
    "print(f'This is NEGATIVE - impossible with current approach!')\n",
    "print(f'\\nThe intercept ({intercept:.5f}) is {intercept/target:.2f}x higher than target.')\n",
    "print(f'Even with CV=0, predicted LB would be {intercept:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What experiments have been tried?\n",
    "experiments_tried = [\n",
    "    ('exp_000', 'MLP [128,128,64], Spange only, HuberLoss, 3 models'),\n",
    "    ('exp_001', 'LightGBM, Spange only'),\n",
    "    ('exp_002', 'DRFP with PCA (100 components) - FAILED'),\n",
    "    ('exp_003', 'MLP [256,128,64], Spange+DRFP, HuberLoss, 5 models'),\n",
    "    ('exp_004', 'Deep Residual MLP - FAILED'),\n",
    "    ('exp_005', 'MLP [256,128,64], Spange+DRFP, 15 models'),\n",
    "    ('exp_006', 'MLP [64,32], Spange+DRFP, 5 models'),\n",
    "    ('exp_007', 'MLP [32,16], Spange+DRFP, 5 models'),\n",
    "    ('exp_008', 'MLP [16], single layer'),\n",
    "    ('exp_009', 'Ridge Regression'),\n",
    "    ('exp_010', 'MLP [16], single layer'),\n",
    "    ('exp_011', 'Diverse ensemble'),\n",
    "    ('exp_012', 'MLP [32,16] + LightGBM ensemble'),\n",
    "    ('exp_013', 'Compliant ensemble'),\n",
    "    ('exp_014', 'Ensemble weights tuning'),\n",
    "    ('exp_015', 'Three-model ensemble'),\n",
    "    ('exp_016', 'Final summary'),\n",
    "    ('exp_017', 'Attention model'),\n",
    "    ('exp_018', 'Fragprints features'),\n",
    "    ('exp_019', 'ACS PCA features'),\n",
    "    ('exp_023', 'ACS PCA compliant'),\n",
    "    ('exp_024', 'ACS PCA fixed'),\n",
    "    ('exp_025', 'Per-target models - FAILED'),\n",
    "    ('exp_026', 'Weighted loss [1,1,2] - BEST'),\n",
    "    ('exp_027', 'Simple features (23) - FAILED'),\n",
    "    ('exp_028', 'Four-model ensemble (MLP+LGBM+XGB+CatBoost) - FAILED'),\n",
    "]\n",
    "\n",
    "print('=== Experiments Tried (28 total) ===')\n",
    "for exp_id, desc in experiments_tried:\n",
    "    print(f'{exp_id}: {desc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have NOT been tried?\n",
    "print('=== UNEXPLORED Approaches ===')\n",
    "unexplored = [\n",
    "    ('Gaussian Process Regression', 'Competition description mentions GP for imputation'),\n",
    "    ('Physics constraint (SM+P2+P3≈1)', 'Mass balance constraint for regularization'),\n",
    "    ('Higher SM weights [1,1,3] or [1,1,4]', 'SM is still the bottleneck'),\n",
    "    ('Stacking meta-learner', 'Train a meta-model on base predictions'),\n",
    "    ('Learned loss weights (homoscedastic)', 'Kendall et al. uncertainty weighting'),\n",
    "    ('Post-processing normalization', 'Normalize predictions to sum to 1'),\n",
    "    ('Domain adaptation', 'Handle distribution shift explicitly'),\n",
    "    ('Adversarial validation', 'Identify features causing distribution shift'),\n",
    "]\n",
    "\n",
    "for approach, rationale in unexplored:\n",
    "    print(f'\\n{approach}:')\n",
    "    print(f'  Rationale: {rationale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d029e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight from \"mixall\" kernel\n",
    "print('=== Key Insight from Kaggle Kernels ===')\n",
    "print('\\n\"mixall\" kernel uses GroupKFold(n_splits=5) instead of Leave-One-Out!')\n",
    "print('This is a DIFFERENT CV scheme than what we use.')\n",
    "print('\\nOur CV scheme:')\n",
    "print('- Single solvents: Leave-one-solvent-out (24 folds)')\n",
    "print('- Mixtures: Leave-one-ramp-out (13 folds)')\n",
    "print('- Total: 37 folds')\n",
    "print('\\nPossible LB CV scheme:')\n",
    "print('- GroupKFold (5 folds)')\n",
    "print('- Different random seed')\n",
    "print('- Different data ordering')\n",
    "print('\\nThis could explain the CV-LB gap!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another key insight: Post-processing normalization\n",
    "print('=== Post-Processing Normalization ===')\n",
    "print('\\nFrom \"mr0106/catechol\" kernel:')\n",
    "print('```python')\n",
    "print('# Post-processing: Chemical constraints (Clip and Normalize)')\n",
    "print('# Ensure outputs are between 0 and 1')\n",
    "print('preds = np.clip(preds, 0, 1)')\n",
    "print('')\n",
    "print('# Normalize rows so the sum of products equals 1 (or 100%)')\n",
    "print('row_sums = preds.sum(axis=1)[:, np.newaxis]')\n",
    "print('row_sums[row_sums == 0] = 1 # Avoid division by zero')\n",
    "print('preds = preds / row_sums')\n",
    "print('```')\n",
    "print('\\nThis enforces the physical constraint that SM + P2 + P3 = 1!')\n",
    "print('We have NOT tried this post-processing step.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority ranking for next experiments\n",
    "print('=== PRIORITY RANKING ===')\n",
    "print('\\n1. HIGHEST PRIORITY: Post-Processing Normalization')\n",
    "print('   - Enforce SM + P2 + P3 = 1 constraint')\n",
    "print('   - Simple to implement, no retraining needed')\n",
    "print('   - Used by other competitors')\n",
    "print('   - Physical constraint for regularization')\n",
    "\n",
    "print('\\n2. HIGH PRIORITY: Higher SM Weights [1,1,3]')\n",
    "print('   - SM is still the hardest target')\n",
    "print('   - Weighted loss [1,1,2] improved all targets by 2.58%')\n",
    "print('   - More aggressive weighting may help further')\n",
    "\n",
    "print('\\n3. MEDIUM PRIORITY: Gaussian Process Regression')\n",
    "print('   - Competition description mentions GP')\n",
    "print('   - Different model type with uncertainty quantification')\n",
    "print('   - May have different generalization properties')\n",
    "\n",
    "print('\\n4. LOWER PRIORITY: Stacking Meta-Learner')\n",
    "print('   - Train a simple model on base predictions')\n",
    "print('   - Can learn optimal combination weights')\n",
    "print('   - May improve generalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('=== FINAL RECOMMENDATION ===')\n",
    "print('\\nGiven:')\n",
    "print('- 3 submissions remaining')\n",
    "print('- CV-LB gap is ~10x (structural, not model-specific)')\n",
    "print('- Target 0.01727 is 5x better than best LB 0.0887')\n",
    "print('- exp_028 (four-model ensemble) was WORSE than exp_026')\n",
    "\n",
    "print('\\nStrategy:')\n",
    "print('1. Try post-processing normalization (SM+P2+P3=1)')\n",
    "print('2. Try higher SM weights [1,1,3]')\n",
    "print('3. Combine both: weighted loss + normalization')\n",
    "\n",
    "print('\\nKey insight:')\n",
    "print('The CV-LB gap is the fundamental problem.')\n",
    "print('We need approaches that GENERALIZE better, not just improve CV.')\n",
    "print('Post-processing normalization is a physics-based constraint that may help.')\n",
    "print('\\nDO NOT SUBMIT exp_028 - it is worse than exp_026.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
