{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053f3378",
   "metadata": {},
   "source": [
    "# Loop 36 Analysis: Critical Assessment\n",
    "\n",
    "**Situation:**\n",
    "- 36 experiments completed\n",
    "- 11 submissions made, 5 remaining\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap: 2.53x (153% worse)\n",
    "\n",
    "**Latest Experiment (exp_038):**\n",
    "- Minimal features (8 vs 145): 19.91% WORSE (CV 0.009825 vs baseline 0.008194)\n",
    "- CONFIRMS that DRFP and other features ARE valuable\n",
    "\n",
    "**Key Question:** What approaches haven't we tried that could change the CV-LB relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7685a03d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.696905Z",
     "iopub.status.busy": "2026-01-15T00:03:42.696128Z",
     "iopub.status.idle": "2026-01-15T00:03:42.705539Z",
     "shell.execute_reply": "2026-01-15T00:03:42.704842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All submissions:\n",
      "    exp     cv     lb\n",
      "exp_000 0.0111 0.0982\n",
      "exp_001 0.0123 0.1065\n",
      "exp_003 0.0105 0.0972\n",
      "exp_005 0.0104 0.0969\n",
      "exp_006 0.0097 0.0946\n",
      "exp_007 0.0093 0.0932\n",
      "exp_009 0.0092 0.0936\n",
      "exp_012 0.0090 0.0913\n",
      "exp_024 0.0087 0.0893\n",
      "exp_026 0.0085 0.0887\n",
      "exp_030 0.0083 0.0877\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('All submissions:')\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5641082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.707537Z",
     "iopub.status.busy": "2026-01-15T00:03:42.707327Z",
     "iopub.status.idle": "2026-01-15T00:03:42.718230Z",
     "shell.execute_reply": "2026-01-15T00:03:42.717627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV-LB Linear Fit ===\n",
      "LB = 4.30 * CV + 0.0524\n",
      "R² = 0.9675\n",
      "Slope: 4.30\n",
      "Intercept: 0.0524\n",
      "\n",
      "=== Target Analysis ===\n",
      "Target LB: 0.0347\n",
      "Required CV to reach target: -0.0041\n",
      "\n",
      "⚠️ With current CV-LB relationship, target appears unreachable!\n",
      "Intercept (0.0524) > Target (0.0347)\n",
      "Even with CV=0, predicted LB would be 0.0524\n",
      "\n",
      "BUT: The target IS reachable - we need to CHANGE the relationship!\n"
     ]
    }
   ],
   "source": [
    "# Linear regression on CV-LB relationship\n",
    "cv_vals = df['cv'].values\n",
    "lb_vals = df['lb'].values\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_vals, lb_vals)\n",
    "\n",
    "print(f'\\n=== CV-LB Linear Fit ===')\n",
    "print(f'LB = {slope:.2f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'Slope: {slope:.2f}')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "target = 0.0347\n",
    "required_cv = (target - intercept) / slope\n",
    "print(f'\\n=== Target Analysis ===')\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV to reach target: {required_cv:.4f}')\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(f'\\n⚠️ With current CV-LB relationship, target appears unreachable!')\n",
    "    print(f'Intercept ({intercept:.4f}) > Target ({target})')\n",
    "    print(f'Even with CV=0, predicted LB would be {intercept:.4f}')\n",
    "    print(f'\\nBUT: The target IS reachable - we need to CHANGE the relationship!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd23d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.720173Z",
     "iopub.status.busy": "2026-01-15T00:03:42.719988Z",
     "iopub.status.idle": "2026-01-15T00:03:42.727085Z",
     "shell.execute_reply": "2026-01-15T00:03:42.726511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY OF ALL APPROACHES TRIED ===\n",
      "\n",
      "MLP architectures:\n",
      "  exp_000: CV 0.0111 (LB 0.0982) - baseline [128,128,64]\n",
      "  exp_004: CV 0.0519 (not submitted) - deep residual - FAILED\n",
      "  exp_006: CV 0.0097 (LB 0.0946) - simpler [64,32]\n",
      "  exp_007: CV 0.0093 (LB 0.0932) - even simpler [32,16]\n",
      "\n",
      "Feature engineering:\n",
      "  exp_002: CV 0.0169 (not submitted) - DRFP with PCA - WORSE\n",
      "  exp_003: CV 0.0105 (LB 0.0972) - Spange+DRFP combined\n",
      "  exp_027: CV 0.0091 (not submitted) - simple features (23) - WORSE\n",
      "  exp_038: CV 0.0098 (not submitted) - minimal features (8) - WORSE\n",
      "\n",
      "Ensemble methods:\n",
      "  exp_005: CV 0.0104 (LB 0.0969) - 15 models\n",
      "  exp_011: CV 0.0090 (not submitted) - diverse ensemble\n",
      "  exp_012: CV 0.0090 (LB 0.0913) - simple ensemble\n",
      "  exp_028: CV 0.0087 (not submitted) - 4-model ensemble - WORSE\n",
      "\n",
      "GP models:\n",
      "  exp_030: CV 0.0083 (LB 0.0877) - GP+MLP+LGBM (0.15/0.55/0.3)\n",
      "  exp_031: CV 0.0082 (not submitted) - higher GP weight\n",
      "  exp_032: CV 0.0394 (not submitted) - pure GP - WORSE\n",
      "  exp_035: CV 0.0082 (not submitted) - lower GP weight\n",
      "\n",
      "Regularization:\n",
      "  exp_033: CV 0.0225 (not submitted) - Ridge regression - WORSE\n",
      "  exp_034: CV 0.0172 (not submitted) - Kernel Ridge - WORSE\n",
      "\n",
      "Distribution shift:\n",
      "  exp_037: CV 0.0263 (not submitted) - similarity weighting - FAILED\n"
     ]
    }
   ],
   "source": [
    "# Summary of all approaches tried\n",
    "print('\\n=== SUMMARY OF ALL APPROACHES TRIED ===')\n",
    "approaches = {\n",
    "    'MLP architectures': [\n",
    "        ('exp_000', 'baseline [128,128,64]', 0.0111, 0.0982),\n",
    "        ('exp_004', 'deep residual - FAILED', 0.0519, 'N/A'),\n",
    "        ('exp_006', 'simpler [64,32]', 0.0097, 0.0946),\n",
    "        ('exp_007', 'even simpler [32,16]', 0.0093, 0.0932),\n",
    "    ],\n",
    "    'Feature engineering': [\n",
    "        ('exp_002', 'DRFP with PCA - WORSE', 0.0169, 'N/A'),\n",
    "        ('exp_003', 'Spange+DRFP combined', 0.0105, 0.0972),\n",
    "        ('exp_027', 'simple features (23) - WORSE', 0.0091, 'N/A'),\n",
    "        ('exp_038', 'minimal features (8) - WORSE', 0.0098, 'N/A'),\n",
    "    ],\n",
    "    'Ensemble methods': [\n",
    "        ('exp_005', '15 models', 0.0104, 0.0969),\n",
    "        ('exp_011', 'diverse ensemble', 0.0090, 'N/A'),\n",
    "        ('exp_012', 'simple ensemble', 0.0090, 0.0913),\n",
    "        ('exp_028', '4-model ensemble - WORSE', 0.0087, 'N/A'),\n",
    "    ],\n",
    "    'GP models': [\n",
    "        ('exp_030', 'GP+MLP+LGBM (0.15/0.55/0.3)', 0.0083, 0.0877),\n",
    "        ('exp_031', 'higher GP weight', 0.0082, 'N/A'),\n",
    "        ('exp_032', 'pure GP - WORSE', 0.0394, 'N/A'),\n",
    "        ('exp_035', 'lower GP weight', 0.0082, 'N/A'),\n",
    "    ],\n",
    "    'Regularization': [\n",
    "        ('exp_033', 'Ridge regression - WORSE', 0.0225, 'N/A'),\n",
    "        ('exp_034', 'Kernel Ridge - WORSE', 0.0172, 'N/A'),\n",
    "    ],\n",
    "    'Distribution shift': [\n",
    "        ('exp_037', 'similarity weighting - FAILED', 0.0263, 'N/A'),\n",
    "    ],\n",
    "}\n",
    "\n",
    "for category, exps in approaches.items():\n",
    "    print(f'\\n{category}:')\n",
    "    for exp, desc, cv, lb in exps:\n",
    "        lb_str = f'LB {lb}' if lb != 'N/A' else 'not submitted'\n",
    "        print(f'  {exp}: CV {cv:.4f} ({lb_str}) - {desc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176f2bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.728602Z",
     "iopub.status.busy": "2026-01-15T00:03:42.728435Z",
     "iopub.status.idle": "2026-01-15T00:03:42.735497Z",
     "shell.execute_reply": "2026-01-15T00:03:42.734969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== APPROACHES NOT YET TRIED ===\n",
      "\n",
      "1. **Different CV scheme** (GroupKFold instead of Leave-One-Out)\n",
      "   - The \"mixall\" kernel uses GroupKFold(5) and claims \"good CV/LB\"\n",
      "   - BUT: Competition rules require the template's CV scheme\n",
      "   - VERDICT: Cannot change CV scheme\n",
      "\n",
      "2. **Per-target optimization**\n",
      "   - Train separate models for SM, Product 2, Product 3\n",
      "   - Each target might have different optimal features/hyperparameters\n",
      "   - VERDICT: Worth trying\n",
      "\n",
      "3. **Prediction post-processing**\n",
      "   - Clip predictions to [0, 1]\n",
      "   - Normalize so SM + Product 2 + Product 3 = 1?\n",
      "   - VERDICT: Already clipping, but normalization might help\n",
      "\n",
      "4. **Different base models**\n",
      "   - CatBoost (handles categorical features natively)\n",
      "   - TabNet (attention-based tabular model)\n",
      "   - VERDICT: Worth trying\n",
      "\n",
      "5. **Feature interactions**\n",
      "   - Polynomial features\n",
      "   - Interaction terms between kinetics and solvent properties\n",
      "   - VERDICT: Worth trying\n",
      "\n",
      "6. **Uncertainty-aware predictions**\n",
      "   - Use GP uncertainty to weight predictions\n",
      "   - Bayesian Neural Network\n",
      "   - VERDICT: Partially tried with GP, could explore more\n",
      "\n",
      "7. **Data augmentation beyond TTA**\n",
      "   - Add noise to training data\n",
      "   - Mixup augmentation\n",
      "   - VERDICT: Worth trying\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What approaches HAVEN'T we tried?\n",
    "print('\\n=== APPROACHES NOT YET TRIED ===')\n",
    "print('''\n",
    "1. **Different CV scheme** (GroupKFold instead of Leave-One-Out)\n",
    "   - The \"mixall\" kernel uses GroupKFold(5) and claims \"good CV/LB\"\n",
    "   - BUT: Competition rules require the template's CV scheme\n",
    "   - VERDICT: Cannot change CV scheme\n",
    "\n",
    "2. **Per-target optimization**\n",
    "   - Train separate models for SM, Product 2, Product 3\n",
    "   - Each target might have different optimal features/hyperparameters\n",
    "   - VERDICT: Worth trying\n",
    "\n",
    "3. **Prediction post-processing**\n",
    "   - Clip predictions to [0, 1]\n",
    "   - Normalize so SM + Product 2 + Product 3 = 1?\n",
    "   - VERDICT: Already clipping, but normalization might help\n",
    "\n",
    "4. **Different base models**\n",
    "   - CatBoost (handles categorical features natively)\n",
    "   - TabNet (attention-based tabular model)\n",
    "   - VERDICT: Worth trying\n",
    "\n",
    "5. **Feature interactions**\n",
    "   - Polynomial features\n",
    "   - Interaction terms between kinetics and solvent properties\n",
    "   - VERDICT: Worth trying\n",
    "\n",
    "6. **Uncertainty-aware predictions**\n",
    "   - Use GP uncertainty to weight predictions\n",
    "   - Bayesian Neural Network\n",
    "   - VERDICT: Partially tried with GP, could explore more\n",
    "\n",
    "7. **Data augmentation beyond TTA**\n",
    "   - Add noise to training data\n",
    "   - Mixup augmentation\n",
    "   - VERDICT: Worth trying\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcd504a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.736932Z",
     "iopub.status.busy": "2026-01-15T00:03:42.736759Z",
     "iopub.status.idle": "2026-01-15T00:03:42.743582Z",
     "shell.execute_reply": "2026-01-15T00:03:42.743109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KEY INSIGHT: CV-LB RELATIONSHIP ===\n",
      "\n",
      "Current relationship: LB = 4.30 * CV + 0.0524\n",
      "\n",
      "This means:\n",
      "- For every 0.001 improvement in CV, LB improves by 0.0043\n",
      "- The intercept (0.0524) represents the \"base\" LB error\n",
      "- To reach target (0.0347), we need to reduce the intercept\n",
      "\n",
      "What could reduce the intercept?\n",
      "1. Better generalization to unseen solvents\n",
      "2. More robust features that don't overfit\n",
      "3. Different model family with different bias-variance tradeoff\n",
      "\n",
      "What we've learned:\n",
      "- Simpler features (8 vs 145) made CV WORSE, not better\n",
      "- Simpler models (Ridge, Kernel Ridge) made CV WORSE\n",
      "- GP helps slightly but doesn't change the relationship\n",
      "- Similarity weighting failed due to implementation bug\n",
      "\n",
      "Conclusion:\n",
      "The CV-LB gap is NOT due to overfitting to features or model complexity.\n",
      "It's likely due to fundamental differences in how the competition evaluates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The CV-LB relationship\n",
    "print('\\n=== KEY INSIGHT: CV-LB RELATIONSHIP ===')\n",
    "print(f'''\n",
    "Current relationship: LB = {slope:.2f} * CV + {intercept:.4f}\n",
    "\n",
    "This means:\n",
    "- For every 0.001 improvement in CV, LB improves by {slope * 0.001:.4f}\n",
    "- The intercept ({intercept:.4f}) represents the \"base\" LB error\n",
    "- To reach target ({target}), we need to reduce the intercept\n",
    "\n",
    "What could reduce the intercept?\n",
    "1. Better generalization to unseen solvents\n",
    "2. More robust features that don't overfit\n",
    "3. Different model family with different bias-variance tradeoff\n",
    "\n",
    "What we've learned:\n",
    "- Simpler features (8 vs 145) made CV WORSE, not better\n",
    "- Simpler models (Ridge, Kernel Ridge) made CV WORSE\n",
    "- GP helps slightly but doesn't change the relationship\n",
    "- Similarity weighting failed due to implementation bug\n",
    "\n",
    "Conclusion:\n",
    "The CV-LB gap is NOT due to overfitting to features or model complexity.\n",
    "It's likely due to fundamental differences in how the competition evaluates.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c082e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.745242Z",
     "iopub.status.busy": "2026-01-15T00:03:42.745070Z",
     "iopub.status.idle": "2026-01-15T00:03:42.751411Z",
     "shell.execute_reply": "2026-01-15T00:03:42.750862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HYPOTHESIS: COMPETITION EVALUATION DIFFERENCES ===\n",
      "\n",
      "Possible differences between our local CV and competition LB:\n",
      "\n",
      "1. **Metric calculation**\n",
      "   - We use MSE, competition might use different metric?\n",
      "   - Check: Competition says MSE, so this is unlikely\n",
      "\n",
      "2. **Fold construction**\n",
      "   - We use Leave-One-Solvent-Out for single solvent\n",
      "   - We use Leave-One-Ramp-Out for full data\n",
      "   - Competition might use different folds?\n",
      "   - Check: Template shows same CV scheme\n",
      "\n",
      "3. **Data weighting**\n",
      "   - We weight single solvent and full data equally by sample count\n",
      "   - Competition might weight differently?\n",
      "   - Check: Need to verify\n",
      "\n",
      "4. **Prediction bounds**\n",
      "   - We clip to [0, 1]\n",
      "   - Competition might not clip, or might normalize?\n",
      "   - Check: Need to verify\n",
      "\n",
      "5. **Random seed effects**\n",
      "   - Our models have some randomness\n",
      "   - Competition might use different random state?\n",
      "   - Check: Unlikely to cause 2.5x gap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What's different about the competition evaluation?\n",
    "print('\\n=== HYPOTHESIS: COMPETITION EVALUATION DIFFERENCES ===')\n",
    "print('''\n",
    "Possible differences between our local CV and competition LB:\n",
    "\n",
    "1. **Metric calculation**\n",
    "   - We use MSE, competition might use different metric?\n",
    "   - Check: Competition says MSE, so this is unlikely\n",
    "\n",
    "2. **Fold construction**\n",
    "   - We use Leave-One-Solvent-Out for single solvent\n",
    "   - We use Leave-One-Ramp-Out for full data\n",
    "   - Competition might use different folds?\n",
    "   - Check: Template shows same CV scheme\n",
    "\n",
    "3. **Data weighting**\n",
    "   - We weight single solvent and full data equally by sample count\n",
    "   - Competition might weight differently?\n",
    "   - Check: Need to verify\n",
    "\n",
    "4. **Prediction bounds**\n",
    "   - We clip to [0, 1]\n",
    "   - Competition might not clip, or might normalize?\n",
    "   - Check: Need to verify\n",
    "\n",
    "5. **Random seed effects**\n",
    "   - Our models have some randomness\n",
    "   - Competition might use different random state?\n",
    "   - Check: Unlikely to cause 2.5x gap\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8de76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.752904Z",
     "iopub.status.busy": "2026-01-15T00:03:42.752745Z",
     "iopub.status.idle": "2026-01-15T00:03:42.758779Z",
     "shell.execute_reply": "2026-01-15T00:03:42.758277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RECOMMENDATION FOR LOOP 36\n",
      "======================================================================\n",
      "\n",
      "**SITUATION:**\n",
      "- 5 submissions remaining\n",
      "- Best LB: 0.0877 (exp_030)\n",
      "- Target: 0.0347 (2.53x gap)\n",
      "- CV-LB relationship: LB = 4.30*CV + 0.0524\n",
      "\n",
      "**WHAT WE'VE LEARNED:**\n",
      "1. Minimal features (8 vs 145) made CV 19.91% WORSE\n",
      "   → DRFP and other features ARE valuable\n",
      "2. All attempts to change CV-LB relationship have failed\n",
      "3. The gap is structural, not due to overfitting\n",
      "\n",
      "**PRIORITY 1: Per-Target Optimization**\n",
      "- Train separate models for SM, Product 2, Product 3\n",
      "- Each target might have different optimal features/hyperparameters\n",
      "- This is a fundamentally different approach we haven't tried\n",
      "\n",
      "**PRIORITY 2: CatBoost with Native Categorical Handling**\n",
      "- CatBoost handles categorical features (solvent names) natively\n",
      "- Might capture solvent-specific patterns better\n",
      "- Could have different CV-LB relationship\n",
      "\n",
      "**PRIORITY 3: Prediction Normalization**\n",
      "- Normalize predictions so SM + Product 2 + Product 3 = 1\n",
      "- Some kernels do this (mr0106/catechol)\n",
      "- Might improve LB even if CV stays same\n",
      "\n",
      "**DO NOT TRY:**\n",
      "- More feature simplification (proven to hurt)\n",
      "- More regularization (proven to hurt)\n",
      "- Similarity weighting (implementation too complex)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final recommendation\n",
    "print('\\n' + '='*70)\n",
    "print('FINAL RECOMMENDATION FOR LOOP 36')\n",
    "print('='*70)\n",
    "print(f'''\n",
    "**SITUATION:**\n",
    "- 5 submissions remaining\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347 (2.53x gap)\n",
    "- CV-LB relationship: LB = {slope:.2f}*CV + {intercept:.4f}\n",
    "\n",
    "**WHAT WE'VE LEARNED:**\n",
    "1. Minimal features (8 vs 145) made CV 19.91% WORSE\n",
    "   → DRFP and other features ARE valuable\n",
    "2. All attempts to change CV-LB relationship have failed\n",
    "3. The gap is structural, not due to overfitting\n",
    "\n",
    "**PRIORITY 1: Per-Target Optimization**\n",
    "- Train separate models for SM, Product 2, Product 3\n",
    "- Each target might have different optimal features/hyperparameters\n",
    "- This is a fundamentally different approach we haven't tried\n",
    "\n",
    "**PRIORITY 2: CatBoost with Native Categorical Handling**\n",
    "- CatBoost handles categorical features (solvent names) natively\n",
    "- Might capture solvent-specific patterns better\n",
    "- Could have different CV-LB relationship\n",
    "\n",
    "**PRIORITY 3: Prediction Normalization**\n",
    "- Normalize predictions so SM + Product 2 + Product 3 = 1\n",
    "- Some kernels do this (mr0106/catechol)\n",
    "- Might improve LB even if CV stays same\n",
    "\n",
    "**DO NOT TRY:**\n",
    "- More feature simplification (proven to hurt)\n",
    "- More regularization (proven to hurt)\n",
    "- Similarity weighting (implementation too complex)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d392946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:03:42.760337Z",
     "iopub.status.busy": "2026-01-15T00:03:42.760173Z",
     "iopub.status.idle": "2026-01-15T00:03:42.785486Z",
     "shell.execute_reply": "2026-01-15T00:03:42.784897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHECKING IF NORMALIZATION MAKES SENSE ===\n",
      "Single Solvent target sums:\n",
      "  Mean: 0.7955\n",
      "  Std: 0.1943\n",
      "  Min: 0.0288\n",
      "  Max: 1.0000\n",
      "\n",
      "Full Data target sums:\n",
      "  Mean: 0.8035\n",
      "  Std: 0.2092\n",
      "  Min: 0.0112\n",
      "  Max: 1.1233\n",
      "\n",
      "Conclusion: Targets do NOT sum to 1.0, so normalization is NOT appropriate.\n"
     ]
    }
   ],
   "source": [
    "# Check if normalization makes sense\n",
    "print('\\n=== CHECKING IF NORMALIZATION MAKES SENSE ===')\n",
    "\n",
    "# Load actual data\n",
    "DATA_PATH = '/home/data'\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "# Check if targets sum to 1\n",
    "df_single['sum'] = df_single['SM'] + df_single['Product 2'] + df_single['Product 3']\n",
    "df_full['sum'] = df_full['SM'] + df_full['Product 2'] + df_full['Product 3']\n",
    "\n",
    "print(f'Single Solvent target sums:')\n",
    "print(f'  Mean: {df_single[\"sum\"].mean():.4f}')\n",
    "print(f'  Std: {df_single[\"sum\"].std():.4f}')\n",
    "print(f'  Min: {df_single[\"sum\"].min():.4f}')\n",
    "print(f'  Max: {df_single[\"sum\"].max():.4f}')\n",
    "\n",
    "print(f'\\nFull Data target sums:')\n",
    "print(f'  Mean: {df_full[\"sum\"].mean():.4f}')\n",
    "print(f'  Std: {df_full[\"sum\"].std():.4f}')\n",
    "print(f'  Min: {df_full[\"sum\"].min():.4f}')\n",
    "print(f'  Max: {df_full[\"sum\"].max():.4f}')\n",
    "\n",
    "print(f'\\nConclusion: Targets do NOT sum to 1.0, so normalization is NOT appropriate.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
