{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b46a12",
   "metadata": {},
   "source": [
    "# Loop 28 Analysis: Understanding the CV-LB Gap\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.01727\n",
    "- CV-LB ratio: ~10.5x\n",
    "- Linear fit: LB = 4.22*CV + 0.0533 (R²=0.96)\n",
    "\n",
    "**Critical Insight:**\n",
    "The intercept (0.0533) is 3x higher than target (0.01727). This means even with CV=0, predicted LB would be 0.0533.\n",
    "\n",
    "**Latest Experiment (exp_027):**\n",
    "- Tested simpler features (23 vs 145) - FAILED\n",
    "- CV 0.009150 (8.09% worse than exp_026)\n",
    "- DRFP features ARE valuable\n",
    "\n",
    "**Key Question:**\n",
    "What can we do to REDUCE the CV-LB gap, not just improve CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d70ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All 10 submissions with CV and LB scores\n",
    "submissions = [\n",
    "    {'id': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'id': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'id': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'id': 'exp_005', 'cv': 0.01043, 'lb': 0.09691},\n",
    "    {'id': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'id': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'id': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'id': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'id': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'id': 'exp_026', 'cv': 0.008465, 'lb': 0.08875},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('All submissions:')\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Linear fit\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'\\nLinear fit: LB = {slope:.4f} * CV + {intercept:.5f}')\n",
    "print(f'R² = {r_value**2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efa218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the residuals - which experiments deviate from the linear fit?\n",
    "print('=== Residual Analysis ===')\n",
    "predicted_lb = slope * cv + intercept\n",
    "residuals = lb - predicted_lb\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(f'{row[\"id\"]}: Residual = {residuals[i]:.5f} ({\"better\" if residuals[i] < 0 else \"worse\"} than predicted)')\n",
    "\n",
    "print(f'\\nBest residual: {df.iloc[residuals.argmin()][\"id\"]} ({residuals.min():.5f})')\n",
    "print(f'Worst residual: {df.iloc[residuals.argmax()][\"id\"]} ({residuals.max():.5f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's special about experiments with negative residuals (better than predicted)?\n",
    "print('=== Experiments with Negative Residuals (Better Generalization) ===')\n",
    "for i, row in df.iterrows():\n",
    "    if residuals[i] < 0:\n",
    "        print(f'{row[\"id\"]}: CV={row[\"cv\"]:.6f}, LB={row[\"lb\"]:.5f}, Residual={residuals[i]:.5f}')\n",
    "\n",
    "print('\\n=== Experiments with Positive Residuals (Worse Generalization) ===')\n",
    "for i, row in df.iterrows():\n",
    "    if residuals[i] > 0:\n",
    "        print(f'{row[\"id\"]}: CV={row[\"cv\"]:.6f}, LB={row[\"lb\"]:.5f}, Residual={residuals[i]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f18e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches were used in experiments with better generalization?\n",
    "print('=== Approach Analysis ===')\n",
    "approaches = {\n",
    "    'exp_000': 'MLP [128,128,64], Spange only, HuberLoss, 3 models',\n",
    "    'exp_001': 'LightGBM, Spange only',\n",
    "    'exp_003': 'MLP [256,128,64], Spange+DRFP, HuberLoss, 5 models',\n",
    "    'exp_005': 'MLP [256,128,64], Spange+DRFP, HuberLoss, 15 models',\n",
    "    'exp_006': 'MLP [64,32], Spange+DRFP, HuberLoss, 5 models',\n",
    "    'exp_007': 'MLP [32,16], Spange+DRFP, HuberLoss, 5 models',\n",
    "    'exp_009': 'Ridge Regression, Spange+DRFP',\n",
    "    'exp_012': 'MLP [32,16] + LightGBM ensemble, Spange+DRFP',\n",
    "    'exp_024': 'MLP [32,16] + LightGBM, Spange+DRFP+ACS_PCA',\n",
    "    'exp_026': 'MLP [32,16] + LightGBM, Spange+DRFP+ACS_PCA, Weighted Loss [1,1,2]',\n",
    "}\n",
    "\n",
    "print('\\nBetter generalization (negative residuals):')\n",
    "for i, row in df.iterrows():\n",
    "    if residuals[i] < 0:\n",
    "        print(f'  {row[\"id\"]}: {approaches[row[\"id\"]]}')\n",
    "\n",
    "print('\\nWorse generalization (positive residuals):')\n",
    "for i, row in df.iterrows():\n",
    "    if residuals[i] > 0:\n",
    "        print(f'  {row[\"id\"]}: {approaches[row[\"id\"]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ad347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What's the pattern?\n",
    "print('=== Pattern Analysis ===')\n",
    "print('\\nObservations:')\n",
    "print('1. exp_000 (Spange only, simpler) has negative residual')\n",
    "print('2. exp_003, exp_005 (larger models) have negative residuals')\n",
    "print('3. exp_009 (Ridge Regression) has positive residual')\n",
    "print('4. exp_007 (simpler MLP) has positive residual')\n",
    "print('5. exp_024, exp_026 (best CV) have negative residuals')\n",
    "\n",
    "print('\\nConclusion:')\n",
    "print('- No clear pattern between model complexity and generalization')\n",
    "print('- The residuals are small (RMSE ~0.001) - the linear fit is very tight')\n",
    "print('- The CV-LB gap is STRUCTURAL, not due to specific model choices')\n",
    "print('- The gap is likely due to evaluation procedure differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if the evaluation uses a different CV scheme?\n",
    "print('=== Hypothesis: Different CV Scheme ===')\n",
    "print('\\nOur CV scheme:')\n",
    "print('- Single solvents: Leave-one-solvent-out (24 folds)')\n",
    "print('- Mixtures: Leave-one-ramp-out (13 folds)')\n",
    "print('- Total: 37 folds')\n",
    "\n",
    "print('\\nPossible LB CV scheme:')\n",
    "print('- GroupKFold (5 folds) as seen in \"mixall\" kernel')\n",
    "print('- Different random seed')\n",
    "print('- Different data ordering')\n",
    "\n",
    "print('\\nKey insight from \"mixall\" kernel:')\n",
    "print('- Uses GroupKFold(n_splits=5) instead of Leave-One-Out')\n",
    "print('- This is a DIFFERENT CV scheme!')\n",
    "print('- Our local CV may not match the LB evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches remain unexplored?\n",
    "print('=== UNEXPLORED Approaches ===')\n",
    "unexplored = [\n",
    "    ('XGBoost/CatBoost ensemble', 'Different tree algorithms may generalize differently'),\n",
    "    ('Stacking meta-learner', 'Train a meta-model on base predictions'),\n",
    "    ('Higher SM weights [1,1,3] or [1,1,4]', 'SM is still the bottleneck'),\n",
    "    ('Learned loss weights (homoscedastic)', 'Kendall et al. uncertainty weighting'),\n",
    "    ('Consistency constraint (SM+P2+P3≈1)', 'Physical constraint for regularization'),\n",
    "    ('Different CV scheme (GroupKFold)', 'May match LB evaluation better'),\n",
    "    ('Adversarial validation', 'Identify features causing distribution shift'),\n",
    "    ('Domain adaptation techniques', 'Handle distribution shift explicitly'),\n",
    "]\n",
    "\n",
    "for approach, rationale in unexplored:\n",
    "    print(f'\\n{approach}:')\n",
    "    print(f'  Rationale: {rationale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268131c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority ranking based on potential impact\n",
    "print('=== Priority Ranking ===')\n",
    "print('\\n1. HIGHEST PRIORITY: XGBoost/CatBoost Ensemble')\n",
    "print('   - We only have MLP + LightGBM')\n",
    "print('   - XGBoost and CatBoost are different algorithms')\n",
    "print('   - May capture different patterns')\n",
    "print('   - Easy to implement')\n",
    "\n",
    "print('\\n2. HIGH PRIORITY: Higher SM Weights [1,1,3]')\n",
    "print('   - SM is still the hardest target')\n",
    "print('   - Weighted loss [1,1,2] improved all targets')\n",
    "print('   - More aggressive weighting may help further')\n",
    "\n",
    "print('\\n3. MEDIUM PRIORITY: Stacking Meta-Learner')\n",
    "print('   - Train a simple model on base predictions')\n",
    "print('   - Can learn optimal combination weights')\n",
    "print('   - May improve generalization')\n",
    "\n",
    "print('\\n4. LOWER PRIORITY: Consistency Constraint')\n",
    "print('   - SM + P2 + P3 ≈ 1 (mass balance)')\n",
    "print('   - Physical constraint for regularization')\n",
    "print('   - May improve predictions near boundaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('=== FINAL RECOMMENDATION ===')\n",
    "print('\\nGiven:')\n",
    "print('- 3 submissions remaining')\n",
    "print('- CV-LB gap is ~10x (structural, not model-specific)')\n",
    "print('- Target 0.01727 is 5x better than best LB 0.0887')\n",
    "\n",
    "print('\\nStrategy:')\n",
    "print('1. Try XGBoost/CatBoost ensemble (new model diversity)')\n",
    "print('2. Try higher SM weights [1,1,3] (target the bottleneck)')\n",
    "print('3. Try stacking meta-learner (optimal combination)')\n",
    "\n",
    "print('\\nKey insight:')\n",
    "print('The CV-LB gap is the fundamental problem.')\n",
    "print('We need approaches that GENERALIZE better, not just improve CV.')\n",
    "print('New model types (XGBoost, CatBoost) may have different generalization properties.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
