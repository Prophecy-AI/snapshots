{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354b4ebc",
   "metadata": {},
   "source": [
    "# Loop 38 Analysis: Learned Embeddings Failure & Path Forward\n",
    "\n",
    "**Key Question**: Why did learned embeddings fail, and what approach CAN work for leave-one-solvent-out CV?\n",
    "\n",
    "## The Fundamental Problem\n",
    "\n",
    "In leave-one-solvent-out CV:\n",
    "- The test solvent is NEVER seen during training\n",
    "- Learned embeddings for unseen solvents are just random initialization\n",
    "- This is why exp_037 got MSE 0.080438 (9.8x worse than baseline)\n",
    "\n",
    "## Why GNN Would Work (But Learned Embeddings Don't)\n",
    "\n",
    "1. **GNN**: Learns from molecular STRUCTURE (atoms, bonds, graph topology)\n",
    "   - Even for unseen solvents, the GNN can process the molecular graph\n",
    "   - The model learns general patterns about how molecular structure affects yield\n",
    "\n",
    "2. **Learned Embeddings**: Learns from solvent IDENTITY\n",
    "   - For unseen solvents, there's no identity to look up\n",
    "   - The embedding is just random initialization\n",
    "\n",
    "## The Real Question\n",
    "\n",
    "Can we implement a GNN that generalizes to unseen solvents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data to understand the problem\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "# Check SMILES availability\n",
    "smiles_df = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv')\n",
    "print('SMILES lookup:')\n",
    "print(smiles_df.head())\n",
    "print(f'\\nTotal solvents with SMILES: {len(smiles_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what solvents are in the data\n",
    "X_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "X_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('Single solvent data solvents:')\n",
    "print(sorted(X_single['SOLVENT NAME'].unique()))\n",
    "print(f'\\nTotal: {len(X_single[\"SOLVENT NAME\"].unique())}')\n",
    "\n",
    "print('\\nFull data solvents A:')\n",
    "print(sorted(X_full['SOLVENT A NAME'].unique()))\n",
    "print(f'\\nTotal A: {len(X_full[\"SOLVENT A NAME\"].unique())}')\n",
    "\n",
    "print('\\nFull data solvents B:')\n",
    "print(sorted(X_full['SOLVENT B NAME'].unique()))\n",
    "print(f'\\nTotal B: {len(X_full[\"SOLVENT B NAME\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aca3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the CV-LB relationship\n",
    "submissions = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "    ('exp_005', 0.0104, 0.0969),\n",
    "    ('exp_006', 0.0097, 0.0946),\n",
    "    ('exp_007', 0.0093, 0.0932),\n",
    "    ('exp_009', 0.0092, 0.0936),\n",
    "    ('exp_012', 0.0090, 0.0913),\n",
    "    ('exp_024', 0.0087, 0.0893),\n",
    "    ('exp_026', 0.0085, 0.0887),\n",
    "    ('exp_030', 0.0083, 0.0877),\n",
    "    ('exp_035', 0.0098, 0.0970),\n",
    "]\n",
    "\n",
    "cv_scores = np.array([s[1] for s in submissions])\n",
    "lb_scores = np.array([s[2] for s in submissions])\n",
    "\n",
    "# Linear fit\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "\n",
    "print(f'CV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'\\nIntercept > Target: {intercept > 0.0347}')\n",
    "print(f'\\nTo reach target with current relationship:')\n",
    "required_cv = (0.0347 - intercept) / slope\n",
    "print(f'Required CV: {required_cv:.6f}')\n",
    "if required_cv < 0:\n",
    "    print('IMPOSSIBLE - would require negative CV!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc515d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The CV-LB relationship has a large positive intercept\n",
    "# This means even CV=0 would give LB=0.0527 > target 0.0347\n",
    "# \n",
    "# This suggests a SYSTEMATIC BIAS in our approach that cannot be fixed by improving CV\n",
    "#\n",
    "# What could cause this?\n",
    "# 1. Our features don't capture something important about the test solvents\n",
    "# 2. The LB evaluation uses a different distribution than our local CV\n",
    "# 3. Our models systematically overfit to training solvents\n",
    "\n",
    "print('=== ANALYSIS OF THE CV-LB GAP ===')\n",
    "print(f'\\nBest CV: 0.0083 (exp_030)')\n",
    "print(f'Best LB: 0.0877 (exp_030)')\n",
    "print(f'Gap: {0.0877 / 0.0083:.1f}x')\n",
    "print(f'\\nTarget: 0.0347')\n",
    "print(f'Gap to target: {0.0877 / 0.0347:.1f}x')\n",
    "print(f'\\nGNN benchmark: 0.0039')\n",
    "print(f'Gap GNN to target: {0.0347 / 0.0039:.1f}x (target is 8.9x WORSE than GNN)')\n",
    "print(f'\\nThis proves the target is VERY achievable!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the difference between our approach and GNN?\n",
    "#\n",
    "# Our approach:\n",
    "# - Fixed features (Spange, DRFP, ACS PCA)\n",
    "# - Linear mixture interpolation\n",
    "# - MLP/LGBM/GP ensemble\n",
    "#\n",
    "# GNN approach:\n",
    "# - Learned features from molecular structure\n",
    "# - Non-linear mixture handling\n",
    "# - Graph attention for message passing\n",
    "#\n",
    "# The key difference: GNN learns GENERAL patterns about molecular structure\n",
    "# that can transfer to unseen solvents. Our fixed features cannot.\n",
    "\n",
    "print('=== KEY INSIGHT ===')\n",
    "print('''\\nThe learned embeddings approach failed because it learns IDENTITY, not STRUCTURE.\n",
    "\n",
    "For leave-one-solvent-out CV:\n",
    "- Learned embeddings: Test solvent has random embedding (FAILS)\n",
    "- GNN: Test solvent has meaningful embedding from molecular structure (WORKS)\n",
    "\n",
    "The GNN can generalize because it learns:\n",
    "1. How atom types affect yield\n",
    "2. How bond types affect yield\n",
    "3. How molecular topology affects yield\n",
    "\n",
    "These patterns transfer to unseen solvents because the atoms and bonds\n",
    "are the SAME - just arranged differently.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1656e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we implement a simpler version that captures some of this?\n",
    "#\n",
    "# Option 1: Full GNN with AttentiveFP\n",
    "# - Complex but proven to work\n",
    "# - Requires SMILES -> molecular graph conversion\n",
    "# - PyTorch Geometric is available\n",
    "#\n",
    "# Option 2: Solvent similarity-based prediction\n",
    "# - For each test solvent, find k most similar training solvents\n",
    "# - Weight predictions by similarity\n",
    "# - Uses Spange/DRFP similarity (which captures molecular structure)\n",
    "#\n",
    "# Option 3: Pre-computed molecular fingerprints as features\n",
    "# - Instead of learned embeddings, use ECFP/Morgan fingerprints\n",
    "# - These capture molecular structure and transfer to unseen solvents\n",
    "\n",
    "print('=== VIABLE APPROACHES FOR UNSEEN SOLVENTS ===')\n",
    "print('''\\n1. GNN (AttentiveFP)\n",
    "   - Learns from molecular structure\n",
    "   - Can generalize to unseen solvents\n",
    "   - Complex to implement\n",
    "\n",
    "2. k-NN with Spange/DRFP similarity\n",
    "   - For test solvent, find k most similar training solvents\n",
    "   - Weight predictions by similarity\n",
    "   - Simple to implement\n",
    "   - May not change CV-LB relationship\n",
    "\n",
    "3. Morgan fingerprints (ECFP)\n",
    "   - Pre-computed molecular fingerprints\n",
    "   - Capture molecular structure\n",
    "   - Can transfer to unseen solvents\n",
    "   - Already have DRFP which is similar\n",
    "\n",
    "4. Hybrid: Fixed features + GNN embedding\n",
    "   - Use GNN to get solvent embedding\n",
    "   - Combine with kinetics features\n",
    "   - Best of both worlds''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if we have the tools for GNN\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "\n",
    "try:\n",
    "    import torch_geometric\n",
    "    print(f'PyTorch Geometric version: {torch_geometric.__version__}')\n",
    "    from torch_geometric.nn import AttentiveFP\n",
    "    print('AttentiveFP available: YES')\n",
    "except ImportError as e:\n",
    "    print(f'PyTorch Geometric error: {e}')\n",
    "\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    print('RDKit available: YES')\n",
    "except ImportError as e:\n",
    "    print(f'RDKit error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03155fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SMILES to molecular graph conversion\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"Convert SMILES to PyTorch Geometric Data object.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Atom features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            atom.GetNumRadicalElectrons(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetTotalNumHs(),\n",
    "            atom.GetNumImplicitHs(),\n",
    "            int(atom.IsInRing()),\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge features\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.extend([[i, j], [j, i]])\n",
    "        \n",
    "        bond_features = [\n",
    "            int(bond.GetBondType()),\n",
    "            int(bond.GetIsAromatic()),\n",
    "            int(bond.IsInRing()),\n",
    "        ]\n",
    "        edge_attr.extend([bond_features, bond_features])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Test with a few solvents\n",
    "test_smiles = smiles_df.head(5)\n",
    "for _, row in test_smiles.iterrows():\n",
    "    name = row['SOLVENT NAME']\n",
    "    smiles = row['solvent smiles']\n",
    "    graph = smiles_to_graph(smiles)\n",
    "    if graph is not None:\n",
    "        print(f'{name}: {graph.x.shape[0]} atoms, {graph.edge_index.shape[1]} edges')\n",
    "    else:\n",
    "        print(f'{name}: FAILED to parse SMILES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbdb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GNN approach is viable!\n",
    "# All solvents can be converted to molecular graphs.\n",
    "#\n",
    "# However, implementing a full GNN is complex and time-consuming.\n",
    "# Let me think about what's the SIMPLEST approach that could work.\n",
    "#\n",
    "# Key insight: The problem is that our features don't capture\n",
    "# something important about the test solvents.\n",
    "#\n",
    "# What if we use a DIFFERENT validation strategy?\n",
    "# - Instead of leave-one-solvent-out, use random splits\n",
    "# - This would allow learned embeddings to work\n",
    "# - But this violates the competition rules!\n",
    "#\n",
    "# So we MUST use leave-one-solvent-out CV.\n",
    "# This means we MUST use features that generalize to unseen solvents.\n",
    "\n",
    "print('=== CONCLUSION ===')\n",
    "print('''\\nFor leave-one-solvent-out CV, we MUST use features that generalize to unseen solvents.\n",
    "\n",
    "Options:\n",
    "1. Fixed molecular descriptors (Spange, DRFP, ACS PCA) - ALREADY DOING THIS\n",
    "2. GNN features from SMILES - WOULD WORK but complex\n",
    "3. Learned embeddings - DO NOT WORK (test solvent never seen)\n",
    "\n",
    "The CV-LB gap is NOT due to feature limitations that learned embeddings could fix.\n",
    "It's due to something else - possibly:\n",
    "1. Distribution shift between train and test\n",
    "2. Systematic bias in our predictions\n",
    "3. Different evaluation procedure on LB\n",
    "\n",
    "Since learned embeddings don't work, and GNN is complex,\n",
    "let's focus on what we CAN do:\n",
    "1. Better feature engineering with existing descriptors\n",
    "2. Calibration / post-processing to reduce systematic bias\n",
    "3. Ensemble diversity to capture different patterns''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554166be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze what's different about the LB evaluation\n",
    "#\n",
    "# The CV-LB relationship: LB = 4.27*CV + 0.0527\n",
    "# This means:\n",
    "# - LB is ~4x worse than CV\n",
    "# - There's a constant offset of 0.0527\n",
    "#\n",
    "# The offset suggests systematic bias that doesn't depend on model quality.\n",
    "# This could be due to:\n",
    "# 1. Different solvents in LB vs local CV\n",
    "# 2. Different data distribution\n",
    "# 3. Different evaluation metric\n",
    "\n",
    "print('=== ANALYZING THE SYSTEMATIC BIAS ===')\n",
    "print(f'\\nCV-LB relationship: LB = 4.27*CV + 0.0527')\n",
    "print(f'\\nThe intercept (0.0527) represents systematic bias.')\n",
    "print(f'This is {0.0527 / 0.0347:.1f}x larger than the target!')\n",
    "print(f'\\nPossible causes:')\n",
    "print('1. LB uses different solvents than local CV')\n",
    "print('2. LB has different data distribution')\n",
    "print('3. Our models have systematic prediction bias')\n",
    "print(f'\\nTo reach target (0.0347), we need to either:')\n",
    "print('1. Reduce the intercept (fix systematic bias)')\n",
    "print('2. Change the CV-LB relationship entirely (different approach)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a21ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('=== FINAL RECOMMENDATION ===')\n",
    "print('''\\n**The learned embeddings approach FAILED because:**\n",
    "- Test solvent is never seen during training\n",
    "- Its embedding is just random initialization\n",
    "- This is a FUNDAMENTAL flaw for leave-one-solvent-out CV\n",
    "\n",
    "**What we should try next:**\n",
    "\n",
    "1. **GNN with AttentiveFP** (PRIORITY 1)\n",
    "   - Learns from molecular structure, not identity\n",
    "   - Can generalize to unseen solvents\n",
    "   - Proven to achieve MSE 0.0039 on this dataset\n",
    "   - Complex but worth trying\n",
    "\n",
    "2. **k-NN with Spange similarity** (PRIORITY 2)\n",
    "   - For test solvent, find k most similar training solvents\n",
    "   - Weight predictions by similarity\n",
    "   - Simple to implement\n",
    "   - May help with systematic bias\n",
    "\n",
    "3. **Calibration / Post-processing** (PRIORITY 3)\n",
    "   - Adjust predictions based on solvent similarity to training set\n",
    "   - Temperature scaling or isotonic regression\n",
    "   - May reduce the intercept\n",
    "\n",
    "**What NOT to try:**\n",
    "- Learned embeddings (PROVEN TO FAIL)\n",
    "- More regularization (already tried, doesn't help)\n",
    "- Simpler features (exp_038 proved it hurts)\n",
    "\n",
    "**Submissions remaining:** 4\n",
    "**Best LB:** 0.0877\n",
    "**Target:** 0.0347\n",
    "**Gap:** 2.53x''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key findings\n",
    "print('=== KEY FINDINGS TO RECORD ===')\n",
    "print('''\\n1. Learned embeddings FAIL for leave-one-solvent-out CV because test solvent is never seen during training.\n",
    "\n",
    "2. GNN works because it learns from molecular STRUCTURE, not IDENTITY.\n",
    "\n",
    "3. The CV-LB relationship has intercept (0.0527) > target (0.0347), meaning we need to change the relationship, not just improve CV.\n",
    "\n",
    "4. All solvents can be converted to molecular graphs using RDKit.\n",
    "\n",
    "5. PyTorch Geometric and AttentiveFP are available for GNN implementation.''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
