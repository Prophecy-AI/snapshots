{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d429b55",
   "metadata": {},
   "source": [
    "# Loop 45 Strategic Analysis\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the actual CV-LB relationship?\n",
    "2. What would it take to reach target 0.073?\n",
    "3. What unexplored approaches remain?\n",
    "4. Should we submit exp_044 or try something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f27dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    ('exp_000', 0.011081, 0.09816),\n",
    "    ('exp_001', 0.012297, 0.10649),\n",
    "    ('exp_003', 0.010501, 0.09719),\n",
    "    ('exp_005', 0.01043, 0.09691),\n",
    "    ('exp_006', 0.009749, 0.09457),\n",
    "    ('exp_007', 0.009262, 0.09316),\n",
    "    ('exp_009', 0.009192, 0.09364),\n",
    "    ('exp_012', 0.009004, 0.09134),\n",
    "    ('exp_024', 0.008689, 0.08929),\n",
    "    ('exp_026', 0.008465, 0.08875),\n",
    "    ('exp_030', 0.008298, 0.08772),\n",
    "    ('exp_035', 0.009825, 0.09696),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions, columns=['exp', 'cv', 'lb'])\n",
    "print('=== Submission History ===')\n",
    "print(df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Fit linear regression\n",
    "X = df['cv'].values.reshape(-1, 1)\n",
    "y = df['lb'].values\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(f'CV-LB Relationship: LB = {reg.coef_[0]:.4f} * CV + {reg.intercept_:.4f}')\n",
    "print(f'RÂ² = {reg.score(X, y):.4f}')\n",
    "print()\n",
    "\n",
    "# What CV would we need to hit target?\n",
    "target = 0.073\n",
    "required_cv = (target - reg.intercept_) / reg.coef_[0]\n",
    "print(f'Target LB: {target}')\n",
    "print(f'Required CV to hit target: {required_cv:.6f}')\n",
    "print(f'Current best CV: {df[\"cv\"].min():.6f}')\n",
    "print(f'Gap: {df[\"cv\"].min() - required_cv:.6f}')\n",
    "print()\n",
    "\n",
    "# Best LB so far\n",
    "best_lb = df['lb'].min()\n",
    "best_cv = df.loc[df['lb'].idxmin(), 'cv']\n",
    "print(f'Best LB: {best_lb:.5f} (from CV {best_cv:.6f})')\n",
    "print(f'Gap to target: {best_lb - target:.5f} ({(best_lb - target)/target*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the anomaly: exp_035 had worse CV but similar LB to exp_030\n",
    "print('=== Anomaly Analysis ===')\n",
    "print()\n",
    "print('exp_030: CV=0.008298, LB=0.08772 (BEST LB)')\n",
    "print('exp_035: CV=0.009825, LB=0.09696')\n",
    "print()\n",
    "print('exp_035 had 18.4% worse CV but only 10.5% worse LB')\n",
    "print('This suggests the CV-LB relationship may not be perfectly linear')\n",
    "print()\n",
    "\n",
    "# Calculate residuals\n",
    "df['predicted_lb'] = reg.predict(df['cv'].values.reshape(-1, 1))\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "print('Residuals from linear fit:')\n",
    "print(df[['exp', 'cv', 'lb', 'predicted_lb', 'residual']].to_string(index=False))\n",
    "print()\n",
    "print(f'Mean residual: {df[\"residual\"].mean():.6f}')\n",
    "print(f'Std residual: {df[\"residual\"].std():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we could reduce the intercept?\n",
    "print('=== Intercept Analysis ===')\n",
    "print()\n",
    "print(f'Current intercept: {reg.intercept_:.4f}')\n",
    "print(f'Target: {target}')\n",
    "print()\n",
    "print('If intercept were 0.04 (instead of 0.0528):')\n",
    "new_intercept = 0.04\n",
    "required_cv_new = (target - new_intercept) / reg.coef_[0]\n",
    "print(f'  Required CV: {required_cv_new:.6f}')\n",
    "print(f'  This is achievable with current best CV {df[\"cv\"].min():.6f}')\n",
    "print()\n",
    "print('Key insight: The intercept is the bottleneck, not the CV')\n",
    "print('We need to find an approach that reduces the intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7657394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== Unexplored Approaches ===')\n",
    "print()\n",
    "print('TRIED AND FAILED:')\n",
    "print('- GNN (exp_040): CV 0.068767 - too high')\n",
    "print('- ChemBERTa (exp_041): CV 0.010288 - no improvement')\n",
    "print('- Calibration (exp_042): CV 0.010008 - no improvement')\n",
    "print('- Non-linear mixture (exp_043): CV 0.073776 - mixture only')\n",
    "print('- Hybrid model (exp_044): CV 0.008597 - slight degradation')\n",
    "print('- Learned embeddings (exp_039): CV 0.080438 - OOD failure')\n",
    "print()\n",
    "print('POTENTIALLY UNEXPLORED:')\n",
    "print('1. Importance-weighted CV (address distribution shift)')\n",
    "print('2. Adversarial validation (identify drifting features)')\n",
    "print('3. Mean reversion (blend predictions toward training mean)')\n",
    "print('4. Separate models for single vs mixture (not just features)')\n",
    "print('5. Target-specific models (SM, Product 2, Product 3)')\n",
    "print('6. Ensemble of diverse model families (GP + MLP + LGBM + Ridge)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908780f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what made exp_030 the best LB\n",
    "print('=== exp_030 Analysis ===')\n",
    "print()\n",
    "print('exp_030 achieved best LB (0.08772) with CV 0.008298')\n",
    "print('This was a GP+MLP+LGBM ensemble with weights (0.15, 0.55, 0.3)')\n",
    "print()\n",
    "print('Key features of exp_030:')\n",
    "print('- GP weight: 0.15 (Gaussian Process for uncertainty)')\n",
    "print('- MLP weight: 0.55 (Neural network for non-linear patterns)')\n",
    "print('- LGBM weight: 0.30 (Gradient boosting for tabular data)')\n",
    "print('- Combined Spange + DRFP features')\n",
    "print('- Arrhenius kinetics features')\n",
    "print()\n",
    "print('The ensemble diversity may be key to the good LB performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic recommendation\n",
    "print('=== STRATEGIC RECOMMENDATION ===')\n",
    "print()\n",
    "print('CURRENT SITUATION:')\n",
    "print(f'- Best LB: 0.08772 (exp_030)')\n",
    "print(f'- Target: 0.073')\n",
    "print(f'- Gap: 20.2%')\n",
    "print(f'- Remaining submissions: 4')\n",
    "print()\n",
    "print('THE INTERCEPT PROBLEM:')\n",
    "print(f'- CV-LB relationship: LB = 4.29*CV + 0.0528')\n",
    "print(f'- Intercept (0.0528) is 72% of target (0.073)')\n",
    "print(f'- Even CV=0 would give LB=0.0528')\n",
    "print()\n",
    "print('RECOMMENDED APPROACH:')\n",
    "print('1. DO NOT submit exp_044 (CV 0.008597 is worse than exp_030)')\n",
    "print('2. Focus on approaches that could change the CV-LB relationship:')\n",
    "print('   a. Mean reversion: blend predictions toward training mean')\n",
    "print('   b. Separate models: train completely different models for single vs mixture')\n",
    "print('   c. Target-specific tuning: optimize for each target separately')\n",
    "print('3. The key is to reduce the INTERCEPT, not just improve CV')\n",
    "print()\n",
    "print('SUBMISSION STRATEGY:')\n",
    "print('- Submission 1: Mean reversion on exp_030 (alpha=0.8-0.9)')\n",
    "print('- Submission 2: Based on results, refine or try separate models')\n",
    "print('- Save 2 submissions for final refinements')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
