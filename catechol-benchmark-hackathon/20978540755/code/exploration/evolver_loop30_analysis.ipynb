{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c66964",
   "metadata": {},
   "source": [
    "# Loop 30 Analysis: Critical Strategy Review\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.01727\n",
    "- Gap to target: 5.14x\n",
    "- Submissions remaining: 3\n",
    "\n",
    "**Key Insight from exp_029:**\n",
    "The normalization constraint (SM+P2+P3=1) is WRONG. Actual targets:\n",
    "- Single Solvent: mean=0.7955, range [0.0288, 1.0000]\n",
    "- Full Data: mean=0.8035, range [0.0112, 1.1233]\n",
    "\n",
    "**Critical Discovery from Kernel Analysis:**\n",
    "The `mixall` kernel uses **GroupKFold (5 splits)** instead of Leave-One-Out CV!\n",
    "This could explain the CV-LB gap - our CV scheme may not match the LB evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'cv': 0.010430, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.08870},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nTarget LB: 0.01727')\n",
    "print(f'Best CV: {df[\"cv\"].min():.6f}')\n",
    "print(f'Best LB: {df[\"lb\"].min():.5f}')\n",
    "print(f'Gap to target: {df[\"lb\"].min() / 0.01727:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f81b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB relationship\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'=== CV-LB Linear Fit ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'RÂ² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.01727')\n",
    "print(f'\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.01727)')\n",
    "print('This means even with CV=0, predicted LB would be above target!')\n",
    "\n",
    "# What CV would we need?\n",
    "required_cv = (0.01727 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "print('This is NEGATIVE - mathematically impossible with current relationship!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a039787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap pattern\n",
    "df['gap_ratio'] = df['lb'] / df['cv']\n",
    "df['gap_additive'] = df['lb'] - df['cv']\n",
    "\n",
    "print('=== Gap Analysis ===')\n",
    "print(df[['exp', 'cv', 'lb', 'gap_ratio', 'gap_additive']].to_string(index=False))\n",
    "print(f'\\nMean gap ratio: {df[\"gap_ratio\"].mean():.2f}x')\n",
    "print(f'Mean additive gap: {df[\"gap_additive\"].mean():.4f}')\n",
    "print(f'\\nThe additive gap is relatively stable (~0.08)')\n",
    "print('This suggests a systematic bias, not random variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40947af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: Our CV is BETTER than the top LB!\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print(f'Our best CV: 0.008465')\n",
    "print(f'Top LB (target): 0.01727')\n",
    "print(f'\\nOur CV is {0.01727 / 0.008465:.2f}x BETTER than the target LB!')\n",
    "print('\\nThis means:')\n",
    "print('1. Our model is actually very good at the CV task')\n",
    "print('2. The CV-LB gap is the problem, not model quality')\n",
    "print('3. We need to change something fundamental about our approach')\n",
    "print('\\nPossible explanations:')\n",
    "print('1. Different CV scheme (GroupKFold vs Leave-One-Out)')\n",
    "print('2. Different evaluation metric on LB')\n",
    "print('3. Distribution shift between CV and LB data')\n",
    "print('4. Our CV is overfitting to the specific fold structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have we tried?\n",
    "print('=== APPROACHES TRIED ===')\n",
    "approaches = [\n",
    "    ('Baseline MLP', 'exp_000', 0.011081, 'Arrhenius kinetics + Spange'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'Tree-based alternative'),\n",
    "    ('DRFP features', 'exp_002', 0.016948, 'Molecular fingerprints'),\n",
    "    ('Combined features', 'exp_003', 0.010501, 'Spange + DRFP'),\n",
    "    ('Deep Residual MLP', 'exp_004', 0.051912, 'FAILED - too complex'),\n",
    "    ('Large ensemble (15)', 'exp_005', 0.010430, 'More models'),\n",
    "    ('Simpler model [64,32]', 'exp_006', 0.009749, 'Reduced complexity'),\n",
    "    ('Even simpler [32,16]', 'exp_007', 0.009262, 'Further reduction'),\n",
    "    ('Ridge regression', 'exp_009', 0.009192, 'Linear baseline'),\n",
    "    ('Simple ensemble', 'exp_012', 0.009004, 'MLP + LGBM'),\n",
    "    ('ACS PCA features', 'exp_022', 0.008601, 'New feature set'),\n",
    "    ('Weighted loss', 'exp_026', 0.008465, 'SM weight 2x'),\n",
    "    ('Four-model ensemble', 'exp_028', 0.008674, 'Added XGB, CatBoost'),\n",
    "    ('Normalization', 'exp_029', 0.016180, 'FAILED - wrong constraint'),\n",
    "]\n",
    "\n",
    "for name, exp, cv, notes in approaches:\n",
    "    print(f'{exp}: {name} | CV: {cv:.6f} | {notes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f644b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What HASN'T been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('\\n1. Gaussian Process Regression (GP)')\n",
    "print('   - Mentioned in competition description')\n",
    "print('   - Works well with small datasets')\n",
    "print('   - Different inductive bias than NNs')\n",
    "print('   - May have different CV-LB relationship')\n",
    "print('\\n2. Different CV scheme (GroupKFold)')\n",
    "print('   - The \"mixall\" kernel uses GroupKFold(5) instead of LOO')\n",
    "print('   - This may better match the LB evaluation')\n",
    "print('   - Could explain the CV-LB gap')\n",
    "print('\\n3. Aggressive feature selection')\n",
    "print('   - Current: 145 features')\n",
    "print('   - Try: Top 20-30 by importance')\n",
    "print('   - May reduce overfitting')\n",
    "print('\\n4. Simpler linear models')\n",
    "print('   - Ridge/Lasso with fewer features')\n",
    "print('   - May generalize better')\n",
    "print('\\n5. Multi-task GP')\n",
    "print('   - Explicitly mentioned in competition description')\n",
    "print('   - \"imputing any missing values using a multi-task GP\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b70a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy recommendation\n",
    "print('=== RECOMMENDED STRATEGY ===')\n",
    "print('\\nPRIORITY 1: Try Gaussian Process Regression')\n",
    "print('- Competition explicitly mentions GPs')\n",
    "print('- Different inductive bias may break CV-LB pattern')\n",
    "print('- Works well with small datasets')\n",
    "print('- Implementation: sklearn.gaussian_process.GaussianProcessRegressor')\n",
    "print('\\nPRIORITY 2: Try simpler features + Ridge regression')\n",
    "print('- Reduce from 145 to ~20-30 features')\n",
    "print('- Use feature importance from LightGBM')\n",
    "print('- May reduce overfitting and improve generalization')\n",
    "print('\\nPRIORITY 3: Ensemble GP + MLP + LGBM')\n",
    "print('- Combine different model types')\n",
    "print('- GP provides different predictions')\n",
    "print('- May improve diversity')\n",
    "print('\\nDO NOT TRY:')\n",
    "print('- Normalization constraints (targets dont sum to 1)')\n",
    "print('- More complex architectures (already failed)')\n",
    "print('- More models in ensemble (diminishing returns)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eef7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('=== LOOP 30 SUMMARY ===')\n",
    "print('\\nexp_029 (Normalization) FAILED: 91% worse than baseline')\n",
    "print('Key insight: Targets do NOT sum to 1.0 (mean ~0.80)')\n",
    "print('\\nCurrent best: exp_026 (CV 0.008465, LB 0.0887)')\n",
    "print('Target: 0.01727 (5.14x gap)')\n",
    "print('\\nThe CV-LB gap is the fundamental problem.')\n",
    "print('Our CV is already 2x better than the target LB!')\n",
    "print('\\nNext steps:')\n",
    "print('1. Try Gaussian Process Regression (different inductive bias)')\n",
    "print('2. Try aggressive feature selection (reduce overfitting)')\n",
    "print('3. Consider different CV scheme (GroupKFold vs LOO)')\n",
    "print('\\nSubmissions remaining: 3')\n",
    "print('Only submit if we see fundamentally different behavior.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
