{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c66964",
   "metadata": {},
   "source": [
    "# Loop 30 Analysis: Critical Strategy Review\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008465 (exp_026)\n",
    "- Best LB: 0.0887 (exp_026)\n",
    "- Target: 0.01727\n",
    "- Gap to target: 5.14x\n",
    "- Submissions remaining: 3\n",
    "\n",
    "**Key Insight from exp_029:**\n",
    "The normalization constraint (SM+P2+P3=1) is WRONG. Actual targets:\n",
    "- Single Solvent: mean=0.7955, range [0.0288, 1.0000]\n",
    "- Full Data: mean=0.8035, range [0.0112, 1.1233]\n",
    "\n",
    "**Critical Discovery from Kernel Analysis:**\n",
    "The `mixall` kernel uses **GroupKFold (5 splits)** instead of Leave-One-Out CV!\n",
    "This could explain the CV-LB gap - our CV scheme may not match the LB evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed67d9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:52.936902Z",
     "iopub.status.busy": "2026-01-14T10:11:52.936636Z",
     "iopub.status.idle": "2026-01-14T10:11:54.156141Z",
     "shell.execute_reply": "2026-01-14T10:11:54.155445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Submission History ===\n",
      "    exp       cv      lb\n",
      "exp_000 0.011081 0.09816\n",
      "exp_001 0.012297 0.10649\n",
      "exp_003 0.010501 0.09719\n",
      "exp_005 0.010430 0.09691\n",
      "exp_006 0.009749 0.09457\n",
      "exp_007 0.009262 0.09316\n",
      "exp_009 0.009192 0.09364\n",
      "exp_012 0.009004 0.09134\n",
      "exp_024 0.008689 0.08929\n",
      "exp_026 0.008465 0.08870\n",
      "\n",
      "Target LB: 0.01727\n",
      "Best CV: 0.008465\n",
      "Best LB: 0.08870\n",
      "Gap to target: 5.14x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'cv': 0.010430, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.08870},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('=== Submission History ===')\n",
    "print(df.to_string(index=False))\n",
    "print(f'\\nTarget LB: 0.01727')\n",
    "print(f'Best CV: {df[\"cv\"].min():.6f}')\n",
    "print(f'Best LB: {df[\"lb\"].min():.5f}')\n",
    "print(f'Gap to target: {df[\"lb\"].min() / 0.01727:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f81b33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.158399Z",
     "iopub.status.busy": "2026-01-14T10:11:54.158014Z",
     "iopub.status.idle": "2026-01-14T10:11:54.165853Z",
     "shell.execute_reply": "2026-01-14T10:11:54.165267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CV-LB Linear Fit ===\n",
      "LB = 4.2222 * CV + 0.0533\n",
      "R² = 0.9618\n",
      "\n",
      "Intercept: 0.0533\n",
      "Target: 0.01727\n",
      "\n",
      "CRITICAL: Intercept (0.0533) > Target (0.01727)\n",
      "This means even with CV=0, predicted LB would be above target!\n",
      "\n",
      "Required CV to hit target: -0.008530\n",
      "This is NEGATIVE - mathematically impossible with current relationship!\n"
     ]
    }
   ],
   "source": [
    "# Analyze CV-LB relationship\n",
    "cv = df['cv'].values\n",
    "lb = df['lb'].values\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(cv, lb)\n",
    "print(f'=== CV-LB Linear Fit ===')\n",
    "print(f'LB = {slope:.4f} * CV + {intercept:.4f}')\n",
    "print(f'R² = {r_value**2:.4f}')\n",
    "print(f'\\nIntercept: {intercept:.4f}')\n",
    "print(f'Target: 0.01727')\n",
    "print(f'\\nCRITICAL: Intercept ({intercept:.4f}) > Target (0.01727)')\n",
    "print('This means even with CV=0, predicted LB would be above target!')\n",
    "\n",
    "# What CV would we need?\n",
    "required_cv = (0.01727 - intercept) / slope\n",
    "print(f'\\nRequired CV to hit target: {required_cv:.6f}')\n",
    "print('This is NEGATIVE - mathematically impossible with current relationship!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a039787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.167752Z",
     "iopub.status.busy": "2026-01-14T10:11:54.167539Z",
     "iopub.status.idle": "2026-01-14T10:11:54.181497Z",
     "shell.execute_reply": "2026-01-14T10:11:54.180748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gap Analysis ===\n",
      "    exp       cv      lb  gap_ratio  gap_additive\n",
      "exp_000 0.011081 0.09816   8.858406      0.087079\n",
      "exp_001 0.012297 0.10649   8.659836      0.094193\n",
      "exp_003 0.010501 0.09719   9.255309      0.086689\n",
      "exp_005 0.010430 0.09691   9.291467      0.086480\n",
      "exp_006 0.009749 0.09457   9.700482      0.084821\n",
      "exp_007 0.009262 0.09316  10.058303      0.083898\n",
      "exp_009 0.009192 0.09364  10.187119      0.084448\n",
      "exp_012 0.009004 0.09134  10.144380      0.082336\n",
      "exp_024 0.008689 0.08929  10.276211      0.080601\n",
      "exp_026 0.008465 0.08870  10.478441      0.080235\n",
      "\n",
      "Mean gap ratio: 9.69x\n",
      "Mean additive gap: 0.0851\n",
      "\n",
      "The additive gap is relatively stable (~0.08)\n",
      "This suggests a systematic bias, not random variance\n"
     ]
    }
   ],
   "source": [
    "# Analyze the gap pattern\n",
    "df['gap_ratio'] = df['lb'] / df['cv']\n",
    "df['gap_additive'] = df['lb'] - df['cv']\n",
    "\n",
    "print('=== Gap Analysis ===')\n",
    "print(df[['exp', 'cv', 'lb', 'gap_ratio', 'gap_additive']].to_string(index=False))\n",
    "print(f'\\nMean gap ratio: {df[\"gap_ratio\"].mean():.2f}x')\n",
    "print(f'Mean additive gap: {df[\"gap_additive\"].mean():.4f}')\n",
    "print(f'\\nThe additive gap is relatively stable (~0.08)')\n",
    "print('This suggests a systematic bias, not random variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40947af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.184134Z",
     "iopub.status.busy": "2026-01-14T10:11:54.183885Z",
     "iopub.status.idle": "2026-01-14T10:11:54.191053Z",
     "shell.execute_reply": "2026-01-14T10:11:54.190365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRITICAL INSIGHT ===\n",
      "Our best CV: 0.008465\n",
      "Top LB (target): 0.01727\n",
      "\n",
      "Our CV is 2.04x BETTER than the target LB!\n",
      "\n",
      "This means:\n",
      "1. Our model is actually very good at the CV task\n",
      "2. The CV-LB gap is the problem, not model quality\n",
      "3. We need to change something fundamental about our approach\n",
      "\n",
      "Possible explanations:\n",
      "1. Different CV scheme (GroupKFold vs Leave-One-Out)\n",
      "2. Different evaluation metric on LB\n",
      "3. Distribution shift between CV and LB data\n",
      "4. Our CV is overfitting to the specific fold structure\n"
     ]
    }
   ],
   "source": [
    "# Key insight: Our CV is BETTER than the top LB!\n",
    "print('=== CRITICAL INSIGHT ===')\n",
    "print(f'Our best CV: 0.008465')\n",
    "print(f'Top LB (target): 0.01727')\n",
    "print(f'\\nOur CV is {0.01727 / 0.008465:.2f}x BETTER than the target LB!')\n",
    "print('\\nThis means:')\n",
    "print('1. Our model is actually very good at the CV task')\n",
    "print('2. The CV-LB gap is the problem, not model quality')\n",
    "print('3. We need to change something fundamental about our approach')\n",
    "print('\\nPossible explanations:')\n",
    "print('1. Different CV scheme (GroupKFold vs Leave-One-Out)')\n",
    "print('2. Different evaluation metric on LB')\n",
    "print('3. Distribution shift between CV and LB data')\n",
    "print('4. Our CV is overfitting to the specific fold structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f55cf48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.193735Z",
     "iopub.status.busy": "2026-01-14T10:11:54.193484Z",
     "iopub.status.idle": "2026-01-14T10:11:54.200450Z",
     "shell.execute_reply": "2026-01-14T10:11:54.199814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPROACHES TRIED ===\n",
      "exp_000: Baseline MLP | CV: 0.011081 | Arrhenius kinetics + Spange\n",
      "exp_001: LightGBM | CV: 0.012297 | Tree-based alternative\n",
      "exp_002: DRFP features | CV: 0.016948 | Molecular fingerprints\n",
      "exp_003: Combined features | CV: 0.010501 | Spange + DRFP\n",
      "exp_004: Deep Residual MLP | CV: 0.051912 | FAILED - too complex\n",
      "exp_005: Large ensemble (15) | CV: 0.010430 | More models\n",
      "exp_006: Simpler model [64,32] | CV: 0.009749 | Reduced complexity\n",
      "exp_007: Even simpler [32,16] | CV: 0.009262 | Further reduction\n",
      "exp_009: Ridge regression | CV: 0.009192 | Linear baseline\n",
      "exp_012: Simple ensemble | CV: 0.009004 | MLP + LGBM\n",
      "exp_022: ACS PCA features | CV: 0.008601 | New feature set\n",
      "exp_026: Weighted loss | CV: 0.008465 | SM weight 2x\n",
      "exp_028: Four-model ensemble | CV: 0.008674 | Added XGB, CatBoost\n",
      "exp_029: Normalization | CV: 0.016180 | FAILED - wrong constraint\n"
     ]
    }
   ],
   "source": [
    "# What approaches have we tried?\n",
    "print('=== APPROACHES TRIED ===')\n",
    "approaches = [\n",
    "    ('Baseline MLP', 'exp_000', 0.011081, 'Arrhenius kinetics + Spange'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'Tree-based alternative'),\n",
    "    ('DRFP features', 'exp_002', 0.016948, 'Molecular fingerprints'),\n",
    "    ('Combined features', 'exp_003', 0.010501, 'Spange + DRFP'),\n",
    "    ('Deep Residual MLP', 'exp_004', 0.051912, 'FAILED - too complex'),\n",
    "    ('Large ensemble (15)', 'exp_005', 0.010430, 'More models'),\n",
    "    ('Simpler model [64,32]', 'exp_006', 0.009749, 'Reduced complexity'),\n",
    "    ('Even simpler [32,16]', 'exp_007', 0.009262, 'Further reduction'),\n",
    "    ('Ridge regression', 'exp_009', 0.009192, 'Linear baseline'),\n",
    "    ('Simple ensemble', 'exp_012', 0.009004, 'MLP + LGBM'),\n",
    "    ('ACS PCA features', 'exp_022', 0.008601, 'New feature set'),\n",
    "    ('Weighted loss', 'exp_026', 0.008465, 'SM weight 2x'),\n",
    "    ('Four-model ensemble', 'exp_028', 0.008674, 'Added XGB, CatBoost'),\n",
    "    ('Normalization', 'exp_029', 0.016180, 'FAILED - wrong constraint'),\n",
    "]\n",
    "\n",
    "for name, exp, cv, notes in approaches:\n",
    "    print(f'{exp}: {name} | CV: {cv:.6f} | {notes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f644b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.203309Z",
     "iopub.status.busy": "2026-01-14T10:11:54.202554Z",
     "iopub.status.idle": "2026-01-14T10:11:54.209293Z",
     "shell.execute_reply": "2026-01-14T10:11:54.208671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNEXPLORED APPROACHES ===\n",
      "\n",
      "1. Gaussian Process Regression (GP)\n",
      "   - Mentioned in competition description\n",
      "   - Works well with small datasets\n",
      "   - Different inductive bias than NNs\n",
      "   - May have different CV-LB relationship\n",
      "\n",
      "2. Different CV scheme (GroupKFold)\n",
      "   - The \"mixall\" kernel uses GroupKFold(5) instead of LOO\n",
      "   - This may better match the LB evaluation\n",
      "   - Could explain the CV-LB gap\n",
      "\n",
      "3. Aggressive feature selection\n",
      "   - Current: 145 features\n",
      "   - Try: Top 20-30 by importance\n",
      "   - May reduce overfitting\n",
      "\n",
      "4. Simpler linear models\n",
      "   - Ridge/Lasso with fewer features\n",
      "   - May generalize better\n",
      "\n",
      "5. Multi-task GP\n",
      "   - Explicitly mentioned in competition description\n",
      "   - \"imputing any missing values using a multi-task GP\"\n"
     ]
    }
   ],
   "source": [
    "# What HASN'T been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print('\\n1. Gaussian Process Regression (GP)')\n",
    "print('   - Mentioned in competition description')\n",
    "print('   - Works well with small datasets')\n",
    "print('   - Different inductive bias than NNs')\n",
    "print('   - May have different CV-LB relationship')\n",
    "print('\\n2. Different CV scheme (GroupKFold)')\n",
    "print('   - The \"mixall\" kernel uses GroupKFold(5) instead of LOO')\n",
    "print('   - This may better match the LB evaluation')\n",
    "print('   - Could explain the CV-LB gap')\n",
    "print('\\n3. Aggressive feature selection')\n",
    "print('   - Current: 145 features')\n",
    "print('   - Try: Top 20-30 by importance')\n",
    "print('   - May reduce overfitting')\n",
    "print('\\n4. Simpler linear models')\n",
    "print('   - Ridge/Lasso with fewer features')\n",
    "print('   - May generalize better')\n",
    "print('\\n5. Multi-task GP')\n",
    "print('   - Explicitly mentioned in competition description')\n",
    "print('   - \"imputing any missing values using a multi-task GP\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b70a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.211538Z",
     "iopub.status.busy": "2026-01-14T10:11:54.211060Z",
     "iopub.status.idle": "2026-01-14T10:11:54.217521Z",
     "shell.execute_reply": "2026-01-14T10:11:54.216927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECOMMENDED STRATEGY ===\n",
      "\n",
      "PRIORITY 1: Try Gaussian Process Regression\n",
      "- Competition explicitly mentions GPs\n",
      "- Different inductive bias may break CV-LB pattern\n",
      "- Works well with small datasets\n",
      "- Implementation: sklearn.gaussian_process.GaussianProcessRegressor\n",
      "\n",
      "PRIORITY 2: Try simpler features + Ridge regression\n",
      "- Reduce from 145 to ~20-30 features\n",
      "- Use feature importance from LightGBM\n",
      "- May reduce overfitting and improve generalization\n",
      "\n",
      "PRIORITY 3: Ensemble GP + MLP + LGBM\n",
      "- Combine different model types\n",
      "- GP provides different predictions\n",
      "- May improve diversity\n",
      "\n",
      "DO NOT TRY:\n",
      "- Normalization constraints (targets dont sum to 1)\n",
      "- More complex architectures (already failed)\n",
      "- More models in ensemble (diminishing returns)\n"
     ]
    }
   ],
   "source": [
    "# Strategy recommendation\n",
    "print('=== RECOMMENDED STRATEGY ===')\n",
    "print('\\nPRIORITY 1: Try Gaussian Process Regression')\n",
    "print('- Competition explicitly mentions GPs')\n",
    "print('- Different inductive bias may break CV-LB pattern')\n",
    "print('- Works well with small datasets')\n",
    "print('- Implementation: sklearn.gaussian_process.GaussianProcessRegressor')\n",
    "print('\\nPRIORITY 2: Try simpler features + Ridge regression')\n",
    "print('- Reduce from 145 to ~20-30 features')\n",
    "print('- Use feature importance from LightGBM')\n",
    "print('- May reduce overfitting and improve generalization')\n",
    "print('\\nPRIORITY 3: Ensemble GP + MLP + LGBM')\n",
    "print('- Combine different model types')\n",
    "print('- GP provides different predictions')\n",
    "print('- May improve diversity')\n",
    "print('\\nDO NOT TRY:')\n",
    "print('- Normalization constraints (targets dont sum to 1)')\n",
    "print('- More complex architectures (already failed)')\n",
    "print('- More models in ensemble (diminishing returns)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05eef7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T10:11:54.219930Z",
     "iopub.status.busy": "2026-01-14T10:11:54.219315Z",
     "iopub.status.idle": "2026-01-14T10:11:54.225702Z",
     "shell.execute_reply": "2026-01-14T10:11:54.225110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOOP 30 SUMMARY ===\n",
      "\n",
      "exp_029 (Normalization) FAILED: 91% worse than baseline\n",
      "Key insight: Targets do NOT sum to 1.0 (mean ~0.80)\n",
      "\n",
      "Current best: exp_026 (CV 0.008465, LB 0.0887)\n",
      "Target: 0.01727 (5.14x gap)\n",
      "\n",
      "The CV-LB gap is the fundamental problem.\n",
      "Our CV is already 2x better than the target LB!\n",
      "\n",
      "Next steps:\n",
      "1. Try Gaussian Process Regression (different inductive bias)\n",
      "2. Try aggressive feature selection (reduce overfitting)\n",
      "3. Consider different CV scheme (GroupKFold vs LOO)\n",
      "\n",
      "Submissions remaining: 3\n",
      "Only submit if we see fundamentally different behavior.\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print('=== LOOP 30 SUMMARY ===')\n",
    "print('\\nexp_029 (Normalization) FAILED: 91% worse than baseline')\n",
    "print('Key insight: Targets do NOT sum to 1.0 (mean ~0.80)')\n",
    "print('\\nCurrent best: exp_026 (CV 0.008465, LB 0.0887)')\n",
    "print('Target: 0.01727 (5.14x gap)')\n",
    "print('\\nThe CV-LB gap is the fundamental problem.')\n",
    "print('Our CV is already 2x better than the target LB!')\n",
    "print('\\nNext steps:')\n",
    "print('1. Try Gaussian Process Regression (different inductive bias)')\n",
    "print('2. Try aggressive feature selection (reduce overfitting)')\n",
    "print('3. Consider different CV scheme (GroupKFold vs LOO)')\n",
    "print('\\nSubmissions remaining: 3')\n",
    "print('Only submit if we see fundamentally different behavior.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
