{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50939be",
   "metadata": {},
   "source": [
    "# Loop 41 Analysis: GNN Failed - What Next?\n",
    "\n",
    "**Situation:**\n",
    "- GNN (AttentiveFP) test fold MSE: 0.068767 (8.4x WORSE than baseline)\n",
    "- Best CV: 0.008194 (exp_035)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.30*CV + 0.0524 (R²=0.97)\n",
    "- Submissions remaining: 4\n",
    "\n",
    "**Key Question:** Why did GNN fail when the benchmark achieved MSE 0.0039?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print('Submission History:')\n",
    "print(df)\n",
    "\n",
    "# Linear fit\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "print(f'Intercept: {intercept:.4f}')\n",
    "print(f'Target: 0.0347')\n",
    "print(f'Gap: Intercept is {intercept/0.0347:.2f}x larger than target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GNN failure\n",
    "print('=== GNN FAILURE ANALYSIS ===')\n",
    "print()\n",
    "print('GNN Test Fold MSE: 0.068767')\n",
    "print('Baseline (exp_035) CV: 0.008194')\n",
    "print('GNN is 8.4x WORSE than baseline')\n",
    "print()\n",
    "print('Possible reasons for GNN failure:')\n",
    "print('1. Training data too small (~619 samples) for GNN to learn meaningful representations')\n",
    "print('2. Leave-one-solvent-out CV is extremely challenging for GNN')\n",
    "print('3. The GNN benchmark may have used different CV scheme (not leave-one-solvent-out)')\n",
    "print('4. AttentiveFP may need more training epochs or different hyperparameters')\n",
    "print('5. The molecular graphs may need more sophisticated features')\n",
    "print()\n",
    "print('Key insight: The GNN benchmark (MSE 0.0039) may have used a different evaluation scheme!')\n",
    "print('Our leave-one-solvent-out CV is MUCH harder than standard random splits.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50325e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('=== UNEXPLORED APPROACHES ===')\n",
    "print()\n",
    "print('1. Pre-trained molecular embeddings (ChemBERTa, MolBERT)')\n",
    "print('   - Use embeddings from models trained on millions of molecules')\n",
    "print('   - These capture general chemical knowledge that transfers to new solvents')\n",
    "print()\n",
    "print('2. k-NN with Tanimoto similarity')\n",
    "print('   - For test solvent, find k most similar training solvents')\n",
    "print('   - Weight predictions by similarity')\n",
    "print('   - Simple but may work for distribution shift')\n",
    "print()\n",
    "print('3. Meta-learning / Few-shot learning')\n",
    "print('   - Learn a model that can quickly adapt to new solvents')\n",
    "print('   - MAML, Prototypical Networks, etc.')\n",
    "print()\n",
    "print('4. Adversarial domain adaptation')\n",
    "print('   - Learn features that are invariant across solvents')\n",
    "print('   - May reduce distribution shift')\n",
    "print()\n",
    "print('5. Pure GP with different kernels')\n",
    "print('   - GP provides uncertainty estimates')\n",
    "print('   - May have different CV-LB relationship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the benchmark paper might have done differently\n",
    "print('=== BENCHMARK ANALYSIS ===')\n",
    "print()\n",
    "print('GNN Benchmark (arXiv:2512.19530) achieved MSE 0.0039')\n",
    "print('Our best LB: 0.0877 (22x worse)')\n",
    "print('Target: 0.0347 (8.9x worse than benchmark)')\n",
    "print()\n",
    "print('Possible differences in benchmark evaluation:')\n",
    "print('1. Different CV scheme (random splits vs leave-one-solvent-out)')\n",
    "print('2. Pre-training on larger molecular datasets')\n",
    "print('3. Different GNN architecture (not AttentiveFP)')\n",
    "print('4. Different feature engineering')\n",
    "print('5. Different evaluation metric')\n",
    "print()\n",
    "print('CRITICAL: The competition uses leave-one-solvent-out CV!')\n",
    "print('This is MUCH harder than random splits because:')\n",
    "print('- Test solvent is NEVER seen during training')\n",
    "print('- Model must generalize to completely new molecular structures')\n",
    "print('- This is an out-of-distribution (OOD) problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1036ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What can we do with 4 submissions remaining?\n",
    "print('=== SUBMISSION STRATEGY ===')\n",
    "print()\n",
    "print('Submissions remaining: 4')\n",
    "print('Best LB so far: 0.0877 (exp_030)')\n",
    "print('Target: 0.0347')\n",
    "print('Gap: 2.53x')\n",
    "print()\n",
    "print('Options:')\n",
    "print('1. Submit exp_035 (CV 0.008194) - our best CV model')\n",
    "print('   - Expected LB: 4.30*0.008194 + 0.0524 = 0.0876 (similar to exp_030)')\n",
    "print('   - Unlikely to beat target')\n",
    "print()\n",
    "print('2. Try pre-trained embeddings (ChemBERTa)')\n",
    "print('   - May have different CV-LB relationship')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('3. Try k-NN with Tanimoto similarity')\n",
    "print('   - Simple approach that may work for OOD')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('4. Try pure GP with sophisticated kernels')\n",
    "print('   - GP may have different CV-LB relationship')\n",
    "print('   - Worth trying before submitting')\n",
    "print()\n",
    "print('RECOMMENDATION: Try pre-trained embeddings first, then k-NN, then submit best.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have the right packages for pre-trained embeddings\n",
    "import subprocess\n",
    "result = subprocess.run(['pip', 'list'], capture_output=True, text=True)\n",
    "print('Checking available packages for pre-trained embeddings...')\n",
    "if 'transformers' in result.stdout:\n",
    "    print('✓ transformers is available')\n",
    "else:\n",
    "    print('✗ transformers is NOT available')\n",
    "\n",
    "if 'torch' in result.stdout:\n",
    "    print('✓ torch is available')\n",
    "else:\n",
    "    print('✗ torch is NOT available')\n",
    "\n",
    "if 'rdkit' in result.stdout.lower():\n",
    "    print('✓ rdkit is available')\n",
    "else:\n",
    "    print('✗ rdkit is NOT available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ChemBERTa is available\n",
    "try:\n",
    "    from transformers import AutoModel, AutoTokenizer\n",
    "    print('Testing ChemBERTa...')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "    model = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "    print('✓ ChemBERTa is available!')\n",
    "    \n",
    "    # Test on a simple SMILES\n",
    "    smiles = 'CCO'  # Ethanol\n",
    "    inputs = tokenizer(smiles, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    print(f'Embedding shape: {outputs.last_hidden_state.shape}')\n",
    "except Exception as e:\n",
    "    print(f'✗ ChemBERTa not available: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9079858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('=== LOOP 41 SUMMARY ===')\n",
    "print()\n",
    "print('GNN (AttentiveFP) FAILED with MSE 0.068767 (8.4x worse than baseline)')\n",
    "print()\n",
    "print('Key insight: The GNN benchmark (MSE 0.0039) likely used a different CV scheme.')\n",
    "print('Our leave-one-solvent-out CV is an OOD problem that is MUCH harder.')\n",
    "print()\n",
    "print('Next steps:')\n",
    "print('1. Try pre-trained molecular embeddings (ChemBERTa) if available')\n",
    "print('2. Try k-NN with Tanimoto similarity as a simple OOD approach')\n",
    "print('3. Try pure GP with sophisticated kernels')\n",
    "print('4. If none work, submit exp_035 (best CV) and accept the gap')\n",
    "print()\n",
    "print('The target (0.0347) may be achievable with a fundamentally different approach,')\n",
    "print('but we need to find what changes the CV-LB relationship.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
