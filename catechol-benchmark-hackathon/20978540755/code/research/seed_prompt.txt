## Current Status
- Best CV score: 0.008465 (exp_026 - Weighted Loss Joint Model)
- Best LB score: 0.0887 (exp_026)
- CV-LB gap: ~10.5x ratio (LB = 4.22*CV + 0.0533, R²=0.96)
- Target: 0.01727
- Gap to target: 5.14x (0.0887 / 0.01727)
- Submissions remaining: 3

## Response to Evaluator
- Technical verdict was TRUSTWORTHY. The exp_028 four-model ensemble was well-executed.
- Evaluator's top priority: DO NOT SUBMIT exp_028 (worse than exp_026). AGREED - exp_028 is 2.47% worse.
- Key concerns raised: (1) Adding more tree-based models (XGBoost, CatBoost) did NOT help. (2) MLP + LightGBM is already a strong combination. (3) The CV-LB gap is NOT caused by lack of model diversity.
- Evaluator correctly identified that we need FUNDAMENTALLY DIFFERENT approaches, not just more models.

## Critical Analysis: The CV-LB Gap is Structural

The linear fit LB = 4.22*CV + 0.0533 has R²=0.96, meaning the relationship is very tight.
- The intercept (0.0533) is 3.09x higher than target (0.01727)
- Even with CV=0, predicted LB would be 0.0533
- To reach target 0.01727, we would need CV = -0.0086 (IMPOSSIBLE)
- The gap is NOT caused by model diversity - exp_028 proved this

**Key Insight from Kaggle Kernels:**
1. "mixall" kernel uses GroupKFold(n_splits=5) instead of Leave-One-Out - different CV scheme!
2. "mr0106/catechol" kernel uses POST-PROCESSING NORMALIZATION (SM+P2+P3=1)
3. We have NOT tried post-processing normalization - this is a physics-based constraint!

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop29_analysis.ipynb` for analysis
- Key patterns:
  - SM is the hardest target (MSE ~0.012 vs ~0.006 for products)
  - Weighted loss (2x SM) improved all targets by 2.58%
  - The CV-LB ratio is consistently ~10x across all 10 submissions
  - Post-processing normalization (SM+P2+P3=1) is used by other competitors but NOT by us

## Recommended Approaches (Priority Order)

### PRIORITY 1: Post-Processing Normalization (SM+P2+P3=1)
**Rationale**: This is a physics-based constraint that we have NOT tried. Other competitors use it. It enforces mass balance.

**Implementation**:
```python
# After model predictions
preds = np.clip(preds, 0, 1)
row_sums = preds.sum(axis=1, keepdims=True)
row_sums[row_sums == 0] = 1  # Avoid division by zero
preds = preds / row_sums
```

**Expected outcome**: Better generalization through physics-based regularization. May reduce the CV-LB gap.

### PRIORITY 2: Higher SM Weights [1,1,3]
**Rationale**: SM is still the bottleneck. Weighted loss [1,1,2] improved all targets by 2.58%. More aggressive weighting may help further.

**Implementation**:
- Try weights [1.0, 1.0, 3.0] for [P2, P3, SM]
- Keep same architecture and features
- Combine with post-processing normalization

**Expected outcome**: Better SM predictions, which may improve overall score.

### PRIORITY 3: Combine Both (Weighted Loss + Normalization)
**Rationale**: Best of both worlds - weighted loss for training, normalization for inference.

**Implementation**:
- Use weighted loss [1,1,3] during training
- Apply post-processing normalization after predictions
- Keep MLP [32,16] + LightGBM ensemble

**Expected outcome**: Synergistic improvement from both techniques.

### PRIORITY 4: Gaussian Process Regression (if time permits)
**Rationale**: Competition description mentions GP for imputation. GPs have different generalization properties and provide uncertainty quantification.

**Implementation**:
- Use scikit-learn's GaussianProcessRegressor
- Use the same 145 features (or a subset via PCA)
- Multi-output GP for the 3 targets
- RBF kernel with automatic relevance determination (ARD)

**Expected outcome**: Fundamentally different model type that may break the CV-LB pattern.

## What NOT to Try
- More tree-based models (exp_028 proved XGBoost/CatBoost don't help)
- Simpler features (exp_027 proved DRFP is valuable)
- Deeper architectures (exp_004 failed with residual networks)
- More models in same ensemble (15 models gave only 0.7% improvement)
- Per-target models (exp_025 was worse than joint model)

## Validation Notes
- CV scheme: Leave-one-solvent-out for single solvents (24 folds), leave-one-ramp-out for mixtures (13 folds)
- CV-LB relationship: LB = 4.22*CV + 0.0533 (R²=0.96)
- The intercept (0.0533) is the key problem - need approaches that reduce it
- Post-processing normalization may help by enforcing physical constraints

## Key Insight
The target 0.01727 is BELOW the intercept of our CV-LB fit (0.0533). This means:
1. Our current approach has a "floor" of ~0.05 LB
2. To break through, we need approaches that REDUCE THE INTERCEPT
3. Post-processing normalization is a physics-based constraint that may help
4. Other competitors use this technique - we should try it

**Focus on POST-PROCESSING NORMALIZATION and HIGHER SM WEIGHTS, not more model diversity.**

## Template Compliance
- Last 3 cells must match template exactly
- Only model definition line can be changed
- Remove any verification cells after the final cell