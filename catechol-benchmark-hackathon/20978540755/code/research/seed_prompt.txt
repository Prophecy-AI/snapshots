## Current Status
- Best CV score: 0.008194 (exp_032/035/036 - GP+MLP+LGBM ensemble)
- Best LB score: 0.0877 (exp_030)
- CV-LB relationship: LB = 4.30*CV + 0.0524 (RÂ²=0.97)
- **CRITICAL**: Intercept (0.0524) > Target (0.0347)
- Submissions remaining: 5

## Response to Evaluator
- Technical verdict was TRUSTWORTHY - results can be relied upon
- Evaluator correctly identified that exp_038 (minimal features) was a clean test of the hypothesis
- Evaluator's top priority: Investigate WHY the CV-LB gap exists before more experiments
- I AGREE with the evaluator's assessment. The negative result (19.91% worse) confirms DRFP features ARE valuable.
- Key concerns raised: The CV-LB relationship has intercept > target, suggesting systematic difference
- Addressing by: Trying post-hoc calibration and per-target optimization

## Data Understanding
- Reference notebooks: `exploration/eda.ipynb`, `exploration/evolver_loop36_analysis.ipynb`
- Key patterns:
  - CV-LB gap is STRUCTURAL (intercept 0.0524 > target 0.0347)
  - Targets do NOT sum to 1.0 (mean ~0.80), so normalization is NOT appropriate
  - DRFP features ARE valuable (minimal features made CV 19.91% worse)
  - All attempts to change CV-LB relationship have failed

## CRITICAL INSIGHT FROM RESEARCH
Web search revealed: "The most effective way to shrink the validation-vs-leaderboard gap when the 
model's intercept is noticeably larger than the true target is to treat the intercept as a tunable 
bias and align it with the test-set distribution."

**Techniques to try:**
1. **Post-hoc calibration**: Fit a simple linear scaling on predictions
2. **XGBoost base_score tuning**: Override the automatically estimated intercept
3. **Stacking with residual correction**: Use base_margin to learn only the residual

## Recommended Approaches

### PRIORITY 1: Post-Hoc Calibration
**Rationale**: The CV-LB gap might be due to systematic bias in predictions. A simple linear 
calibration could reduce the intercept. Scale predictions toward the training mean.

**Implementation**:
```python
# After getting predictions from ensemble, apply calibration
# Calibration: scale predictions toward the mean by factor alpha
class CalibratedEnsemble:
    def __init__(self, base_model, calibration_alpha=0.8):
        self.base_model = base_model
        self.calibration_alpha = calibration_alpha  # Scale predictions toward mean
    
    def train_model(self, X_train, y_train):
        self.base_model.train_model(X_train, y_train)
        # Store training target mean for calibration
        self.target_mean = y_train.mean().values
    
    def predict(self, X_test):
        raw_pred = self.base_model.predict(X_test)
        # Calibrate: scale predictions toward the mean
        calibrated = self.calibration_alpha * raw_pred + (1 - self.calibration_alpha) * self.target_mean
        return torch.clamp(calibrated, 0, 1)
```

### PRIORITY 2: Per-Target Optimization with Different Models
**Rationale**: SM, Product 2, and Product 3 might have different optimal models/features.
This is a fundamentally different approach we haven't tried.

**Implementation**:
```python
class PerTargetEnsemble:
    def __init__(self, data='single'):
        self.data_type = data
        # Different model for each target
        self.sm_model = GPEnsemble(data=data)  # GP might be better for SM
        self.p2_model = MLPEnsemble(data=data)  # MLP for Product 2
        self.p3_model = LGBMModel(data=data)   # LGBM for Product 3
    
    def train_model(self, X_train, y_train):
        self.sm_model.train_model(X_train, y_train[['SM']])
        self.p2_model.train_model(X_train, y_train[['Product 2']])
        self.p3_model.train_model(X_train, y_train[['Product 3']])
    
    def predict(self, X_test):
        sm_pred = self.sm_model.predict(X_test)
        p2_pred = self.p2_model.predict(X_test)
        p3_pred = self.p3_model.predict(X_test)
        return torch.cat([p2_pred, p3_pred, sm_pred], dim=1)  # Order: P2, P3, SM
```

### PRIORITY 3: XGBoost/CatBoost with Tuned Base Score
**Rationale**: Tree-based models can have their intercept (base_score) tuned to match test distribution.

**Implementation**:
```python
import xgboost as xgb

class TunedXGBModel:
    def __init__(self, data='single', base_score=0.3):  # Lower base_score
        self.data_type = data
        self.base_score = base_score
        self.featurizer = CombinedFeaturizer(mixed=(data=='full'))
    
    def train_model(self, X_train, y_train):
        X_feat = self.featurizer.featurize(X_train)
        self.models = []
        for i in range(3):
            model = xgb.XGBRegressor(
                n_estimators=200,
                max_depth=5,
                learning_rate=0.05,
                base_score=self.base_score,  # Tuned intercept
                random_state=42
            )
            model.fit(X_feat, y_train.iloc[:, i])
            self.models.append(model)
```

### PRIORITY 4: Stacking with Residual Correction
**Rationale**: Use first-stage predictions as base_margin, then train second-stage to learn residuals.

## What NOT to Try
- More feature simplification (exp_038 proved it hurts: 19.91% worse)
- More regularization (Ridge, Kernel Ridge both much worse)
- Similarity weighting (implementation too complex, failed)
- Normalization of predictions (targets don't sum to 1.0)

## Validation Notes
- CV scheme: Leave-one-solvent-out (fixed by competition)
- CV-LB relationship: LB = 4.30*CV + 0.0524
- The intercept (0.0524) > target (0.0347) is the key problem
- We need to REDUCE the intercept, not just improve CV

## Submission Strategy
With 5 submissions remaining:
1. Try Priority 1 (post-hoc calibration) - submit if CV is reasonable
2. Try Priority 2 (per-target optimization) - submit if different from Priority 1
3. Try Priority 3 (XGBoost with tuned base_score)
4. Reserve 2 submissions for best models

## Key Insight
The target IS reachable. The problem is the systematic bias (intercept) in our predictions.
By calibrating predictions or using models with tunable intercepts, we can potentially
reduce the CV-LB gap. The fact that the target (0.0347) exists means someone achieved it -
we need to find what they did differently.