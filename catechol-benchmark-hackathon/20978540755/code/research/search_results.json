{
  "query": "What techniques can fundamentally change the relationship between cross-validation score and test performance in machine learning when there is distribution shift?",
  "results": [
    {
      "title": "ANSWER",
      "text": "When the training and test data come from different distributions (covariate\u2011 or label\u2011shift), the ordinary cross\u2011validation (CV) score is no longer an unbiased estimator of future test performance.  A family of *importance\u2011weighting* methods restores this link by re\u2011weighting each training example with an estimate of the density\u2011ratio \\(w(x)=p_{\\text{test}}(x)/p_{\\text{train}}(x)\\).  The **Importance\u2011Weighted Cross\u2011Validation (IWCV)** procedure proves that, under covariate shift, the weighted CV risk is unbiased and can be used for model selection\u202f([jmlr](https://jmlr.org/papers/v8/sugiyama07a.html)).  Practical implementations estimate the ratios with kernel mean matching or other density\u2011ratio estimators\u202f([jmlr](https://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf)).  \n\nBeyond simple weighting, more robust adjustments have been proposed.  **Robust Covariate\u2011Shift Adjustment (RCSA)** treats re\u2011weighting as a game against an adversarial test distribution and yields weights that remain effective even when the model class is misspecified\u202f([mlr.press](https://proceedings.mlr.press/v32/wen14.pdf)).  For **label\u2011shift**, the **Black\u2011Box Shift Estimation (BBSE)** technique uses the confusion matrix of any pretrained classifier to estimate the test label marginals and then corrects predictions without requiring test labels\u202f([mlr.press](https://proceedings.mlr.press/v80/lipton18a.html)).  \n\nRecent work on **test\u2011time adaptation** shows that adapting the model on the unlabeled test batch (e.g., entropy minimization, batch\u2011norm statistics alignment) can dramatically reduce the gap between CV and actual test error under shift\u202f([arxiv](https://arxiv.org/abs/2303.15361)).  Complementary approaches such as **weighted conformal prediction** and **weighted conformal risk control** provide distribution\u2011free, calibrated prediction sets that remain valid when covariate shift is present\u202f([arxiv](https://arxiv.org/abs/2501.11413), [semanticscholar](https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01)).  Together, these techniques fundamentally alter the relationship between CV scores and test performance by explicitly accounting for the shift, yielding unbiased or calibrated estimates of future error.",
      "url": ""
    },
    {
      "title": "Covariate Shift Adaptation by Importance Weighted Cross Validation",
      "text": "[Home Page](https://www.jmlr.org/)\n\n[Papers](https://www.jmlr.org/papers)\n\n[Submissions](https://www.jmlr.org/author-info.html)\n\n[News](https://www.jmlr.org/news.html)\n\n[Editorial Board](https://www.jmlr.org/editorial-board.html)\n\n[Special Issues](https://www.jmlr.org/special_issues/)\n\n[Open Source Software](https://www.jmlr.org/mloss)\n\n[Proceedings (PMLR)](https://proceedings.mlr.press/)\n\n[Data (DMLR)](https://data.mlr.press/)\n\n[Transactions (TMLR)](https://www.jmlr.org/tmlr)\n\n[Search](https://www.jmlr.org/search-jmlr.html)\n\n[Statistics](https://www.jmlr.org/stats.html)\n\n[Login](https://www.jmlr.org/manudb)\n\n[Frequently Asked Questions](https://www.jmlr.org/faq.html)\n\n[Contact Us](https://www.jmlr.org/contact.html)\n\n## Covariate Shift Adaptation by Importance Weighted Cross Validation\n\n**_Masashi Sugiyama, Matthias Krauledat, Klaus-Robert M\u00fcller_**; 8(35):985\u22121005, 2007.\n\n### Abstract\n\nA common assumption in supervised learning is that the input points in\nthe training set follow the _same_ probability distribution as\nthe input points that will be given in the future test phase.\nHowever, this assumption is not satisfied, for example, when the\noutside of the training region is extrapolated. The situation where\nthe training input points and test input points follow\n_different_ distributions while the conditional distribution of\noutput values given input points is unchanged is called the\n_covariate shift_. Under the covariate shift, standard model\nselection techniques such as cross validation do not work as desired\nsince its unbiasedness is no longer maintained. In this paper, we\npropose a new method called _importance weighted cross_\n_validation_ (IWCV), for which we prove its unbiasedness even under the\ncovariate shift. The IWCV procedure is the only one that can be\napplied for unbiased classification under covariate shift, whereas\nalternatives to IWCV exist for regression. The usefulness of our\nproposed method is illustrated by simulations, and furthermore\ndemonstrated in the brain-computer interface, where strong\nnon-stationarity effects can be seen between training and test\nsessions.\n\n\\[abs\\]\\[ [pdf](https://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf)\\]\\[ [bib](https://www.jmlr.org/papers/v8/sugiyama07a.bib)\\]\n\n\n|     |\n| --- |\n| \u00a9 [JMLR](https://www.jmlr.org) 2007.<br>( [edit](https://github.com/JmlrOrg/v8/tree/main/sugiyama07a), [beta](http://jmlr.org/beta/papers/v8/sugiyama07a.html)) |\n\n [Mastodon](https://sigmoid.social/@jmlr)",
      "url": "https://jmlr.org/papers/v8/sugiyama07a.html"
    },
    {
      "title": "",
      "text": "Journal of Machine Learning Research 8 (2007) 985-1005 Submitted 6/06; Revised 8/06; Published 5/07\nCovariate Shift Adaptation by Importance Weighted Cross Validation\nMasashi Sugiyama SUGI@CS.TITECH.AC.JP\nDepartment of Computer Science\nTokyo Institute of Technology\n2-12-1, O-okayama, Meguro-ku, Tokyo, 152-8552, Japan\nMatthias Krauledat MATTHIAS.KRAULEDAT@FIRST.FHG.DE\nKlaus-Robert Muller \u00a8 KLAUS@FIRST.FHG.DE\nDepartment of Computer Science\nTechnical University Berlin\nFranklinstr. 28/29, 10587 Berlin, Germany\nEditor: Yoshua Bengio\nAbstract\nA common assumption in supervised learning is that the input points in the training set follow\nthe same probability distribution as the input points that will be given in the future test phase.\nHowever, this assumption is not satisfied, for example, when the outside of the training region is\nextrapolated. The situation where the training input points and test input points follow different\ndistributions while the conditional distribution of output values given input points is unchanged\nis called the covariate shift. Under the covariate shift, standard model selection techniques such\nas cross validation do not work as desired since its unbiasedness is no longer maintained. In this\npaper, we propose a new method called importance weighted cross validation (IWCV), for which\nwe prove its unbiasedness even under the covariate shift. The IWCV procedure is the only one\nthat can be applied for unbiased classification under covariate shift, whereas alternatives to IWCV\nexist for regression. The usefulness of our proposed method is illustrated by simulations, and\nfurthermore demonstrated in the brain-computer interface, where strong non-stationarity effects\ncan be seen between training and test sessions.\nKeywords: covariate shift, cross validation, importance sampling, extrapolation, brain-computer\ninterface\n1. Introduction\nThe goal of supervised learning is to infer an unknown input-output dependency from training\nsamples, by which output values for unseen test input points can be estimated. When developing\na method of supervised learning, it is commonly assumed that the input points in the training set\nand the input points used for testing follow the same probability distribution (e.g., Wahba, 1990;\nBishop, 1995; Vapnik, 1998; Duda et al., 2001; Hastie et al., 2001; Scholk \u00a8 opf and Smola, 2002).\nHowever, this common assumption is not fulfilled, for example, when we extrapolate outside of\nthe training region1 or when training input points are designed by an active learning (experimental\ndesign) algorithm. The situation where the training input points and test input points follow different\n1. The term \u2018extrapolation\u2019 could have been defined in a narrow sense as prediction in regions with no training samples.\nOn the other hand, the situation we are considering here is \u2018weak\u2019 extrapolation; prediction is carried out in the region\nwhere only a small number of training samples is available.\n\rc 2007 Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert Muller \u00a8 .\nSUGIYAMA, KRAULEDAT AND MU\u00a8 LLER\nprobability distributions but the conditional distributions of output values given input points are\nunchanged is called the covariate shift (Shimodaira, 2000). For data from many applications such\nas off-policy reinforcement learning (Shelton, 2001), spam filtering (Bickel and Scheffer, 2007),\nbioinformatics (Baldi et al., 1998; Borgwardt et al., 2006) or brain-computer interfacing (Wolpaw\net al., 2002), the covariate shift phenomenon is conceivable. Sample selection bias (Heckman, 1979)\nin economics may also include a form of the covariate shift. Illustrative examples of covariate shift\nsituations are depicted in Figures 1 and 3.\nIn this paper, we develop a new learning method and prove that we can alleviate misestimation\ndue to covariate shift. From the beginning, we note that all the theoretical discussions will be made\nunder the assumption that the ratio of test and training input densities at training input points is\nknown; in experimental studies, the density ratio will be replaced by their empirical estimates and\nthe practical performance of our approach will be evaluated.\nModel selection is one of the key ingredients in machine learning. However, under the covariate\nshift, a standard model selection technique such as cross validation (CV) (Stone, 1974; Wahba,\n1990) does not work as desired; more specifically, the unbiasedness that guarantees the accuracy\nof CV does not hold under the covariate shift anymore. To cope with this problem, we propose a\nnovel variant of CV called importance weighted CV (IWCV). We prove that IWCV gives an almost\nunbiased estimate of the risk even under the covariate shift. Model selection under the covariate\nshift has been studied so far only by few researchers (e.g., Shimodaira, 2000; Sugiyama and Muller, \u00a8\n2005)\u2014existing methods have a number of limitations, for example, in the loss function, parameter\nlearning method, and model. In particular, the existing methods can not be applied to classification\nscenarios. On the other hand, the proposed IWCV overcomes these limitations: it allows for any\nloss function, parameter learning method, and model; even non-parametric learning methods can\nbe employed. To the best of our knowledge, the proposed IWCV is the first method that can be\nsuccessfully applied to model selection in covariate-shifted classification tasks. The usefulness of\nthe proposed method is demonstrated in the brain-computer interface applications, in which existing\nmethods for covariate shift compensation could not be employed.\n2. Problem Formulation\nIn this section, we formulate the supervised learning problem with the covariate shift, and review\nexisting learning methods.\n2.1 Supervised Learning under Covariate Shift\nLet us consider the supervised learning problem of estimating an unknown input-output depen\u0002dency from training samples. Let T = {(xi\n, yi)}\nn\ni=1\nbe the training samples, where xi \u2208 X \u2282 R\nd\nis\nan i.i.d. training input point following a probability distribution Ptrain(x) and yi \u2208 Y \u2282 R is a corre\u0002sponding training output value following a conditional probability distribution P(y|x). P(y|x) may\nbe regarded as the sum of true output f(x) and noise.\nLet `(x, y, yb): X \u00d7Y \u00d7Y \u2192 [0,\u221e) be the loss function, which measures the discrepancy between\nthe true output value y at an input point x and its estimate yb. Let us employ a parametric model\nfb(x;\u03b8) for estimating the output value y, where \u03b8 \u2208 \u0398 \u2282 R\nb\n. Note that the range of application\nof our proposed method given in Section 3 includes non-parametric methods, but we focus on a\nparametric setting for simplicity. A model fb(x;\u03b8) is said to be correctly specified if there exists a\nparameter \u03b8\n\u2217\nsuch that fb(x;\u03b8\n\u2217\n) = f(x); otherwise the model is said to be misspecified. In practice,\n986\nCOVARIATE SHIFT ADAPTATION BY IMPORTANCE WEIGHTED CROSS VALIDATION\nthe model used for learning would be misspecified to a greater or lesser extent. For this reason,\nwe do not assume that the model is correct in this paper. The goal of supervised learning is to\ndetermine the value of the parameter \u03b8 so that output values for unlearned test input points are\naccurately estimated.\nLet us consider a test sample, which is not given to the user in the training phase, but will be\ngiven in the test phase in the future. We denote the test sample by (t,u), where t \u2208 X is a test input\npoint and u \u2208 Y is a corresponding test output value. The test error expected over test samples is\nexpressed as\nEt,u\nh\n`(t,u, fb(t;b\u03b8))i, (1)\nwhere E denotes the expectation. Note that the learned parameter b\u03b8 generally depends on the train\u0002ing set T = {(xi\n, yi)}\nn\ni=1\n. In the following, we consider the expected test error over the training\nsamples, which is called the risk or the generalization error:\nR\n(n) \u2261 E{xi\n,yi}\nn\ni=1\n,t,u\nh\n`(t,u, fb(t;b\u03b8))i. (2)\nIn standard supervised learning theories, the testsample (t,u)is assumed to follow P(u|t)Ptrain(t),\nwhich is the same probability...",
      "url": "https://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2303.15361] A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2303.15361\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2303.15361**(cs)\n[Submitted on 27 Mar 2023 ([v1](https://arxiv.org/abs/2303.15361v1)), last revised 12 Dec 2024 (this version, v2)]\n# Title:A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts\nAuthors:[Jian Liang](https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+J),[Ran He](https://arxiv.org/search/cs?searchtype=author&amp;query=He,+R),[Tieniu Tan](https://arxiv.org/search/cs?searchtype=author&amp;query=Tan,+T)\nView a PDF of the paper titled A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts, by Jian Liang and Ran He and Tieniu Tan\n[View PDF](https://arxiv.org/pdf/2303.15361)[HTML (experimental)](https://arxiv.org/html/2303.15361v2)> > Abstract:\n> Machine learning methods strive to acquire a robust model during the training process that can effectively generalize to test samples, even in the presence of distribution shifts. However, these methods often suffer from performance degradation due to unknown test distributions. Test-time adaptation (TTA), an emerging paradigm, has the potential to adapt a pre-trained model to unlabeled data during testing, before making predictions. Recent progress in this paradigm has highlighted the significant benefits of using unlabeled data to train self-adapted models prior to inference. In this survey, we categorize TTA into several distinct groups based on the form of test data, namely, test-time domain adaptation, test-time batch adaptation, and online test-time adaptation. For each category, we provide a comprehensive taxonomy of advanced algorithms and discuss various learning scenarios. Furthermore, we analyze relevant applications of TTA and discuss open challenges and promising areas for future research. For a comprehensive list of TTA methods, kindly refer to \\url{\n[> this https URL\n](https://github.com/tim-learn/awesome-test-time-adaptation)> }. Comments:|Discussions, comments, and questions are all welcomed in \\\\url{[this https URL](https://github.com/tim-learn/awesome-test-time-adaptation)}|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)|\nCite as:|[arXiv:2303.15361](https://arxiv.org/abs/2303.15361)[cs.LG]|\n|(or[arXiv:2303.15361v2](https://arxiv.org/abs/2303.15361v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2303.15361](https://doi.org/10.48550/arXiv.2303.15361)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nJournalreference:|International Journal of Computer Vision (2024)|\nRelated DOI:|[https://doi.org/10.1007/s11263-024-02181-w](https://doi.org/10.1007/s11263-024-02181-w)\nFocus to learn more\nDOI(s) linking to related resources\n|\n## Submission history\nFrom: Jian Liang [[view email](https://arxiv.org/show-email/a8a6c287/2303.15361)]\n**[[v1]](https://arxiv.org/abs/2303.15361v1)**Mon, 27 Mar 2023 16:32:21 UTC (1,021 KB)\n**[v2]**Thu, 12 Dec 2024 09:06:56 UTC (686 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts, by Jian Liang and Ran He and Tieniu Tan\n* [View PDF](https://arxiv.org/pdf/2303.15361)\n* [HTML (experimental)](https://arxiv.org/html/2303.15361v2)\n* [TeX Source](https://arxiv.org/src/2303.15361)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2303.15361&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2303.15361&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2023-03](https://arxiv.org/list/cs.LG/2023-03)\nChange to browse by:\n[cs](https://arxiv.org/abs/2303.15361?context=cs)\n[cs.AI](https://arxiv.org/abs/2303.15361?context=cs.AI)\n[cs.CV](https://arxiv.org/abs/2303.15361?context=cs.CV)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2303.15361)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2303.15361)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2303.15361)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2303.15361&amp;description=A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2303.15361&amp;title=A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organiza...",
      "url": "https://arxiv.org/abs/2303.15361"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2501.11413] Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2501.11413\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2501.11413**(cs)\n[Submitted on 20 Jan 2025]\n# Title:Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift\nAuthors:[Matteo Zecchin](https://arxiv.org/search/cs?searchtype=author&amp;query=Zecchin,+M),[Fredrik Hellstr\u00f6m](https://arxiv.org/search/cs?searchtype=author&amp;query=Hellstr\u00f6m,+F),[Sangwoo Park](https://arxiv.org/search/cs?searchtype=author&amp;query=Park,+S),[Shlomo Shamai](https://arxiv.org/search/cs?searchtype=author&amp;query=Shamai,+S)(Shitz),[Osvaldo Simeone](https://arxiv.org/search/cs?searchtype=author&amp;query=Simeone,+O)\nView a PDF of the paper titled Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift, by Matteo Zecchin and 4 other authors\n[View PDF](https://arxiv.org/pdf/2501.11413)[HTML (experimental)](https://arxiv.org/html/2501.11413v1)> > Abstract:\n> Predictive models are often required to produce reliable predictions under statistical conditions that are not matched to the training data. A common type of training-testing mismatch is covariate shift, where the conditional distribution of the target variable given the input features remains fixed, while the marginal distribution of the inputs changes. Weighted conformal risk control (W-CRC) uses data collected during the training phase to convert point predictions into prediction sets with valid risk guarantees at test time despite the presence of a covariate shift. However, while W-CRC provides statistical reliability, its efficiency -- measured by the size of the prediction sets -- can only be assessed at test time. In this work, we relate the generalization properties of the base predictor to the efficiency of W-CRC under covariate shifts. Specifically, we derive a bound on the inefficiency of the W-CRC predictor that depends on algorithmic hyperparameters and task-specific quantities available at training time. This bound offers insights on relationships between the informativeness of the prediction sets, the extent of the covariate shift, and the size of the calibration and training sets. Experiments on fingerprinting-based localization validate the theoretical results. Subjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Theory (cs.IT)|\nCite as:|[arXiv:2501.11413](https://arxiv.org/abs/2501.11413)[cs.LG]|\n|(or[arXiv:2501.11413v1](https://arxiv.org/abs/2501.11413v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2501.11413](https://doi.org/10.48550/arXiv.2501.11413)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Matteo Zecchin [[view email](https://arxiv.org/show-email/9ca7e07e/2501.11413)]\n**[v1]**Mon, 20 Jan 2025 11:26:36 UTC (679 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift, by Matteo Zecchin and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2501.11413)\n* [HTML (experimental)](https://arxiv.org/html/2501.11413v1)\n* [TeX Source](https://arxiv.org/src/2501.11413)\n[![license icon](https://arxiv.org/icons/licenses/by-nc-nd-4.0.png)view license](http://creativecommons.org/licenses/by-nc-nd/4.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2501.11413&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2501.11413&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-01](https://arxiv.org/list/cs.LG/2025-01)\nChange to browse by:\n[cs](https://arxiv.org/abs/2501.11413?context=cs)\n[cs.AI](https://arxiv.org/abs/2501.11413?context=cs.AI)\n[cs.IT](https://arxiv.org/abs/2501.11413?context=cs.IT)\n[math](https://arxiv.org/abs/2501.11413?context=math)\n[math.IT](https://arxiv.org/abs/2501.11413?context=math.IT)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2501.11413)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2501.11413)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2501.11413)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2501.11413&amp;description=Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2501.11413&amp;title=Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv feature...",
      "url": "https://arxiv.org/abs/2501.11413"
    },
    {
      "title": "",
      "text": "Robust Learning under Uncertain Test Distributions:\nRelating Covariate Shift to Model Misspecification\nJunfeng Wen1JUNFENG.WEN@UALBERTA.CA\nChun-Nam Yu2 CHUN-NAM.YU@ALCATEL-LUCENT.COM\nRussell Greiner1 RGREINER@UALBERTA.CA\n1Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E8 CANADA\n2Bell Labs, Alcatel-Lucent, 600 Mountain Avenue, Murray Hill, NJ 07974 USA\nAbstract\nMany learning situations involve learning the\nconditional distribution ppy|xq when the training\ninstances are drawn from the training distribu\u0002tion ptrpxq, even though it will later be used to\npredict for instances drawn from a different test\ndistribution ptepxq. Most current approaches fo\u0002cus on learning how to reweigh the training ex\u0002amples, to make them resemble the test distribu\u0002tion. However, reweighing does not always help,\nbecause (we show that) the test error also de\u0002pends on the correctness of the underlying model\nclass. This paper analyses this situation by view\u0002ing the problem of learning under changing dis\u0002tributions as a game between a learner and an ad\u0002versary. We characterize when such reweighing\nis needed, and also provide an algorithm, robust\ncovariate shift adjustment (RCSA), that provides\nrelevant weights. Our empirical studies, on UCI\ndatasets and a real-world cancer prognostic pre\u0002diction dataset, show that our analysis applies,\nand that our RCSA works effectively.\n1. Introduction\nTraditional machine learning often explicitly or implicitly\nassumes that the data used for training a model come from\nthe same distribution as that of the test data. However, this\nassumption is violated in many real-world applications. For\nexample, biostatisticians often try to collect a large and di\u0002verse training set, perhaps for building prognostic predic\u0002tors for patients with different diseases. When clinicians\ndeploy these predictors, they do not know whether the lo\u0002cal test patient population will be even close to that training\npopulation. Sometimes we can collect a small sample from\nthe target test population, but in most cases we have noth\u0002Proceedings of the 31 st International Conference on Machine\nLearning, Beijing, China, 2014. JMLR: W&CP volume 32. Copy\u0002right 2014 by the author(s).\ning more than weak prior knowledge about how the test\ndistribution may shift, such as anticipated changes in gen\u0002der ratio or age distribution. It is useful to build predictors\nthat are robust against such changes in test distributions.\nIn this work, we investigate the problem of distribu\u0002tion change under covariate shift assumption (Shimodaira,\n2000), in which both training and test distributions share\nthe same conditional distribution ppy|xq, while their\nmarginal distributions, ptrpxq and ptepxq, are different. To\ncorrect the shifted distribution, major efforts have been\ndedicated to importance reweighing (Quionero-Candela\net al., 2009; Sugiyama & Kawanabe, 2012). However,\nreweighing methods will not necessarily improve the per\u0002formance in test set, as prediction accuracy under covariate\nshift is also dependent on model misspecification (White,\n1981). Fig. 1 shows three examples of misspecified mod\u0002els, where we are considering the model class of straight\nlines of the form y\u201cax`b, for xP r\u00b41.5, 2.5s. In Fig. 1(a),\nno straight line is a good fit for the cubic curve across\nthe whole interval, but Model 2 fits the curve reasonably\nwell in the small interval r\u00b40.5, 0.5s. If training data is\nspread all over r\u00b41.5, 2.5s while test data concentrates on\nr\u00b40.5, 0.5s, improvement via reweighing could be signif\u0002icant. The situation in Fig. 1(b) is different: although the\ntrue model is a curve and not a straight line, the best linear\nfit is no more than \u000f away from the value of the true model.\nIn this case, no matter what test distributions we see in the\ninterval r\u00b41.5, 2.5s, the regression loss of the best linear\nmodel will never be more than \u000f from the Bayes optimal\nloss. In Fig. 1(c), the true model is a straight line except at\nx \u201c 0; perhaps this outlier is a cancer patient whose tumour\nspontaneously disappeared on its own. Unless the test dis\u0002tribution concentrates most of its mass at x \u201c 0, the straight\nline fit learned from the training data over the interval will\nstill be a very good predictor. Sometimes we can rule out\nthis type of covariate shift through prior knowledge. If such\noutliers are extremely rare during training time, we would\nnot expect the test population to have many such patients.\nReweighing will not help much in cases 1(b) and 1(c).\nRobust Learning under Uncertain Test Distributions\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22122\n0\n2\n4\n6\n8\n10\n12\n14\n16\nInput\nOutput\nTrue model\nModel 1\nModel 2\n(a) Large misspecification.\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22122\n\u22121\n0\n1\n2\n3\n4\n5\nInput\nOutput\n\u2191\n\u2193\n\u03b5\nTrue model\nBest linear fit\n(b) Small misspecification.\n\u22121.5 \u22121 \u22120.5 0 0.5 1 1.5 2 2.5\n\u22120.5\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\nInput\nOutput\nTrue model\n(c) Single point misspecification.\nFigure 1. Three different scenarios of model misspecifications.\nIn this paper, we relate covariate shift to model misspecifi\u0002cation and investigate when reweighing can help a learner\ndeal with covariate shift. We introduce a game between a\nlearner and an adversary that performs robust learning. The\nlearner chooses a model \u03b8 from a set \u0398 to minimize the\nloss, while the adversary chooses a reweighing function \u03b1\nfrom a set A to create new test distributions to maximize the\nloss. There are two major contributions in this paper: First,\nwe provide an improved understanding of the relation be\u0002tween covariate shift and model misspecification through\nthis game analysis. If the learner can find a \u03b8 that min\u0002imizes the loss against any possible \u03b1 that the adversary\ncan play, then it is not necessary to perform reweighing\nagainst covariate shift scenarios represented by A. Sec\u0002ond, we provide a systematic method for checking a model\nclass \u0398 against different covariate shift scenarios, such as\nchanging gender ratio and age distributions in the prognos\u0002tic predictor example, to help user decide whether impor\u0002tance reweighing would be beneficial.\nFor practical use, our method can be used to decide if the\nmodel class is sufficient against shifts that are close to a test\nsample; or robust against a known range of potential shifts\nif test sample is unavailable. If the model class is insuffi\u0002cient, we can consider different ways to deal with covariate\nshifts, such as reweighing using unlabelled test samples, or\nexploring a different model class for the problem.\n2. Related Work\nOur work is inspired by Grunwald & Dawid \u00a8 (2004), who\ninterpret maximum entropy as a game between an adver\u0002sary and a learner on minimizing the worst case expected\nlog loss. Teo et al. (2008) and Globerson & Roweis (2006)\nalso consider an adversarial scenario under changing test\nset conditions, but they are concerned with corruption or\ndeletion of features rather than covariate shift.\nMany results on covariate shift correction involve density\nratio estimation. Shimodaira (2000) showed that, given co\u0002variate shift and model misspecification, reweighing each\ninstance with ptepxq{ptrpxq is asymptotically optimal for\nlog-likelihood estimation, where ptrpxq and ptepxq are as\u0002sumed to be known or estimated in advance. Sugiyama\n& Muller \u00a8 (2005) extended this work by proposing an\n(almost) unbiased estimator for L2 generalization error.\nThere are several works focusing on minimizing differ\u0002ent types of divergence between distributions in the liter\u0002ature (Kanamori et al., 2008; Sugiyama et al., 2008; Ya\u0002mada et al., 2011). Kernel mean matching (KMM) (Huang\net al., 2007) reweighs instances to match means in a\nRKHS (Scholkopf & Smola \u00a8 , 2002). Our work and some\nother approaches (Pan et al., 2009) adapt the idea of match\u0002ing means of the datasets to correct shifted distribution,\nbut we extend their approaches from a two-step optimiza\u0002tion to a game framework that jointly learns a model\nand weights with covariate shift correction. Some other\napproaches (Zadrozny, 2004; Bickel et al.,...",
      "url": "https://proceedings.mlr.press/v32/wen14.pdf"
    },
    {
      "title": "Detecting and Correcting for Label Shift with Black Box Predictors",
      "text": "Detecting and Correcting for Label Shift with Black Box Predictors\n[![[International Conference on Machine Learning Logo]](https://proceedings.mlr.press/v80/assets/images/logo-pmlr.svg)](https://proceedings.mlr.press/)Proceedings of Machine Learning Research\n[[edit](https://github.com/mlresearch/v80/edit/gh-pages/_posts/2018-07-03-lipton18a.md)]\n# Detecting and Correcting for Label Shift with Black Box Predictors\nZachary Lipton,Yu-Xiang Wang,Alexander Smola\n*Proceedings of the 35th International Conference on Machine Learning*,PMLR 80:3122-3130,2018.\n#### Abstract\nFaced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE\u2019s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.\n#### Cite this Paper\nBibTeX\n`@InProceedings{pmlr-v80-lipton18a,\ntitle = {Detecting and Correcting for Label Shift with Black Box Predictors},\nauthor = {Lipton, Zachary and Wang, Yu-Xiang and Smola, Alexander},\nbooktitle = {Proceedings of the 35th International Conference on Machine Learning},\npages = {3122--3130},\nyear = {2018},\neditor = {Dy, Jennifer and Krause, Andreas},\nvolume = {80},\nseries = {Proceedings of Machine Learning Research},\nmonth = {10--15 Jul},\npublisher = {PMLR},\npdf = {http://proceedings.mlr.press/v80/lipton18a/lipton18a.pdf},\nurl = {https://proceedings.mlr.press/v80/lipton18a.html},\nabstract = {Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE\u2019s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.}\n}`\nCopy to ClipboardDownload\nEndnote\n`%0 Conference Paper\n%T Detecting and Correcting for Label Shift with Black Box Predictors\n%A Zachary Lipton\n%A Yu-Xiang Wang\n%A Alexander Smola\n%B Proceedings of the 35th International Conference on Machine Learning\n%C Proceedings of Machine Learning Research\n%D 2018\n%E Jennifer Dy\n%E Andreas Krause\t%F pmlr-v80-lipton18a\n%I PMLR\n%P 3122--3130\n%U https://proceedings.mlr.press/v80/lipton18a.html\n%V 80\n%X Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE\u2019s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.`\nCopy to ClipboardDownload\nAPA\n`Lipton, Z., Wang, Y. & Smola, A.. (2018). Detecting and Correcting for Label Shift with Black Box Predictors.*Proceedings of the 35th International Conference on Machine Learning*, in*Proceedings of Machine Learning Research*80:3122-3130 Available from https://proceedings.mlr.press/v80/lipton18a.html.`\nCopy to ClipboardDownload\n#### Related Material\n* [Download PDF](http://proceedings.mlr.press/v80/lipton18a/lipton18a.pdf)\n* [Supplementary PDF](http://proceedings.mlr.press/v80/lipton18a/lipton18a-supp.pdf)",
      "url": "https://proceedings.mlr.press/v80/lipton18a.html"
    },
    {
      "title": "Conformal Prediction Under Covariate Shift",
      "text": "[PDF] Conformal Prediction Under Covariate Shift | Semantic Scholar\n[Skip to search form](#search-form)[Skip to main content](#main-content)[Skip to account menu](#account-menu)\n[Semantic ScholarSemantic Scholar&#x27;s Logo](https://www.semanticscholar.org/)\nSearch 231,958,520 papers from all fields of science\nSearch\n* Corpus ID: 115140768# Conformal Prediction Under Covariate Shift\n```\n@inproceedings{Tibshirani2019ConformalPU,\ntitle={Conformal Prediction Under Covariate Shift},\nauthor={Ryan J. Tibshirani and Rina Foygel Barber and Emmanuel J. Cand{\\\\`e}s and Aaditya Ramdas},\nbooktitle={Neural Information Processing Systems},\nyear={2019},\nurl={https://api.semanticscholar.org/CorpusID:115140768}\n}\n```\n* [R. Tibshirani](https://www.semanticscholar.org/author/R.-Tibshirani/7135376),[R. Barber](https://www.semanticscholar.org/author/R.-Barber/32492090),+1 author[Aaditya Ramdas](https://www.semanticscholar.org/author/Aaditya-Ramdas/2556942)\n* Publishedin[Neural Information Processing\u2026](https://www.semanticscholar.org/venue?name=Neural%20Information%20Processing%20Systems)1 April 2019\n* Mathematics, Computer Science\nTLDR\nIt is shown that a weighted version of conformal prediction can be used to compute distribution-free prediction intervals for problems in which the test and training covariate distributions differ, but the likelihood ratio between these two distributions is known.Expand\n[[PDF] Semantic Reader](https://www.semanticscholar.org/reader/f08e13d65cb17856427b429d79f01922584a6f01)\nSave to LibrarySave\nCreate AlertAlert\nCite\nShare\n568 Citations\n[\nHighly Influential Citations\n](#citing-papers)[](https://www.semanticscholar.org/faq#influential-citations)\n82\n[\nBackground Citations\n](#citing-papers)\n159\n[\nMethods Citations\n](#citing-papers)\n108\n[\nResults Citations\n](#citing-papers)\n11\n[View All](#citing-papers)\n## Figures from this paper\n* [\n![figure 1](https://figures.semanticscholar.org/f08e13d65cb17856427b429d79f01922584a6f01/6-Figure1-1.png)\nfigure 1](https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01/figure/0)\n* [\n![figure 2](https://figures.semanticscholar.org/f08e13d65cb17856427b429d79f01922584a6f01/7-Figure2-1.png)\nfigure 2](https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01/figure/1)\n* [\n![figure 3](https://figures.semanticscholar.org/f08e13d65cb17856427b429d79f01922584a6f01/9-Figure3-1.png)\nfigure 3](https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01/figure/2)\n* [\n![figure 4](https://figures.semanticscholar.org/f08e13d65cb17856427b429d79f01922584a6f01/10-Figure4-1.png)\nfigure 4](https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01/figure/3)\n## Topics\nAI-Generated\n[Exchangeable Data(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/65913150729?corpusId=115140768)[Weighted Conformal Prediction(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/37687961291?corpusId=115140768)[Exchangeability(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/9947308610?corpusId=115140768)[Conformal Prediction(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/42804067572?corpusId=115140768)[Distribution-free Prediction Intervals(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/62461328648?corpusId=115140768)[Split Conformal Prediction(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/50613023324?corpusId=115140768)[Conformal Procedures(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/2038276229?corpusId=115140768)[Split Conformal Prediction Method(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/66937044779?corpusId=115140768)[Conditional Coverage(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/38444859492?corpusId=115140768)[Conformal Sets(opens in a new tab)](https://topics-beta.apps.semanticscholar.org/topic/721219165?corpusId=115140768)\n## 568 Citations\nCitation Type\nHas PDF\nAuthor\nMore Filters\nMore Filters\nFilters\nSort by RelevanceSort by Most Influenced PapersSort by Citation CountSort by Recency\n[### A Distribution-Free Test of Covariate Shift Using Conformal Prediction\n](https://www.semanticscholar.org/paper/A-Distribution-Free-Test-of-Covariate-Shift-Using-Hu-Lei/351507cf1ac2b07ce4dbda0b1168642d88a26c47)[Xiaoyu Hu](https://www.semanticscholar.org/author/Xiaoyu-Hu/152246541)[Jing Lei](https://www.semanticscholar.org/author/Jing-Lei/145258822)\nComputer Science\n* 2020\nTLDR\nThis is the first successful attempt of using conformal prediction for testing statistical hypotheses and can be effectively combined with existing classification algorithms to find good conformity score functions.Expand\n* [\n30\n](https://www.semanticscholar.org/paper/351507cf1ac2b07ce4dbda0b1168642d88a26c47#citing-papers)\n* [Highly Influenced](https://www.semanticscholar.org/paper/351507cf1ac2b07ce4dbda0b1168642d88a26c47?sort=is-influential#citing-papers)\n* 3 Excerpts\nSave\n[### Fair conformal prediction for incomplete covariate data\n](https://www.semanticscholar.org/paper/Fair-conformal-prediction-for-incomplete-covariate-Kong-Liu/aec23af74cf11c641e04dd6a9d2e5c69c0b759d2)[Jingsen Kong](https://www.semanticscholar.org/author/Jingsen-Kong/2334592352)[Yiming Liu](https://www.semanticscholar.org/author/Yiming-Liu/2261328770)[Guangren Yang](https://www.semanticscholar.org/author/Guangren-Yang/2269458790)[Ding Zhong](https://www.semanticscholar.org/author/Ding-Zhong/2393068540)\nMathematics, Medicine\n[Statistics and Computing](https://www.semanticscholar.org/venue?name=Statistics%20and%20Computing)\n* 2025\nTLDR\nThis study explores the application of conformal prediction in scenarios where covariates are missing, which introduces significant challenges for uncertainty quantification and proposes a nonexchangeable conformal prediction method for missing covariates that satisfies both marginal and mask-conditional validity.Expand\n* [\n1\n](https://www.semanticscholar.org/paper/aec23af74cf11c641e04dd6a9d2e5c69c0b759d2#citing-papers)\n* [Highly Influenced](https://www.semanticscholar.org/paper/aec23af74cf11c641e04dd6a9d2e5c69c0b759d2?sort=is-influential#citing-papers)\n[[PDF]](https://www.semanticscholar.org/reader/aec23af74cf11c641e04dd6a9d2e5c69c0b759d2)\n* 2 Excerpts\nSave\n[### Split Conformal Prediction under Data Contamination\n](https://www.semanticscholar.org/paper/Split-Conformal-Prediction-under-Data-Contamination-Clarkson-Xu/8b5f4e013bc2baad97c6c82be21abf2616f7228d)[Jase Clarkson](https://www.semanticscholar.org/author/Jase-Clarkson/2310607712)[Wenkai Xu](https://www.semanticscholar.org/author/Wenkai-Xu/2293764224)[Mihai Cucuringu](https://www.semanticscholar.org/author/Mihai-Cucuringu/2264879492)[G. Reinert](https://www.semanticscholar.org/author/G.-Reinert/2666765)\nMathematics, Computer Science\n[COPA](https://www.semanticscholar.org/venue?name=COPA)\n* 2024\nTLDR\nThis work studies the robustness of split conformal prediction in a data contamination setting, where a small fraction of the calibration scores are drawn from a different distribution than the bulk, and proposes an adjustment in the classification setting which is called Contamination Robust Conformal Prediction.Expand\n* [\n7\n](https://www.semanticscholar.org/paper/8b5f4e013bc2baad97c6c82be21abf2616f7228d#citing-papers)[[PDF]](https://www.semanticscholar.org/reader/8b5f4e013bc2baad97c6c82be21abf2616f7228d)\n* 1 Excerpt\nSave\n[### Design-based conformal prediction\n](https://www.semanticscholar.org/paper/Design-based-conformal-prediction-Wieczorek/47b78fb63594fe5abbd10cd816759f5c23b00685)[J. Wieczorek](https://www.semanticscholar.org/author/J.-Wieczorek/2050438733)\nMathematics\n* 2023\nConformal pred...",
      "url": "https://www.semanticscholar.org/paper/Conformal-Prediction-Under-Covariate-Shift-Tibshirani-Barber/f08e13d65cb17856427b429d79f01922584a6f01"
    },
    {
      "title": "Covariate shift and local learning by distribution matching",
      "text": "Covariate shift and local learning by distribution matching | Empirical Inference \u2013MPI-IS\n[Institute Homepage](https://is.mpg.de/)\n[Institute Homepage](https://is.mpg.de/)[Sign In](https://is.mpg.de/ei/en/sign_in)\n[Back](https://is.mpg.de/ei/publications)\n[Empirical Inference](https://is.mpg.de/ei)[Book Chapter](https://is.mpg.de/ei/en/publications?bibtex_type=inbook)[2009](https://is.mpg.de/ei/en/publications?year=2009)# Covariate shift and local learning by distribution matching\n[PDF](http://www.is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/shift-book-for-LeEtAl-webversion_5376[0].pdf)[Web](http://mitpress.mit.edu/books/dataset-shift-machine-learning)\n[![no image](https://is.mpg.de/assets/no_employee-e06e20249dbc33f3e8311182c2fca99231e034c34648cfcc73f637940e3012d2.png)](https://is.mpg.de/ei/person/arthur)\nEmpirical Inference\n[Arthur Gretton](https://is.mpg.de/ei/person/arthur)\n[![Thumb ticker sm l1170153](https://is.mpg.de/uploads/person/image/999145/thumb_ticker_sm_L1170153.jpg)](https://is.mpg.de/ei/person/bs)\nEmpirical Inference\n[Bernhard Sch\u00f6lkopf](https://is.mpg.de/ei/person/bs)\n* Director\n[![no image](https://is.mpg.de/assets/no_employee-e06e20249dbc33f3e8311182c2fca99231e034c34648cfcc73f637940e3012d2.png)](https://is.mpg.de/ei/person/huang)\nEmpirical Inference\n[Jiayuan Huang](https://is.mpg.de/ei/person/huang)\n* Doctoral Researcher\n[![no image](https://is.mpg.de/assets/no_employee-e06e20249dbc33f3e8311182c2fca99231e034c34648cfcc73f637940e3012d2.png)](https://is.mpg.de/ei/person/msl)\nEmpirical Inference\n[Marcel Schmittfull](https://is.mpg.de/ei/person/msl)\n[![Thumb ticker sm borgwardt](https://is.mpg.de/uploads/person/image/99922/thumb_ticker_sm_borgwardt.jpg)](https://is.mpg.de/ei/person/99922)\nEmpirical Inference\n[Karsten Borgwardt](https://is.mpg.de/ei/person/99922)\n* Research Group Leader\nGiven sets of observations of training and test data, we consider the problem of re-weighting the training data such that its distribution more closely matches that of the test data. We achieve this goal by matching covariate distributions between training and test sets in a high dimensional feature space (specifically, a reproducing\rkernel Hilbert space). This approach does not require distribution estimation. Instead, the sample weights are obtained by a simple quadratic programming procedure. We provide a uniform convergence bound on the distance between\rthe reweighted training feature mean and the test feature mean, a transductive bound on the expected loss of an algorithm trained on the reweighted data, and a connection to single class SVMs. While our method is designed to deal with the case of simple covariate shift (in the sense of Chapter ??), we have also found benefits for sample selection bias on the labels. Our correction procedure yields its greatest and most consistent advantages when the learning algorithm returns a classifier/regressor that is simpler&quot; than the data might suggest.\nAuthor(s):|Gretton, A. and Smola, AJ. and Huang, J. and Schmittfull, M. and Borgwardt, KM. and Sch\u00f6lkopf, B.|\n**Links:**|\n* [PDF](http://www.is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/shift-book-for-LeEtAl-webversion_5376[0].pdf)\n* [Web](http://mitpress.mit.edu/books/dataset-shift-machine-learning)|\nBook Title:|Dataset Shift in Machine Learning|\nPages:|131-160|\nYear:|2009|\nDay:|0|\nEditors:|Qui\u00f1onero-Candela, J., Sugiyama, M., Schwaighofer, A. and Lawrence, N. D.|\nPublisher:|MIT Press|\n|\nBibTeX Type:|Book Chapter(inbook)|\n|\n**Address:**|Cambridge, MA, USA|\n|\n**Electronic Archiving:**|grant\\_archive|\n**ISBN:**|978-0-262-17005-5|\n**Language:**|en|\n**Organization:**|Max-Planck-Gesellschaft|\n**School:**|Biologische Kybernetik|\n### BibTeX\n```\n@inbook{5376,\ntitle = {Covariate shift and local learning by distribution matching},\nbooktitle = {Dataset Shift in Machine Learning},\nabstract = {Given sets of observations of training and test data, we consider the problem of re-weighting the training data such that its distribution more closely matches that of the test data. We achieve this goal by matching covariate distributions between training and test sets in a high dimensional feature space (specifically, a reproducing\rkernel Hilbert space). This approach does not require distribution estimation. Instead, the sample weights are obtained by a simple quadratic programming procedure. We provide a uniform convergence bound on the distance between\rthe reweighted training feature mean and the test feature mean, a transductive bound on the expected loss of an algorithm trained on the reweighted data, and a connection to single class SVMs. While our method is designed to deal with the case of simple covariate shift (in the sense of Chapter ??), we have also found benefits for sample selection bias on the labels. Our correction procedure yields its greatest and most consistent advantages when the learning algorithm returns a classifier/regressor that is simpler&quot;&quot; than the data might suggest.},\npages = {131-160},\neditors = {Qui\u00f1onero-Candela, J., Sugiyama, M., Schwaighofer, A. and Lawrence, N. D.},\npublisher = {MIT Press},\norganization = {Max-Planck-Gesellschaft},\nschool = {Biologische Kybernetik},\naddress = {Cambridge, MA, USA},\nyear = {2009},\nauthor = {Gretton, A. and Smola, AJ. and Huang, J. and Schmittfull, M. and Borgwardt, KM. and Sch{\\\\&quot;&quot;o}lkopf, B.}\n}\n```\n</div>\n##### </button>\n[More information**]()\n##### Download QR Code",
      "url": "https://is.mpg.de/ei/publications/5376"
    }
  ]
}