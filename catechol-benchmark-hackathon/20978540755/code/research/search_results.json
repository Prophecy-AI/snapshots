{
  "query": "What are the best techniques for predicting chemical reaction yields when test solvents are completely unseen during training?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields for solvents that never appear in the training set is an out\u2011of\u2011distribution (OOD) problem.  Conventional models that rely only on categorical (one\u2011hot) solvent identifiers tend to over\u2011fit to the solvent distribution seen during training, leading to large errors when a new solvent is introduced.  To obtain reliable predictions you need (i) a representation that captures the continuous physicochemical properties of the solvent, and (ii) a learning strategy that can quickly adapt to a handful of new solvent\u2011reaction examples while providing calibrated uncertainty estimates\u3010arxiv.org](https://arxiv.org/html/2506.07619v1)\u3010arxiv.org](https://arxiv.org/abs/2512.19530)\u3010nature.com](https://www.nature.com/articles/s41467-025-59812-0)\u3010arxiv.org](https://arxiv.org/abs/2501.06669)\u3011.\n\nThe most effective techniques reported so far combine three ingredients:\n\n1. **Graph\u2011based or continuous solvent embeddings** \u2013 Graph neural networks (GNNs) that ingest the molecular graph of the solvent (and reagents) learn transferable solvent\u2011effect features and have set the benchmark on the Catechol transient\u2011flow dataset, outperforming fingerprint\u2011based baselines when solvents are unseen\u3010arxiv.org](https://arxiv.org/abs/2512.19530)\u3010arxiv.org](https://arxiv.org/html/2506.07619v1)\u3011.  \n2. **Meta\u2011learning / few\u2011shot adaptation** \u2013 The MetaRF framework uses an attention\u2011weighted differentiable random forest that is meta\u2011trained across many reactions; a few new solvent\u2011reaction points are enough to fine\u2011tune the model for accurate yield prediction on completely novel solvents\u3010arxiv.org](https://arxiv.org/pdf/2208.10083)\u3011.  Similar few\u2011shot transfer\u2011learning pipelines were benchmarked on the Catechol solvent\u2011selection task, showing that a small set of strategically chosen solvent experiments (active learning) dramatically reduces error on unseen solvents\u3010arxiv.org](https://arxiv.org/html/2506.07619v1)\u3011.  \n3. **Bayesian / uncertainty\u2011aware learning** \u2013 Bayesian deep learning approaches provide posterior predictive distributions that flag high\u2011uncertainty predictions, which are especially common for OOD solvents.  Incorporating uncertainty not only improves robustness but also guides active\u2011learning acquisition of the most informative new solvent data\u3010nature.com](https://www.nature.com/articles/s41467-025-59812-0)\u3011\u3010research.ibm.com](https://research.ibm.com/publications/low-data-regime-yield-predictions-with-uncertainty-estimation-using-deep-learning-approaches)\u3011.\n\nIn practice, a state\u2011of\u2011the\u2011art workflow would (a) encode solvents with GNN\u2011derived continuous descriptors, (b) pre\u2011train a meta\u2011learning model such as MetaRF on large high\u2011throughput experimentation (HTE) datasets, (c) fine\u2011tune on a few experimentally measured yields for the new solvent using active\u2011learning selection, and (d) report Bayesian confidence intervals to identify predictions that require further experimental validation.  This combination has been shown to achieve the highest accuracy and reliability when test solvents are completely unseen during training\u3010arxiv.org](https://arxiv.org/abs/2501.06669)\u3010ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC10189898)\u3011.",
      "url": ""
    },
    {
      "title": "Towards global reaction feasibility and robustness prediction with high throughput data and bayesian deep learning",
      "text": "## Introduction\n\nPredicting the feasibility of any given reaction has been a fundamental yet long perplexing problem for organic chemists. Addressing this issue would enable organic chemists to swiftly rule out non-viable reactions during the synthesis design process, thereby saving enormous time while navigating complex pathways to synthesize highly valuable compounds[1](https://www.nature.com/articles/s41467-025-59812-0#ref-CR1). This is particularly critical in the field of medicinal chemistry, where time and cost constraints are crucial during stages such as early drug discovery and preclinical process development[2](https://www.nature.com/articles/s41467-025-59812-0#ref-CR2), [3](https://www.nature.com/articles/s41467-025-59812-0#ref-CR3). However, to date, no universal \u201coracle\u201d exists to definitively predict the feasibility of a reaction before experimental validation[4](https://www.nature.com/articles/s41467-025-59812-0#ref-CR4). Although theoretical advances in the reactivity of organic compounds have progressed rapidly, a complete understanding of the causal relationships between molecular structures and reaction outcomes based solely on first principles remains elusive. Emerging statistical learning methods that leverage existing literature data show promise but are still in their early stage, mainly due to the lack of negative results in published data[5](https://www.nature.com/articles/s41467-025-59812-0#ref-CR5), [6](https://www.nature.com/articles/s41467-025-59812-0#ref-CR6). In practice, identifying feasible reactions is still a task that highly relies on the expertise and intuition of seasoned experts in organic chemistry[7](https://www.nature.com/articles/s41467-025-59812-0#ref-CR7). Training such experts requires both smart learning strategies and rigorous efforts. Similarly, developing an artificial intelligence (AI) system that matches the performance of such experts requires smart strategies to navigate global chemical space using minimal data amount and systematically acquiring extensive, unbiased wetlab data automatically. Despite many promising pioneering works[2](https://www.nature.com/articles/s41467-025-59812-0#ref-CR2), [5](https://www.nature.com/articles/s41467-025-59812-0#ref-CR5), [8](http://www.nature.com/www.nature.com#ref-CR8), [9](http://www.nature.com/www.nature.com#ref-CR9), [10](http://www.nature.com/www.nature.com#ref-CR10), [11](https://www.nature.com/articles/s41467-025-59812-0#ref-CR11), researchers are still in the early exploring stage to build an AI system that can steadily serve as an \u201coracle\u201d to predict the feasibility of any given organic reaction.\n\nBeneath the surface of predicting reaction feasibility lies a more complex challenge: assessing the robustness of reactions. The results of organic reactions can be influenced by many factors, _e.g_., minor changes in environments (moisture, oxygen level, light, _etc_.), nuanced differences in analytical and separation methods, and subtle variations in manual operations. This intrinsic stochasticity often makes certain sensitive reactions difficult to replicate across different laboratories. Scaling up such sensitive reactions to an industrial level requires enormous efforts in process and operational control. Consequently, process engineers frequently seek alternative reactions that are less sensitive and more reliable whenever possible. Therefore, there is a strong demand for an AI system capable of pre-emptively assessing reaction robustness. However, this task is also extremely challenging. The main reasons lie in two aspects: firstly, to build such an AI system, a high-throughput and autonomous method to navigate the enormous chemical space is needed, but not attainable. Secondly, to understand the underlying uncertainty for organic reactions, fine-grained uncertainty analysis and disentanglement based on the results of chemical space exploration is necessary, however, there has been no such demonstration to dig the intrinsic stochasticity of chemical reactions systematically. To date, the problem of estimating the robustness of chemical reactions is still unsolved.\n\nIn this work, we demonstrate a synergistic and systematic solution based on high-throughput experimentation (HTE) and Bayesian deep learning to effectively tackle the challenges of feasibility and robustness estimation in organic reactions. We present (1) an extensive wetlab dataset based on an automated HTE platform developed by our team; (2) a model uncertainty-driven learning strategy to navigate a broad chemical space with minimal data requirements to predict reaction feasibility; and (3) a data uncertainty analysis procedure to grasp intrinsic stochasticity for the estimation of reaction robustness. The overall workflow described in this work is shown in Fig.\u00a0[1](https://www.nature.com/articles/s41467-025-59812-0#Fig1). Specifically, we focus on acid amine coupling reactions, which are most widely reported and used in organic synthesis, yet remain challenging to assess for feasibility and robustness, even for experienced bench chemists[12](https://www.nature.com/articles/s41467-025-59812-0#ref-CR12). We conduct 11,669 reactions for 8095 target products at 200\u2013300\u2009\u03bcL scale, covering 272 acids, 231 amines, 6 condensation reagents, 2 bases, and 1 solvent, on an in-house HTE platform within 156 instrument working hours to explore both the substrate and condition space of general acid amine condensation reactions rationally and globally. The overall chemical space explored is shown in Fig.\u00a0[2](https://www.nature.com/articles/s41467-025-59812-0#Fig2) a. To the best of our knowledge, this is the most extensive single reaction-type HTE dataset covering a broad chemical space at a volume scale practical for industrial delivery[13](https://www.nature.com/articles/s41467-025-59812-0#ref-CR13). It is also the HTE dataset that covers the most target products to date. Based on the HTE data, our Bayesian neural network (BNN) model achieves a feasibility prediction accuracy of 89.48% and an F1 score of 0.86, outperforming existing feasibility prediction approaches on broad chemical spaces. With fine-grained uncertainty disentanglement, we identify the modeling and chemical origins of prediction uncertainty and demonstrate that an active learning strategy saves \u00a0~\u200980% data for feasibility prediction. At the same time, we discover that extensive experimental exploration contributes to high-quality uncertainty estimation. We correlate the intrinsic data uncertainty with the robustness of chemical reactions. This is validated by the analysis of reactions reported on the mg scale and in the kg/ton scale in the literature. We note here that our work focuses on the reaction process without considering the feasibility or robustness during the separation process. Diverging from nearly all existing HTE works in organic synthesis, our approach demonstrated a potential way to combine HTE and Bayesian deep learning to systematically answer the questions about reaction feasibility and robustness, thus enabling highly efficient organic synthesis and scaling up.\n\n**Fig. 1: Overall workflow combining HTE and bayesian deep learning to estimate reaction feasibility and robustness against environmental factors.**\n\nWetlab data is collected using automated HTE, followed by probabilistic modeling using Bayesian neural networks. The uncertainty is disentangled into epistemic uncertainty and aleatoric uncertainty. Epistemic uncertainty originates from insufficient data and is used for further design of experiments (DoE). Aleatoric uncertainty is linked to the intrinsic noise of experimentation and is demonstrated to be an indicator of reaction robustness. We also found extensive HTE exploration enhances the quality of uncertainty estimation.\n\n[Full size image](https://www.nature.com/articles/s41467-025-59812-0/figures/1)\n\n**Fig. 2: Data analysis of the automated HTE data and substrate down-sampling process.**\n\n**a** Overvie...",
      "url": "https://www.nature.com/articles/s41467-025-59812-0"
    },
    {
      "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning",
      "text": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\n# The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\nToby Boyne1, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College, London, UK1\nDepartment of Chemistry, Imperial College, London, UK2\nSOLVE Chemistry, London, UK3t.boyne23@imperial.ac.uk;\u2020jose@solvechemistry.com\n###### Abstract\nMachine learning has promised to change the landscape of laboratory chemistry, with impressive results in molecular property prediction and reaction retro-synthesis. However, chemical datasets are often inaccessible to the machine learning community as they tend to require cleaning, thorough understanding of the chemistry, or are simply not available. In this paper, we introduce a novel dataset for yield prediction, providing the first-ever transient flow dataset for machine learning benchmarking, covering over 1200 process conditions. While previous datasets focus on discrete parameters, our experimental set-up allow us to sample a large number of continuous process conditions, generating new challenges for machine learning models. We focus on solvent selection, a task that is particularly difficult to model theoretically and therefore ripe for machine learning applications. We showcase benchmarking for regression algorithms, transfer-learning approaches, feature engineering, and active learning, with important applications towards solvent replacement and sustainable manufacturing.\n## 1Introduction\nMachine learning (ML) and artificial intelligence (AI) have showcased enormous potential in empowering the world of the natural sciences: from famous examples such as AlphaFold for protein predictions> [\n[> 1\n](https://arxiv.org/html/2506.07619v1#bib.bib1)> ]\n, to fusion reactor control> [\n[> 2\n](https://arxiv.org/html/2506.07619v1#bib.bib2)> ]\n, disease detection> [\n[> 3\n](https://arxiv.org/html/2506.07619v1#bib.bib3)> ]\n, battery design> [\n[> 4\n](https://arxiv.org/html/2506.07619v1#bib.bib4)> ]\n, and material discovery> [\n[> 5\n](https://arxiv.org/html/2506.07619v1#bib.bib5)> ]\n, among many more. However, we seldom see the machine learning community benchmark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how expensive the data can be to produce, resulting in many datasets being locked behind closed doors by large companies.\nAIchemy ([https://aichemy.ac.uk](https://aichemy.ac.uk)) is an interdisciplinary UK hub with the mission of transforming the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE Chemistry ([https://www.solvechemistry.com](https://www.solvechemistry.com)), we present a first important step into addressing the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data machine learning algorithms for chemistry.\nSolvent selection is one of the biggest challenges for chemical manufacturing, with solvents often being the main source of waste in the manufacturing process> [\n[> 6\n](https://arxiv.org/html/2506.07619v1#bib.bib6)> ]\n. Increased regulation on solvents and a drive to making process manufacturing more sustainable led to an interest in the discovery of greener solvents and for improved solvent replacement tools. However, most of the solvent replacement tools focus purely on learning unsupervised representations of solvents, with the hope that experimentalists can find solvents with similar properties to replace those with environmental concerns. A much stronger approach would consider the interaction of a variety of different solvents with a reaction of interest to directly predict reaction yields, in such a way that the best possible solvent can be selected according to a yield-sustainability trade-off.\nMachine learning approaches have been shown to be a powerful tool for the prediction of chemical reaction conditions. Success has been reported in retro-synthesis> [\n[> 7\n](https://arxiv.org/html/2506.07619v1#bib.bib7)> , [> 8\n](https://arxiv.org/html/2506.07619v1#bib.bib8)> ]\n, condition recommendations> [\n[> 9\n](https://arxiv.org/html/2506.07619v1#bib.bib9)> ]\n, product predictions> [\n[> 10\n](https://arxiv.org/html/2506.07619v1#bib.bib10)> , [> 11\n](https://arxiv.org/html/2506.07619v1#bib.bib11)> ]\n, among others. While yield prediction has proven to be more difficult due to large inconsistencies in procedure and data reporting> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\n, we have still seen promising yield prediction results for smaller and more carefully curated datasets> [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> , [> 14\n](https://arxiv.org/html/2506.07619v1#bib.bib14)> , [> 15\n](https://arxiv.org/html/2506.07619v1#bib.bib15)> , [> 16\n](https://arxiv.org/html/2506.07619v1#bib.bib16)> ]\n. However, these datasets lack the continuous reaction conditions, such as temperature and residence time, that are required to scale-up processes to practical manufacturing conditions.\nIn this paper, we release the first machine-learning-ready transient flow dataset, a framework that allows for quick and efficient screening of continuous reaction conditions. We specifically provide yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure[1](https://arxiv.org/html/2506.07619v1#S1.F1), with dense measurements across the residence time, temperature, and solvent space. We further showcase how this type ofkinetic dataposes new challenges to current machine learning methods for chemistry, and identify how the challenges can potentially be tackled by the community.\n![Refer to caption](extracted/6524982/figures/Project2_rxn.png)Figure 1:Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the reaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement products. We investigate the yield of the reaction for a range of different solvents. Product 1 was not observed and reacted immediately to form Product 2 and later 3.\n### 1.1Related works\nReaction datasets are common in chemistry research, but their suitability for machine learning benchmarking tends to be poor. This can be a result of improper formatting or documentation, incomplete information about reaction conditions or the experimental set-up, or the lack of machine readability, leading to limited usage by the ML community. However, some effort has been made to address this, with the biggest example being the creation of the Open Reaction Database (ORD)> [\n[> 17\n](https://arxiv.org/html/2506.07619v1#bib.bib17)> ]\n, a repository containing over 2M different reactions, many of which come from US patent data (USPTO)> [\n[> 18\n](https://arxiv.org/html/2506.07619v1#bib.bib18)> ]\n. However, the dataset falls short in some aspects, in particular with respect to machine learning readiness and data inconsistencies across reactions.\nORDerly> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\nallows for easy cleaning and preparation of ORD data, showing the promise of the dataset for forward and retro-synthetic prediction using transformers; however, it also shows that yield prediction cannot be done well due to data inconsistencies.> Schwaller et\u00a0al. [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> ]\ndrew similar conclusions when using the USPTO dataset, stating that reaction conditions such as temperature, concentrations, and duration have a significant effect on yield. The assumption that every reaction in the dataset is optimized for reaction param...",
      "url": "https://arxiv.org/html/2506.07619v1"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "",
      "text": "MetaRF: Differentiable Random Forest for Reaction\nYield Prediction with a Few Trails\nKexin Chen\nDepartment of Computer Science and Engineering\nThe Chinese University of Hong Kong\nNew Territories, Hong Kong SAR\nkxchen@cse.cuhk.edu.hk\nGuangyong Chen\u2217\nZhejiang Lab\nZhejiang University\nHangzhou, China\ngychen@zhejianglab.com\nJunyou Li\nZhejiang Lab\nHangzhou, China\nlijunyou@zhejianglab.com\nYuansheng Huang\nZhejiang Lab\nZhejiang University\nHangzhou, China\n22219109@zju.edu.cn\nPheng-Ann Heng\nDepartment of Computer Science and Engineering\nThe Chinese University of Hong Kong\nNew Territories, Hong Kong SAR\npheng@cse.cuhk.edu.hk\nAbstract\u2014Artificial intelligence has deeply revolutionized the\nfield of medicinal chemistry with many impressive applications,\nbut the success of these applications requires a massive amount of\ntraining samples with high-quality annotations, which seriously\nlimits the wide usage of data-driven methods. In this paper, we\nfocus on the reaction yield prediction problem, which assists\nchemists in selecting high-yield reactions in a new chemical space\nonly with a few experimental trials. To attack this challenge, we\nfirst put forth MetaRF, an attention-based differentiable random\nforest model specially designed for the few-shot yield prediction,\nwhere the attention weight of a random forest is automatically\noptimized by the meta-learning framework and can be quickly\nadapted to predict the performance of new reagents while given\na few additional samples. To improve the few-shot learning\nperformance, we further introduce a dimension-reduction based\nsampling method to determine valuable samples to be experimen\u0002tally tested and then learned. Our methodology is evaluated on\nthree different datasets and acquires satisfactory performance on\nfew-shot prediction. In high-throughput experimentation (HTE)\ndatasets, the average yield of our methodology\u2019s top 10 high-yield\nreactions is relatively close to the results of ideal yield selection.\nIndex Terms\u2014few-shot, yield prediction, random forest, meta\u0002learning\nI. INTRODUCTION\nComputer-aided synthesis planning (CASP) [1], which aims\nto assist chemists in synthesizing new molecule compounds,\nhas been rapidly transformed by artificial intelligence methods.\nGiven the availability of large-scale reaction datasets, such as\nthe United States Patent and Trademark Office (USPTO) [2],\nReaxys [3], and SciFinder [4], CASP has become an increas\u0002ingly popular topic in pharmaceutical discovery and organic\nchemistry with many impressive breakthroughs achieved [5].\nThe current CASP systems can be divided into two critical as\u0002pects, retrosynthetic planning and forward-reaction prediction\n[6]. Retrosynthetic planning, including template-based and\ntemplate-free methods, can help generate possible synthetic\nThis work is supported by XXX(Grant No. XXX).\n*Correspondence author: Guangyong Chen (gychen@zhejianglab.com);\nroutes of target molecules [7]. Forward-reaction prediction is\nmainly used to evaluate the strategies proposed by retrosyn\u0002thetic planning and increase the likelihood of experimental\nsuccess [8]. However, without considering reaction yield or\nreaction conditions, the synthetic strategies proposed in the\nCASP systems would be difficult to be implemented. It still\nremains a big challenge to predict the reaction yield. Due to\nthe complexity of chemical experiments, few solid theories can\nhelp predict the reaction yield of a new chemical reaction given\na specific condition, let alone optimize a reaction condition,\nwhich heavily depends on expertise, knowledge, intuition,\nnumerous practices, extensive literature reading and even the\nluck of chemists [5], [9].\nSome pioneer efforts have been contributed to predict the\nreaction yield, and then find the optimal reaction condition.\nNote that the optimal reaction selection problem can be natu\u0002rally treated as a classical out-of-distribution (OOD) problem,\nsince the optimal reaction is often not included in the training\nset. Ahneman et al. [10] reported that the random forest\nmodel achieved the best performance on OOD yield prediction\ndue to its good generalization ability. Zuranski et al. [11]\nreviewed and examined the OOD performance of different\nmachine learning algorithms and reaction embedding tech\u0002niques. Dong et al. [12] used the XGBoost model and achieved\nsatisfactory OOD performance. Zhu et al. [13] demonstrated\nthat regression-based machine learning had great application\npotential in OOD yield prediction. However, in OOD yield\nprediction, the relatively large difference between training and\ntesting data deteriorates the predicting performance of the\nmodel.\nIn this paper, we follow a more relaxed but practical setting,\nwhere we are allowed to add a few data of new reagents\nor conditions into the training set. Considering the limited\namount of reaction condition data, few-shot yield prediction\nhas great potential in solving this problem. Few-shot yield\nprediction adds very few reaction samples(e.g. around five\narXiv:2208.10083v1 [cs.LG] 22 Aug 2022\nsamples) from new reagents or conditions into training data. It\nis reasonable to hypothesize that using data of a new reagent\ncan improve prediction results. Questions yet to be explored\nare how to use these new samples, which sample to select, and\nhow much data from the new reagent leads to a satisfactory\nresult.\nTo bridge this gap, we proposed MetaRF, an attention\u0002based differentiable random forest model with a meta-learning\ntechnique applied to determine attention weights adaptively.\nThe random forest has been proved as an ensemble method\nwith outstanding performance on datasets with small sample\nsize [14], [15].\nHowever, the structure of random forest is non-differential,\nwhich is hard to combine with the gradient-based techniques\nin meta-learning. To solve this problem and achieve robust\nperformance on new reagents, we propose to add attention\nweights to the random forest through a meta-learning frame\u0002work, Model Agnostic Meta-Learning (MAML) algorithm\n[16]. The key idea of MAML is to train the model\u2019s initial pa\u0002rameters so that the model can quickly adapt to a new task after\nthe parameters have been updated through a few gradient steps\ncomputed with few-shot data from that new task [16]. MAML\nis applied to determine the attention weights of decision trees\nin the random forest so that the model can quickly adapt\nto predict the performance of new reagents using few-shot\ntraining samples. The choice of few-shot training samples also\nhas a significant influence on model performance. Few-shot\nlearning can have better-predicting performance if it is allowed\nto choose the training samples [17]. To tackle this challenge,\nwe use Kennard-Stone (KS) algorithm [18] to select the most\nrepresentative samples which cover the experimental space\nhomogeneously. Since the KS algorithm is based on Euclidean\ndistance, which suffers from the curse of dimensionality [19],\nT-distributed stochastic neighbor embedding (TSNE) [20] is\napplied for unsupervised nonlinear dimension reduction.\nOur methodology is comprehensively evaluated on\nBuchwald-Hartwig high-throughput experimentation (HTE)\ndataset [10], Buchwald-Hartwig electronic laboratory\nnotebooks (ELN) dataset [21] and Suzuki\u2013Miyaura HTE\ndataset [22]. In Buchwald\u2013Hartwig high-throughput\nexperimentation (HTE) dataset, our method achieves\nR2=0.648 using 2.5% of the dataset as the training set. To\nreach a comparable result, the baseline method (random\nforest) needs to use at least 20% of the dataset as the training\nset. With the help of 5 additional samples, our method\ncan effectively explore unseen chemical space and select\nhigh-yield reactions. The 10 reactions, which are predicted\nto have the highest yield, reach an average yield of 93.7%,\nrelatively close to the result of ideal yield selection (95.5%).\nIn contrast, the top 10 high-yield reactions selected by the\nbaseline method have an average yield of 86.3%, and the\naverage yield of random selection is 52.1%.\nThe overview framework of thi...",
      "url": "https://arxiv.org/pdf/2208.10083"
    },
    {
      "title": "",
      "text": "# Computer Science > Machine Learning\n\n**arXiv:2501.06669** (cs)\n\n\\[Submitted on 11 Jan 2025\\]\n\n# Title:Challenging reaction prediction models to generalize to novel chemistry\n\nAuthors: [John Bradshaw](https://arxiv.org/search/cs?searchtype=author&query=Bradshaw,+J), [Anji Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+A), [Babak Mahjour](https://arxiv.org/search/cs?searchtype=author&query=Mahjour,+B), [David E. Graff](https://arxiv.org/search/cs?searchtype=author&query=Graff,+D+E), [Marwin H.S. Segler](https://arxiv.org/search/cs?searchtype=author&query=Segler,+M+H), [Connor W. Coley](https://arxiv.org/search/cs?searchtype=author&query=Coley,+C+W)\n\nView a PDF of the paper titled Challenging reaction prediction models to generalize to novel chemistry, by John Bradshaw and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2501.06669) [HTML (experimental)](https://arxiv.org/html/2501.06669v1)\n\n> Abstract:Deep learning models for anticipating the products of organic reactions have found many use cases, including validating retrosynthetic pathways and constraining synthesis-based molecular design tools. Despite compelling performance on popular benchmark tasks, strange and erroneous predictions sometimes ensue when using these models in practice. The core issue is that common benchmarks test models in an in-distribution setting, whereas many real-world uses for these models are in out-of-distribution settings and require a greater degree of extrapolation. To better understand how current reaction predictors work in out-of-distribution domains, we report a series of more challenging evaluations of a prototypical SMILES-based deep learning model. First, we illustrate how performance on randomly sampled datasets is overly optimistic compared to performance when generalizing to new patents or new authors. Second, we conduct time splits that evaluate how models perform when tested on reactions published in years after those in their training set, mimicking real-world deployment. Finally, we consider extrapolation across reaction classes to reflect what would be required for the discovery of novel reaction types. This panel of tasks can reveal the capabilities and limitations of today's reaction predictors, acting as a crucial first step in the development of tomorrow's next-generation models capable of reaction discovery.\n\n|     |     |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Chemical Physics (physics.chem-ph) |\n| Cite as: | [arXiv:2501.06669](https://arxiv.org/abs/2501.06669) \\[cs.LG\\] |\n| (or [arXiv:2501.06669v1](https://arxiv.org/abs/2501.06669v1) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2501.06669](https://doi.org/10.48550/arXiv.2501.06669) <br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: John Bradshaw \\[ [view email](https://arxiv.org/show-email/47bd441c/2501.06669)\\] **\\[v1\\]**\nSat, 11 Jan 2025 23:49:14 UTC (2,297 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Challenging reaction prediction models to generalize to novel chemistry, by John Bradshaw and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2501.06669)\n- [HTML (experimental)](https://arxiv.org/html/2501.06669v1)\n- [TeX Source](https://arxiv.org/src/2501.06669)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2501.06669&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2501.06669&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2025-01](https://arxiv.org/list/cs.LG/2025-01)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2501.06669?context=cs) [physics](https://arxiv.org/abs/2501.06669?context=physics) [physics.chem-ph](https://arxiv.org/abs/2501.06669?context=physics.chem-ph)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2501.06669)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2501.06669)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2501.06669)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2501.06669) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2501.06669"
    },
    {
      "title": "Low-data regime yield predictions with uncertainty estimation using deep learning approaches for ACS Fall 2021",
      "text": "Authors Low-data regime yield predictions with uncertainty estimation using deep learning approaches for ACS Fall 2021 https://research.ibm.com/publications/low-data-regime-yield-predictions-with-uncertainty-estimation-using-deep-learning-approaches\nLow-data regime yield predictions with uncertainty estimation using deep learning approaches for ACS Fall 2021\nAuthors\n2021-08-22T00:00:00Z\n## Abstract\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, have successfully become part of the organic chemists\u2019 daily laboratory work, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could help chemists navigate reaction space, optimize reactions, and accelerate the design of more effective routes. Here, we investigate high-throughput experimentation data sets and show how data augmentation on chemical reactions can improve yield predictions\u2019 accuracy, even when only small training sets are available. Previous work used molecular fingerprints, physics-based or categorical descriptors of the precursors. In our work, we fine-tune natural language processing-inspired reaction transformer models on different augmented data sets to predict yields solely using a text-based representation of chemical reactions. When the augmented training sets contain 2.5% or more of the data, our models outperform previous models, including those using physics-based descriptors as inputs. Moreover, we demonstrate the use of test-time augmentation to generate uncertainty estimates, which correlate with the prediction errors.\n## Related\nPaper\n### [Will OLED displays challenge liquid crystal displays in notebook computer applications?](https://research.ibm.com/publications/will-oled-displays-challenge-liquid-crystal-displays-in-notebook-computer-applications)\nRonald Troutman\nSynthetic Metals\nPaper\n### [Effect of oxygen on the electrical transport in RuO2](https://research.ibm.com/publications/effect-of-oxygen-on-the-electrical-transport-in-ruolessinfgreater2lessinfgreater)\nL. Krusin-Elbaum\nThin Solid Films\nPaper\n### [Kinetic model for the chemical vapor deposition of tungsten in the silane reduction process](https://research.ibm.com/publications/kinetic-model-for-the-chemical-vapor-deposition-of-tungsten-in-the-silane-reduction-process)\nJulian J. Hsieh\nJournal of Vacuum Science and Technology A: Vacuum, Surfaces and Films\nTalk\n### [On the automation of de-novo molecular design and chemical synthesis planning: A case study on SARS-CoV-2](https://research.ibm.com/publications/on-the-automation-of-de-novo-molecular-design-and-chemical-synthesis-planning-a-case-study-on-sars-cov-2)\nJannis Born, Matteo Manica, et al.\nACS Fall 2021\n[View all publications](https://research.ibm.com/publications)",
      "url": "https://research.ibm.com/publications/low-data-regime-yield-predictions-with-uncertainty-estimation-using-deep-learning-approaches"
    },
    {
      "title": "On the use of real-world datasets for reaction yield prediction",
      "text": "<div><div>\n \n <main>\n \n <article><section></section><section><section><h2>Abstract</h2>\n<p>The lack of publicly available, large, and unbiased datasets is a key bottleneck for the application of machine learning (ML) methods in synthetic chemistry. Data from electronic laboratory notebooks (ELNs) could provide less biased, large datasets, but no such datasets have been made publicly available. The first real-world dataset from the ELNs of a large pharmaceutical company is disclosed and its relationship to high-throughput experimentation (HTE) datasets is described. For chemical yield predictions, a key task in chemical synthesis, an attributed graph neural network (AGNN) performs as well as or better than the best previous models on two HTE datasets for the Suzuki\u2013Miyaura and Buchwald\u2013Hartwig reactions. However, training the AGNN on an ELN dataset does not lead to a predictive model. The implications of using ELN data for training ML-based models are discussed in the context of yield predictions.</p></section><section><hr/>\n<p>An attributed graph neural network predicts the yield of Suzuki\u2013Miyaura and Buchwald\u2013Hartwig reactions for datasets from high-throughput experimentation (HTE) but not for a more diverse real-world dataset from electronic lab notebooks (ELNs).<a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10189898_d2sc06041h-ga.jpg\"></a></p></section><section><h2>Introduction</h2>\n<p>The development of predictive methods is a long-standing goal of computational chemistry. Initially, physics based modeling techniques such as DFT or force field methods were used to understand reaction mechanisms and predict <em>e.g.</em> the stereochemical outcome of reactions<sup><a href=\"#cit1\">1</a></sup> or suitable catalysts for their acceleration.<sup><a href=\"#cit2\">2</a></sup> More recently, machine leaning (ML) methods<sup><a href=\"#cit3\">3</a></sup> have been used to predict the likely products of reactions (forward synthesis prediction)<sup><a href=\"#cit4\">4,5</a></sup> and promising pathways for the synthesis of organic molecules with a range of complexity.<sup><a href=\"#cit6\">6\u20139</a></sup></p>\n<p>The prediction of yields of chemical reactions is a particularly challenging task because it is influenced not only by the variables of the reaction under study, but also by all possible side reactions. At the same time, it is an extremely important task due to the significant effort needed to optimize the yield of a reaction by variation of reaction conditions and catalysts. Doyle and coworkers<sup><a href=\"#cit10\">10\u201312</a></sup> sought to address this challenge for the case of predicting the effect of heterocyclic poisons on the yield of the widely used Buchwald\u2013Hartwig amination by training a ML model on a dataset of 4608 reactions from high-throughput experimentation (HTE). Using a random forest (RF) model and computed physics-based features such as NMR shifts or HOMO/LUMO energies, an <em>R</em><sup>2</sup> of 0.92 was achieved (<a href=\"#fig1\">Fig. 1 A</a>). More complex models such as neural networks did not provide higher predictivity.<sup><a href=\"#cit10\">10</a></sup> Fu <em>et al.</em><sup><a href=\"#cit13\">13</a></sup> used a dataset of 387 Suzuki\u2013Miyaura reactions<sup><a href=\"#cit14\">14</a></sup> and features from DFT calculations to train a deep neural network, resulting in a model with an <em>R</em><sup>2</sup> of 0.92. Both HTE datasets have subsequently been successfully used in a range of ML models for yield predictions.<sup><a href=\"#cit15\">15\u201317</a></sup> Bayesian optimizers<sup><a href=\"#cit18\">18,19</a></sup> and deep reinforcement learning<sup><a href=\"#cit20\">20</a></sup> were also successful in the iterative optimization of reaction conditions for a variety of reactions. As will be discussed in more detail below, the use of HTE datasets in ML predictions has some significant drawbacks in that these datasets represent a very narrow part of the reaction space, are very time- and resource intensive and present challenges with overfitting of the models.</p>\n<figure><h3>Fig. 1. Previous work on yield predictions using ML models: (A) HTE-generated datasets using random forest models<sup><a href=\"#cit18\">18</a></sup> (B) HTE (blue) and USPTO derived (red) datasets using the BERT model.<sup><a href=\"#cit22\">22</a></sup>.</h3>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=10189898_d2sc06041h-f1.jpg\"></a></p>\n</figure><p>In contrast, the use of legacy datasets from published scientific or patent literature for yield prediction has been less successful. The attempt to classify reaction yields as above or below 65% based on a training set of \u223c10<sup>6</sup> reactions from the Reaxys database using a large number of descriptors and ML methods gave an accuracy of 65 \u00b1 5%, <em>i.e.</em> a 35% error.<sup><a href=\"#cit21\">21</a></sup> The authors of that study attributed this finding to the deficiencies of \u201ccurrently available chemical descriptors\u201d, but it should also be noted that the reaction space represented in their dataset is vast. Schwaller <em>et al.</em><sup><a href=\"#cit22\">22</a></sup> developed a modification of the bidirectional encoder representations from transformers (BERT) model,<sup><a href=\"#cit23\">23</a></sup> which uses natural language processing to build a reaction SMILES encoder trained on a large corpus of reactions, followed by a classification or regression layer for a specific task. This approach was successful for product predictions<sup><a href=\"#cit5\">5</a></sup> as well as for reaction yield predictions of the Suzuki\u2013Miyaura (blue in <a href=\"#fig1\">Fig. 1B</a>) and Buchwald\u2013Hartwig reactions.<sup><a href=\"#cit22\">22</a></sup> While this approach achieves <em>R</em><sup>2</sup> values of 0.81 and 0.95, respectively, in line with other ML models when trained on these HTE datasets,<sup><a href=\"#cit10\">10,24</a></sup> training on a dataset of Suzuki\u2013Miyaura reactions from the US Patent database (USPTO)<sup><a href=\"#cit22\">22,25</a></sup> led to a maximum <em>R</em><sup>2</sup> score of 0.388 (red in <a href=\"#fig1\">Fig. 1B</a>). When the training set was limited to reactions run on a gram scale, the <em>R</em><sup>2</sup> value dropped further to 0.277, which was attributed to the strong bias of this dataset towards high-yielding reactions.<sup><a href=\"#cit22\">22</a></sup> Similarly, a recent study on the predictions of optimal conditions by Burke and Grzybowski showed that even when limiting the dataset to a single reaction, in their case 16\u2009748 Suzuki\u2013Miyaura reactions curated from the literature, a range of ML models did not perform better than a model based only on the popularity of a set of reaction conditions.<sup><a href=\"#cit26\">26</a></sup> Finally, Reymond and coworkers<sup><a href=\"#cit27\">27</a></sup> constructed a more qualitative \u201cdata-driven cheat-sheet\u201d for the recommendation of conditions for the Buchwald\u2013Hartwig reaction based on a dataset of 62\u2009000 examples from a variety of databases.</p>\n<p>Taken together, these previous findings highlight the challenges in using legacy datasets to train ML yield prediction models. As in other areas of ML, there is a lack of suitable datasets to train and validate the models. Although most of the chemical literature is summarized in commercial databases, they are proprietary. The USPTO, which was converted into a widely used dataset,<sup><a href=\"#cit4\">4</a></sup> and the recently introduced Open Reaction Database<sup><a href=\"#cit28\">28</a></sup> are exceptions. As a result, studies using commercial databases do not include the data the models were built with.<sup><a href=\"#cit27\">27,29</a></sup> Furthermore, databases such as Reaxys frequently do not contain complete reaction information and reflect the bias of the published literature towards high-yielding r...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10189898"
    },
    {
      "title": "Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates",
      "text": "[Jump to main content ![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#maincontent) [Jump to site search ![](https://www.rsc-cdn.org/oxygen/assets/icons/arrow-right-o-light.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#SearchText)\n\n[Issue 7, 2024](https://pubs.rsc.org/en/journals/journal/sc?issueid=sc015007&type=current&issnprint=2041-6520)\n\n[![](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=CoverIssue&imageInfo.ImageIdentifier.SerCode=SC&imageInfo.ImageIdentifier.IssueId=SC015007)\\\n\\\nFrom the journal: **Chemical Science**](https://pubs.rsc.org/en/journals/journal/sc)\n\n## Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates [\u2020](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a\\#fn1)\n\n![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg)\n\n[Yunsie\\\nChung](https://pubs.rsc.org/en/results?searchtext=Author%3AYunsie%20Chung) [![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0002-3097-010X)_a_\nand\n[William H.\\\nGreen](https://pubs.rsc.org/en/results?searchtext=Author%3AWilliam%20H.%20Green)[![ORCID logo](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/orcid_16x16.png)](https://orcid.org/0000-0003-2603-9694)\n\\*_a_\n\n[Author affiliations](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n\\\\* Corresponding authors\n\naDepartment of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA\n\n**E-mail:** [whgreen@mit.edu](mailto:whgreen@mit.edu)\n\n### Abstract\n\nFast and accurate prediction of solvent effects on reaction rates are crucial for kinetic modeling, chemical process design, and high-throughput solvent screening. Despite the recent advance in machine learning, a scarcity of reliable data has hindered the development of predictive models that are generalizable for diverse reactions and solvents. In this work, we generate a large set of data with the COSMO-RS method for over 28\u2006000 neutral reactions and 295 solvents and train a machine learning model to predict the solvation free energy and solvation enthalpy of activation (\u0394\u0394 _G_\u2021solv, \u0394\u0394 _H_\u2021solv) for a solution phase reaction. On unseen reactions, the model achieves mean absolute errors of 0.71 and 1.03 kcal mol\u22121 for \u0394\u0394 _G_\u2021solv and \u0394\u0394 _H_\u2021solv, respectively, relative to the COSMO-RS calculations. The model also provides reliable predictions of relative rate constants within a factor of 4 when tested on experimental data. The presented model can provide nearly instantaneous predictions of kinetic solvent effects or relative rate constants for a broad range of neutral closed-shell or free radical reactions and solvents only based on atom-mapped reaction SMILES and solvent SMILES strings.\n\n![Graphical abstract: Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates](https://pubs.rsc.org/en/Image/Get?imageInfo.ImageType=GA&imageInfo.ImageIdentifier.ManuscriptID=D3SC05353A&imageInfo.ImageIdentifier.Year=2024)\n\n- This article is part of the themed collections:\n[#MyFirstChemSci 2024](https://pubs.rsc.org/en/journals/articlecollectionlanding?sercode=sc&themeid=26a1e262-5929-453c-b3a7-f61b43147ce2) and [Most popular 2024 physical, theoretical and computational chemistry articles](https://pubs.rsc.org/en/journals/articlecollectionlanding?sercode=sc&themeid=777d3e88-b794-457a-8932-5995aa89df7b)\n\nThis article is Open Access\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\nPlease wait while we load your content...\nSomething went wrong. [Try again?](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n[About](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlAbstract)\n\n[Cited by](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlCitation)\n\n[Related](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a#pnlRelatedContent)\n\n[Download options Please wait...](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n## Supplementary files\n\n- [Supplementary information\\\nPDF (4245K)](https://www.rsc.org/suppdata/d3/sc/d3sc05353a/d3sc05353a1.pdf)\n\n## Transparent peer review\n\nTo support increased transparency, we offer authors the option to publish the peer review history alongside their article.\n\n[View this article\u2019s peer review history](https://www.webofscience.com/api/gateway/wos/peer-review/10.1039/D3SC05353A)\n\n## Article information\n\nDOI[https://doi.org/10.1039/D3SC05353A](https://doi.org/10.1039/D3SC05353A)\n\n**Article type**Edge Article\n\nSubmitted10 Oct 2023\n\nAccepted04 Jan 2024\n\nFirst published10 Jan 2024\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/open-access-icon-orange.png)\n\n**This article is Open Access**\n\nAll publication charges for this article have been paid for by the Royal Society of Chemistry[![Creative Commons BY license](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/CCBY.svg)](http://creativecommons.org/licenses/by/3.0/)\n\n### Download Citation\n\n_**Chem. Sci.**_, 2024, **15**, 2410-2424\n\nBibTexEndNoteMEDLINEProCiteReferenceManagerRefWorksRIS\n\n### Permissions\n\n[Request permissions](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n### Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\n\nY. Chung and W. H. Green,\n_Chem. Sci._, 2024,\u00a0**15**, 2410\n**DOI:** 10.1039/D3SC05353A\n\nThis article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](https://creativecommons.org/licenses/by/3.0/). **You can use material from this article**\n**in other publications without requesting further permissions** from the RSC, provided that the\ncorrect acknowledgement is given.\n\nRead more about [how to correctly acknowledge RSC content](https://www.rsc.org/journals-books-databases/journal-authors-reviewers/licences-copyright-permissions/#acknowledgements).\n\n[![](https://www.rsc-cdn.org/oxygen/assets/icons/cross.png)](https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a)\n\n### Social activity\n\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/twitter.svg)Tweet](https://twitter.com/intent/tweet/?text=Machine+learning+from+quantum+chemistry+to+predict+experimental+solvent+effects+on+reaction+rates+-+now+published+in+Chemical+Science&url=https%3a%2f%2fpubs.rsc.org%2fen%2fcontent%2farticlelanding%2f2024%2fsc%2fd3sc05353a)\n\n[![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/wechat.svg)Share](https://pubs.rsc.org/en/Image/GetQrCode?url=https%3A%2F%2Fpubs.rsc.org%2Fen%2Fcontent%2Farticlelanding%2F2024%2Fsc%2Fd3sc05353a)\n\n## Search articles by author\n\nYunsie Chung\n\nWilliam H. Green\n\n![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\nFetching data from CrossRef.\n\nThis may take some time to load.\n\nLoading related content![](https://www.rsc-cdn.org/pubs-core/2022.0.171/content/NewImages/Ajax-GA-Loader.gif)\n\n### Spotlight\n\n### Advertisements\n\nThis website collects cookies to deliver a better user experience.\nSee how this site uses [Cookies](https://pubs.rsc.org/en/content/cookies).\n[Do not sell my personal data](https://pubs.rsc.org/en/content/cookies).\n\nEste site coleta cookies para oferecer uma melhor experi\u00eancia ao usu\u00e1rio.\nVeja como este site usa [Cookies](https://pubs.rsc.org/en/content/cookies).",
      "url": "https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc05353a"
    }
  ]
}