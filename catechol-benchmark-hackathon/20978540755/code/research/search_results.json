{
  "query": "How can multi-task learning loss weighting improve prediction for targets with different variances in neural networks?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Multi\u2011task learning (MTL) combines several objectives into a single network, but when the targets have very different variances (e.g., one loss in the tens and another in the\u202f100\u202f000s) the raw losses dominate the gradient of the larger\u2011scale task and the smaller\u2011scale task is ignored.  A principled way to avoid this is to weight each task\u2019s loss by its **homoscedastic uncertainty** (the task\u2011specific variance that is independent of the input).  Kendall\u202fet\u202fal. show that a regression loss can be written as  \n\n\\[\nL_i=\\frac{1}{2\\sigma_i^{2}}\\|y_i-\\hat y_i\\|^{2}+ \\log\\sigma_i ,\n\\]\n\nwhere \\(\\sigma_i^{2}\\) is learned jointly with the network parameters.  The inverse\u2011variance term automatically down\u2011weights noisy (high\u2011variance) targets and up\u2011weights precise (low\u2011variance) ones, allowing the shared representation to be trained with balanced gradients and often surpassing separately trained single\u2011task models ([CVPR\u202f2018](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf)).  \n\nLater work extends this idea with **dynamic weight averaging (DWA)** and analytical uncertainty\u2011based schemes that adjust weights according to the relative rate of loss decrease, further stabilising training when tasks evolve at different speeds ([arXiv\u202f2024\u201108\u201115](https://arxiv.org/html/2408.07985v1)).  In the traffic\u2011scene domain, an uncertainty\u2011weighting module that generates adaptive weights from task\u2011specific uncertainties has been shown to improve semantic\u2011segmentation and depth\u2011prediction accuracy under real\u2011world variance differences ([Nature\u202fSci\u202fRep\u202f2025](https://www.nature.com/articles/s41598-025-24838-3)).  \n\nEven simple heuristic approaches, such as learning a scalar weight for each MSE loss (as discussed on the PyTorch forum), can be interpreted as approximating the inverse\u2011variance weighting and help prevent one loss from overwhelming the other ([PyTorch\u202fForums\u202f2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315)).  Overall, loss\u2011weighting mechanisms that account for task\u2011specific variance align the optimisation landscape, reduce gradient imbalance, and lead to more accurate predictions for all targets in a multi\u2011task neural network.",
      "url": ""
    },
    {
      "title": "[PDF] Multi-Task Learning Using Uncertainty to Weigh Losses for Scene ...",
      "text": "Multi-Task Learning Using Uncertainty to Weigh Losses\nfor Scene Geometry and Semantics\nAlex Kendall\nUniversity of Cambridge\nagk34@cam.ac.uk\nYarin Gal\nUniversity of Cambridge\nyg279@cam.ac.uk\nRoberto Cipolla\nUniversity of Cambridge\nrc10001@cam.ac.uk\nAbstract\nNumerous deep learning applications benefit from multi\u0002task learning with multiple regression and classification ob\u0002jectives. In this paper we make the observation that the\nperformance of such systems is strongly dependent on the\nrelative weighting between each task\u2019s loss. Tuning these\nweights by hand is a difficult and expensive process, mak\u0002ing multi-task learning prohibitive in practice. We pro\u0002pose a principled approach to multi-task deep learning\nwhich weighs multiple loss functions by considering the ho\u0002moscedastic uncertainty of each task. This allows us to si\u0002multaneously learn various quantities with different units\nor scales in both classification and regression settings. We\ndemonstrate our model learning per-pixel depth regression,\nsemantic and instance segmentation from a monocular in\u0002put image. Perhaps surprisingly, we show our model can\nlearn multi-task weightings and outperform separate mod\u0002els trained individually on each task.\n1. Introduction\nMulti-task learning aims to improve learning efficiency\nand prediction accuracy by learning multiple objectives\nfrom a shared representation [7]. Multi-task learning is\nprevalent in many applications of machine learning \u2013 from\ncomputer vision [27] to natural language processing [11] to\nspeech recognition [23].\nWe explore multi-task learning within the setting of vi\u0002sual scene understanding in computer vision. Scene under\u0002standing algorithms must understand both the geometry and\nsemantics of the scene at the same time. This forms an in\u0002teresting multi-task learning problem because scene under\u0002standing involves joint learning of various regression and\nclassification tasks with different units and scales. Multi\u0002task learning of visual scene understanding is of crucial\nimportance in systems where long computation run-time is\nprohibitive, such as the ones used in robotics. Combining\nall tasks into a single model reduces computation and allows\nthese systems to run in real-time.\nPrior approaches to simultaneously learning multiple\ntasks use a na\u00a8\u0131ve weighted sum of losses, where the loss\nweights are uniform, or manually tuned [38, 27, 15]. How\u0002ever, we show that performance is highly dependent on an\nappropriate choice of weighting between each task\u2019s loss.\nSearching for an optimal weighting is prohibitively expen\u0002sive and difficult to resolve with manual tuning. We observe\nthat the optimal weighting of each task is dependent on the\nmeasurement scale (e.g. meters, centimetres or millimetres)\nand ultimately the magnitude of the task\u2019s noise.\nIn this work we propose a principled way of combining\nmultiple loss functions to simultaneously learn multiple ob\u0002jectives using homoscedastic uncertainty. We interpret ho\u0002moscedastic uncertainty as task-dependent weighting and\nshow how to derive a principled multi-task loss function\nwhich can learn to balance various regression and classifica\u0002tion losses. Our method can learn to balance these weight\u0002ings optimally, resulting in superior performance, compared\nwith learning each task individually.\nSpecifically, we demonstrate our method in learning\nscene geometry and semantics with three tasks. Firstly, we\nlearn to classify objects at a pixel level, also known as se\u0002mantic segmentation [32, 3, 42, 8, 45]. Secondly, our model\nperforms instance segmentation, which is the harder task of\nsegmenting separate masks for each individual object in an\nimage (for example, a separate, precise mask for each in\u0002dividual car on the road) [37, 18, 14, 4]. This is a more\ndifficult task than semantic segmentation, as it requires not\nonly an estimate of each pixel\u2019s class, but also which object\nthat pixel belongs to. It is also more complicated than ob\u0002ject detection, which often predicts object bounding boxes\nalone [17]. Finally, our model predicts pixel-wise metric\ndepth. Depth by recognition has been demonstrated using\ndense prediction networks with supervised [15] and unsu\u0002pervised [16] deep learning. However it is very hard to esti\u0002mate depth in a way which generalises well. We show that\nwe can improve our estimation of geometry and depth by\nusing semantic labels and multi-task deep learning.\nIn existing literature, separate deep learning models\n17482\nEncoder\nSemantic\nDecoder\nInput Image\nMulti-Task\nLoss\nInstance\nDecoder\nDepth\nDecoder\nSemantic\nTask\nUncertainty\nInstance\nTask\nUncertainty\nDepth\nTask\nUncertainty\n\u03a3\nFigure 1: Multi-task deep learning. We derive a principled way of combining multiple regression and classification loss functions for\nmulti-task learning. Our architecture takes a single monocular RGB image as input and produces a pixel-wise classification, an instance\nsemantic segmentation and an estimate of per pixel depth. Multi-task learning can improve accuracy over separately trained models because\ncues from one task, such as depth, are used to regularize and improve the generalization of another domain, such as segmentation.\nwould be used to learn depth regression, semantic segmen\u0002tation and instance segmentation to create a complete scene\nunderstanding system. Given a single monocular input im\u0002age, our system is the first to produce a semantic segmenta\u0002tion, a dense estimate of metric depth and an instance level\nsegmentation jointly (Figure 1). While other vision mod\u0002els have demonstrated multi-task learning, we show how to\nlearn to combine semantics and geometry. Combining these\ntasks into a single model ensures that the model agrees be\u0002tween the separate task outputs while reducing computa\u0002tion. Finally, we show that using a shared representation\nwith multi-task learning improves performance on various\nmetrics, making the models more effective.\nIn summary, the key contributions of this paper are:\n1. a novel and principled multi-task loss to simultane\u0002ously learn various classification and regression losses\nof varying quantities and units using homoscedastic\ntask uncertainty,\n2. a unified architecture for semantic segmentation, in\u0002stance segmentation and depth regression,\n3. demonstrating the importance of loss weighting in\nmulti-task deep learning and how to obtain superior\nperformance compared to equivalent separately trained\nmodels.\n2. Related Work\nMulti-task learning aims to improve learning efficiency\nand prediction accuracy for each task, when compared to\ntraining a separate model for each task [40, 5]. It can be con\u0002sidered an approach to inductive knowledge transfer which\nimproves generalisation by sharing the domain information\nbetween complimentary tasks. It does this by using a shared\nrepresentation to learn multiple tasks \u2013 what is learned from\none task can help learn other tasks [7].\nFine-tuning [1, 36] is a basic example of multi-task\nlearning, where we can leverage different learning tasks by\nconsidering them as a pre-training step. Other models al\u0002ternate learning between each training task, for example in\nnatural language processing [11]. Multi-task learning can\nalso be used in a data streaming setting [40], or to prevent\nforgetting previously learned tasks in reinforcement learn\u0002ing [26]. It can also be used to learn unsupervised features\nfrom various data sources with an auto-encoder [35].\nIn computer vision there are many examples of methods\nfor multi-task learning. Many focus on semantic tasks, such\nas classification and semantic segmentation [30] or classifi\u0002cation and detection [38]. MultiNet [39] proposes an archi\u0002tecture for detection, classification and semantic segmenta\u0002tion. CrossStitch networks [34] explore methods to com\u0002bine multi-task neural activations. Uhrig et al. [41] learn\nsemantic and instance segmentations under a classification\nsetting. Multi-task deep learning has also been used for ge\u0002ometry and regression tasks. [15] show how to learn se\u0002mantic segmentation, depth and su...",
      "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf"
    },
    {
      "title": "Analytical Uncertainty-Based Loss Weighting in Multi-Task Learning",
      "text": "arXiv reCAPTCHA\n[![Cornell University](https://static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n[We gratefully acknowledge support from\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)\n# [![arxiv logo](https://static.arxiv.org/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)",
      "url": "https://arxiv.org/html/2408.07985v1"
    },
    {
      "title": "Uncertainty weighted multi task learning for robust traffic scene ...",
      "text": "Uncertainty weighted multi task learning for robust traffic scene semantic understanding | Scientific Reports\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Scientific Reports](https://media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg)](https://www.nature.com/srep)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41598-025-24838-3?error=cookies_not_supported&code=e609cee7-5763-4ef1-b725-c2f49f84c9ba)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41598)\n* [RSS feed](https://www.nature.com/srep.rss)\nUncertainty weighted multi task learning for robust traffic scene semantic understanding\n[Download PDF](https://www.nature.com/articles/s41598-025-24838-3.pdf)\n[Download PDF](https://www.nature.com/articles/s41598-025-24838-3.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:20 November 2025# Uncertainty weighted multi task learning for robust traffic scene semantic understanding\n* [Zhiping Wan](#auth-Zhiping-Wan-Aff1)[1](#Aff1),\n* [Shitong Ye](#auth-Shitong-Ye-Aff2)[2](#Aff2),\n* [Feng Wang](#auth-Feng-Wang-Aff1)[1](#Aff1),\n* [Shaojiang Liu](#auth-Shaojiang-Liu-Aff1)[1](#Aff1)&amp;\n* \u2026* [Ling Peng](#auth-Ling-Peng-Aff3)[3](#Aff3)Show authors\n[*Scientific Reports*](https://www.nature.com/srep)**volume15**, Article\u00a0number:40993(2025)[Cite this article](#citeas)\n* 874Accesses\n* [Metricsdetails](https://www.nature.com/articles/s41598-025-24838-3/metrics)\n### Subjects\n* [Engineering](https://www.nature.com/subjects/engineering)\n* [Mathematics and computing](https://www.nature.com/subjects/mathematics-and-computing)\n## Abstract\nThis paper addresses perception degradation caused by adverse weather, occlusion, and asynchronous sampling by proposing an uncertainty-weighted multi-task learning framework for robust semantic understanding of traffic scenes (UW-MTL). The method performs differentiable multi-source spatiotemporal alignment to unify camera, LiDAR, radar, and IMU into a BEV sequence, and adopts a hybrid backbone that combines a Mixture of Experts Transformer with a spatiotemporal graph neural network to balance global semantics and local topology. Each task employs evidential prediction heads that explicitly output confidence and uncertainty. During training, soft-temperature weighting and a sigma aware gradient conflict resolver enable stable joint optimization. On the nuScenes benchmark, UW-MTL consistently surpasses BEVFusion and UniAD on 3D object detection, BEV semantic segmentation, and short-horizon trajectory prediction, with especially pronounced gains at long range, under heavy occlusion, and in low-visibility conditions.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42256-022-00520-5/MediaObjects/42256_2022_520_Fig1_HTML.png)\n### [Deep learning-based robust positioning for all-weather autonomous driving](https://www.nature.com/articles/s42256-022-00520-5?fromPaywallRec=false)\nArticleOpen access08 September 2022\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41597-025-05603-7/MediaObjects/41597_2025_5603_Fig1_HTML.png)\n### [HDSVT: High-Density Semantic Vehicle Trajectory Dataset Based on a Cosmopolitan City Bridge](https://www.nature.com/articles/s41597-025-05603-7?fromPaywallRec=false)\nArticleOpen access27 December 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-023-43458-3/MediaObjects/41598_2023_43458_Fig1_HTML.jpg)\n### [Multi-object detection for crowded road scene based on ML-AFP of YOLOv5](https://www.nature.com/articles/s41598-023-43458-3?fromPaywallRec=false)\nArticleOpen access12 October 2023\n## Introduction\nIntelligent transportation is transitioning from a human-driven paradigm to a software-defined system centered on perception and decision-making. To operate safely on real urban roads, perception modules must not only identify vehicles, pedestrians, cyclists, and dynamic obstacles, but also understand road semantics under varying weather and lighting conditions, including drivable areas, lane markings, median strips, intersection topology, and the resulting traffic constraints[1](https://www.nature.com/articles/s41598-025-24838-3#ref-CR1),[2](https://www.nature.com/articles/s41598-025-24838-3#ref-CR2). Unlike controlled environments, urban roads are subject to adverse factors such as rain, fog, strong reflections, low illumination at night, high-speed vehicle intersections, long-tail vehicle shapes, and heavy occlusions. Sensors themselves also suffer from measurement noise and field-of-view limitations[3](https://www.nature.com/articles/s41598-025-24838-3#ref-CR3),[4](https://www.nature.com/articles/s41598-025-24838-3#ref-CR4). Single-modal approaches are prone to failure in such scenarios, making multi-modal fusion the mainstream trend. To enhance efficiency and global consistency, an increasing number of studies are integrating detection, segmentation, depth estimation, and trajectory prediction into a multi-task learning framework within the feature space of a bird\u2019s-eye view[5](#ref-CR5),[6](#ref-CR6),[7](https://www.nature.com/articles/s41598-025-24838-3#ref-CR7), aiming to capture the semantic and geometric characteristics of traffic scenes in a shared representation.\nCurrently, multi-task learning methods for transportation scenarios still face three fundamental challenges[8](#ref-CR8),[9](#ref-CR9),[10](https://www.nature.com/articles/s41598-025-24838-3#ref-CR10). The first challenge is the contradiction between the differentiability and accuracy of cross-modal spatio-temporal alignment. The sampling frequency, exposure delay, and external parameter errors of cameras, lidars, millimeter-wave radars, and inertial navigation systems can all lead to coordinate mismatches. If the alignment is not differentiable, end-to-end training will be difficult to correct. If the alignment is coarse, the fusion effect will be limited by artifacts. The second challenge is gradient conflicts and resource competition among multi-tasks. Detection prioritizes the consistency of object contours and scales, segmentation emphasizes the fineness of regional boundaries, depth estimation relies on geometric priors, and trajectory prediction requires temporal continuity and interactive modeling. These objectives often exhibit conflicting optimization directions on a shared backbone, leading to negative transfer. The third category involves the measurement and utilization of uncertainty. Observational uncertainty stems from sensor noise and occlusion, while model uncertainty is related to data coverage and capacity. If uncertainty is not incorporated into optimization and routing, it is difficult to suppress noise dominance during training and to provide risk-aware confidence for planning and control during inference.\nThe current unified BEV representation demonstrates advantages in terms of geometric consistency and convenience for downstream tasks, but it typically requires a trade-off between precise spatio-temporal alignment and end-to-end trainability. Multi-task learning offers significant benefits in terms of parameter sharing and efficiency, but fixed weights or heuristic weights often become unstable in...",
      "url": "https://www.nature.com/articles/s41598-025-24838-3"
    },
    {
      "title": "Balance between 2 MSE losses - PyTorch Forums",
      "text": "[Skip to main content](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315#main-container)\n\n# [Balance between 2 MSE losses](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315)\n\nYou have selected **0** posts.\n\n[select all](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315)\n\n[cancel selecting](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315)\n\n1.4kviews\n2links\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/ays/48/56534_2.png)5](https://discuss.pytorch.org/u/ays)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/innovarul/48/5282_2.png)2](https://discuss.pytorch.org/u/InnovArul)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/j_johnson/48/55494_2.png)2](https://discuss.pytorch.org/u/J_Johnson)\n\n[![](https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/k/ecb155/48.png)](https://discuss.pytorch.org/u/KFrank)\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/1)\n\n2 / 10\n\nJul 2023\n\n[Aug 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/10)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/ays/48/56534_2.png)](https://discuss.pytorch.org/u/ays)\n\n[ays](https://discuss.pytorch.org/u/ays)\n\n1\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315)\n\nI have an MLP and trying to predict 2 values from the MLP (so i\u2019m doing a multi task learning). these values have two losses of different scales (one is in the tens and the other is in 100,000s). so I cant simply add the losses together before back propagating. I\u2019m currently trying to learn a weight so I can use it to balance the losses but I dont know how do go about that. Below is a brief summary of the code\n\n```\n\nclass MLP(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 100)\n        self.out1 = nn.Linear(100, output_dim - 1)\n        self.out2 = nn.Linear(100, 1)\n        self.relu = nn.ReLU()\n\n        #create a learnable parameter that is used to weight the two losses\n        self.weight = nn.Parameter(torch.ones(1, requires_grad=True))\n\n\n\n    def forward(self, x):\n        out1 = self.out1(self.relu(self.fc1(x)))\n        out2 = self.out2(self.relu(self.fc1(x)))\n        return out1, out2, self.weight\n\n#in train method (assume we have the target values and data)\npredicted_one, predicted_two, weight = model(data)\n\nloss_one = nn.Functional.mse_loss(predicted_one, target_one)\nloss_two = nn.Functional.mse_loss(predicted_two, target_two)\n\ntotal_loss = loss_one + weight * loss_two\n\n```\n\nI dont think this is how to go about it because the the weight doesn\u2019t learn. Please Kindly assist.\n\n1.4kviews\n2links\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/ays/48/56534_2.png)5](https://discuss.pytorch.org/u/ays)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/innovarul/48/5282_2.png)2](https://discuss.pytorch.org/u/InnovArul)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/j_johnson/48/55494_2.png)2](https://discuss.pytorch.org/u/J_Johnson)\n\n[![](https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/k/ecb155/48.png)](https://discuss.pytorch.org/u/KFrank)\n\n[![](https://discuss.pytorch.org/letter_avatar_proxy/v4/letter/k/ecb155/48.png)](https://discuss.pytorch.org/u/KFrank)\n\n[KFrank](https://discuss.pytorch.org/u/KFrank)\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/2)\n\nHi Ays!\n\nIf it were me, I would just treat `weight` as a hyperparameter to be tuned\n\nby hand.\n\nThere is, however, a proposed `MultiTaskLoss` (that I have never used) that\n\nseems to be a theoretically-sound approach to automatically tuning the\n\nrelative weight between two losses.\n\nHere is an implementation:\n\nAnd here is the paper about the scheme that is referenced in the code:\n\nBest.\n\nK. Frank\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/ays/48/56534_2.png)](https://discuss.pytorch.org/u/ays)\n\n[ays](https://discuss.pytorch.org/u/ays)\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/3)\n\nHi Frank. Thanks a lot for your response. I tried using the Multi-task Learning approach but im getting a loss as in the graph below.\n\n[![image](https://discuss.pytorch.org/uploads/default/optimized/3X/6/3/63175de3898dd71b44196545e147c3051d9fb207_2_1380x480.jpeg)\\\nimage1878\u00d7654 90.9 KB](https://discuss.pytorch.org/uploads/default/original/3X/6/3/63175de3898dd71b44196545e147c3051d9fb207.jpeg)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/innovarul/48/5282_2.png)](https://discuss.pytorch.org/u/InnovArul)\n\n[InnovArul](https://discuss.pytorch.org/u/InnovArul)[Arul](https://discuss.pytorch.org/u/InnovArul)\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/4)\n\nSilly question:\n\nDid you try normalizing the target values?\n\n(say with -1 to 1, maybe `tanh()` final layer + MSE loss / L1 loss, and during inference, rescale the values accordingly)\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/ays/48/56534_2.png)](https://discuss.pytorch.org/u/ays)\n\n[ays](https://discuss.pytorch.org/u/ays)\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/5)\n\nHi Arul,\n\nThanks for the suggestion. So my first loss has target values ranging between 0 and 1, my second loss has target values ranging between 0 and 4202496. So do you mean I should normalise the second target variable to values between 0 and 1? if yes, does that mean I wouldn\u2019t need a weight in the loss because it would be of the same scale?\n\nNB: sorry I\u2019m a bit new to all these so its still trying to get a hang of it.\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/innovarul/48/5282_2.png)](https://discuss.pytorch.org/u/InnovArul)\n\n[InnovArul](https://discuss.pytorch.org/u/InnovArul)[Arul](https://discuss.pytorch.org/u/InnovArul)\n\n1\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/6)\n\nNo worries. We all are learning:)\n\nYes, I meant to keep both the target variables on the same scale. (either \\[0,1\\] or \\[-1,1\\]).\n\nThe method proposed by Kendall et. al\u2019s paper is from a different perspective to learn to weigh the losses based on the uncertainties (if the variance of a particular loss is very high, its contribution to the gradients will be low and vice versa). I would still keep it (or you can experiment without it too).\n\nPlease let me know how it goes.\n\n[![](https://discuss.pytorch.org/user_avatar/discuss.pytorch.org/j_johnson/48/55494_2.png)](https://discuss.pytorch.org/u/J_Johnson)\n\n[J\\_Johnson](https://discuss.pytorch.org/u/J_Johnson)\n\n1\n\n[Jul 2023](https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315/7)\n\nHere is a simple function you can apply to normalize 2 or more rewards in order to balance various objectives:\n\n```\n\nimport torch\n\ndef norm_rewards(raw_rewards, alphas, freq_weights, max_clip, scale = 1.):\n    raw_rewards = torch.clip(raw_rewards, max = max_clip)\n    return torch.sum(alphas*freq_weights*raw_rewards/max_clip)*scale\n\nraw_rewards = torch.tensor([0.5, 2_000_000.]) # these are the dynamic raw rewards from each objective\nalphas = torch.tensor([2., 1.]) #this should be priority of each reward; if all equal, can use torch.ones_like(raw_rewards)\nfreq_weights = torch.tensor([4., 1.]) #this should be the inverse of the frequency the reward occurs, i.e. 25% of the time would be 4. and 100% of the time would be 1.\nmax_clip = torch.tensor([1., 4_202_496.]) #this should be the max expected value of each reward and can also be used to clamp reward values for stability\nscale = 1. #optional scale value which scales the overall reward\n\nprint(norm_rewards(raw_rewards, alphas, freq_weights, max_clip, scale))\n\n```\n\nJust to clarify the difference between the freq\\_weights and the alphas. The alphas are what you do to set priority of a given objective. I\u2019ll give an example from ...",
      "url": "https://discuss.pytorch.org/t/balance-between-2-mse-losses/185315"
    },
    {
      "title": "Multitask Learning Based on Improved Uncertainty Weighted Loss ...",
      "text": "## 1\\. Introduction\n\nChanges in meteorological factors (such as wind speed, temperature, humidity, precipitation, etc.) have a profound impact on human life. Accurate prediction of future meteorological elements can be widely used in people\u2019s daily life, transportation, agriculture, forestry and animal husbandry, disaster-causing weather avoidance, and other fields. At the same time, accurate prediction of meteorological elements can provide forward-looking guidance for extreme weather warnings, military analysis, and future investment, thus helping various departments to make advance coordination arrangements according to weather changes \\[ [1](http://www.mdpi.com/www.mdpi.com#B1-atmosphere-13-00989)\\].\n\nIn the early stage, scholars used statistical algorithms and model prediction methods to predict meteorological elements \\[ [2](http://www.mdpi.com/www.mdpi.com#B2-atmosphere-13-00989), [3](http://www.mdpi.com/www.mdpi.com#B3-atmosphere-13-00989)\\], i.e., using weather science, dynamics, and other meteorological theories to investigate the changing patterns of the corresponding elements under the initial and boundary conditions. Since the construction of such models generally requires the application of a large number of assumptions, there are many limitations and discrepancies with the actual situation. Therefore, some scholars have introduced statistical-based algorithms \\[ [4](http://www.mdpi.com/www.mdpi.com#B4-atmosphere-13-00989), [5](http://www.mdpi.com/www.mdpi.com#B5-atmosphere-13-00989)\\]. Such algorithms infer the probability of occurrence of a phenomenon in a future period by counting the frequency of a phenomenon in a specific situation in a past period. However, such algorithms are subject to some errors brought about by statistics itself, making the accuracy of the prediction suffer to some extent. In the last decade, with the continuous upgrading of relevant meteorological observation facilities, the amount of data and the types of meteorological parameters obtained from observations have increased geometrically \\[ [6](http://www.mdpi.com/www.mdpi.com#B6-atmosphere-13-00989)\\]. The huge amount of data and the wide variety of data types have led to the fact that traditional algorithms such as statistical algorithms and model prediction methods can no longer meet the demand for real-time prediction of multi-parameter meteorological data. In contrast, with the great breakthroughs in information technology and intelligent algorithm techniques, artificial intelligence (AI) technologies have produced quite mature results in the fields of machine learning, image recognition, and big data analysis. Therefore, researchers are also actively exploring new ideas for applying AI techniques to the field of multi-parameter meteorological data prediction \\[ [7](http://www.mdpi.com/www.mdpi.com#B7-atmosphere-13-00989), [8](http://www.mdpi.com/www.mdpi.com#B8-atmosphere-13-00989), [9](http://www.mdpi.com/www.mdpi.com#B9-atmosphere-13-00989), [10](http://www.mdpi.com/www.mdpi.com#B10-atmosphere-13-00989), [11](http://www.mdpi.com/www.mdpi.com#B11-atmosphere-13-00989)\\].\n\nSingle-task learning methods have been widely used in previous research on multi-parameter meteorological data prediction \\[ [12](http://www.mdpi.com/www.mdpi.com#B12-atmosphere-13-00989), [13](http://www.mdpi.com/www.mdpi.com#B13-atmosphere-13-00989)\\]. The idea of using single-task learning for meteorological data prediction is to decompose a complex meteorological problem into simple and mutually independent subproblems solved individually and then combining the results to obtain the results of the initial complex problem. This may seem reasonable, but it is inappropriate. On the one hand, the subproblems of the meteorological prediction problem are often interrelated and linked by some common factors or common representations \\[ [14](http://www.mdpi.com/www.mdpi.com#B14-atmosphere-13-00989)\\]. If the multi-parameter meteorological data prediction problem is treated as multiple independent single tasks, the rich information such as associations, conflicts, and constraints between parameters will be ignored. On the other hand, in previous studies using single-task learning methods for prediction multi-parameter meteorological data, artificially selected meteorological parameters with strong correlations are usually used for forecasting to guarantee the prediction results. This operation discards the correlation information between the selected parameters and other parameters, which weakens the generalization performance of the model. When the prediction task contains multiple weakly correlated meteorological parameters, the single-task learning approach is no longer applicable. We refer to this phenomenon as the correlation dependence problem of the prediction parameters.\n\nMultitask learning is an important class of machine learning paradigms that aims to improve the generalization of the main task with other related tasks. In simple terms, multitask learning is an integrated learning approach that allows multiple tasks to influence each other by training several tasks simultaneously. Usually, this influence is achieved by sharing parameters, i.e., multiple tasks share a feature-sharing layer, and the parameters in this feature-sharing layer are influenced by all tasks at optimization time \\[ [15](http://www.mdpi.com/www.mdpi.com#B15-atmosphere-13-00989)\\]. By designing different feature-sharing layers for subtasks, the parameter-sharing process between different features can be artificially intervened, which is called the asymmetric sharing mechanism of multitask learning. Compared to single-task learning, multitask learning has the advantages of reduced computational resource usage, faster inference, and improved overall performance and generalization capabilities. At the same time, the asymmetric sharing mechanism endows multitask learning with higher flexibility. Therefore, we believe that the neural network design based on prior knowledge and the asymmetric sharing mechanism is expected to solve the correlation dependence problem of prediction parameters in single-task learning and provide a new solution for the prediction of complex correlation meteorological data.\n\nCurrently, only a few studies in the field of meteorological data prediction have used multitask learning methods. Lucas Borges Ferreira et al. \\[ [16](http://www.mdpi.com/www.mdpi.com#B16-atmosphere-13-00989)\\] evaluated different approaches based on temperature and relative humidity and temperature estimation of ETo using multitask models and single-task models. Yang Han et al. \\[ [17](http://www.mdpi.com/www.mdpi.com#B17-atmosphere-13-00989)\\] proposed a multitask machine learning model to re-estimate official air quality data during the recent BSD using PM data reported by the U.S. Embassy in Beijing and proxy data covering aerosol optical depth (AOD) and meteorology. Qiang Zhang et al. \\[ [18](http://www.mdpi.com/www.mdpi.com#B18-atmosphere-13-00989)\\] combined deep learning with multitask learning to propose a hybrid model for air quality prediction and proved experimentally that the model has good temporal stability and generalization ability. The introduction of multitask learning methods in the field of meteorological data prediction is novel and efficient, but due to the nature of meteorological data and multitask learning, there are still problems such as over-sensitivity to outliers, failure of simultaneous convergence of the tasks, and degradation of multitask learning to single-task learning. This is due to the following reasons: Simultaneous prediction tasks for multi-parameter meteorological data involve the joint learning of multiple regression tasks with different numerical scales, which creates an interesting multitask learning problem. Previously, multitask learning methods used simple loss-weighted summation, where the loss weights for each task were uniform or manually adjusted. Recently, it ...",
      "url": "https://www.mdpi.com/2073-4433/13/6/989"
    },
    {
      "title": "[PDF] Impartial Multi-task Representation Learning via Variance-invariant ...",
      "text": "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 19883\u201319897\nJuly 27 - August 1, 2025 \u00a92025 Association for Computational Linguistics\nImpartial Multi-task Representation Learning via Variance-invariant\nProbabilistic Decoding\nDou Hu1,2and Lingwei Wei1* and Wei Zhou1and Songlin Hu1,2*\n1\nInstitute of Information Engineering, Chinese Academy of Sciences\n2 School of Cyber Security, University of Chinese Academy of Sciences\n{hudou, weilingwei, zhouwei, husonglin}@iie.ac.cn\nAbstract\nMulti-task learning (MTL) enhances efficiency\nby sharing representations across tasks, but\ntask dissimilarities often cause partial learn\u0002ing, where some tasks dominate while others\nare neglected. Existing methods mainly focus\non balancing loss or gradients but fail to funda\u0002mentally address this issue due to the represen\u0002tation discrepancy in latent space. In this paper,\nwe propose variance-invariant probabilistic de\u0002coding for multi-task learning (VIP-MTL), a\nframework that ensures impartial learning by\nharmonizing representation spaces across tasks.\nVIP-MTL decodes shared representations into\ntask-specific probabilistic distributions and ap\u0002plies variance normalization to constrain these\ndistributions to a consistent scale. Experiments\non two language benchmarks show that VIP\u0002MTL outperforms 12 representative methods\nunder the same multi-task settings, especially\nin heterogeneous task combinations and data\u0002constrained scenarios. Further analysis shows\nthat VIP-MTL is robust to sampling distribu\u0002tions, efficient on optimization process, and\nscale-invariant to task losses. Additionally,\nthe learned task-specific representations are\nmore informative, enhancing the language un\u0002derstanding abilities of pre-trained language\nmodels under the multi-task paradigm.\n1 Introduction\nMulti-task learning (MTL) has emerged as a pow\u0002erful paradigm in machine learning, enabling mod\u0002els to jointly learn multiple tasks together from\nthe shared representations (Caruana, 1997; Kendall\net al., 2018). Unlike single-task learning, MTL\nparadigm not only allows the learned representa\u0002tions to simultaneously make predictions for sev\u0002eral tasks, but also reduces computation costs and\nimproves efficiency (Royer et al., 2023).\nHowever, a persistent challenge in MTL stems\nfrom the inherent task dissimilarity, which often\n*Corresponding author.\nleads to the partial learning problem (Liu et al.,\n2021b). This occurs when the model dispropor\u0002tionately prioritizes certain tasks while neglecting\nothers, resulting in suboptimal overall performance.\nIn multi-task learning, the latent variable distribu\u0002tions of different tasks are often inconsistent. For\nexample, the latent variable distribution of Task A\nmay have a larger variance, while the latent variable\ndistribution of Task B may have a smaller variance.\nThis discrepancy can cause the representations of\nTask A to dominate the optimization process, while\nthe representations of Task B is neglected.\nExisting methods (Kendall et al., 2018; Chennu\u0002pati et al., 2019; Liu et al., 2019a; Yu et al., 2020;\nLiu et al., 2021b; Lin et al., 2022) primarily fo\u0002cus on balancing task losses or gradients but fail\nto address the fundamental misalignment in repre\u0002sentations. Balancing losses adjusts task weights\nheuristically, yet it cannot resolve scale dispari\u0002ties in latent spaces. Similarly, gradient balancing\nharmonizes parameter updates during backpropaga\u0002tion. However, gradients are inherently influenced\nby the statistical properties of representations (e.g.,\nmagnitude, variance). If representations are im\u0002balanced, gradients will inevitably reflect this bias.\nSpecifically, high-variance tasks generate larger\ngradients, perpetuating their dominance despite\ngradient normalization efforts. These limitations\nare particularly pronounced in scenarios involving\nheterogeneous tasks or limited data, where the dis\u0002parities in task complexity and data availability\nexacerbate the imbalance. Therefore, balancing\nrepresentations offers a more principled and effec\u0002tive solution to the partiality problem in MTL.\nIn this paper, we introduce a multi-task rep\u0002resentation learning framework named variance\u0002invariant probabilistic decoding (VIP-MTL), which\ntackles the partial learning problem in MTL by\nharmonizing representation spaces across tasks.\nSpecifically, VIP-MTL decodes task-agnostic\nshared representations into task-specific probabilis\u000219883\ntic distributions, where each point in the distribu\u0002tion corresponds to a potential task-specific rep\u0002resentation. Unlike prior methods that focus on\nloss or gradient balancing, VIP-MTL operates at\nthe level of representation balancing, ensuring im\u0002partial learning on representation spaces for all\ntasks. To address the issue of scale variance across\ntasks, we apply variance normalization on proba\u0002bilistic distributions, adaptively constraining them\nto a consistent scale. By aligning the representation\ndistributions, VIP-MTL prevents any single task\nfrom dominating the shared representation space\nand ensures that the influence of each task remains\nbalanced during training.\nWe conduct experiments on two multi-task\nbenchmarks, TweetEval and AffectEval for lan\u0002guage understanding. The former includes 6 clas\u0002sification tasks, while the latter involves 2 classifi\u0002cation tasks and 2 regression tasks in a heteroge\u0002neous multi-task setting. The results show that our\nVIP-MTL consistently surpasses 12 representative\nmethods across different pre-trained language mod\u0002els (PLMs) under the same multi-task settings. For\nexample, with the RoBERTa backbone, VIP-MTL\nimproves the average relative improvement (\u2206p) by\n+5.06% on TweetEval and +7.66% on AffectEval,\nand improves the average performance (Avg.) by\n+2.92% on TweetEval and +3.76% on AffectEval,\ncompared to the EW baseline. Compared to single\ntask learning baselines, VIP-MTL also achieves\nbetter results on most tasks with the same scale of\nmodel parameters. Further analysis shows that our\nmethod is robust to sampling distributions, efficient\non optimization process, and scale-invariant to task\nlosses. Extensive experiments demonstrate that\nVIP-MTL offers significant advantages in hetero\u0002geneous task combinations and data-constrained\nscenarios. Additionally, the learned task-specific\nrepresentations are more informative, enhancing\nthe language understanding abilities of PLMs un\u0002der the multi-task paradigm.\nThe contributions are as follows: 1) We intro\u0002duce a new idea of balancing representations to ad\u0002dress the partial learning problem in MTL, which is\na significant departure from existing works that fo\u0002cus on balancing losses or gradients. 2) We propose\na probabilistic framework VIP-MTL to ensure im\u0002partial learning in MTL by harmonizing representa\u0002tion spaces across tasks. It decodes shared represen\u0002tations into task-specific probabilistic distributions\nand applies variance normalization ensure these\ndistributions maintain a consistent scale. 3) Experi-\n(a) Vanilla MTL paradigm\n(b) VIP-MTL (ours)\nFigure 1: Comparison of vanilla MTL paradigm and the\nproposed VIP-MTL. The deterministic decoder maps\neach vector point to a fixed vector, while the probabilis\u0002tic decoder maps each point to a probability distribution.\nments on two language understanding benchmarks\nshow that our method outperforms 12 representa\u0002tive methods under the same multi-task settings,\nespecially in heterogeneous and data-constrained\nscenarios. Further analysis shows that VIP-MTL\nis distribution-robust, efficient, scale-invariant, and\nthe learned task-specific representations are more\ninformative for all tasks.1\n2 Preliminary\nScope of the Study. The goal of this paper is to\nstudy multi-task optimization that typically utilizes\na hard parameter-sharing setting (Caruana, 1993),\nwhere several lightweight task-specific heads are\nattached to a heavyweight task-agnostic backbone\nmodel. Another orthogonal line of research on\nmulti-task learning mainly emphasizes designing\nof netwo...",
      "url": "https://aclanthology.org/2025.acl-long.975.pdf"
    },
    {
      "title": "A Comparison of Loss Weighting Strategies for Multi task Learning in Deep Neural Networks",
      "text": "Received August 22, 2019, accepted September 20, 2019, date of publication September 25, 2019, date of current version October 10, 2019.\nDigital Object Identifier 10.1109/ACCESS.2019.2943604\nA Comparison of Loss Weighting Strategies for\nMulti task Learning in Deep Neural Networks\nTING GONG , TYLER LEE, CORY STEPHENSON, VENKATA RENDUCHINTALA,\nSUCHISMITA PADHY, ANTHONY NDIRANGO,\nGOKCE KESKIN, AND OGUZ H. ELIBOL\nIntel AI Lab, Santa Clara, CA 95054, USA\nCorresponding author: Ting Gong (ting.gong@intel.com)\nABSTRACT With the success of deep learning in a wide variety of areas, many deep multi-task learning\n(MTL) models have been proposed claiming improvements in performance obtained by sharing the learned\nstructure across several related tasks. However, the dynamics of multi-task learning in deep neural networks\nis still not well understood at either the theoretical or experimental level. In particular, the usefulness of\ndifferent task pairs is not known a priori. Practically, this means that properly combining the losses of\ndifferent tasks becomes a critical issue in multi-task learning, as different methods may yield different\nresults. In this paper, we benchmarked different multi-task learning approaches using shared trunk with task\nspecific branches architecture across three different MTL datasets. For the first dataset, i.e. Multi-MNIST\n(Modified National Institute of Standards and Technology database), we thoroughly tested several weighting\nstrategies, including simply adding task-specific cost functions together, dynamic weight average (DWA)\nand uncertainty weighting methods each with various amounts of training data per-task. We find that multi\u0002task learning typically does not improve performance for a user-defined combination of tasks. Further\nexperiments evaluated on diverse tasks and network architectures on various datasets suggested that multi\u0002task learning requires careful selection of both task pairs and weighting strategies to equal or exceed the\nperformance of single task learning.\nINDEX TERMS Dynamic weighting average, multi-MNIST, multi-objective optimization, multi-task\nlearning, uncertainty weighting.\nI. INTRODUCTION\nThe goal of multi-task learning (MTL) is to learn multi\u0002ple different yet related tasks simultaneously [1]. Multi-task\nlearning has been studied across several fields in machine\nlearning. More recently it has been incorporated into a variety\nof deep neural network models, addressing problems in the\ndomains of vision [2], speech [3], natural language process\u0002ing [4], and reinforcement learning [5] [6]. The advantages\nof MTL are 1) the number of parameters in a multi-task\nmodel would be fewer than building multiple models each\nof which is optimized for their own individual tasks; and\n2) more importantly, models trained to accomplish many\ntasks simultaneously should be able to synergize to uncover\nthe common underlying structure, enabling better single-task\nperformance (STL) with smaller amounts of data per-task [7].\nAlthough MTL has shown impressive results on the\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Bora Onat.\ngeneralization performance on many tasks, existing MTL\nstudies mainly adopted manually designed feature shar\u0002ing or parameter sharing on a problem-by-problem basis [8].\nThe deep learning community still lacks common under\u0002standing or rules about \u2018what to share\u2018 and \u2018how to share\u2018,\ni.e., concrete ways to share knowledge among tasks [8].\nTo avoid conflicting gradients among tasks, a prevailing issue\nin MTL, recently researchers also realized that it is critical to\nfind appropriate weighting strategies for MTL so that the total\nempirical loss is minimized without the trade-off of learning\nindividual tasks [9]. In this work, we empirically evaluate\nseveral recently proposed MTL weighting strategies across\nseveral MTL benchmark datasets including the Multi-MNIST\ndataset, the NYU v2 dataset and the IMDB-WIKI dataset.\nThe weighting approaches we evaluated include uni\u0002form combination of losses from different tasks, dynamic\nweight average (DWA) [10] and uncertainty weighting meth\u0002ods [11] [12] with various amounts of training data per-task.\nThese controlled scenarios help us to frame the problem of\nVOLUME 7, 2019 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/ 141627\nT. Gong et al.: Comparison of Loss Weighting Strategies for MTL in Deep Neural Networks\nMTL in a manner which can be studied carefully and we\ncan draw significant insights from it reliably. In this paper,\nour analysis shows that MTL by combining multiple user\u0002defined tasks does not necessarily establish better perfor\u0002mance records than single task learning. In order to leverage\nthe knowledge and information across different tasks, we sug\u0002gest researchers carefully select related tasks and appropriate\nloss function weighting schemes to optimize the objective\nfunctions in MTL.\nInformation sharing can be achieved using various for\u0002malisms and architectures to perform multi-task learning in\ndeep learning [1]. Most existing approaches to multi-task\nlearning attempt to learn a single, yet non-trivial general\u0002purpose representation which is shared among tasks, while\nkeeping several task-specific output layers separate [13].\nThus, we will focus our discussion using this kind of deep\nlearning architecture with shared lower representation lay\u0002ers (trunk), and then fork into task-specific separate layers\n(heads) and losses for each task. Additionally, in [14], authors\ncategorized MTL into two sub-categories: homogeneous\nMTL vs. heterogeneous MTL. In homogeneous MTL, each\nhead performs the same type of task i.e., either classifica\u0002tion or regression task [15], while in heterogeneous MTL\neach head may perform different types of task simultane\u0002ously or in a sequential order [16]. We will investigate both\nscenarios in our experiments.\nOur contributions are as follows: a) To the best of our\nknowledge, this is the first meta-analysis that extensively\ncompares the different weighting approaches combining mul\u0002tiple loss functions in the context of both heterogeneous MTL\nand homogeneous MTL. b) The key observation is that MTL\napproaches which enforce shared data representations (by\nusing a shared feature extractor network) could show more\nefficacy when the training samples are sparse. c) We find\nthat many of the results obtained with any chosen set of\ntasks, which we refer to user-defined tasks, may not achieve\nperformance gains over single task learning (STL), which\ncalls the attention of the deep learning community for more\nrigorous theoretical analysis.\nThe remainder of this paper is organized as follows.\nSection 2 introduces datasets, experimental design and the\nweighting approaches we compared in our MTL experiments.\nIn Section 3, details of experiments and our results are pre\u0002sented. Finally, we make our conclusions in Section 4 and\ndiscuss future directions in MTL.\nII. DATASETS AND RELATED WORK FOR WEIGHTING\nMETHODS IN MTL\nA. DATASETS\nUntil now, many recent deep learning approaches have\nclaimed to observe an improvement in performance by shar\u0002ing learned structure across related tasks [13], [17], [18].\nIn this paper we investigate several multi-task learning meth\u0002ods and explore when they are most appropriate. MNIST\ndigit recognition is commonly used to evaluate classification\nalgorithms by casting it as 10 binary classification tasks [19].\nGiven our motivation, we use Multi-MNIST, an MTL ver\u0002sion of the MNIST dataset [15]. We follow the experimental\nsettings in [15] and overlay two randomly selected digits\ntogether to form the training sample. Each digit is shifted\nup to 4 pixels in each direction (left and right) resulting in\na 36\u00d736 pixel image. It is worth noting that we also use 60K\nsamples instead of 60M samples as done in [15] to directly\napply existing single-task MNIST models to Multi-MNIST.\nWe also evaluate ...",
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08848395.pdf?tp=&amp;arnumber=8848395&amp;isnumber=8600701&amp;ref=aHR0cHM6Ly9zY2hvbGFyLmdvb2dsZS5kZS8="
    },
    {
      "title": "(PDF) A Comparison of Loss Weighting Strategies for Multi task Learning in Deep Neural Networks",
      "text": "With the success of deep learning in a wide variety of areas, many deep multi-task learning (MTL) models have been proposed claiming improvements in performance obtained by sharing the learned structure across several related tasks. However, the dynamics of multi-task learning in deep neural networks is still not well understood at either the theoretical or experimental level. In particular, the usefulness of different task pairs is not known a priori. Practically, this means that properly combining the losses of different tasks becomes a critical issue in multi-task learning, as different methods may yield different results. In this paper, we benchmarked different multi-task learning approaches using shared trunk with task specific branches architecture across three different MTL datasets. For the first dataset, i.e. Multi-MNIST (Modified National Institute of Standards and Technology database), we thoroughly tested several weighting strategies, including simply adding task-specific cost functions together, dynamic weight average (DWA) and uncertainty weighting methods each with various amounts of training data per-task. We find that multi-task learning typically does not improve performance for a user-defined combination of tasks. Further experiments evaluated on diverse tasks and network architectures on various datasets suggested that multi-task learning requires careful selection of both task pairs and weighting strategies to equal or exceed the performance of single task learning.\n\nContent may be subject to copyright.\n\n**Discover the world's research**\n\n- 25+ million members\n- 160+ million publication pages\n- 2.3+ billion citations\n\n[Join for free](https://www.researchgate.net/publication/signup.SignUp.html)\n\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.\n\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI\n\n10.1109/ACCESS.2019.2943604, IEEE Access\n\nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\n\nDigital Object Identi\ufb01er 10.1109/ACCESS.2017.DOI\n\nA comparison of loss weighting\n\nstrategies for multi-task learning in deep\n\nneural networks\n\nTING GONG, TYLER LEE, CORY STEPHENSON, VENKATA RENDUCHINTALA1,\n\nSUCHISMITA PADHY, ANTHONY NDIRANGO, GOKCE KESKIN, OGUZ H. ELIBOL\n\nIntel AI Lab (USA), Santa Clara, CA 95054 USA\n\nCorresponding author: Ting Gong (e-mail: ting.gong@intel.com).\n\n1: completed the work while an intern at AIPG AI Lab, Intel, Santa Clara.\n\nABSTRACT With the success of deep learning in a wide variety of areas, many deep multi-task learning\n\n(MTL) models have been proposed claiming improvements in performance obtained by sharing the learned\n\nstructure across several related tasks. However, the dynamics of multi-task learning in deep neural networks\n\nis still not well understood at either the theoretical or experimental level. In particular, the usefulness of\n\ndifferent task pairs is not known a priori. Practically, this means that properly combining the losses of\n\ndifferent tasks becomes a critical issue in multi-task learning, as different methods may yield different\n\nresults. In this paper, we benchmarked different multi-task learning approaches using shared trunk with\n\ntask speci\ufb01c branches architecture across three different MTL datasets. For the \ufb01rst dataset, i.e. Multi-\n\nMNIST (Modi\ufb01ed National Institute of Standards and Technology database), we thoroughly tested several\n\nweighting strategies, including simply adding task-speci\ufb01c cost functions together, dynamic weight average\n\n(DWA) and uncertainty weighting methods each with various amounts of training data per-task. We \ufb01nd\n\nthat multi-task learning typically does not improve performance for a user-de\ufb01ned combination of tasks.\n\nFurther experiments evaluated on diverse tasks and network architectures on various datasets suggested that\n\nmulti-task learning requires careful selection of both task pairs and weighting strategies to equal or exceed\n\nthe performance of single task learning.\n\nINDEX TERMSDynamic weighting average, Multi-MNIST, Multi-objective optimization, Multi-task\n\nlearning, Uncertainty weighting\n\nI. INTRODUCTION\n\nTHE goal of multi-task learning (MTL) is to learn\n\nmultiple different yet related tasks simultaneously \\[1\\].\n\nMulti-task learning has been studied across several \ufb01elds in\n\nmachine learning. More recently it has been incorporated\n\ninto a variety of deep neural network models, addressing\n\nproblems in the domains of vision \\[2\\], speech \\[3\\], natural\n\nlanguage processing \\[4\\], and reinforcement learning \\[5\\] \\[6\\].\n\nThe advantages of MTL are 1) the number of parameters in\n\na multi-task model would be fewer than building multiple\n\nmodels each of which is optimized for their own individual\n\ntasks; and 2) more importantly, models trained to accomplish\n\nmany tasks simultaneously should be able to synergize to\n\nuncover the common underlying structure, enabling better\n\nsingle-task performance (STL) with smaller amounts of data\n\nper-task \\[7\\].\n\nAlthough MTL has shown impressive results on the gen-\n\neralization performance on many tasks, existing MTL stud-\n\nies mainly adopted manually designed feature sharing or\n\nparameter sharing on a problem-by-problem basis \\[8\\]. The\n\ndeep learning community still lacks common understanding\n\nor rules about \u2018what to share\u2018 and \u2018how to share\u2018, i.e.,\n\nconcrete ways to share knowledge among tasks \\[8\\]. To\n\navoid con\ufb02icting gradients among tasks, a prevailing issue\n\nin MTL, recently researchers also realized that it is critical\n\nto \ufb01nd appropriate weighting strategies for MTL so that the\n\ntotal empirical loss is minimized without the trade-off of\n\nlearning individual tasks \\[9\\]. In this work, we empirically\n\nevaluate several recently proposed MTL weighting strategies\n\nacross several MTL benchmark datasets including the Multi-\n\nMNIST dataset, the NYU v2 dataset and the IMDB-WIKI\n\ndataset.\n\nThe weighting approaches we evaluated include uniform\n\ncombination of losses from different tasks, dynamic weight\n\nVOLUME 4, 20161\n\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/.\n\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI\n\n10.1109/ACCESS.2019.2943604, IEEE Access\n\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n\naverage (DWA) \\[10\\] and uncertainty weighting methods \\[11\\]\n\n\\[12\\] with various amounts of training data per-task. These\n\ncontrolled scenarios help us to frame the problem of MTL in\n\na manner which can be studied carefully and we can draw\n\nsigni\ufb01cant insights from it reliably. In this paper, our analysis\n\nshows that MTL by combining multiple user-de\ufb01ned tasks\n\ndoes not necessarily establish better performance records\n\nthan single task learning. In order to leverage the knowl-\n\nedge and information across different tasks, we suggest re-\n\nsearchers carefully select related tasks and appropriate loss\n\nfunction weighting schemes to optimize the objective func-\n\ntions in MTL.\n\nInformation sharing can be achieved using various for-\n\nmalisms and architectures to perform multi-task learning in\n\ndeep learning \\[1\\]. Most existing approaches to multi-task\n\nlearning attempt to learn a single, yet non-trivial general-\n\npurpose representation which is shared among tasks, while\n\nkeeping several task-speci\ufb01c output layers separate \\[13\\].\n\nThus, we will focus our discussion using this kind of deep\n\nlearning architecture with shared lower representation lay-\n\ners (trunk), and then fork into task-speci\ufb01c separate layers\n\n(heads) and losses for each task. Additionally, in \\[14\\], authors\n\ncategorized MTL into two sub-categories: homogeneous...",
      "url": "https://www.researchgate.net/publication/336069340_A_Comparison_of_Loss_Weighting_Strategies_for_Multi_task_Learning_in_Deep_Neural_Networks"
    }
  ]
}