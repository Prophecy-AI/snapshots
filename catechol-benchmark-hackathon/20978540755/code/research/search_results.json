{
  "query": "How can sample weighting based on similarity to test distribution improve model generalization in chemical property prediction?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Sample weighting that reflects how similar each training molecule is to the molecules expected at test time directly tackles the train\u2011test distribution shift that is common in chemical property prediction.  By estimating a distance (e.g., the Wasserstein distance) between the empirical distribution of the training set\u202f\ud835\udcae and a reference set\u202f\ud835\udcaf that approximates the test distribution, a greedy re\u2011weighing algorithm can assign larger loss weights to training examples that lie in regions of feature space that are well\u2011represented in\u202f\ud835\udcaf and smaller weights to out\u2011of\u2011distribution points.  This reshapes the effective training distribution so that the limiting distribution of the network parameters after training on\u202f\ud835\udcae approaches the one that would have been obtained by training on\u202f\ud835\udcaf, even when the test labels are unavailable\u202f([research.google](https://research.google/pubs/enhancing-molecular-selectivity-using-wasserstein-distance-based-reweighing); [arxiv.org](https://arxiv.org/abs/2401.11562)).  The method comes with theoretical guarantees: when the metric entropy of the input data is bounded, the greedy scheme yields a near\u2011optimal weighting whose induced weight\u2011distribution distance is provably small in total\u2011variation\u202f([arxiv.org](https://arxiv.org/abs/2401.11562)).  In practice, re\u2011weighting dramatically improves selectivity\u2014e.g., a graph neural net trained to distinguish MNK2 binders from MNK1 non\u2011binders raised the fraction of top\u2011100 MNK2 binders that are MNK1 non\u2011binders from\u202f54\u202f% to\u202f95\u202f% while keeping overall loss unchanged\u202f([research.google](https://research.google/pubs/enhancing-molecular-selectivity-using-wasserstein-distance-based-reweighing)).\n\nThe benefit of similarity\u2011aware weighting is also reflected in broader evaluations of model generalizability.  Analyses that plot performance against decreasing cross\u2011split overlap (the \u201cSPECTRA\u201d framework) show that models tend to degrade as the similarity between training and test molecules drops, underscoring that explicit accounting for similarity can close this gap\u202f([biorxiv.org](https://www.biorxiv.org/content/10.1101/2024.02.25.581982v1.full)).  By up\u2011weighting samples that are chemically or feature\u2011wise close to the test domain, the model learns representations that are more robust to covariate shift, leading to more reliable predictions on out\u2011of\u2011distribution compounds\u2014a critical advantage for drug\u2011discovery pipelines where the most valuable molecules often lie beyond the original training set.",
      "url": ""
    },
    {
      "title": "Enhancing molecular selectivity using Wasserstein distance based reweighing",
      "text": "# Enhancing molecular selectivity using Wasserstein distance based reweighing\n[Pratik Worah](https://research.google/people/pratikworah/)\nRecomb 24 (2024)\n[Download](https://arxiv.org/abs/2401.11562) [Google Scholar](https://scholar.google.com/scholar?lr&ie=UTF-8&oe=UTF-8&q=Enhancing molecular selectivity using Wasserstein distance based reweighing Pratik Worah)\nCopy Bibtex\n### Abstract\nGiven a training data-set $\\\\mathcal{S}$, and a reference data-set $\\\\mathcal{T}$, we design a simple and efficient algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\\\mathcal{T}$. Such reweighing can be used to correct for Train-Test distribution shift, when we don't have access to the labels of $\\\\mathcal{T}$. It can also be used to perform (soft) multi-criteria optimization on neural nets, when we have access to the labels of $\\\\mathcal{T}$, but $\\\\mathcal{S}$ and $\\\\mathcal{T}$ have few common points.\nAs a motivating application, we train a graph neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a very similar protein), even in the absence of training data common to both data-sets. We are able to tune the reweighing parameters so that overall change in holdout loss is negligible, but the selectivity, i.e., the fraction of top 100 MNK2 binders that are MNK1 non-binders, increases from 54\\\\% to 95\\\\%, as a result of our reweighing.\nWe expect the algorithm to be applicable in other settings as well, since we prove that when the metric entropy of the input data-sets is bounded, our random sampling based greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance.\n### Research Areas\n- [Health & Bioscience](https://research.google/research-areas/health-bioscience/)\n- [Algorithms and Theory](https://research.google/research-areas/algorithms-and-theory/)\n## Learn more about how we conduct our research\nWe maintain a portfolio of research projects, providing individuals and teams the freedom to emphasize specific types of work.\n[Our research philosophy](https://research.google/philosophy/)\n![Philosophy-light-banner](https://storage.googleapis.com/gweb-research2023-media/images/Philosophy-light-banner.original.jpg)",
      "url": "https://research.google/pubs/enhancing-molecular-selectivity-using-wasserstein-distance-based-reweighing"
    },
    {
      "title": "Enhancing selectivity using Wasserstein distance based reweighing",
      "text": "# Statistics > Machine Learning\n\n**arXiv:2401.11562** (stat)\n\n\\[Submitted on 21 Jan 2024 ( [v1](https://arxiv.org/abs/2401.11562v1)), last revised 25 Feb 2025 (this version, v2)\\]\n\n# Title:Enhancing selectivity using Wasserstein distance based reweighing\n\nAuthors: [Pratik Worah](https://arxiv.org/search/stat?searchtype=author&query=Worah,+P)\n\nView a PDF of the paper titled Enhancing selectivity using Wasserstein distance based reweighing, by Pratik Worah\n\n[View PDF](https://arxiv.org/pdf/2401.11562) [HTML (experimental)](https://arxiv.org/html/2401.11562v2)\n\n> Abstract:Given two labeled data-sets $\\\\mathcal{S}$ and $\\\\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\\\\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\\\\mathcal{T}$.\n>\n> On the theoretical side, we prove that when the metric entropy of the input datasets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.\n>\n> As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1 (a highly similar protein). In our example dataset, of the 43 distinct small molecules predicted to be most selective from the enamine catalog, 2 small molecules were experimentally verified to be selective, i.e., they reduced the enzyme activity of MNK2 below 50\\\\% but not MNK1, at 10$\\\\mu$M -- a 5\\\\% success rate.\n\n|     |     |\n| --- | --- |\n| Subjects: | Machine Learning (stat.ML); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM) |\n| Cite as: | [arXiv:2401.11562](https://arxiv.org/abs/2401.11562) \\[stat.ML\\] |\n|  | (or [arXiv:2401.11562v2](https://arxiv.org/abs/2401.11562v2) \\[stat.ML\\] for this version) |\n|  | [https://doi.org/10.48550/arXiv.2401.11562](https://doi.org/10.48550/arXiv.2401.11562)<br>Focus to learn more<br>arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Pratik Worah \\[ [view email](https://arxiv.org/show-email/d4797b81/2401.11562)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2401.11562v1)**\nSun, 21 Jan 2024 18:43:18 UTC (143 KB)\n\n**\\[v2\\]**\nTue, 25 Feb 2025 18:28:31 UTC (358 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Enhancing selectivity using Wasserstein distance based reweighing, by Pratik Worah\n\n- [View PDF](https://arxiv.org/pdf/2401.11562)\n- [HTML (experimental)](https://arxiv.org/html/2401.11562v2)\n- [TeX Source](https://arxiv.org/src/2401.11562)\n- [Other Formats](https://arxiv.org/format/2401.11562)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2401.11562&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2401.11562&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2024-01](https://arxiv.org/list/stat.ML/2024-01)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2401.11562?context=cs)\n\n[cs.LG](https://arxiv.org/abs/2401.11562?context=cs.LG)\n\n[q-bio](https://arxiv.org/abs/2401.11562?context=q-bio)\n\n[q-bio.QM](https://arxiv.org/abs/2401.11562?context=q-bio.QM)\n\n[stat](https://arxiv.org/abs/2401.11562?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2401.11562)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2401.11562)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2401.11562)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2401.11562&description=Enhancing selectivity using Wasserstein distance based reweighing) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2401.11562&title=Enhancing selectivity using Wasserstein distance based reweighing)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2401.11562) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
      "url": "https://arxiv.org/abs/2401.11562"
    },
    {
      "title": "Evaluating generalizability of artificial intelligence models for molecular datasets",
      "text": "<div><div><div>\n <p><span>\n New Results </span></p> \n <div><p><span>, <span><span>Andrew</span> <span>Shen</span></span>, <span><span>Daria</span> <span>Bykova</span></span>, <span><span>Maximillian</span> <span>Marin</span></span>, <span><a href=\"http://orcid.org/0000-0001-8530-7228\"><span></span> <span>View ORCID Profile</span></a><span>Marinka</span> <span>Zitnik</span></span>, <span><span>Maha</span> <span>Farhat</span></span></span></p></div>\n \n <p><span><span>doi:</span> https://doi.org/10.1101/2024.02.25.581982 </span></p>\n \n \n </div>\n<div><div><h2>Abstract</h2><p>Deep learning has made rapid advances in modeling molecular sequencing data. Despite achieving high performance on benchmarks, it remains unclear to what extent deep learning models learn general principles and generalize to previously unseen sequences. Benchmarks traditionally interrogate model generalizability by generating metadata based (MB) or sequence-similarity based (SB) train and test splits of input data before assessing model performance. Here, we show that this approach mischaracterizes model generalizability by failing to consider the full spectrum of cross-split overlap, <em>i.e.</em>, similarity between train and test splits. We introduce SPECTRA, a spectral framework for comprehensive model evaluation. For a given model and input data, SPECTRA plots model performance as a function of decreasing cross-split overlap and reports the area under this curve as a measure of generalizability. We apply SPECTRA to 18 sequencing datasets with associated phenotypes ranging from antibiotic resistance in tuberculosis to protein-ligand binding to evaluate the generalizability of 19 state-of-the-art deep learning models, including large language models, graph neural networks, diffusion models, and convolutional neural networks. We show that SB and MB splits provide an incomplete assessment of model generalizability. With SPECTRA, we find as cross-split overlap decreases, deep learning models consistently exhibit a reduction in performance in a task- and model-dependent manner. Although no model consistently achieved the highest performance across all tasks, we show that deep learning models can generalize to previously unseen sequences on specific tasks. SPECTRA paves the way toward a better understanding of how foundation models generalize in biology.</p></div><div><h2>Main</h2><p>Understanding generalizability \u2013 how well a machine learning model performs on unseen data \u2013 is a fundamental challenge for the broad use of computation in biological discovery. In living cells, information flows from DNA to RNA to protein and dictates cell phenotypes. To model phenotypes, deep learning models are trained to predict biological relationships between and within sequences and the phenotype. This approach has been successfully implemented through a broad array of machine learning models, including convolutional neural networks [<a href=\"#ref-1\">1</a>\u2013<a href=\"#ref-4\">4</a>], recurrent neural networks [<a href=\"#ref-5\">5</a>\u2013<a href=\"#ref-7\">7</a>], graph neural networks [<a href=\"#ref-8\">8</a>\u2013<a href=\"#ref-11\">11</a>], and large language models [<a href=\"#ref-12\">12</a>\u2013<a href=\"#ref-16\">16</a>]. However, model evaluation is challenging because (1) available molecular sequencing data often capture a small fraction of all possible sequences due to the time and cost of generating sequencing data [<a href=\"#ref-17\">17</a>, <a href=\"#ref-18\">18</a>]. (2) Sequences evolve and acquire new mutations over time that are not present in existing datasets. This results in differences in the distribution of sequences and their aggregate properties between datasets, known as distribution shifts that can lead to degradation of model performance [<a href=\"#ref-19\">19</a>\u2013<a href=\"#ref-21\">21</a>]. Although distributional shifts are a well-recognized challenge in machine learning more generally [<a href=\"#ref-22\">22</a>, <a href=\"#ref-23\">23</a>], they are less well characterized in biology due to the lack of approaches that measure model performance in the context of distribution shifts. Though numerous benchmarks have been developed to assess model performance across datasets [<a href=\"#ref-16\">16</a>, <a href=\"#ref-24\">24</a>\u2013<a href=\"#ref-27\">27</a>], there are still large gaps between model performance during benchmarking and real-world use [<a href=\"#ref-28\">28</a>\u2013<a href=\"#ref-32\">32</a>] (<a href=\"#F1\">Figure 1a</a>). This gap in assessing generalizability must be addressed before machine learning models can be broadly used in biology.</p><div><div><div><p><a href=\"https://www.biorxiv.org/content/biorxiv/early/2024/02/28/2024.02.25.581982/F1.large.jpg?width=800&amp;height=600&amp;carousel=1\"><span></span></a></p></div><ul><li><a href=\"https://www.biorxiv.org/content/biorxiv/early/2024/02/28/2024.02.25.581982/F1.large.jpg?download=true\">Download figure</a></li><li><a href=\"https://www.biorxiv.org/content/biorxiv/early/2024/02/28/2024.02.25.581982/F1.large.jpg\">Open in new tab</a></li></ul></div><div><p><span>Figure 1:</span> <span>The SPECTRA framework for model evaluation (SPECTRA).</span></p><p><strong>(a)</strong> Machine learning (ML) models for molecular sequencing data struggle to generalize across datasets. <strong>(b)</strong> Every train-test split partitions samples based on a chosen molecular sequence property. Cross-split overlap exists between train and test sets when samples share molecular sequence properties. Shown are two examples of train-test splits. In the first, samples are split based on their identity, shown by the sample number, and there is no cross-split overlap as no two samples share identity across the train and test set. In the second, samples are split based on metadata-based attributes with cross-split overlap as two samples share an attribute across the train and test set. <strong>(c)</strong> Traditional approaches for model evaluation create train-test splits either based on metadata-based attributes (metadata based split) or sequence similarity (similarity based split). <strong>(d)</strong> The SPECTRA or spectral framework for model evaluation generates train-test splits with a spectrum of cross-split overlap. It does so by constructing a spectral property graph where nodes are samples and edges are between samples that share a spectral property. The spectral property is a molecular sequence property which influences model generalizability. It then iteratively deletes nodes and edges based on the spectral parameter, an internal parameter, to generate train and test sets. After training and evaluating an input model to each generated split, SPECTRA generates a spectral performance curve which plots model test performance versus the spectral parameter, an internal parameter that scales with cross-split overlap. The spectral performance curve shows the gap in generalizability depicted in panel a is due to differing levels of cross-split overlap between splits generated in dataset A and those of dataset B. The area under the spectral performance curve (highlighted in yellow) summarizes model performance across all levels of cross-split overlap and is a new metric for model generalizability. Note: The use of the word spectral here refers only to the framework for model evaluation and should not be confused with other uses of the term in matrix analysis.</p></div></div><p>While useful, the central shortcoming of existing benchmarks is the approach to model evaluation. Existing methods for model evaluation split input molecular sequencing datasets into train and test sets in metadata-based (MB) or similarity-based (SB) splits (<a href=\"#F1\">Figure 1c</a>). MB splits ensure certain metadata properties are not shared across splits. One example is a temporal split of Covid-19 viral sequences in which a vaccine escape model is trained on sequences collected before a specific time and tested on sequences evolved after that time [<a href=\"#ref-33\">33</a>\u2013<a href=\"#ref-35\">35<...",
      "url": "https://www.biorxiv.org/content/10.1101/2024.02.25.581982v1.full"
    },
    {
      "title": "Robust Molecular Property Prediction via Densifying Scarce Labeled Data",
      "text": "[View PDF](https://arxiv.org/pdf/2506.11877) [HTML (experimental)](https://arxiv.org/html/2506.11877v1)\n\n> Abstract:A widely recognized limitation of molecular prediction models is their reliance on structures observed in the training data, resulting in poor generalization to out-of-distribution compounds. Yet in drug discovery, the compounds most critical for advancing research often lie beyond the training set, making the bias toward the training data particularly problematic. This mismatch introduces substantial covariate shift, under which standard deep learning models produce unstable and inaccurate predictions. Furthermore, the scarcity of labeled data, stemming from the onerous and costly nature of experimental validation, further exacerbates the difficulty of achieving reliable generalization. To address these limitations, we propose a novel meta-learning-based approach that leverages unlabeled data to interpolate between in-distribution (ID) and out-of-distribution (OOD) data, enabling the model to meta-learn how to generalize beyond the training distribution. We demonstrate significant performance gains over state-of-the-art methods on challenging real-world datasets that exhibit substantial covariate shift.\n\n## Submission history\n\nFrom: Jina Kim \\[ [view email](https://arxiv.org/show-email/96b77896/2506.11877)\\]\n\n**\\[v1\\]**\nFri, 13 Jun 2025 15:27:40 UTC (10,933 KB)",
      "url": "https://arxiv.org/abs/2506.11877"
    },
    {
      "title": "Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation",
      "text": "<div>\n<div>\n<p><a href=\"https://www.cornell.edu/\"></a>\n</p>\n<div>\n<p><a href=\"https://confluence.cornell.edu/x/ALlRF\">We gratefully acknowledge support from<br/>\nthe Simons Foundation and member institutions.</a>\n</p></div>\n</div>\n<div>\n<h2><a href=\"https://arxiv.org/\">\n</a></h2>\n</div>\n</div>",
      "url": "https://arxiv.org/abs/2504.09481"
    },
    {
      "title": "Robust Molecular Property Prediction via  Densifying Scarce Labeled Data",
      "text": "Robust Molecular Property Prediction via\nDensifying Scarce Labeled Data\nJina Kim * 1 Jeffrey Willette * 1 Bruno Andreis * 1 Sung Ju Hwang 1 2\nAbstract\nA widely recognized limitation of molecular pre\u0002diction models is their reliance on structures ob\u0002served in the training data, resulting in poor gener\u0002alization to out-of-distribution compounds. Yet in\ndrug discovery, the compounds most critical for\nadvancing research often lie beyond the training\nset, making the bias toward the training data par\u0002ticularly problematic. This mismatch introduces\nsubstantial covariate shift, under which standard\ndeep learning models produce unstable and in\u0002accurate predictions. Furthermore, the scarcity\nof labeled data\u2014stemming from the onerous and\ncostly nature of experimental validation\u2014further\nexacerbates the difficulty of achieving reliable\ngeneralization. To address these limitations, we\npropose a novel meta-learning-based approach\nthat leverages unlabeled data to interpolate be\u0002tween in-distribution (ID) and out-of-distribution\n(OOD) data, enabling the model to meta-learn\nhow to generalize beyond the training distribution.\nWe demonstrate significant performance gains on\nchallenging real-world datasets with substantial\ncovariate shift, supported by t-SNE visualizations\nhighlighting our interpolation method.\n1. Introduction\nMolecular property prediction plays a central role in drug\ndiscovery pipelines, enabling researchers to prioritize com\u0002pounds for costly and time-consuming experimental valida\u0002tion. Accurate computational models have the potential to\ndramatically accelerate early-stage discovery by predicting\ncritical attributes such as bioactivity, toxicity, and solubility\n*Equal contribution 1Korea Advanced Institute of Sci\u0002ence and Technology (KAIST), South Korea 2Deepauto.ai,\nSouth Korea. Correspondence to: Jina Kim <ji\u0002nakim@kaist.ac.kr>, Jeffrey Willette <jwillette@kaist.ac.kr>,\nBruno Andreis <andries@kaist.ac.kr>, Sung Ju Hwang\n<sungju.hwang@kaist.ac.kr>.\nProceedings of the Workshop on Generative AI for Biology at the\n42 nd International Conference on Machine Learning, Vancouver,\nCanada. PMLR 267, 2025. Copyright 2025 by the author(s).\nIn-Distribution Out-Of-Distribution\nGeneralizing OOD\ntrain point\n, \nContext guided Interpolation\ncontext point\nRobust\nPrediction\nCovariate Shift\nOOD data point\nlogP: 1.2 | Tox: low logP: 4.2 | Tox: high\nlogP: 2.5 | Tox: medium\nFigure 1. Concept. We densify the train dataset using external\nunlabeled data (context point) for robust generalization across\ncovariate shift. Notation details are provided in Section 4.\nbefore synthesis (Schneider, 2018; Vamathevan et al., 2019).\nHowever, building reliable predictive models generalizing to\nnovel, unseen compounds remains a fundamental challenge.\nStandard molecular property prediction models tend to rely\nheavily on patterns observed within the training distribution,\nresulting in poor generalization to out-of-distribution com\u0002pounds (Klarner et al., 2023; Ovadia et al., 2019; Koh et al.,\n2021). In drug discovery, this limitation is particularly prob\u0002lematic, since the compounds most crucial for advancing re\u0002search often lie far beyond the chemical spaces represented\nduring training (Lee et al., 2023). The resulting covariate\nshift introduces significant obstacles to reliable prediction,\nwith models frequently producing unstable outputs when\nextrapolating to new regions of chemical space. Further\ncompounding these challenges, experimental validation of\nmolecular properties is both costly and resource-intensive,\nleading to a scarcity of labeled data and increasing reliance\non computational exploration (Altae-Tran et al., 2017). Also,\navailable labeled data is typically concentrated in narrow\nregions of chemical space, introducing bias that hampers\ngeneralization to unseen compounds (Klarner et al., 2023).\nWhile vast collections of unlabeled molecular structures\nare readily available (Sterling & Irwin, 2015; Kim et al.,\n2021), offering rich information about the structure of\nchemical space, existing methods often fail to fully ex\u0002ploit this resource to improve generalization (Klarner et al.,\n1\nRobust Molecular Property Prediction via Densifying Scarce Labeled Data\n2023). Therefore, we propose a novel meta-learning based\nmethod that leverages unlabeled data to densify the scarce\ntrain dataset and guide the model toward sensible behav\u0002ior in unexplored regions of chemical space. Our code\ncan be found at https://github.com/JinA0218/\ndrugood-densify.\n2. Methodology\nPreliminaries. We consider the problem of molecular\nproperty prediction under covariate shift. Given a small\nlabeled dataset Dtrain = {(xi, yi)}\nn\ni=1 and abundant unla\u0002beled molecules Dunlabeled = {xj}\nm\nj=1, the goal is to learn a\npredictive model f : X \u2192 Y that reliably generalizes to a\ndistributionally shifted test set Dtest.\nScarce Data Densification with Unlabeled Data To ad\u0002dress this, we propose a meta-learning based framework that\ninterpolates the training distribution Dtrain with an exoge\u0002nous distribution Dunlabeled. Our objective is to leverage the\ncheaper and more abundant distribution Dunlabeled to densify\nthe scarce labeled distribution Dtrain in a way that encour\u0002ages the model to generalize robustly under covariate shift,\nparticularly in out-of-distribution scenarios where we have\nno label information and therefore high uncertainty. For this,\nwe utilize subsets of Dunlabeled as Dcontext and Dmvalid, where\nDcontext is a domain-informed external task distribution for\ninterpolating to Dtrain, and Dmvalid is a meta-validation set\nused to guide the interpolation function. Inspired by (Lee\net al., 2024), we introduce a permutation invariant learnable\nset function (Zaheer et al., 2017; Lee et al., 2019) \u00b5\u03bb as a\nmixer (interpolator), which learns to mix each point from\nxi \u223c Dtrain with the context points {cij}\nmi\nj=1 in a way that\ndensifies Dtrain, where\n(xi, yi) \u223c Dtrain, {cij}\nmi\nj=1 \u223c Dcontext, i \u2208 {1, . . . , B}\nand B denotes the minibatch size, mi \u223c Uint(0, M) where\nM controls the maximum number of context samples drawn\nfrom Dcontext for each minibatch. Given a feature dimen\u0002sion D, for each i, the input consists of, xi \u2208 R\nB\u00d71\u00d7D\nand {cij}\nmi\nj=1 \u2208 R\nB\u00d71\u00d7D, where the set {cij}\nmi\nj=1 can be\norganized into a tensor Ci \u2208 R\nB\u00d7mi\u00d7D.\nOverall, our model has two main components: (1) a meta\u0002learner f\u03b8l\n, which is a standard MLP at the l\nth layer, that\nmaps input data x\n(l\u22121)\ni \u2208 R\nB\u00d71\u00d7D to the feature space of\nthe (l + 1)th layer, producing x\n(l)\ni = f\u03b8l\n(x\n(l\u22121)\ni\n), and (2) a\nlearnable set function \u00b5\u03bb which mixes x\n(lmix)\ni\nand C\n(lmix)\ni\nas\na set and outputs a single pooled representation x\u02dc\n(lmix)\ni =\n\u00b5\u03bb({x\n(lmix)\ni\n, C(lmix)\ni\n}) \u2208 R\nB\u00d71\u00d7H, where H is the hidden\ndimension and lmix is the layer where the mixing happens.\nThe full model structure with L layers can be expressed as\n\u02c6f\u03b8,\u03bb := f\u03b8L\n\u25e6 \u00b7 \u00b7 \u00b7 \u25e6 f\u03b8lmix+1 \u25e6 \u00b5\u03bb \u25e6 f\u03b8lmix\u22121\n\u25e6 \u00b7 \u00b7 \u00b7 \u25e6 f\u03b81.\nWe utilize bilevel optimization for training meta-learner f\u03b8l,\nand treat the set function parameter \u00b5\u03bb as a hyperparameter\nto be optimized in the outer loop (Lorraine et al., 2019). As\nshown in Table 2 (w/o bilevel optimization), simply opti\u0002mizing the meta-learner parameters \u03b8 and the set function\nparameters \u03bb jointly can lead to overfitting to the task dis\u0002tribution and harms test-time generalization. Following the\nsetting of (Lorraine et al., 2019), during training, we only\nupdate the parameter \u03b8 in the inner loop and we only update\nthe parameter \u03bb in the outer loop (see Figure 9b for the\ndetailed model structure of the bilevel optimization).\nIn the inner loop, the model accepts xi \u2208 R\nB\u00d71\u00d7H\nand Ci \u2208 R\nB\u00d7mi\u00d7H and the set encoder \u00b5\u03bb mixes\n{x\n(lmix)\ni\n, C(lmix)\ni\n} and outputs x\u02dc\n(lmix)\ni \u2208 R\nB\u00d71\u00d7H. Since Ci\nis used to introduce a domain-informed external context to\ndensify Dtrain, we utilize the original label yi from Dtrain to\ntrain the task learner parameters f\u03b8l, with the mixed x\u02dc\n(lmix)\ni\n.\nIn the outer loop, we train the set encoder using hypergra\u0002dient (Lorraine et al., 2019), w...",
      "url": "https://openreview.net/pdf/70bee4e7da17329c1a51ab89274f7974d10cc74d.pdf"
    },
    {
      "title": "Fast and effective molecular property prediction with transferability map",
      "text": "Fast and effective molecular property prediction with transferability map\n\n[Download PDF](https://www.nature.com/articles/s42004-024-01169-4.pdf)\n\n[Download PDF](https://www.nature.com/articles/s42004-024-01169-4.pdf)\n\n### Subjects\n\n- [Computational chemistry](https://www.nature.com/subjects/computational-chemistry)\n- [Drug discovery and development](https://www.nature.com/subjects/drug-discovery-and-development)\n\n## Abstract\n\nEffective transfer learning for molecular property prediction has shown considerable strength in addressing insufficient labeled molecules. Many existing methods either disregard the quantitative relationship between source and target properties, risking negative transfer, or require intensive training on target tasks. To quantify transferability concerning task-relatedness, we propose Principal Gradient-based Measurement (PGM) for transferring molecular property prediction ability. First, we design an optimization-free scheme to calculate a principal gradient for approximating the direction of model optimization on a molecular property prediction dataset. We have analyzed the close connection between the principal gradient and model optimization through mathematical proof. PGM measures the transferability as the distance between the principal gradient obtained from the source dataset and that derived from the target dataset. Then, we perform PGM on various molecular property prediction datasets to build a quantitative transferability map for source dataset selection. Finally, we evaluate PGM on multiple combinations of transfer learning tasks across 12 benchmark molecular property prediction datasets and demonstrate that it can serve as fast and effective guidance to improve the performance of a target task. This work contributes to more efficient discovery of drugs, materials, and catalysts by offering a task-relatedness quantification prior to transfer learning and understanding the relationship between chemical properties.\n\n### Similar content being viewed by others\n\n### [Knowledge graph-enhanced molecular contrastive learning with functional prompt](https://www.nature.com/articles/s42256-023-00654-0?fromPaywallRec=false)\n\nArticleOpen access04 May 2023\n\n### [A knowledge-guided pre-training framework for improving molecular representation learning](https://www.nature.com/articles/s41467-023-43214-1?fromPaywallRec=false)\n\nArticleOpen access21 November 2023\n\n### [Enhancing property and activity prediction and interpretation using multiple molecular graph representations with MMGX](https://www.nature.com/articles/s42004-024-01155-w?fromPaywallRec=false)\n\nArticleOpen access05 April 2024\n\n## Introduction\n\nMolecular property prediction, which involves identifying molecules with desired properties[1](https://www.nature.com/articles/s42004-024-01169-4#ref-CR1), [2](https://www.nature.com/articles/s42004-024-01169-4#ref-CR2), poses a critical challenge prevalent across various scientific fields. It holds particular significance in chemistry for designing drugs, catalysts, and materials. In recent years, artificial intelligence (AI) technologies have come mainstream in this area, and AI-guided chemical design can efficiently explore chemical space while improving performance based on experimental feedback, showing promise from laboratory research to real-world industry applications[3](https://www.nature.com/articles/s42004-024-01169-4#ref-CR3). However, it is common that the experimental data size is small as producing labeled data requires time-consuming and expensive experiments[4](https://www.nature.com/articles/s42004-024-01169-4#ref-CR4), [5](https://www.nature.com/articles/s42004-024-01169-4#ref-CR5). In contrast, transfer learning[6](https://www.nature.com/articles/s42004-024-01169-4#ref-CR6) has become a powerful paradigm for addressing data scarcity problem by exploiting the knowledge from related datasets across fields such as natural language processing[7](https://www.nature.com/articles/s42004-024-01169-4#ref-CR7), [8](https://www.nature.com/articles/s42004-024-01169-4#ref-CR8), computer vision[9](https://www.nature.com/articles/s42004-024-01169-4#ref-CR9), [10](https://www.nature.com/articles/s42004-024-01169-4#ref-CR10), and biomedcine[11](https://www.nature.com/articles/s42004-024-01169-4#ref-CR11), [12](https://www.nature.com/articles/s42004-024-01169-4#ref-CR12). In chemistry, transfer learning leverages pre-trained models on extensive or related datasets to facilitate efficient exploration of vast chemical space[13](https://www.nature.com/articles/s42004-024-01169-4#ref-CR13), [14](https://www.nature.com/articles/s42004-024-01169-4#ref-CR14) for various downstream tasks. It has been used to predict properties[15](https://www.nature.com/articles/s42004-024-01169-4#ref-CR15), [16](https://www.nature.com/articles/s42004-024-01169-4#ref-CR16), plan synthesis[17](https://www.nature.com/articles/s42004-024-01169-4#ref-CR17), [18](https://www.nature.com/articles/s42004-024-01169-4#ref-CR18), and explore the space of chemical reactions[19](https://www.nature.com/www.nature.com#ref-CR19), [20](https://www.nature.com/www.nature.com#ref-CR20), [21](https://www.nature.com/www.nature.com#ref-CR21), [22](https://www.nature.com/articles/s42004-024-01169-4#ref-CR22).\n\nTransfer learning can enhance molecular property prediction in limited data sets by borrowing knowledge from sufficient source data sets, thus improving both model accuracy and computation efficiency. Although several previous works have explored the power of transfer learning to enhance molecular property prediction[11](https://www.nature.com/articles/s42004-024-01169-4#ref-CR11), [12](https://www.nature.com/articles/s42004-024-01169-4#ref-CR12), [23](https://www.nature.com/www.nature.com#ref-CR23), [24](https://www.nature.com/www.nature.com#ref-CR24), [25](https://www.nature.com/articles/s42004-024-01169-4#ref-CR25), challenges remain. One major challenge is negative transfer, which occurs when the performance after transfer learning is adversely affected due to minimal similarity between the source and target tasks[26](https://www.nature.com/articles/s42004-024-01169-4#ref-CR26), [27](https://www.nature.com/articles/s42004-024-01169-4#ref-CR27). For example, Hu et al.[23](https://www.nature.com/articles/s42004-024-01169-4#ref-CR23) observed that pretrained GNN (at both node-level and graph-level) performed well but yielded negative transfer when pretrained at the level of either entire graphs or individual nodes. Additionally, some supervised pre-training tasks unrelated to the downstream task of interest can even degrade the downstream performance[23](https://www.nature.com/articles/s42004-024-01169-4#ref-CR23), [28](https://www.nature.com/articles/s42004-024-01169-4#ref-CR28).\n\nNegative transfer primarily stems from suboptimal model and layer choices, as well as insufficient task relatedness, highlighting the need to evaluate transferability prior to applying transfer learning. In computer vision, some researchers have recently focused on selecting the best model from a pool of options by estimating the transferability of each model[29](https://www.nature.com/www.nature.com#ref-CR29), [30](https://www.nature.com/www.nature.com#ref-CR30), [31](https://www.nature.com/www.nature.com#ref-CR31), [32](https://www.nature.com/articles/s42004-024-01169-4#ref-CR32). In molecular property prediction, recent efforts involve investigating the relatedness of the source task to the target task. To maximize the performance on a target task and prevent negative transfer, existing methods mainly rely on a molecular distance metric to measure the similarity of molecules, such as Tanimoto coefficient (based on molecular fingerprint)[33](https://www.nature.com/articles/s42004-024-01169-4#ref-CR33), [34](https://www.nature.com/articles/s42004-024-01169-4#ref-CR34) and a chemical distance measure (based on fingerprint and subgraph)[35](https://www.nature.com/articles/s42004-024-01169-...",
      "url": "https://www.nature.com/articles/s42004-024-01169-4"
    },
    {
      "title": "Molecular property prediction in the ultra\u2010low data regime",
      "text": "Molecular property prediction in the ultra\u2010low data regime | Communications Chemistry\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Communications Chemistry](https://media.springernature.com/full/nature-cms/uploads/product/commschem/header-3dc28429486e0d2c8f49fd9baf5afa40.svg)](https://www.nature.com/commschem)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s42004-025-01592-1?error=cookies_not_supported&code=080dccb6-b4aa-47ba-840b-aba438a0f70a)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;42004)\n* [RSS feed](https://www.nature.com/commschem.rss)\nMolecular property prediction in the ultra\u2010low data regime\n[Download PDF](https://www.nature.com/articles/s42004-025-01592-1.pdf)\n[Download PDF](https://www.nature.com/articles/s42004-025-01592-1.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:08 July 2025# Molecular property prediction in the ultra\u2010low data regime\n* [Basem A. Eraqi](#auth-Basem_A_-Eraqi-Aff1)[ORCID:orcid.org/0000-0003-2911-221X](https://orcid.org/0000-0003-2911-221X)[1](#Aff1),\n* [Dmitrii Khizbullin](#auth-Dmitrii-Khizbullin-Aff2)[2](#Aff2),\n* [Shashank S. Nagaraja](#auth-Shashank_S_-Nagaraja-Aff1)[ORCID:orcid.org/0000-0003-4930-6513](https://orcid.org/0000-0003-4930-6513)[1](#Aff1)&amp;\n* \u2026* [S. Mani Sarathy](#auth-S__Mani-Sarathy-Aff1)[ORCID:orcid.org/0000-0002-3975-6206](https://orcid.org/0000-0002-3975-6206)[1](#Aff1)Show authors\n[*Communications Chemistry*](https://www.nature.com/commschem)**volume8**, Article\u00a0number:201(2025)[Cite this article](#citeas)\n* 8813Accesses\n* 1Citations\n* 21Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s42004-025-01592-1/metrics)\n### Subjects\n* [Chemical engineering](https://www.nature.com/subjects/chemical-engineering)\n* [Cheminformatics](https://www.nature.com/subjects/cheminformatics)\n## Abstract\nData scarcity remains a major obstacle to effective machine learning in molecular property prediction and design, affecting diverse domains such as pharmaceuticals, solvents, polymers, and energy carriers. Although multi-task learning (MTL) can leverage correlations among properties to improve predictive performance, imbalanced training datasets often degrade its efficacy through negative transfer. Here, we present adaptive checkpointing with specialization (ACS), a training scheme for multi-task graph neural networks that mitigates detrimental inter-task interference while preserving the benefits of MTL. We validate ACS on multiple molecular property benchmarks, where it consistently surpasses or matches the performance of recent supervised methods. To illustrate its practical utility, we deploy ACS in a real-world scenario of predicting sustainable aviation fuel properties, showing that it can learn accurate models with as few as 29 labeled samples. By enabling reliable property prediction in low-data regimes, ACS broadens the scope and accelerates the pace of artificial intelligence-driven materials discovery and design.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-024-55082-4/MediaObjects/41467_2024_55082_Fig1_HTML.png)\n### [Multi-channel learning for integrating structural hierarchies into context-dependent molecular representation](https://www.nature.com/articles/s41467-024-55082-4?fromPaywallRec=false)\nArticleOpen access06 January 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41524-025-01836-7/MediaObjects/41524_2025_1836_Fig1_HTML.png)\n### [Attention-based functional-group coarse-graining: a deep learning framework for molecular prediction and design](https://www.nature.com/articles/s41524-025-01836-7?fromPaywallRec=false)\nArticleOpen access21 November 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42004-022-00790-5/MediaObjects/42004_2022_790_Fig1_HTML.png)\n### [Transferring chemical and energetic knowledge between molecular systems with machine learning](https://www.nature.com/articles/s42004-022-00790-5?fromPaywallRec=false)\nArticleOpen access13 January 2023\n## Introduction\nMachine learning (ML)-based molecular property prediction models can significantly accelerate the de novo design of high-performance molecules and mixtures by providing accurate property predictions. This data-driven approach explores the chemical space defined by learned model representations, enabling the discovery of materials that fulfill specific application requirements. However, the efficacy of such models relies heavily on predictive accuracy, which is constrained by the availability and quality of training data[1](https://www.nature.com/articles/s42004-025-01592-1#ref-CR1),[2](https://www.nature.com/articles/s42004-025-01592-1#ref-CR2). Across many practical domains\u2014including pharmaceutical drugs[3](https://www.nature.com/articles/s42004-025-01592-1#ref-CR3), chemical solvents[2](https://www.nature.com/articles/s42004-025-01592-1#ref-CR2), polymers[4](https://www.nature.com/articles/s42004-025-01592-1#ref-CR4), and green energy carriers[5](https://www.nature.com/articles/s42004-025-01592-1#ref-CR5)\u2014the scarcity of reliable, high-quality labels impedes the development of robust molecular property predictors.\nMulti-task learning (MTL) has been proposed to alleviate data bottlenecks by exploiting correlations among related molecular properties (hereafter termed*tasks*)[6](#ref-CR6),[7](#ref-CR7),[8](https://www.nature.com/articles/s42004-025-01592-1#ref-CR8). Through inductive transfer, MTL leverages the training signals or learned representations from one task to improve another, allowing the model to discover and utilize shared structures for more accurate predictions across all tasks. In practice, however, MTL is frequently undermined by negative transfer (NT)[7](https://www.nature.com/articles/s42004-025-01592-1#ref-CR7): performance drops that occur when updates driven by one task are detrimental to another. Prior studies linked NT primarily to*low task relatedness*and the associated*gradient conflicts*in shared parameters[9](#ref-CR9),[10](#ref-CR10),[11](https://www.nature.com/articles/s42004-025-01592-1#ref-CR11). The resulting gradient conflicts can reduce the overall benefits of MTL or even degrade performance.\nBeyond task dissimilarity, NT can also arise from architectural or optimization mismatches[12](https://www.nature.com/articles/s42004-025-01592-1#ref-CR12). Capacity mismatch occurs when the shared backbone lacks sufficient flexibility to support divergent task demands, leading to overfitting on some tasks and underfitting on others. Similarly, when tasks exhibit different optimal learning rates, shared training may update parameters at incompatible magnitudes, destabilizing convergence[11](https://www.nature.com/articles/s42004-025-01592-1#ref-CR11). Additionally, data distribution differences, such as temporal and spatial disparities, can impede effective knowledge transfer[13](https://www.nature.com/articles/s42004-025-01592-1#ref-CR13),[14](https://www.nature.com/articles/s42004-025-01592-1#ref-CR14). Temporal differences\u2014such as variations in the measurement years of molecular data\u2014can lead to inflated performance estimates if not properly accounted for. This inflation has been shown to re...",
      "url": "https://www.nature.com/articles/s42004-025-01592-1"
    }
  ]
}