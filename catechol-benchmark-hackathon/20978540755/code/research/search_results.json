{
  "query": "How can XGBoost and Random Forest ensemble improve neural network predictions for small tabular datasets?",
  "results": [
    {
      "title": "ANSWER",
      "text": "XGBoost and Random\u202fForest are tree\u2011based ensembles that possess inductive biases very different from those of feed\u2011forward neural networks, making them especially useful when the training set contains only a few hundred or thousand rows.  Benchmarks on dozens of real\u2011world tabular problems show that tree ensembles remain the top\u2011performing models on medium\u2011sized data (\u224810\u202fk samples) and often dominate neural nets on smaller sets because they can capture irregular feature interactions without heavy hyper\u2011parameter tuning\u202f([hal.science](https://hal.science/hal-03723551/file/Tabular_NeurIPS2022%20%2828%29.pdf)).  Neural networks, by contrast, tend to over\u2011fit on limited data and are sensitive to feature scaling and architecture choices, so their predictions can be stabilized by borrowing the strengths of trees.\n\nA practical way to combine them is **stacking**: each base learner (e.g., XGBoost, LightGBM, CatBoost, AdaBoost) generates predictions on the training folds, and a Random\u202fForest meta\u2011model learns to weight these outputs to produce a final estimate.  This approach leverages the low\u2011bias, high\u2011variance predictions of the boosted trees while the Random\u202fForest meta\u2011learner reduces variance and mitigates over\u2011fitting, yielding consistently higher accuracy and better generalisation on small tabular datasets\u202f([researchsquare.com](https://www.researchsquare.com/article/rs-7944070/v1.pdf?c=1761822346000)).  Even a simple hybrid\u2014feeding the neural\u2011network outputs as additional features to XGBoost, or averaging the NN and XGBoost scores\u2014has been shown to outperform XGBoost alone on a range of tasks\u202f([thesai.org](https://thesai.org/Downloads/Volume13No4/Paper_54-Is_Deep_Learning_on_Tabular_Data_Enough.pdf)).\n\nIn practice, one can train a modest multilayer perceptron (or a tabular\u2011specific net such as TabNet) on the raw data, obtain its probability or regression predictions, and then **stack** those predictions with those of XGBoost and Random\u202fForest.  The ensemble benefits from the neural net\u2019s ability to learn smooth, high\u2011dimensional representations and the trees\u2019 robustness to sparse, categorical, or noisy features, resulting in lower bias\u2011variance trade\u2011offs and more reliable performance on the limited samples typical of many business and scientific tabular problems.",
      "url": ""
    },
    {
      "title": "",
      "text": "Stacking Ensemble Learning : Combining XGBoost,\nLightGBM, CatBoost, and AdaBoost with Random\nForest Meta Model\nSindhu\u00a0\nNugroho https://orcid.org/0009-0002-1558-4574\nResearch Article\nKeywords: Articial Intelligence, Deep Learning, Machine Learning, Ensemble Learning\nPosted Date: October 30th, 2025\nDOI: https://doi.org/10.21203/rs.3.rs-7944070/v1\nLicense: \uf25e \uf4e7 This work is licensed under a Creative Commons Attribution 4.0 International License. \u00a0\nRead Full License\nAdditional Declarations: The authors declare no competing interests.\nSTACKING ENSEMBLE LEARNING : COMBINING XGBOOST,\nLIGHTGBM, CATBOOST, AND ADABOOST WITH RANDOM\nFOREST META MODEL\nA PREPRINT\nSindhu Wijaya Mulyo Nugroho, S.Kom*\nProduct Development, Educourse.id\nSemarang, Indonesia\nsindhu.nugroho99@gmail.com\nORCID: 0009-0002-1558-4574\nOctober 27, 2025\nABSTRACT\nEnsemble learning has become a powerful approach in machine learning, particularly for improving\nprediction accuracy and generalization. This work proposes a stacking ensemble framework that\nintegrates four popular boosting algorithms, XGBoost, LightGBM, CatBoost, and AdaBoost, as base\nlearners, with Random Forest employed as the meta-lover. The design leverages the complementary\nstrengths of boosting algorithms in handling tabular data, categorical variables, and imbalanced\ndatasets, while Random Forest ensures robust decision-making at the meta-level. The results show\nthat the proposed stacking ensemble consistently outperforms individual models, achieving better\nstability and reducing both variance and bias. This highlights the effectiveness of combining multiple\nboosting algorithms with a Random Forest metamodel to build a hybrid system that is accurate,\ngeneralizable, and applicable across different machine learning domains.\nKeywords Artificial Intelligence \u00b7 Deep Learning \u00b7 Machine Learning \u00b7 Ensemble Learning\n1 Introduction\nEnsemble learning has become a core paradigm in machine learning due to its ability to improve prediction accuracy\nand generalization by combining multiple models. Unlike single learners, ensembles exploit model diversity to capture\ndifferent aspects of data distributions, thereby reducing both bias and variance. This makes them highly effective across\ndomains where robustness and reliability are critical.\nSeveral ensemble strategies exist, including bagging, boosting, and stacking. Bagging reduces variance by training\nmultiple models on bootstrapped subsets of data and aggregating their outputs, with Random Forest being the most\nwidely used example. Boosting reduces bias by sequentially training learners, where each subsequent model focuses on\ncorrecting the errors of its predecessors. Stacking differs by training multiple base models in parallel and using a meta\nlearner to integrate their predictions. Stacking is particularly powerful because it can capture complementary strengths\nof heterogeneous learners.\nAmong ensemble methods, boosting algorithms such as XGBoost, LightGBM, CatBoost, and AdaBoost have consis\u0002tently shown strong performance. Each algorithm has unique strengths. XGBoost employs regularization and efficient\ntree pruning, making it scalable and less prone to overfitting. LightGBM introduces histogram-based feature binning\nand leaf-wise growth, enabling faster training and reduced memory usage, especially on large datasets. CatBoost\nnatively handles categorical variables using ordered boosting and statistical encodings, which minimizes target leakage\nand improves generalization. AdaBoost, though simpler, provides robustness by iteratively reweighting misclassified\nsamples, ensuring that weak learners are adaptively strengthened.\n\u2217\nSTACKING ENSEMBLE LEARNING A PREPRINT\nWhile each boosting method is powerful, none consistently dominates across all tasks. XGBoost may demand extensive\ntuning, LightGBM risks overfitting with deep trees, CatBoost can be computationally heavier, and AdaBoost may\nunderperform on highly complex feature interactions. These trade-offs make boosting algorithms ideal candidates for\nstacking, where their individual advantages can be combined to achieve superior performance.\nIn this work, we propose a stacking ensemble framework that employs XGBoost, LightGBM, CatBoost, and AdaBoost\nas base learners. Their predictions are combined by a meta learner, for which we choose Random Forest. The choice of\nRandom Forest is motivated by its robustness and interpretability. As a bagging-based method, Random Forest builds\nmultiple decision trees using bootstrapped samples and random feature subsets, which reduces variance and prevents\noverfitting. As a meta learner, Random Forest can effectively capture non-linear dependencies between base predictions,\noffering a richer integration mechanism than simple averaging or linear models.\n2 Boosting and Bagging in a Nutshell\nBoosting, introduced by Freund and Schapire (1997), combines many weak learners to create a highly accurate model.\nFriedman (2001, 2002) and Natekin & Knoll (2013) refined this through Gradient Boosting Machines (GBM), which\niteratively improve predictions by minimizing a loss function. Instead of training one model, GBM starts with a\nsimple base model and repeatedly adds new models to correct previous errors. This paper focuses on the mathematical\nfoundation of gradient boosting\u2014covering optimization methods, loss functions, various boosting algorithms, and their\napplication to ranking real-world data (1).\nDecision Contribution algorithm designed to make Gradient Boosted Decision Trees (GBDT) locally explainable by\ndecomposing each prediction into the sum of node-level contributions along the decision path.\nMathematically, each model iteration is defined as:\nFt(x) = Ft\u22121(x) + \u03b1ht(x), (1)\nwhere \u03b1 is the learning rate and ht(x) is the residual tree. Each tree prediction can be rewritten as the sum of\ncontributions from every node decision:\nhl(x) = X\ni(l)\nj=0\ngl(sj ), (2)\nleading to the overall GBDT formulation:\nFt(x) = Xt\nl=0\nX\ni(l)\nj=0\n\u03b1gl(sj ), (3)\nwhere gl(sj ) quantifies the influence of each decision node sj on the final prediction.\nThe authors demonstrate that this approach provides intrinsic explainability unlike post-hoc XAI models such as LIME\nand SHAP, which approximate explanations externally. Through experiments on Diabetes and Concrete datasets, the\nmethod proved consistent under correlation and noise tests, and outperformed SHAP in handling outliers (2).\n2.1 Decision Tree\na decision tree is described as a binary tree structure used for classification or regression tasks. Each internal node\nrepresents a condition on an attribute (for example, Ai > vj ), and each leaf node provides a numerical value or class\nlabel. To classify an input instance x = (v1, v2, . . . , vn), the model follows a path from the root to a leaf based on\nwhether the conditions at each node are satisfied. The output of the tree, denoted as w(T, x), corresponds to the value at\nthe leaf reached by x.\nA forest is defined as a collection of several decision trees F\nj = {T\nj\n1\n, Tj\n2\n, . . . , Tj\npj\n}, where the total output for an\ninstance x is obtained by summing the outputs of the individual trees:\nw(F\nj\n, x) = Xpj\nk=1\nw(T\nj\nk\n, x)\nA boosted tree model (BT) consists of multiple forests, each corresponding to a class. For binary classification, the final\nprediction is defined as:\nBT(x) = \u001a\n1, if w(F, x) > 0\n0, otherwise\n2\nSTACKING ENSEMBLE LEARNING A PREPRINT\nand for multiclass classification, the class with the highest total weight is selected:\nBT(x) = j if w(F\nj\n, x) > w(F\ni\n, x) \u2200i \u0338= j\nThe paper also introduces the concept of abductive explanations, which are minimal subsets of features that are sufficient\nto produce the same classification result as the full input. Formally, a subset t of the feature assignments tx is an\nabductive explanation if, for any instance x\n\u2032\nconsistent with t, the model gives the same output as for x:\n\u2200x\n\u2032\nsuch that t \u2286 tx\u2032 =\u21d2 f(x\n\u2032\n) = f(x)\nThe minimal version of such a subset, containing no unnecessary features, ...",
      "url": "https://www.researchsquare.com/article/rs-7944070/v1.pdf?c=1761822346000"
    },
    {
      "title": "",
      "text": "Why do tree-based models still outperform deep\nlearning on typical tabular data?\nL\u00e9o Grinsztajn\nSoda, Inria Saclay\nleo.grinsztajn@inria.fr\nEdouard Oyallon\nMLIA, Sorbonne University\nGa\u00ebl Varoquaux\nSoda, Inria Saclay\nAbstract\nWhile deep learning has enabled tremendous progress on text and image datasets,\nits superiority on tabular data is not clear. We contribute extensive benchmarks of\nstandard and novel deep learning methods as well as tree-based models such as\nXGBoost and Random Forests, across a large number of datasets and hyperparam\u0002eter combinations. We define a standard set of 48 datasets from varied domains\nwith clear characteristics of tabular data and a benchmarking methodology account\u0002ing for both fitting models and finding good hyperparameters. Results show that\ntree-based models remain state-of-the-art on medium-sized data (\u223c10K samples)\neven without accounting for their superior speed. To understand this gap, we\nconduct an empirical investigation into the differing inductive biases of tree-based\nmodels and neural networks. This leads to a series of challenges which should\nguide researchers aiming to build tabular-specific neural network: 1. be robust\nto uninformative features, 2. preserve the orientation of the data, and 3. be able\nto easily learn irregular functions. To stimulate research on tabular architectures,\nwe contribute a standard benchmark and raw data for baselines: every point of a\n20 000 compute hours hyperparameter search for each learner.\n1 Introduction\nDeep learning has enabled tremendous progress for learning on image, language, or even audio\ndatasets. On tabular data, however, the picture is muddier and ensemble models based on decision\ntrees like XGBoost remain the go-to tool for most practitioners [Sta] and data science competitions\n[Kossen et al., 2021]. Indeed deep learning architectures have been crafted to create inductive biases\nmatching invariances and spatial dependencies of the data. Finding corresponding invariances is hard\nin tabular data, made of heterogeneous features, small sample sizes, extreme values.\nCreating tabular-specific deep learning architectures is a very active area of research (see section 2).\nOne motivation is that tree-based models are not differentiable, and thus cannot be easily composed\nand jointly trained with other deep learning blocks. Most tabular deep learning publications claim\nto beat or match tree-based models, but their claims have been put into question: a simple Resnet\nseems to be competitive with some of these new models [Gorishniy et al., 2021], and most of\nthese methods seem to fail on new datasets [Shwartz-Ziv and Armon, 2021]. Indeed, the lack\nof an established benchmark for tabular data learning provides additional degrees of freedom to\nresearchers when evaluating their method. Furthermore, most tabular datasets available online are\nsmall compared to benchmarks in other machine learning subdomains, such as ImageNet [Ima],\nmaking evaluation noisier. These issues add up to other sources of unreplicability across machine\nlearning, such as unequal hyperparameters tuning efforts [Lipton and Steinhardt, 2019] or failure\nto account for statistical uncertainty in benchmarks [Bouthillier et al., 2021]. To alleviate these\nconcerns, we contribute a tabular data benchmark with a precise methodology for datasets inclusion\nand hyperparameter tuning. This enables us to evaluate recent deep learning models which have\n36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks.\nnot yet been independently evaluated, and to show that tree-based models remain state-of-the-art\non medium-sized tabular datasets, even without accounting for the slower training of deep learning\nalgorithms. Furthermore, we show that this performance gap is not mostly due to categorical features,\nand does not disappear after tuning hyperparameters.\nImpressed by the superiority of tree-based models on tabular data, we strive to understand which\ninductive biases make them well-suited for these data. By transforming tabular datasets to modify\nthe performances of different models, we uncover differing biases of tree-based models and deep\nlearning algorithms which partly explain their different performances: neural networks struggle to\nlearn irregular patterns of the target function, and their rotation invariance hurt their performance, in\nparticular when handling the numerous uninformative features present in tabular data.\nOur contributions are as follow: 1. We create a new benchmark for tabular data, with a precise\nmethodology for choosing and preprocessing a large number of representative datasets. We share\nthese datasets through OpenML [Vanschoren et al., 2014], which makes them easy to use. 2. We\nextensively compare deep learning models and tree-based models on generic tabular datasets in\nmultiple settings, accounting for the cost of choosing hyperparameters. We also share the raw\nresults of our random searches, which will enable researchers to cheaply test new algorithms for a\nfixed hyperparameter optimization budget. 3. We investigate empirically why tree-based models\noutperform deep learning, by finding data transformations which narrow or widen their performance\ngap. This highlights desirable biases for tabular data learning, which we hope will help other\nresearchers to successfully build deep learning models for tabular data.\nIn Sec. 2 we cover related work. Sec. 3 gives a short description of our benchmark methodology,\nincluding datasets, data processing, and hyper-parameter tuning. Then, Sec. 4 shows our raw results\non deep learning and tree-based models after an extensive random search. Finally, Sec. 5 provides\nthe results of an empirical study which exhibit desirable implicit biases of tabular datasets.1\n2 Related work\nDeep learning for tabular data As described by Borisov et al. [2021] in their review of the field,\nthere have been various attempts to adapt deep learning to tabular data: data encoding techniques to\nmake tabular data better suited for deep learning [Hancock and Khoshgoftaar, 2020, Yoon et al., 2020],\n\"hybrid methods\" to benefit from the flexibility of neural networks while keeping the inductive biases\nof other algorithms like tree-based models [Lay et al., 2018, Popov et al., 2020, Abutbul et al., 2020,\nHehn et al., 2019, Tanno et al., 2019, Chen, 2020, Kontschieder et al., 2015, Rodriguez et al., 2019,\nPopov et al., 2020, Lay et al., 2018] or Factorization Machines Guo et al. [2017], tabular-specific\ntransformers architectures Somepalli et al. [2021], Kossen et al. [2021], Arik and Pfister [2019],\nHuang et al. [2020], and various regularization techniques to adapt classical architectures to tabular\ndata [Lounici et al., 2021, Shavitt and Segal, 2018, Kadra et al., 2021a, Fiedler, 2021]. In this paper,\nwe focus on architectures directly inspired by classic deep learning models, in particular Transformers\nand Multi-Layer-Perceptrons (MLPs).\nComparisons between neural networks and tree-based models The most comprehensive com\u0002parisons of machine learning algorithms have been published before the advent of new deep learning\nmethods [Caruana and Niculescu-Mizil, 2006, Fern\u00e1ndez-Delgado et al., 2014], or on specific prob\u0002lems [Sakr et al., 2017, Korotcov et al., 2017, Uddin et al., 2019]. Recently, Shwartz-Ziv and Armon\n[2021] evaluated modern tabular-specific deep learning methods, but their goal was more to reveal that\n\"New deep learning architectures fail to generalize to new datasets\" than to create a comprehensive\nbenchmark. Borisov et al. [2022] benchmarked recent algorithms in their review of deep learning for\ntabular data, but only on 3 datasets, and \"highlight[ed] the need for unified benchmarks\" for tabular\ndata. Most papers introducing a new architecture for tabular data benchmark various algorithms,\nbut with a highly variable evaluation methodology, a small number of datasets, and the evaluation\ncan be biased toward the authors\u2019 model [S...",
      "url": "https://hal.science/hal-03723551/file/Tabular_NeurIPS2022%20%2828%29.pdf"
    },
    {
      "title": "Is Deep Learning on Tabular Data Enough? An Assessment",
      "text": "(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 13, No. 4, 2022\n466 | P a g e\nwww.ijacsa.thesai.org\nIs Deep Learning on Tabular Data Enough? An \nAssessment\nSheikh Amir Fayaz1\nResearch Scholar\nDepartment of Computer Sciences\nUniversity of Kashmir, J&K, India-190006\nMajid Zaman2\nDirectorate of IT & SS\nUniversity of Kashmir\nSrinagar, J&K, India-190006\nSameer Kaul3\nDepartment of Computer Sciences\nUniversity of Kashmir\nSrinagar, J&K, India-190006\nMuheet Ahmed Butt4\nDepartment of Computer Sciences\nUniversity of Kashmir\nSrinagar, J&K, India-190006\nAbstract\u2014It is critical to select the model that best fits the \nsituation while analyzing the data. Many scholars on \nclassification and regression issues have offered ensemble \ntechniques on tabular data, as well as other approaches to \nclassification and regression problems (Like Boosting and \nLogistic Model tree ensembles). Furthermore, various deep \nlearning algorithms have recently been implemented on tabular \ndata, with the authors claiming that deep models outperform \nBoosting and Model tree approaches. On a range of datasets \nincluding historical geographical data, this study compares the \nnew deep models (TabNet, NODE, and DNF-net) against the \nboosting model (XGBoost) to see if they should be regarded a \npreferred choice for tabular data. We look at how much \ntweaking and computation they require, as well as how well they \nperform based on the metrics evaluation and statistical \nsignificance test. According to our study, XGBoost outperforms \nthese deep models across all datasets, including the datasets used \nin the journals that presented the deep models. We further show \nthat, when compared to deep models, XGBoost requires \nconsiderably less tweaking. In addition, we can also confirm that \na combination of deep models with XGBoost outperforms \nXGBoost alone on almost all datasets.\nKeywords\u2014Deep learning; XGBoost; NODE; TabNet; DNF\u0002net; statistical significance test; tabular geographical data\nI. INTRODUCTION\nDeep learning has gained popularity in a variety of fields in \nrecent years, including medicine, engineering, and agriculture. \nThe exponential growth of data is most likely to blame. Deep \nlearning algorithms have shown to be effective in a variety of \ndomains, including audio [1], images [2], and text data [3]. \nMany architectures exist in these domains that are capable of \nconverting raw data into meaningful exemplifications. Because \nthe most common type of data is in tabular format, which \nconsists of rows and columns with a variety of parameters, \nThese types of data are used in real-world applications in a \nvariety of fields, including medicine, agriculture, academia, \nand geography. Traditional and ensemble machine learning \napproaches, such as Logistic model tree (LMT), Decision tree \n(DT), Random forest (RF), Gradient Boosted decision tree \n(GBDT), and others, are used to process these tabular datasets, \nand these models still outperform deep learning on tabular \ndata. When using a deep learning model on tabular data, there \nare a number of issues to consider, including missing data, data \nintegrity i.e., mixed data (nominal, numerical, and categorical), \ndata imbalance, data overfitting, and a lack of specific \nknowledge about the dataset's structure. When tabular data is \ntaken into account, boosting machine-learning algorithms like \nXGBoost perform better, according to the \u2015no free lunch\u2016 \n(NFL) theorem [4] [5]. Since then, the authors [6] [7] have \nimplemented deep learning on the tabular dataset in their \nresearch, and it has been demonstrated that the deep learning \nmodel outperforms GBDT. However, because each study was \nconducted on different datasets, one of the major flaws in their \napproach is that there was no benchmark dataset [8] [9]. So, \nbased on these papers alone, it's difficult to claim that deep \nlearning always outperforms traditional and ensemble \nalgorithms like GBDT when dealing with tabular data [10].\nSince the number of research studies using deep learning \non tabular data is growing, there is no standard benchmark \nmodel in deep learning from which we can conclude that deep \nlearning always outperforms traditional machine learning on \ntabular data. As a result, the main goal of this paper is to see if \nany deep learning model is a good fit for these types of tabular \ndataset problems. Furthermore, in this paper, we attempt to \nevaluate the proposed deep learning models on tabular datasets, \nas well as implement XGBoost on various algorithms, with a \nfocus on a historical geographical dataset from India's Kashmir \nprovince [11].\nThis paper is structured as: Section 2 provides a basic \nbackground of deep learning and ensemble models on the \ntabular data. Next, Section 3 presents the experimental setup \nwhere dataset descriptions are presented and furthermore this \nsection defines the implementation details with optimization \nparameters and statistical significance test. Section 4 defines \nthe experimental results and model evaluation. Section 5 \ndefines the overall working of the paper. Finally, the \nconclusion and future strategies have been suggested in \nSection 6.\n(IJACSA) International Journal of Advanced Computer Science and Applications,\nVol. 13, No. 4, 2022\n467 | P a g e\nwww.ijacsa.thesai.org\nII. REVIEW OF LITERATURE\nIn this section, we present studies that used deep learning \napproaches and ensemble approaches to predict rainfall using a \ntabular geographical dataset. This section is divided into two \nsubsections: Section 1 contains several studies that use deep \nlearning models on tabular datasets, and Section 2 contains \nsome model ensemble approaches that use the same tabular \ngeographical dataset and record individual performances.\nA. Deep Learning on Tabular Geographical Dataset\nSalman et al. [12] (2015) use a variety of deep learning \ntechniques, including recurrence neural networks (RNN), \nconvolutional neural networks (CNN), and conditional \nrestricted Boltzmann machines (CRBM), to look for hidden \npatterns in the dataset. These techniques were used in the \nIndonesian region, with data collected from the national \nweather service center for environmental forecasting (NOAA). \nThis study used a dataset that spanned 35 years, from 1973 to \n2009. Initially, RNN was applied to a dataset containing ESNO \nvariables. RNN produces results with a higher level of \naccuracy, according to the findings.\nEmiley et al [13] (2016) present a deep learning \narchitecture-based accumulated daily rainfall prediction. This \nresearch employs auto encoders to reduce non-linear attribute \nrelationships and a multi-layer perceptron (MLP) for \nprediction. This hybrid architecture was then compared to \npreviously implemented techniques, and it was discovered that \nthe model performs better for daily rainfall prediction when \nusing root mean square error (RMSE) and mean squared error\n(MSE) statistical approaches. This research was carried out in \nthe Colombian city of Manziles, where the data was grouped \ninto a daily time series spanning the years 2002 to 2013.\nDevi et al. [14] (2017) propose an artificial neural network \n(ANN) model for a reliable forecast mechanism. This method \nwas used to analyze spatial and temporal data from the Nilgiris \ndistrict in Tamil Nadu, India. Performance was measured using \na variety of statistical parameters such as correlation \ncoefficient, MSE, and so on. When compared to time delay \nneural network (NN) and other ANN models, the best model in \nthis study is a wavelet Elman model. This research also \ndevelops a system for early landslide warnings based on the \nwavelet Elman model.\nAccording to Geetha et al. [15] (2018), using deep learning \ntechniques for meteorological purposes on a time series dataset \nwill significantly improve accuracy precision. This research \nuses deep learning architectures such as LSTM and ConvNet to \nanalyze time series data from 468 months in various locations. \nLater, it was disco...",
      "url": "https://thesai.org/Downloads/Volume13No4/Paper_54-Is_Deep_Learning_on_Tabular_Data_Enough.pdf"
    },
    {
      "title": "(PDF) Comparison of Neural Networks with Traditional Machine Learning Models (e.g., XGBoost, Random Forest)",
      "text": "- [Home](https://www.researchgate.net/directory/publications)\n- [Statistical Learning](https://www.researchgate.net/topic/Statistical-Learning/publications)\n- [Biosignal Processing](https://www.researchgate.net/topic/Biosignal-Processing/publications)\n- [Biosignals](https://www.researchgate.net/topic/Biosignals/publications)\n- [Biological Science](https://www.researchgate.net/topic/Biological-Science/publications)\n- [Physiology](https://www.researchgate.net/topic/Physiology/publications)\n- [Random Forests](https://www.researchgate.net/topic/Random-Forests/publications)\n\nArticle\n\n# Comparison of Neural Networks with Traditional Machine Learning Models (e.g., XGBoost, Random Forest)\n\n- November 2025\n\nAuthors:\n\n[Teslim Lekan](https://www.researchgate.net/scientific-contributions/Teslim-Lekan-2291814365)\n\n[Teslim Lekan](https://www.researchgate.net/scientific-contributions/Teslim-Lekan-2291814365)\n\n- This person is not on ResearchGate, or hasn't claimed this research yet.\n\n\n[Joshua Cena](https://www.researchgate.net/scientific-contributions/Joshua-Cena-2272181118)\n\n[Joshua Cena](https://www.researchgate.net/scientific-contributions/Joshua-Cena-2272181118)\n\n- This person is not on ResearchGate, or hasn't claimed this research yet.\n\n\n[Alfie Harry](https://www.researchgate.net/scientific-contributions/Alfie-Harry-2288249729)\n\n[Alfie Harry](https://www.researchgate.net/scientific-contributions/Alfie-Harry-2288249729)\n\n- This person is not on ResearchGate, or hasn't claimed this research yet.\n\n\n[Husam Rajab](https://www.researchgate.net/scientific-contributions/Husam-Rajab-2316174644)\n\n[Husam Rajab](https://www.researchgate.net/scientific-contributions/Husam-Rajab-2316174644)\n\n- This person is not on ResearchGate, or hasn't claimed this research yet.\n\n\nRequest full-text\n\n[Download citation](https://www.researchgate.net/publication/389546882_Comparison_of_Neural_Networks_with_Traditional_Machine_Learning_Models_eg_XGBoost_Random_Forest/citation/download)\n\nCopy link Link copied\n\n[Request full-text](https://www.researchgate.net/lite.research.ResearchResourcesSummary.requestFulltext.html?publicationUid=389546882&ev=su_requestFulltext) [Download citation](https://www.researchgate.net/publication/389546882_Comparison_of_Neural_Networks_with_Traditional_Machine_Learning_Models_eg_XGBoost_Random_Forest/citation/download)\nCopy link Link copied\n\nTo read the full-text of this research, you can request a copy directly from the authors.\n\n## Abstract\n\nThe rapid advancement of machine learning has led to the development of various modeling techniques, each with its strengths and limitations. This study compares the performance of neural networks (NNs) with traditional machine learning models such as XGBoost and Random Forest across multiple datasets and tasks. While neural networks, particularly deep learning architectures, have gained significant attention for their ability to capture complex, non-linear relationships in large-scale data, traditional models like XGBoost and Random Forest remain highly effective for structured data and tabular datasets. The comparison focuses on key metrics such as accuracy, computational efficiency, interpretability, and scalability. Neural networks often excel in tasks involving unstructured data (e.g., images, text) and large datasets with high dimensionality, leveraging their ability to learn hierarchical features. However, they typically require substantial computational resources and extensive hyperparameter tuning. In contrast, XGBoost and Random Forest are more interpretable, computationally efficient, and often outperform neural networks on smaller, structured datasets. This study also highlights the trade-offs between model complexity and performance, emphasizing the importance of selecting the right model based on the problem domain, data characteristics, and resource constraints. The findings suggest that while neural networks are powerful tools for specific applications, traditional machine learning models remain highly competitive and practical for many real-world scenarios. This comparison provides valuable insights for practitioners and researchers in choosing the most appropriate modeling approach for their specific use cases.\n\n**Discover the world's research**\n\n- 25+ million members\n- 160+ million publication pages\n- 2.3+ billion citations\n\n[Join for free](https://www.researchgate.net/signup.SignUp.html)\n\n## No full-text available\n\nTo read the full-text of this research, you can request a copy directly from the authors.\n\nRequest full-text PDF\n\nResearchGate has not been able to resolve any citations for this publication.\n\n[AI in Treasury Management: Enhancing Bank's Treasury System for Budget Execution in the Medium Term](https://www.researchgate.net/publication/386426285_AI_in_Treasury_Management_Enhancing_Bank's_Treasury_System_for_Budget_Execution_in_the_Medium_Term)\n\nArticle\n\nFull-text available\n\n- Jun 2024\n\n- [Ardhendu Sekhar Nanda](https://www.researchgate.net/profile/Ardhendu-Sekhar-Nanda)\n\nArtificial intelligence (AI), which has become more famous in demand in the global financial as well as other industries, has influenced human life's many aspects. In the context of technology adoption of Treasury Systems of Banks (TSB), various studies have been conducted by researchers. But, for budget executions, a small amount of studies have been conducted on the impact of AI in the TSB. Hence, this research investigated the AI functional model impacts on the banks' TS for budget execution in the medium term to fill this study gap. By using a convenience sampling technique, data has been gathered from 349 respondents in metro cities in India. As per the outcome, \"AI Awareness\", \"AI Ethical principles\", \"Deep Learning (DL) \", \"Machine Learning (ML) \", and \"robotics\" had a positive and significant association with banks' TSs for budget execution in the medium term. Moreover, as per the hypothesis testing, hypothesis 2 had significantly gained the highest relationship between the functional model of AI and the TSB.\n\n[View](https://www.researchgate.net/publication/386426285_AI_in_Treasury_Management_Enhancing_Bank's_Treasury_System_for_Budget_Execution_in_the_Medium_Term)\n\nShow abstract\n\n[This work is licensed under CC BY-NC-SA 4.0. Advancements in Natural Language Processing for Automotive Virtual Assistants Enhancing User Experience and Safety](https://www.researchgate.net/publication/384111181_This_work_is_licensed_under_CC_BY-NC-SA_40_Advancements_in_Natural_Language_Processing_for_Automotive_Virtual_Assistants_Enhancing_User_Experience_and_Safety)\n\nArticle\n\nFull-text available\n\n- Mar 2023\n\n- [Aravind Sasidharan Pillai](https://www.researchgate.net/profile/Aravind-Sasidharan-Pillai)\n\nAdvancements in Natural Language Processing (NLP) have significantly enhanced the capabilities of automotive virtual assistants, revolutionizing user experience and safety in vehicles. This research article explores the integration of NLP technologies in automotive virtual assistants, focusing on improving user interaction and safety features. It covers topics such as voice-activated control systems, sentiment analysis for personalized responses, and NLP-driven predictive maintenance alerts for vehicles. The paper provides insights into the latest developments in NLP for automotive applications and discusses the potential benefits and challenges of integrating these technologies into vehicles.\n\n[View](https://www.researchgate.net/publication/384111181_This_work_is_licensed_under_CC_BY-NC-SA_40_Advancements_in_Natural_Language_Processing_for_Automotive_Virtual_Assistants_Enhancing_User_Experience_and_Safety)\n\nShow abstract\n\n[A Natural Language Processing Approach to Grouping Students by Shared Interests](https://www.researchgate.net/publication/384110746_A_Natural_Language_Processing_Approach_to_Grouping_Students_by_Shared_Interests)\n\nArticle\n\nFull-text available\n\n- Jan 2022\n\n- [Aravind Sasidharan Pillai](https://www.researchgate.net/profile/Ara...",
      "url": "https://www.researchgate.net/publication/389546882_Comparison_of_Neural_Networks_with_Traditional_Machine_Learning_Models_eg_XGBoost_Random_Forest"
    },
    {
      "title": "TabM : Advancing Tabular Deep Learning\n with Parameter-Efficient Ensembling",
      "text": "TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling\n# TabM: Advancing Tabular Deep Learning\nwith Parameter-Efficient Ensembling\nYury Gorishniy\nYandex\n&amp;Akim Kotelnikov\nHSE University, Yandex\n&amp;Artem Babenko\nYandexThe corresponding author:firstnamelastname@gmail.com\n###### Abstract\nDeep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods.\nThis study highlights a major, yet so far overlooked opportunity for substantially improving tabular MLPs: namely, parameter-efficient ensembling\n\u2014a paradigm for implementing an ensemble of models as one model producing multiple predictions.\nWe start by developingTabM\u2014 a simple model based on MLP and our variations of BatchEnsemble (an existing technique).\nThen, we perform a large-scale evaluation of tabular DL architectures on public benchmarks in terms of both task performance and efficiency, which renders the landscape of tabular DL in a new light.\nGenerally, we show that MLPs, includingTabM, form a line of stronger and more practical models compared to attention- and retrieval-based architectures.\nIn particular, we find thatTabMdemonstrates the best performance among tabular DL models.\nLastly, we conduct an empirical analysis on the ensemble-like nature ofTabM.\nFor example, we observe that the multiple predictions ofTabMare weak individually, but powerful collectively.\nOverall, our work brings an impactful technique to tabular DL, analyses its behaviour, and advances the performance-efficiencytrade-offwithTabM\u2014 a simple and powerful baseline for researchers and practitioners.\nThe code is available at:[https://github.com/yandex-research/tabm](https://github.com/yandex-research/tabm).\n## 1Introduction\nSupervised learning on tabular data is a ubiquitous machine learning (ML) scenario in a wide range of industrial applications.\nAmong classic non-deep-learning methods, the state-of-the-art solution for such tasks is gradient-boosted decision trees (GBDT)> (Prokhorenkova et\u00a0al., [> 2018\n](https://arxiv.org/html/2410.24210v1#bib.bib35)> ; Chen &amp; Guestrin, [> 2016\n](https://arxiv.org/html/2410.24210v1#bib.bib10)> ; Ke et\u00a0al., [> 2017\n](https://arxiv.org/html/2410.24210v1#bib.bib23)> )\n.\nDeep learning (DL) models for tabular data, in turn, are reportedly improving, and the most recent works claim to perform on par or even outperform GBDT on academic benchmarks> (Hollmann et\u00a0al., [> 2023\n](https://arxiv.org/html/2410.24210v1#bib.bib18)> ; Chen et\u00a0al., [> 2023b\n](https://arxiv.org/html/2410.24210v1#bib.bib9)> ; [> a\n](https://arxiv.org/html/2410.24210v1#bib.bib8)> ; Gorishniy et\u00a0al., [> 2024\n](https://arxiv.org/html/2410.24210v1#bib.bib15)> )\n.\nHowever, from the practical perspective, it is unclear if tabular DL offers any obvious go-to baselines beyond simple architectures in the spirit of a multilayer perceptron (MLP).First, the scale and consistency of performance improvements of new methods w.r.t. simple MLP-like baselines are not always explicitly analyzed in the literature.\nThus, one has to infer those statistics from numerous per-dataset performance scores, which makes it hard to reason about the progress.\nAt the same time, due to the extreme diversity of tabular datasets, consistency is an especially valuable and hard-to-achieve property for a hypothetical go-to baseline.Second, efficiency-related properties, such as training time, and especially inference throughput, sometimes receive less attention.\nWhile methods are usually equally affordable on small-to-medium datasets (e.g.&lt;&lt;&lt;100K objects), their applicability to larger datasets remains uncertain.Third, some recent work generally suggests that the progress on academic benchmarks may not transfer that well to real-world tasks> (Rubachev et\u00a0al., [> 2024\n](https://arxiv.org/html/2410.24210v1#bib.bib38)> )\n.\nWith all the above in mind, in this work, we thoroughly evaluate existing tabular DL methods and find that non-MLP models do not yet offer a convincing replacement for MLPs.\nAt the same time, we identify a previously overlooked path towards more powerful, reliable and reasonably efficient tabular DL models.\nIn a nutshell, we find that the parameter-efficient approach to deep ensembling, where most weights are shared between ensemble members, allows making simple and strong tabular models out of plain MLPs.\nFor example, MLP coupled with BatchEnsemble> (Wen et\u00a0al., [> 2020\n](https://arxiv.org/html/2410.24210v1#bib.bib46)> )\n\u2014a long-existing method \u2014right away outperforms popular attention-based models, such as FT-Transformer> (Gorishniy et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib13)> )\n, while being simpler and more efficient.\nThis result alone suggests that the parameter-efficient ensembling is a low-hanging fruit for tabular DL.\nOur work builds on the above observations, and offersTabM\u2014 a new powerful and practical model for researchers and practitioners.\nDrawing an informal parallel with GBDT (an ensemble of decision trees),TabMcan also be viewed as a simple base model (MLP) combined with an ensembling-like technique, providing high performance and simple implementation at the same time.\nMain contributions.We summarize our main contributions as follows:\n1. 1.\nWe presentTabM\u2014 a simple DL architecture for supervised learning on tabular data.TabMis based on MLP and parameter-efficient ensembling techniques closely related to BatchEnsemble> (Wen et\u00a0al., [> 2020\n](https://arxiv.org/html/2410.24210v1#bib.bib46)> )\n.\nIn particular,TabMproducesMultiple predictions per object.TabMeasily competes with GBDT and outperforms prior tabular DL models, while being more efficient than attention- and retrieval-based DL architectures.\n2. 2.\nWe provide a fresh perspective on tabular DL models in a large-scale evaluation along four dimensions: performance ranks, performance score distributions, training time and inference throughput.\nOne of our findings is that MLPs, includingTabM, hit an appealing performance-efficiency tradeoff, which is not the case for attention- and retrieval-based models.\n3. 3.\nEmpirically, we show that the multiple predictions ofTabMare weak and overfitted individually, while their average is strong and generalizable.\nThe training gradients ofTabM, in turn, can be viewed as an \u201censemble\u201d of diverse gradients coming from the multiple predictions.\n## 2Related work\nDecision-tree-based models.Gradient-boosted decision trees (GBDT)> (Chen &amp; Guestrin, [> 2016\n](https://arxiv.org/html/2410.24210v1#bib.bib10)> ; Ke et\u00a0al., [> 2017\n](https://arxiv.org/html/2410.24210v1#bib.bib23)> ; Prokhorenkova et\u00a0al., [> 2018\n](https://arxiv.org/html/2410.24210v1#bib.bib35)> )\nis a strong and efficient baseline for tabular tasks.\nGBDT is a classic machine learning model, specifically, an ensemble of decision trees.\nOur modelTabMis a deep learning model, specifically, a parameter-efficient ensemble of MLPs.\nTabular deep learning architectures.A large number of deep learning architectures for tabular data has been proposed over the recent years.\nThat includes attention-based architectures> (Song et\u00a0al., [> 2019\n](https://arxiv.org/html/2410.24210v1#bib.bib40)> ; Gorishniy et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib13)> ; Somepalli et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib39)> ; Kossen et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib26)> ; Yan et\u00a0al., [> 2023\n](https://arxiv.org/html/2410.24210v1#bib.bib47)> )\n, retrieval-augmented architectures> (Somepalli et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib39)> ; Kossen et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib26)> ; Gorishniy et\u00a0al., [> 2024\n](https://arxiv.org/html/2410.24210v1#bib.bib15)> ; Ye et\u00a0al., [> 2024\n](https://arxiv.org/html/2410.24210v1#bib.bib48)> )\n, MLP-like models> (Gorishniy et\u00a0al., [> 2021\n](https://arxiv.org/html/2410.24210v1#bib.bib13)> ; Klambauer e...",
      "url": "https://arxiv.org/html/2410.24210v1"
    },
    {
      "title": "Why do tree-based models still outperform deep learning on tabular data?",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/abs/2207.08815"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2006.14284] Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2006.14284\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2006.14284**(cs)\n[Submitted on 25 Jun 2020]\n# Title:Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation\nAuthors:[Rasool Fakoor](https://arxiv.org/search/cs?searchtype=author&amp;query=Fakoor,+R),[Jonas Mueller](https://arxiv.org/search/cs?searchtype=author&amp;query=Mueller,+J),[Nick Erickson](https://arxiv.org/search/cs?searchtype=author&amp;query=Erickson,+N),[Pratik Chaudhari](https://arxiv.org/search/cs?searchtype=author&amp;query=Chaudhari,+P),[Alexander J. Smola](https://arxiv.org/search/cs?searchtype=author&amp;query=Smola,+A+J)\nView a PDF of the paper titled Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation, by Rasool Fakoor and 4 other authors\n[View PDF](https://arxiv.org/pdf/2006.14284)> > Abstract:\n> Automated machine learning (AutoML) can produce complex model ensembles by stacking, bagging, and boosting many individual models like trees, deep networks, and nearest neighbor estimators. While highly accurate, the resulting predictors are large, slow, and opaque as compared to their constituents. To improve the deployment of AutoML on tabular data, we propose FAST-DAD to distill arbitrarily complex ensemble predictors into individual models like boosted trees, random forests, and deep networks. At the heart of our approach is a data augmentation strategy based on Gibbs sampling from a self-attention pseudolikelihood estimator. Across 30 datasets spanning regression and binary/multiclass classification tasks, FAST-DAD distillation produces significantly better individual models than one obtains through standard training on the original data. Our individual distilled models are over 10x faster and more accurate than ensemble predictors produced by AutoML tools like H2O/AutoSklearn. Subjects:|Machine Learning (cs.LG); Machine Learning (stat.ML)|\nCite as:|[arXiv:2006.14284](https://arxiv.org/abs/2006.14284)[cs.LG]|\n|(or[arXiv:2006.14284v1](https://arxiv.org/abs/2006.14284v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2006.14284](https://doi.org/10.48550/arXiv.2006.14284)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\nJournalreference:|NeurIPS 2020|\n## Submission history\nFrom: Jonas Mueller [[view email](https://arxiv.org/show-email/368fadf3/2006.14284)]\n**[v1]**Thu, 25 Jun 2020 09:57:47 UTC (3,854 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation, by Rasool Fakoor and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2006.14284)\n* [TeX Source](https://arxiv.org/src/2006.14284)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2006.14284&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2006.14284&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2020-06](https://arxiv.org/list/cs.LG/2020-06)\nChange to browse by:\n[cs](https://arxiv.org/abs/2006.14284?context=cs)\n[stat](https://arxiv.org/abs/2006.14284?context=stat)\n[stat.ML](https://arxiv.org/abs/2006.14284?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2006.14284)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2006.14284)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2006.14284)\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2006.html#abs-2006-14284)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2006-14284)\n[Rasool Fakoor](<https://dblp.uni-trier.de/search/author?author=Rasool Fakoor>)\n[Jonas Mueller](<https://dblp.uni-trier.de/search/author?author=Jonas Mueller>)\n[Nick Erickson](<https://dblp.uni-trier.de/search/author?author=Nick Erickson>)\n[Pratik Chaudhari](<https://dblp.uni-trier.de/search/author?author=Pratik Chaudhari>)\n[Alexander J. Smola](<https://dblp.uni-trier.de/search/author?author=Alexander J. Smola>)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2006.14284&amp;description=Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2006.14284&amp;title=Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organ...",
      "url": "https://arxiv.org/abs/2006.14284"
    },
    {
      "title": "",
      "text": "Transformers Boost the Performance of Decision Trees on Tabular\nData across Sample Sizes\nMayuka Jayawardhana\u2217 1, Renbo Tu2, Samuel Dooley3, Valeriia Cherepanova4,\nAndrew Gordon Wilson5, Frank Hutter6, Colin White7, Tom Goldstein1, Micah Goldblum8\n1 University of Maryland, 2 University of Toronto, 3 Meta, 4 Amazon, 5 New York University,\n6 University of Freiburg, 7 Abacus.AI, 8 Columbia University\nAbstract\nLarge language models (LLMs) perform remarkably well on tabular datasets in zero- and\nfew-shot settings, since they can extract meaning from natural language column headers that\ndescribe features and labels. Similarly, TabPFN, a recent non-LLM transformer pretrained on\nnumerous tables for in-context learning, has demonstrated excellent performance for dataset sizes\nup to a thousand samples. In contrast, gradient-boosted decision trees (GBDTs) are typically\ntrained from scratch on each dataset without benefiting from pretraining data and must learn\nthe relationships between columns from their entries alone since they lack natural language\nunderstanding. LLMs and TabPFN excel on small tabular datasets where a strong prior is\nessential, yet they are not competitive with GBDTs on medium or large datasets, since their\ncontext lengths are limited. In this paper, we propose a simple and lightweight approach for\nfusing large language models and TabPFN with gradient-boosted decision trees, which allows\nscalable GBDTs to benefit from the natural language capabilities and pretraining of transformers.\nWe name our fusion methods LLM-Boost and PFN-Boost, respectively. While matching or\nsurpassing the performance of the transformer at sufficiently small dataset sizes and GBDTs at\nsufficiently large sizes, LLM-Boost and PFN-Boost outperform both standalone components on\na wide range of dataset sizes in between. We demonstrate state-of-the-art performance against\nnumerous baselines and ensembling algorithms. We find that PFN-Boost achieves the best\naverage performance among all methods we test for all but very small dataset sizes. We release\nour code at https://github.com/MayukaJ/LLM-Boost.\n1 Introduction\nTabular data, or spreadsheets, constitute a large portion of real-world machine learning problems\n[4]. Tabular data comprise (a) columns, each containing a different feature or label; (b) rows, each\ncontaining an individual data sample; and (c) column headers describing the content of each column,\noften in the form of text.\nGradient-boosted decision trees (GBDTs), such as XGBoost [6], LightGBM [22], and CatBoost\n[27], have remained the de facto machine learning algorithms for analyzing tabular data over the\npast decade [24]. They are efficient to train even on a CPU, they achieve competitive performance\non a wide variety of datasets and sample sizes, and they can be deployed via user-friendly packages\n\u2217Correspondence to: mayukaj@umd.edu, micah.g@columbia.edu.\n1\narXiv:2502.02672v2 [cs.CL] 6 Feb 2025\naccessible to non-experts. However, gradient-boosted decision trees have two major drawbacks:\n(a) They only ingest the row features in a table and not the column headers, which may contain\nuseful text descriptions. For example, one may not need training data to anticipate that a hospital\npatient\u2019s weight is useful for predicting occurrences of heart disease. Instead of leveraging column\nheaders, from which a human might intuit relationships between columns, GBDTs have to learn\nthese relationships from scratch from the feature values themselves. (b) GBDTs are trained from\nscratch on each dataset, instead of benefiting from vast prior experience on other datasets, a staple\nof foundation models.\nIn contrast to gradient-boosted decision trees, large language models (LLMs) can parse and\nextract meaning from column headers, enabling them to achieve performance superior to GBDTs on\nvery small tabular datasets with interpretable headers [18]. LLMs can even make accurate zero-shot\npredictions solely by applying natural language understanding to column headers without in-context\ntraining samples at all [18]. Despite their ability to parse column headers, LLMs are severely limited\nby their limited context length and high fine-tuning costs.\nTabPFN [19] is a tabular transformer, pretrained on a vast number of synthetic tables, that can\nsimultaneously perform in-context learning on an entire trainset and make predictions for the entire\ntestset all in a single forward pass. Similarly to LLMs, TabPFN performance is very strong on small\ndatasets, but it suffers from context-length limitations and can only handle datasets with up to\n1000 samples. Therefore, LLMs and TabPFN cannot easily make use of large sample sizes, whereas\nGBDTs scale well to massive datasets.\nIn this paper, we combine the strengths of gradient-boosted decision trees and recent transformers\nto build models that simultaneously benefit from pretraining and textual column headers while scaling\nto much larger tabular datasets than LLMs and TabPFN could alone. Our method LLM-Boost,\nuses LLM predictions as a starting point for GBDTs, and then learns the residuals from the LLM\npredictions to the label. This technique allows us to not only use the column headers for a strong\nprior but also benefits from the inductive bias and scalability of decision tree algorithms. In our\nexperiments, LLM-Boost showcases state-of-the-art performance, outcompeting strong baselines\nincluding both single models and other ensemble approaches, across a large range of dataset sizes.\nLLM-Boost excels at small and medium sized datasets that are too large for LLMs yet not large\nenough that column headers are not beneficial. Motivated by the strong performance of TabPFN,\nwe apply the same boosting approach swapping out LLMs for TabPFN. Importantly, we find that\nour boosted TabPFN combination, PFN-Boost, achieves the top performance among all methods\nwe consider outside of the very small dataset regime where our boosted LLMs reign supreme. We\nsummarize our contributions as follows.\n\u2022 We propose LLM-Boost: a novel yet simple and easy-to-implement boosting mechanism that\ncombines LLMs, which ingest semantic column headers, with GBDTs that can scale to massive\ndatasets.\n\u2022 We further propose PFN-Boost, where we instead fuse TabPFN and GBDTs for performance\ngains over GBDTs alone across dataset sizes without using column headers.\n\u2022 We conduct thorough experiments across numerous datasets and sample sizes, comparing to\nstrong baselines. LLM-Boost and PFN-Boost demonstrate consistently strong performance.\n2\n2 Related Work\n2.1 GBDTs for Tabular Data\nGradient boosted decision tree algorithms such as XGBoost [6], Catboost [27] and LightGBM [22]\noffer state-of-the-art or near state-of-the-art performance on many tabular tasks [16]. Compared to\ndeep learning models with similar performance, GBDTs offer faster training and inference speeds\neven without GPUs, are easy to tune, and are more straightforward to interpret. However, when\ncompared to deep learning models, tree based models do not generalize as well to diverse unseen\ndata and are not as robust to uninformative features [16]. Recently, TabPFN [19], a transformer for\ntabular in-context learning has demonstrated superior performance on small datasets [24]. In our\nwork, we adopt GBDTs as a base model due to their ability to benefit from large volumes of data,\nand we augment them with TabPFN and LLMs using boosting.\n2.2 Boosting\nBoosting is an ensembling technique for combining multiple weak learners to form a single strong\nprediction model [13]. Boosting algorithms are sequential processes whereby new learners are progres\u0002sively added to predict the residual error of the current ensemble until the error becomes sufficiently\nsmall. Gradient boosting additionally provides a mechanism to update the new learners using an\narbitrary differentiable loss function via gradient descent [14]. Although there are implementation\ndifferences in the GBDT algorithms mentioned above, they share the fundamental process of makin...",
      "url": "https://arxiv.org/pdf/2502.02672"
    }
  ]
}