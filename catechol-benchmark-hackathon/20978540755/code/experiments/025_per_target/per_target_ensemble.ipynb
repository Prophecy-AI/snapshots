{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206d5c18",
   "metadata": {},
   "source": [
    "# Per-Target Ensemble Model\n",
    "\n",
    "**Hypothesis**: Training separate models for SM vs Products may improve performance because:\n",
    "- SM has different distribution (mean 0.52, std 0.36) vs Products (mean ~0.13, std ~0.14)\n",
    "- Product 2 and Product 3 are highly correlated (0.923)\n",
    "- Competition explicitly allows \"different hyper-parameters for different objectives\"\n",
    "\n",
    "**Approach**:\n",
    "- SM model: MLP[64,32] + LightGBM (larger architecture for higher-variance target)\n",
    "- Product model: MLP[32,16] + LightGBM (shared model for correlated P2/P3)\n",
    "\n",
    "**Baseline to beat**: exp_024 CV 0.008689, LB 0.0893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b99796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:02.264560Z",
     "iopub.status.busy": "2026-01-14T03:25:02.263892Z",
     "iopub.status.idle": "2026-01-14T03:25:04.806935Z",
     "shell.execute_reply": "2026-01-14T03:25:04.806322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f4d253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.809033Z",
     "iopub.status.busy": "2026-01-14T03:25:04.808726Z",
     "iopub.status.idle": "2026-01-14T03:25:04.815989Z",
     "shell.execute_reply": "2026-01-14T03:25:04.815450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3579f3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.818021Z",
     "iopub.status.busy": "2026-01-14T03:25:04.817609Z",
     "iopub.status.idle": "2026-01-14T03:25:04.869166Z",
     "shell.execute_reply": "2026-01-14T03:25:04.868656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), DRFP filtered: (24, 122), ACS PCA: (24, 5)\n",
      "Total features: 5 (kinetic) + 13 (Spange) + 122 (DRFP) + 5 (ACS PCA) = 145\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups INCLUDING ACS PCA\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "# Filter DRFP to high-variance columns\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'Total features: 5 (kinetic) + {SPANGE_DF.shape[1]} (Spange) + {DRFP_FILTERED.shape[1]} (DRFP) + {ACS_PCA_DF.shape[1]} (ACS PCA) = {5 + SPANGE_DF.shape[1] + DRFP_FILTERED.shape[1] + ACS_PCA_DF.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2a31f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.871101Z",
     "iopub.status.busy": "2026-01-14T03:25:04.870914Z",
     "iopub.status.idle": "2026-01-14T03:25:04.879445Z",
     "shell.execute_reply": "2026-01-14T03:25:04.878923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 145\n"
     ]
    }
   ],
   "source": [
    "# Combined Featurizer with Arrhenius kinetics AND ACS PCA\n",
    "class ACSPCAFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'Feature dimension: {ACSPCAFeaturizer().feats_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20febdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.881285Z",
     "iopub.status.busy": "2026-01-14T03:25:04.880887Z",
     "iopub.status.idle": "2026-01-14T03:25:04.888448Z",
     "shell.execute_reply": "2026-01-14T03:25:04.887939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModelInternal defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model with configurable output dimension\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('MLPModelInternal defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c5792d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.889995Z",
     "iopub.status.busy": "2026-01-14T03:25:04.889831Z",
     "iopub.status.idle": "2026-01-14T03:25:04.901460Z",
     "shell.execute_reply": "2026-01-14T03:25:04.900935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleTargetMLPEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# Single-Target MLP Ensemble (for SM or Products separately)\n",
    "class SingleTargetMLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=5, data='single', output_dim=1):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.output_dim = output_dim\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize_torch(X_train, flip=False)\n",
    "        # y_train can be a DataFrame with 1 or 2 columns\n",
    "        if isinstance(y_train, pd.DataFrame):\n",
    "            y_vals = torch.tensor(y_train.values)\n",
    "        else:\n",
    "            y_vals = torch.tensor(y_train.reshape(-1, self.output_dim))\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i * 13)\n",
    "            np.random.seed(42 + i * 13)\n",
    "            \n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims, output_dim=self.output_dim).to(device).double()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "            criterion = nn.HuberLoss()\n",
    "            \n",
    "            dataset = TensorDataset(X_all.to(device), y_all.to(device))\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_X, batch_y in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(batch_X)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                scheduler.step(epoch_loss / len(loader))\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize_torch(X_test, flip=False).to(device)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_test, flip=True).to(device)\n",
    "        \n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                pred = model(X_feat)\n",
    "                if self.data_type == 'full':\n",
    "                    pred_flip = model(X_flip)\n",
    "                    pred = (pred + pred_flip) / 2\n",
    "                all_preds.append(pred)\n",
    "        \n",
    "        return torch.stack(all_preds).mean(dim=0).cpu()\n",
    "\n",
    "print('SingleTargetMLPEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceac20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.903271Z",
     "iopub.status.busy": "2026-01-14T03:25:04.903032Z",
     "iopub.status.idle": "2026-01-14T03:25:04.910786Z",
     "shell.execute_reply": "2026-01-14T03:25:04.910301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleTargetLGBMWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# Single-Target LightGBM Wrapper\n",
    "class SingleTargetLGBMWrapper:\n",
    "    def __init__(self, data='single', output_dim=1):\n",
    "        self.data_type = data\n",
    "        self.output_dim = output_dim\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        if isinstance(y_train, pd.DataFrame):\n",
    "            y_vals = y_train.values\n",
    "        else:\n",
    "            y_vals = y_train.reshape(-1, self.output_dim)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.models = []\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        for i in range(self.output_dim):\n",
    "            train_data = lgb.Dataset(X_all, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize(X_test, flip=False)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_test, flip=True)\n",
    "        \n",
    "        preds = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred = model.predict(X_feat)\n",
    "            if self.data_type == 'full':\n",
    "                pred_flip = model.predict(X_flip)\n",
    "                pred = (pred + pred_flip) / 2\n",
    "            preds.append(pred)\n",
    "        \n",
    "        return torch.tensor(np.column_stack(preds))\n",
    "\n",
    "print('SingleTargetLGBMWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8507175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:04.912526Z",
     "iopub.status.busy": "2026-01-14T03:25:04.912356Z",
     "iopub.status.idle": "2026-01-14T03:25:04.919349Z",
     "shell.execute_reply": "2026-01-14T03:25:04.918804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerTargetEnsemble defined\n"
     ]
    }
   ],
   "source": [
    "# Per-Target Ensemble: Separate models for SM vs Products\n",
    "class PerTargetEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        \n",
    "        # SM model: larger architecture for higher-variance target (mean 0.52, std 0.36)\n",
    "        self.sm_mlp = SingleTargetMLPEnsemble(hidden_dims=[64, 32], n_models=5, data=data, output_dim=1)\n",
    "        self.sm_lgbm = SingleTargetLGBMWrapper(data=data, output_dim=1)\n",
    "        \n",
    "        # Product model: shared model for correlated P2/P3 (correlation 0.923)\n",
    "        self.product_mlp = SingleTargetMLPEnsemble(hidden_dims=[32, 16], n_models=5, data=data, output_dim=2)\n",
    "        self.product_lgbm = SingleTargetLGBMWrapper(data=data, output_dim=2)\n",
    "        \n",
    "        self.mlp_weight = 0.6\n",
    "        self.lgbm_weight = 0.4\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # Train SM model on SM target only\n",
    "        y_sm = y_train[['SM']]\n",
    "        self.sm_mlp.train_model(X_train, y_sm)\n",
    "        self.sm_lgbm.train_model(X_train, y_sm)\n",
    "        \n",
    "        # Train Product model on both products\n",
    "        y_products = y_train[['Product 2', 'Product 3']]\n",
    "        self.product_mlp.train_model(X_train, y_products)\n",
    "        self.product_lgbm.train_model(X_train, y_products)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # SM predictions\n",
    "        sm_mlp_pred = self.sm_mlp.predict(X_test)  # Shape: [N, 1]\n",
    "        sm_lgbm_pred = self.sm_lgbm.predict(X_test)  # Shape: [N, 1]\n",
    "        sm_pred = self.mlp_weight * sm_mlp_pred + self.lgbm_weight * sm_lgbm_pred\n",
    "        \n",
    "        # Product predictions\n",
    "        product_mlp_pred = self.product_mlp.predict(X_test)  # Shape: [N, 2]\n",
    "        product_lgbm_pred = self.product_lgbm.predict(X_test)  # Shape: [N, 2]\n",
    "        product_pred = self.mlp_weight * product_mlp_pred + self.lgbm_weight * product_lgbm_pred\n",
    "        \n",
    "        # Combine: [Product 2, Product 3, SM] to match expected output order\n",
    "        return torch.cat([product_pred, sm_pred], dim=1)\n",
    "\n",
    "print('PerTargetEnsemble defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c604adee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T03:25:18.354495Z",
     "iopub.status.busy": "2026-01-14T03:25:18.353980Z",
     "iopub.status.idle": "2026-01-14T04:02:31.465072Z",
     "shell.execute_reply": "2026-01-14T04:02:31.464470Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:34, 94.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [03:07, 93.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [04:35, 91.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [06:03, 90.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [07:36, 90.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [09:08, 91.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [10:40, 91.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [12:13, 91.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [13:45, 92.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [15:19, 92.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [16:52, 92.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [18:25, 92.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [19:59, 93.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [21:32, 93.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [23:06, 93.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [24:40, 93.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [26:18, 94.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [27:51, 94.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [29:25, 94.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [30:59, 94.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [32:32, 93.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [34:05, 93.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [35:39, 93.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [37:13, 93.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [37:13, 93.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2050345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T04:02:43.843531Z",
     "iopub.status.busy": "2026-01-14T04:02:43.842717Z",
     "iopub.status.idle": "2026-01-14T05:16:15.878414Z",
     "shell.execute_reply": "2026-01-14T05:16:15.877829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [05:25, 325.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [10:47, 323.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [16:18, 327.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [21:41, 325.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [27:06, 325.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [32:31, 325.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [37:53, 324.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [43:17, 324.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [48:38, 323.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [54:25, 330.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [1:00:32, 341.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [1:07:03, 356.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [1:13:32, 366.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [1:13:32, 339.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = PerTargetEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab3fdb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:16:29.371595Z",
     "iopub.status.busy": "2026-01-14T05:16:29.370963Z",
     "iopub.status.idle": "2026-01-14T05:16:29.392779Z",
     "shell.execute_reply": "2026-01-14T05:16:29.392022Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947a6408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:16:29.395137Z",
     "iopub.status.busy": "2026-01-14T05:16:29.394908Z",
     "iopub.status.idle": "2026-01-14T05:16:29.438301Z",
     "shell.execute_reply": "2026-01-14T05:16:29.437753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV SCORE VERIFICATION ===\n",
      "Single Solvent MSE: 0.009249 (n=656)\n",
      "Full Data MSE: 0.008971 (n=1227)\n",
      "Overall MSE: 0.009068\n",
      "\n",
      "=== PER-TARGET MSE (Single Solvent) ===\n",
      "Product 2 MSE: 0.005917\n",
      "Product 3 MSE: 0.007797\n",
      "SM MSE: 0.014034\n",
      "\n",
      "exp_024 baseline: CV 0.008689, LB 0.0893\n",
      "Submission shape: (1883, 7)\n",
      "\n",
      "✗ WORSE: 4.36% worse than exp_024\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV score (for verification only - not part of template)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "# Per-target MSE breakdown\n",
    "mse_p2 = np.mean((actuals_single[:, 0] - preds_single[:, 0]) ** 2)\n",
    "mse_p3 = np.mean((actuals_single[:, 1] - preds_single[:, 1]) ** 2)\n",
    "mse_sm = np.mean((actuals_single[:, 2] - preds_single[:, 2]) ** 2)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\n=== PER-TARGET MSE (Single Solvent) ===')\n",
    "print(f'Product 2 MSE: {mse_p2:.6f}')\n",
    "print(f'Product 3 MSE: {mse_p3:.6f}')\n",
    "print(f'SM MSE: {mse_sm:.6f}')\n",
    "print(f'\\nexp_024 baseline: CV 0.008689, LB 0.0893')\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "\n",
    "if overall_mse < 0.008689:\n",
    "    improvement = (0.008689 - overall_mse) / 0.008689 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than exp_024!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008689) / 0.008689 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than exp_024')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
