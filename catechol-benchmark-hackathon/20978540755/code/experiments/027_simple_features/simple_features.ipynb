{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad79186e",
   "metadata": {},
   "source": [
    "# Simple Features for Better Generalization\n",
    "\n",
    "**Problem**: The CV-LB gap is ~10x (LB = 4.22*CV + 0.0533). The intercept (0.0533) is 3x higher than target (0.01727).\n",
    "\n",
    "**Hypothesis**: With 145 features, some may be overfitting to train distribution. Simpler feature set may generalize better and reduce the CV-LB gap.\n",
    "\n",
    "**Approach**:\n",
    "- Remove DRFP features (122 features) - they may not generalize\n",
    "- Use only Spange (13) + ACS PCA (5) + Arrhenius (5) = 23 features\n",
    "- Keep weighted loss (2x SM) from exp_026\n",
    "\n",
    "**Goal**: Reduce the CV-LB gap, not just improve CV.\n",
    "\n",
    "**Baseline**: exp_026 CV 0.008465, LB 0.0887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c23ce2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:50.634597Z",
     "iopub.status.busy": "2026-01-14T06:40:50.634060Z",
     "iopub.status.idle": "2026-01-14T06:40:53.182611Z",
     "shell.execute_reply": "2026-01-14T06:40:53.181801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c24d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.185067Z",
     "iopub.status.busy": "2026-01-14T06:40:53.184290Z",
     "iopub.status.idle": "2026-01-14T06:40:53.192024Z",
     "shell.execute_reply": "2026-01-14T06:40:53.191348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fbf2fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.194345Z",
     "iopub.status.busy": "2026-01-14T06:40:53.193721Z",
     "iopub.status.idle": "2026-01-14T06:40:53.204697Z",
     "shell.execute_reply": "2026-01-14T06:40:53.204030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13)\n",
      "ACS PCA: (24, 5)\n",
      "Total features: 5 (kinetic) + 13 (Spange) + 5 (ACS PCA) = 23\n",
      "\n",
      "NO DRFP features - testing if simpler features generalize better\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookups - ONLY Spange and ACS PCA (NO DRFP)\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}')\n",
    "print(f'ACS PCA: {ACS_PCA_DF.shape}')\n",
    "print(f'Total features: 5 (kinetic) + {SPANGE_DF.shape[1]} (Spange) + {ACS_PCA_DF.shape[1]} (ACS PCA) = {5 + SPANGE_DF.shape[1] + ACS_PCA_DF.shape[1]}')\n",
    "print('\\nNO DRFP features - testing if simpler features generalize better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5f06cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.206588Z",
     "iopub.status.busy": "2026-01-14T06:40:53.206015Z",
     "iopub.status.idle": "2026-01-14T06:40:53.214609Z",
     "shell.execute_reply": "2026-01-14T06:40:53.213979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFeaturizer defined with 23 features (vs 145 in exp_026)\n"
     ]
    }
   ],
   "source": [
    "# Simple Featurizer - Spange + ACS PCA + Arrhenius kinetics ONLY (23 features)\n",
    "class SimpleFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.acs_pca_df.shape[1]  # 23 features\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                X_spange = B_spange * (1 - (1-pct)) + A_spange * (1-pct)\n",
    "                X_acs = B_acs * (1 - (1-pct)) + A_acs * (1-pct)\n",
    "            else:\n",
    "                X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "                X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip))\n",
    "\n",
    "print(f'SimpleFeaturizer defined with {SimpleFeaturizer().feats_dim} features (vs 145 in exp_026)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a476ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.216371Z",
     "iopub.status.busy": "2026-01-14T06:40:53.216188Z",
     "iopub.status.idle": "2026-01-14T06:40:53.221390Z",
     "shell.execute_reply": "2026-01-14T06:40:53.220737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedHuberLoss defined: weights = [1.0, 1.0, 2.0] for [P2, P3, SM]\n"
     ]
    }
   ],
   "source": [
    "# Weighted Huber Loss - weights SM (target 2) higher\n",
    "class WeightedHuberLoss(nn.Module):\n",
    "    def __init__(self, weights=[1.0, 1.0, 2.0]):  # [P2, P3, SM]\n",
    "        super().__init__()\n",
    "        self.weights = torch.tensor(weights, dtype=torch.double)\n",
    "        self.huber = nn.HuberLoss(reduction='none')\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        huber_loss = self.huber(pred, target)\n",
    "        weighted_loss = huber_loss * self.weights.to(pred.device)\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "print('WeightedHuberLoss defined: weights = [1.0, 1.0, 2.0] for [P2, P3, SM]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b20c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.223161Z",
     "iopub.status.busy": "2026-01-14T06:40:53.222754Z",
     "iopub.status.idle": "2026-01-14T06:40:53.228754Z",
     "shell.execute_reply": "2026-01-14T06:40:53.228097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModelInternal defined\n"
     ]
    }
   ],
   "source": [
    "# MLP Model [32,16] with BatchNorm\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('MLPModelInternal defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85941369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.230518Z",
     "iopub.status.busy": "2026-01-14T06:40:53.230332Z",
     "iopub.status.idle": "2026-01-14T06:40:53.241083Z",
     "shell.execute_reply": "2026-01-14T06:40:53.240441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLPEnsemble defined with 23 features\n"
     ]
    }
   ],
   "source": [
    "# MLP Ensemble with Simple Features and Weighted Loss\n",
    "class SimpleMLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=5, data='single', loss_weights=[1.0, 1.0, 2.0]):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.loss_weights = loss_weights\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))  # SIMPLE FEATURES\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize_torch(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        self.models = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i * 13)\n",
    "            np.random.seed(42 + i * 13)\n",
    "            \n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims).to(device).double()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "            criterion = WeightedHuberLoss(weights=self.loss_weights)\n",
    "            \n",
    "            dataset = TensorDataset(X_all.to(device), y_all.to(device))\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for batch_X, batch_y in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(batch_X)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                scheduler.step(epoch_loss / len(loader))\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize_torch(X_test, flip=False).to(device)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_test, flip=True).to(device)\n",
    "        \n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                pred = model(X_feat)\n",
    "                if self.data_type == 'full':\n",
    "                    pred_flip = model(X_flip)\n",
    "                    pred = (pred + pred_flip) / 2\n",
    "                all_preds.append(pred)\n",
    "        \n",
    "        return torch.stack(all_preds).mean(dim=0).cpu()\n",
    "\n",
    "print('SimpleMLPEnsemble defined with 23 features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1353d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.243124Z",
     "iopub.status.busy": "2026-01-14T06:40:53.242602Z",
     "iopub.status.idle": "2026-01-14T06:40:53.250543Z",
     "shell.execute_reply": "2026-01-14T06:40:53.249924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLGBMWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Wrapper with Simple Features\n",
    "class SimpleLGBMWrapper:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = SimpleFeaturizer(mixed=(data=='full'))  # SIMPLE FEATURES\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = y_train.values\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_std, X_flip])\n",
    "            y_all = np.vstack([y_vals, y_vals])\n",
    "        else:\n",
    "            X_all, y_all = X_std, y_vals\n",
    "        \n",
    "        self.models = []\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_all, label=y_all[:, i])\n",
    "            model = lgb.train(params, train_data, num_boost_round=100)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_feat = self.featurizer.featurize(X_test, flip=False)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_test, flip=True)\n",
    "        \n",
    "        preds = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred = model.predict(X_feat)\n",
    "            if self.data_type == 'full':\n",
    "                pred_flip = model.predict(X_flip)\n",
    "                pred = (pred + pred_flip) / 2\n",
    "            preds.append(pred)\n",
    "        \n",
    "        return torch.tensor(np.column_stack(preds))\n",
    "\n",
    "print('SimpleLGBMWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f245d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:40:53.252561Z",
     "iopub.status.busy": "2026-01-14T06:40:53.252050Z",
     "iopub.status.idle": "2026-01-14T06:40:53.257877Z",
     "shell.execute_reply": "2026-01-14T06:40:53.257230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFeaturesEnsemble defined (23 features vs 145 in exp_026)\n"
     ]
    }
   ],
   "source": [
    "# Simple Features Ensemble: MLP (0.6) + LightGBM (0.4)\n",
    "class SimpleFeaturesEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.mlp = SimpleMLPEnsemble(hidden_dims=[32, 16], n_models=5, data=data, loss_weights=[1.0, 1.0, 2.0])\n",
    "        self.lgbm = SimpleLGBMWrapper(data=data)\n",
    "        self.mlp_weight = 0.6\n",
    "        self.lgbm_weight = 0.4\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        self.lgbm.train_model(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        mlp_pred = self.mlp.predict(X_test)\n",
    "        lgbm_pred = self.lgbm.predict(X_test)\n",
    "        # Clip predictions to [0, 1]\n",
    "        combined = self.mlp_weight * mlp_pred + self.lgbm_weight * lgbm_pred\n",
    "        return torch.clamp(combined, 0, 1)\n",
    "\n",
    "print('SimpleFeaturesEnsemble defined (23 features vs 145 in exp_026)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3292ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T06:41:02.562269Z",
     "iopub.status.busy": "2026-01-14T06:41:02.561560Z",
     "iopub.status.idle": "2026-01-14T07:01:46.130612Z",
     "shell.execute_reply": "2026-01-14T07:01:46.129993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:49, 49.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:37, 48.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:23, 47.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [03:09, 46.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [03:58, 47.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [04:46, 47.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [05:34, 48.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [06:23, 48.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [07:11, 48.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [08:02, 48.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [08:54, 49.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [09:48, 51.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [10:42, 52.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [11:37, 52.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [12:31, 53.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [13:26, 53.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [14:23, 54.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [15:17, 54.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [16:12, 54.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [17:06, 54.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [18:01, 54.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [18:55, 54.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [19:49, 54.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [20:43, 54.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [20:43, 51.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleFeaturesEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7951ba02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:02:00.421777Z",
     "iopub.status.busy": "2026-01-14T07:02:00.420930Z",
     "iopub.status.idle": "2026-01-14T07:41:34.651706Z",
     "shell.execute_reply": "2026-01-14T07:41:34.651176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [03:10, 190.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [06:18, 189.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [09:31, 190.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [12:40, 190.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [15:35, 184.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [18:41, 185.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [21:40, 183.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [24:32, 179.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [27:20, 176.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [30:23, 178.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [33:26, 179.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [36:30, 181.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [39:34, 181.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [39:34, 182.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = SimpleFeaturesEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6326f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:41:51.236759Z",
     "iopub.status.busy": "2026-01-14T07:41:51.236206Z",
     "iopub.status.idle": "2026-01-14T07:41:51.254440Z",
     "shell.execute_reply": "2026-01-14T07:41:51.253888Z"
    }
   },
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6298db0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T07:42:31.505252Z",
     "iopub.status.busy": "2026-01-14T07:42:31.505000Z",
     "iopub.status.idle": "2026-01-14T07:42:31.547180Z",
     "shell.execute_reply": "2026-01-14T07:42:31.546599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV SCORE VERIFICATION ===\n",
      "Single Solvent MSE: 0.009116 (n=656)\n",
      "Full Data MSE: 0.009168 (n=1227)\n",
      "Overall MSE: 0.009150\n",
      "\n",
      "exp_026 baseline (145 features): CV 0.008465, LB 0.0887\n",
      "This (23 features): CV 0.009150\n",
      "\n",
      "Feature reduction: 145 -> 23 (84.1% fewer features)\n",
      "\n",
      "✗ WORSE: 8.09% worse than exp_026\n",
      "But simpler features may generalize better (lower CV-LB gap)\n"
     ]
    }
   ],
   "source": [
    "# Calculate CV score (for verification only - NOT part of submission)\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "X_full, Y_full = load_data(\"full\")\n",
    "\n",
    "# Get actuals in same order as predictions\n",
    "actuals_single = []\n",
    "for solvent in sorted(X_single[\"SOLVENT NAME\"].unique()):\n",
    "    mask = X_single[\"SOLVENT NAME\"] == solvent\n",
    "    actuals_single.append(Y_single[mask].values)\n",
    "actuals_single = np.vstack(actuals_single)\n",
    "\n",
    "actuals_full = []\n",
    "ramps = X_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "for _, row in ramps.iterrows():\n",
    "    mask = (X_full[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X_full[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"])\n",
    "    actuals_full.append(Y_full[mask].values)\n",
    "actuals_full = np.vstack(actuals_full)\n",
    "\n",
    "# Get predictions\n",
    "preds_single = submission_single_solvent[['target_1', 'target_2', 'target_3']].values\n",
    "preds_full = submission_full_data[['target_1', 'target_2', 'target_3']].values\n",
    "\n",
    "# Calculate MSE\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== CV SCORE VERIFICATION ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')\n",
    "print(f'\\nexp_026 baseline (145 features): CV 0.008465, LB 0.0887')\n",
    "print(f'This (23 features): CV {overall_mse:.6f}')\n",
    "print(f'\\nFeature reduction: 145 -> 23 ({(145-23)/145*100:.1f}% fewer features)')\n",
    "\n",
    "if overall_mse < 0.008465:\n",
    "    improvement = (0.008465 - overall_mse) / 0.008465 * 100\n",
    "    print(f'\\n✓ IMPROVEMENT: {improvement:.2f}% better than exp_026!')\n",
    "else:\n",
    "    degradation = (overall_mse - 0.008465) / 0.008465 * 100\n",
    "    print(f'\\n✗ WORSE: {degradation:.2f}% worse than exp_026')\n",
    "    print('But simpler features may generalize better (lower CV-LB gap)')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
