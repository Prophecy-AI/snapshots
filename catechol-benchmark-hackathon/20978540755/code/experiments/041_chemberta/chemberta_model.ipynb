{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4df7318",
   "metadata": {},
   "source": [
    "# Experiment 041: ChemBERTa Pre-trained Embeddings\n",
    "\n",
    "**Hypothesis:** Pre-trained molecular embeddings from ChemBERTa (trained on millions of molecules) will transfer better to unseen solvents than models trained from scratch.\n",
    "\n",
    "**Approach:**\n",
    "1. Use ChemBERTa to get 768-dim embeddings for each solvent SMILES\n",
    "2. Combine with Arrhenius kinetics features\n",
    "3. Feed into MLP model\n",
    "4. Test on single fold first, then full CV if promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bf162a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:10:32.144480Z",
     "iopub.status.busy": "2026-01-15T05:10:32.143734Z",
     "iopub.status.idle": "2026-01-15T05:10:35.022811Z",
     "shell.execute_reply": "2026-01-15T05:10:35.022170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers available\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for transformers\n",
    "try:\n",
    "    from transformers import AutoModel, AutoTokenizer\n",
    "    print('Transformers available')\n",
    "except ImportError:\n",
    "    print('Installing transformers...')\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'transformers', '-q'])\n",
    "    from transformers import AutoModel, AutoTokenizer\n",
    "    print('Transformers installed')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c43c757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:11:13.410946Z",
     "iopub.status.busy": "2026-01-15T05:11:13.410213Z",
     "iopub.status.idle": "2026-01-15T05:11:13.415930Z",
     "shell.execute_reply": "2026-01-15T05:11:13.415345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"SM\", \"Product 2\", \"Product 3\"]]  # Correct column names\n",
    "    return X, Y\n",
    "\n",
    "print('Data loading functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceabc65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:10:35.031568Z",
     "iopub.status.busy": "2026-01-15T05:10:35.031364Z",
     "iopub.status.idle": "2026-01-15T05:10:35.042639Z",
     "shell.execute_reply": "2026-01-15T05:10:35.042036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES lookup: 26 solvents\n",
      "                                           solvent smiles\n",
      "SOLVENT NAME                                             \n",
      "Cyclohexane                                      C1CCCCC1\n",
      "Ethyl Acetate                                   O=C(OCC)C\n",
      "Acetic Acid                                       CC(=O)O\n",
      "2-Methyltetrahydrofuran [2-MeTHF]              O1C(C)CCC1\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol  C(C(F)(F)F)(C(F)(F)F)O\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES lookup\n",
    "SMILES_DF = pd.read_csv(f'{DATA_PATH}/smiles_lookup.csv', index_col=0)\n",
    "print(f'SMILES lookup: {len(SMILES_DF)} solvents')\n",
    "print(SMILES_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05aaa0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:10:35.044278Z",
     "iopub.status.busy": "2026-01-15T05:10:35.044100Z",
     "iopub.status.idle": "2026-01-15T05:10:36.030888Z",
     "shell.execute_reply": "2026-01-15T05:10:36.030195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChemBERTa model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTa loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa Featurizer\n",
    "class ChemBERTaFeaturizer:\n",
    "    def __init__(self):\n",
    "        print('Loading ChemBERTa model...')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "        self.model = AutoModel.from_pretrained('seyonec/ChemBERTa-zinc-base-v1')\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        print(f'ChemBERTa loaded on {device}')\n",
    "        \n",
    "        # Cache for embeddings\n",
    "        self.cache = {}\n",
    "    \n",
    "    def get_embedding(self, smiles):\n",
    "        \"\"\"Get 768-dim embedding for a SMILES string.\"\"\"\n",
    "        if smiles in self.cache:\n",
    "            return self.cache[smiles]\n",
    "        \n",
    "        # Handle mixture SMILES by averaging components\n",
    "        if '.' in smiles:\n",
    "            components = smiles.split('.')\n",
    "            embeddings = [self._get_single_embedding(s) for s in components]\n",
    "            embedding = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            embedding = self._get_single_embedding(smiles)\n",
    "        \n",
    "        self.cache[smiles] = embedding\n",
    "        return embedding\n",
    "    \n",
    "    def _get_single_embedding(self, smiles):\n",
    "        \"\"\"Get embedding for a single SMILES (no mixtures).\"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(smiles, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = self.model(**inputs)\n",
    "            # Use [CLS] token embedding\n",
    "            embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "        return embedding\n",
    "\n",
    "# Initialize featurizer\n",
    "featurizer = ChemBERTaFeaturizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25815dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:10:36.033090Z",
     "iopub.status.busy": "2026-01-15T05:10:36.032635Z",
     "iopub.status.idle": "2026-01-15T05:10:37.093096Z",
     "shell.execute_reply": "2026-01-15T05:10:37.092504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cyclohexane: embedding shape (768,)\n",
      "Ethyl Acetate: embedding shape (768,)\n",
      "Acetic Acid: embedding shape (768,)\n",
      "2-Methyltetrahydrofuran [2-MeTHF]: embedding shape (768,)\n",
      "1,1,1,3,3,3-Hexafluoropropan-2-ol: embedding shape (768,)\n",
      "IPA [Propan-2-ol]: embedding shape (768,)\n",
      "Ethanol: embedding shape (768,)\n",
      "Methanol: embedding shape (768,)\n",
      "Ethylene Glycol [1,2-Ethanediol]: embedding shape (768,)\n",
      "Acetonitrile: embedding shape (768,)\n",
      "Water: embedding shape (768,)\n",
      "Diethyl Ether [Ether]: embedding shape (768,)\n",
      "MTBE [tert-Butylmethylether]: embedding shape (768,)\n",
      "Dimethyl Carbonate: embedding shape (768,)\n",
      "tert-Butanol [2-Methylpropan-2-ol]: embedding shape (768,)\n",
      "DMA [N,N-Dimethylacetamide]: embedding shape (768,)\n",
      "2,2,2-Trifluoroethanol: embedding shape (768,)\n",
      "Dihydrolevoglucosenone (Cyrene): embedding shape (768,)\n",
      "Decanol: embedding shape (768,)\n",
      "Butanone [MEK]: embedding shape (768,)\n",
      "Ethyl Lactate: embedding shape (768,)\n",
      "Methyl Propionate: embedding shape (768,)\n",
      "THF [Tetrahydrofuran]: embedding shape (768,)\n",
      "Water.Acetonitrile: embedding shape (768,)\n",
      "Acetonitrile.Acetic Acid: embedding shape (768,)\n",
      "Water.2,2,2-Trifluoroethanol: embedding shape (768,)\n",
      "\n",
      "Total embeddings: 26\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute embeddings for all solvents\n",
    "SOLVENT_EMBEDDINGS = {}\n",
    "for solvent_name in SMILES_DF.index:\n",
    "    smiles = SMILES_DF.loc[solvent_name, 'solvent smiles']\n",
    "    try:\n",
    "        embedding = featurizer.get_embedding(smiles)\n",
    "        SOLVENT_EMBEDDINGS[solvent_name] = embedding\n",
    "        print(f\"{solvent_name}: embedding shape {embedding.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {solvent_name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal embeddings: {len(SOLVENT_EMBEDDINGS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d632c190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:11:22.363730Z",
     "iopub.status.busy": "2026-01-15T05:11:22.363441Z",
     "iopub.status.idle": "2026-01-15T05:11:22.369127Z",
     "shell.execute_reply": "2026-01-15T05:11:22.368573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTaMLPModel defined\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa MLP Model\n",
    "class ChemBERTaMLPModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, 3))  # 3 outputs: SM, Product 1, Product 2\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print('ChemBERTaMLPModel defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cb6655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:11:22.371082Z",
     "iopub.status.busy": "2026-01-15T05:11:22.370906Z",
     "iopub.status.idle": "2026-01-15T05:11:22.383631Z",
     "shell.execute_reply": "2026-01-15T05:11:22.383147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChemBERTaWrapper defined\n"
     ]
    }
   ],
   "source": [
    "# ChemBERTa Wrapper for training and prediction\n",
    "class ChemBERTaWrapper:\n",
    "    def __init__(self, data='single', n_models=3):\n",
    "        self.data_type = data\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "        self.scalers = []\n",
    "        self.solvent_embeddings = SOLVENT_EMBEDDINGS\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        \"\"\"Extract features: ChemBERTa embeddings + Arrhenius kinetics.\"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for idx, row in X.iterrows():\n",
    "            # Kinetics features\n",
    "            time_m = row['Residence Time']\n",
    "            temp_c = row['Temperature']\n",
    "            temp_k = temp_c + 273.15\n",
    "            \n",
    "            kinetics = np.array([\n",
    "                time_m,\n",
    "                temp_c,\n",
    "                1.0 / temp_k,  # Arrhenius\n",
    "                np.log(time_m + 1),  # log time\n",
    "                time_m / temp_k  # interaction\n",
    "            ])\n",
    "            \n",
    "            # ChemBERTa embedding\n",
    "            if self.data_type == 'single':\n",
    "                solvent_name = row['SOLVENT NAME']\n",
    "                embedding = self.solvent_embeddings[solvent_name]\n",
    "            else:\n",
    "                # Full solvent (mixture)\n",
    "                solvent_a = row['SOLVENT A NAME']\n",
    "                solvent_b = row['SOLVENT B NAME']\n",
    "                pct_b = row['SolventB%'] / 100.0\n",
    "                \n",
    "                emb_a = self.solvent_embeddings[solvent_a]\n",
    "                emb_b = self.solvent_embeddings[solvent_b]\n",
    "                embedding = (1 - pct_b) * emb_a + pct_b * emb_b\n",
    "            \n",
    "            # Combine\n",
    "            features = np.concatenate([kinetics, embedding])\n",
    "            features_list.append(features)\n",
    "        \n",
    "        return np.array(features_list, dtype=np.float32)\n",
    "    \n",
    "    def train_model(self, X_train, y_train, epochs=200):\n",
    "        \"\"\"Train ensemble of MLP models.\"\"\"\n",
    "        X_feat = self._get_features(X_train)\n",
    "        y_np = y_train.values.astype(np.float32)\n",
    "        \n",
    "        self.models = []\n",
    "        self.scalers = []\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_feat)\n",
    "            self.scalers.append(scaler)\n",
    "            \n",
    "            # Create model\n",
    "            input_dim = X_scaled.shape[1]  # 5 kinetics + 768 ChemBERTa = 773\n",
    "            model = ChemBERTaMLPModel(input_dim).to(device)\n",
    "            \n",
    "            # Training\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "            \n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            y_tensor = torch.tensor(y_np).to(device)\n",
    "            \n",
    "            dataset = TensorDataset(X_tensor, y_tensor)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                for X_batch, y_batch in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(X_batch)\n",
    "                    loss = nn.MSELoss()(pred, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                scheduler.step()\n",
    "            \n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict using ensemble.\"\"\"\n",
    "        X_feat = self._get_features(X_test)\n",
    "        \n",
    "        all_preds = []\n",
    "        for model, scaler in zip(self.models, self.scalers):\n",
    "            X_scaled = scaler.transform(X_feat)\n",
    "            X_tensor = torch.tensor(X_scaled).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred = model(X_tensor).cpu()\n",
    "            all_preds.append(pred)\n",
    "        \n",
    "        # Average predictions\n",
    "        return torch.stack(all_preds).mean(dim=0)\n",
    "\n",
    "print('ChemBERTaWrapper defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a3378e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T05:11:22.385461Z",
     "iopub.status.busy": "2026-01-15T05:11:22.385254Z",
     "iopub.status.idle": "2026-01-15T05:11:27.487545Z",
     "shell.execute_reply": "2026-01-15T05:11:27.486900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test solvent: 1,1,1,3,3,3-Hexafluoropropan-2-ol\n",
      "Training samples: 619, Test samples: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test fold MSE: 0.061135\n",
      "Predictions shape: torch.Size([37, 3])\n",
      "\n",
      "Comparison: exp_035 baseline CV = 0.008194\n",
      "GNN (exp_040) test fold MSE = 0.068767\n"
     ]
    }
   ],
   "source": [
    "# Quick test on single fold\n",
    "X_single, Y_single = load_data(\"single_solvent\")\n",
    "test_solvent = sorted(X_single[\"SOLVENT NAME\"].unique())[0]\n",
    "mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "\n",
    "print(f\"Test solvent: {test_solvent}\")\n",
    "print(f\"Training samples: {mask.sum()}, Test samples: {(~mask).sum()}\")\n",
    "\n",
    "model = ChemBERTaWrapper(data='single', n_models=1)\n",
    "model.train_model(X_single[mask], Y_single[mask], epochs=100)\n",
    "preds = model.predict(X_single[~mask])\n",
    "\n",
    "actuals = Y_single[~mask].values\n",
    "mse = np.mean((actuals - preds.numpy())**2)\n",
    "print(f\"\\nTest fold MSE: {mse:.6f}\")\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"\\nComparison: exp_035 baseline CV = 0.008194\")\n",
    "print(f\"GNN (exp_040) test fold MSE = 0.068767\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df61135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChemBERTa alone is not enough (MSE 0.061135 vs baseline 0.008194)\n",
    "# Let's try combining ChemBERTa with Spange descriptors\n",
    "\n",
    "# Load Spange descriptors\n",
    "spange_df = pd.read_csv(f'{DATA_PATH}/spange_descriptors.csv', index_col=0)\n",
    "print(f\"Spange descriptors: {spange_df.shape}\")\n",
    "print(spange_df.head())\n",
    "\n",
    "# Create combined features: ChemBERTa + Spange + Arrhenius\n",
    "SPANGE_COLS = ['alpha', 'beta', 'pi_star', 'eps', 'cohesive_pressure', 'viscosity', 'surface_tension']\n",
    "SPANGE_DICT = {}\n",
    "for solvent in spange_df.index:\n",
    "    SPANGE_DICT[solvent] = spange_df.loc[solvent, SPANGE_COLS].values.astype(np.float32)\n",
    "print(f\"\\nSpange dict: {len(SPANGE_DICT)} solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461df87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If promising, run full CV\n",
    "print(\"Running full leave-one-solvent-out CV...\")\n",
    "\n",
    "all_solvents = sorted(X_single[\"SOLVENT NAME\"].unique())\n",
    "fold_mses = []\n",
    "\n",
    "for test_solvent in all_solvents:\n",
    "    mask = X_single[\"SOLVENT NAME\"] != test_solvent\n",
    "    \n",
    "    model = ChemBERTaWrapper(data='single', n_models=3)\n",
    "    model.train_model(X_single[mask], Y_single[mask], epochs=150)\n",
    "    preds = model.predict(X_single[~mask])\n",
    "    \n",
    "    actuals = Y_single[~mask].values\n",
    "    mse = np.mean((actuals - preds.numpy())**2)\n",
    "    fold_mses.append(mse)\n",
    "    print(f\"{test_solvent}: MSE = {mse:.6f}\")\n",
    "\n",
    "mean_mse = np.mean(fold_mses)\n",
    "std_mse = np.std(fold_mses)\n",
    "print(f\"\\n=== ChemBERTa CV Results ===\")\n",
    "print(f\"Mean MSE: {mean_mse:.6f} Â± {std_mse:.6f}\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  exp_035 baseline: CV = 0.008194\")\n",
    "print(f\"  GNN (exp_040): test fold MSE = 0.068767\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
