{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd2625d",
   "metadata": {},
   "source": [
    "# MLP with DRFP Features\n",
    "\n",
    "This experiment uses DRFP (Differential Reaction Fingerprints) features instead of Spange descriptors.\n",
    "\n",
    "Key changes:\n",
    "1. DRFP features (2048-dim) instead of Spange (13-dim)\n",
    "2. PCA for dimensionality reduction (try 50, 100, 200 components)\n",
    "3. Combined with Arrhenius kinetics features\n",
    "4. Same MLP architecture as baseline\n",
    "\n",
    "GNN benchmark achieved MSE 0.0039 using DRFP - this is 25x better than current LB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and features\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[[\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load DRFP features\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "print(f'DRFP shape: {DRFP_DF.shape}')\n",
    "print(f'DRFP sparsity: {(DRFP_DF.values == 0).mean():.2%}')\n",
    "print(f'Solvents: {list(DRFP_DF.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurizer with DRFP + Arrhenius kinetics\n",
    "class DRFPFeaturizer:\n",
    "    def __init__(self, mixed=False, n_components=100):\n",
    "        self.mixed = mixed\n",
    "        self.n_components = n_components\n",
    "        self.drfp_df = DRFP_DF\n",
    "        self.pca = None\n",
    "        self.fitted = False\n",
    "        # 2 numeric + 3 kinetic + n_components DRFP\n",
    "        self.feats_dim = 2 + 3 + n_components\n",
    "\n",
    "    def fit_pca(self, solvent_names):\n",
    "        \"\"\"Fit PCA on training solvents only.\"\"\"\n",
    "        # Get unique solvents from training data\n",
    "        if isinstance(solvent_names, pd.Series):\n",
    "            unique_solvents = solvent_names.unique()\n",
    "        else:\n",
    "            unique_solvents = list(set(solvent_names))\n",
    "        \n",
    "        # Get DRFP features for training solvents\n",
    "        train_drfp = self.drfp_df.loc[unique_solvents].values\n",
    "        \n",
    "        # Fit PCA\n",
    "        self.pca = PCA(n_components=min(self.n_components, len(unique_solvents), train_drfp.shape[1]))\n",
    "        self.pca.fit(train_drfp)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[[\"Residence Time\", \"Temperature\"]].values.astype(np.float64)\n",
    "        \n",
    "        # Arrhenius kinetics features\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        # DRFP features\n",
    "        if self.mixed:\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            \n",
    "            if flip:\n",
    "                X_drfp = B_drfp * (1 - (1-pct)) + A_drfp * (1-pct)\n",
    "            else:\n",
    "                X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "        else:\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        # Apply PCA if fitted\n",
    "        if self.fitted and self.pca is not None:\n",
    "            X_drfp_reduced = self.pca.transform(X_drfp)\n",
    "        else:\n",
    "            X_drfp_reduced = X_drfp[:, :self.n_components]\n",
    "        \n",
    "        return torch.tensor(np.hstack([X_kinetic, X_drfp_reduced]))\n",
    "\n",
    "print(f'DRFPFeaturizer defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model with DRFP features\n",
    "class MLPInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], output_dim=3, dropout=0.2):\n",
    "        super(MLPInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        \n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DRFPMLP(nn.Module):\n",
    "    def __init__(self, data='single', n_models=5, n_components=100):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.n_models = n_models\n",
    "        self.n_components = n_components\n",
    "        self.featurizer = DRFPFeaturizer(mixed=(data=='full'), n_components=n_components)\n",
    "        self.models = nn.ModuleList()\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=250, batch_size=32, lr=5e-4):\n",
    "        # Fit PCA on training solvents\n",
    "        if self.data_type == 'full':\n",
    "            all_solvents = list(X_train[\"SOLVENT A NAME\"]) + list(X_train[\"SOLVENT B NAME\"])\n",
    "        else:\n",
    "            all_solvents = list(X_train[\"SOLVENT NAME\"])\n",
    "        self.featurizer.fit_pca(all_solvents)\n",
    "        \n",
    "        # Create features\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            # Set different seed for each model\n",
    "            torch.manual_seed(42 + i)\n",
    "            \n",
    "            model = MLPInternal(input_dim, hidden_dims=[256, 128, 64]).to(device)\n",
    "            model.train()\n",
    "            self.models.append(model)\n",
    "            \n",
    "            dataset = TensorDataset(X_all, y_all)\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=20\n",
    "            )\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for inputs, targets in loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                scheduler.step(epoch_loss / len(dataset))\n",
    "\n",
    "    def predict(self, X):\n",
    "        device = next(self.models[0].parameters()).device\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_std = self.featurizer.featurize(X, flip=False).to(device)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True).to(device)\n",
    "            \n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    p1 = model(X_std)\n",
    "                    p2 = model(X_flip)\n",
    "                    pred_sum += (p1 + p2) * 0.5\n",
    "            \n",
    "            avg_pred = pred_sum / self.n_models\n",
    "        else:\n",
    "            X_std = self.featurizer.featurize(X).to(device)\n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    pred_sum += model(X_std)\n",
    "            avg_pred = pred_sum / self.n_models\n",
    "\n",
    "        return avg_pred.cpu()\n",
    "\n",
    "print('DRFPMLP model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d24a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation for single solvent data\n",
    "print(\"\\n--- TASK 0: Single Solvent (24 folds) ---\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = DRFPMLP(data='single', n_models=5, n_components=100)\n",
    "    model.train_model(train_X, train_Y, epochs=250)\n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0, \"fold\": fold_idx, \"row\": row_idx,\n",
    "            \"target_1\": row[0], \"target_2\": row[1], \"target_3\": row[2]\n",
    "        })\n",
    "    \n",
    "    all_actuals.append(test_Y.values)\n",
    "\n",
    "submission_single = pd.DataFrame(all_predictions)\n",
    "\n",
    "actuals_single = np.vstack(all_actuals)\n",
    "preds_single = submission_single[['target_1', 'target_2', 'target_3']].values\n",
    "mse_single = np.mean((actuals_single - preds_single) ** 2)\n",
    "print(f'\\nSingle Solvent MSE: {mse_single:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation for full data (mixtures)\n",
    "print(\"\\n--- TASK 1: Full Data (13 folds) ---\")\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = DRFPMLP(data='full', n_models=5, n_components=100)\n",
    "    model.train_model(train_X, train_Y, epochs=250)\n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    \n",
    "    for row_idx, row in enumerate(predictions):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1, \"fold\": fold_idx, \"row\": row_idx,\n",
    "            \"target_1\": row[0], \"target_2\": row[1], \"target_3\": row[2]\n",
    "        })\n",
    "    \n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "submission_full = pd.DataFrame(all_predictions_full)\n",
    "\n",
    "actuals_full = np.vstack(all_actuals_full)\n",
    "preds_full = submission_full[['target_1', 'target_2', 'target_3']].values\n",
    "mse_full = np.mean((actuals_full - preds_full) ** 2)\n",
    "print(f'\\nFull Data MSE: {mse_full:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall MSE\n",
    "n_single = len(actuals_single)\n",
    "n_full = len(actuals_full)\n",
    "overall_mse = (mse_single * n_single + mse_full * n_full) / (n_single + n_full)\n",
    "\n",
    "print(f'\\n=== FINAL RESULTS ===')\n",
    "print(f'Single Solvent MSE: {mse_single:.6f} (n={n_single})')\n",
    "print(f'Full Data MSE: {mse_full:.6f} (n={n_full})')\n",
    "print(f'Overall MSE: {overall_mse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9382c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.concat([submission_single, submission_full])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "print(f'Submission saved to /home/submission/submission.csv')\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
