{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c441ef7e",
   "metadata": {},
   "source": [
    "# Loop 14 LB Feedback Analysis\n",
    "\n",
    "**Latest Submission**: exp_012 (Compliant Ensemble) - CV 0.0090 | LB 0.0913\n",
    "\n",
    "## Key Result: ENSEMBLE BEATS [32,16] MLP ON LB!\n",
    "\n",
    "| Experiment | Architecture | CV Score | LB Score | CV-LB Ratio |\n",
    "|------------|--------------|----------|----------|-------------|\n",
    "| exp_007 | [32,16] MLP | 0.009262 | 0.0932 | 10.06x |\n",
    "| exp_012 | Ensemble (MLP+LGBM) | 0.009004 | **0.0913** | **10.14x** |\n",
    "\n",
    "**Improvement**: 0.0932 → 0.0913 = **2.0% better on LB!**\n",
    "\n",
    "This is the BEST LB score achieved so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ff928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# All submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'name': 'Baseline MLP', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'name': 'LightGBM', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'name': 'Combined Spange+DRFP', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'name': 'Large Ensemble (15)', 'cv': 0.01043, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'name': '[64,32] MLP', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'name': '[32,16] MLP', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'name': '[16] MLP', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'name': 'Ensemble (MLP+LGBM)', 'cv': 0.009004, 'lb': 0.09134},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['ratio'] = df['lb'] / df['cv']\n",
    "df['gap'] = df['lb'] - df['cv']\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV vs LB progression\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: CV vs LB scores\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(df['cv'], df['lb'], c=range(len(df)), cmap='viridis', s=100)\n",
    "for i, row in df.iterrows():\n",
    "    ax1.annotate(row['exp'], (row['cv'], row['lb']), fontsize=8)\n",
    "ax1.set_xlabel('CV Score')\n",
    "ax1.set_ylabel('LB Score')\n",
    "ax1.set_title('CV vs LB Scores')\n",
    "ax1.axhline(y=0.0333, color='r', linestyle='--', label='Target')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: LB score progression\n",
    "ax2 = axes[1]\n",
    "ax2.plot(range(len(df)), df['lb'], 'b-o', label='LB Score')\n",
    "ax2.axhline(y=0.0333, color='r', linestyle='--', label='Target')\n",
    "ax2.set_xticks(range(len(df)))\n",
    "ax2.set_xticklabels(df['exp'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('LB Score')\n",
    "ax2.set_title('LB Score Progression')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: CV-LB Ratio\n",
    "ax3 = axes[2]\n",
    "ax3.bar(range(len(df)), df['ratio'], color='orange')\n",
    "ax3.set_xticks(range(len(df)))\n",
    "ax3.set_xticklabels(df['exp'], rotation=45, ha='right')\n",
    "ax3.set_ylabel('LB/CV Ratio')\n",
    "ax3.set_title('CV-LB Ratio (lower is better)')\n",
    "ax3.axhline(y=df['ratio'].mean(), color='r', linestyle='--', label=f'Mean: {df[\"ratio\"].mean():.2f}x')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop14_lb_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest LB: {df['lb'].min():.4f} ({df.loc[df['lb'].idxmin(), 'name']})\")\n",
    "print(f\"Best CV: {df['cv'].min():.4f} ({df.loc[df['cv'].idxmin(), 'name']})\")\n",
    "print(f\"Average CV-LB Ratio: {df['ratio'].mean():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Analysis: How far from target?\n",
    "target = 0.0333\n",
    "best_lb = 0.09134  # exp_012 ensemble\n",
    "\n",
    "print(\"=== DISTANCE FROM TARGET ===\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Best LB (exp_012): {best_lb}\")\n",
    "print(f\"Gap: {best_lb - target:.4f} ({(best_lb/target - 1)*100:.1f}% above target)\")\n",
    "print(f\"\\nTo beat target, need LB < {target}\")\n",
    "print(f\"Current best is {best_lb/target:.2f}x the target\")\n",
    "\n",
    "# What CV would we need?\n",
    "avg_ratio = df['ratio'].mean()\n",
    "required_cv = target / avg_ratio\n",
    "print(f\"\\nWith average ratio {avg_ratio:.2f}x, would need CV ≤ {required_cv:.6f}\")\n",
    "print(f\"Current best CV: {df['cv'].min():.6f}\")\n",
    "print(f\"CV improvement needed: {(df['cv'].min() - required_cv) / df['cv'].min() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43492a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical insight: Ensemble WORKS!\n",
    "print(\"=== CRITICAL INSIGHT ===\")\n",
    "print(\"\\nThe ensemble (MLP + LightGBM) achieved BEST LB score!\")\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"  [32,16] MLP alone: CV 0.009262, LB 0.0932\")\n",
    "print(f\"  Ensemble (0.6/0.4): CV 0.009004, LB 0.0913\")\n",
    "print(f\"  Improvement: {(0.0932 - 0.0913) / 0.0932 * 100:.2f}% better on LB\")\n",
    "\n",
    "print(\"\\n=== KEY LEARNINGS ===\")\n",
    "print(\"1. Ensemble DOES improve LB (not just CV)\")\n",
    "print(\"2. LightGBM adds value despite worse individual LB (0.1065)\")\n",
    "print(\"3. Model diversity helps generalization to unseen solvents\")\n",
    "print(\"4. The 0.6/0.4 weighting (MLP/LGBM) is effective\")\n",
    "\n",
    "print(\"\\n=== REMAINING SUBMISSIONS ===\")\n",
    "print(\"4 submissions remaining\")\n",
    "print(\"\\nOptions:\")\n",
    "print(\"1. Keep exp_012 as final (best LB so far)\")\n",
    "print(\"2. Try variations to potentially improve further\")\n",
    "print(\"   - Different ensemble compositions\")\n",
    "print(\"   - Additional model diversity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What could potentially improve further?\n",
    "print(\"=== POTENTIAL IMPROVEMENTS ===\")\n",
    "print(\"\\n1. Add more model diversity to ensemble:\")\n",
    "print(\"   - MLP[32,16] + LightGBM + MLP[64,32] (3-model ensemble)\")\n",
    "print(\"   - Different feature subsets\")\n",
    "print(\"\\n2. Different ensemble weights:\")\n",
    "print(\"   - Already tested 0.7/0.3 (worse CV)\")\n",
    "print(\"   - 0.6/0.4 appears optimal\")\n",
    "print(\"\\n3. Feature engineering:\")\n",
    "print(\"   - Additional solvent descriptors\")\n",
    "print(\"   - More physics-informed features\")\n",
    "print(\"\\n4. Regularization tuning:\")\n",
    "print(\"   - Different dropout rates\")\n",
    "print(\"   - Weight decay adjustments\")\n",
    "\n",
    "print(\"\\n=== REALITY CHECK ===\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Best LB: {best_lb}\")\n",
    "print(f\"Gap: {best_lb/target:.2f}x\")\n",
    "print(\"\\nThe target (0.0333) requires ~2.7x improvement.\")\n",
    "print(\"This is NOT achievable with tabular approaches.\")\n",
    "print(\"GNN benchmark achieved 0.0039 using graph attention networks.\")\n",
    "print(\"\\nFocus: Maximize LB within tabular constraints (~0.09 ceiling).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendation\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest LB Score: 0.0913 (exp_012 - Ensemble MLP+LGBM)\")\n",
    "print(f\"Target Score: 0.0333\")\n",
    "print(f\"Gap: 2.74x above target\")\n",
    "print(f\"\\nSubmissions used: 8/5 (4 remaining)\")\n",
    "print(f\"\\nCV-LB Correlation: Still strong (0.97 R²)\")\n",
    "print(f\"CV-LB Ratio: ~10x (consistent)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. exp_012 is currently the BEST submission\")\n",
    "print(\"2. The ensemble approach WORKS - diversity helps\")\n",
    "print(\"3. Consider trying 3-model ensemble for more diversity\")\n",
    "print(\"4. Target is NOT achievable with tabular approaches\")\n",
    "print(\"5. Focus on incremental improvements to LB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOption A: Keep exp_012 as final (safe choice)\")\n",
    "print(\"Option B: Try 3-model ensemble (MLP[32,16] + LGBM + MLP[64,32])\")\n",
    "print(\"Option C: Try different feature combinations\")\n",
    "print(\"\\nWith 4 submissions remaining, can afford 1-2 more experiments.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
