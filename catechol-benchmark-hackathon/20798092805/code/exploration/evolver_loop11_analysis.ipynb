{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba6b638",
   "metadata": {},
   "source": [
    "# Loop 11 Analysis: Diverse Ensemble Results & Strategy Assessment\n",
    "\n",
    "## Current Situation\n",
    "- **Best CV**: exp_010 (Diverse Ensemble) = 0.008829 (NEW BEST!)\n",
    "- **Best LB**: exp_007 ([32,16]) = 0.0932\n",
    "- **Target**: 0.0333 (2.8x gap from best LB)\n",
    "- **Submissions**: 0 remaining today\n",
    "\n",
    "## Key Questions\n",
    "1. Does the ensemble's CV improvement (4.7%) predict LB improvement?\n",
    "2. What is the CV-LB correlation trend?\n",
    "3. Is the notebook structure compliant with competition requirements?\n",
    "4. What should be the next experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5be0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Complete submission history\n",
    "submissions = pd.DataFrame({\n",
    "    'experiment': ['exp_000', 'exp_001', 'exp_003', 'exp_005', 'exp_006', 'exp_007', 'exp_009'],\n",
    "    'architecture': ['[128,128,64]', 'LightGBM', '[256,128,64]', '[256,128,64] 15-bag', '[64,32]', '[32,16]', '[16]'],\n",
    "    'cv_score': [0.0111, 0.0123, 0.0105, 0.0104, 0.0097, 0.0093, 0.0092],\n",
    "    'lb_score': [0.0982, 0.1065, 0.0972, 0.0969, 0.0946, 0.0932, 0.0936]\n",
    "})\n",
    "\n",
    "submissions['lb_cv_ratio'] = submissions['lb_score'] / submissions['cv_score']\n",
    "submissions['cv_improvement'] = (submissions['cv_score'].iloc[0] - submissions['cv_score']) / submissions['cv_score'].iloc[0] * 100\n",
    "submissions['lb_improvement'] = (submissions['lb_score'].iloc[0] - submissions['lb_score']) / submissions['lb_score'].iloc[0] * 100\n",
    "\n",
    "print(\"=== COMPLETE SUBMISSION HISTORY ===\")\n",
    "print(submissions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd20f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze CV-LB correlation\n",
    "from scipy import stats\n",
    "\n",
    "corr, p_value = stats.pearsonr(submissions['cv_score'], submissions['lb_score'])\n",
    "print(f\"\\n=== CV-LB CORRELATION ===\")\n",
    "print(f\"Pearson correlation: {corr:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "# Linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(submissions['cv_score'], submissions['lb_score'])\n",
    "print(f\"\\nLinear fit: LB = {slope:.2f} * CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "\n",
    "# Predict LB for ensemble\n",
    "ensemble_cv = 0.008829\n",
    "predicted_lb = slope * ensemble_cv + intercept\n",
    "print(f\"\\n=== ENSEMBLE PREDICTION ===\")\n",
    "print(f\"Ensemble CV: {ensemble_cv:.6f}\")\n",
    "print(f\"Predicted LB (linear fit): {predicted_lb:.4f}\")\n",
    "print(f\"Predicted LB (10x ratio): {ensemble_cv * 10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the CV-LB relationship\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: CV vs LB scatter\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(submissions['cv_score'], submissions['lb_score'], s=100, c='blue', alpha=0.7)\n",
    "for i, row in submissions.iterrows():\n",
    "    ax1.annotate(row['experiment'], (row['cv_score'], row['lb_score']), \n",
    "                 textcoords=\"offset points\", xytext=(5,5), fontsize=8)\n",
    "\n",
    "# Add linear fit line\n",
    "cv_range = np.linspace(0.008, 0.013, 100)\n",
    "lb_fit = slope * cv_range + intercept\n",
    "ax1.plot(cv_range, lb_fit, 'r--', label=f'Linear fit (R²={r_value**2:.3f})')\n",
    "\n",
    "# Add ensemble prediction\n",
    "ax1.scatter([ensemble_cv], [predicted_lb], s=150, c='green', marker='*', label=f'Ensemble (predicted)')\n",
    "ax1.axhline(y=0.0333, color='orange', linestyle=':', label='Target (0.0333)')\n",
    "\n",
    "ax1.set_xlabel('CV Score')\n",
    "ax1.set_ylabel('LB Score')\n",
    "ax1.set_title('CV vs LB Score Relationship')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: LB/CV ratio trend\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(len(submissions)), submissions['lb_cv_ratio'], color='steelblue', alpha=0.7)\n",
    "ax2.set_xticks(range(len(submissions)))\n",
    "ax2.set_xticklabels(submissions['experiment'], rotation=45)\n",
    "ax2.set_ylabel('LB/CV Ratio')\n",
    "ax2.set_title('LB/CV Ratio Trend (Increasing = Diminishing Returns)')\n",
    "ax2.axhline(y=submissions['lb_cv_ratio'].mean(), color='red', linestyle='--', label=f'Mean: {submissions[\"lb_cv_ratio\"].mean():.2f}x')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop11_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"\\nPlot saved to /home/code/exploration/loop11_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical insight: The [16] model broke the CV-LB correlation\n",
    "print(\"=== CRITICAL INSIGHT: CV-LB CORRELATION BREAKDOWN ===\")\n",
    "print(\"\\nexp_007 ([32,16]): CV 0.0093, LB 0.0932 (BEST LB)\")\n",
    "print(\"exp_009 ([16]):    CV 0.0092, LB 0.0936 (WORSE LB despite better CV!)\")\n",
    "print(\"\\nThis proves that CV improvements no longer predict LB improvements.\")\n",
    "print(\"\\nThe ensemble (CV 0.008829) may NOT improve LB despite 4.7% better CV.\")\n",
    "\n",
    "# Calculate what would happen if the trend continues\n",
    "print(\"\\n=== SCENARIO ANALYSIS ===\")\n",
    "print(f\"If LB/CV ratio stays at 10x: Ensemble LB = {ensemble_cv * 10:.4f}\")\n",
    "print(f\"If LB/CV ratio increases to 10.5x: Ensemble LB = {ensemble_cv * 10.5:.4f}\")\n",
    "print(f\"If LB/CV ratio increases to 11x: Ensemble LB = {ensemble_cv * 11:.4f}\")\n",
    "print(f\"\\nBest LB so far: 0.0932 (exp_007 [32,16])\")\n",
    "print(f\"\\nConclusion: Ensemble may achieve LB ~0.088-0.097, likely similar to [32,16]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook compliance check\n",
    "print(\"=== NOTEBOOK COMPLIANCE CHECK ===\")\n",
    "print(\"\\nCompetition requires:\")\n",
    "print(\"1. Last 3 cells must follow the template exactly\")\n",
    "print(\"2. Only the model definition line can be changed\")\n",
    "print(\"3. Model must have train_model(X_train, y_train) and predict(X) methods\")\n",
    "print(\"\\nCurrent exp_010 notebook structure:\")\n",
    "print(\"- Custom DiverseEnsemble class with train_model() and predict() methods ✓\")\n",
    "print(\"- BUT: The last 3 cells are NOT the template cells ✗\")\n",
    "print(\"- The notebook uses custom CV loops instead of template CV loops ✗\")\n",
    "print(\"\\n⚠️ CRITICAL: The current notebook may NOT be compliant!\")\n",
    "print(\"\\nTo make it compliant:\")\n",
    "print(\"1. Move all class definitions to earlier cells\")\n",
    "print(\"2. Use the EXACT last 3 cells from the template\")\n",
    "print(\"3. Only change: model = DiverseEnsemble(data='single') and model = DiverseEnsemble(data='full')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategic assessment\n",
    "print(\"=== STRATEGIC ASSESSMENT ===\")\n",
    "print(\"\\n1. WHAT'S WORKING:\")\n",
    "print(\"   - Diverse ensemble achieved best CV (0.008829)\")\n",
    "print(\"   - Ensemble helps more on mixture data (0.008487) than single solvent (0.009469)\")\n",
    "print(\"   - The [32,16] MLP remains the best LB model (0.0932)\")\n",
    "print(\"\\n2. WHAT'S NOT WORKING:\")\n",
    "print(\"   - CV-LB correlation has broken down\")\n",
    "print(\"   - Better CV no longer predicts better LB\")\n",
    "print(\"   - Target (0.0333) is unreachable with current approach\")\n",
    "print(\"\\n3. NEXT STEPS (when submissions reset):\")\n",
    "print(\"   Priority 1: Ensure notebook compliance before any submission\")\n",
    "print(\"   Priority 2: Test ensemble on LB to verify CV-LB relationship\")\n",
    "print(\"   Priority 3: If ensemble doesn't improve LB, try different ensemble weights\")\n",
    "print(\"   Priority 4: Consider simpler ensemble ([32,16] + LightGBM only)\")\n",
    "print(\"\\n4. EXPERIMENTS TO RUN NOW (no submissions needed):\")\n",
    "print(\"   - Test different ensemble weights\")\n",
    "print(\"   - Try [32,16] + LightGBM only (simpler ensemble)\")\n",
    "print(\"   - Try stronger regularization on [32,16]\")\n",
    "print(\"   - Prepare compliant notebook for submission\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
