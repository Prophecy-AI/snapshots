{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3e3b8e",
   "metadata": {},
   "source": [
    "# Loop 6 Analysis: CV-LB Gap and Strategy Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. Why is the CV-LB gap ~9x consistently?\n",
    "2. What approaches might reduce this gap?\n",
    "3. Is the target (0.023) achievable with MLP-based approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93742b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state to analyze experiments\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze submissions\n",
    "print('=== SUBMISSION ANALYSIS ===')\n",
    "submissions = state.get('submissions', [])\n",
    "for sub in submissions:\n",
    "    cv = sub.get('cv_score', 'N/A')\n",
    "    lb = sub.get('lb_score', 'N/A')\n",
    "    exp_id = sub.get('experiment_id', 'N/A')\n",
    "    if cv != 'N/A' and lb != 'N/A':\n",
    "        ratio = lb / cv\n",
    "        print(f'{exp_id}: CV={cv:.4f}, LB={lb:.4f}, Ratio={ratio:.1f}x')\n",
    "    else:\n",
    "        print(f'{exp_id}: CV={cv}, LB={lb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all experiments\n",
    "print('\\n=== EXPERIMENT SCORES ===')\n",
    "experiments = state.get('experiments', [])\n",
    "for exp in experiments:\n",
    "    print(f\"{exp['id']}: {exp['name'][:50]:50s} CV={exp['score']:.6f}\")\n",
    "\n",
    "# Best CV\n",
    "best_cv = min(exp['score'] for exp in experiments)\n",
    "print(f'\\nBest CV: {best_cv:.6f}')\n",
    "\n",
    "# With 9x ratio, predicted LB\n",
    "predicted_lb = best_cv * 9\n",
    "print(f'Predicted LB (9x ratio): {predicted_lb:.4f}')\n",
    "print(f'Target: 0.023')\n",
    "print(f'Gap to target: {(predicted_lb - 0.023) / 0.023 * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce821ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the CV-LB gap more carefully\n",
    "print('\\n=== CV-LB GAP ANALYSIS ===')\n",
    "\n",
    "# Known submissions\n",
    "submission_data = [\n",
    "    ('exp_000', 0.0111, 0.0982),\n",
    "    ('exp_001', 0.0123, 0.1065),\n",
    "    ('exp_003', 0.0105, 0.0972),\n",
    "]\n",
    "\n",
    "for exp_id, cv, lb in submission_data:\n",
    "    ratio = lb / cv\n",
    "    print(f'{exp_id}: CV={cv:.4f}, LB={lb:.4f}, Ratio={ratio:.2f}x')\n",
    "\n",
    "avg_ratio = np.mean([lb/cv for _, cv, lb in submission_data])\n",
    "print(f'\\nAverage CV-LB ratio: {avg_ratio:.2f}x')\n",
    "\n",
    "# To beat target 0.023\n",
    "target = 0.023\n",
    "required_cv = target / avg_ratio\n",
    "print(f'\\nTo beat target {target}:')\n",
    "print(f'  Required CV: {required_cv:.6f}')\n",
    "print(f'  Current best CV: {best_cv:.6f}')\n",
    "print(f'  Improvement needed: {(best_cv - required_cv) / best_cv * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6961662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's causing the CV-LB gap\n",
    "print('\\n=== POTENTIAL CAUSES OF CV-LB GAP ===')\n",
    "print('''\n",
    "1. LEAVE-ONE-SOLVENT-OUT GENERALIZATION:\n",
    "   - CV tests on solvents seen during training (other folds)\n",
    "   - LB tests on completely unseen solvents\n",
    "   - This is fundamentally harder than interpolation\n",
    "\n",
    "2. DISTRIBUTION SHIFT:\n",
    "   - Training solvents may have different properties than test solvents\n",
    "   - Model may be overfitting to training solvent characteristics\n",
    "\n",
    "3. MODEL VARIANCE:\n",
    "   - Neural networks have high variance between runs\n",
    "   - Different random seeds give different predictions\n",
    "   - Larger ensembles reduce this but don't eliminate it\n",
    "\n",
    "4. FEATURE REPRESENTATION:\n",
    "   - Spange descriptors may not capture all relevant solvent properties\n",
    "   - DRFP may not generalize well to unseen solvents\n",
    "   - Linear mixing for mixtures may be too simplistic\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the data to understand the problem better\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('=== DATA OVERVIEW ===')\n",
    "print(f'Single solvent samples: {len(df_single)}')\n",
    "print(f'Full data samples: {len(df_full)}')\n",
    "print(f'Total samples: {len(df_single) + len(df_full)}')\n",
    "\n",
    "print(f'\\nUnique solvents (single): {df_single[\"SOLVENT NAME\"].nunique()}')\n",
    "print(f'Unique solvent pairs (full): {len(df_full[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f636ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target distributions\n",
    "print('\\n=== TARGET DISTRIBUTIONS ===')\n",
    "for col in ['Product 2', 'Product 3', 'SM']:\n",
    "    print(f'\\n{col}:')\n",
    "    print(f'  Single - Mean: {df_single[col].mean():.4f}, Std: {df_single[col].std():.4f}')\n",
    "    print(f'  Full   - Mean: {df_full[col].mean():.4f}, Std: {df_full[col].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42710323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-solvent variance in single solvent data\n",
    "print('\\n=== PER-SOLVENT VARIANCE (Single Solvent) ===')\n",
    "solvent_stats = df_single.groupby('SOLVENT NAME')[['Product 2', 'Product 3', 'SM']].agg(['mean', 'std'])\n",
    "print(solvent_stats.head(10))\n",
    "\n",
    "# Which solvents have highest variance?\n",
    "print('\\n=== SOLVENTS WITH HIGHEST SM VARIANCE ===')\n",
    "sm_std = df_single.groupby('SOLVENT NAME')['SM'].std().sort_values(ascending=False)\n",
    "print(sm_std.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e19532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The problem is fundamentally about generalizing to unseen solvents\n",
    "print('\\n=== KEY INSIGHTS ===')\n",
    "print('''\n",
    "1. The CV-LB gap (~9x) is consistent across all experiments\n",
    "   - This suggests the gap is inherent to the problem, not the model\n",
    "   - Leave-one-solvent-out CV is fundamentally different from LB evaluation\n",
    "\n",
    "2. Larger ensembles (15 vs 5 models) only improved CV by 0.7%\n",
    "   - Variance reduction has diminishing returns\n",
    "   - The gap is NOT primarily due to model variance\n",
    "\n",
    "3. The target (0.023) may be unrealistic for MLP approaches\n",
    "   - GNN benchmark achieved 0.0039 using graph neural networks\n",
    "   - Our best LB (0.0972) is competitive for MLP approaches\n",
    "   - To beat 0.023 with 9x ratio, need CV ~0.0026 (75% improvement)\n",
    "\n",
    "4. Potential strategies to reduce CV-LB gap:\n",
    "   a. Simpler models (less overfitting to training solvents)\n",
    "   b. Better regularization (L1/L2, dropout)\n",
    "   c. Feature engineering (more generalizable features)\n",
    "   d. Per-target models (different patterns for different targets)\n",
    "   e. Gaussian Processes (better uncertainty quantification)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc666dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the latest experiment (exp_005) results\n",
    "print('\\n=== LATEST EXPERIMENT ANALYSIS (exp_005) ===')\n",
    "print('''\n",
    "exp_005: Large Ensemble (15 models) with Same Architecture\n",
    "- Single Solvent MSE: 0.011533 (slightly worse than exp_003)\n",
    "- Full Data MSE: 0.009841 (slightly better than exp_003)\n",
    "- Overall MSE: 0.010430 (0.7% better than exp_003)\n",
    "\n",
    "Key observations:\n",
    "1. Larger ensemble helped more for mixtures than single solvents\n",
    "2. Marginal improvement suggests we're near the ceiling\n",
    "3. Training time increased 3x (6.5h vs 2h) for 0.7% improvement\n",
    "\n",
    "This experiment has NOT been submitted to LB yet.\n",
    "With 2 submissions remaining, we should:\n",
    "1. Submit exp_005 to validate if variance reduction helps on LB\n",
    "2. If LB doesn't improve, pivot to fundamentally different approaches\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('\\n=== STRATEGIC RECOMMENDATION ===')\n",
    "print('''\n",
    "Given the analysis:\n",
    "\n",
    "1. SUBMIT exp_005 to LB (Priority 1)\n",
    "   - Validate if larger ensemble reduces CV-LB gap\n",
    "   - If LB improves proportionally to CV, continue this direction\n",
    "   - If not, the gap is NOT due to model variance\n",
    "\n",
    "2. If LB doesn't improve, try SIMPLER models (Priority 2)\n",
    "   - Reduce model complexity to prevent overfitting\n",
    "   - Try MLP [64, 32] or even linear models\n",
    "   - May generalize better to unseen solvents\n",
    "\n",
    "3. Try per-target models (Priority 3)\n",
    "   - SM, Product 2, Product 3 may have different optimal patterns\n",
    "   - Competition allows different hyperparameters for different objectives\n",
    "\n",
    "4. Consider Gaussian Processes (Priority 4)\n",
    "   - Better uncertainty quantification\n",
    "   - May handle small data better\n",
    "   - Tanimoto kernel for molecular similarity\n",
    "\n",
    "REALITY CHECK:\n",
    "- Target (0.023) is 4x better than our best LB (0.0972)\n",
    "- With 9x CV-LB ratio, would need CV ~0.0026\n",
    "- This is 75% improvement from current best CV (0.0104)\n",
    "- May be unrealistic for MLP approaches\n",
    "- Focus on closing the CV-LB gap rather than improving CV\n",
    "''')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
