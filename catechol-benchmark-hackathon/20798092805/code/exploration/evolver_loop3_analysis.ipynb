{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b45e9c",
   "metadata": {},
   "source": [
    "# Loop 3 Analysis: DRFP Failure and Next Steps\n",
    "\n",
    "## Key Findings from Evaluator\n",
    "1. **PCA is wrong for sparse fingerprints** - DRFP is 97.4% sparse, PCA treats zeros as informative\n",
    "2. **DRFP CV 0.017 vs Spange CV 0.011** - DRFP performed WORSE\n",
    "3. **GNN benchmark used graph architecture, not just DRFP features**\n",
    "\n",
    "## Research Insights\n",
    "- Use Truncated SVD instead of PCA for sparse data\n",
    "- Or use raw DRFP with strong regularization\n",
    "- Or combine DRFP + Spange features\n",
    "- Consider feature selection based on variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "# Load all feature sets\n",
    "spange = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "drfp = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "acs_pca = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "print('Feature dimensions:')\n",
    "print(f'  Spange: {spange.shape}')\n",
    "print(f'  DRFP: {drfp.shape}')\n",
    "print(f'  ACS PCA: {acs_pca.shape}')\n",
    "print(f'\\nDRFP sparsity: {(drfp.values == 0).mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze DRFP feature variance\n",
    "drfp_var = drfp.var(axis=0)\n",
    "print(f'DRFP feature variance statistics:')\n",
    "print(f'  Min: {drfp_var.min():.6f}')\n",
    "print(f'  Max: {drfp_var.max():.6f}')\n",
    "print(f'  Mean: {drfp_var.mean():.6f}')\n",
    "print(f'  Median: {drfp_var.median():.6f}')\n",
    "\n",
    "# How many features have non-zero variance?\n",
    "nonzero_var = (drfp_var > 0).sum()\n",
    "print(f'\\nFeatures with non-zero variance: {nonzero_var} / {len(drfp_var)}')\n",
    "\n",
    "# How many features have variance > 0.01?\n",
    "high_var = (drfp_var > 0.01).sum()\n",
    "print(f'Features with variance > 0.01: {high_var}')\n",
    "\n",
    "# How many features have variance > 0.05?\n",
    "very_high_var = (drfp_var > 0.05).sum()\n",
    "print(f'Features with variance > 0.05: {very_high_var}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PCA vs Truncated SVD on DRFP\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "# PCA (what we used - problematic for sparse data)\n",
    "pca = PCA(n_components=min(50, drfp.shape[0]-1))\n",
    "drfp_pca = pca.fit_transform(drfp.values)\n",
    "print(f'PCA explained variance ratio (first 10): {pca.explained_variance_ratio_[:10].round(3)}')\n",
    "print(f'PCA total explained variance: {pca.explained_variance_ratio_.sum():.3f}')\n",
    "\n",
    "# Truncated SVD (better for sparse data)\n",
    "svd = TruncatedSVD(n_components=min(50, drfp.shape[0]-1))\n",
    "drfp_svd = svd.fit_transform(drfp.values)\n",
    "print(f'\\nTruncated SVD explained variance ratio (first 10): {svd.explained_variance_ratio_[:10].round(3)}')\n",
    "print(f'Truncated SVD total explained variance: {svd.explained_variance_ratio_.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10be807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection: keep only non-zero variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove zero-variance features\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "drfp_selected = selector.fit_transform(drfp.values)\n",
    "print(f'DRFP after removing zero-variance features: {drfp_selected.shape}')\n",
    "\n",
    "# More aggressive: remove low-variance features\n",
    "selector_high = VarianceThreshold(threshold=0.01)\n",
    "drfp_high_var = selector_high.fit_transform(drfp.values)\n",
    "print(f'DRFP after removing low-variance features (threshold=0.01): {drfp_high_var.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Spange descriptors - these are working well\n",
    "print('Spange descriptor statistics:')\n",
    "print(spange.describe().T[['mean', 'std', 'min', 'max']])\n",
    "\n",
    "# Check correlation between Spange features\n",
    "spange_corr = spange.corr()\n",
    "print(f'\\nSpange feature correlations (high correlations > 0.8):')\n",
    "high_corr = []\n",
    "for i in range(len(spange_corr.columns)):\n",
    "    for j in range(i+1, len(spange_corr.columns)):\n",
    "        if abs(spange_corr.iloc[i, j]) > 0.8:\n",
    "            high_corr.append((spange_corr.columns[i], spange_corr.columns[j], spange_corr.iloc[i, j]))\n",
    "for c1, c2, corr in high_corr:\n",
    "    print(f'  {c1} - {c2}: {corr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What if we combine Spange + selected DRFP features?\n",
    "# This could give us the best of both worlds\n",
    "\n",
    "# Get the indices of high-variance DRFP features\n",
    "high_var_mask = drfp_var > 0.01\n",
    "high_var_indices = drfp_var[high_var_mask].index.tolist()\n",
    "print(f'Number of high-variance DRFP features: {len(high_var_indices)}')\n",
    "\n",
    "# Create combined feature set\n",
    "drfp_subset = drfp[high_var_indices]\n",
    "print(f'\\nCombined feature dimensions:')\n",
    "print(f'  Spange: {spange.shape[1]}')\n",
    "print(f'  DRFP (high-var): {drfp_subset.shape[1]}')\n",
    "print(f'  Total: {spange.shape[1] + drfp_subset.shape[1]}')\n",
    "\n",
    "# Check if solvents match\n",
    "print(f'\\nSolvents in Spange: {len(spange.index)}')\n",
    "print(f'Solvents in DRFP: {len(drfp.index)}')\n",
    "print(f'Common solvents: {len(set(spange.index) & set(drfp.index))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the CV-LB gap\n",
    "print('CV-LB Gap Analysis:')\n",
    "print('='*50)\n",
    "print('Submission 1 (MLP): CV 0.0111 -> LB 0.0982 (gap: 0.0871)')\n",
    "print('Submission 2 (LightGBM): CV 0.0123 -> LB 0.1065 (gap: 0.0942)')\n",
    "print('\\nThe gap is MASSIVE - 8-9x difference!')\n",
    "print('\\nPossible explanations:')\n",
    "print('1. Our local CV calculation differs from competition')\n",
    "print('2. The competition uses different random seeds')\n",
    "print('3. Model variance between runs')\n",
    "print('4. Different library versions on Kaggle')\n",
    "print('\\nKey insight: Both MLP and LightGBM show similar gaps.')\n",
    "print('This suggests the gap is NOT due to model variance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy analysis: What should we try next?\n",
    "print('STRATEGY ANALYSIS')\n",
    "print('='*50)\n",
    "print('\\nWhat has worked:')\n",
    "print('  - MLP with Spange + Arrhenius: LB 0.0982 (best)')\n",
    "print('  - Chemical symmetry handling (TTA)')\n",
    "print('\\nWhat has NOT worked:')\n",
    "print('  - LightGBM: LB 0.1065 (worse than MLP)')\n",
    "print('  - DRFP with PCA: CV 0.017 (worse than Spange CV 0.011)')\n",
    "print('\\nWhat to try next:')\n",
    "print('  1. DRFP without PCA - use raw features with regularization')\n",
    "print('  2. DRFP with Truncated SVD instead of PCA')\n",
    "print('  3. Combine Spange + DRFP (high-variance features only)')\n",
    "print('  4. Hyperparameter tuning on MLP')\n",
    "print('  5. Ensemble: average MLP predictions from different seeds')\n",
    "print('\\nTarget: 0.0333 (need 3x improvement from 0.0982)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d51823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print('RECOMMENDED NEXT EXPERIMENTS')\n",
    "print('='*50)\n",
    "print('\\nPriority 1: Combine Spange + DRFP (high-variance)')\n",
    "print('  - Spange (13 features) + DRFP high-var (~50-100 features)')\n",
    "print('  - Use Truncated SVD on DRFP, not PCA')\n",
    "print('  - Keep Arrhenius kinetics features')\n",
    "print('  - Same MLP architecture')\n",
    "print('\\nPriority 2: Hyperparameter tuning on baseline MLP')\n",
    "print('  - Try different hidden layer sizes')\n",
    "print('  - Try different dropout rates')\n",
    "print('  - Try more epochs')\n",
    "print('  - Try different learning rates')\n",
    "print('\\nPriority 3: Ensemble multiple MLP models')\n",
    "print('  - Train 10+ models with different seeds')\n",
    "print('  - Average predictions')\n",
    "print('  - This should reduce variance and improve LB')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
