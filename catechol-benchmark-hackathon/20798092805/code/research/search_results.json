{
  "query": "What neural network architectures work best for predicting chemical reaction yields when you need to generalize to completely unseen solvents?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields while the solvent is completely novel to the model is a classic out\u2011of\u2011distribution problem.  It requires an architecture that can learn a chemically meaningful representation of every reaction component (reactants, catalysts, solvents, etc.) and then extrapolate that knowledge to unseen solvent environments.  Recent work shows that graph\u2011based neural networks, which treat molecules as graphs of atoms and bonds, are especially suited to this task because they can encode subtle electronic and steric effects of solvents alongside the rest of the reaction\u202f([pubs.rsc.org](https://pubs.rsc.org/en/content/articlelanding/2025/cp/d5cp01072a)).  \n\nAmong the graph\u2011neural\u2011network (GNN) families evaluated on large cross\u2011coupling datasets, **message\u2011passing neural networks (MPNNs)** consistently achieved the highest predictive power (R\u00b2\u202f\u2248\u202f0.75) and were more robust to solvent variation than residual GCNs, GraphSAGE, GAT/GATv2, or GIN models\u202f([pubs.rsc.org](https://pubs.rsc.org/en/content/articlelanding/2025/cp/d5cp01072a)).  A specialized variant, the **reaction\u2011difference MPNN (RD\u2011MPNN)**, further improves performance by explicitly modelling the change from reactants to products and integrating molecular\u2011 and reaction\u2011level descriptors, reaching R\u00b2\u202f=\u202f0.86\u20130.93 on public Suzuki\u2011Miyaura and Buchwald\u2011Hartwig datasets\u202f([blackthorn.ai](https://blackthorn.ai/projects/chemical-reaction-yield-prediction)).  Transformer\u2011style architectures that operate on text\u2011based SMILES strings also show strong results; an encoder\u2011transformer with a regression head achieved \u201coutstanding\u201d yield predictions on high\u2011throughput data\u202f([rxn4chemistry.github.io](https://rxn4chemistry.github.io/rxn_yields)).  More recently, **graph\u2011based Transformers** that combine the relational power of GNNs with self\u2011attention have been proposed for high\u2011throughput cross\u2011coupling yields, further narrowing the gap between GNNs and pure language models\u202f([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720)).  \n\nTo generalize to **completely unseen solvents**, the most effective strategy is to pair a high\u2011capacity GNN (MPNN or RD\u2011MPNN) with **explicit solvent descriptors** (e.g., polarity, donor/acceptor numbers) and to employ **transfer\u2011learning or few\u2011shot fine\u2011tuning** on a small set of reactions in the new solvent.  A benchmark study on continuous solvent effects demonstrated that GNNs can learn solvent\u2011dependent reaction landscapes when trained on transient flow data, and that transfer\u2011learning markedly improves out\u2011of\u2011sample solvent predictions\u202f([arxiv.org](https://arxiv.org/html/2512.19530)).  Complementary work on the Catechol benchmark highlighted the value of active learning and feature engineering for solvent selection tasks, confirming that models which incorporate solvent\u2011specific features and are pre\u2011trained on diverse reaction families achieve the best extrapolation to novel solvents\u202f([openreview.net](https://openreview.net/pdf?id=6l8q74TabE)).  \n\nIn practice, a **message\u2011passing graph neural network (or its RD\u2011MPNN variant) augmented with solvent physicochemical features and fine\u2011tuned via transfer learning** offers the most reliable performance when predicting yields for reactions in completely new solvents.",
      "url": ""
    },
    {
      "title": "Performance assessment of various graph neural network ...",
      "text": "<div><div>\n<section>\n<article>\n<div>\n<p><a href=\"#\">\n<span></span> Author affiliations\n</a></p><div>\n<p>\n<span>\n* </span>\n<span>\nCorresponding authors\n</span>\n</p>\n<p>\n<span>\n<sup>a</sup>\n</span>\n<span>\nDepartment of Chemistry, CMS College Kottayam (Autonomous) Mahatma Gandhi University, Kottayam, Kerala, India\n<br/>\n<b>E-mail:</b>\n<a href=\"mailto:vibin@cmscollege.ac.in\">vibin@cmscollege.ac.in</a> </span>\n</p>\n<p>\n<span>\n<sup>b</sup>\n</span>\n<span>\nE. C. G. Sudarshan Center for Theoretical Sciences, CMS College Kottayam (Autonomous), Kerala, India\n</span>\n</p>\n</div>\n</div>\n<h3>Abstract</h3>\n<div>\n<p>Machine learning (ML) is revolutionizing various scientific fields, including chemistry. Among different ML techniques, graph neural networks (GNNs) have emerged as a powerful tool for capturing complex relationships in data by representing datapoints as graphs. Applying GNNs for predicting yields in chemical reactions is one of the emerging areas of focus. However, handling heterogeneous datasets remains a key challenge. In this study, we utilized diverse datasets encompassing various transition metal-catalyzed cross-coupling reactions including Suzuki, Sonogashira, Cadiot\u2013Chodkiewicz, Ullmann-type, and Buchwald\u2013Hartwig coupling reactions. To predict reaction yields, we implement multiple GNN architectures, including message passing neural networks (MPNN), residual graph convolutional networks (ResGCN), graph sample and aggregate (GraphSAGE), graph attention networks (GAT and GATv2), graph convolutional networks (GCN), and graph isomorphism networks (GIN). The comparative analysis of these architectures reveals that MPNN achieve the highest predictive performance, with an <em>R</em><small><sup>2</sup></small> value of 0.75. Additionally, to enhance the interpretability of our models, we employed the integrated gradients method to determine the contribution of each input descriptor to the model's yield prediction. This study highlights the potential of effective and explainable graph-based models to predict the yields of chemical reactions. This work contributes to the application of machine learning in catalysis, providing valuable insights for optimizing catalytic reactions and contributing to innovations in sustainable chemistry and organic synthesis.</p>\n<p>\n</p>\n</div>\n</article>\n</section>\n<div>\n<div>\n<h2>Article information</h2>\n<dl>\n<p>\n</p><dt>DOI</dt>\n<dd><a href=\"https://doi.org/10.1039/D5CP01072A\">https://doi.org/10.1039/D5CP01072A</a></dd>\n<p></p>\n<p>\n</p><dt><strong>Article type</strong></dt>\n<dd>Paper</dd>\n<p></p>\n<p>\n</p><dt>Submitted</dt>\n<dd>19 Mar 2025</dd>\n<p></p>\n<p>\n</p><dt>Accepted</dt>\n<dd>02 Jun 2025</dd>\n<p></p>\n<p>\n</p><dt>First published</dt>\n<dd>02 Jun 2025</dd>\n<p></p>\n</dl>\n<div>\n<p>\n</p><h3>\n</h3>\n<p></p>\n<div>\n<p><i><strong>Phys. Chem. Chem. Phys.</strong></i>, 2025,<span></span><strong>27</strong>, 14277-14287\n</p> </div>\n</div>\n<div>\n<div>\n<p></p><h3>Permissions</h3><p></p>\n</div>\n<div>\n<p><a href=\"#\">\n</a></p><h3>\nPerformance assessment of various graph neural network architectures for predicting yields in cross-coupling reactions\n</h3>\n<p>\nC. Rajalakshmi, S. Salim, S. S. Cherian, R. Darsana, S. Rosemary, S. Kavya and V. I. Thomas,\n<i>Phys. Chem. Chem. Phys.</i>, 2025,\u00a0<strong>27</strong>, 14277\n<strong>DOI: </strong> 10.1039/D5CP01072A </p>\n<p>\nTo request permission to reproduce material from this article, please go to the\n<a href=\"https://marketplace.copyright.com/rs-ui-web/mp/search/all/10.1039%2fD5CP01072A\">Copyright Clearance Center request page</a>.\n</p>\n<p>\nIf you are <b>an author contributing to an RSC publication, you do not need to request permission</b>\nprovided correct acknowledgement is given.\n</p>\n<p>\nIf you are <b>the author of this article, you do not need to request permission to reproduce figures\nand diagrams</b> provided correct acknowledgement is given. If you want to reproduce the whole article\nin a third-party publication (excluding your thesis/dissertation for which permission is not required)\nplease go to the <a href=\"https://marketplace.copyright.com/rs-ui-web/mp/search/all/10.1039%2fD5CP01072A\">Copyright Clearance Center request page</a>.\n</p>\n<p>\nRead more about <a href=\"https://www.rsc.org/journals-books-databases/journal-authors-reviewers/licences-copyright-permissions/#acknowledgements\">how to correctly acknowledge RSC content</a>.\n</p>\n<p><a href=\"#\"></a>\n</p></div>\n</div>\n<div>\n<p></p><h3>Social activity</h3><p></p>\n</div>\n</div>\n<section>\n<h3>Spotlight</h3>\n<h3>Advertisements</h3>\n</section>\n</div>\n</div></div>",
      "url": "https://pubs.rsc.org/en/content/articlelanding/2025/cp/d5cp01072a"
    },
    {
      "title": "Chemical Graph-Based Transformer Models for Yield Prediction of ...",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#main-content)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n\n**Official websites use .gov**\n\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n\n**Secure .gov websites use HTTPS**\n\nA **lock** (\nLock\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n\n- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\n\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\n![ACS Omega logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-acsomega.png)\n\nACS Omega\n\n. 2024 Sep 17;9(39):40907\u201340919. doi: [10.1021/acsomega.4c06113](https://doi.org/10.1021/acsomega.4c06113)\n\n# Chemical Graph-Based Transformer Models for Yield Prediction of High-Throughput Cross-Coupling Reaction Datasets\n\n[Akinori Sato](https://pubmed.ncbi.nlm.nih.gov/?term=%22Sato%20A%22%5BAuthor%5D)\n\n### Akinori Sato\n\n\u2020Data\nScience Center, Nara Institute of Science\nand Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\n\u2021Graduate\nSchool of Science and Technology, Nara Institute\nof Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\nFind articles by [Akinori Sato](https://pubmed.ncbi.nlm.nih.gov/?term=%22Sato%20A%22%5BAuthor%5D)\n\n\u2020,\u2021, [Ryosuke Asahara](https://pubmed.ncbi.nlm.nih.gov/?term=%22Asahara%20R%22%5BAuthor%5D)\n\n### Ryosuke Asahara\n\n\u2021Graduate\nSchool of Science and Technology, Nara Institute\nof Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\nFind articles by [Ryosuke Asahara](https://pubmed.ncbi.nlm.nih.gov/?term=%22Asahara%20R%22%5BAuthor%5D)\n\n\u2021, [Tomoyuki Miyao](https://pubmed.ncbi.nlm.nih.gov/?term=%22Miyao%20T%22%5BAuthor%5D)\n\n### Tomoyuki Miyao\n\n\u2020Data\nScience Center, Nara Institute of Science\nand Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\n\u2021Graduate\nSchool of Science and Technology, Nara Institute\nof Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\nFind articles by [Tomoyuki Miyao](https://pubmed.ncbi.nlm.nih.gov/?term=%22Miyao%20T%22%5BAuthor%5D)\n\n\u2020,\u2021,\\*\n\n- Author information\n- Article notes\n- Copyright and License information\n\n\u2020Data\nScience Center, Nara Institute of Science\nand Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\n\u2021Graduate\nSchool of Science and Technology, Nara Institute\nof Science and Technology, 8916-5 Takayama-cho, Ikoma, Nara 630-0192, Japan\n\n\\*\n\nEmail: miyao@dsc.naist.jp.\n\nReceived 2024 Jul 2; Accepted 2024 Sep 3; Revised 2024 Aug 28; Collection date 2024 Oct 1.\n\n\u00a9 2024 The Authors. Published by American Chemical Society\n\nPermits the broadest form of re-use including for commercial purposes, provided that author attribution and integrity are maintained ( [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC11447720\u00a0\u00a0PMID: [39372005](https://pubmed.ncbi.nlm.nih.gov/39372005/)\n\n## Abstract\n\n[![graphic file with name ao4c06113_0008.jpg](https://cdn.ncbi.nlm.nih.gov/pmc/blobs/f819/11447720/8b566af620e0/ao4c06113_0008.jpg)](https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=11447720_ao4c06113_0008.jpg)\n\nThe chemical reaction yield is an important factor to\ndetermine\nthe reaction conditions. Recently, many data-driven models for yield\nprediction using high-throughput experimentation datasets have been\nreported. In this study, we propose a neural network architecture\nbased on the chemical graphs of the reaction components to predict\nthe reaction yield. The proposed model is the sequential combination\nof a message-passing neural network and a transformer encoder ( _MPNN-Transformer_). The reaction components are converted\nto molecular matrices by the first network, followed by the interplay\nof the reaction components in the second network after adding the\nembeddings of the compound roles in the chemical reaction. The predictive\nability of the proposed models was compared with state-of-the-art\nyield prediction models using two high-throughput experimental datasets:\nthe Buchwald\u2013Hartwig cross-coupling (BHC) and Suzuki\u2013Miyaura\ncross-coupling (SMC) reaction datasets. Overall, the _MPNN-Transformer_ models showed high prediction accuracy for the BHC reaction datasets\nand some of the extrapolation-oriented SMC reaction datasets. These\nmodels also performed well when the training dataset size was relatively\nlarge. Furthermore, analyzing the poorly predicted reactions for the\nBHC reaction dataset revealed a limitation of the data-driven yield\nprediction approach based on the chemical structural similarity.\n\n## 1\\. Introduction\n\nThe chemical reaction\nyield is defined as the number of moles of\nthe product obtained divided by the theoretical number of moles of\nthe product based on the stoichiometry, which is one of the most important\nfactors to determine the reaction conditions. In other words, the\nreaction yield depends on the reaction conditions, such as temperature,\nconcentrations, and reaction time. Thus, data-driven yield prediction\nusing a dataset obtained from a homogeneous reaction condition is\na reasonable approach,[1](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref1) and several studies\nhave been reported accordingly. Among the yield prediction models,\nmachine learning (ML) including deep neural network models can predict\nthe reaction yield with high accuracy when it is trained on a few\nthousand chemical reactions under controlled reaction conditions,\nwhich is called high-throughput experimentation (HTE).[2](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref2), [3](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref3) For example, highly predictive random forest (RF) models for the\nyield prediction of the Buchwald\u2013Hartwig cross-coupling (BHC)\nreaction have been reported using a HTE dataset with the descriptors\ncalculated by quantum chemical calculations.[2](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref2) Several ML models constructed based on the HTE data of the Suzuki\u2013Miyaura\ncross-coupling (SMC) reaction have also been reported to optimize\nthe reaction conditions for higher yield.[4](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref4)\n\nHTE reaction datasets have been extensively used for the development\nof ML yield prediction models. A neural network model based on bidirectional\nencoder representations from transformers (BERT) has been proposed\nto predict the yields of SMC reactions,[3](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref3) where the chemical language of simplified molecular-input line-entry\nsystem (SMILES) was used as the input.[5](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref5) A language-based network architecture as a derivative of the text-to-text\ntransfer transformer (T5)[6](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref6) has been developed\nfor solving multiple tasks in a chemical reaction by one model.[7](https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720/#ref7) The direct use of chemical graphs as model input\nhas been proposed in combination with graph neural networks.[8](https://pmc.ncbi.nlm.nih.gov/articles/PM...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11447720"
    },
    {
      "title": "Chemical reaction yield prediction - Blackthorn AI",
      "text": "Chemical Sciences\n# Chemical reaction yield prediction\nA novel graph neural network architecture was designed for organic reaction yield prediction. The network combines structural information, molecular-, and reaction-level descriptors. Our approach outperforms or equals all known AI models predicting chemical reaction yields.\n### Business Goals\nDevelop an application for estimating the chemical yield of the target product for [unexplored organic reactions](https://blackthorn.ai/industries/pharma-biotech-software-development/).\n### Challenge\nTypically, product yield estimations are empirical, i.e., based on synthetic chemists\u2019 experience. Therefore, there is no reliable way to predict yields for new chemical reactions.\n### Results\n- Our approach outperforms or equals all known state-of-the-art AI models predicting chemical reaction yields on public datasets:\n- R^2 = 0.86, RMSE = 1.35 on Suzuki-Miyaura \\[https://www.science.org/doi/10.1126/science.aap9112\\]\n- R^2 = 0.93 on Buchwald-Hartwig \\[https://www.science.org/doi/10.1126/science.aar5169\\]\n#### Implementation Details\n- A novel graph neural network architecture (RD-MPNN) was designed for organic reaction yield prediction. The network combines structural information, molecular-, and reaction-level descriptors. The network\u2019s performance was compared with the performance of other machine learning models on the same data and targets: linear models, decision tree ensembles, fully-connected feed-forward, and transformer networks. The RD-MPNN outperformed all the listed approaches in single- and multi-reaction class settings.\nGet a technical consultation\n![Alex Gurbych](https://blackthorn.ai/wp-content/uploads/2024/12/photo-150x150.jpg)\nAlex Gurbych\nChief Solutions Architect\nReceive a professional and in-depth consultation from an experienced expert. Get tailored advice to address your specific needs and achieve your goals effectively.\n[Book A Meeting](https://meetings-eu1.hubspot.com/meetings/gurbycholeksandr)",
      "url": "https://blackthorn.ai/projects/chemical-reaction-yield-prediction"
    },
    {
      "title": "Predicting Chemical Reaction Yields | RXN yield prediction",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "",
      "text": "The Catechol Benchmark: Time-series Solvent\nSelection Data for Few-shot Machine Learning\nToby Boyne1\u2217, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College London, London, UK1\nDepartment of Chemistry, Imperial College London, London, UK2\nSOLVE Chemistry, London, UK3\nAbstract\n1 Machine learning has promised to change the landscape of laboratory chem\u00022 istry, with impressive results in molecular property prediction and reaction retro\u00023 synthesis. However, chemical datasets are often inaccessible to the machine\n4 learning community as they tend to require cleaning, thorough understanding of the\n5 chemistry, or are simply not available. In this paper, we introduce a novel dataset\n6 for yield prediction, providing the first-ever transient flow dataset for machine\n7 learning benchmarking, covering over 1200 process conditions. While previous\n8 datasets focus on discrete parameters, our experimental set-up allow us to sample\n9 a large number of continuous process conditions, generating new challenges for\n10 machine learning models. We focus on solvent selection, a task that is particularly\n11 difficult to model theoretically and therefore ripe for machine learning applica\u000212 tions. We showcase benchmarking for regression algorithms, transfer-learning\n13 approaches, feature engineering, and active learning, with important applications\n14 towards solvent replacement and sustainable manufacturing.\n15 1 Introduction\n16 Machine learning (ML) and artificial intelligence (AI) have showcased enormous potential in em\u000217 powering the world of the natural sciences: from famous examples such as AlphaFold for protein\n18 predictions [1], to fusion reactor control [2], disease detection [3], battery design [4], and material\n19 discovery [5], among many more. However, we seldom see the machine learning community bench\u000220 mark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world\n21 data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how\n22 expensive the data can be to produce, resulting in many datasets being locked behind closed doors by\n23 large companies.\n24 AIchemy (https://aichemy.ac.uk) is an interdisciplinary UK hub with the mission of transform\u000225 ing the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as\n26 addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE\n27 Chemistry (https://www.solvechemistry.com), we present a first important step into addressing\n28 the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data\n29 machine learning algorithms for chemistry.\n30 Solvent selection is one of the biggest challenges for chemical manufacturing, with solvents often\n31 being the main source of waste in the manufacturing process [6]. Increased regulation on solvents and\n32 a drive to making process manufacturing more sustainable led to an interest in the discovery of greener\n\u2217\nt.boyne23@imperial.ac.uk ;\n\u2020\njose@solvechemistry.com\nSubmitted to 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Do not distribute.\nFigure 1: Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the\nreaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement\nproducts. We investigate the yield of the reaction for a range of different solvents. Product 1 was not\nobserved and reacted immediately to form Product 2 and later 3.\n33 solvents and for improved solvent replacement tools. However, most of the solvent replacement tools\n34 focus purely on learning unsupervised representations of solvents, with the hope that experimentalists\n35 can find solvents with similar properties to replace those with environmental concerns. A much\n36 stronger approach would consider the interaction of a variety of different solvents with a reaction of\n37 interest to directly predict reaction yields, in such a way that the best possible solvent can be selected\n38 according to a yield-sustainability trade-off.\n39 Machine learning approaches have been shown to be a powerful tool for the prediction of chemical\n40 reaction conditions. Success has been reported in retro-synthesis [7, 8], condition recommendations\n41 [9], product predictions [10, 11], among others. While yield prediction has proven to be more difficult\n42 due to large inconsistencies in procedure and data reporting [12], we have still seen promising yield\n43 prediction results for smaller and more carefully curated datasets [13\u201316]. However, these datasets\n44 lack the continuous reaction conditions, such as temperature and residence time, that are required to\n45 scale-up processes to practical manufacturing conditions.\n46 In this paper, we release the first machine-learning-ready transient flow dataset, a framework that\n47 allows for quick and efficient screening of continuous reaction conditions. We specifically provide\n48 yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure 1, with dense\n49 measurements across the residence time, temperature, and solvent space. We answer the call for\n50 more flow chemistry reaction data [17], further showcase how this type of kinetic data poses new\n51 challenges to current machine learning methods for chemistry, and identify potential solutions.\n52 1.1 Related works\n53 Reaction datasets are common in chemistry research, but their suitability for machine learning\n54 benchmarking tends to be poor. This can be a result of improper formatting or documentation,\n55 incomplete information about reaction conditions or the experimental set-up, or the lack of machine\n56 readability, leading to limited usage by the ML community. However, some effort has been made\n57 to address this, with the biggest example being the creation of the Open Reaction Database (ORD)\n58 [18], a repository containing over 2M different reactions, many of which come from US patent data\n59 (USPTO) [19]. However, the dataset falls short in some aspects, in particular with respect to machine\n60 learning readiness and data inconsistencies across reactions.\n61 ORDerly [12] allows for easy cleaning and preparation of ORD data, showing the promise of the\n62 dataset for forward and retro-synthetic prediction using transformers; however, it also shows that\n63 yield prediction cannot be done well due to data inconsistencies. Schwaller et al. [13] drew similar\n64 conclusions when using the USPTO dataset, stating that reaction conditions such as temperature,\n65 concentrations, and duration have a significant effect on yield. The assumption that every reaction in\n66 the dataset is optimized for reaction parameters proved too loose, resulting in inaccurate predictive\n67 models for yield, and highlighting the importance of creating datasets with full (including potentially\n68 sub-optimal) reaction conditions.\n69 More relevant to our work, Perera et al. [20] introduced a dataset of 5760 Suzuki-Miyaura cross\u000270 coupling reactions, Ahneman et al. [21] introduced a dataset of 3956 Buchwald\u2013Hartwig aminations,\n71 and Prieto Kullmer et al. [22] investigated screening additives for Ni-catalysed reactions, all for the\n72 purposes of yield prediction. The datasets have been used in the benchmarking of Gaussian processes\n73 and Bayesian neural networks [14], deep learning models [13], language-model-based embeddings\n2\n74 [16], data augmentation techniques [23], and Bayesian optimisation [15]. In each case, the datasets\n75 focus on discrete reaction variables, such as ligand, base, additives, or reactants at fixed temperatures\n76 and residence times. We are instead introducing a dataset rich in continuous reaction conditions (in\n77 our case temperature ...",
      "url": "https://openreview.net/pdf?id=6l8q74TabE"
    },
    {
      "title": "Interpretation of chemical reaction yields with graph neural additive ...",
      "text": "<div><div>\n<h2>We apologize for the inconvenience...</h2>\n<p>To ensure we keep this website safe, please can you confirm you are a human by ticking the box below. </p>\n<p>If you are unable to complete the above request please contact us using the below link, providing a screenshot of your experience.</p>\n<p>\n<a href=\"https://ioppublishing.org/contacts/\">https://ioppublishing.org/contacts/</a>\n</p>\n</div></div>",
      "url": "https://iopscience.iop.org/article/10.1088/2632-2153/addfaa"
    },
    {
      "title": "Machine learning for yield prediction for chemical reactions using in ...",
      "text": "<div><div><header></header><div><div><ul><li><a><span><span><span>View\u00a0<strong>PDF</strong></span></span></span></a></li><li></li></ul></div><div><article><div><p><a href=\"https://www.sciencedirect.com/journal/journal-of-molecular-graphics-and-modelling\"><span><span></span></span></a></p><p><a href=\"https://www.sciencedirect.com/journal/journal-of-molecular-graphics-and-modelling/vol/118/suppl/C\"><span><span></span></span></a></p></div><div><p><span>Under a Creative Commons </span><a href=\"http://creativecommons.org/licenses/by/4.0/\"><span><span>license</span></span></a></p><p><span></span>Open access</p></div><div><h2>Abstract</h2><div><p>Machine learning models were developed to predict product formation from time-series reaction data for ten Buchwald-Hartwig coupling reactions. The data was provided by DeepMatter and was collected in their DigitalGlassware cloud platform. The reaction probe has 12 sensors to measure properties of interest, including temperature, pressure, and colour. Colour was a good predictor of product formation for this reaction and machine learning models were able to learn which of the properties were important. Predictions for the current product formation (in terms of % yield) had a mean absolute error of 1.2%. For predicting 30, 60 and 120\u00a0min ahead the error rose to 3.4, 4.1 and 4.6%, respectively. The work here presents an example into the insight that can be obtained from applying machine learning methods to sensor data in synthetic chemistry.</p></div></div><ul><li></li><li></li></ul><div><h2>Keywords</h2><p><span>Buchwald-Hartwig cross-coupling</span></p><p><span>Long short-term memory neural network</span></p><p><span>Reaction monitoring</span></p><p><span>Time series data</span></p></div><section><header><h2>Cited by (0)</h2></header></section><p><span>\u00a9 2022 The Author(s). Published by Elsevier Inc.</span></p></article></div></div></div></div>",
      "url": "https://www.sciencedirect.com/science/article/pii/S1093326322002352"
    },
    {
      "title": "Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2411.03320v3"
    }
  ]
}