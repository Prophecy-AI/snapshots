{
  "query": "What are the best simple models for predicting chemical reaction yields with small datasets that need to generalize to unseen conditions?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting reaction yields when only a handful of experimental points are available calls for models that are both data\u2011efficient and easy to train.  The most widely\u2011used \u201csimple\u201d approach is a **random\u2011forest (RF) regression** built on reaction\u2011level descriptors (e.g., concatenated Morgan fingerprints or computed physicochemical features).  RFs handle heterogeneous inputs, are robust to over\u2011fitting on small sets, and can be interpreted through feature importance.  An even more data\u2011frugal variant is **MetaRF**, an attention\u2011augmented, differentiable random\u2011forest that learns to weight trees meta\u2011optimally and can be fine\u2011tuned with just a few new reactions, achieving strong few\u2011shot performance on high\u2011throughput\u2011experiment (HTE) datasets\u202f([jcheminf](https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-023-00715-x.pdf)).  \n\nWhen a modest amount of prior data exists (e.g., literature collections such as NiCOlit), **gradient\u2011boosted decision trees** (e.g., XGBoost) or **linear regression on curated molecular descriptors** provide a lightweight alternative that still captures non\u2011linear structure\u2013yield relationships.  These models have been shown to work well on small, domain\u2011specific datasets of nickel\u2011catalyzed C\u2013O couplings\u202f([HAL](https://hal.sorbonne-universite.fr/hal-03790865v1/preview/Predicting_reaction_yields___JACS_Format_changes.pdf)).  Adding a **k\u2011nearest\u2011neighbors (k\u2011NN)** baseline on reaction SMILES fingerprints can further help assess whether a new condition lies within the training manifold, flagging extrapolation risks.  \n\nTo improve generalization to **unseen reaction conditions**, recent work combines the above simple learners with **active transfer learning**: a meta\u2011model is first trained on a large, related reaction space and then selectively fine\u2011tuned on the few available points from the target domain, often using an acquisition function to choose the most informative experiments\u202f([RSC](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b)).  In practice, a workflow that starts with an RF or XGBoost baseline, augments it with attention/meta\u2011learning (MetaRF) when possible, and leverages active transfer learning for experimental design offers the best balance of simplicity, data efficiency, and ability to extrapolate to new reagents, solvents, or temperatures.",
      "url": ""
    },
    {
      "title": "MetaRF: attention-based random forest for reaction yield prediction with a few trails",
      "text": "Chen\u00a0et\u00a0al. Journal of Cheminformatics (2023) 15:43 \nhttps://doi.org/10.1186/s13321-023-00715-x\nRESEARCH Open Access\n\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativeco\nmmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nJournal of Cheminformatics\nMetaRF: attention-based random forest \nfor\u00a0reaction yield prediction with\u00a0a\u00a0few trails\nKexin Chen1, Guangyong Chen2*, Junyou Li2, Yuansheng Huang3, Ercheng Wang2,3, Tingjun Hou3 and \nPheng\u2011Ann Heng1,2\nAbstract\nArtifcial intelligence has deeply revolutionized the feld of medicinal chemistry with many impressive applications, \nbut the success of these applications requires a massive amount of training samples with high-quality annotations, \nwhich seriously limits the wide usage of data-driven methods. In this paper, we focus on the reaction yield prediction \nproblem, which assists chemists in selecting high-yield reactions in a new chemical space only with a few experi\u2011\nmental trials. To attack this challenge, we frst put forth MetaRF, an attention-based random forest model specially \ndesigned for the few-shot yield prediction, where the attention weight of a random forest is automatically optimized \nby the meta-learning framework and can be quickly adapted to predict the performance of new reagents while given \na few additional samples. To improve the few-shot learning performance, we further introduce a dimension-reduction \nbased sampling method to determine valuable samples to be experimentally tested and then learned. Our methodol\u2011\nogy is evaluated on three diferent datasets and acquires satisfactory performance on few-shot prediction. In high\u0002throughput experimentation (HTE) datasets, the average yield of our methodology\u2019s top 10 high-yield reactions is \nrelatively close to the results of ideal yield selection.\nKeywords Few-shot, Yield prediction, Random forest, Meta-learning\nIntroduction\nComputer-aided synthesis planning (CASP)\u00a0 [1], which \naims to assist chemists in synthesizing new molecule \ncompounds, has been rapidly transformed by artifcial \nintelligence methods. Given the availability of large-scale \nreaction datasets, such as the United States Patent and \nTrademark Ofce (USPTO) [2], Reaxys [3], and SciFinder \n[4], CASP has become an increasingly popular topic in \npharmaceutical discovery and organic chemistry with \nmany impressive breakthroughs achieved [5]. Te current \nCASP systems can be divided into two critical aspects, \nretrosynthetic planning and forward-reaction prediction \n[6]. Retrosynthetic planning, including template-based \nand template-free methods, can help generate possible \nsynthetic routes of target molecules [7]. Forward-reac\u0002tion prediction is mainly used to evaluate the strategies \nproposed by retrosynthetic planning and increase the \nlikelihood of experimental success [8]. However, with\u0002out considering reaction yield or reaction conditions, the \nsynthetic strategies proposed in the CASP systems would \nbe difcult to be implemented. It still remains a big chal\u0002lenge to predict the reaction yield. Due to the complexity \nof chemical experiments, few solid theories can help pre\u0002dict the reaction yield of a new chemical reaction given \na specifc condition, let alone optimize a reaction con\u0002dition, which heavily depends on expertise, knowledge, \nintuition, numerous practices, extensive literature read\u0002ing and even the luck of chemists [5, 9].\n*Correspondence:\nGuangyong Chen\ngychen@zhejianglab.com\n1\n Department of Computer Science and Engineering, The Chinese \nUniversity of Hong Kong, New Territories, Hong Kong SAR 2\n Zhejiang Lab, Zhejiang, China\n3\n College of Pharmaceutical Sciences, Zhejiang University, Zhejiang, China\nChen\u00a0et\u00a0al. Journal of Cheminformatics (2023) 15:43 Page 2 of 12\nSome pioneer eforts have been contributed to pre\u0002dict the reaction yield, and then fnd the optimal reac\u0002tion condition. Note that the optimal reaction selection \nproblem can be naturally treated as a classical out-of-dis\u0002tribution (OOD) problem, since the optimal reaction is \noften not included in the training set. Ahneman et\u00a0al. [10] \nreported that the random forest model achieved the best \nperformance on OOD yield prediction due to its good \ngeneralization ability. Zuranski et\u00a0 al. [11] reviewed and \nexamined the OOD performance of diferent machine \nlearning algorithms and reaction embedding techniques. \nDong et\u00a0 al. [12] used the XGBoost model and achieved \nsatisfactory OOD performance. Zhu et\u00a0 al. [13] demon\u0002strated that regression-based machine learning had great \napplication potential in OOD yield prediction.\n[R2\u20134] Studying the experimental results in previ\u0002ous work, we found that the predicting performance \nwill deteriorate dramatically when there exists relatively \nlarge diference between training and testing data. For \ninstance, in the experiments of [10, 14, 15], when the \ntesting data do not contain any new reagents that are \ndiferent from the training set (testing data is randomly \nselected from the whole dataset, and the rest of the data \nis used as training set), the R2\n of random forest model \nis 0.92. When the testing data includes new additives \nthat are not contained in the training data (testing data \nincludes reactions with some additives, while training \ndata includes reactions with other additives), the R2\n of \nrandom forest model will drop to 0.19 in the worst case \n(the size of training set is almost same). Tis performance \ndeterioration problem will be very common when using \nyield prediction model to explore new reaction chemi\u0002cal space, as the size of unknown chemical space to be \npredicted can be huge. Enlarging training set with huge \namount of data may solve this performance deteriora\u0002tion problem, but it is not practical due to the high cost \nof experimental data and huge size of unknown chemical \nspace.\nIn this paper, we follow a more relaxed but practical \nsetting, where we are allowed to add a few data of new \nreagents or conditions into the training set. Considering \nthe limited amount of reaction condition data, few-shot \nyield prediction has great potential in solving this prob\u0002lem. Few-shot yield prediction adds very few reaction \nsamples(e.g. around fve samples) from new reagents or \nconditions into training data. It is reasonable to hypoth\u0002esize that using data of a new reagent can improve pre\u0002diction results. Questions yet to be explored are how to \nuse these new samples, which sample to select, and how \nmuch data from the new reagent leads to a satisfactory \nresult.\nTo bridge this gap, we proposed MetaRF, an atten\u0002tion-based random forest model with a meta-learning \ntechnique applied to determine attention weights adap\u0002tively. Te random forest has been proved as an ensem\u0002ble method with outstanding performance on datasets \nwith small sample size [16, 17]. Since the size of reaction \ncondition datasets are relatively small (e.g. 781 reactions \nin Buchwald-Hartwig electronic laboratory notebooks \ndataset [18]), random forest models have shown excellent \nperformance on reaction yield predictio...",
      "url": "https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-023-00715-x.pdf"
    },
    {
      "title": "Machine Learning Yield Prediction from NiCOlit, a Small-Size Literature Data Set of Nickel Catalyzed C\u2013O Couplings",
      "text": "HAL Id: hal-03790865\nhttps://hal.sorbonne-universite.fr/hal-03790865v1\nSubmitted on 28 Sep 2022\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci\u0002entific research documents, whether they are pub\u0002lished or not. The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\nL\u2019archive ouverte pluridisciplinaire HAL, est\ndestin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents\nscientifiques de niveau recherche, publi\u00e9s ou non,\n\u00e9manant des \u00e9tablissements d\u2019enseignement et de\nrecherche fran\u00e7ais ou \u00e9trangers, des laboratoires\npublics ou priv\u00e9s.\nMachine Learning Yield Prediction from NiCOlit, a\nSmall-Size Literature Data Set of Nickel Catalyzed C\u2013O\nCouplings\nJules Schleinitz, Maxime Langevin, Yanis Smail, Benjamin Wehnert, Laurence\nGrimaud, Rodolphe Vuilleumier\nTo cite this version:\nJules Schleinitz, Maxime Langevin, Yanis Smail, Benjamin Wehnert, Laurence Grimaud, et al..\nMachine Learning Yield Prediction from NiCOlit, a Small-Size Literature Data Set of Nickel Cat\u0002alyzed C\u2013O Couplings. Journal of the American Chemical Society, 2022, 144 (32), pp.14722-14730.\nff10.1021/jacs.2c05302ff. ffhal-03790865ff\nMachine Learning Yield Prediction from\nNiCOlit, a Small-Size Literature Dataset of\nNickel Catalyzed C-O Couplings\nJ. Schleinitz,\u2217,\u2020,\u2021 M. Langevin,\u2217,\u2020,\u00b6,\u00a7 Y. Smail,\u2225 B. Wehnert,\u2225 L. Grimaud,\u2217,\u2021and R.\nVuilleumier\u2217,\u00b6\n\u2020Those authors contributed equally to this work\n\u2021LBM, D\u00e9partement de chimie, \u00c9cole Normale Sup\u00e9rieure, PSL University, Sorbonne\nUniversit\u00e9, CNRS, 75005, Paris, France\n\u00b6PASTEUR, D\u00e9partement de chimie, \u00c9cole Normale Sup\u00e9rieure, PSL University, Sorbonne\nUniversit\u00e9, CNRS, 75005, Paris, France\n\u00a7Molecular Design Sciences - Integrated Drug Discovery, Sanofi R&D, 94400,\nVitry-Sur-Seine, France\n\u2225UPMC, PSL University, Sorbonne Universit\u00e9, CNRS, 75005, Paris, France\nE-mail: jules.schleinitz@ens.psl.eu; maxime.langevin@sanofi.com; laurence.grimaud@ens.psl.eu;\nrodolphe.vuilleumier@ens.psl.eu\nAbstract\nSynthetic yield prediction using machine learning is intensively studied. Previous\nwork focused on two categories of datasets: High-Throughput Experimentation data,\nas an ideal case study and datasets extracted from proprietary databases, which are\nknown to have a strong reporting bias towards high yields. However, predicting yields\nusing published reaction data remains elusive. To fill the gap, we built a dataset on\n1\nnickel-catalyzed cross-couplings extracted from organic reaction publications, including\nscope and optimization information. We demonstrate the importance of including\noptimization data as a source of failed experiments and emphasize how publication\nconstraints shape the exploration of the chemical space by the synthetic community.\nWhile machine learning models still fail to perform out-of-sample predictions, this work\nshows that adding chemical knowledge enables fair predictions in a low-data regime.\nEventually, we hope that this unique public database will foster further improvements\nof machine learning methods for reaction yield prediction in a more realistic context.\nIntroduction\nMachine learning (ML) algorithms learn complex functions from data. As it can leverage\nexisting data to perform in silico approximations of costly experimental processes, ML\napplications have sparked strong interest in chemical sciences. While ML has already made a\nsignificant impact in drug development, 1,2 synthetizability assessment of small molecules 3 or\nComputer Aided Synthesis Planning, 4the ability of ML to predict a reaction yield from its\nexperimental conditions remains a major challenge 5that is intensively studied. 6,7 Advances\non reaction yield prediction would have a major impact on organic synthesis by significantly\nreducing cost, time and resources necessary to synthesize new chemicals.\nProgress in ML is markedly driven by the increasing access to data. Thus, currently\navailable datasets shape the evolution of ML for reaction yield prediction. Despite this,\nthere are very few publicly available and easily operable datasets of chemical reactions with\nassociated yields (Table S1). One of those few public datasets is the United State Patent\nand Trademark Office (USPTO) dataset, 8that covers a wide range of chemical reactions\nextracted from patents. USPTO data is extremely diverse and suffers from a selection bias\nas only successful reactions tend to be reported in patents. ML has shown poor performance\npredicting yields on this dataset (R2 < 0.2).7In addition, two sets of High Throughput\nExperimentation (HTE) data, one of a Suzuki-Miyaura coupling, 9 and one of a palladium\u00022\ncatalyzed Buchwald-Hartwig cross-coupling, 10 are available in the literature. State-of-the-art\nmodeling performs extremely well on those high-quality datasets (R2 > 0.8),7,10 but the\nextremely focused chemical reaction space covered by HTE limits the predictions to a narrow\nscope of experimental conditions and reactants.\nWhile these datasets have enabled rapid progress of ML for yield prediction, there is a\nneed for publicly available datasets 11,12 more representative of published reaction data or\nused by chemists in their everyday work. To the best of our knowledge, the most recent\nworks on predicting reaction yields 5,13 rely on datasets extracted from Reaxys or Sci-Findern,\nwhich are not representative of the whole information contained in published reaction data.\nThe main hurdle to gather a machine readable reaction database is the difficulty to automate\ndata extraction from publications. One of the solution to overcome this issue would be\na change toward a numerical data storage in the chemistry community, an option being\nthe use of electronic laboratory notebooks 14 (ELN) interfaced with open-access database. 15\nNevertheless, the implementation of such tools requires significant time and investment. It\nalso requires to convince the chemistry community of the merits of gathering data in a\nmachine-readable format. Thus, we believe that showing the potentiality of a dataset derived\nfrom published reaction data to predict reaction yield would encourage chemists to embrace\nthe new technologies available. Such a change would benefit the whole chemistry community.\nTo address this, we built a literature-mined, open-access reaction dataset that focuses on\nthe Ni-catalyzed C\u2013O bond activation to form C\u2013C and C\u2013N bonds: the NiCOlit dataset. 16 It\ngathers more than two thousand peer-reviewed reactions with detailed experimental conditions.\nAs a singular literature representative dataset, NiCOlit stands as a benchmark for machine\nlearning prediction of chemical yields found in published reaction data.\n3\nFigure 1: (A) Chemical space of NiCOlit, (B) Diversity of NiCOlit in terms of coupling\npartners, substrates and ligands combinations, the color map is proportional to the number of\nreactions encountered for each combination. (C) t-SNE projection of NiCOlit obtained with\na DFT-featurization of the dataset, reaction data points are coloured by coupling partner\ncategory (left figure) and by publication origin (right figure).\n4\nResults and Discussion\nDescription of NiCOlit\nNiCOlit was manually extracted from published reaction data cited in a recent review from\nDiao and co-workers. 17 In this review, the authors focus on the activation of carbon-oxygen\nbonds of phenol derivatives with nickel catalysts for coupling reactions. In order to reduce\nthe size and the diversity of the dataset we arbitrarily restrained the study to challenging\nelectrophiles towards the oxidative addition: sulfonates, 18 phosphates and in situ activated\nphenols were left aside.\nThe reactions displayed in both the main articles and their SI were extracted. For each\nreaction, the Simplified Molecular-Input Line-Entry System (SMILES) 19 chains of substrates,\ncoupling partners, precursors, ligands, bases, additives, solvents, and products were gathered\nas well as experimental variables: reaction time, temperature and molar ratios of ...",
      "url": "https://hal.sorbonne-universite.fr/hal-03790865v1/preview/Predicting_reaction_yields___JACS_Format_changes.pdf"
    },
    {
      "title": "Predicting reaction conditions from limited data through active transfer learning",
      "text": "[![Royal Society of Chemistry](https://pubs.rsc.org/content/NewImages/royal-society-of-chemistry-logo.png)](https://pubs.rsc.org/)\n\n[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2022/sc/d1sc06932b)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d2sc01662a)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc05681f)\n\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b)\n\n![](https://pubs.rsc.org/content/newimages/open_access_blue.png) Open Access Article\n\n![](https://pubs.rsc.org/content/newimages/CCBY-NC.svg)\nThis Open Access Article is licensed under a [Creative Commons Attribution-Non Commercial 3.0 Unported Licence](http://creativecommons.org/licenses/by-nc/3.0/)\n\nDOI:\u00a0[10.1039/D1SC06932B](https://doi.org/10.1039/D1SC06932B)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2022, **13**, 6655-6668\n\n# Predicting reaction conditions from limited data through active transfer learning [\u2020](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b\\#fn1)\n\nEunjae\nShim\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-4085-9659)a,\nJoshua A.\nKammeraad\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-0386-7198)ab,\nZiping\nXu\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-2591-0356)b,\nAmbuj\nTewari\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0001-6969-7844)bc,\nTim\nCernak\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0001-5407-0643)\\*ad and Paul M.\nZimmerman\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-7444-1314)\\*a\n\naDepartment of Chemistry, University of Michigan, Ann Arbor, MI, USA. E-mail: [paulzim@umich.edu](mailto:paulzim@umich.edu)\n\nbDepartment of Statistics, University of Michigan, Ann Arbor, MI, USA\n\ncDepartment of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA\n\ndDepartment of Medicinal Chemistry, University of Michigan, Ann Arbor, MI, USA. E-mail: [tcernak@med.umich.edu](mailto:tcernak@med.umich.edu)\n\nReceived\n10th December 2021\n, Accepted 10th May 2022\n\nFirst published on 11th May 2022\n\n* * *\n\n## Abstract\n\nTransfer and active learning have the potential to accelerate the development of new chemical reactions, using prior data and new experiments to inform models that adapt to the target area of interest. This article shows how specifically tuned machine learning models, based on random forest classifiers, can expand the applicability of Pd-catalyzed cross-coupling reactions to types of nucleophiles unknown to the model. First, model transfer is shown to be effective when reaction mechanisms and substrates are closely related, even when models are trained on relatively small numbers of data points. Then, a model simplification scheme is tested and found to provide comparative predictivity on reactions of new nucleophiles that include unseen reagent combinations. Lastly, for a challenging target where model transfer only provides a modest benefit over random selection, an active transfer learning strategy is introduced to improve model predictions. Simple models, composed of a small number of decision trees with limited depths, are crucial for securing generalizability, interpretability, and performance of active transfer learning.\n\n* * *\n\n## Introduction\n\nComputers are becoming increasingly capable of performing high-level chemical tasks. [1\u20134](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit1) Machine learning approaches have demonstrated viable retrosynthetic analyses, [5\u20137](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit5) product prediction, [8\u201311](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit8) reaction condition suggestion, [12\u201316](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit12) prediction of stereoselectivity, [17\u201320](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit17) regioselectivity, [19,21\u201324](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit19) and reaction yield [25,26](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit25) and optimization of reaction conditions. [27\u201330](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit27) These advances allow computers to assist synthesis planning for functional molecules using well-established chemistry. For machine learning to aid the development of new reactions, a model based on established chemical knowledge must be able to generalize its predictions to reactivity that lies outside of the dataset. However, because most supervised learning algorithms learn how features (e.g. reaction conditions) within a particular domain relate to an outcome (e.g. yield), the model is not expected to be accurate outside its domain. This situation requires chemists to consider other machine learning methods for navigating new reactivity.\n\nExpert knowledge based on known reactions plays a central role in the design of new reactions. The assumption that substrates with chemically similar reaction centers have transferable performance provides a plausible starting point for experimental exploration. This concept of chemical similarity, together with literature data, guides expert chemists in the development of new reactions. Transfer learning, which assumes that data from a nearby domain, called the source domain, can be leveraged to model the problem of interest in a new domain, called the target domain, [31](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) emulates a tactic commonly employed by human chemists.\n\nTransfer learning is a promising strategy when limited data is available in the domain of interest, but a sizeable dataset is available in a related domain. [31,32](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) Models are first created using the source data, then transferred to the target domain using various algorithms. [19,33\u201335](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit19) For new chemical targets where no labeled data is available, the head start in predictivity a source model can provide becomes important. However, when a shift in distribution of descriptor values occurs (e.g., descriptors outside of the original model ranges) in the target data, making predictions becomes challenging. For such a situation, the objective of transfer learning becomes training a model that is as predictive in the target domain as possible. [31,36](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit31) Toward this end, cross-validation is known to improve generalizability by providing a procedure to avoid overfitting on the training data. [37](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit37) The reduction of generalization error, however, may not be sufficient outside the source domain. Accordingly, new methods that enhance the applicability of a transferred model to new targets would be beneficial for reaction condition prediction.\n\nAnother machine learning method that can help tackle data scarcity is active learning. By making iterative queries of labeling a small number of datapoints, active learning updates models with knowledge from newly labeled data. As a result, exploration is guided into the most informative areas and avoids collection of unnecessary data. [38,39](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b#cit38) Active learning is therefore well-suited for reaction development, which greatly benefits from efficient exploration and where chemists conduct the next batch of reactions based on previous experimental result...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2022/sc/d1sc06932b"
    },
    {
      "title": "Predicting Chemical Reaction Yields",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "Dataset Design for Building Models of Chemical Reactivity",
      "text": "UCLA\nUCLA Previously Published Works\nTitle\nDataset Design for Building Models of Chemical Reactivity.\nPermalink\nhttps://escholarship.org/uc/item/1s46j7rv\nJournal\nACS Central Science, 9(12)\nISSN\n2374-7943\nAuthors\nRaghavan, Priyanka\nHaas, Brittany\nRuos, Madeline\net al.\nPublication Date\n2023-12-27\nDOI\n10.1021/acscentsci.3c01163\nCopyright Information\nThis work is made available under the terms of a Creative Commons Attribution License,\navailable at https://creativecommons.org/licenses/by/4.0/\nPeer reviewed\neScholarship.org Powered by the California Digital Library\nUniversity of California\nDataset Design for Building Models of Chemical Reactivity\nPriyanka Raghavan, Brittany C. Haas,\u22a5 Madeline E. Ruos,\u22a5 Jules Schleinitz,\u22a5 Abigail G. Doyle,\nSarah E. Reisman, Matthew S. Sigman, and Connor W. Coley*\nCite This: ACS Cent. Sci. 2023, 9, 2196\u22122204 Read Online\nACCESS Metrics & More Article Recommendations\nABSTRACT: Models can codify our understanding of chemical\nreactivity and serve a useful purpose in the development of new\nsynthetic processes via, for example, evaluating hypothetical reaction\nconditions or in silico substrate tolerance. Perhaps the most determining\nfactor is the composition of the training data and whether it is sufficient\nto train a model that can make accurate predictions over the full domain\nof interest. Here, we discuss the design of reaction datasets in ways that\nare conducive to data-driven modeling, emphasizing the idea that training\nset diversity and model generalizability rely on the choice of molecular or\nreaction representation. We additionally discuss the experimental\nconstraints associated with generating common types of chemistry\ndatasets and how these considerations should influence dataset design\nand model building.\n\u25a0 INTRODUCTION\nData-driven modeling in organic chemistry dates back almost a\ncentury.1 Since then, researchers have explored various\napproaches to correlate molecular properties with reaction\nperformance by using a broad range of techniques from linear\nfree energy relationships (LFERs) to multivariate linear\nregression to deep learning. Besides the type of model itself,\napproaches have varied with respect to their application\ndomain, diversity of inputs, and performance measure or\nprediction target. Here, we focus on models that are trained on\nexperimental data to anticipate quantitative performance\nmetrics, such as reaction yields, selectivities, or even rates.\nThe major themes and trends in building such structure\u2212\nproperty relationships2,3 and the broader landscape of\npredictive chemistry4 have been the subject of recent reviews.\nHowever, in addition to the many publicized success stories\nusing models to predict the performance of chemical reactions,\nwe have witnessed many cases where modeling has been less\nsuccessful. Our ability to train models that support chemistry\nobjectives is dependent on data in ways that may be\nunderappreciated and underreported.\nIn this Outlook, we discuss the concept of dataset design\n(Figure 1)\ufffdthe construction of experimental datasets with\nmodeling applications in mind\ufffdand some of the pitfalls that\nwe have encountered when learning from datasets that have\nnot been intentionally designed for machine learning. We have\norganized our discussion around the primary considerations\nwhen the aim is model building and describe at each stage how\nthose model considerations should directly influence dataset\ndesign.\n\u25a0 DEFINING THE DESIRED DOMAIN OF\nAPPLICABILITY\nA primary consideration of model building is the desired\ndomain of applicability: the range of inputs over which we\nwould like a model to make accurate predictions. Do we want\nto be able to query the model with any set of reactants,\nconditions, and products and have it estimate the yield? Or, are\nthere specific combinations of known substrates that we want\nto study? Is it acceptable to assume a constant, unvarying\ntemperature and reaction time, or do we also want to\nunderstand how those factors influence the reaction perform\u0002ance? Here, we can draw a distinction between \u201cglobal\u201d and\n\u201clocal\u201d models. The former might involve using a corpus of\nliterature data (for example, the Chemical Abstracts Service\n(CAS) Content Collection or the Pistachio, USPTO, or\nReaxys datasets) containing millions of examples and spanning\nthousands of reaction types. The latter might involve focusing\non a single reaction type and a well-defined set of substrates\nand reaction conditions; in most substrate scope studies, the\nreaction conditions are not varied. While a globally useful\nmodel is appealing in its scope, it is generally advantageous to\nhave a sufficiently narrow domain of applicability to minimize\nReceived: September 20, 2023\nRevised: November 6, 2023\nAccepted: November 15, 2023\nPublished: December 8, 2023\nhttp://pubs.acs.org/journal/acscii Outlook\n\u00a9 2023 The Authors. Published by American Chemical Society 2196\nhttps://doi.org/10.1021/acscentsci.3c01163\nACS Cent. Sci. 2023, 9, 2196\u22122204\nThis article is licensed under CC-BY 4.0\nunderlying mechanism changes, reactivity cliffs, or interaction\neffects in the dataset. These are factors that not only increase\nmodeling difficulty but also are seldom accounted for in model\ninputs. This perhaps explains why predicting selectivity has\nseen more consistent success than predicting yield, as is\ndiscussed later. Furthermore, some literature-derived datasets\nare algorithmically extracted from text and have not undergone\nextensive manual curation or validation, so certain fields may\nbe omitted or incorrect.\nThe datasets we can use for model training exhibit diversity\nalong different axes (Figure 2A). Data derived from the\npublished literature span a wide range of substrates and\nreaction types, but each reactant\u2212product combination might\nbe reported only once or twice. In contrast, public datasets\nfrom high-throughput experimentation (HTE) exist only for a\nfew reaction types so far (Buchwald\u2212Hartwig amination7 and\nSuzuki coupling8 being the most popular datasets), although\nmore varied datasets, both in terms of reaction types and\ndesign workflow, are emerging.9,10 Most HTE datasets are\ngenerated through parallel plate-based chemistry in 24-, 96-,\n384-, or even higher density well formats. In these\nexperimental campaigns, some reaction variables are easy to\nvary via automated liquid handling capabilities (e.g., the\ndiversity of concentrations and the combinations of additives),\nwhile other aspects (e.g., heterogeneous reactants and the\ndiversity of solvents) are harder to vary given the practical\nchallenges of stock solution preparation.\nAcquiring and screening a large number of diverse substrates\nis the most salient challenge that tends to limit the number of\ndistinct components used in HTE campaigns, which often\nleverage the combinatorial nature of discrete variable selection.\nFor example, the C\u2212N coupling dataset from Ahneman et al.7\ncovers 4140 reactions defined by the combination of 15\nchoices for the aryl halide, 23 additives, 4 Pd catalysts, 3 bases,\n1 amine, and 1 solvent, at fixed time, temperature, and\nconcentrations. Similarly, the dataset from Perera et al. of 5760\nSuzuki reactions8 was defined by combinations of 5 electro\u0002philes, 6 nucleophiles, 11 ligands, 7 bases, and 4 solvents. Even\na few choices for each component can quickly represent a large\nexperimental space, for which there tends to be a higher cost\nassociated with the HTE campaigns and, particularly with\nsignificant numbers of distinct products, a higher analytical\nburden.\nThe variation of individual components or aspects of\nreaction conditions is directly tied to the applicability domain,\nas a model should not be expected to generalize to a new\nFigure 1. Recommended conceptual workflow for dataset design. From top to bottom, (1) task definition with respect to the modeling space,\nsetting, and target; (2) experimental constraints, including the number of reactions and throughput of the analytical method; and (3) intentional\ndataset design, emphasizi...",
      "url": "https://escholarship.org/content/qt1s46j7rv/qt1s46j7rv.pdf"
    },
    {
      "title": "Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2411.03320v3"
    },
    {
      "title": "",
      "text": "Kexin Chen kxchen@cse.cuhk.edu.hk \nGuangyong Chen gychen@zhejianglab.com \nJunyou Li lijunyou@zhejianglab.com \nYuansheng Huang \nPheng-Ann Heng pheng@cse.cuhk.edu.hk \n\nDepartment of Computer Science and Engineering\nZhejiang Lab Zhejiang University Hangzhou\nThe Chinese University of Hong Kong New Territories\nHong Kong SARChina\n\n\nZhejiang Lab Hangzhou\nChina\n\n\nDepartment of Computer Science and Engineering\nZhejiang Lab Zhejiang University Hangzhou\nThe Chinese University of Hong Kong New Territories\nHong Kong SARChina\n\nMetaRF: Differentiable Random Forest for Reaction Yield Prediction with a Few Trails\nIndex Terms-few-shotyield predictionrandom forestmeta- learning\nArtificial intelligence has deeply revolutionized the field of medicinal chemistry with many impressive applications, but the success of these applications requires a massive amount of training samples with high-quality annotations, which seriously limits the wide usage of data-driven methods. In this paper, we focus on the reaction yield prediction problem, which assists chemists in selecting high-yield reactions in a new chemical space only with a few experimental trials. To attack this challenge, we first put forth MetaRF, an attention-based differentiable random forest model specially designed for the few-shot yield prediction, where the attention weight of a random forest is automatically optimized by the meta-learning framework and can be quickly adapted to predict the performance of new reagents while given a few additional samples. To improve the few-shot learning performance, we further introduce a dimension-reduction based sampling method to determine valuable samples to be experimentally tested and then learned. Our methodology is evaluated on three different datasets and acquires satisfactory performance on few-shot prediction. In high-throughput experimentation (HTE) datasets, the average yield of our methodology's top 10 high-yield reactions is relatively close to the results of ideal yield selection.\n\nI. INTRODUCTION\n\nComputer-aided synthesis planning (CASP) [1], which aims to assist chemists in synthesizing new molecule compounds, has been rapidly transformed by artificial intelligence methods. Given the availability of large-scale reaction datasets, such as the United States Patent and Trademark Office (USPTO) [2], Reaxys [3], and SciFinder [4], CASP has become an increasingly popular topic in pharmaceutical discovery and organic chemistry with many impressive breakthroughs achieved [5]. The current CASP systems can be divided into two critical aspects, retrosynthetic planning and forward-reaction prediction [6]. Retrosynthetic planning, including template-based and template-free methods, can help generate possible synthetic This work is supported by XXX(Grant No. XXX). *Correspondence author: Guangyong Chen (gychen@zhejianglab.com); routes of target molecules [7]. Forward-reaction prediction is mainly used to evaluate the strategies proposed by retrosynthetic planning and increase the likelihood of experimental success [8]. However, without considering reaction yield or reaction conditions, the synthetic strategies proposed in the CASP systems would be difficult to be implemented. It still remains a big challenge to predict the reaction yield. Due to the complexity of chemical experiments, few solid theories can help predict the reaction yield of a new chemical reaction given a specific condition, let alone optimize a reaction condition, which heavily depends on expertise, knowledge, intuition, numerous practices, extensive literature reading and even the luck of chemists [5], [9]. Some pioneer efforts have been contributed to predict the reaction yield, and then find the optimal reaction condition. Note that the optimal reaction selection problem can be naturally treated as a classical out-of-distribution (OOD) problem, since the optimal reaction is often not included in the training set. Ahneman et al. [10] reported that the random forest model achieved the best performance on OOD yield prediction due to its good generalization ability. Zuranski et al. [11] reviewed and examined the OOD performance of different machine learning algorithms and reaction embedding techniques. Dong et al. [12] used the XGBoost model and achieved satisfactory OOD performance. Zhu et al. [13] demonstrated that regression-based machine learning had great application potential in OOD yield prediction. However, in OOD yield prediction, the relatively large difference between training and testing data deteriorates the predicting performance of the model.\n\nIn this paper, we follow a more relaxed but practical setting, where we are allowed to add a few data of new reagents or conditions into the training set. Considering the limited amount of reaction condition data, few-shot yield prediction has great potential in solving this problem. Few-shot yield prediction adds very few reaction samples(e.g. around five samples) from new reagents or conditions into training data. It is reasonable to hypothesize that using data of a new reagent can improve prediction results. Questions yet to be explored are how to use these new samples, which sample to select, and how much data from the new reagent leads to a satisfactory result.\n\nTo bridge this gap, we proposed MetaRF, an attentionbased differentiable random forest model with a meta-learning technique applied to determine attention weights adaptively. The random forest has been proved as an ensemble method with outstanding performance on datasets with small sample size [14], [15].\n\nHowever, the structure of random forest is non-differential, which is hard to combine with the gradient-based techniques in meta-learning. To solve this problem and achieve robust performance on new reagents, we propose to add attention weights to the random forest through a meta-learning framework, Model Agnostic Meta-Learning (MAML) algorithm [16]. The key idea of MAML is to train the model's initial parameters so that the model can quickly adapt to a new task after the parameters have been updated through a few gradient steps computed with few-shot data from that new task [16]. MAML is applied to determine the attention weights of decision trees in the random forest so that the model can quickly adapt to predict the performance of new reagents using few-shot training samples. The choice of few-shot training samples also has a significant influence on model performance. Few-shot learning can have better-predicting performance if it is allowed to choose the training samples [17]. To tackle this challenge, we use Kennard-Stone (KS) algorithm [18] to select the most representative samples which cover the experimental space homogeneously. Since the KS algorithm is based on Euclidean distance, which suffers from the curse of dimensionality [19], T-distributed stochastic neighbor embedding (TSNE) [20] is applied for unsupervised nonlinear dimension reduction.\n\nOur methodology is comprehensively evaluated on Buchwald-Hartwig high-throughput experimentation (HTE) dataset [10], Buchwald-Hartwig electronic laboratory notebooks (ELN) dataset [21] and Suzuki-Miyaura HTE dataset [22]. In Buchwald-Hartwig high-throughput experimentation (HTE) dataset, our method achieves R 2 =0.648 using 2.5% of the dataset as the training set. To reach a comparable result, the baseline method (random forest) needs to use at least 20% of the dataset as the training set. With the help of 5 additional samples, our method can effectively explore unseen chemical space and select high-yield reactions. The 10 reactions, which are predicted to have the highest yield, reach an average yield of 93.7%, relatively close to the result of ideal yield selection (95.5%). In contrast, the top 10 high-yield reactions selected by the baseline method have an average yield of 86.3%, and the average yield of random selection is 52.1%.\n\nThe overview framework of this research is presented in Fig. 1. More details of methodology are in ...",
      "url": "https://export.arxiv.org/pdf/2208.10083v1.pdf"
    },
    {
      "title": "",
      "text": "[![Royal Society of Chemistry](https://pubs.rsc.org/content/NewImages/royal-society-of-chemistry-logo.png)](https://pubs.rsc.org/)\n\n[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2021/sc/d0sc04896h)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc05084a)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d1sc90015c)\n\n[![Check for updates](https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg)](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h)\n\n![](https://pubs.rsc.org/content/newimages/open_access_blue.png) Open Access Article\n\n![](https://pubs.rsc.org/content/newimages/CCBY.svg)\nThis Open Access Article is licensed under a\n\n[Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D0SC04896H](https://doi.org/10.1039/D0SC04896H)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2021, **12**, 1163-1175\n\n# Machine learning meets mechanistic modelling for accurate prediction of experimental activation energies [\u2020](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h\\#fn1)\n\nKjell\nJorner\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-4191-6790)a,\nTore\nBrinck\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0003-2673-075X)b,\nPer-Ola\nNorrby\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0002-2419-0705)c and David\nButtar\n[![ORCID logo](https://pubs.rsc.org/content/NewImages/orcid_16x16.png)](http://orcid.org/0000-0001-5466-023X)\\*a\n\naEarly Chemical Development, Pharmaceutical Sciences, R&D, AstraZeneca, Macclesfield, UK. E-mail: [david.buttar@astrazeneca.com](mailto:david.buttar@astrazeneca.com)\n\nbApplied Physical Chemistry, Department of Chemistry, CBH, KTH Royal Institute of Technology, Stockholm, Sweden\n\ncData Science & Modelling, Pharmaceutical Sciences, R&D, AstraZeneca, Gothenburg, Sweden\n\nReceived\n4th September 2020\n, Accepted 2nd November 2020\n\nFirst published on 5th November 2020\n\n* * *\n\n## Abstract\n\nAccurate prediction of chemical reactions in solution is challenging for current state-of-the-art approaches based on transition state modelling with density functional theory. Models based on machine learning have emerged as a promising alternative to address these problems, but these models currently lack the precision to give crucial information on the magnitude of barrier heights, influence of solvents and catalysts and extent of regio- and chemoselectivity. Here, we construct hybrid models which combine the traditional transition state modelling and machine learning to accurately predict reaction barriers. We train a Gaussian Process Regression model to reproduce high-quality experimental kinetic data for the nucleophilic aromatic substitution reaction and use it to predict barriers with a mean absolute error of 0.77 kcal mol\u22121 for an external test set. The model was further validated on regio- and chemoselectivity prediction on patent reaction data and achieved a competitive top-1 accuracy of 86%, despite not being trained explicitly for this task. Importantly, the model gives error bars for its predictions that can be used for risk assessment by the end user. Hybrid models emerge as the preferred alternative for accurate reaction prediction in the very common low-data situation where only 100\u2013150 rate constants are available for a reaction class. With recent advances in deep learning for quickly predicting barriers and transition state geometries from density functional theory, we envision that hybrid models will soon become a standard alternative to complement current machine learning approaches based on ground-state physical organic descriptors or structural information such as molecular graphs or fingerprints.\n\n* * *\n\n## Introduction\n\nAccurate prediction of chemical reactions is an important goal both in academic and industrial research. [1\u20133](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit1) Recently, machine learning approaches have had tremendous success in quantitative prediction of reaction yields based on data from high-throughput experimentation [4,5](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit4) and enantioselectivities based on carefully selected universal training sets. [6](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit6) At the same time, traditional quantitative structure\u2013reactivity relationship (QSRR) methods based on linear regression have seen a renaissance with interpretable, holistic models that can generalize across reaction types. [7](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit7) In parallel with these developments of quantitative prediction methods, deep learning models trained on reaction databases containing millions of patent and literature data have made quick qualitative yes/no feasibility prediction routine for almost any reaction type. [8](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit8)\n\nIn the pharmaceutical industry, prediction tools have great potential to accelerate synthesis of prospective drugs ( [Fig. 1a](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#imgfig1)). [9](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit9) Quick prediction is essential in the discovery phase, especially within the context of automation and rapid synthesis of a multitude of candidates for initial activity screening. [3,10,11](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit3) In these circumstances, a simple yes/no as provided by classification models is usually sufficient. More accurate prediction is necessary in the later drug development process, where the synthesis route and formulation of one or a few promising drug candidates is optimized. Here, regression models that give the reaction activation energy can be used to predict both absolute reactivity and selectivity ( [Fig. 1b](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#imgfig1)). Prediction of absolute reactivity can be used to assess feasibility under process-relevant conditions, while prediction of selectivity is key to reducing purification steps. Predictive tools therefore hold great promise for accelerating route and process development, ultimately delivering medicines to patients both faster and at lower costs.\n\n|     |     |     |\n| --- | --- | --- |\n| [![image file: d0sc04896h-f1.tif](https://pubs.rsc.org/image/article/2021/SC/d0sc04896h/d0sc04896h-f1.gif)](https://pubs.rsc.org/image/article/2021/SC/d0sc04896h/d0sc04896h-f1_hi-res.gif) |\n|  | **Fig. 1**(a) Example of synthetic route to a drug compound. Prospects for AI-assisted route design. (b) Accurate prediction of reaction barriers gives both rate and selectivity. (c) The nucleophilic aromatic substitution (SNAr) reaction. |  |\n\nThe current workhorse for computational studies of organic reactions is density functional theory (DFT, [Fig. 2a](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#imgfig2)). Since rising to prominence in the early 90s, DFT has enjoyed extraordinary success in rationalizing reactivity and selectivity across the reaction spectrum by modelling the full reaction mechanism. [12](https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h#cit12) The success of DFT can be traced in part due to a fortuitous cancellation of errors, which makes it particularly suited for properties such as enantioselectivity, which depends on the relative energies of two structurally very similar transition states (TSs). However, this cancellation of errors does not generally extend to the prediction of the absolute magnitude of reactions barriers (activation free energies, \u0394G\u2021). In particular, DFT struggles with one very important class of reactions: ionic reactions in solution. Plata and Singleton even sug...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2021/sc/d0sc04896h"
    }
  ]
}