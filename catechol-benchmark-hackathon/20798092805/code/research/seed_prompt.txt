# Seed Prompt: Chemical Reaction Yield Prediction - Loop 3

## Current Status
- Best CV score: 0.0111 from exp_000 (MLP with Spange + Arrhenius)
- Best LB score: 0.0982 from exp_000 (MLP)
- CV-LB gap: ~9x difference → **CV does not predict LB; focus on LB-validated approaches**
- Target: 0.0333 (need ~66% improvement from current best LB)

## Response to Evaluator

**Technical verdict was TRUSTWORTHY.** The DRFP experiment was correctly implemented.

**Evaluator's key insight was CORRECT:** PCA is wrong for sparse fingerprints. The evaluator correctly identified that:
1. DRFP is 97.4% sparse with only ~52 non-zero features per solvent
2. PCA treats zeros as informative, which distorts the information
3. The GNN benchmark's success was due to the architecture (graph attention, message-passing), not just DRFP features

**Evaluator's top priority:** Combine Spange + DRFP with proper handling. I AGREE with this recommendation.

**Key concerns addressed:**
1. **PCA information loss** → Will use variance-based feature selection instead (122 non-zero variance features)
2. **Feature combination not explored** → Will try Spange + DRFP (high-variance) combined
3. **Target requires 3x improvement** → Focus on feature engineering first, then ensembling

## Data Understanding
**Reference notebooks:**
- `exploration/eda.ipynb` - Data shapes, CV structure, target distributions
- `exploration/evolver_loop1_analysis.ipynb` - DRFP feature analysis
- `exploration/evolver_loop3_analysis.ipynb` - DRFP variance analysis, feature selection

**Key data facts:**
- Single solvent: 656 samples, 24 solvents (24-fold leave-one-solvent-out CV)
- Full data: 1227 samples, 13 ramps (13-fold leave-one-ramp-out CV)
- Targets: Product 2, Product 3, SM (yields 0-1)
- DRFP: 2048 features, but only 122 have non-zero variance
- Spange: 13 features, compact and effective

## What's Working
1. **MLP with Spange + Arrhenius** - LB 0.0982 (best so far)
2. **Chemical symmetry handling** - Data augmentation + TTA for mixtures
3. **Arrhenius kinetics features** - Physics-informed features consistently help

## What's NOT Working
1. **LightGBM** - LB 0.1065 (worse than MLP). Tree models don't generalize to unseen solvents.
2. **DRFP with PCA** - CV 0.017 (worse than Spange CV 0.011). PCA destroys sparse fingerprint information.
3. **Local CV as LB predictor** - 9x gap makes local CV unreliable for model selection.

## Recommended Approaches (Priority Order)

### 1. COMBINE SPANGE + DRFP (HIGH-VARIANCE) - HIGHEST PRIORITY
**Why:** Spange captures physicochemical properties, DRFP captures molecular structure. Combining them should give complementary information.
**How:**
- Use Spange (13 features) as base
- Add DRFP features with non-zero variance (122 features) - NO PCA
- Keep Arrhenius kinetics features (5 features)
- Total: ~140 features
- Use same MLP architecture with increased regularization (higher dropout, weight decay)
- Consider L1 regularization to encourage sparsity

**Expected outcome:** If DRFP adds complementary information, CV should improve. If not, confirms Spange is optimal.

### 2. DRFP WITH VARIANCE-BASED FEATURE SELECTION - MEDIUM PRIORITY
**Why:** Raw DRFP without PCA, but only keep informative features.
**How:**
- Use VarianceThreshold to keep only 122 non-zero variance features
- Combine with Arrhenius kinetics (5 features)
- Total: 127 features
- Train MLP with stronger regularization

### 3. ENSEMBLE MULTIPLE MLP MODELS - MEDIUM PRIORITY
**Why:** Reduce variance between runs, which may help close the CV-LB gap.
**How:**
- Train 10+ MLP models with different random seeds
- Average predictions
- Use the Spange + Arrhenius baseline (proven to work)

### 4. HYPERPARAMETER TUNING - LOW PRIORITY
**Why:** Current architecture may not be optimal, but features are more important.
**What to try:**
- Hidden layers: [256, 128, 64] vs [128, 128, 64] vs [512, 256, 128]
- Dropout: 0.1, 0.2, 0.3
- Learning rate: 1e-4, 5e-4, 1e-3
- Epochs: 200, 300, 500

## What NOT to Try
1. **LightGBM/XGBoost** - Already proven worse on LB (0.1065 vs 0.0982)
2. **DRFP with PCA** - Already proven worse on CV (0.017 vs 0.011)
3. **GNN from scratch** - Too complex, requires molecular graph construction
4. **Chasing local CV** - Local CV doesn't predict LB; focus on LB-validated approaches

## Validation Notes
- **DO NOT trust local CV for model selection** - Use LB submissions for validation
- **Template compliance is CRITICAL** - Last 3 cells must match template exactly
- **MLP is the baseline to beat** - Any new approach must beat LB 0.0982

## Competition Template Requirements
The model class MUST implement:
- `train_model(X_train, Y_train)` - Training method
- `predict(X_test)` - Returns predictions (numpy array or tensor)

The last 3 cells must be EXACTLY as in the template:
1. Single solvent CV loop with `model = YourModel()`
2. Full data CV loop with `model = YourModel(data='full')`
3. Submission file creation

## Technical Notes on Sparse Fingerprints
From web research:
1. **Avoid vanilla PCA** - It treats zeros as informative, distorting distances
2. **Use Truncated SVD** - Better for sparse data, operates directly on sparse matrix
3. **Feature selection by variance** - Keep only non-zero variance features
4. **Raw sparse features with regularization** - Let the model learn what's important

## Target Path
- Current best LB: 0.0982
- Target: 0.0333
- GNN benchmark: 0.0039

The path to beating the target is through better features (combining Spange + DRFP properly), not different models. The MLP architecture is sufficient; the bottleneck is feature representation.

## Next Experiment Specification
**Experiment: Spange + DRFP (high-variance) combined features**
1. Load Spange descriptors (13 features)
2. Load DRFP and select features with variance > 0 (122 features)
3. Combine: Spange + DRFP_selected + Arrhenius kinetics
4. Train MLP with:
   - Hidden layers: [256, 128, 64]
   - Dropout: 0.3 (increased for more features)
   - Weight decay: 1e-4 (increased)
   - Epochs: 300
   - 5 models bagged
5. Use same TTA for mixtures
6. Compare CV to baseline (0.011)
