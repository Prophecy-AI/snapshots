# Seed Prompt: Chemical Reaction Yield Prediction - Loop 4

## Current Status
- Best CV score: 0.0105 from exp_003 (Combined Spange + DRFP)
- Best LB score: 0.0982 from exp_000 (MLP with Spange)
- CV-LB gap: ~8.75x → **Local CV is optimistic; LB validation critical**
- Target: 0.0333 (need ~66% improvement from current best LB)

## Response to Evaluator

**Technical verdict was TRUSTWORTHY.** The combined Spange + DRFP experiment was correctly implemented.

**Evaluator's top priority: SUBMIT TO KAGGLE FOR LB VALIDATION.** I AGREE completely.
- The 5% CV improvement (0.0111 → 0.0105) needs LB validation
- If CV-LB ratio holds (~8.75x), predicted LB would be ~0.092 (marginal improvement)
- This submission will calibrate our understanding of CV-LB relationship

**Key concerns addressed:**
1. **Single solvent degradation** → Noted. If LB validates, consider task-specific features
2. **Notebook template compliance** → Will ensure last 3 cells match template exactly
3. **Training time** → Acceptable for validation; can optimize later

**Evaluator's strategic assessment was correct:**
- DRFP helps more for mixtures than single solvents (makes sense - molecular structure matters for interactions)
- Variance-based feature selection (122 features) works better than PCA
- Combined features show promise but need LB validation

## Data Understanding
**Reference notebooks:**
- `exploration/eda.ipynb` - Data shapes, CV structure, target distributions
- `exploration/evolver_loop1_analysis.ipynb` - DRFP feature analysis
- `exploration/evolver_loop3_analysis.ipynb` - DRFP variance analysis
- `exploration/evolver_loop4_analysis.ipynb` - CV-LB gap analysis

**Key data facts:**
- Single solvent: 656 samples, 24 solvents (24-fold leave-one-solvent-out CV)
- Full data: 1227 samples, 13 ramps (13-fold leave-one-ramp-out CV)
- Targets: Product 2, Product 3, SM (yields 0-1)
- DRFP: 2048 features, but only 122 have non-zero variance
- Spange: 13 features, compact and effective
- ACS PCA: 5 features (not yet tried with MLP)

## What's Working
1. **MLP with Spange + Arrhenius** - LB 0.0982 (best LB so far)
2. **Combined Spange + DRFP** - CV 0.0105 (best CV, needs LB validation)
3. **Chemical symmetry handling** - Data augmentation + TTA for mixtures
4. **Arrhenius kinetics features** - Physics-informed features consistently help
5. **Variance-based DRFP selection** - Better than PCA for sparse fingerprints

## What's NOT Working
1. **LightGBM** - LB 0.1065 (worse than MLP). Tree models don't generalize to unseen solvents.
2. **DRFP with PCA** - CV 0.017 (worse than Spange CV 0.011). PCA destroys sparse fingerprint information.
3. **Local CV as LB predictor** - 8.75x gap makes local CV unreliable for model selection.

## Critical Gap Analysis
**To beat target 0.0333 with 8.75x CV-LB ratio:**
- Required CV: < 0.0038
- Current best CV: 0.0105
- Gap to close: ~2.8x improvement needed

**GNN benchmark achieved MSE 0.0039** - This is close to what we need. The key was:
- Graph Attention Networks with molecular graph message-passing
- DRFP features (2048-dim)
- Mixture-aware continuous solvent encodings

## Recommended Approaches (Priority Order)

### 1. SUBMIT exp_003 FOR LB VALIDATION - HIGHEST PRIORITY
**Why:** We need to validate if the CV improvement translates to LB improvement.
**Expected outcome:** If LB improves proportionally (~0.092), continue this direction. If not, reconsider approach.

### 2. TASK-SPECIFIC FEATURES - HIGH PRIORITY (if LB validates)
**Why:** exp_003 showed single solvent MSE degraded (0.010429 → 0.011491) while mixture improved (0.011429 → 0.009972).
**How:**
- Single solvent: Use Spange + Arrhenius only (proven to work well)
- Full data: Use Spange + DRFP + Arrhenius (better for mixtures)
- Implement as task-aware model that selects features based on data type

### 3. MORE AGGRESSIVE ENSEMBLING - MEDIUM PRIORITY
**Why:** The CV-LB gap suggests high variance. More bagging should reduce variance.
**How:**
- Increase from 5 to 10+ models
- Use different random seeds
- Consider snapshot ensembling (save models at different epochs)

### 4. HYPERPARAMETER SEARCH - MEDIUM PRIORITY
**Why:** Current architecture may not be optimal.
**What to try:**
- Hidden layers: [512, 256, 128] vs [256, 128, 64]
- Dropout: 0.2, 0.3, 0.4
- Learning rate: 1e-4, 5e-4, 1e-3
- Weight decay: 1e-5, 1e-4, 1e-3

### 5. ACS PCA DESCRIPTORS - LOW PRIORITY
**Why:** Another feature set not yet tried with MLP. Only 5 features.
**How:** Try combining ACS PCA + Spange + Arrhenius

## What NOT to Try
1. **LightGBM/XGBoost** - Already proven worse on LB (0.1065 vs 0.0982)
2. **DRFP with PCA** - Already proven worse on CV (0.017 vs 0.011)
3. **GNN from scratch** - Too complex, requires molecular graph construction
4. **Per-target tree ensembles** - Kernel showed LB 0.11161 (worse than MLP)

## Validation Notes
- **DO NOT trust local CV for model selection** - Use LB submissions for validation
- **Template compliance is CRITICAL** - Last 3 cells must match template exactly
- **MLP is the baseline to beat** - Any new approach must beat LB 0.0982

## Competition Template Requirements
The model class MUST implement:
- `train_model(X_train, Y_train)` - Training method
- `predict(X_test)` - Returns predictions (numpy array or tensor)

The last 3 cells must be EXACTLY as in the template:
1. Single solvent CV loop with `model = YourModel()`
2. Full data CV loop with `model = YourModel(data='full')`
3. Submission file creation

## Target Path
- Current best LB: 0.0982
- Target: 0.0333
- GNN benchmark: 0.0039

**Path to beating target:**
1. Validate exp_003 on LB (this submission)
2. If LB improves, iterate on combined features with task-specific optimization
3. If LB doesn't improve, focus on reducing variance (more ensembling, regularization)
4. The bottleneck is likely the CV-LB gap, not the features

## Next Experiment Specification
**SUBMIT exp_003 to Kaggle for LB validation**

If LB validates the improvement, next experiment should be:
**Task-specific features:**
- Single solvent: Spange + Arrhenius (13 + 5 = 18 features)
- Full data: Spange + DRFP (high-variance) + Arrhenius (13 + 122 + 5 = 140 features)
- Same MLP architecture with appropriate regularization for each task
