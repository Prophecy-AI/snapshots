{
  "query": "What are the best machine learning techniques for predicting chemical reaction yields?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Predicting the yield of a chemical reaction is now treated as a supervised regression problem that can be tackled with a variety of modern machine\u2011learning models.  The most successful approaches combine rich, text\u2011based representations of the reaction (e.g., reaction SMILES) with deep\u2011learning architectures originally developed for natural\u2011language processing.  Encoder\u2011transformer models that treat the whole reaction string as a \u201csentence\u201d and attach a regression head have shown \u201coutstanding\u201d performance on high\u2011throughput experiment datasets, often surpassing traditional fingerprint\u2011based methods that rely on one\u2011hot encodings or concatenated molecular descriptors\u202f([research.ibm.com](https://research.ibm.com/publications/prediction-of-chemical-reaction-yields-using-deep-learning))\u202f([rxn4chemistry.github.io](https://rxn4chemistry.github.io/rxn_yields)).  Variants of the Molecular Transformer, fine\u2011tuned on yield data, are now a standard baseline for yield prediction.\n\nWhen only a few hundred measured reactions are available, hybrid models that blend mechanistic calculations with machine learning are preferred.  A Gaussian Process Regression (GPR) model trained on experimental kinetic data can reproduce activation barriers with sub\u2011kcal\u202fmol\u207b\u00b9 error and, when coupled to transition\u2011state calculations, yields accurate yield estimates together with calibrated uncertainty intervals\u202f([pubs.rsc.org](https://pubs.rsc.org/en/content/articlepdf/2021/sc/d0sc04896h)).  More recently, Deep Kernel Learning\u2014combining neural feature extractors with a Gaussian\u2011process kernel\u2014has been applied to both outcome prediction and reaction\u2011condition optimization, delivering high accuracy while preserving the ability to quantify prediction confidence\u202f([nature.com](https://www.nature.com/articles/s42004-024-01219-x)).\n\nIn practice, the \u201cbest\u201d technique depends on data volume and the desired trade\u2011off between raw predictive power and interpretability.  For large, publicly available datasets (e.g., USPTO or high\u2011throughput screens), transformer\u2011based regression models are currently state\u2011of\u2011the\u2011art.  For low\u2011data regimes or when mechanistic insight is crucial, hybrid GPR or deep\u2011kernel approaches provide superior accuracy and reliable uncertainty estimates.",
      "url": ""
    },
    {
      "title": "Machine learning meets mechanistic modelling for accurate prediction of experimental activation energies",
      "text": "Kjell Jorner \nEarly Chemical Development\nPharmaceutical Sciences\nR&D, AstraZeneca\nMacclesfieldUnited Kingdom\n\nTore Brinck \nApplied Physical Chemistry\nDepartment of Chemistry\nCBH\nKTH Royal Institute of Technology\nStockholmSweden\n\nPer-Ola Norrby \nData Science & Modelling\nPharmaceutical Sciences\nR&D, AstraZeneca\nGothenburgSweden\n\nDavid Buttar \nEarly Chemical Development\nPharmaceutical Sciences\nR&D, AstraZeneca\nMacclesfieldUnited Kingdom\n\nMachine learning meets mechanistic modelling for accurate prediction of experimental activation energies\n1\nAccurate prediction of chemical reactions in solution is challenging for current state-of-the-art approaches based on transition state modelling with density functional theory. Models based on machine learning have emerged as a promising alternative to address these problems, but these models currently lack the precision to give crucial information on the magnitude of barrier heights, influence of solvents and catalysts and extent of regio-and chemoselectivity. Here, we construct hybrid models which combine the traditional transition state modelling and machine learning to accurately predict reaction barriers. We train a Gaussian Process Regression model to reproduce high-quality experimental kinetic data for the nucleophilic aromatic substitution reaction and use it to predict barriers with a mean absolute error of 0.77 kcal/mol for an external test set. The model was further validated on regio-and chemoselectivity prediction on patent reaction data and achieved a competitive top-1 accuracy of 86%, despite not being trained explicitly for this task. Importantly, the model gives error bars for its predictions that can be used for risk assessment by the end user. Hybrid models emerge as the preferred alternative for accurate reaction prediction in the very common low-data situation where only 100-150 rate constants are available for a reaction class. With recent advances in deep learning for quickly predicting barriers and transition state geometries from density functional theory, we envision that hybrid models will soon become a standard alternative to complement current machine learning approaches based on ground-state physical organic descriptors or structural information such as molecular graphs or fingerprints.\n\nIntroduction\n\nAccurate prediction of chemical reactions is an important goal both in academic and industrial research. [1][2][3] Recently, machine learning approaches have had tremendous success in quantitative prediction of reaction yields based on data from high-throughput experimentation 4,5 and enantioselectivities based on carefully selected universal training sets. 6 At the same time, traditional quantitative structure-reactivity relationship (QSRR) methods based on linear regression have seen a renaissance with interpretable, holistic models that can generalize across reaction types. 7 In parallel with these developments of quantitative prediction methods, deep learning models trained on reaction databases containing millions of patent and literature data have made quick qualitative yes/no feasibility prediction routine for almost any reaction type. 8 In the pharmaceutical industry, prediction tools have great potential to accelerate synthesis of prospective drugs (Figure 1a). 9 Quick prediction is essential in the discovery phase, especially within the context of automation and rapid synthesis of a multitude of candidates for initial activity screening. 3,10,11 In these circumstances, a simple yes/no as provided by classification models is usually sufficient. More accurate prediction is necessary in the later drug development process, where the synthesis route and formulation of one or a few promising drug candidates is optimized. Here, regression models that give the reaction activation energy can be used to predict both absolute reactivity and selectivity (Figure 1b). Prediction of absolute reactivity can be used to assess feasibility under process-relevant conditions, while prediction of selectivity is key to reducing purification steps. Predictive tools therefore hold great promise for accelerating route and process development, ultimately delivering medicines to patients both faster and at lower costs. The current workhorse for prediction of organic reactions is density functional theory (DFT, Figure 2a). Since rising to prominence in the early 90s, DFT has enjoyed extraordinary success in rationalizing reactivity and selectivity across the reaction spectrum by modelling the full reaction mechanism. 12 The success of DFT can be traced in part due to a fortuitous cancellation of errors, which makes it particularly suited for properties such as enantioselectivity, which depends on the relative energies of two structurally very similar transition states (TSs). However, this cancellation of errors does not generally extend to the prediction of the absolute magnitude of reactions barriers (activation free energies, \u0394G \u2021 ). In particular, DFT struggles with one very important class of reactions: ionic reactions in solution. Plata and Singleton even suggested that computed mechanisms of this type can be so flawed that they are \"not even wrong\". 13 Similarly, Maseras and co-workers only achieved agreement with experiment for the simple condensation of an imine and an aldehyde in water by introducing an ad-hoc correction factor, even when using more accurate methods than DFT. 14 These results point to the fact that the largest error in the DFT simulations is often due to the poor performance of the solvation model. Machine learning represents a potential solution to the problems of DFT. Based on reaction data in different solvents, machine learning models could in principle learn to compensate for both the deficiencies in the DFT energies and the solvation model. Accurate QSRR machine learning models ( Figure 2b) have been constructed for, e.g., cycloaddition, 15,16 SN2 substitution, 17 and E2 elimination. 18 While these models are highly encouraging, they treat simple reactions that occur in a single mechanistic step and they are based on an amount of kinetic data (>500 samples) that is only available for very few reaction classes. It is also not clear how they would incorporate the effects of more complex reaction conditions, such as the use of catalysts or reagents. Another promising line of research uses machine learning to predict DFT barrier heights and then use these barrier heights to predict experimental outcomes. A recent study from Hong and co-workers used the ratio of predicted DFT barriers to predict regioselectivity in radical C\u2212H functionalization reactions. 19 While these models can show good performance, the predicted barriers still suffer from the shortcomings of the underlying DFT method and solvation model. We therefore believe that for models to be broadly applicable in guiding experiments, they should be trained to reproduce experimental rather than computed barrier heights. Based on the recent success of machine learning for modelling reaction barriers, we wondered if we could combine the traditional mechanistic modelling using DFT with machine learning in a hybrid method (Figure 2d). Machine learning would here be used to correct for the deficiencies in the mechanistic modelling. Hybrid models could potentially reach useful chemical accuracy (error below 1 kcal/mol) 20,21 with fewer training data than QSRR models, be able to treat more complicated multi-step reactions, and naturally incorporate the effect of catalysts directly in the DFT calculations. Mechanistic models are also chemically understandable and the results can be presented to the chemist with both a view of the computed mechanism and a value for the associated barrier. As a prototype application for a hybrid model, we study the nucleophilic aromatic substitution (SNAr) reaction (Figure 1c), one of the most important reactions in chemistry in general and the pharmaceutical chemistry in particular. The SNAr rea...",
      "url": "https://pubs.rsc.org/en/content/articlepdf/2021/sc/d0sc04896h"
    },
    {
      "title": "Prediction of chemical reaction yields using deep learning for Machine Learning: Science and Tech.",
      "text": "## Abstract\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, have successfully become part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the data set applicability in reaction yields predictions.\n## Related\nPaper\n### [Transfer learning enables the molecular transformer to predict regio- and stereoselective reactions on carbohydrates](https://research.ibm.com/publications/transfer-learning-enables-the-molecular-transformer-to-predict-regio-and-stereoselective-reactions-on-carbohydrates)\nPaper\n### [Comparison of computational methods for the electrochemical stability window of solid-state electrolyte materials](https://research.ibm.com/publications/comparison-of-computational-methods-for-the-electrochemical-stability-window-of-solid-state-electrolyte-materials)\nPoster\n### [Molecular transformer-aided biocatalysed synthesis planning](https://research.ibm.com/publications/molecular-transformer-aided-biocatalysed-synthesis-planning)\nShort paper\n### [Simulating fluid flow at pore scale with carbon dioxide in digital rock](https://research.ibm.com/publications/simulating-fluid-flow-at-pore-scale-with-carbon-dioxide-in-digital-rock)\n[View all publications](https://research.ibm.com/publications)",
      "url": "https://research.ibm.com/publications/prediction-of-chemical-reaction-yields-using-deep-learning"
    },
    {
      "title": "Predicting Chemical Reaction Yields",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "Deep Kernel learning for reaction outcome prediction and optimization",
      "text": "Deep Kernel learning for reaction outcome prediction and optimization | Communications Chemistry\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Communications Chemistry](https://media.springernature.com/full/nature-cms/uploads/product/commschem/header-3dc28429486e0d2c8f49fd9baf5afa40.svg)](https://www.nature.com/commschem)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s42004-024-01219-x?error=cookies_not_supported&code=339c684d-2df4-42bb-a10b-c18beba44b3d)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;42004)\n* [RSS feed](https://www.nature.com/commschem.rss)\nDeep Kernel learning for reaction outcome prediction and optimization\n[Download PDF](https://www.nature.com/articles/s42004-024-01219-x.pdf)\n[Download PDF](https://www.nature.com/articles/s42004-024-01219-x.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:14 June 2024# Deep Kernel learning for reaction outcome prediction and optimization\n* [Sukriti Singh](#auth-Sukriti-Singh-Aff1)[ORCID:orcid.org/0000-0003-2286-2974](https://orcid.org/0000-0003-2286-2974)[1](#Aff1)&amp;\n* [Jos\u00e9 Miguel Hern\u00e1ndez-Lobato](#auth-Jos__Miguel-Hern_ndez_Lobato-Aff1)[ORCID:orcid.org/0000-0001-7610-949X](https://orcid.org/0000-0001-7610-949X)[1](#Aff1)\n[*Communications Chemistry*](https://www.nature.com/commschem)**volume7**, Article\u00a0number:136(2024)[Cite this article](#citeas)\n* 7809Accesses\n* 14Citations\n* 8Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s42004-024-01219-x/metrics)\n### Subjects\n* [Catalysis](https://www.nature.com/subjects/catalysis)\n* [Computational chemistry](https://www.nature.com/subjects/computational-chemistry)\n* [Method development](https://www.nature.com/subjects/method-development)\n* [Synthetic chemistry methodology](https://www.nature.com/subjects/methodology)\n* [Structure prediction](https://www.nature.com/subjects/structure-prediction)\n## Abstract\nRecent years have seen a rapid growth in the application of various machine learning methods for reaction outcome prediction. Deep learning models have gained popularity due to their ability to learn representations directly from the molecular structure. Gaussian processes (GPs), on the other hand, provide reliable uncertainty estimates but are unable to learn representations from the data. We combine the feature learning ability of neural networks (NNs) with uncertainty quantification of GPs in a deep kernel learning (DKL) framework to predict the reaction outcome. The DKL model is observed to obtain very good predictive performance across different input representations. It significantly outperforms standard GPs and provides comparable performance to graph neural networks, but with uncertainty estimation. Additionally, the uncertainty estimates on predictions provided by the DKL model facilitated its incorporation as a surrogate model for Bayesian optimization (BO). The proposed method, therefore, has a great potential towards accelerating reaction discovery by integrating accurate predictive models that provide reliable uncertainty estimates with BO.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-00144-6/MediaObjects/41598_2021_144_Fig1_HTML.png)\n### [Deep Bayesian Gaussian processes for uncertainty estimation in electronic health records](https://www.nature.com/articles/s41598-021-00144-6?fromPaywallRec=false)\nArticleOpen access19 October 2021\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-024-57135-6/MediaObjects/41598_2024_57135_Fig1_HTML.png)\n### [Relationship between prediction accuracy and uncertainty in compound potency prediction using deep neural networks and control models](https://www.nature.com/articles/s41598-024-57135-6?fromPaywallRec=false)\nArticleOpen access19 March 2024\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-021-88939-5/MediaObjects/41598_2021_88939_Fig1_HTML.png)\n### [GPCR\\_LigandClassify.py; a rigorous machine learning classifier for GPCR targeting compounds](https://www.nature.com/articles/s41598-021-88939-5?fromPaywallRec=false)\nArticleOpen access04 May 2021\n## Introduction\nChemical reaction optimization is central to organic synthesis and has largely been based on chemical intuition[1](https://www.nature.com/articles/s42004-024-01219-x#ref-CR1). During optimization, the aim is to maximize the reaction outcome (e.g., yield and/or enantiomeric excess) by identifying suitable experimental conditions[2](https://www.nature.com/articles/s42004-024-01219-x#ref-CR2). This involves evaluating a multidimensional chemical space comprising of reaction variables such as catalyst, solvent, substrate, additive, time, temperature, concentration, etc.[3](https://www.nature.com/articles/s42004-024-01219-x#ref-CR3),[4](https://www.nature.com/articles/s42004-024-01219-x#ref-CR4). Owing to the complexity of this problem, several data-driven approaches have been employed for efficient exploration of the chemical space[5](#ref-CR5),[6](#ref-CR6),[7](https://www.nature.com/articles/s42004-024-01219-x#ref-CR7).\nThe estimation of reaction outcome is of great importance in reaction development. It could enable chemists to identify, for instance, low-yield reactions prior to wet-lab experiments, thereby saving time and resources. Machine learning (ML) has shown an impressive degree of success in many areas of chemistry[8](#ref-CR8),[9](#ref-CR9),[10](#ref-CR10),[11](https://www.nature.com/articles/s42004-024-01219-x#ref-CR11). Earlier efforts toward reaction outcome prediction use hand-crafted features such as physical organic descriptors and molecular fingerprints[12](https://www.nature.com/articles/s42004-024-01219-x#ref-CR12),[13](https://www.nature.com/articles/s42004-024-01219-x#ref-CR13). Conventional ML methods, particularly random forests, perform extremely well with these non-learned representations. Recently, the advances in deep learning (DL) have led to the development of new molecular representations[14](https://www.nature.com/articles/s42004-024-01219-x#ref-CR14). These are learned directly from molecular structures like simplified molecular input line entry specifications (SMILES) and molecular graphs. The chemical language models (LMs) and graph neural networks (GNNs) trained using these string or graph-based representations have displayed great potential in reaction outcome prediction[15](#ref-CR15),[16](#ref-CR16),[17](#ref-CR17),[18](https://www.nature.com/articles/s42004-024-01219-x#ref-CR18).\nThe reaction outcome prediction augmented with uncertainty quantification is expected to find superior utility during reaction optimization[19](https://www.nature.com/articles/s42004-024-01219-x#ref-CR19). As an example, Bayesian optimization (BO) works with the uncertainty estimates to suggest new experiments in a search for optimal reaction conditions[20](https://www.nature.com/articles/s42004-024-01219-x#ref-CR20). While the quantification of uncertainty using the above-mentioned ML methods might not be straightforward, the uncertainty-awareness of Gaussian processes (GPs) is well-known[21](https://www.nature.com/articles/s42004-024-01219-x#ref-CR21),[22](https://www.nature.com/articles/s42004-024-01219-x#ref-CR22). G...",
      "url": "https://www.nature.com/articles/s42004-024-01219-x"
    },
    {
      "title": "Predictive chemistry: machine learning for reaction deployment, reaction development, and reaction discovery",
      "text": "Zhengkai Tu \nThijs Stuyver \nConnor W Coley \nPredictive chemistry: machine learning for reaction deployment, reaction development, and reaction discovery\n10.1039/d2sc05089g\nThe field of predictive chemistry relates to the development of models able to describe how molecules interact and react. It encompasses the long-standing task of computer-aided retrosynthesis, but is far more reaching and ambitious in its goals. In this review, we summarize several areas where predictive chemistry models hold the potential to accelerate the deployment, development, and discovery of organic reactions and advance synthetic chemistry.Fig. 2Overview of five key reaction deployment tasks. Reaction outcome prediction aims to predict the major product given the reactants. One-step retrosynthesis is the reverse task of proposing reaction precursors for new targets. The one-step models are called at each step of multi-step planning, which aims to propose synthesis routes that end in commercially/experimentally accessible building blocks. Atom mapping aligns the atoms on both sides of a reaction, and reaction classification maps reactions into distinct (human-interpretable) classes, both of which are complementary to the core synthesis planning workflow. Fig. 5 Systematic design of a substrate scope promoting diversity in descriptor space. Reproduced with permission from Kariofillis et al. 164\n\nIntroduction\n\nAdvances in the high-throughput generation and availability of chemical reaction data have spurred a rapidly growing interest in the intersection of machine learning and chemical synthesis. [1][2][3][4] Deep learning approaches have achieved unprecedented accuracy and performance in a wide variety of predictive tasks; their potential to accelerate scienti\ue103c discovery is therefore of immense interest. [5][6][7] Here, we discuss recent advances in the application of machine learning to synthetic chemistry, divided in three categories ( Fig. 1):\n\n(1) Reaction deployment-learning from reaction corpora to identify trends and predict when known reactions apply to novel substrates or combinations thereof.\n\n(2) Reaction development-accelerating the improvement or optimization of an existing chemical process, o\ue09den in an iterative setting incorporating experimental feedback.\n\n(3) Reaction discovery-creating new knowledge through the elucidation of reaction mechanisms or the discovery of unprecedented synthetic methods.\n\nProgress in these areas has bene\ue103ted from a \"virtuous cycle\" between chemistry and computer science experts, where the former identify pressing domain challenges and the latter design new computational tools to tackle them. As new algorithmic methods are developed, intended either for chemical problems or for the more widespread applications of image and language processing, the scope of synthetic problems able to be addressed by computational assistance expands. We encourage all synthetic and computational chemists to familiarize themselves with these Zhengkai Tu received his BASc in Chemical Engineering from University of Waterloo and his SM in Computational Science and Engineering from MIT. He is currently a PhD student in Electrical Engineering and Computer Science at MIT. His research interest is in using machine learning for synthesis planning and for scienti\ue103c information extraction. applications and methods to identify (a) tools that can be directly incorporated into their R&D work\ue104ows, (b) additional applications where similar tools may be impactful, and (c) opportunities for developing novel algorithms.\n\nThis review will highlight progress towards building machine learning models that support synthetic chemistry in each of the areas of reaction deployment, development, and discovery. The progression through these three topics is meant to re\ue104ect an increasing degree of extrapolation from known reactivity to new reactivity. Throughout, we emphasize the major questions that models have been built to address, the myriad of approaches that have been developed to help address them, and some goals where further development is still needed. At times, we will go into some technical depth to describe and distinguish different models built for the same task, but these details may not be relevant for every reader.\n\n\nPreliminaries on machine learning and molecular representation\n\nThere are numerous reviews for machine learning in chemistry that provide an introduction to the \ue103eld. Rather than explaining the basics of statistical learning, we instead redirect the reader to work by Strieth-Kalthoff et al., 3 Butler et al., 8 and Janet and Kulik. 9 Here, we will only brie\ue104y mention a few key considerations in molecular representation and algorithm design.\n\nSupervised learning problems are typically divided into regression and classi\ue103cation tasks, which seek to predict either a continuous scalar value or a discrete category. Both types of problems are ubiquitous in molecular machine learning and drug discovery applications (e.g., in the form of quantitative structure-property relationship models), but cannot describe every task we discuss below. While the learning objective may be to predict reaction yield, rate, enantiomeric excess, etc., some tasks require the prediction/generation of a molecular structure; for example, when predicting the product of a chemical reaction. Nevertheless, the types of tasks we will review are predominantly supervised learning problems wherein we try to recapitulate the relationship between input-output pairs derived from experiments or computational chemistry. When describing a supervised learning problem, it is essential to be precise about which factors should be considered part of the input, which factors are held constant, and which confounding factors are omitted due to missing data.\n\nMolecular representation is perhaps the most fundamental aspect of molecular machine learning. In order for a model to learn the relationship between an input and an output, we must be able to describe the input in some objective, mathematical way. When working with reactions, we must choose how to represent the constituent molecules and other aspects of the reaction conditions. There has been a substantial amount of work on the former from cheminformatics and adjacent \ue103elds. 10 The \ue103rst consideration one makes is whether a molecular structure should be considered a rigid 3D object or a more \ue104exible structure de\ue103ned as a 4D conformer ensemble or a 2D/ 2.5D molecular graph. This choice is in\ue104uenced by the learning problem, i.e., whether the goal is to predict properties of an ensemble of 3D conformers, a speci\ue103c 3D conformer, or the molecular identity. For most learning problems involving experimental reaction data, representing the molecular identity without restricting it to any individual conformation should be appropriate. However, computing properties of 3D conformers Fig. 1 Overview of the three main categories of predictive chemistry tasks discussed throughout this review: reaction deployment, development, and discovery. It is useful to consider the extent to which each task represents an extrapolation from known reactivity to new reactivity. has proven to be an effective way to featurize catalysts and ligands for various learning problems, and 4D conformer ensemble inputs have been demonstrated to yield excellent results for, among others, solvation properties. 11,12 Broadly speaking, molecular representations include structure-based \ue103ngerprints, SMILES strings, 13 2D graphs, and 3D conformations as well as descriptor-based vector representations using computed properties o\ue09den inspired by physical organic chemistry. Descriptors may be directly derived from molecular structure and the two are by no means mutually exclusive. 14 Each of these representations is compatible with a different set of machine learning model architectures (see Fig. 1 of Pattanaik and Coley 15 for an illustration). What is considered \"machine learning\" is ambiguous; multiv...",
      "url": "https://pubs.rsc.org/en/content/articlepdf/2022/SC/D2SC05089G"
    },
    {
      "title": "Predicting Reaction Yields via Supervised Learning",
      "text": "![](https://d.adroll.com/cm/b/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/g/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/index/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/n/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/o/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/outbrain/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/pubmatic/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/r/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/taboola/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/triplelift/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)![](https://d.adroll.com/cm/x/out?adroll_fpc=27796471ba52583f00ea19617bdf55b4-1719909597164&pv=78716895666.00757&arrfrr=https%3A%2F%2Fpubs.acs.org%2Fdoi%2F10.1021%2Facs.accounts.0c00770&advertisable=3LBZJ4KXKBF2PJ46QCMT3X)\n\nRecently Viewed [close modal](javascript:void(0))\n\nRecently Viewed\n\n- [Dispersing Zwitterions into Comb Polymers for Nonviral Transfection: Experiments and Molecular Simulation](https://pubs.acs.org/doi/full/10.1021/acs.biomac.5b01462)\n- [Backgrounds for Liquid Scintillation Counting of Colored Solutions](https://pubs.acs.org/doi/full/10.1021/ac60167a027)\n\nPair your accounts.\n\nExport articles to Mendeley\n\nGet article recommendations from ACS based on references in your Mendeley library.\n\nPair your accounts.\n\nExport articles to Mendeley\n\nGet article recommendations from ACS based on references in your Mendeley library.\n\nYou\u2019ve supercharged your research process with ACS and Mendeley!\n\nContinue\n\n###### STEP 1:\n\nLogin with ACS IDLogged in SuccessClick to create an ACS ID\n\n###### STEP 2:\n\nLogin with MendeleyLogged in Success [Create a Mendeley account](https://id.elsevier.com/as/authorization.oauth2?state=c33c27125763433d4d32a15accaacc18&prompt=login&scope=openid%20email%20profile%20els_auth_info&authType=SINGLE_SIGN_IN&response_type=code&platSite=MDY%2Fmendeley&redirect_uri=https%3A%2F%2Fwww.mendeley.com%2Fcallback%2F&client_id=MENDELEY)\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease note: If you switch to a different device, you may be asked to login again with only your ACS ID.\n\nPlease login with your ACS ID before connecting to your Mendeley account.\n\nLogin with ACS ID\n\nMENDELEY PAIRING EXPIREDReconnect\n\nYour Mendeley pairing has expired. Please reconnect\n\n![Figure 1](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770)![Loading Img](https://pubs.acs.org/specs/products/achs/releasedAssets/images/loading/loading-018624cffd023ad5641b8e99931a80e6.gif)\n\n[Download Hi-Res Image](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770) [Download to MS-PowerPoint](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770) [**Cite This:**](https://pubs.acs.org/action/showCitFormats?doi=10.1021/acs.accounts.0c00770&href=/doi/10.1021/acs.accounts.0c00770) _Acc. Chem. Res._ 2021, 54, 8, 1856-1865\n\n[ADVERTISEMENT](http://acsmediakit.org)\n\n[RETURN TO ISSUE](https://pubs.acs.org/toc/achre4/54/8) [PREV](https://pubs.acs.org/doi/10.1021/acs.accounts.1c00019) Article [NEXT](https://pubs.acs.org/doi/10.1021/acs.accounts.1c00007)\n\n[![Journal Logo](https://pubs.acs.org/doi/10.1021/specs/products/achs/releasedAssets/images/loading/loader-128b5db1cc3a83761a15cf2e5c9b452d.gif)](https://pubs.acs.org/journal/achre4)\n\n[Get e-Alerts](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770) close\n\n# Predicting Reaction Yields via Supervised Learning\n\n- Andrzej M. \u017bura\u0144ski\n\n\n\n\nAndrzej M. \u017bura\u0144ski\n\n\n\n\n\nDepartment of Chemistry, Princeton University, Princeton, New Jersey 08544, United States\n\n\n\n\n\nMore by [Andrzej M. \u017bura\u0144ski](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Andrzej+M.++%C5%BBura%C5%84ski)\n\n\n\n[View Biography](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770#ath1)\n\n- ,\n- Jesus I. Martinez Alvarado\n\n\n\n\nJesus I. Martinez Alvarado\n\n\n\n\n\nDepartment of Chemistry, Princeton University, Princeton, New Jersey 08544, United States\n\n\n\n\n\nMore by [Jesus I. Martinez Alvarado](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Jesus+I.++Martinez+Alvarado)\n\n\n\n[View Biography](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770#ath2)\n\n- ,\n- Benjamin J. Shields\n\n\n\n\nBenjamin J. Shields\n\n\n\n\n\nDepartment of Chemistry, Princeton University, Princeton, New Jersey 08544, United States\n\n\n\n\n\nMore by [Benjamin J. Shields](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Benjamin+J.++Shields)\n\n\n\n[View Biography](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770#ath3)\n\n- ,\u00a0and\n- Abigail G. Doyle **\\***\n\n\n\n\nAbigail G. Doyle\n\n\n\n\n\nDepartment of Chemistry, Princeton University, Princeton, New Jersey 08544, United States\n\n\n\n**\\*** Email: [agdoyle@princeton.edu](mailto:agdoyle@princeton.edu)\n\nMore by [Abigail G. Doyle](https://pubs.acs.org/action/doSearch?field1=Contrib&text1=Abigail+G.++Doyle)\n\n\n\n[View Biography](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770#ath4)\n\n\n\n![Orcid](https://pubs.acs.org/products/achs/releasedAssets/images/orchid-2856f829046fbda55b90e1582edf0e9a.png)[http://orcid.org/0000-0002-6641-0833](http://orcid.org/0000-0002-6641-0833)\n\n\n[**Cite this:**](https://pubs.acs.org/action/showCitFormats?doi=10.1021%2Facs.accounts.0c00770&href=/doi/10.1021%2Facs.accounts.0c00770) _Acc. Chem. Res._2021, 54, 8, 1856\u20131865\n\nPublication Date (Web):March 31, 2021\n\n#### Publication History\n\n- **Received**18 November 2020\n- **Published** online31 March 2021\n- **Published** inissue 20 April 2021\n\n[https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770](https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770)\n\n[https://doi.org/10.1021/acs.accounts.0c00770](https://doi.org/10.1021/acs.accounts.0c00770)\n\nresearch-article\n\nACS Publications\n\n**Copyright \u00a9 2021 American Chemical Society**\n\n[Request reuse permissions](https://pubs.acs.org/servlet/linkout?type=rightslink&url=startPage%3D1856%26pageCount%3D10%26copyright%3DAmerican%2BChemical%2BSociety%26author%3DAndrzej%2BM.%2B%25C5%25BBura%25C5%2584ski%252C%2BJesus%2BI.%2BMartinez%2BAlvarado%252C%2BBenjamin%2BJ.%2BShields%252C%2Bet%2Bal%26orderBeanReset%3Dtrue%26imprint%3DAmerican%2BChemical%2BSociety%26volumeNum%3D54%26issueNum%3D8%26contentID%3Dacs.accounts.0c00770%26title%3DPredicting%2BReaction%2BYields%2Bvia%2BSupervised...",
      "url": "https://pubs.acs.org/doi/10.1021/acs.accounts.0c00770"
    },
    {
      "title": "Prediction of Chemical Reaction Yields using Deep Learning",
      "text": "We use cookies to distinguish you from other users and to provide you with a better experience on our websites.Close this message to accept cookies or find out how to manage your cookie settings. [Learn more about our Privacy Notice...\\\n\\[opens in a new tab\\]](https://www.cambridge.org/about-us/legal-notices/privacy-notice/)\n\n[Back to\\\nTheoretical and Computational Chemistry](https://chemrxiv.org/engage/chemrxiv/category-dashboard/605c72ef153207001f6470ce)\n\nSearch within Theoretical and Computational Chemistry\n\n![RSS feed for Theoretical and Computational Chemistry](https://chemrxiv.org/engage/assets/public/chemrxiv/social/rss.svg)\n\n# Prediction of Chemical Reaction Yields using Deep Learning\n\n12 October 2020, Version 2\n\nWorking Paper\n\n## Authors\n\n- [Philippe Schwaller](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Philippe%20Schwaller)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-3046-6576),\n- [Alain C. Vaucher](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Alain%20C.%20Vaucher)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0001-7554-0288),\n- [Teodoro Laino](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Teodoro%20Laino),\n- [Jean-Louis Reymond](https://chemrxiv.org/engage/chemrxiv/search-dashboard?authors=Jean-Louis%20Reymond)[![Author ORCID: We display the ORCID iD icon alongside authors names on our website to acknowledge that the ORCiD has been authenticated when entered by the user. To view the users ORCiD record click the icon. [opens in a new tab]](https://chemrxiv.org/engage/assets/public/chemrxiv/images/logos/orcid.png)](https://orcid.org/0000-0003-2724-2942)\n\n[Show author details](https://chemrxiv.org/engage/chemrxiv/article-details/60c750f2ee301c70b1c7a973)\n\n![](https://chemrxiv.org/engage/_nuxt/img/NonPeerReviewed.5753084.svg)This content is a preprint and has not undergone peer review at the time of posting.\n\nDownload\n\nCite\n\nComment\n\n## Abstract\n\nArtificial intelligence is driving one of the most important revolutions in organic chemistry.\n\nMultiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists' daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\n\n## Keywords\n\n[SMILES-Encoded Molecular Structures](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES-Encoded%20Molecular%20Structures)\n\n[SMILES](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=SMILES)\n\n[BERT](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=BERT)\n\n[Regression](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Regression)\n\n[Yields](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Yields)\n\n[Deep Learning](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Deep%20Learning)\n\n[Chemical Reactions](https://chemrxiv.org/engage/chemrxiv/search-dashboard?keywords=Chemical%20Reactions)\n\n## Supplementary weblinks\n\n**Title**\n\n**Description**\n\n**Actions**\n\n**Title**\n\n![](https://chemrxiv.org/engage/_nuxt/img/Weblink.b642c15.svg)\n\n**Description**\n\n**Actions**\n\n[**View**](https://rxn4chemistry.github.io/rxn_yields/)\n\n## Comments\n\nYou are signed in as . Your name will appear\nwith any comment you post.\n\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our\n[Commenting Policy\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)\n\\- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can\n[find more information about how to use the commenting feature here\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs)\n.\n\n\u200b\n\n300 words allowed\n\nYou can enter up to 300 words.\nPost comment\n\nLog in or register with\nORCID to comment\n\nComments are not moderated before they are posted, but they can be removed\nby the site moderators if they are found to be in contravention of our\n[Commenting Policy\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/about-information?show=commenting-policy)\n\\- please read this policy before you post. Comments should be used for\nscholarly discussion of the content in question. You can\n[find more information about how to use the commenting feature here\\\n\\[opens in a new tab\\]](https://chemrxiv.org/engage/chemrxiv/contact-information?show=faqs)\n.\n\nThis site is protected by reCAPTCHA and the Google\n[Privacy Policy\\\n\\[opens in a new tab\\]](https://policies.google.com/privacy)\nand\n[Terms of Service\\\n\\[opens in a new tab\\]](https://policies.google.com/terms)\napply.\n\n## Now Published\n\n[**Prediction of chemical reaction yields using deep learning**\\[opens in a new tab\\]](https://doi.org/10.1088/2632-2153/abc81d)\n\nPhilippe Schwaller, Alain C Vaucher, Teodoro Laino, Jean-Louis Reymondjournal article\n\n_Machine Learning: Science and Technology_, Volume 2, Issue 1\n\nOnline publication date: Mar 31, 2021\n\n## Version History\n\nOct 12, 2020 Version 2\n\n[Aug 05, 2020 Version\\\n1](https://chemrxiv.org/engage/chemrxiv/article-details/60c750b10f50db65cc3975e7)\n\n## Metrics\n\n10,348\n\n3,785\n\n2\n\nViews\n\nDownloads\n\nView article\nCitations\n\n## License\n\n![CC logo](https://chemrxiv.org/engage/_nuxt/img/cc.e3defa7.svg)\n\nCC\n\n![BY logo](https://chemrxiv.org/engage/_nuxt/img/by.7813b57.svg)\n\nBY\n\n![NC logo](https://chemrxiv.org/engage/_nuxt/img/nc.e378f90.svg)\n\nNC\n\n![ND logo](https://chemrxiv.org/engage/_nuxt/img/nd.7966b83.svg)\n\nND\n\nThe content is available under\n[CC BY NC ND 4.0\\[opens in a new tab\\]](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n## DOI\n\n[10.26434/chemrxiv.12758474.v2\\\nD O I: 10.26434/chemrxiv.12758474.v2 \\[opens in a new tab\\]](https://doi.org/10.26434/chemrxiv.12758474.v2)\n\n## Author\u2019s competing interest statement\n\nNo conflict of interest.\n\n## Share",
      "url": "https://chemrxiv.org/engage/chemrxiv/article-details/60c750f2ee301c70b1c7a973"
    },
    {
      "title": "\ud835\uddc5\ud835\uddc8\ud835\uddc0 \u2062 - \u2062 \ud835\uddb1\ud835\uddb1\ud835\udda8\ud835\uddac \ud835\uddc5\ud835\uddc8\ud835\uddc0 - \ud835\uddb1\ud835\uddb1\ud835\udda8\ud835\uddac \\mathop{\\mathsf{log\\text{-}RRIM}}\\limits sansserif_log - sansserif_RRIM : Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
      "text": "[We gratefully acknowledge support from\\\nthe Simons Foundation and member institutions.](https://confluence.cornell.edu/x/ALlRF)",
      "url": "https://arxiv.org/html/2411.03320v3"
    }
  ]
}