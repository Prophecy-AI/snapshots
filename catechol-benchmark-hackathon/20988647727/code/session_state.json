{
  "workspace_dir": "/home/code",
  "competition_id": "catechol-benchmark-hackathon",
  "metric_direction": true,
  "start_time": "2026-01-14T09:17:13.972797",
  "time_limit_minutes": 2100,
  "experiments": [],
  "candidates": [],
  "submissions": [],
  "strategy_history": [],
  "feedback_history": [],
  "data_findings": [
    {
      "finding": "Arrhenius kinetics feature engineering: Use 1/Temperature (in Kelvin), ln(Time), and their interaction as features. This is physics-informed and improves predictions.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Test Time Augmentation (TTA) for chemical symmetry: For mixed solvents, predict twice - once with (A,B) and once with (B,A) flipped - then average. This respects physical symmetry of mixtures.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Spange descriptors provide best base for linear mixing of solvents. Use linear interpolation: A*(1-pct) + B*pct for mixed solvent features.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Model bagging with 7 models improves robustness. Use HuberLoss for robustness to outliers. MLP architecture: BatchNorm -> Linear(128) -> ReLU -> Dropout(0.2) repeated, ending with Sigmoid.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Numeric feature engineering: rt, temp, rt^2, temp^2, log1p(rt), log1p(temp), rt*temp. Use StandardScaler on all features.",
      "source": "../research/kernels/paritoshtripathi5_alchemy-baseline/alchemy-baseline.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "CV structure: Task 0 = single solvent (leave-one-solvent-out), Task 1 = full data with mixtures (leave-one-ramp-out). Target columns are Product 2, Product 3, SM (yields 0-1).",
      "source": "../research/kernels/josepablofolch_catechol-benchmark-hackathon-template/catechol-benchmark-hackathon-template.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "XGBoost approach: Feature engineering with Reaction_Energy = Temperature * Residence Time, B_Conc_Temp = SolventB% * Temperature. Post-processing: clip to [0,1] and normalize rows to sum to 1.",
      "source": "../research/kernels/mr0106_catechol/catechol.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Available solvent featurizations: spange_descriptors (best for linear mixing), acs_pca_descriptors, drfps_catechol, fragprints. Spange descriptors are most commonly used in top solutions.",
      "source": "../research/description.md",
      "agent": "explorer"
    }
  ],
  "web_research": [
    {
      "query": "What are the best machine learning techniques for predicting chemical reaction yields?",
      "finding": "Predicting the yield of a chemical reaction is now treated as a supervised regression problem that can be tackled with a variety of modern machine\u2011learning models.  The most successful approaches combine rich, text\u2011based representations of the reaction (e.g., reaction SMILES) with deep\u2011learning architectures originally developed for natural\u2011language processing.  Encoder\u2011transformer models that treat the whole reaction string as a \u201csentence\u201d and attach a regression head have shown \u201coutstanding\u201d performance on high\u2011throughput experiment datasets, often surpassing traditional fingerprint\u2011based methods that rely on one\u2011hot encodings or concatenated molecular descriptors\u202f([research.ibm.com](https://research.ibm.com/publications/prediction-of-chemical-reaction-yields-using-deep-learning))\u202f([rxn4chemistry.github.io](https://rxn4chemistry.github.io/rxn_yields)).  Variants of the Molecular Transformer, fine\u2011tuned on yield data, are now a standard baseline for yield prediction.\n\nWhen only a few ",
      "agent": "explorer"
    }
  ],
  "max_submissions": 5,
  "remaining_submissions": 0
}