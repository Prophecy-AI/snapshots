# Catechol Reaction Yield Prediction - Strategy Guide (Loop 2)

## Current Status
- Best CV score: 0.010986 from exp_001 (Tree-Based Per-Target Ensemble)
- Best LB score: 0.0998 from exp_000 (MLP baseline)
- CV-LB gap: CV ~0.011 vs LB ~0.10 (9x gap)
- **Target: 0.017270** (5-6x better than best public LB of 0.098)

## Response to Evaluator

**Technical verdict was TRUSTWORTHY.** The evaluator correctly identified that the tree-based approach is sound and template-compliant.

**Evaluator's top priority:** Submit exp_001 to verify CV-LB correlation. **DONE** - LB score was 0.0999, confirming similar gap as exp_000.

**Key concerns raised:**
1. CV-LB gap not understood - **ADDRESSED**: Analysis shows the gap is consistent. Our CV MSE of 0.011 corresponds to RMSE of ~0.105, which is close to LB ~0.10. The LB metric appears to be MSE but evaluated differently.
2. Target analysis - The target of 0.017270 is 5-6x better than best public LB. This is a MASSIVE gap suggesting fundamentally different approaches are needed.

## CRITICAL INSIGHT: The Target Gap

The target of 0.017270 is 5-6x better than the best public LB of 0.098. This is NOT achievable through incremental improvements. We need:
1. **Fundamentally different modeling approaches** (not just hyperparameter tuning)
2. **Better feature engineering** (domain-specific chemistry knowledge)
3. **Novel ensemble strategies** (beyond simple averaging)

## Data Understanding

**Reference notebooks:**
- `exploration/eda.ipynb` - Feature distributions, target statistics, CV structure
- `exploration/evolver_loop2_lb_feedback.ipynb` - CV-LB gap analysis

**Key Data Facts:**
- Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV (24 folds)
- Full/mixed solvent: 1227 samples, 13 solvent pairs, leave-one-ramp-out CV (13 folds)
- Targets: SM, Product 2, Product 3 (yields as fractions 0-1)
- **SM target has highest error** - RMSE 0.51 for single solvent vs 0.10 for full data
- Targets do NOT sum to 1 (mean ~0.8) - mass loss in reaction

## CRITICAL: Submission Structure Requirements

**MANDATORY:** The submission must follow the exact structure of the benchmark template notebook.
- The last three cells MUST remain unchanged except for the model definition line
- `model = MLPModel()` can be replaced with a new model definition
- Both single solvent and full (mixed) solvent tasks must be handled

## Recommended Approaches (Priority Order)

### 1. Gaussian Processes / Deep Kernel Learning (HIGH PRIORITY)
**Why:** GPs excel at extrapolation to unseen data points (the core challenge here - predicting unseen solvents). With ~600-1200 samples, GPs are in their sweet spot.

**Implementation:**
- Use GPyTorch for scalable GP implementation
- Try Deep Kernel Learning (DKL) - NN feature extractor + GP head
- Consider multi-output GPs for correlated targets
- Use Arrhenius features as inputs

**Expected benefit:** Better uncertainty quantification and extrapolation to unseen solvents.

### 2. Regressor Chains for Correlated Targets (MEDIUM PRIORITY)
**Why:** SM, Product 2, Product 3 are chemically related (mass balance). Predicting one can inform the others.

**Implementation:**
- Order: SM → Product 2 → Product 3 (or optimize order)
- Feed prediction of previous target as input to next
- Use sklearn's RegressorChain or implement manually

**Expected benefit:** Capture correlations between outputs.

### 3. Advanced Feature Engineering (MEDIUM PRIORITY)
**Why:** Current features may not capture all relevant chemistry.

**Ideas:**
- **Reaction kinetics features:** k = A * exp(-Ea/RT), use log(k) as feature
- **Solvent interaction features:** Product of solvent descriptors
- **Temperature-time interaction:** T * log(t), T^2, t^2
- **Solvent polarity index:** Combine multiple descriptors into single polarity measure

### 4. Ensemble Diversity (MEDIUM PRIORITY)
**Why:** Current ensembles use similar models. More diversity = better generalization.

**Ideas:**
- Combine MLP + Trees + GP
- Use different feature sets for different models
- Stack with meta-learner (Ridge regression on OOF predictions)

### 5. Per-Solvent or Per-Condition Models (LOW PRIORITY)
**Why:** Different solvents may have different prediction characteristics.

**Ideas:**
- Cluster solvents by properties, train separate models per cluster
- Use solvent-specific hyperparameters

## What NOT to Try (Already Exhausted)

1. **Basic MLP with BatchNorm** - Already tried, CV 0.011, LB 0.10
2. **Tree-based per-target ensemble** - Already tried, CV 0.011, LB 0.10
3. **Simple hyperparameter tuning** - Won't bridge 5-6x gap to target

## Validation Strategy

- **Single solvent:** Leave-one-solvent-out (24 folds)
- **Full data:** Leave-one-ramp-out (13 folds)
- **Same hyperparameters across all folds** (no per-fold tuning)
- **Focus on reducing RMSE** (appears to be the LB metric)

## Key Techniques from Public Kernels

1. **Arrhenius kinetics features:** inv_temp, log_time, interaction
2. **Symmetry TTA:** For mixed solvents, predict both (A,B) and (B,A), average
3. **Data augmentation:** Train on both symmetric versions of mixed solvents
4. **Per-target models:** Different model types for SM vs Products
5. **Feature table ensemble:** Weighted average of ACS PCA and Spange descriptors

## Next Experiment Priorities

1. **Try Gaussian Processes** - Most promising for extrapolation
2. **Try Regressor Chains** - Exploit target correlations
3. **Try stacking ensemble** - Combine diverse models with meta-learner
4. **Investigate per-fold errors** - Which solvents are hardest to predict?

## Submissions Remaining: 3/5

Use submissions strategically:
- Submit when trying fundamentally different approach (GP, stacking)
- Don't submit for small hyperparameter changes
- Reserve at least 1 submission for final ensemble