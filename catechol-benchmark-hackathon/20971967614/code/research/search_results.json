{
  "query": "What is the catechol_hackathon_metric evaluation metric in Kaggle competition? How is it calculated?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The provided search results do not contain information about the\u202fcatechol_hackathon_metric\u202for how it is calculated. ([kaggle\u2011metrics.readthedocs.io](https://kaggle-metrics.readthedocs.io))",
      "url": ""
    },
    {
      "title": "kaggle-metrics \u00b6",
      "text": "kaggle-metrics &mdash; kaggle-metrics 0.1.0 documentation\n* [Docs](#)&raquo;\n* kaggle-metrics\n* [Edit on GitHub](https://github.com/krzjoa/kaggle-metrics/blob/master/docs/source/index.rst)\n# kaggle-metrics[\u00b6](#kaggle-metrics)\n[![Python version](https://img.shields.io/badge/python-3.7-blue.svg)](https://bace.readthedocs.io/en/latest/?badge=latest)[![PyPI version](https://badge.fury.io/py/kaggle-metrics.svg)](https://badge.fury.io/py/kaggle-metrics)[![Documentation Status](https://readthedocs.org/projects/kaggle-metrics/badge/?version=latest)](https://kaggle-metrics.readthedocs.io/en/latest/?badge=latest)[![Licence](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT))\nMetrics for Kaggle competitions.\n## Installation[\u00b6](#installation)\nYou can install this module directly from GitHub repo with command:\nor as a PyPI package\n## Usage[\u00b6](#usage)\n```\nfromxgboostimportXGBRegressorimportkaggle\\_metricsaskmX\\_train,y\\_train,X\\_test,y\\_test=get\\_data()# Trainclf=XGBRegressor()clf.fit(X\\_train,y\\_train)# Get predictionsy\\_pred=clf.predict(X\\_test)# Evaluate with kaggle-metricskm.rmse(y\\_test,y\\_pred)\n```\nContents:\n* [kaggle-metrics API](api.html)\n* [Classification](api.html#classification)\n* [Regression](api.html#regression)\n* [Order-based](api.html#order-based)\n* [Other](api.html#other)\n* [Index](genindex.html)[Module Index](py-modindex.html)[Search Page](search.html)",
      "url": "https://kaggle-metrics.readthedocs.io"
    },
    {
      "title": "GitHub - krzjoa/kaggle-metrics: Metrics for Kaggle competitions \ud83d\udccf",
      "text": "[Skip to content](https://github.com/krzjoa/kaggle-metrics#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/krzjoa/kaggle-metrics) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/krzjoa/kaggle-metrics) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/krzjoa/kaggle-metrics) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[krzjoa](https://github.com/krzjoa)/ **[kaggle-metrics](https://github.com/krzjoa/kaggle-metrics)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fkrzjoa%2Fkaggle-metrics) You must be signed in to change notification settings\n- [Fork\\\n3](https://github.com/login?return_to=%2Fkrzjoa%2Fkaggle-metrics)\n- [Star\\\n8](https://github.com/login?return_to=%2Fkrzjoa%2Fkaggle-metrics)\n\n\nMetrics for Kaggle competitions \ud83d\udccf\n\n[kaggle-metrics.readthedocs.io](https://kaggle-metrics.readthedocs.io)\n\n[8\\\nstars](https://github.com/krzjoa/kaggle-metrics/stargazers) [3\\\nforks](https://github.com/krzjoa/kaggle-metrics/forks) [Branches](https://github.com/krzjoa/kaggle-metrics/branches) [Tags](https://github.com/krzjoa/kaggle-metrics/tags) [Activity](https://github.com/krzjoa/kaggle-metrics/activity)\n\n[Star](https://github.com/login?return_to=%2Fkrzjoa%2Fkaggle-metrics)\n\n[Notifications](https://github.com/login?return_to=%2Fkrzjoa%2Fkaggle-metrics) You must be signed in to change notification settings\n\n# krzjoa/kaggle-metrics\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmaster\n\n[Branches](https://github.com/krzjoa/kaggle-metrics/branches) [Tags](https://github.com/krzjoa/kaggle-metrics/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[44 Commits](https://github.com/krzjoa/kaggle-metrics/commits/master/) |\n| [docs/source](https://github.com/krzjoa/kaggle-metrics/tree/master/docs/source) | [docs/source](https://github.com/krzjoa/kaggle-metrics/tree/master/docs/source) |  |  |\n| [img](https://github.com/krzjoa/kaggle-metrics/tree/master/img) | [img](https://github.com/krzjoa/kaggle-metrics/tree/master/img) |  |  |\n| [kaggle\\_metrics](https://github.com/krzjoa/kaggle-metrics/tree/master/kaggle_metrics) | [kaggle\\_metrics](https://github.com/krzjoa/kaggle-metrics/tree/master/kaggle_metrics) |  |  |\n| [tests](https://github.com/krzjoa/kaggle-metrics/tree/master/tests) | [tests](https://github.com/krzjoa/kaggle-metrics/tree/master/tests) |  |  |\n| [.gitignore](https://github.com/krzjoa/kaggle-metrics/blob/master/.gitignore) | [.gitignore](https://github.com/krzjoa/kaggle-metrics/blob/master/.gitignore) |  |  |\n| [README.md](https://github.com/krzjoa/kaggle-metrics/blob/master/README.md) | [README.md](https://github.com/krzjoa/kaggle-metrics/blob/master/README.md) |  |  |\n| [requirements.txt](https://github.com/krzjoa/kaggle-metrics/blob/master/requirements.txt) | [requirements.txt](https://github.com/krzjoa/kaggle-metrics/blob/master/requirements.txt) |  |  |\n| [setup.py](https://github.com/krzjoa/kaggle-metrics/blob/master/setup.py) | [setup.py](https://github.com/krzjoa/kaggle-metrics/blob/master/setup.py) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# kaggle-metrics [![](https://raw.githubusercontent.com/krzjoa/kaggle-metrics/master/img/kmlogo.png)](https://raw.githubusercontent.com/krzjoa/kaggle-metrics/master/img/kmlogo.png)\n\n[![Python 3.7](https://camo.githubusercontent.com/95b21c103ef88619e23fd3ffad97d3cb47df959c62d18908ec71c823636e6158/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e372d626c75652e737667)](https://camo.githubusercontent.com/95b21c103ef88619e23fd3ffad97d3cb47df959c62d18908ec71c823636e6158/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e372d626c75652e737667)[![PyPI version](https://camo.githubusercontent.com/cfce36ab367e15c9a92173b375d7a632552fe6538929cd8e21b1bb4f758b9fe9/68747470733a2f2f62616467652e667572792e696f2f70792f6b6167676c652d6d6574726963732e737667)](https://badge.fury.io/py/kaggle-metrics)[![Documentation Status](https://camo.githubusercontent.com/b20d35a29c4cdf619f0ee98f4154dc2c0508554577520cb519c7619e4069d068/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6b6167676c652d6d6574726963732f62616467652f3f76657273696f6e3d6c6174657374)](https://kaggle-metrics.readthedocs.io/en/latest/?badge=latest)[![License: MIT](https://camo.githubusercontent.com/a4426cbe5c21edb002526331c7a8fbfa089e84a550567b02a0d829a98b136ad0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667)](https://opensource.org/licenses/MIT)\n\nMetrics for Kaggle competitions.\n\n## Installation\n\n```\npython3.7 -m pip install git+https://github.com/krzjoa/kaggle-metrics.git\n```\n\nor:\n\n```\npython3.7 -m pip install kaggle_metrics\n```\n\n## Usage\n\n```\nfrom xgboost import XGBRegressor\nimport kaggle_metrics as km\n\nX_train, y_train, X_test, y_test = get_data()\n\n# Train\nclf = XGBRegressor()\nclf.fit(X_train, y_train)\n\n# Get predictions\ny_pred = clf.predict(X_test)\n\n# Evaluate with kaggle-metrics\nkm.rmse(y_test, y_pred)\n\n```\n\n## About\n\nMetrics for Kaggle competitions \ud83d\udccf\n\n[kaggle-metrics.readthedocs.io](https://kaggle-metrics.readthedocs.io)\n\n### Topics\n\n[metrics](https://github.com/topics/metrics) [regression](https://github.com/topics/regression) [kaggle](https://github.com/topics/kaggle) [kaggle-competition](https://github.com/topics/kaggle-competition) [classification](https://github.com/topics/classification)\n\n### Resources\n\n[Readme](https://github.com/krzjoa/kaggle-metrics#readme-ov-file)\n\n[Activity](https://github.com/krzjoa/kaggle-metrics/activity)\n\n### Stars\n\n[**8**\\\nstars](https://github.com/krzjoa/kaggle-metrics/stargazers)\n\n### Watchers\n\n[**3**\\\nwatching](https://github.com/krzjoa/kaggle-metrics/watchers)\n\n### Forks\n\n[**3**\\\nforks](https://github.com/krzjoa/kaggle-metrics/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fkrzjoa%2Fkaggle-metrics&report=krzjoa+%28user%29)\n\n## [Releases](https://github.com/krzjoa/kaggle-metrics/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/krzjoa/packages?repo_name=kaggle-metrics)\n\nNo packages published\n\n## Languages\n\n- [Python100.0%](https://github.com/krzjoa/kaggle-metrics/search?l=python)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/krzjoa/kaggle-metrics"
    },
    {
      "title": "Checking your browser - reCAPTCHA",
      "text": "Checking your browser - reCAPTCHA\nChecking your browser before accessing www.kaggle.com ...\nClick[here](#)if you are not automatically redirected after 5 seconds.",
      "url": "https://www.kaggle.com/docs/competitions-setup"
    },
    {
      "title": "How to use AutoGluon for Kaggle competitions \u00b6",
      "text": "How to use AutoGluon for Kaggle competitions &#8212; AutoGluon Documentation 0.0.15 documentation\n[![AutoGluon Documentation](../../_static/AutogluonLogo.png)](../../index.html)\nTable Of Contents\n[![AutoGluon Documentation](../../_static/AutogluonLogo.png)](../../index.html)\nTable Of Contents\n# How to use AutoGluon for Kaggle competitions[\u00b6](#how-to-use-autogluon-for-kaggle-competitions)\nThis tutorial will teach you how to use AutoGluon to become a serious\nKaggle competitor without writing lots of code. We first outline the\ngeneral steps to use AutoGluon in Kaggle contests. Here, we assume the\ncompetition involves tabular data which are stored in one (or more) CSV\nfiles.\n1. Run Bash command: pip install kaggle\n2. Navigate to:[https://www.kaggle.com/account](https://www.kaggle.com/account)and create an account (if\nnecessary). Then , click on \u201cCreate New API Token\u201d and move\ndownloaded file to this location on your machine:`\\~/.kaggle/kaggle.json`. For troubleshooting, see[Kaggle API\ninstructions](https://www.kaggle.com/docs/api).\n3. To download data programmatically: Execute this Bash command in your\nterminal:\n`kagglecompetitionsdownload-c[COMPETITION]`\nHere, [COMPETITION] should be replaced by the name of the competition\nyou wish to enter. Alternatively, you can download data manually: Just\nnavigate to website of the Kaggle competition you wish to enter, click\n\u201cDownload All\u201d, and accept the competition\u2019s terms.\n1. If the competition\u2019s training data is comprised of multiple CSV\nfiles, use[pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)to properly merge/join them into a single data table where rows =\ntraining examples, columns = features.\n2. Run autogluon`fit()`on the resulting data table.\n3. Load the test dataset from competition (again making the necessary\nmerges/joins to ensure it is in the exact same format as the training\ndata table), and then call autogluon`predict()`. Subsequently use[pandas.read\\_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)to load the competition\u2019s`sample\\_submission.csv`file into a\nDataframe, put the AutoGluon predictions in the right column of this\nDataframe, and finally save it as a CSV\u00a0file via[pandas.to\\_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html).\nIf the competition does not offer a sample submission file, you will\nneed to create the submission file yourself by appropriately\nreformatting AutoGluon\u2019s test predictions.\n4. Submit your predictions via Bash command:\n`kagglecompetitionssubmit-c[COMPETITION]-f[FILE]-m[&quot;MESSAGE&quot;]`\nHere, [COMPETITION] again is the competition\u2019s name, [FILE] is the name\nof the CSV file you created with your predictions, and [\u201cMESSAGE\u201d] is a\nstring message you want to record with this submitted entry.\nAlternatively, you can manually upload your file of predictions on the\ncompetition website.\n1. Finally, navigate to competition leaderboard website to see how well\nyour submission performed! It may take time for your submission to\nappear.\nBelow, we demonstrate how to do steps (4)-(6) in Python for a specific\nKaggle competition:[ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\nThis means you\u2019ll need to run the above steps with`[COMPETITION]`replaced by`ieee-fraud-detection`in each command. Here, we assume\nyou\u2019ve already completed steps (1)-(3) and the data CSV files are\navailable on your computer. To begin step (4), we first load the\ncompetition\u2019s training data into Python:\n```\nimportpandasaspdimportnumpyasnpfromautogluonimportTabularPredictionastaskfromautogluon.utils.tabular.metricsimportroc\\_aucdirectory=&#39;&#39;\\~/IEEEfraud/&#39;&#39;# directory where you have downloaded the data CSV files from the competitionlabel\\_column=&#39;isFraud&#39;# name of target variable to predict in this competitioneval\\_metric=&#39;&#39;roc\\_auc&#39;&#39;# Optional: specify that competition evaluation metric is AUCoutput\\_directory=directory+&#39;AutoGluonModels/&#39;# where to store trained modelstrain\\_identity=pd.read\\_csv(directory+&#39;&#39;train\\_identity.csv&#39;&#39;)train\\_transaction=pd.read\\_csv(directory+&#39;&#39;train\\_transaction.csv&#39;&#39;)\n```\nSince the training data for this competition is comprised of multiple\nCSV files, we just first join them into a single large table (with rows\n= examples, columns = features) before applying AutoGluon:\n```\ntrain=pd.merge(train\\_transaction,train\\_identity,on=&#39;TransactionID&#39;,how=&#39;left&#39;)train\\_data=task.Dataset(df=train)# convert to AutoGluon datasetdeltrain\\_identity,train\\_transaction,train# free unused memory\n```\nNote that a left-join on the`TransactionID`key happened to be most\nappropriate for this Kaggle competition, but for others involving\nmultiple training data files, you will likely need to use a different\njoin strategy (always consider this very carefully). Now that all our\ntraining data resides within a single table, we can apply AutoGluon.\nBelow, we specify the`presets`argument to maximize AutoGluon\u2019s\npredictive accuracy which usually requires that you run`fit()`with\nlonger time limits (3600s below should likely be increased in your run):\n```\npredictor=task.fit(train\\_data=train\\_data,label=label\\_column,output\\_directory=output\\_directory,eval\\_metric=eval\\_metric,presets=&#39;&#39;best\\_quality&#39;&#39;,verbosity=3,time\\_limits=3600)results=predictor.fit\\_summary()\n```\nNow, we use the trained AutoGluon Predictor to make predictions on the\ncompetition\u2019s test data. It is imperative that multiple test data files\nare joined together in the exact same manner as the training data.\nBecause this competition is evaluated based on the AUC (Area under the\nROC curve) metric, we ask AutoGluon for predicted class-probabilities\nrather than class predictions. In general, when to use`predict`vs`predict\\_proba`will depend on the particular competition.\n```\ntest\\_identity=pd.read\\_csv(directory+&#39;&#39;test\\_identity.csv&#39;&#39;)test\\_transaction=pd.read\\_csv(directory+&#39;&#39;test\\_transaction.csv&#39;&#39;)test=pd.merge(test\\_transaction,test\\_identity,on=&#39;TransactionID&#39;,how=&#39;left&#39;)# same join applied to training filestest\\_data=task.Dataset(df=test)# convert to AutoGluon datasetdeltest\\_identity,test\\_transaction,test# free unused memoryy\\_predproba=predictor.predict\\_proba(test\\_data)print(y\\_predproba[:5])# some example predicted fraud-probabilities\n```\nWhen submitting predicted probabilities for classification competitions,\nit is imperative these correspond to the same class expected by Kaggle.\nFor binary classification tasks, you can see which class AutoGluon\u2019s\npredicted probabilities correspond to via:\n```\npositive\\_class=[labelforlabelinpredictor.class\\_labelsifpredictor.class\\_labels\\_internal\\_map[label]==1][0]\n```\nFor multiclass classification tasks, you can see which classes\nAutoGluon\u2019s predicted probabilities correspond to via:\n```\npredictor.class\\_labels# classes in this list correspond to columns of predict\\_proba() output\n```\nAlternatively, the following command should clarify which\npredicted-probability corresponds to which class:\n```\ny\\_predproba=predictor.predict\\_proba(test\\_data,as\\_pandas=True)\n```\nNow that we have made a prediction for each row in the test dataset, we\ncan submit these predictions to Kaggle. Most Kaggle competitions provide\na sample submission file, in which you can simply overwrite the sample\npredictions with your own as we do below:\n```\nsubmission=pd.read\\_csv(directory+&#39;&#39;sample\\_submission.csv&#39;&#39;)submission[&#39;isFraud&#39;]=y\\_predprobasubmission.head()submission.to\\_csv(directory+&#39;&#39;my\\_submission.csv&#39;&#39;,index=False)\n```\nWe have now completed steps (4)-(6) from the top of this tutorial. To\nsubmit your predictions to Kaggle, you can run the following command in\nyour terminal (from the appropriate directory):\n`kagglecompetitionssubmit-cieee-fraud-detection-fsample\\_submission.csv-m&quot;myfirstsubmission&...",
      "url": "https://auto.gluon.ai/0.0.15/tutorials/tabular_prediction/tabular-kaggle.html"
    },
    {
      "title": "Understand the problem | Python",
      "text": "Understand the problem | Python https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/dive-into-the-competition?ex=1\nUnderstand the problem | Python\nNone\n2022-06-13T00:00:00Z\n# Understand the problem\n####. Understand the problem\nIn the previous chapter, we got acquainted with what Machine Learning competition actually looks like, and had an overview of the general competition process. Now it's time to start solving the problems!\n####. Solution workflow\nBefore proceeding, let's take a look at the broad scheme that we'll be using throughout the subsequent chapters.\nLet's call it a 'solution workflow'. Typically it consists of four major stages.\nFirst, we start by understanding the problem and the competition metric.\n####. Solution workflow\nThen we need to make some EDA (exploratory data analysis) in order to see and understand the data we're working with.\n####. Solution workflow\nThe next very important step is to establish the local validation strategy. We already know that its goal is to prevent overfitting.\n####. Solution workflow\nFinally, the longest part of the competition is Modeling, which includes continuous improvements of the solution.\nIn this chapter, we will talk about the first three blocks. The third and fourth chapters are entirely devoted to Modeling.\n####. Understand the problem\nTo understand the problem we need to perform the following steps.\nDetermine the data type we will be dealing with.\nIs it the usual tabular data?\n####. Understand the problem\nOr maybe we're given time series data.\n####. Understand the problem\nOr it's unstructured data like images.\n####. Understand the problem\nOr text, and so on. It could be even a mix of multiple data types.\nIn this course, we mostly concentrate on the tabular data and time series. No worries, the general solution workflow is the same for any data type.\nThe next step is to determine the problem type. We've talked about it a little in the previous chapter. Here we should select between classification, regression, ranking and so on.\nLastly, we should get familiar with the metric being optimized. As we already know, every competition has a single metric. It is used by Kaggle to evaluate the submissions and to determine the best performing solution.\n####. Metric definition\nGenerally, the majority of the metrics can be found in the sklearn.metrics library. However, there are some special competition metrics that are not available in scikit-learn. In such cases, we have to create metrics manually.\nSuppose we're solving the competition problem with Root Mean Squared Logarithmic Error as an evaluation metric. This metric is not implemented in scikit-learn. Its formula is presented on the slide. N is the number of observations in the test set, y is the actual value, y hat is the predicted value. So, it is a usual Root Mean Squared Error in a logarithmic scale.\nIn this situation, we have to define a custom function that takes as input the true and predicted values, and outputs the metric value. Firstly, we compute squares under the sum using numpy log and power methods.\nFinally, we get the square root of the mean over all the observations, and return the result.\n####. Let's practice!\nThe main takeaway from this lesson is that before building any models, we should perform some preliminary steps to understand the data and the problem we're facing. So, let's practice with other problem types and metrics!\nShow Transcripts\n### Create Your Free Account\nor\nEmail AddressPasswordStart Learning for FreeBy continuing, you accept our [Terms of Use](https://www.datacamp.com/terms-of-use), our [Privacy Policy](https://www.datacamp.com/privacy-policy) and that your data is stored in the USA.",
      "url": "https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/dive-into-the-competition?ex=1"
    },
    {
      "title": "Define a competition metric | Python",
      "text": "# Define a competition metric\nCompetition metric is used by Kaggle to evaluate your submissions. Moreover, you also need to measure the performance of different models on a local validation set.\nFor now, your goal is to manually develop a couple of competition metrics in case if they are not available in `sklearn.metrics`.\nIn particular, you will define:\n- Mean Squared Error (MSE) for the regression problem:\n$$MSE = \\\\frac{1}{N}\\\\sum\\_{i=1}^{N}{(y\\_i - \\\\hat{y}\\_i)^2}$$\n- Logarithmic Loss (LogLoss) for the binary classification problem:\n$$LogLoss = -\\\\frac{1}{N}\\\\sum\\_{i=1}^{N}{(y\\_i\\\\ln p\\_i + (1-y\\_i)\\\\ln (1-p\\_i))}$$\nThis exercise is part of the course\n## Winning a Kaggle Competition in Python\n[View Course](https://www.datacamp.com/courses/winning-a-kaggle-competition-in-python)\n### Hands-on interactive exercise\nHave a go at this exercise by completing this sample code.\n```\nimport numpy as np\n# Import MSE from sklearn\nfrom sklearn.metrics import mean_squared_error\n# Define your own MSE function\ndef own_mse(y_true, y_pred):\n# Raise differences to the power of 2\nsquares = np.____(y_true - y_pred, 2)\n# Find mean over all observations\nerr = np.____(squares)\nreturn err\nprint('Sklearn MSE: {:.5f}. '.format(mean_squared_error(y_regression_true, y_regression_pred)))\nprint('Your MSE: {:.5f}. '.format(own_mse(y_regression_true, y_regression_pred)))\n```\n[Edit and Run Code](https://www.datacamp.com/users/sign_up?redirect=%2Fcourses%2Fwinning-a-kaggle-competition-in-python%2Fdive-into-the-competition%3Fex%3D3)",
      "url": "https://campus.datacamp.com/courses/winning-a-kaggle-competition-in-python/dive-into-the-competition?ex=3"
    },
    {
      "title": "Learn Intermediate Machine Learning Tutorials",
      "text": "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n\n[Learn more](https://www.kaggle.com/cookies)\n\nOK, Got it.\n\n# Intermediate Machine Learning\n\nHandle missing values, non-numeric values, data leakage, and more.\n\nBegin Course\n\n4 hours to go\n\nCoursesDiscussions\n\n## Lessons\n\n### Tutorial\n\n### Exercise\n\n- ### 1\n\n[Introduction\\\n\\\nReview what you need for this course.](https://www.kaggle.com/code/alexisbcook/introduction)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/introduction)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370272)\n\n- ### 2\n\n[Missing Values\\\n\\\nMissing values happen. Be prepared for this common challenge in real datasets.](https://www.kaggle.com/code/alexisbcook/missing-values)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/missing-values)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370280)\n\n- ### 3\n\n[Categorical Variables\\\n\\\nThere's a lot of non-numeric data out there. Here's how to use it for machine learning.](https://www.kaggle.com/code/alexisbcook/categorical-variables)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/categorical-variables)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370279)\n\n- ### 4\n\n[Pipelines\\\n\\\nA critical skill for deploying (and even testing) complex models with pre-processing.](https://www.kaggle.com/code/alexisbcook/pipelines)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/pipelines)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370278)\n\n- ### 5\n\n[Cross-Validation\\\n\\\nA better way to test your models.](https://www.kaggle.com/code/alexisbcook/cross-validation)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/cross-validation)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370281)\n\n- ### 6\n\n[XGBoost\\\n\\\nThe most accurate modeling technique for structured data.](https://www.kaggle.com/code/alexisbcook/xgboost)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/xgboost)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370271)\n\n- ### 7\n\n[Data Leakage\\\n\\\nFind and fix this problem that ruins your model in subtle ways.](https://www.kaggle.com/code/alexisbcook/data-leakage)\n\n\n\n[local\\_library](https://www.kaggle.com/code/alexisbcook/data-leakage)\n\n\n\n[code](https://www.kaggle.com/code/fork/3370270)\n\n\nBuilds on\n\n[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)\n\n[Pandas](https://www.kaggle.com/learn/pandas)\n\nPreparation for\n\n[Feature Engineering](https://www.kaggle.com/learn/feature-engineering)\n\n[Time Series](https://www.kaggle.com/learn/time-series)\n\nHours to earn certificate\n\n4 (estimated)\n\nCost\n\nNo cost, like all Kaggle Learn Courses\n\nInstructor\n\n[Alexis Cook](https://www.kaggle.com/alexisbcook)",
      "url": "https://kaggle.com/learn/intermediate-machine-learning"
    },
    {
      "title": "How to use AutoGluon for Kaggle competitions \u00b6",
      "text": "How to use AutoGluon for Kaggle competitions &#8212; AutoGluon Documentation 0.1.1 documentation\n[![AutoGluon Documentation](../../_static/AutogluonLogo.png)](../../index.html)\nTable Of Contents\n[![AutoGluon Documentation](../../_static/AutogluonLogo.png)](../../index.html)\nTable Of Contents\n# How to use AutoGluon for Kaggle competitions[\u00b6](#how-to-use-autogluon-for-kaggle-competitions)\nThis tutorial will teach you how to use AutoGluon to become a serious\nKaggle competitor without writing lots of code. We first outline the\ngeneral steps to use AutoGluon in Kaggle contests. Here, we assume the\ncompetition involves tabular data which are stored in one (or more) CSV\nfiles.\n1. Run Bash command: pip install kaggle\n2. Navigate to:[https://www.kaggle.com/account](https://www.kaggle.com/account)and create an account (if\nnecessary). Then , click on \u201cCreate New API Token\u201d and move\ndownloaded file to this location on your machine:`\\~/.kaggle/kaggle.json`. For troubleshooting, see[Kaggle API\ninstructions](https://www.kaggle.com/docs/api).\n3. To download data programmatically: Execute this Bash command in your\nterminal:\n`kagglecompetitionsdownload-c[COMPETITION]`\nHere, [COMPETITION] should be replaced by the name of the competition\nyou wish to enter. Alternatively, you can download data manually: Just\nnavigate to website of the Kaggle competition you wish to enter, click\n\u201cDownload All\u201d, and accept the competition\u2019s terms.\n1. If the competition\u2019s training data is comprised of multiple CSV\nfiles, use[pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)to properly merge/join them into a single data table where rows =\ntraining examples, columns = features.\n2. Run autogluon`fit()`on the resulting data table.\n3. Load the test dataset from competition (again making the necessary\nmerges/joins to ensure it is in the exact same format as the training\ndata table), and then call autogluon`predict()`. Subsequently use[pandas.read\\_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)to load the competition\u2019s`sample\\_submission.csv`file into a\nDataframe, put the AutoGluon predictions in the right column of this\nDataframe, and finally save it as a CSV file via[pandas.to\\_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html).\nIf the competition does not offer a sample submission file, you will\nneed to create the submission file yourself by appropriately\nreformatting AutoGluon\u2019s test predictions.\n4. Submit your predictions via Bash command:\n`kagglecompetitionssubmit-c[COMPETITION]-f[FILE]-m[&quot;MESSAGE&quot;]`\nHere, [COMPETITION] again is the competition\u2019s name, [FILE] is the name\nof the CSV file you created with your predictions, and [\u201cMESSAGE\u201d] is a\nstring message you want to record with this submitted entry.\nAlternatively, you can manually upload your file of predictions on the\ncompetition website.\n1. Finally, navigate to competition leaderboard website to see how well\nyour submission performed! It may take time for your submission to\nappear.\nBelow, we demonstrate how to do steps (4)-(6) in Python for a specific\nKaggle competition:[ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\nThis means you\u2019ll need to run the above steps with`[COMPETITION]`replaced by`ieee-fraud-detection`in each command. Here, we assume\nyou\u2019ve already completed steps (1)-(3) and the data CSV files are\navailable on your computer. To begin step (4), we first load the\ncompetition\u2019s training data into Python:\n```\nimportpandasaspdimportnumpyasnpfromautogluon.tabularimportTabularPredictordirectory=&#39;&#39;\\~/IEEEfraud/&#39;&#39;# directory where you have downloaded the data CSV files from the competitionlabel=&#39;isFraud&#39;# name of target variable to predict in this competitioneval\\_metric=&#39;&#39;roc\\_auc&#39;&#39;# Optional: specify that competition evaluation metric is AUCsave\\_path=directory+&#39;AutoGluonModels/&#39;# where to store trained modelstrain\\_identity=pd.read\\_csv(directory+&#39;&#39;train\\_identity.csv&#39;&#39;)train\\_transaction=pd.read\\_csv(directory+&#39;&#39;train\\_transaction.csv&#39;&#39;)\n```\nSince the training data for this competition is comprised of multiple\nCSV files, we just first join them into a single large table (with rows\n= examples, columns = features) before applying AutoGluon:\n```\ntrain\\_data=pd.merge(train\\_transaction,train\\_identity,on=&#39;TransactionID&#39;,how=&#39;left&#39;)\n```\nNote that a left-join on the`TransactionID`key happened to be most\nappropriate for this Kaggle competition, but for others involving\nmultiple training data files, you will likely need to use a different\njoin strategy (always consider this very carefully). Now that all our\ntraining data resides within a single table, we can apply AutoGluon.\nBelow, we specify the`presets`argument to maximize AutoGluon\u2019s\npredictive accuracy which usually requires that you run`fit()`with\nlonger time limits (3600s below should likely be increased in your run):\n```\npredictor=TabularPredictor(label=label,eval\\_metric=eval\\_metric,path=save\\_path,verbosity=3).fit(train\\_data,presets=&#39;&#39;best\\_quality&#39;&#39;,time\\_limit=3600)results=predictor.fit\\_summary()\n```\nNow, we use the trained AutoGluon Predictor to make predictions on the\ncompetition\u2019s test data. It is imperative that multiple test data files\nare joined together in the exact same manner as the training data.\nBecause this competition is evaluated based on the AUC (Area under the\nROC curve) metric, we ask AutoGluon for predicted class-probabilities\nrather than class predictions. In general, when to use`predict`vs`predict\\_proba`will depend on the particular competition.\n```\ntest\\_identity=pd.read\\_csv(directory+&#39;&#39;test\\_identity.csv&#39;&#39;)test\\_transaction=pd.read\\_csv(directory+&#39;&#39;test\\_transaction.csv&#39;&#39;)test\\_data=pd.merge(test\\_transaction,test\\_identity,on=&#39;TransactionID&#39;,how=&#39;left&#39;)# same join applied to training filesy\\_predproba=predictor.predict\\_proba(test\\_data)y\\_predproba.head(5)# some example predicted fraud-probabilities\n```\nWhen submitting predicted probabilities for classification competitions,\nit is imperative these correspond to the same class expected by Kaggle.\nFor binary classification tasks, you can see which class AutoGluon\u2019s\npredicted probabilities correspond to via:\n```\npredictor.positive\\_class\n```\nFor multiclass classification tasks, you can see which classes\nAutoGluon\u2019s predicted probabilities correspond to via:\n```\npredictor.class\\_labels# classes in this list correspond to columns of predict\\_proba() output\n```\nNow, lets get prediction probabilities for the entire test data, while\nonly getting the positive class predictions by specifying:\n```\ny\\_predproba=predictor.predict\\_proba(test\\_data,as\\_multiclass=False)\n```\nNow that we have made a prediction for each row in the test dataset, we\ncan submit these predictions to Kaggle. Most Kaggle competitions provide\na sample submission file, in which you can simply overwrite the sample\npredictions with your own as we do below:\n```\nsubmission=pd.read\\_csv(directory+&#39;&#39;sample\\_submission.csv&#39;&#39;)submission[&#39;isFraud&#39;]=y\\_predprobasubmission.head()submission.to\\_csv(directory+&#39;&#39;my\\_submission.csv&#39;&#39;,index=False)\n```\nWe have now completed steps (4)-(6) from the top of this tutorial. To\nsubmit your predictions to Kaggle, you can run the following command in\nyour terminal (from the appropriate directory):\n`kagglecompetitionssubmit-cieee-fraud-detection-fsample\\_submission.csv-m&quot;myfirstsubmission&quot;`\nYou can now play with different`fit()`arguments and\nfeature-engineering techniques to try and maximize the rank of your\nsubmissions in the Kaggle Leaderboard!\n**Tips to maximize predictive performance:**\n* Be sure to specify the appropriate evaluation metric if one is\nspecified on the competition website! If you are unsure which metric\nis best, then simply do not specify this arg...",
      "url": "https://auto.gluon.ai/scoredebugweight/tutorials/tabular_prediction/tabular-kaggle.html"
    }
  ]
}