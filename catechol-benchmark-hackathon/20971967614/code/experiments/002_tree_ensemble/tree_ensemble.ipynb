{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0f5aac",
   "metadata": {},
   "source": [
    "# Tree-Based Per-Target Ensemble Model\n",
    "\n",
    "This notebook follows the EXACT template structure required by the competition.\n",
    "Only the model definition line is changed in the last 3 cells.\n",
    "\n",
    "Features:\n",
    "1. Arrhenius kinetics features (inv_temp, log_time, interaction)\n",
    "2. Spange descriptors + ACS PCA descriptors combined\n",
    "3. Per-target models: HistGradientBoosting for SM, ExtraTrees for Products\n",
    "4. Symmetry TTA for mixed solvents\n",
    "5. Reproducibility seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072a72b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:46.066100Z",
     "iopub.status.busy": "2026-01-13T21:47:46.065605Z",
     "iopub.status.idle": "2026-01-13T21:47:47.454367Z",
     "shell.execute_reply": "2026-01-13T21:47:47.453905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052c42d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:47.455672Z",
     "iopub.status.busy": "2026-01-13T21:47:47.455498Z",
     "iopub.status.idle": "2026-01-13T21:47:47.461058Z",
     "shell.execute_reply": "2026-01-13T21:47:47.460659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data utilities loaded\n"
     ]
    }
   ],
   "source": [
    "# Data loading utilities - adapted for local paths\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_FEATURES = [\"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_FEATURES = [\"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "print(\"Data utilities loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0b43eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:47.462236Z",
     "iopub.status.busy": "2026-01-13T21:47:47.462124Z",
     "iopub.status.idle": "2026-01-13T21:47:47.465512Z",
     "shell.execute_reply": "2026-01-13T21:47:47.465131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base classes defined\n"
     ]
    }
   ],
   "source": [
    "# Base classes (from template)\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def featurize(X, Y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "print(\"Base classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30639342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:47.466621Z",
     "iopub.status.busy": "2026-01-13T21:47:47.466513Z",
     "iopub.status.idle": "2026-01-13T21:47:47.472362Z",
     "shell.execute_reply": "2026-01-13T21:47:47.471967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange descriptors: (26, 13)\n",
      "ACS PCA descriptors: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load feature lookup tables\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange descriptors: {SPANGE_DF.shape}\")\n",
    "print(f\"ACS PCA descriptors: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adf01a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:47.473293Z",
     "iopub.status.busy": "2026-01-13T21:47:47.473187Z",
     "iopub.status.idle": "2026-01-13T21:47:48.037488Z",
     "shell.execute_reply": "2026-01-13T21:47:48.037023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# Tree-based Per-Target Ensemble Model\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TreeEnsembleModel(BaseModel):\n",
    "    \"\"\"Tree-based per-target ensemble with Arrhenius features and symmetry TTA.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}  # Per-target models\n",
    "        \n",
    "    def _create_features(self, X, flip=False):\n",
    "        \"\"\"Create feature matrix with Arrhenius kinetics and solvent descriptors.\"\"\"\n",
    "        # Numeric features\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetics features\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        # Solvent features\n",
    "        if self.data_type == 'full':\n",
    "            # Mixed solvent: weighted average\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            \n",
    "            if flip:\n",
    "                # Symmetry flip: swap A and B\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                pct_use = 1 - pct\n",
    "            else:\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                pct_use = pct\n",
    "            \n",
    "            spange_feat = spange_A * (1 - pct_use) + spange_B * pct_use\n",
    "            acs_feat = acs_A * (1 - pct_use) + acs_B * pct_use\n",
    "        else:\n",
    "            # Single solvent\n",
    "            spange_feat = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            acs_feat = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        # Combine all features\n",
    "        features = np.hstack([\n",
    "            time_m, temp_c,           # Original numeric (2)\n",
    "            inv_temp, log_time, interaction,  # Arrhenius (3)\n",
    "            spange_feat,              # Spange descriptors (13)\n",
    "            acs_feat                  # ACS PCA descriptors (5)\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train per-target models.\"\"\"\n",
    "        # Create features\n",
    "        X_feat = self._create_features(X_train, flip=False)\n",
    "        \n",
    "        # Data augmentation for mixed solvents\n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self._create_features(X_train, flip=True)\n",
    "            X_feat = np.vstack([X_feat, X_flip])\n",
    "            y_train_aug = pd.concat([y_train, y_train], ignore_index=True)\n",
    "        else:\n",
    "            y_train_aug = y_train\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        # Train per-target models\n",
    "        # SM: HistGradientBoosting (better for smooth targets)\n",
    "        self.models['SM'] = HistGradientBoostingRegressor(\n",
    "            max_depth=7, max_iter=700, learning_rate=0.04,\n",
    "            random_state=42, early_stopping=False\n",
    "        )\n",
    "        self.models['SM'].fit(X_scaled, y_train_aug['SM'].values)\n",
    "        \n",
    "        # Product 2 & 3: ExtraTrees (better for noisy targets)\n",
    "        self.models['Product 2'] = ExtraTreesRegressor(\n",
    "            n_estimators=500, min_samples_leaf=2,\n",
    "            random_state=42, n_jobs=-1\n",
    "        )\n",
    "        self.models['Product 2'].fit(X_scaled, y_train_aug['Product 2'].values)\n",
    "        \n",
    "        self.models['Product 3'] = ExtraTreesRegressor(\n",
    "            n_estimators=500, min_samples_leaf=2,\n",
    "            random_state=42, n_jobs=-1\n",
    "        )\n",
    "        self.models['Product 3'].fit(X_scaled, y_train_aug['Product 3'].values)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict with symmetry TTA for mixed solvents.\"\"\"\n",
    "        # Standard prediction\n",
    "        X_feat = self._create_features(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        pred_p2 = self.models['Product 2'].predict(X_scaled)\n",
    "        pred_p3 = self.models['Product 3'].predict(X_scaled)\n",
    "        pred_sm = self.models['SM'].predict(X_scaled)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            # TTA: Also predict with flipped inputs\n",
    "            X_flip = self._create_features(X_test, flip=True)\n",
    "            X_flip_scaled = self.scaler.transform(X_flip)\n",
    "            \n",
    "            pred_p2_flip = self.models['Product 2'].predict(X_flip_scaled)\n",
    "            pred_p3_flip = self.models['Product 3'].predict(X_flip_scaled)\n",
    "            pred_sm_flip = self.models['SM'].predict(X_flip_scaled)\n",
    "            \n",
    "            # Average predictions\n",
    "            pred_p2 = (pred_p2 + pred_p2_flip) / 2\n",
    "            pred_p3 = (pred_p3 + pred_p3_flip) / 2\n",
    "            pred_sm = (pred_sm + pred_sm_flip) / 2\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        pred_p2 = np.clip(pred_p2, 0, 1)\n",
    "        pred_p3 = np.clip(pred_p3, 0, 1)\n",
    "        pred_sm = np.clip(pred_sm, 0, 1)\n",
    "        \n",
    "        # Stack predictions: [Product 2, Product 3, SM]\n",
    "        predictions = np.column_stack([pred_p2, pred_p3, pred_sm])\n",
    "        return torch.tensor(predictions)\n",
    "\n",
    "print(\"TreeEnsembleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90462cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:48.038777Z",
     "iopub.status.busy": "2026-01-13T21:47:48.038576Z",
     "iopub.status.idle": "2026-01-13T21:47:49.183950Z",
     "shell.execute_reply": "2026-01-13T21:47:49.183512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Single solvent: (656, 3), (656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([37, 3])\n",
      "Sample predictions: tensor([[0.0035, 0.0042, 0.8157],\n",
      "        [0.0055, 0.0064, 0.8633],\n",
      "        [0.0276, 0.0314, 0.7959]])\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(\"Testing model...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent: {X.shape}, {Y.shape}\")\n",
    "\n",
    "# Test on first fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = TreeEnsembleModel(data='single')\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions: {preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6c7154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:47:53.421913Z",
     "iopub.status.busy": "2026-01-13T21:47:53.421408Z",
     "iopub.status.idle": "2026-01-13T21:48:20.507824Z",
     "shell.execute_reply": "2026-01-13T21:48:20.507399Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:01<00:25,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:02<00:24,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:03<00:23,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:04<00:23,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:05<00:21,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:06<00:20,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:08<00:19,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:09<00:18,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:10<00:16,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:11<00:15,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:12<00:14,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:13<00:13,  1.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:14<00:12,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:15<00:11,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:16<00:10,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:18<00:08,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:19<00:07,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:20<00:06,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:21<00:05,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:22<00:04,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:23<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:24<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [00:25<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:27<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:27<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent CV MSE: 0.011227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "all_actuals = []  # For CV calculation\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = TreeEnsembleModel(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals.append(test_Y.values)  # For CV calculation\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_np = np.vstack(all_actuals)\n",
    "all_preds_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions])\n",
    "single_mse = np.mean((all_actuals_np - all_preds_np) ** 2)\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5871631a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:48:26.707730Z",
     "iopub.status.busy": "2026-01-13T21:48:26.707192Z",
     "iopub.status.idle": "2026-01-13T21:48:49.516362Z",
     "shell.execute_reply": "2026-01-13T21:48:49.515912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:01<00:21,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [00:03<00:18,  1.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [00:05<00:17,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [00:06<00:15,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [00:08<00:13,  1.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [00:10<00:12,  1.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [00:12<00:10,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [00:13<00:08,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [00:15<00:06,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [00:17<00:05,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [00:19<00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [00:21<00:01,  1.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:22<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [00:22<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data CV MSE: 0.010857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []  # For CV calculation\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = TreeEnsembleModel(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals_full.append(test_Y.values)  # For CV calculation\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_full_np = np.vstack(all_actuals_full)\n",
    "all_preds_full_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions_full])\n",
    "full_mse = np.mean((all_actuals_full_np - all_preds_full_np) ** 2)\n",
    "print(f\"\\nFull Data CV MSE: {full_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4997136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T21:48:53.336955Z",
     "iopub.status.busy": "2026-01-13T21:48:53.336442Z",
     "iopub.status.idle": "2026-01-13T21:48:53.349021Z",
     "shell.execute_reply": "2026-01-13T21:48:53.348600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULTS ===\n",
      "Single Solvent MSE: 0.011227\n",
      "Full Data MSE: 0.010857\n",
      "Overall CV MSE: 0.010986\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Submission shape: (1883, 7)\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "# Calculate overall CV score\n",
    "total_samples = len(all_actuals_np) + len(all_actuals_full_np)\n",
    "overall_mse = (single_mse * len(all_actuals_np) + full_mse * len(all_actuals_full_np)) / total_samples\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Single Solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full Data MSE: {full_mse:.6f}\")\n",
    "print(f\"Overall CV MSE: {overall_mse:.6f}\")\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
