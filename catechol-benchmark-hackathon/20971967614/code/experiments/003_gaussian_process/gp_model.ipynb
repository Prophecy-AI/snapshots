{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea5e97b",
   "metadata": {},
   "source": [
    "# Gaussian Process Model for Catechol Prediction\n",
    "\n",
    "GPs excel at extrapolation to unseen data points - the core challenge here.\n",
    "With ~600-1200 samples, GPs are in their sweet spot.\n",
    "\n",
    "This notebook implements:\n",
    "1. Multi-output GP using GPyTorch\n",
    "2. Arrhenius kinetics features\n",
    "3. Spange + ACS PCA descriptors\n",
    "4. Symmetry TTA for mixed solvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89da648e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:36.583799Z",
     "iopub.status.busy": "2026-01-13T22:10:36.583284Z",
     "iopub.status.idle": "2026-01-13T22:10:37.970271Z",
     "shell.execute_reply": "2026-01-13T22:10:37.969826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# Check GPU\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f16b669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:37.971522Z",
     "iopub.status.busy": "2026-01-13T22:10:37.971357Z",
     "iopub.status.idle": "2026-01-13T22:10:38.081833Z",
     "shell.execute_reply": "2026-01-13T22:10:38.081424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPyTorch version: 1.14.3\n"
     ]
    }
   ],
   "source": [
    "# GPyTorch imports\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, MaternKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "print(f\"GPyTorch version: {gpytorch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1634004e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:38.082950Z",
     "iopub.status.busy": "2026-01-13T22:10:38.082834Z",
     "iopub.status.idle": "2026-01-13T22:10:38.091512Z",
     "shell.execute_reply": "2026-01-13T22:10:38.091112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data loading utilities\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature lookup tables\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84fb66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:38.092613Z",
     "iopub.status.busy": "2026-01-13T22:10:38.092503Z",
     "iopub.status.idle": "2026-01-13T22:10:38.095134Z",
     "shell.execute_reply": "2026-01-13T22:10:38.094739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base classes\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481f7ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:38.096178Z",
     "iopub.status.busy": "2026-01-13T22:10:38.096077Z",
     "iopub.status.idle": "2026-01-13T22:10:38.099100Z",
     "shell.execute_reply": "2026-01-13T22:10:38.098715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Single-output GP model\n",
    "class SingleOutputGP(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(SingleOutputGP, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(MaternKernel(nu=2.5, ard_num_dims=train_x.shape[1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625722cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:38.100073Z",
     "iopub.status.busy": "2026-01-13T22:10:38.099964Z",
     "iopub.status.idle": "2026-01-13T22:10:38.517223Z",
     "shell.execute_reply": "2026-01-13T22:10:38.516802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPModel defined\n"
     ]
    }
   ],
   "source": [
    "# GP-based model with per-target GPs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class GPModel(BaseModel):\n",
    "    \"\"\"Gaussian Process model with Arrhenius features and symmetry TTA.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', n_epochs=100):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.scaler = StandardScaler()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.models = {}  # Per-target GP models\n",
    "        self.likelihoods = {}  # Per-target likelihoods\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def _create_features(self, X, flip=False):\n",
    "        \"\"\"Create feature matrix with Arrhenius kinetics and solvent descriptors.\"\"\"\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        \n",
    "        # Arrhenius kinetics features\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        # Solvent features\n",
    "        if self.data_type == 'full':\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                pct_use = 1 - pct\n",
    "            else:\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                pct_use = pct\n",
    "            spange_feat = spange_A * (1 - pct_use) + spange_B * pct_use\n",
    "            acs_feat = acs_A * (1 - pct_use) + acs_B * pct_use\n",
    "        else:\n",
    "            spange_feat = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            acs_feat = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        features = np.hstack([\n",
    "            time_m, temp_c, inv_temp, log_time, interaction,\n",
    "            spange_feat, acs_feat\n",
    "        ])\n",
    "        return features\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train per-target GP models.\"\"\"\n",
    "        # Create features\n",
    "        X_feat = self._create_features(X_train, flip=False)\n",
    "        \n",
    "        # Data augmentation for mixed solvents\n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self._create_features(X_train, flip=True)\n",
    "            X_feat = np.vstack([X_feat, X_flip])\n",
    "            y_train_aug = pd.concat([y_train, y_train], ignore_index=True)\n",
    "        else:\n",
    "            y_train_aug = y_train\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(self.device)\n",
    "        \n",
    "        # Train per-target GP models\n",
    "        for target in TARGET_LABELS:\n",
    "            y_tensor = torch.tensor(y_train_aug[target].values, dtype=torch.double).to(self.device)\n",
    "            \n",
    "            # Initialize likelihood and model\n",
    "            likelihood = GaussianLikelihood().to(self.device)\n",
    "            model = SingleOutputGP(X_tensor, y_tensor, likelihood).to(self.device)\n",
    "            \n",
    "            # Training mode\n",
    "            model.train()\n",
    "            likelihood.train()\n",
    "            \n",
    "            # Optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "            mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "            \n",
    "            # Training loop\n",
    "            for i in range(self.n_epochs):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_tensor)\n",
    "                loss = -mll(output, y_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Store trained model\n",
    "            self.models[target] = model\n",
    "            self.likelihoods[target] = likelihood\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict with symmetry TTA for mixed solvents.\"\"\"\n",
    "        # Standard prediction\n",
    "        X_feat = self._create_features(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.double).to(self.device)\n",
    "        \n",
    "        predictions = {}\n",
    "        for target in TARGET_LABELS:\n",
    "            self.models[target].eval()\n",
    "            self.likelihoods[target].eval()\n",
    "            with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                pred = self.likelihoods[target](self.models[target](X_tensor))\n",
    "                predictions[target] = pred.mean.cpu().numpy()\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            # TTA: Also predict with flipped inputs\n",
    "            X_flip = self._create_features(X_test, flip=True)\n",
    "            X_flip_scaled = self.scaler.transform(X_flip)\n",
    "            X_flip_tensor = torch.tensor(X_flip_scaled, dtype=torch.double).to(self.device)\n",
    "            \n",
    "            for target in TARGET_LABELS:\n",
    "                with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                    pred_flip = self.likelihoods[target](self.models[target](X_flip_tensor))\n",
    "                    predictions[target] = (predictions[target] + pred_flip.mean.cpu().numpy()) / 2\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        for target in TARGET_LABELS:\n",
    "            predictions[target] = np.clip(predictions[target], 0, 1)\n",
    "        \n",
    "        # Stack predictions: [Product 2, Product 3, SM]\n",
    "        result = np.column_stack([predictions['Product 2'], predictions['Product 3'], predictions['SM']])\n",
    "        return torch.tensor(result)\n",
    "\n",
    "print(\"GPModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa65f1e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:10:42.712695Z",
     "iopub.status.busy": "2026-01-13T22:10:42.712191Z",
     "iopub.status.idle": "2026-01-13T22:10:44.252283Z",
     "shell.execute_reply": "2026-01-13T22:10:44.251829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GP model...\n",
      "Single solvent: (656, 3), (656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([37, 3])\n",
      "Sample predictions: tensor([[0.0701, 0.0557, 0.7990],\n",
      "        [0.0760, 0.0589, 0.7752],\n",
      "        [0.0928, 0.0733, 0.7086]])\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(\"Testing GP model...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent: {X.shape}, {Y.shape}\")\n",
    "\n",
    "# Test on first fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = GPModel(data='single', n_epochs=50)\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions: {preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef27175c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:11:48.891233Z",
     "iopub.status.busy": "2026-01-13T22:11:48.890578Z",
     "iopub.status.idle": "2026-01-13T22:12:14.147351Z",
     "shell.execute_reply": "2026-01-13T22:12:14.146885Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:01<00:24,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:02<00:22,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [00:03<00:22,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [00:04<00:20,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [00:05<00:19,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:06<00:18,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [00:07<00:17,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [00:08<00:16,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [00:09<00:15,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [00:10<00:14,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [00:11<00:13,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:12<00:12,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [00:13<00:11,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:14<00:10,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [00:15<00:09,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [00:16<00:08,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [00:17<00:07,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [00:18<00:06,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [00:19<00:05,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:21<00:04,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [00:22<00:03,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:23<00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [00:24<00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:25<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [00:25<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent CV MSE: 0.014880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GPModel(data='single', n_epochs=100)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals.append(test_Y.values)\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_np = np.vstack(all_actuals)\n",
    "all_preds_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions])\n",
    "single_mse = np.mean((all_actuals_np - all_preds_np) ** 2)\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c04653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:12:17.979359Z",
     "iopub.status.busy": "2026-01-13T22:12:17.978821Z",
     "iopub.status.idle": "2026-01-13T22:13:45.090606Z",
     "shell.execute_reply": "2026-01-13T22:13:45.090133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:06<01:23,  6.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [00:13<01:13,  6.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [00:20<01:06,  6.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [00:26<01:00,  6.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [00:33<00:53,  6.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [00:40<00:46,  6.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [00:46<00:40,  6.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [00:53<00:33,  6.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [01:00<00:26,  6.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [01:06<00:20,  6.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [01:13<00:13,  6.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [01:20<00:06,  6.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [01:27<00:00,  6.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [01:27<00:00,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data CV MSE: 0.019547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = GPModel(data='full', n_epochs=100)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_full_np = np.vstack(all_actuals_full)\n",
    "all_preds_full_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions_full])\n",
    "full_mse = np.mean((all_actuals_full_np - all_preds_full_np) ** 2)\n",
    "print(f\"\\nFull Data CV MSE: {full_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca74f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:14:06.065109Z",
     "iopub.status.busy": "2026-01-13T22:14:06.064574Z",
     "iopub.status.idle": "2026-01-13T22:14:06.077444Z",
     "shell.execute_reply": "2026-01-13T22:14:06.076970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULTS ===\n",
      "Single Solvent MSE: 0.014880\n",
      "Full Data MSE: 0.019547\n",
      "Overall CV MSE: 0.017921\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Submission shape: (1883, 7)\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "# Calculate overall CV score\n",
    "total_samples = len(all_actuals_np) + len(all_actuals_full_np)\n",
    "overall_mse = (single_mse * len(all_actuals_np) + full_mse * len(all_actuals_full_np)) / total_samples\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Single Solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full Data MSE: {full_mse:.6f}\")\n",
    "print(f\"Overall CV MSE: {overall_mse:.6f}\")\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
