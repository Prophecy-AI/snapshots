{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce1342a",
   "metadata": {},
   "source": [
    "# Stacking Ensemble: MLP + Tree-Based Models\n",
    "\n",
    "This notebook combines:\n",
    "1. MLP with Arrhenius features, BatchNorm, Dropout, HuberLoss (from exp_000)\n",
    "2. Tree-based per-target ensemble (from exp_001)\n",
    "\n",
    "The goal is to leverage diversity between model types to reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd415c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:23:58.767647Z",
     "iopub.status.busy": "2026-01-13T22:23:58.767085Z",
     "iopub.status.idle": "2026-01-13T22:24:00.167185Z",
     "shell.execute_reply": "2026-01-13T22:24:00.166707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC, abstractmethod\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077f704f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.168872Z",
     "iopub.status.busy": "2026-01-13T22:24:00.168458Z",
     "iopub.status.idle": "2026-01-13T22:24:00.177608Z",
     "shell.execute_reply": "2026-01-13T22:24:00.177210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange: (26, 13), ACS PCA: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data loading utilities\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "TARGET_LABELS = [\"Product 2\", \"Product 3\", \"SM\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    return pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load feature lookup tables\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "ACS_PCA_DF = load_features('acs_pca_descriptors')\n",
    "print(f\"Spange: {SPANGE_DF.shape}, ACS PCA: {ACS_PCA_DF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d81b937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.178974Z",
     "iopub.status.busy": "2026-01-13T22:24:00.178852Z",
     "iopub.status.idle": "2026-01-13T22:24:00.181546Z",
     "shell.execute_reply": "2026-01-13T22:24:00.181135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base class\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "    def predict(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183a73f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.182879Z",
     "iopub.status.busy": "2026-01-13T22:24:00.182611Z",
     "iopub.status.idle": "2026-01-13T22:24:00.195505Z",
     "shell.execute_reply": "2026-01-13T22:24:00.195103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP component defined\n"
     ]
    }
   ],
   "source": [
    "# ============ MLP COMPONENT ============\n",
    "# Kinetic Featurizer with Arrhenius features\n",
    "class KineticMixingFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.featurizer = SPANGE_DF\n",
    "        self.feats_dim = self.featurizer.shape[1] + 2 + 3  # 13 spange + 2 numeric + 3 kinetic\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        \n",
    "        # Arrhenius kinetic features\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        X_kinetic = torch.tensor(np.hstack([X_vals, inv_temp, log_time, interaction]))\n",
    "        \n",
    "        if self.mixed:\n",
    "            A = torch.tensor(self.featurizer.loc[X[\"SOLVENT A NAME\"]].values)\n",
    "            B = torch.tensor(self.featurizer.loc[X[\"SOLVENT B NAME\"]].values)\n",
    "            pct = torch.tensor(X[\"SolventB%\"].values.reshape(-1, 1))\n",
    "            if flip:\n",
    "                X_chem = B * (1 - (1-pct)) + A * (1-pct)\n",
    "            else:\n",
    "                X_chem = A * (1 - pct) + B * pct\n",
    "        else:\n",
    "            X_chem = torch.tensor(self.featurizer.loc[X[\"SOLVENT NAME\"]].values)\n",
    "            \n",
    "        return torch.cat([X_kinetic, X_chem], dim=1)\n",
    "\n",
    "# MLP Internal Model\n",
    "class MLPInternal(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPInternal, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# MLP Model with bagging\n",
    "class MLPWithArrhenius(nn.Module):\n",
    "    def __init__(self, data='single', n_models=3, epochs=200):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.featurizer = KineticMixingFeaturizer(mixed=(data=='full'))\n",
    "        self.n_models = n_models\n",
    "        self.epochs = epochs\n",
    "        self.models = nn.ModuleList()\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            model = MLPInternal(input_dim).to(device)\n",
    "            model.train()\n",
    "            self.models.append(model)\n",
    "            \n",
    "            dataset = TensorDataset(X_all, y_all)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for inputs, targets in loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                scheduler.step(epoch_loss / len(dataset))\n",
    "\n",
    "    def predict(self, X):\n",
    "        device = next(self.models[0].parameters()).device\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_std = self.featurizer.featurize(X, flip=False).to(device)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True).to(device)\n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    p1 = model(X_std)\n",
    "                    p2 = model(X_flip)\n",
    "                    pred_sum += (p1 + p2) * 0.5\n",
    "            avg_pred = pred_sum / self.n_models\n",
    "        else:\n",
    "            X_std = self.featurizer.featurize(X).to(device)\n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    pred_sum += model(X_std)\n",
    "            avg_pred = pred_sum / self.n_models\n",
    "\n",
    "        return avg_pred.cpu()\n",
    "\n",
    "print(\"MLP component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff026084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.196838Z",
     "iopub.status.busy": "2026-01-13T22:24:00.196538Z",
     "iopub.status.idle": "2026-01-13T22:24:00.685899Z",
     "shell.execute_reply": "2026-01-13T22:24:00.685449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree component defined\n"
     ]
    }
   ],
   "source": [
    "# ============ TREE COMPONENT ============\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TreeEnsembleModel(BaseModel):\n",
    "    def __init__(self, data='single'):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        \n",
    "    def _create_features(self, X, flip=False):\n",
    "        time_m = X[\"Residence Time\"].values.reshape(-1, 1)\n",
    "        temp_c = X[\"Temperature\"].values.reshape(-1, 1)\n",
    "        \n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1)\n",
    "            if flip:\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                pct_use = 1 - pct\n",
    "            else:\n",
    "                spange_A = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                spange_B = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                acs_A = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "                acs_B = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "                pct_use = pct\n",
    "            spange_feat = spange_A * (1 - pct_use) + spange_B * pct_use\n",
    "            acs_feat = acs_A * (1 - pct_use) + acs_B * pct_use\n",
    "        else:\n",
    "            spange_feat = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            acs_feat = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        features = np.hstack([time_m, temp_c, inv_temp, log_time, interaction, spange_feat, acs_feat])\n",
    "        return features\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        X_feat = self._create_features(X_train, flip=False)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self._create_features(X_train, flip=True)\n",
    "            X_feat = np.vstack([X_feat, X_flip])\n",
    "            y_train_aug = pd.concat([y_train, y_train], ignore_index=True)\n",
    "        else:\n",
    "            y_train_aug = y_train\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X_feat)\n",
    "        \n",
    "        self.models['SM'] = HistGradientBoostingRegressor(\n",
    "            max_depth=7, max_iter=700, learning_rate=0.04, random_state=42, early_stopping=False\n",
    "        )\n",
    "        self.models['SM'].fit(X_scaled, y_train_aug['SM'].values)\n",
    "        \n",
    "        self.models['Product 2'] = ExtraTreesRegressor(n_estimators=500, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "        self.models['Product 2'].fit(X_scaled, y_train_aug['Product 2'].values)\n",
    "        \n",
    "        self.models['Product 3'] = ExtraTreesRegressor(n_estimators=500, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "        self.models['Product 3'].fit(X_scaled, y_train_aug['Product 3'].values)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X_feat = self._create_features(X_test, flip=False)\n",
    "        X_scaled = self.scaler.transform(X_feat)\n",
    "        \n",
    "        pred_p2 = self.models['Product 2'].predict(X_scaled)\n",
    "        pred_p3 = self.models['Product 3'].predict(X_scaled)\n",
    "        pred_sm = self.models['SM'].predict(X_scaled)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self._create_features(X_test, flip=True)\n",
    "            X_flip_scaled = self.scaler.transform(X_flip)\n",
    "            \n",
    "            pred_p2 = (pred_p2 + self.models['Product 2'].predict(X_flip_scaled)) / 2\n",
    "            pred_p3 = (pred_p3 + self.models['Product 3'].predict(X_flip_scaled)) / 2\n",
    "            pred_sm = (pred_sm + self.models['SM'].predict(X_flip_scaled)) / 2\n",
    "        \n",
    "        pred_p2 = np.clip(pred_p2, 0, 1)\n",
    "        pred_p3 = np.clip(pred_p3, 0, 1)\n",
    "        pred_sm = np.clip(pred_sm, 0, 1)\n",
    "        \n",
    "        predictions = np.column_stack([pred_p2, pred_p3, pred_sm])\n",
    "        return torch.tensor(predictions)\n",
    "\n",
    "print(\"Tree component defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4285d291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.687191Z",
     "iopub.status.busy": "2026-01-13T22:24:00.687014Z",
     "iopub.status.idle": "2026-01-13T22:24:00.691718Z",
     "shell.execute_reply": "2026-01-13T22:24:00.691300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingEnsembleModel defined\n"
     ]
    }
   ],
   "source": [
    "# ============ STACKING ENSEMBLE ============\n",
    "class StackingEnsembleModel(BaseModel):\n",
    "    \"\"\"Combines MLP and Tree-based models for ensemble diversity.\"\"\"\n",
    "    \n",
    "    def __init__(self, data='single', mlp_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.tree_weight = 1 - mlp_weight\n",
    "        \n",
    "        # Initialize components\n",
    "        self.mlp = MLPWithArrhenius(data=data, n_models=3, epochs=200)\n",
    "        self.trees = TreeEnsembleModel(data=data)\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train both MLP and Tree components.\"\"\"\n",
    "        # Train MLP\n",
    "        self.mlp.train_model(X_train, y_train)\n",
    "        # Train Trees\n",
    "        self.trees.train_model(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Average predictions from both models.\"\"\"\n",
    "        pred_mlp = self.mlp.predict(X_test)\n",
    "        pred_trees = self.trees.predict(X_test)\n",
    "        \n",
    "        # Weighted average\n",
    "        combined = self.mlp_weight * pred_mlp + self.tree_weight * pred_trees\n",
    "        \n",
    "        # Clip to [0, 1]\n",
    "        combined = torch.clamp(combined, 0, 1)\n",
    "        \n",
    "        return combined\n",
    "\n",
    "print(\"StackingEnsembleModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc331c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:00.692737Z",
     "iopub.status.busy": "2026-01-13T22:24:00.692621Z",
     "iopub.status.idle": "2026-01-13T22:24:27.765159Z",
     "shell.execute_reply": "2026-01-13T22:24:27.764671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing stacking ensemble...\n",
      "Single solvent: (656, 3), (656, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([37, 3])\n",
      "Sample predictions: tensor([[0.0039, 0.0044, 0.8770],\n",
      "        [0.0075, 0.0085, 0.8817],\n",
      "        [0.0256, 0.0289, 0.8124]])\n"
     ]
    }
   ],
   "source": [
    "# Quick test\n",
    "print(\"Testing stacking ensemble...\")\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "print(f\"Single solvent: {X.shape}, {Y.shape}\")\n",
    "\n",
    "# Test on first fold\n",
    "split_gen = generate_leave_one_out_splits(X, Y)\n",
    "(train_X, train_Y), (test_X, test_Y) = next(split_gen)\n",
    "\n",
    "model = StackingEnsembleModel(data='single', mlp_weight=0.5)\n",
    "model.train_model(train_X, train_Y)\n",
    "preds = model.predict(test_X)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Sample predictions: {preds[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44f8e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:24:32.844166Z",
     "iopub.status.busy": "2026-01-13T22:24:32.843634Z",
     "iopub.status.idle": "2026-01-13T22:35:05.383414Z",
     "shell.execute_reply": "2026-01-13T22:35:05.382964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:26<10:04, 26.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:52<09:43, 26.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [01:18<09:03, 25.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [01:43<08:32, 25.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [02:09<08:10, 25.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [02:35<07:47, 25.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [03:01<07:22, 26.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [03:28<06:57, 26.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [03:54<06:34, 26.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [04:21<06:10, 26.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [04:48<05:44, 26.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [05:14<05:17, 26.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [05:40<04:50, 26.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [06:07<04:24, 26.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [06:33<03:57, 26.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [07:00<03:31, 26.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [07:27<03:07, 26.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [07:54<02:39, 26.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [08:20<02:12, 26.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [08:46<01:45, 26.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [09:13<01:19, 26.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [09:39<00:53, 26.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [10:06<00:26, 26.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [10:32<00:00, 26.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [10:32<00:00, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent CV MSE: 0.009713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = StackingEnsembleModel(data='single', mlp_weight=0.5)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals.append(test_Y.values)\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_np = np.vstack(all_actuals)\n",
    "all_preds_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions])\n",
    "single_mse = np.mean((all_actuals_np - all_preds_np) ** 2)\n",
    "print(f\"\\nSingle Solvent CV MSE: {single_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef9fe74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:36:34.077209Z",
     "iopub.status.busy": "2026-01-13T22:36:34.076679Z",
     "iopub.status.idle": "2026-01-13T22:56:22.182980Z",
     "shell.execute_reply": "2026-01-13T22:56:22.182541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [01:33<18:36, 93.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [03:01<16:34, 90.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [04:31<15:04, 90.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [06:00<13:25, 89.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [07:28<11:52, 89.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [08:57<10:22, 88.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [10:26<08:53, 88.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [11:55<07:25, 89.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [13:24<05:56, 89.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [15:00<04:33, 91.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [16:36<03:05, 92.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [18:12<01:33, 93.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [19:48<00:00, 94.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [19:48<00:00, 91.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Data CV MSE: 0.010610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = StackingEnsembleModel(data='full', mlp_weight=0.5)  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "    all_actuals_full.append(test_Y.values)\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "# Save final submission\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "\n",
    "# Calculate CV score\n",
    "all_actuals_full_np = np.vstack(all_actuals_full)\n",
    "all_preds_full_np = np.array([[p['target_1'], p['target_2'], p['target_3']] for p in all_predictions_full])\n",
    "full_mse = np.mean((all_actuals_full_np - all_preds_full_np) ** 2)\n",
    "print(f\"\\nFull Data CV MSE: {full_mse:.6f}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02067e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:56:50.637718Z",
     "iopub.status.busy": "2026-01-13T22:56:50.637109Z",
     "iopub.status.idle": "2026-01-13T22:56:50.656087Z",
     "shell.execute_reply": "2026-01-13T22:56:50.655619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULTS ===\n",
      "Single Solvent MSE: 0.009713\n",
      "Full Data MSE: 0.010610\n",
      "Overall CV MSE: 0.010298\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Submission shape: (1883, 7)\n"
     ]
    }
   ],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "# Calculate overall CV score\n",
    "total_samples = len(all_actuals_np) + len(all_actuals_full_np)\n",
    "overall_mse = (single_mse * len(all_actuals_np) + full_mse * len(all_actuals_full_np)) / total_samples\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Single Solvent MSE: {single_mse:.6f}\")\n",
    "print(f\"Full Data MSE: {full_mse:.6f}\")\n",
    "print(f\"Overall CV MSE: {overall_mse:.6f}\")\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
