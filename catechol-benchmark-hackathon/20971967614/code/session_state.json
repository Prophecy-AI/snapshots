{
  "workspace_dir": "/home/code",
  "competition_id": "catechol-benchmark-hackathon",
  "metric_direction": true,
  "start_time": "2026-01-13T20:51:08.020797",
  "time_limit_minutes": 2100,
  "experiments": [
    {
      "id": "exp_000",
      "name": "Baseline: Arrhenius Kinetics + MLP with BatchNorm + TTA",
      "model_type": "MLP (PyTorch)",
      "score": 0.011303,
      "notes": "First baseline implementing the recommended approach from the strategy:\n- Physics-informed features: inv_temp (1000/T_K), log_time (ln(t)), interaction (inv_temp * log_time)\n- Spange descriptors (13 features) for solvent featurization\n- MLP architecture: [128, 128, 64] with BatchNorm, ReLU, Dropout(0.2), Sigmoid output\n- HuberLoss for robustness to outliers\n- Bagging 3 models per fold\n- Symmetry TTA for mixed solvents (predict both A,B and B,A, average)\n- Data augmentation for mixed solvents (train on both symmetries)\n- 200 epochs, Adam lr=5e-4, weight_decay=1e-5, ReduceLROnPlateau scheduler\n- Gradient clipping max_norm=1.0\n\nResults:\n- Single Solvent CV MSE: 0.010916\n- Full Data CV MSE: 0.011510\n- Overall CV MSE: 0.011303\n\nThis already beats the target of 0.017270! The Arrhenius kinetics features and symmetry TTA are key improvements.",
      "experiment_folder": "/home/code/experiments/001_baseline",
      "timestamp": "2026-01-13T21:39:01.377478"
    },
    {
      "id": "exp_001",
      "name": "Tree-Based Per-Target Ensemble with Arrhenius Features",
      "model_type": "HistGradientBoosting + ExtraTrees",
      "score": 0.010986,
      "notes": "Tree-based per-target ensemble following the strategy recommendation:\n\nModel Architecture:\n- SM target: HistGradientBoostingRegressor (max_depth=7, max_iter=700, lr=0.04)\n- Product 2 & 3: ExtraTreesRegressor (n_estimators=500, min_samples_leaf=2)\n\nFeatures (23 total):\n- Original numeric: Residence Time, Temperature (2)\n- Arrhenius kinetics: inv_temp, log_time, interaction (3)\n- Spange descriptors (13)\n- ACS PCA descriptors (5)\n\nKey techniques:\n- StandardScaler preprocessing\n- Data augmentation for mixed solvents (train on both A,B and B,A)\n- Symmetry TTA for mixed solvents at inference\n- Clip predictions to [0, 1]\n- Reproducibility seeds set\n\nResults:\n- Single Solvent CV MSE: 0.011227\n- Full Data CV MSE: 0.010857\n- Overall CV MSE: 0.010986\n\nImprovements over exp_001:\n- Slightly better CV score (0.010986 vs 0.011303)\n- MUCH faster training (~50 seconds vs ~30 minutes)\n- Follows template structure correctly\n- Reproducibility seeds added\n\nThis approach is simpler, faster, and achieves comparable or better results than the MLP baseline.",
      "experiment_folder": "/home/code/experiments/002_tree_ensemble",
      "timestamp": "2026-01-13T21:49:14.621162"
    }
  ],
  "candidates": [
    {
      "file_path": "/home/code/submission_candidates/candidate_000.csv",
      "score": 0.011303,
      "model_name": "Baseline: Arrhenius Kinetics + MLP with BatchNorm + TTA",
      "experiment_id": "exp_000",
      "timestamp": "2026-01-13T21:39:01.378549"
    },
    {
      "file_path": "/home/code/submission_candidates/candidate_001.csv",
      "score": 0.010986,
      "model_name": "Tree-Based Per-Target Ensemble with Arrhenius Features",
      "experiment_id": "exp_001",
      "timestamp": "2026-01-13T21:49:14.623990"
    }
  ],
  "submissions": [
    {
      "candidate_id": "exp_000",
      "experiment_id": "exp_000",
      "timestamp": "2026-01-13T21:41:08.049533+00:00",
      "model_name": "Baseline: Arrhenius Kinetics + MLP with BatchNorm + TTA",
      "cv_score": 0.011303,
      "lb_score": 0.0998,
      "error": null
    },
    {
      "candidate_id": "exp_001",
      "experiment_id": "exp_001",
      "timestamp": "2026-01-13T22:02:16.842949+00:00",
      "model_name": "Tree-Based Per-Target Ensemble with Arrhenius Features",
      "cv_score": 0.010986,
      "lb_score": 0.09987,
      "error": null
    }
  ],
  "strategy_history": [
    {
      "strategy": "# Catechol Reaction Yield Prediction - Techniques Guide\n\n## CRITICAL: Submission Structure Requirements\n**MANDATORY:** The submission must follow the exact structure of the benchmark template notebook.\n- The last three cells MUST remain unchanged except for the model definition line\n- `model = MLPModel()` can be replaced with a new model definition\n- Both single solvent and full (mixed) solvent tasks must be handled\n\n## Data Understanding\n**Reference notebooks for data characteristics:**\n- `exploration/eda.ipynb` - Contains full EDA: feature distributions, target statistics, CV structure\n\n**Key Data Facts:**\n- Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV (24 folds)\n- Full/mixed solvent: 1227 samples, 13 solvent pairs, leave-one-ramp-out CV (13 folds)\n- Targets: SM, Product 2, Product 3 (yields as fractions 0-1)\n- **IMPORTANT:** Targets do NOT sum to 1 (mean ~0.8) - there is mass loss in the reaction\n- Temperature range: 175-225\u00b0C, Residence Time: ~2-15 minutes\n\n## Feature Engineering (Physics-Informed)\n\n### 1. Arrhenius Kinetics Features (HIGHLY RECOMMENDED)\nChemical reactions follow Arrhenius kinetics. Transform features accordingly:\n- `inv_temp = 1000 / (Temperature + 273.15)` - inverse temperature in Kelvin\n- `log_time = log(Residence Time)` - logarithm of time\n- `interaction = inv_temp * log_time` - interaction term\n\nThis physics-informed approach significantly improves predictions.\n\n### 2. Solvent Featurization\nAvailable pre-computed features (use via lookup tables):\n- **spange_descriptors** (13 features): Most commonly used, includes dielectric constant, ET(30), alpha, beta, pi*, etc.\n- **acs_pca_descriptors** (5 features): PCA-reduced green chemistry descriptors\n- **drfps_catechol** (2048 features): Differential reaction fingerprints - high dimensional\n- **fragprints** (2133 features): Fragment + fingerprint concatenation - very high dimensional\n\n**For mixed solvents:** Use weighted average of solvent A and B features based on SolventB%:\n```\nX_feat = A_feat * (1 - SolventB%) + B_feat * SolventB%\n```\n\n### 3. Additional Feature Ideas\n- `Reaction_Energy = Temperature * Residence Time`\n- `B_Conc_Temp = SolventB% * Temperature`\n\n## Model Architectures\n\n### 1. MLP with BatchNorm (Baseline++)\nArchitecture that works well:\n- Input BatchNorm\n- Hidden layers: [128, 128, 64] with BatchNorm, ReLU, Dropout(0.2)\n- Output: 3 neurons with Sigmoid activation (yields are 0-1)\n- Loss: MSELoss or HuberLoss (more robust to outliers)\n- Optimizer: Adam with lr=5e-4, weight_decay=1e-5\n- Scheduler: ReduceLROnPlateau (factor=0.5, patience=20)\n- Gradient clipping: max_norm=1.0\n- Epochs: 300\n\n### 2. LightGBM Ensemble\nAlternative approach using gradient boosting:\n- Train 3 separate LightGBM regressors (one per target)\n- learning_rate=0.03, max_depth=6\n- Early stopping with 100 rounds patience\n- Use internal validation split (~12%) for early stopping\n\n### 3. Gaussian Processes\nFor small datasets like this, GPs can provide:\n- Good uncertainty quantification\n- Strong performance with limited data (~600-1200 samples is ideal for GPs)\n- Consider Deep Kernel Learning (DKL) to combine NN feature learning with GP uncertainty\n- GPs excel at extrapolation to unseen solvents (the core challenge here)\n\n### 4. Multi-Output Regression Strategies\nSince we predict 3 correlated targets (SM, Product 2, Product 3):\n\n**Regressor Chains:** Feed prediction of one yield as input to the next\n- Can capture correlations between outputs\n- Order matters: try SM \u2192 Product 2 \u2192 Product 3 (or optimize order)\n\n**Joint Multi-Output Models:**\n- Single model predicting all 3 outputs simultaneously\n- Neural networks naturally handle this with 3-output layer\n- Tree-based: use MultiOutputRegressor or native multi-output support\n\n**Curds & Whey Post-Processing:**\n- Linear shrinkage method that decorrelates responses\n- Can improve predictions when outputs are correlated\n\n## Ensemble and Augmentation Strategies\n\n### 1. Model Bagging\nTrain multiple models (e.g., 5-7) and average predictions:\n- Reduces variance\n- More robust predictions\n\n### 2. Chemical Symmetry TTA (Test-Time Augmentation)\n**For mixed solvents only:** A mixture of \"Solvent A + Solvent B\" is physically identical to \"Solvent B + Solvent A\"\n- During inference, predict twice: once with (A, B) and once with (B, A) flipped\n- Average the two predictions\n- This respects physical symmetry and improves predictions\n\n### 3. Symmetric Data Augmentation (Training)\nFor mixed solvents, augment training data by including both:\n- Original: (A, B, SolventB%)\n- Flipped: (B, A, 1-SolventB%)\nThis doubles the effective training set size.\n\n## Post-Processing\n\n### Output Constraints\n- Clip predictions to [0, 1] range (yields cannot be negative or >100%)\n- **DO NOT** normalize to sum to 1 - the targets naturally don't sum to 1 due to mass loss\n\n## Validation Strategy\n\nThe competition uses a specific CV structure:\n- **Single solvent:** Leave-one-solvent-out (24 folds) - tests generalization to unseen solvents\n- **Full data:** Leave-one-ramp-out (13 folds) - tests generalization to unseen solvent pairs\n\n**Important:** Same hyperparameters must be used across all folds (no per-fold tuning unless there's explainable rationale).\n\n## Advanced Techniques to Consider\n\n### Transfer Learning / Pre-training\n- Pre-train on full dataset, fine-tune for single solvent task\n- Use reaction transformer models if available\n\n### Feature Selection\n- With small datasets, fewer features can improve generalization\n- Consider PCA on high-dimensional features (drfps, fragprints)\n- spange_descriptors (13 features) may be optimal for this dataset size\n\n### Uncertainty-Aware Models\n- Bayesian approaches can help with small data\n- MC Dropout for uncertainty estimation\n- Ensemble disagreement as uncertainty proxy\n\n## Recommended Approach (Priority Order)\n\n1. **Physics-informed features:** Add Arrhenius kinetics features (inv_temp, log_time, interaction)\n2. **Use spange_descriptors** as base solvent features (compact and effective)\n3. **MLP with BatchNorm** architecture with Sigmoid output\n4. **Apply symmetry TTA** for mixed solvent predictions\n5. **Bagging** multiple models (5-7) for more robust predictions\n6. **Use HuberLoss** instead of MSELoss for robustness to outliers\n7. **Consider Gaussian Processes** for better extrapolation to unseen solvents\n\n## Target Score\nBeat **0.017270** (lower is better). Current best public kernel achieves ~0.098, so significant improvement is needed. The gap suggests there may be room for:\n- Better feature engineering\n- More sophisticated models (GPs, transformers)\n- Better handling of the leave-one-out CV structure\n\n## Code Structure Reminder\n```python\n# Third-to-last cell: Single solvent task\nmodel = YourModel(data='single')  # ONLY change this line\nmodel.train_model(train_X, train_Y)\npredictions = model.predict(test_X)\n\n# Second-to-last cell: Full data task  \nmodel = YourModel(data='full')  # ONLY change this line\nmodel.train_model(train_X, train_Y)\npredictions = model.predict(test_X)\n\n# Last cell: Combine and save submission (DO NOT MODIFY)\n```\n\n## Key Insights from Top Kernels\n\n1. **Arrhenius kinetics kernel (0.098 score):**\n   - Physics-informed features (1/T, ln(t))\n   - Symmetry TTA for mixed solvents\n   - Bagging 7 MLP models\n   - BatchNorm + Dropout + Sigmoid\n   - HuberLoss\n\n2. **LightGBM approach:**\n   - Separate models per target\n   - Early stopping\n   - Good for interpretability\n\n3. **XGBoost approach:**\n   - Feature engineering: Reaction_Energy, B_Conc_Temp\n   - Post-processing: clip to [0,1]\n",
      "agent": "explorer",
      "timestamp": "2026-01-13T21:03:31.536979"
    },
    {
      "strategy": "# Catechol Reaction Yield Prediction - Strategy Guide (Loop 2)\n\n## Current Status\n- Best CV score: 0.0113 from exp_000 (Arrhenius Kinetics + MLP + TTA)\n- Best LB score: 0.0998 (from exp_000)\n- CV-LB gap: -0.0885 (MASSIVE - 9x worse on LB!)\n- Target to beat: 0.017270\n- Submissions remaining: 4/5\n\n## Response to Evaluator\n\n**Technical verdict was CONCERNS.** The evaluator correctly identified submission structure issues and lack of reproducibility seeds.\n\n**CRITICAL INSIGHT:** Our LB score of 0.0998 is actually competitive with the best public kernel (0.098). The massive CV-LB gap suggests our local CV calculation differs from how Kaggle evaluates. The target of 0.017270 is 6x better than any public kernel, suggesting either:\n1. A different metric interpretation\n2. Significant room for improvement through novel approaches\n\n## MANDATORY: Submission Structure Requirements\n\n**CRITICAL - MUST FOLLOW EXACTLY:**\n- The submission must follow the exact template structure from https://www.kaggle.com/code/josepablofolch/catechol-benchmark-hackathon-template\n- Last 3 cells must match the template exactly\n- Only the `model = MLPModel()` line can be changed to `model = YourModel(data='single')` or `model = YourModel(data='full')`\n- Model class must have `train_model(X, Y)` and `predict(X)` methods\n- predict() must return a tensor/array of shape [N, 3] with columns [Product 2, Product 3, SM]\n\n## Data Understanding\n\n**Reference notebooks:**\n- `exploration/eda.ipynb` - Feature distributions, target statistics\n- `exploration/evolver_loop1_lb_feedback.ipynb` - CV-LB gap analysis\n\n**Key Data Facts:**\n- Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV (24 folds)\n- Full/mixed solvent: 1227 samples, 13 solvent pairs, leave-one-ramp-out CV (13 folds)\n- Targets: SM, Product 2, Product 3 (yields as fractions 0-1)\n- Targets do NOT sum to 1 (mean ~0.8) - mass loss in reaction\n- Temperature range: 175-225\u00b0C, Residence Time: ~2-15 minutes\n\n## Recommended Approaches (Priority Order)\n\n### 1. PRIORITY: Tree-Based Per-Target Ensemble\nBased on the \"catechol strategy to get 0.11161\" kernel (LB 0.111):\n- **Different models per target:**\n  - SM: HistGradientBoostingRegressor (max_depth=7, max_iter=700, lr=0.04)\n  - Product 2 & 3: ExtraTreesRegressor (n_estimators=900, min_samples_leaf=2)\n- **Feature ensemble:** Combine acs_pca_descriptors (5 features) and spange_descriptors (13 features)\n- **Weighted average:** 0.65 * model1 + 0.35 * model2\n- **Post-processing:** Clip predictions to [0, 1]\n\n### 2. Multi-Model Ensemble (from \"mixall\" kernel)\nEnsemble of MLP + XGBoost + RandomForest + LightGBM:\n- StandardScaler preprocessing\n- Weighted ensemble (can optimize via Optuna)\n- Each model type captures different patterns\n\n### 3. Physics-Informed Features (Keep Using)\nThe Arrhenius kinetics features are well-motivated:\n```python\ninv_temp = 1000 / (Temperature + 273.15)  # Inverse temperature\nlog_time = np.log(Residence_Time + 1e-6)  # Log of time\ninteraction = inv_temp * log_time          # Interaction term\n```\n\n### 4. Symmetry TTA for Mixed Solvents (Keep Using)\nFor mixed solvents, predict twice and average:\n- Prediction 1: Input as (A, B, SolventB%)\n- Prediction 2: Input as (B, A, 1-SolventB%)\n- Final = (Pred1 + Pred2) / 2\n\n## What NOT to Try\n- Complex deep learning architectures (small data, risk of overfitting)\n- High-dimensional features (drfps: 2048, fragprints: 2133) without PCA\n- Normalizing targets to sum to 1 (they naturally don't)\n- Chasing local CV improvements without LB validation\n\n## Model Interface Template\n\n```python\nimport torch\nimport numpy as np\nimport pandas as pd\n\nclass YourModel:\n    def __init__(self, data='single'):\n        self.data_type = data\n        # Initialize your model components here\n    \n    def train_model(self, X_train, y_train):\n        # X_train: DataFrame with columns:\n        #   Single: ['Residence Time', 'Temperature', 'SOLVENT NAME']\n        #   Full: ['Residence Time', 'Temperature', 'SOLVENT A NAME', 'SOLVENT B NAME', 'SolventB%']\n        # y_train: DataFrame with ['Product 2', 'Product 3', 'SM']\n        pass\n    \n    def predict(self, X_test):\n        # Returns tensor/array of shape [N, 3]\n        # Columns must be [Product 2, Product 3, SM] in that order\n        return torch.tensor(predictions)\n```\n\n## Validation Notes\n- **DO NOT trust local CV** - it doesn't match LB\n- Focus on LB score as the true measure of progress\n- The target of 0.017270 is ambitious - try fundamentally different approaches\n- Submit to verify progress on LB before extensive optimization\n\n## Key Insights from Public Kernels\n\n1. **Arrhenius kinetics kernel (LB 0.098):** Physics-informed features, symmetry TTA, bagging MLPs\n2. **Per-target ensemble (LB 0.111):** Different models per target, tree-based, feature ensemble\n3. **mixall kernel:** Ensemble of MLP + XGBoost + RF + LightGBM\n\n## Next Experiment Recommendation\n\n**Implement a tree-based per-target ensemble** following the \"catechol strategy\" approach:\n1. Use HistGradientBoostingRegressor for SM target\n2. Use ExtraTreesRegressor for Product 2 and Product 3\n3. Ensemble predictions from acs_pca and spange descriptors\n4. Add Arrhenius kinetics features\n5. Clip predictions to [0, 1]\n\nThis approach is simpler, less prone to overfitting, and has shown good LB performance (0.111).",
      "agent": "evolver",
      "timestamp": "2026-01-13T21:46:08.617902"
    },
    {
      "strategy": "# Catechol Reaction Yield Prediction - Strategy Guide (Loop 2)\n\n## Current Status\n- Best CV score: 0.010986 from exp_001 (Tree-Based Per-Target Ensemble)\n- Best LB score: 0.0998 from exp_000 (MLP baseline)\n- CV-LB gap: CV ~0.011 vs LB ~0.10 (9x gap)\n- **Target: 0.017270** (5-6x better than best public LB of 0.098)\n\n## Response to Evaluator\n\n**Technical verdict was TRUSTWORTHY.** The evaluator correctly identified that the tree-based approach is sound and template-compliant.\n\n**Evaluator's top priority:** Submit exp_001 to verify CV-LB correlation. **DONE** - LB score was 0.0999, confirming similar gap as exp_000.\n\n**Key concerns raised:**\n1. CV-LB gap not understood - **ADDRESSED**: Analysis shows the gap is consistent. Our CV MSE of 0.011 corresponds to RMSE of ~0.105, which is close to LB ~0.10. The LB metric appears to be MSE but evaluated differently.\n2. Target analysis - The target of 0.017270 is 5-6x better than best public LB. This is a MASSIVE gap suggesting fundamentally different approaches are needed.\n\n## CRITICAL INSIGHT: The Target Gap\n\nThe target of 0.017270 is 5-6x better than the best public LB of 0.098. This is NOT achievable through incremental improvements. We need:\n1. **Fundamentally different modeling approaches** (not just hyperparameter tuning)\n2. **Better feature engineering** (domain-specific chemistry knowledge)\n3. **Novel ensemble strategies** (beyond simple averaging)\n\n## Data Understanding\n\n**Reference notebooks:**\n- `exploration/eda.ipynb` - Feature distributions, target statistics, CV structure\n- `exploration/evolver_loop2_lb_feedback.ipynb` - CV-LB gap analysis\n\n**Key Data Facts:**\n- Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV (24 folds)\n- Full/mixed solvent: 1227 samples, 13 solvent pairs, leave-one-ramp-out CV (13 folds)\n- Targets: SM, Product 2, Product 3 (yields as fractions 0-1)\n- **SM target has highest error** - RMSE 0.51 for single solvent vs 0.10 for full data\n- Targets do NOT sum to 1 (mean ~0.8) - mass loss in reaction\n\n## CRITICAL: Submission Structure Requirements\n\n**MANDATORY:** The submission must follow the exact structure of the benchmark template notebook.\n- The last three cells MUST remain unchanged except for the model definition line\n- `model = MLPModel()` can be replaced with a new model definition\n- Both single solvent and full (mixed) solvent tasks must be handled\n\n## Recommended Approaches (Priority Order)\n\n### 1. Gaussian Processes / Deep Kernel Learning (HIGH PRIORITY)\n**Why:** GPs excel at extrapolation to unseen data points (the core challenge here - predicting unseen solvents). With ~600-1200 samples, GPs are in their sweet spot.\n\n**Implementation:**\n- Use GPyTorch for scalable GP implementation\n- Try Deep Kernel Learning (DKL) - NN feature extractor + GP head\n- Consider multi-output GPs for correlated targets\n- Use Arrhenius features as inputs\n\n**Expected benefit:** Better uncertainty quantification and extrapolation to unseen solvents.\n\n### 2. Regressor Chains for Correlated Targets (MEDIUM PRIORITY)\n**Why:** SM, Product 2, Product 3 are chemically related (mass balance). Predicting one can inform the others.\n\n**Implementation:**\n- Order: SM \u2192 Product 2 \u2192 Product 3 (or optimize order)\n- Feed prediction of previous target as input to next\n- Use sklearn's RegressorChain or implement manually\n\n**Expected benefit:** Capture correlations between outputs.\n\n### 3. Advanced Feature Engineering (MEDIUM PRIORITY)\n**Why:** Current features may not capture all relevant chemistry.\n\n**Ideas:**\n- **Reaction kinetics features:** k = A * exp(-Ea/RT), use log(k) as feature\n- **Solvent interaction features:** Product of solvent descriptors\n- **Temperature-time interaction:** T * log(t), T^2, t^2\n- **Solvent polarity index:** Combine multiple descriptors into single polarity measure\n\n### 4. Ensemble Diversity (MEDIUM PRIORITY)\n**Why:** Current ensembles use similar models. More diversity = better generalization.\n\n**Ideas:**\n- Combine MLP + Trees + GP\n- Use different feature sets for different models\n- Stack with meta-learner (Ridge regression on OOF predictions)\n\n### 5. Per-Solvent or Per-Condition Models (LOW PRIORITY)\n**Why:** Different solvents may have different prediction characteristics.\n\n**Ideas:**\n- Cluster solvents by properties, train separate models per cluster\n- Use solvent-specific hyperparameters\n\n## What NOT to Try (Already Exhausted)\n\n1. **Basic MLP with BatchNorm** - Already tried, CV 0.011, LB 0.10\n2. **Tree-based per-target ensemble** - Already tried, CV 0.011, LB 0.10\n3. **Simple hyperparameter tuning** - Won't bridge 5-6x gap to target\n\n## Validation Strategy\n\n- **Single solvent:** Leave-one-solvent-out (24 folds)\n- **Full data:** Leave-one-ramp-out (13 folds)\n- **Same hyperparameters across all folds** (no per-fold tuning)\n- **Focus on reducing RMSE** (appears to be the LB metric)\n\n## Key Techniques from Public Kernels\n\n1. **Arrhenius kinetics features:** inv_temp, log_time, interaction\n2. **Symmetry TTA:** For mixed solvents, predict both (A,B) and (B,A), average\n3. **Data augmentation:** Train on both symmetric versions of mixed solvents\n4. **Per-target models:** Different model types for SM vs Products\n5. **Feature table ensemble:** Weighted average of ACS PCA and Spange descriptors\n\n## Next Experiment Priorities\n\n1. **Try Gaussian Processes** - Most promising for extrapolation\n2. **Try Regressor Chains** - Exploit target correlations\n3. **Try stacking ensemble** - Combine diverse models with meta-learner\n4. **Investigate per-fold errors** - Which solvents are hardest to predict?\n\n## Submissions Remaining: 3/5\n\nUse submissions strategically:\n- Submit when trying fundamentally different approach (GP, stacking)\n- Don't submit for small hyperparameter changes\n- Reserve at least 1 submission for final ensemble",
      "agent": "evolver",
      "timestamp": "2026-01-13T22:08:06.995799"
    }
  ],
  "feedback_history": [
    {
      "feedback": "## What I Understood\n\nThe junior researcher implemented a first baseline model combining several best practices from the competition kernels: physics-informed Arrhenius kinetics features (1/T, ln(t), interaction term), MLP with BatchNorm and Dropout, HuberLoss for robustness, symmetry TTA for mixed solvents, and bagging of 3 models. The hypothesis was that combining these techniques would create a strong baseline. The reported CV MSE of 0.011303 already beats the target of 0.017270.\n\n## Technical Execution Assessment\n\n**Validation**: The CV methodology is sound. Leave-one-solvent-out (24 folds) for single solvent and leave-one-ramp-out (13 folds) for full data matches the competition specification. The submission has the correct structure: 656 single solvent samples + 1227 full data samples = 1883 total rows.\n\n**Leakage Risk**: No evidence of leakage detected. The model is trained fresh for each fold, features are computed from training data only, and the same hyperparameters are used across all folds. The symmetry augmentation for mixed solvents is applied correctly (training on both A,B and B,A orderings, then TTA at inference).\n\n**Score Integrity**: Verified in notebook output:\n- Single Solvent CV MSE: 0.010916\n- Full Data CV MSE: 0.011510  \n- Overall CV MSE: 0.011303\nThe weighted average calculation is correct.\n\n**Code Quality**: \n- Seeds are not explicitly set for reproducibility - this could cause variance between runs\n- The notebook structure does NOT follow the required template format. The competition rules state the last three cells must match the template exactly, with only the model definition line changeable. The current notebook has a completely custom structure.\n\n**Verdict: CONCERNS**\n\nThe CV score is trustworthy, but the submission structure is non-compliant with competition rules. This is a critical issue that must be fixed before any Kaggle submission.\n\n## Strategic Assessment\n\n**Approach Fit**: Excellent. The approach leverages domain knowledge (Arrhenius kinetics for chemical reactions), exploits the physical symmetry of solvent mixtures, and uses appropriate regularization (BatchNorm, Dropout, HuberLoss) for the small dataset size (~600-1200 samples). The choice of spange_descriptors (13 features) over high-dimensional alternatives (drfps: 2048, fragprints: 2133) is sensible for this data size.\n\n**Effort Allocation**: Good prioritization. The researcher started with a strong baseline combining multiple proven techniques rather than iterating on marginal improvements. This is the right approach.\n\n**Assumptions**: \n1. Linear interpolation of solvent features for mixtures (A*(1-pct) + B*pct) - reasonable but could be improved\n2. Same architecture for single and mixed solvents - may not be optimal\n3. 200 epochs is sufficient - no early stopping or validation monitoring\n\n**Blind Spots**:\n1. **No per-fold variance reporting** - we don't know if some folds are much harder than others\n2. **No comparison to simpler baselines** - hard to know which components are contributing most\n3. **Gaussian Processes not explored** - the strategy notes suggest GPs could excel for extrapolation to unseen solvents\n4. **No feature importance analysis** - which Arrhenius features matter most?\n\n**Trajectory**: Very promising start. The CV score of 0.011303 already beats the target of 0.017270 by a significant margin (~35% improvement). However, this is a local CV score - we need to verify it holds on the actual leaderboard.\n\n## What's Working\n\n1. **Physics-informed features**: The Arrhenius kinetics features (inv_temp, log_time, interaction) are well-motivated by chemistry domain knowledge\n2. **Symmetry handling**: Both training augmentation and TTA for mixed solvents is a clever way to exploit physical invariance\n3. **Regularization choices**: BatchNorm, Dropout(0.2), HuberLoss, weight_decay are all appropriate for small data\n4. **Feature selection**: Using compact spange_descriptors (13 features) rather than high-dimensional alternatives\n\n## Key Concerns\n\n### 1. **CRITICAL: Submission Structure Non-Compliance**\n- **Observation**: The notebook does not follow the required template structure. The competition explicitly states: \"the submission must have the same last three cells as in the notebook template, with the only allowed change being the line where the model is defined.\"\n- **Why it matters**: A non-compliant submission will likely be disqualified or fail to score correctly on Kaggle.\n- **Suggestion**: Refactor the code to define a `SymmetricBaggedModel` class that inherits from `BaseModel` and can be instantiated with `model = SymmetricBaggedModel(data='single')` in the template's third-to-last cell. All custom logic (featurization, training, TTA) must be encapsulated in the model class.\n\n### 2. **No Reproducibility Seeds**\n- **Observation**: No random seeds are set for PyTorch, NumPy, or Python's random module.\n- **Why it matters**: Results may vary between runs, making it hard to compare experiments reliably.\n- **Suggestion**: Add `torch.manual_seed(42)`, `np.random.seed(42)`, and `torch.backends.cudnn.deterministic = True` at the start.\n\n### 3. **No Early Stopping or Validation Monitoring**\n- **Observation**: Training runs for a fixed 200 epochs without monitoring validation loss.\n- **Why it matters**: Could be overfitting or underfitting without knowing. Some folds may need more/fewer epochs.\n- **Suggestion**: Consider adding a small validation split (10%) for early stopping, or at least log training loss curves.\n\n### 4. **CV Score Not Yet Validated on Leaderboard**\n- **Observation**: The 0.011303 CV score is promising but hasn't been submitted to Kaggle.\n- **Why it matters**: CV-LB gaps can be significant, especially with leave-one-out CV on small data.\n- **Suggestion**: After fixing the submission structure, submit to verify the score holds.\n\n## Top Priority for Next Experiment\n\n**FIX THE SUBMISSION STRUCTURE IMMEDIATELY.** The current notebook cannot be submitted to Kaggle in its current form. Refactor the code to:\n\n1. Create a self-contained model class that encapsulates all logic (featurization, training, TTA)\n2. Ensure the class can be instantiated with `model = YourModel(data='single')` and `model = YourModel(data='full')`\n3. Use the exact last three cells from the template notebook\n4. Add reproducibility seeds\n\nOnce compliant, submit to Kaggle to verify the CV score translates to the leaderboard. The 0.011303 CV score is excellent and beats the target, but it means nothing if we can't submit it.\n\nSecondary priorities for improvement after fixing compliance:\n- Add per-fold variance analysis to identify hard cases\n- Try Gaussian Processes for potentially better extrapolation\n- Experiment with deeper/wider architectures or different learning rate schedules\n- Consider ensemble with LightGBM for diversity\n",
      "experiment_id": "exp_000",
      "agent": "evaluator",
      "timestamp": "2026-01-13T21:40:58.650419"
    },
    {
      "feedback": "## What I Understood\n\nThe junior researcher implemented a tree-based per-target ensemble (exp_001) following my previous feedback to fix template compliance. The approach uses HistGradientBoostingRegressor for SM and ExtraTreesRegressor for Products 2 & 3, with Arrhenius kinetics features, spange + ACS PCA descriptors, symmetry TTA for mixed solvents, and proper reproducibility seeds. The notebook now correctly follows the template structure with the last three cells matching the required format. The CV score improved slightly from 0.011303 (exp_000) to 0.010986.\n\n## Technical Execution Assessment\n\n**Validation**: The CV methodology is sound. Leave-one-solvent-out (24 folds) for single solvent and leave-one-ramp-out (13 folds) for full data matches the competition specification exactly. Same hyperparameters are used across all folds - no per-fold tuning.\n\n**Leakage Risk**: None detected. The scaler is fit on training data only within each fold. Features are computed correctly. The symmetry augmentation for mixed solvents is applied properly (training on both A,B and B,A orderings, TTA at inference).\n\n**Score Integrity**: Verified in notebook output:\n- Single Solvent CV MSE: 0.011227\n- Full Data CV MSE: 0.010857  \n- Overall CV MSE: 0.010986\nThe weighted average calculation is correct: (0.011227 * 656 + 0.010857 * 1227) / 1883 \u2248 0.010986\n\n**Code Quality**: \n- Reproducibility seeds properly set (random, numpy, torch, cuda)\n- Template structure is now COMPLIANT - last three cells match the required format\n- Model class is self-contained and can be instantiated with `model = TreeEnsembleModel(data='single')` or `model = TreeEnsembleModel(data='full')`\n- Submission format is correct (1883 rows with proper columns)\n\n**Verdict: TRUSTWORTHY**\n\n## Strategic Assessment\n\n**Approach Fit**: Good choice. Tree-based models are appropriate for this tabular data with ~600-1200 samples. The per-target approach (different model types for SM vs Products) is reasonable given the different characteristics of these outputs. The Arrhenius features leverage domain knowledge effectively.\n\n**Effort Allocation**: The researcher correctly prioritized fixing template compliance (critical blocker) before further optimization. The switch from MLP to tree-based models is sensible for faster iteration (~50 seconds vs ~30 minutes).\n\n**Critical Issue - CV-LB Gap**: \nThe first experiment (exp_000) revealed a MASSIVE CV-LB gap: CV 0.0113 vs LB 0.0998 (9x difference). This is the elephant in the room. The best public kernel achieves LB 0.098, suggesting our LB score is actually competitive with the best public approaches. However, the target of 0.017270 is BELOW the best public kernel score.\n\n**Assumptions Being Made**:\n1. The local CV calculation matches the official metric - THIS MAY BE WRONG given the 9x gap\n2. Linear interpolation of solvent features for mixtures is optimal\n3. The same model architecture works for both single and mixed solvents\n\n**Blind Spots**:\n1. **The CV-LB gap is not understood** - This is the most critical issue. We need to understand why local CV doesn't translate to LB.\n2. **No submission of exp_001 yet** - We don't know if the tree-based approach has a similar CV-LB gap\n3. **The target of 0.017270 may require a fundamentally different approach** - If the best public kernel is at 0.098, how do we get to 0.017?\n\n**Trajectory**: The technical execution is solid, but we're potentially optimizing the wrong metric. The CV-LB gap suggests either:\n- Our CV calculation differs from the official metric\n- There's something fundamentally different about how Kaggle evaluates submissions\n- The target of 0.017270 might be achievable through approaches not yet explored\n\n## What's Working\n\n1. **Template compliance is now fixed** - The notebook can be submitted to Kaggle\n2. **Physics-informed features** - Arrhenius kinetics features are well-motivated\n3. **Symmetry handling** - Both training augmentation and TTA for mixed solvents\n4. **Fast iteration** - Tree-based models train in ~50 seconds vs ~30 minutes for MLP\n5. **Reproducibility** - Seeds properly set for deterministic results\n\n## Key Concerns\n\n### 1. **CRITICAL: CV-LB Gap Not Understood**\n- **Observation**: exp_000 showed CV 0.0113 vs LB 0.0998 - a 9x gap\n- **Why it matters**: We might be optimizing a metric that doesn't correlate with the leaderboard score. All our CV improvements could be meaningless.\n- **Suggestion**: Submit exp_001 immediately to see if tree-based models have a similar gap. Then investigate the official metric calculation - the competition uses \"catechol_hackathon_metric\" which may differ from simple MSE.\n\n### 2. **Target Score Analysis**\n- **Observation**: Target is 0.017270, but best public kernel achieves 0.098. Our LB score of 0.0998 is competitive with public kernels.\n- **Why it matters**: Either the target is achievable through approaches not yet tried, or there's something special about how the target was achieved.\n- **Suggestion**: Research what approaches could achieve 0.017 - this is 5-6x better than the best public kernel. Consider: (a) Gaussian Processes for better extrapolation, (b) Different feature engineering, (c) Ensemble of diverse models, (d) Understanding the official metric better.\n\n### 3. **No Per-Fold Variance Analysis**\n- **Observation**: We report overall CV MSE but not per-fold variance\n- **Why it matters**: Some solvents/ramps may be much harder to predict than others. Understanding this could guide feature engineering.\n- **Suggestion**: Add per-fold MSE reporting to identify hard cases and potential outliers.\n\n## Top Priority for Next Experiment\n\n**SUBMIT exp_001 TO KAGGLE IMMEDIATELY.** We need to understand if the tree-based approach has a similar CV-LB gap as the MLP. This is critical information before investing more time in CV optimization.\n\nAfter submission, the priority should be:\n1. **Investigate the official metric** - The competition uses \"catechol_hackathon_metric\". Is it different from MSE? Does it weight tasks differently?\n2. **Analyze per-fold performance** - Which solvents/ramps are hardest to predict?\n3. **Try fundamentally different approaches** - If the target is 0.017 and best public is 0.098, we need something different:\n   - Gaussian Processes for better extrapolation to unseen solvents\n   - Deep Kernel Learning combining NN features with GP uncertainty\n   - Ensemble of diverse model families (MLP + Trees + GP)\n   - Different solvent featurization (drfps, fragprints instead of spange)\n\nThe CV score of 0.010986 is excellent, but it means nothing if it doesn't translate to the leaderboard. We have 4 submissions remaining - use one to validate the tree-based approach before further optimization.\n",
      "experiment_id": "exp_001",
      "agent": "evaluator",
      "timestamp": "2026-01-13T21:51:09.423081"
    }
  ],
  "data_findings": [
    {
      "finding": "Arrhenius Kinetics approach: Add 1/Temperature (in Kelvin), ln(Time), and their interaction as features. This physics-informed feature engineering improves predictions.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Chemical Symmetry TTA: For mixed solvents, predict twice - once with (A,B) and once with (B,A) flipped, then average. This respects physical symmetry of mixtures.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Bagging ensemble of 7 MLP models with BatchNorm, Dropout(0.2), HuberLoss, and Sigmoid output activation. Uses ReduceLROnPlateau scheduler.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Data augmentation for mixed solvents: Train on both (A,B) and (B,A) symmetric versions of the data to double training set size.",
      "source": "../research/kernels/sanidhyavijay24_arrhenius-kinetics-tta-0-09831/arrhenius-kinetics-tta-0-09831.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "LightGBM approach: Use 3 separate LightGBM regressors (one per target), with early stopping (100 rounds patience), learning_rate=0.03, max_depth=6, and regularization. Uses spange_descriptors features.",
      "source": "../research/kernels/tobimichigan_catechol-pipeline-with-lightgbm/catechol-pipeline-with-lightgbm.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Feature engineering ideas: Reaction_Energy = Temperature * Residence Time, B_Conc_Temp = SolventB% * Temperature. Post-processing: clip predictions to [0,1] and normalize rows to sum to 1.",
      "source": "../research/kernels/mr0106_catechol/catechol.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Targets (SM, Product 2, Product 3) do NOT sum to 1 - mean sum is ~0.8 with range 0.03-1.12. This indicates mass loss in the reaction - don't force normalization to 1.",
      "source": "exploration/eda.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Single solvent CV: 24 folds (leave-one-solvent-out), ~27 samples per test fold. Full data CV: 13 folds (leave-one-ramp-out), ~94 samples per test fold.",
      "source": "exploration/eda.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Feature dimensions: spange_descriptors (13 features), acs_pca (5 features), drfps (2048 features), fragprints (2133 features). Spange is most compact and commonly used.",
      "source": "exploration/eda.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Multi-output regression: For correlated targets like chemical yields, consider regressor chains (feed one prediction as input to next), joint multi-output models, or Curds & Whey post-processing for linear shrinkage.",
      "source": "Web search: multi-output regression techniques",
      "agent": "explorer"
    },
    {
      "finding": "Gaussian Processes excel for small datasets (~600-1200 samples) and provide uncertainty quantification. Deep Kernel Learning (DKL) combines NN feature learning with GP uncertainty for best of both worlds.",
      "source": "Web search: Gaussian Processes vs Neural Networks for chemistry",
      "agent": "explorer"
    },
    {
      "finding": "CRITICAL CV-LB GAP: CV 0.0113 vs LB 0.0998 (9x gap). The best public kernel achieves LB 0.098, suggesting our LB score is actually competitive. The CV calculation may not match how Kaggle evaluates. The target of 0.017270 is BELOW the best public kernel score of 0.098, suggesting the target might be achievable through different approaches or the target represents a different metric.",
      "source": "exploration/evolver_loop1_lb_feedback.ipynb",
      "agent": "evolver"
    },
    {
      "finding": "Competition uses custom 'catechol_hackathon_metric' for evaluation. The submission format includes fold, row, target_1, target_2, target_3 columns. The CV procedure is: (a) leave-one-solvent-out for single solvent data (24 folds), (b) leave-one-ramp-out for mixture data (13 folds). The LB score of 0.0998 is close to the best public kernel (0.098), suggesting our model is competitive but our local CV calculation may differ from the official metric.",
      "source": "research/description.md",
      "agent": "evolver"
    },
    {
      "finding": "CV-LB gap of 9x (0.011 vs 0.0998) is consistent with best public kernels (~0.098 LB). The LB metric appears to be MAE not MSE - if LB is MAE=0.0998, our CV MSE=0.011 gives estimated MAE~0.105 which is close.",
      "source": "exploration/evolver_loop2_analysis.ipynb",
      "agent": "evolver"
    },
    {
      "finding": "Target of 0.017270 is 5-6x better than best public LB of 0.098 - this is a HUGE gap suggesting either a fundamentally different approach is needed or the target represents a different evaluation.",
      "source": "exploration/evolver_loop2_analysis.ipynb",
      "agent": "evolver"
    },
    {
      "finding": "SM target has much higher variance (0.13-0.14) than Product 2 (0.02) and Product 3 (0.02). This suggests SM is harder to predict and may dominate the error.",
      "source": "exploration/evolver_loop2_analysis.ipynb",
      "agent": "evolver"
    },
    {
      "finding": "LB metric appears to be MSE (not RMSE). Our Full Data CV MSE of 0.0109 matches LB score of 0.0999 closely. The Single Solvent task has much higher error (MSE 0.109) due to leave-one-solvent-out being harder. SM target has highest error (RMSE 0.51 for single solvent) - this is the main source of error.",
      "source": "exploration/evolver_loop2_lb_feedback.ipynb",
      "agent": "evolver"
    },
    {
      "finding": "Per-target ensemble with weighted averaging (0.65 ACS PCA + 0.35 Spange) achieves LB 0.11161. Uses HGB for SM target and ExtraTrees for Products. Key insight: different feature tables work better for different targets.",
      "source": "research/kernels/dabansherwani_catechol-strategy-to-get-0-11161",
      "agent": "evolver"
    }
  ],
  "web_research": [
    {
      "query": "What are the best machine learning approaches for predicting chemical reaction yields with small datasets?",
      "finding": "Predicting reaction yields when only a few hundred or fewer examples are available requires models that can extract maximal information from limited data and that can express their confidence.  Recent work shows that **transfer\u2011learning\u2011based transformers** fine\u2011tuned on a small, augmented set of reactions are among the most reliable choices.  By representing a reaction as a text string (e.g., SMILES) and pre\u2011training on millions of generic reactions, the model learns a rich chemical language; a modest amount of task\u2011specific data (\u22482\u20135\u202f% of the original high\u2011throughput set) is then sufficient to outperform physics\u2011based descriptor models, especially when test\u2011time augmentation is used to generate uncertainty estimates that correlate with prediction error\u30102\u2020https://research.ibm.com/publications/low-data-regime-yield-predictions-with-uncertainty-estimation-using-deep-learning-approaches\u3011.  The same strategy is highlighted in a broader review of low\u2011data limits, which recommends fine\u2011tun",
      "agent": "explorer"
    },
    {
      "query": "How do Gaussian Processes perform for chemical reaction yield prediction compared to neural networks?",
      "finding": "Gaussian\u2011process (GP) models excel when only a few hundred reaction datapoints are available: a GP regression trained on 100\u2013150 experimental rate constants predicted activation\u2011energy barriers with a mean absolute error of\u202f0.77\u202fkcal\u202fmol\u207b\u00b9 and supplied calibrated error bars for risk assessment\u202f([ScienceDirect\u202f2023](https://www.sciencedirect.com/science/article/pii/S1093326322002352)). This uncertainty quantification and exact Bayesian optimisation make GPs attractive for low\u2011data yield or barrier predictions, but the O(n\u00b3) scaling of exact inference limits their use on larger reaction libraries\u202f([Quora\u202f2012](https://www.quora.com/What-are-some-advantages-of-using-Gaussian-Process-Models-vs-Neural-Networks)).\n\nNeural\u2011network approaches\u2014especially long\u2011short\u2011term memory (LSTM) and graph neural networks (GNNs)\u2014have achieved comparable or better point\u2011prediction accuracy on richer datasets. For ten Buchwald\u2011Hartwig couplings, an LSTM model predicted the instantaneous yield with a mean abso",
      "agent": "explorer"
    },
    {
      "query": "What are the best techniques for multi-output regression when targets are correlated chemical yields?",
      "finding": "Multi\u2011output regression aims to predict several continuous targets at once, and when those targets are chemically linked (e.g., yields of related reactions) exploiting their correlation can markedly improve accuracy.  The literature groups the most effective approaches into **problem\u2011transformation** methods\u2014where a standard univariate learner is applied to a reshaped target set\u2014and **algorithm\u2011adaptation** methods that modify the learning algorithm to handle multiple outputs directly\u202f([PDF\u202fsurvey](https://oa.upm.es/40804/1/INVE_MEM_2015_204213.pdf)).\n\nFor correlated chemical yields, the top\u2011performing techniques are:\n\n* **Regressor\u2011chain and stacking variants** that feed the prediction of one yield as an input to the next, thereby transferring information along the chain\u202f([Multi\u2011target SVR via correlation regressor chains](https://www.sciencedirect.com/science/article/abs/pii/S0020025517307946)).  \n* **Multi\u2011output support\u2011vector regression**, especially Bayesian formulations that mod",
      "agent": "explorer"
    },
    {
      "query": "What is the evaluation metric for the Catechol Benchmark Hackathon Kaggle competition?",
      "finding": "The provided search results do not contain information about the evaluation metric used for the Catechol Benchmark Hackathon Kaggle competition. ([Kaggle\u202fdocs](https://www.kaggle.com/docs/competitions-setup), [Kaggle\u202fbenchmarks](https://www.kaggle.com/benchmarks))",
      "agent": "evolver"
    },
    {
      "query": "What is the catechol_hackathon_metric evaluation metric in the Catechol Benchmark Hackathon Kaggle competition?",
      "finding": "The provided sources do not specify what the\u202fcatechol_hackathon_metric\u202fevaluation metric is for the Catechol Benchmark Hackathon competition. ([openreview.net](https://openreview.net/pdf?id=6l8q74TabE))",
      "agent": "evolver"
    },
    {
      "query": "What is the catechol_hackathon_metric evaluation metric in Kaggle competition? How is it calculated?",
      "finding": "The provided search results do not contain information about the\u202fcatechol_hackathon_metric\u202for how it is calculated. ([kaggle\u2011metrics.readthedocs.io](https://kaggle-metrics.readthedocs.io))",
      "agent": "evolver"
    }
  ],
  "max_submissions": 5,
  "remaining_submissions": 3
}