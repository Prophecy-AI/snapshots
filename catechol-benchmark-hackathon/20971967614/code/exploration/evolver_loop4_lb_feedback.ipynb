{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdc7796",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "## Key Results\n",
    "- **exp_003 (Stacking)**: CV 0.0103 → LB 0.0949\n",
    "- This is our BEST LB score yet!\n",
    "\n",
    "## Submission History\n",
    "| Exp | Model | CV MSE | LB Score | CV-LB Gap |\n",
    "|-----|-------|--------|----------|----------|\n",
    "| exp_000 | MLP | 0.0113 | 0.0998 | -0.0885 |\n",
    "| exp_001 | Trees | 0.0110 | 0.0999 | -0.0889 |\n",
    "| exp_003 | Stacking | 0.0103 | 0.0949 | -0.0846 |\n",
    "\n",
    "## Critical Insights\n",
    "1. **CV improvements DO translate to LB improvements!**\n",
    "   - CV improved from 0.0113 → 0.0103 (9% better)\n",
    "   - LB improved from 0.0998 → 0.0949 (5% better)\n",
    "\n",
    "2. **The gap is shrinking!**\n",
    "   - exp_000: gap = 0.0885\n",
    "   - exp_003: gap = 0.0846\n",
    "   - This suggests we're on the right track\n",
    "\n",
    "3. **Target analysis:**\n",
    "   - Target: 0.017270\n",
    "   - Best LB: 0.0949\n",
    "   - Gap to target: 5.5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0cf725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:19.919650Z",
     "iopub.status.busy": "2026-01-13T23:05:19.919235Z",
     "iopub.status.idle": "2026-01-13T23:05:20.254696Z",
     "shell.execute_reply": "2026-01-13T23:05:20.254268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "    exp    model  cv_mse     lb  cv_rmse    gap\n",
      "exp_000      MLP  0.0113 0.0998 0.106301 0.0885\n",
      "exp_001    Trees  0.0110 0.0999 0.104881 0.0889\n",
      "exp_003 Stacking  0.0103 0.0949 0.101489 0.0846\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'model': 'MLP', 'cv_mse': 0.0113, 'lb': 0.0998},\n",
    "    {'exp': 'exp_001', 'model': 'Trees', 'cv_mse': 0.0110, 'lb': 0.0999},\n",
    "    {'exp': 'exp_003', 'model': 'Stacking', 'cv_mse': 0.0103, 'lb': 0.0949},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "df['cv_rmse'] = np.sqrt(df['cv_mse'])\n",
    "df['gap'] = df['lb'] - df['cv_mse']\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aad7164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.255854Z",
     "iopub.status.busy": "2026-01-13T23:05:20.255703Z",
     "iopub.status.idle": "2026-01-13T23:05:20.259750Z",
     "shell.execute_reply": "2026-01-13T23:05:20.259355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV RMSE vs LB comparison:\n",
      "exp_000: CV RMSE = 0.1063, LB = 0.0998, diff = 0.0065\n",
      "exp_001: CV RMSE = 0.1049, LB = 0.0999, diff = 0.0050\n",
      "exp_003: CV RMSE = 0.1015, LB = 0.0949, diff = 0.0066\n",
      "\n",
      "The CV RMSE values are close to LB scores!\n",
      "This confirms LB metric is likely RMSE.\n",
      "\n",
      "Target: 0.01727\n",
      "Best LB: 0.0949\n",
      "Gap to target: 5.5x\n"
     ]
    }
   ],
   "source": [
    "# Key insight: LB is likely RMSE, not MSE\n",
    "# Let's verify:\n",
    "print(\"\\nCV RMSE vs LB comparison:\")\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"{row['exp']}: CV RMSE = {row['cv_rmse']:.4f}, LB = {row['lb']:.4f}, diff = {abs(row['cv_rmse'] - row['lb']):.4f}\")\n",
    "\n",
    "print(\"\\nThe CV RMSE values are close to LB scores!\")\n",
    "print(\"This confirms LB metric is likely RMSE.\")\n",
    "\n",
    "# Target analysis\n",
    "target = 0.017270\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Best LB: {df['lb'].min()}\")\n",
    "print(f\"Gap to target: {df['lb'].min() / target:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97f4bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.260867Z",
     "iopub.status.busy": "2026-01-13T23:05:20.260588Z",
     "iopub.status.idle": "2026-01-13T23:05:20.263956Z",
     "shell.execute_reply": "2026-01-13T23:05:20.263573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PROGRESS ANALYSIS ===\n",
      "\n",
      "LB improvement from exp_000 to exp_003:\n",
      "  exp_000 LB: 0.0998\n",
      "  exp_003 LB: 0.0949\n",
      "  Improvement: 4.9%\n",
      "\n",
      "CV improvement from exp_000 to exp_003:\n",
      "  exp_000 CV: 0.0113\n",
      "  exp_003 CV: 0.0103\n",
      "  Improvement: 8.8%\n",
      "\n",
      "CV improvements ARE translating to LB improvements!\n",
      "The stacking ensemble is working!\n",
      "\n",
      "Next steps: Continue improving CV to improve LB.\n"
     ]
    }
   ],
   "source": [
    "# Progress analysis\n",
    "print(\"\\n=== PROGRESS ANALYSIS ===\")\n",
    "print(f\"\\nLB improvement from exp_000 to exp_003:\")\n",
    "print(f\"  exp_000 LB: 0.0998\")\n",
    "print(f\"  exp_003 LB: 0.0949\")\n",
    "print(f\"  Improvement: {(0.0998 - 0.0949) / 0.0998 * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nCV improvement from exp_000 to exp_003:\")\n",
    "print(f\"  exp_000 CV: 0.0113\")\n",
    "print(f\"  exp_003 CV: 0.0103\")\n",
    "print(f\"  Improvement: {(0.0113 - 0.0103) / 0.0113 * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nCV improvements ARE translating to LB improvements!\")\n",
    "print(\"The stacking ensemble is working!\")\n",
    "print(\"\\nNext steps: Continue improving CV to improve LB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8802b4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.264875Z",
     "iopub.status.busy": "2026-01-13T23:05:20.264767Z",
     "iopub.status.idle": "2026-01-13T23:05:20.268462Z",
     "shell.execute_reply": "2026-01-13T23:05:20.268058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PATH TO TARGET ===\n",
      "\n",
      "Target: 0.01727\n",
      "Current best LB: 0.0949\n",
      "Gap: 5.5x\n",
      "\n",
      "If target is RMSE:\n",
      "  Target MSE would be: 0.000298\n",
      "  Current CV MSE: 0.0103\n",
      "  Need to reduce MSE by: 34.5x\n",
      "\n",
      "=== POSSIBLE APPROACHES ===\n",
      "1. High-dimensional features (drfps: 2048, fragprints: 2133)\n",
      "2. Regressor chains (predict SM first, use as input)\n",
      "3. Per-target optimization (SM has highest variance)\n",
      "4. More diverse ensemble (add LightGBM, XGBoost)\n",
      "5. Feature selection / dimensionality reduction\n"
     ]
    }
   ],
   "source": [
    "# What would it take to reach the target?\n",
    "target = 0.017270\n",
    "current_lb = 0.0949\n",
    "\n",
    "print(\"\\n=== PATH TO TARGET ===\")\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Current best LB: {current_lb}\")\n",
    "print(f\"Gap: {current_lb / target:.1f}x\")\n",
    "\n",
    "# If LB is RMSE, then target RMSE = 0.017270\n",
    "# This means target MSE = 0.017270^2 = 0.000298\n",
    "target_mse = target ** 2\n",
    "print(f\"\\nIf target is RMSE:\")\n",
    "print(f\"  Target MSE would be: {target_mse:.6f}\")\n",
    "print(f\"  Current CV MSE: 0.0103\")\n",
    "print(f\"  Need to reduce MSE by: {0.0103 / target_mse:.1f}x\")\n",
    "\n",
    "# This is a HUGE gap - 34x improvement needed\n",
    "# But wait - what if the target is achievable through a different approach?\n",
    "print(\"\\n=== POSSIBLE APPROACHES ===\")\n",
    "print(\"1. High-dimensional features (drfps: 2048, fragprints: 2133)\")\n",
    "print(\"2. Regressor chains (predict SM first, use as input)\")\n",
    "print(\"3. Per-target optimization (SM has highest variance)\")\n",
    "print(\"4. More diverse ensemble (add LightGBM, XGBoost)\")\n",
    "print(\"5. Feature selection / dimensionality reduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224a2e4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.269363Z",
     "iopub.status.busy": "2026-01-13T23:05:20.269244Z",
     "iopub.status.idle": "2026-01-13T23:05:20.284515Z",
     "shell.execute_reply": "2026-01-13T23:05:20.284123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA ANALYSIS ===\n",
      "\n",
      "Full data: 1227 samples\n",
      "Single solvent: 656 samples\n",
      "Total: 1883 samples\n",
      "\n",
      "Target statistics (single solvent):\n",
      "  SM: mean=0.5222, std=0.3602, var=0.1298\n",
      "  Product 2: mean=0.1499, std=0.1431, var=0.0205\n",
      "  Product 3: mean=0.1234, std=0.1315, var=0.0173\n",
      "\n",
      "Target statistics (full data):\n",
      "  SM: mean=0.4952, std=0.3794, var=0.1440\n",
      "  Product 2: mean=0.1646, std=0.1535, var=0.0236\n",
      "  Product 3: mean=0.1437, std=0.1458, var=0.0213\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze what we know about the data\n",
    "DATA_PATH = '/home/data'\n",
    "full_df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "single_df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "\n",
    "print(\"\\n=== DATA ANALYSIS ===\")\n",
    "print(f\"\\nFull data: {len(full_df)} samples\")\n",
    "print(f\"Single solvent: {len(single_df)} samples\")\n",
    "print(f\"Total: {len(full_df) + len(single_df)} samples\")\n",
    "\n",
    "# Target statistics\n",
    "print(\"\\nTarget statistics (single solvent):\")\n",
    "for col in ['SM', 'Product 2', 'Product 3']:\n",
    "    print(f\"  {col}: mean={single_df[col].mean():.4f}, std={single_df[col].std():.4f}, var={single_df[col].var():.4f}\")\n",
    "\n",
    "print(\"\\nTarget statistics (full data):\")\n",
    "for col in ['SM', 'Product 2', 'Product 3']:\n",
    "    print(f\"  {col}: mean={full_df[col].mean():.4f}, std={full_df[col].std():.4f}, var={full_df[col].var():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ef5fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.285541Z",
     "iopub.status.busy": "2026-01-13T23:05:20.285435Z",
     "iopub.status.idle": "2026-01-13T23:05:20.289280Z",
     "shell.execute_reply": "2026-01-13T23:05:20.288879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VARIANCE ANALYSIS ===\n",
      "\n",
      "Single solvent variance:\n",
      "  SM: 0.1298 (77.4% of total)\n",
      "  Product 2: 0.0205 (12.2% of total)\n",
      "  Product 3: 0.0173 (10.3% of total)\n",
      "\n",
      "SM contributes ~80% of the total variance!\n",
      "Improving SM prediction is the key to reducing overall error.\n"
     ]
    }
   ],
   "source": [
    "# SM has highest variance - this is the main source of error\n",
    "# Let's calculate the contribution of each target to the overall MSE\n",
    "\n",
    "# If we assume equal MSE per target:\n",
    "# Overall MSE = (MSE_SM + MSE_P2 + MSE_P3) / 3\n",
    "# But SM has higher variance, so it likely contributes more\n",
    "\n",
    "# Variance-based analysis:\n",
    "var_sm_single = single_df['SM'].var()\n",
    "var_p2_single = single_df['Product 2'].var()\n",
    "var_p3_single = single_df['Product 3'].var()\n",
    "\n",
    "print(\"\\n=== VARIANCE ANALYSIS ===\")\n",
    "print(f\"\\nSingle solvent variance:\")\n",
    "print(f\"  SM: {var_sm_single:.4f} ({var_sm_single / (var_sm_single + var_p2_single + var_p3_single) * 100:.1f}% of total)\")\n",
    "print(f\"  Product 2: {var_p2_single:.4f} ({var_p2_single / (var_sm_single + var_p2_single + var_p3_single) * 100:.1f}% of total)\")\n",
    "print(f\"  Product 3: {var_p3_single:.4f} ({var_p3_single / (var_sm_single + var_p2_single + var_p3_single) * 100:.1f}% of total)\")\n",
    "\n",
    "print(\"\\nSM contributes ~80% of the total variance!\")\n",
    "print(\"Improving SM prediction is the key to reducing overall error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2483da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.290190Z",
     "iopub.status.busy": "2026-01-13T23:05:20.290080Z",
     "iopub.status.idle": "2026-01-13T23:05:20.339423Z",
     "shell.execute_reply": "2026-01-13T23:05:20.339025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AVAILABLE FEATURES ===\n",
      "  spange_descriptors_lookup.csv: 13 features, 26 solvents\n",
      "  acs_pca_descriptors_lookup.csv: 5 features, 24 solvents\n",
      "  drfps_catechol_lookup.csv: 2048 features, 24 solvents\n",
      "  fragprints_lookup.csv: 2133 features, 24 solvents\n",
      "\n",
      "High-dimensional features (drfps, fragprints) are unexplored!\n",
      "These could capture chemistry better than low-dimensional descriptors.\n"
     ]
    }
   ],
   "source": [
    "# Feature analysis - what features are available?\n",
    "import os\n",
    "\n",
    "print(\"\\n=== AVAILABLE FEATURES ===\")\n",
    "feature_files = [\n",
    "    'spange_descriptors_lookup.csv',\n",
    "    'acs_pca_descriptors_lookup.csv',\n",
    "    'drfps_catechol_lookup.csv',\n",
    "    'fragprints_lookup.csv',\n",
    "]\n",
    "\n",
    "for f in feature_files:\n",
    "    path = f'{DATA_PATH}/{f}'\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "        print(f\"  {f}: {df.shape[1]} features, {df.shape[0]} solvents\")\n",
    "\n",
    "print(\"\\nHigh-dimensional features (drfps, fragprints) are unexplored!\")\n",
    "print(\"These could capture chemistry better than low-dimensional descriptors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2b9e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T23:05:20.340531Z",
     "iopub.status.busy": "2026-01-13T23:05:20.340418Z",
     "iopub.status.idle": "2026-01-13T23:05:20.344146Z",
     "shell.execute_reply": "2026-01-13T23:05:20.343711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATEGY FOR NEXT EXPERIMENTS\n",
      "============================================================\n",
      "\n",
      "1. PRIORITY: Improve SM prediction\n",
      "   - SM contributes ~80% of variance\n",
      "   - Focus models on SM target\n",
      "   - Try regressor chain: predict SM first, use as input for Products\n",
      "\n",
      "2. HIGH-DIMENSIONAL FEATURES\n",
      "   - drfps (2048 features): Differential reaction fingerprints\n",
      "   - fragprints (2133 features): Fragment + fingerprint\n",
      "   - These may capture chemistry better\n",
      "   - Use PCA or feature selection to reduce dimensionality\n",
      "\n",
      "3. ENSEMBLE OPTIMIZATION\n",
      "   - Current: 50/50 MLP + Trees\n",
      "   - Try: 60/40, 70/30, or learned weights\n",
      "   - Add more diverse models: LightGBM, XGBoost, CatBoost\n",
      "\n",
      "4. REGRESSOR CHAINS\n",
      "   - Targets are correlated (chemical yields)\n",
      "   - Predict SM first (highest variance)\n",
      "   - Use SM prediction as input for Products\n",
      "\n",
      "5. REMAINING SUBMISSIONS: 2\n",
      "   - Use wisely to verify progress\n",
      "   - Submit only when CV improves significantly\n"
     ]
    }
   ],
   "source": [
    "# Strategy for next experiments\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY FOR NEXT EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. PRIORITY: Improve SM prediction\")\n",
    "print(\"   - SM contributes ~80% of variance\")\n",
    "print(\"   - Focus models on SM target\")\n",
    "print(\"   - Try regressor chain: predict SM first, use as input for Products\")\n",
    "\n",
    "print(\"\\n2. HIGH-DIMENSIONAL FEATURES\")\n",
    "print(\"   - drfps (2048 features): Differential reaction fingerprints\")\n",
    "print(\"   - fragprints (2133 features): Fragment + fingerprint\")\n",
    "print(\"   - These may capture chemistry better\")\n",
    "print(\"   - Use PCA or feature selection to reduce dimensionality\")\n",
    "\n",
    "print(\"\\n3. ENSEMBLE OPTIMIZATION\")\n",
    "print(\"   - Current: 50/50 MLP + Trees\")\n",
    "print(\"   - Try: 60/40, 70/30, or learned weights\")\n",
    "print(\"   - Add more diverse models: LightGBM, XGBoost, CatBoost\")\n",
    "\n",
    "print(\"\\n4. REGRESSOR CHAINS\")\n",
    "print(\"   - Targets are correlated (chemical yields)\")\n",
    "print(\"   - Predict SM first (highest variance)\")\n",
    "print(\"   - Use SM prediction as input for Products\")\n",
    "\n",
    "print(\"\\n5. REMAINING SUBMISSIONS: 2\")\n",
    "print(\"   - Use wisely to verify progress\")\n",
    "print(\"   - Submit only when CV improves significantly\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
