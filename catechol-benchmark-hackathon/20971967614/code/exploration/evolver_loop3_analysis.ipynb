{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06e50a1",
   "metadata": {},
   "source": [
    "# Loop 3 Analysis: Understanding the CV-LB Gap and Next Steps\n",
    "\n",
    "## Key Observations:\n",
    "1. GP model (exp_002) achieved CV 0.017921 - WORSE than tree-based (0.010986)\n",
    "2. CV-LB gap is ~9x (CV 0.011 vs LB 0.0998)\n",
    "3. Both submissions have nearly identical LB scores (~0.0998-0.0999)\n",
    "4. Target of 0.017270 is 5.7x better than best public LB of 0.098\n",
    "\n",
    "## Questions to Answer:\n",
    "1. What is the actual LB metric? (MSE? MAE? Weighted?)\n",
    "2. Why do different CV scores give similar LB scores?\n",
    "3. What approaches haven't been tried?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6d7534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.265468Z",
     "iopub.status.busy": "2026-01-13T22:19:44.265060Z",
     "iopub.status.idle": "2026-01-13T22:19:44.890030Z",
     "shell.execute_reply": "2026-01-13T22:19:44.889602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shapes:\n",
      "exp_000: (1883, 8)\n",
      "exp_001: (1883, 8)\n",
      "exp_002: (1883, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our submissions\n",
    "exp_000 = pd.read_csv('/home/code/experiments/001_baseline/submission.csv')\n",
    "exp_001 = pd.read_csv('/home/code/experiments/002_tree_ensemble/submission.csv')\n",
    "exp_002 = pd.read_csv('/home/code/experiments/003_gaussian_process/submission.csv')\n",
    "\n",
    "print('Submission shapes:')\n",
    "print(f'exp_000: {exp_000.shape}')\n",
    "print(f'exp_001: {exp_001.shape}')\n",
    "print(f'exp_002: {exp_002.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310f0214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.891162Z",
     "iopub.status.busy": "2026-01-13T22:19:44.891043Z",
     "iopub.status.idle": "2026-01-13T22:19:44.896504Z",
     "shell.execute_reply": "2026-01-13T22:19:44.896091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Statistics ===\n",
      "\n",
      "exp_000 (MLP):\n",
      "  target_1: mean=0.1626, std=0.1392, min=0.0001, max=0.4477\n",
      "  target_2: mean=0.1392, std=0.1279, min=0.0001, max=0.4257\n",
      "  target_3: mean=0.5162, std=0.3495, min=0.0000, max=0.9983\n",
      "\n",
      "exp_001 (Trees):\n",
      "  target_1: mean=0.1560, std=0.1307, min=0.0000, max=0.4402\n",
      "  target_2: mean=0.1425, std=0.1193, min=0.0000, max=0.4130\n",
      "  target_3: mean=0.5074, std=0.3581, min=0.0000, max=1.0000\n",
      "\n",
      "exp_002 (GP):\n",
      "  target_1: mean=0.1410, std=0.1177, min=0.0000, max=0.4018\n",
      "  target_2: mean=0.1282, std=0.1022, min=0.0000, max=0.4345\n",
      "  target_3: mean=0.5473, std=0.3381, min=0.0000, max=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions between experiments\n",
    "print('\\n=== Prediction Statistics ===')\n",
    "for name, df in [('exp_000 (MLP)', exp_000), ('exp_001 (Trees)', exp_001), ('exp_002 (GP)', exp_002)]:\n",
    "    print(f'\\n{name}:')\n",
    "    for col in ['target_1', 'target_2', 'target_3']:\n",
    "        print(f'  {col}: mean={df[col].mean():.4f}, std={df[col].std():.4f}, min={df[col].min():.4f}, max={df[col].max():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8010e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.897461Z",
     "iopub.status.busy": "2026-01-13T22:19:44.897351Z",
     "iopub.status.idle": "2026-01-13T22:19:44.902030Z",
     "shell.execute_reply": "2026-01-13T22:19:44.901598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Differences (MLP vs Trees) ===\n",
      "target_1: mean_diff=0.028663, max_diff=0.165259\n",
      "target_2: mean_diff=0.030274, max_diff=0.191224\n",
      "target_3: mean_diff=0.061630, max_diff=0.441261\n",
      "\n",
      "=== Prediction Differences (MLP vs GP) ===\n",
      "target_1: mean_diff=0.045911, max_diff=0.304992\n",
      "target_2: mean_diff=0.051088, max_diff=0.266612\n",
      "target_3: mean_diff=0.068739, max_diff=0.524555\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions between MLP and Trees\n",
    "print('\\n=== Prediction Differences (MLP vs Trees) ===')\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    diff = (exp_000[col] - exp_001[col]).abs()\n",
    "    print(f'{col}: mean_diff={diff.mean():.6f}, max_diff={diff.max():.6f}')\n",
    "\n",
    "print('\\n=== Prediction Differences (MLP vs GP) ===')\n",
    "for col in ['target_1', 'target_2', 'target_3']:\n",
    "    diff = (exp_000[col] - exp_002[col]).abs()\n",
    "    print(f'{col}: mean_diff={diff.mean():.6f}, max_diff={diff.max():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c73ebe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.903246Z",
     "iopub.status.busy": "2026-01-13T22:19:44.903140Z",
     "iopub.status.idle": "2026-01-13T22:19:44.917264Z",
     "shell.execute_reply": "2026-01-13T22:19:44.916881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "Single solvent: (656, 13)\n",
      "Full data: (1227, 19)\n",
      "\n",
      "=== Target Statistics (Single Solvent) ===\n",
      "Product 2: mean=0.1499, std=0.1431\n",
      "Product 3: mean=0.1234, std=0.1315\n",
      "SM: mean=0.5222, std=0.3602\n",
      "\n",
      "=== Target Statistics (Full Data) ===\n",
      "Product 2: mean=0.1646, std=0.1535\n",
      "Product 3: mean=0.1437, std=0.1458\n",
      "SM: mean=0.4952, std=0.3794\n"
     ]
    }
   ],
   "source": [
    "# Load actual data to compute per-target errors\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "df_single = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "df_full = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "\n",
    "print('Data shapes:')\n",
    "print(f'Single solvent: {df_single.shape}')\n",
    "print(f'Full data: {df_full.shape}')\n",
    "\n",
    "# Target statistics\n",
    "print('\\n=== Target Statistics (Single Solvent) ===')\n",
    "for col in ['Product 2', 'Product 3', 'SM']:\n",
    "    print(f'{col}: mean={df_single[col].mean():.4f}, std={df_single[col].std():.4f}')\n",
    "\n",
    "print('\\n=== Target Statistics (Full Data) ===')\n",
    "for col in ['Product 2', 'Product 3', 'SM']:\n",
    "    print(f'{col}: mean={df_full[col].mean():.4f}, std={df_full[col].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b74bc81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.918217Z",
     "iopub.status.busy": "2026-01-13T22:19:44.918113Z",
     "iopub.status.idle": "2026-01-13T22:19:44.921320Z",
     "shell.execute_reply": "2026-01-13T22:19:44.920891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV-LB Gap Analysis ===\n",
      "\n",
      "Submission History:\n",
      "exp_000 (MLP): CV=0.0113, LB=0.0998 → gap=8.8x\n",
      "exp_001 (Trees): CV=0.0110, LB=0.0999 → gap=9.1x\n",
      "\n",
      "Key Insight:\n",
      "Both submissions have nearly identical LB scores (~0.0998-0.0999)\n",
      "despite different CV scores (0.0113 vs 0.0110).\n",
      "This suggests the LB metric may be different from our CV MSE calculation.\n",
      "\n",
      "Possible explanations:\n",
      "1. LB uses a different metric (MAE? weighted MSE?)\n",
      "2. LB only evaluates a subset of predictions\n",
      "3. LB weights tasks differently (single vs full)\n",
      "4. Our models are overfitting to CV procedure\n"
     ]
    }
   ],
   "source": [
    "# Analyze the CV-LB gap\n",
    "print('\\n=== CV-LB Gap Analysis ===')\n",
    "print('\\nSubmission History:')\n",
    "print('exp_000 (MLP): CV=0.0113, LB=0.0998 → gap=8.8x')\n",
    "print('exp_001 (Trees): CV=0.0110, LB=0.0999 → gap=9.1x')\n",
    "\n",
    "print('\\nKey Insight:')\n",
    "print('Both submissions have nearly identical LB scores (~0.0998-0.0999)')\n",
    "print('despite different CV scores (0.0113 vs 0.0110).')\n",
    "print('This suggests the LB metric may be different from our CV MSE calculation.')\n",
    "\n",
    "print('\\nPossible explanations:')\n",
    "print('1. LB uses a different metric (MAE? weighted MSE?)')\n",
    "print('2. LB only evaluates a subset of predictions')\n",
    "print('3. LB weights tasks differently (single vs full)')\n",
    "print('4. Our models are overfitting to CV procedure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3653fbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.922389Z",
     "iopub.status.busy": "2026-01-13T22:19:44.922274Z",
     "iopub.status.idle": "2026-01-13T22:19:44.925897Z",
     "shell.execute_reply": "2026-01-13T22:19:44.925445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target Analysis ===\n",
      "Target score: 0.017270\n",
      "Best public LB: ~0.098\n",
      "Gap: 5.7x\n",
      "\n",
      "If target is MSE:\n",
      "  Target RMSE: 0.1314 = 13.14%\n",
      "  Best public RMSE: 0.3130 = 31.30%\n",
      "\n",
      "If target is MAE:\n",
      "  Target MAE: 0.0173 = 1.73%\n",
      "  Best public MAE: 0.098 = 9.8%\n",
      "\n",
      "Conclusion:\n",
      "The target of 0.017270 is MUCH better than the best public LB.\n",
      "This suggests either:\n",
      "1. A fundamentally different approach is needed\n",
      "2. The target represents a different evaluation\n",
      "3. There is a breakthrough technique we have not discovered\n"
     ]
    }
   ],
   "source": [
    "# Check if the target of 0.017270 is achievable\n",
    "print('\\n=== Target Analysis ===')\n",
    "print(f'Target score: 0.017270')\n",
    "print(f'Best public LB: ~0.098')\n",
    "print(f'Gap: {0.098 / 0.017270:.1f}x')\n",
    "\n",
    "print('\\nIf target is MSE:')\n",
    "print(f'  Target RMSE: {np.sqrt(0.017270):.4f} = {np.sqrt(0.017270)*100:.2f}%')\n",
    "print(f'  Best public RMSE: {np.sqrt(0.098):.4f} = {np.sqrt(0.098)*100:.2f}%')\n",
    "\n",
    "print('\\nIf target is MAE:')\n",
    "print(f'  Target MAE: 0.0173 = 1.73%')\n",
    "print(f'  Best public MAE: 0.098 = 9.8%')\n",
    "\n",
    "print('\\nConclusion:')\n",
    "print('The target of 0.017270 is MUCH better than the best public LB.')\n",
    "print('This suggests either:')\n",
    "print('1. A fundamentally different approach is needed')\n",
    "print('2. The target represents a different evaluation')\n",
    "print('3. There is a breakthrough technique we have not discovered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8af097f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.926885Z",
     "iopub.status.busy": "2026-01-13T22:19:44.926771Z",
     "iopub.status.idle": "2026-01-13T22:19:44.930304Z",
     "shell.execute_reply": "2026-01-13T22:19:44.929873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Unexplored Approaches ===\n",
      "\n",
      "1. FEATURE ENGINEERING:\n",
      "   - drfps (2048 features) - differential reaction fingerprints\n",
      "   - fragprints (2133 features) - fragment + fingerprint\n",
      "   - Custom chemistry features (reaction SMILES)\n",
      "   - Feature selection/PCA on high-dim features\n",
      "\n",
      "2. MODEL ARCHITECTURES:\n",
      "   - Stacking ensemble (MLP + Trees + GP)\n",
      "   - Regressor chains (feed one prediction as input to next)\n",
      "   - Multi-output models with shared representations\n",
      "   - Transformer-based models for SMILES\n",
      "\n",
      "3. TRAINING STRATEGIES:\n",
      "   - Per-target optimization (different models for SM vs Products)\n",
      "   - Task-specific models (different for single vs full)\n",
      "   - Adversarial validation to identify distribution shift\n",
      "   - Pseudo-labeling or self-training\n",
      "\n",
      "4. POST-PROCESSING:\n",
      "   - Curds & Whey decorrelation\n",
      "   - Prediction calibration\n",
      "   - Ensemble blending with optimized weights\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print('\\n=== Unexplored Approaches ===')\n",
    "print('\\n1. FEATURE ENGINEERING:')\n",
    "print('   - drfps (2048 features) - differential reaction fingerprints')\n",
    "print('   - fragprints (2133 features) - fragment + fingerprint')\n",
    "print('   - Custom chemistry features (reaction SMILES)')\n",
    "print('   - Feature selection/PCA on high-dim features')\n",
    "\n",
    "print('\\n2. MODEL ARCHITECTURES:')\n",
    "print('   - Stacking ensemble (MLP + Trees + GP)')\n",
    "print('   - Regressor chains (feed one prediction as input to next)')\n",
    "print('   - Multi-output models with shared representations')\n",
    "print('   - Transformer-based models for SMILES')\n",
    "\n",
    "print('\\n3. TRAINING STRATEGIES:')\n",
    "print('   - Per-target optimization (different models for SM vs Products)')\n",
    "print('   - Task-specific models (different for single vs full)')\n",
    "print('   - Adversarial validation to identify distribution shift')\n",
    "print('   - Pseudo-labeling or self-training')\n",
    "\n",
    "print('\\n4. POST-PROCESSING:')\n",
    "print('   - Curds & Whey decorrelation')\n",
    "print('   - Prediction calibration')\n",
    "print('   - Ensemble blending with optimized weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5a61e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.931127Z",
     "iopub.status.busy": "2026-01-13T22:19:44.931021Z",
     "iopub.status.idle": "2026-01-13T22:19:44.934557Z",
     "shell.execute_reply": "2026-01-13T22:19:44.934117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Key Insights from Public Kernels ===\n",
      "\n",
      "1. Arrhenius Kinetics + TTA (LB 0.09831):\n",
      "   - Uses inv_temp, log_time, interaction features\n",
      "   - Symmetry TTA for mixed solvents\n",
      "   - 7 models for bagging\n",
      "   - HuberLoss for robustness\n",
      "\n",
      "2. Per-Target Ensemble (LB 0.11161):\n",
      "   - Different models for SM vs Products\n",
      "   - HGB for SM, ExtraTrees for Products\n",
      "   - Weighted ensemble (0.65 ACS PCA + 0.35 Spange)\n",
      "   - Uses both feature tables\n",
      "\n",
      "3. System Malfunction V1 (29 votes):\n",
      "   - Simple MLP with BatchNorm\n",
      "   - Uses spange_descriptors only\n",
      "   - No Arrhenius features\n",
      "\n",
      "Key Takeaway:\n",
      "The best public kernels achieve LB ~0.098-0.11.\n",
      "To reach target 0.017, we need a 5-6x improvement.\n",
      "This is a HUGE gap that requires a breakthrough.\n"
     ]
    }
   ],
   "source": [
    "# Key insight from public kernels\n",
    "print('\\n=== Key Insights from Public Kernels ===')\n",
    "print('\\n1. Arrhenius Kinetics + TTA (LB 0.09831):')\n",
    "print('   - Uses inv_temp, log_time, interaction features')\n",
    "print('   - Symmetry TTA for mixed solvents')\n",
    "print('   - 7 models for bagging')\n",
    "print('   - HuberLoss for robustness')\n",
    "\n",
    "print('\\n2. Per-Target Ensemble (LB 0.11161):')\n",
    "print('   - Different models for SM vs Products')\n",
    "print('   - HGB for SM, ExtraTrees for Products')\n",
    "print('   - Weighted ensemble (0.65 ACS PCA + 0.35 Spange)')\n",
    "print('   - Uses both feature tables')\n",
    "\n",
    "print('\\n3. System Malfunction V1 (29 votes):')\n",
    "print('   - Simple MLP with BatchNorm')\n",
    "print('   - Uses spange_descriptors only')\n",
    "print('   - No Arrhenius features')\n",
    "\n",
    "print('\\nKey Takeaway:')\n",
    "print('The best public kernels achieve LB ~0.098-0.11.')\n",
    "print('To reach target 0.017, we need a 5-6x improvement.')\n",
    "print('This is a HUGE gap that requires a breakthrough.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e27ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:19:44.935485Z",
     "iopub.status.busy": "2026-01-13T22:19:44.935383Z",
     "iopub.status.idle": "2026-01-13T22:19:44.938770Z",
     "shell.execute_reply": "2026-01-13T22:19:44.938311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RECOMMENDED NEXT STEPS ===\n",
      "\n",
      "PRIORITY 1: Stacking Ensemble\n",
      "   - Combine MLP + Trees predictions\n",
      "   - Use meta-learner to blend\n",
      "   - Leverage diversity between model families\n",
      "\n",
      "PRIORITY 2: High-Dimensional Features\n",
      "   - Try drfps (2048 features) with dimensionality reduction\n",
      "   - Try fragprints (2133 features) with feature selection\n",
      "   - These may capture chemistry better than spange\n",
      "\n",
      "PRIORITY 3: Per-Target Optimization\n",
      "   - SM has highest variance - focus on improving SM predictions\n",
      "   - Different models/features for each target\n",
      "   - Regressor chains to capture target correlations\n",
      "\n",
      "PRIORITY 4: Investigate LB Metric\n",
      "   - The CV-LB gap is consistent (~9x)\n",
      "   - Need to understand what the LB actually measures\n",
      "   - Consider that LB may weight tasks/targets differently\n"
     ]
    }
   ],
   "source": [
    "# Recommended next steps\n",
    "print('\\n=== RECOMMENDED NEXT STEPS ===')\n",
    "print('\\nPRIORITY 1: Stacking Ensemble')\n",
    "print('   - Combine MLP + Trees predictions')\n",
    "print('   - Use meta-learner to blend')\n",
    "print('   - Leverage diversity between model families')\n",
    "\n",
    "print('\\nPRIORITY 2: High-Dimensional Features')\n",
    "print('   - Try drfps (2048 features) with dimensionality reduction')\n",
    "print('   - Try fragprints (2133 features) with feature selection')\n",
    "print('   - These may capture chemistry better than spange')\n",
    "\n",
    "print('\\nPRIORITY 3: Per-Target Optimization')\n",
    "print('   - SM has highest variance - focus on improving SM predictions')\n",
    "print('   - Different models/features for each target')\n",
    "print('   - Regressor chains to capture target correlations')\n",
    "\n",
    "print('\\nPRIORITY 4: Investigate LB Metric')\n",
    "print('   - The CV-LB gap is consistent (~9x)')\n",
    "print('   - Need to understand what the LB actually measures')\n",
    "print('   - Consider that LB may weight tasks/targets differently')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
