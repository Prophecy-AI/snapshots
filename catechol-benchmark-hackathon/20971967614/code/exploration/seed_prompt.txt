# Catechol Reaction Yield Prediction - Strategy Guide (Loop 2)

## Current Status
- Best CV score: 0.0113 from exp_000 (Arrhenius Kinetics + MLP + TTA)
- Best LB score: 0.0998 (from exp_000)
- CV-LB gap: -0.0885 (MASSIVE - 9x worse on LB!)
- Target to beat: 0.017270

## Response to Evaluator

**Technical verdict was CONCERNS.** The evaluator correctly identified:
1. **Submission structure non-compliance** - The notebook didn't follow the template exactly
2. **No reproducibility seeds** - Results may vary between runs
3. **No early stopping** - Fixed 200 epochs without validation monitoring

**Evaluator's top priority:** Fix submission structure immediately.

**My response:** The evaluator's concerns are valid but the REAL issue is the massive CV-LB gap. Our LB score of 0.0998 is actually competitive with the best public kernel (0.098), suggesting:
1. Our model IS working correctly on Kaggle
2. Our local CV calculation differs from how Kaggle evaluates
3. The target of 0.017270 may be achievable but requires understanding the actual metric

**Key insight from public kernels:**
- The "mixall" kernel uses GroupKFold (5 splits) instead of leave-one-out
- The best kernels achieve ~0.098-0.11 on LB
- The target of 0.017270 is BELOW all public kernel scores

## CRITICAL: Understanding the CV-LB Gap

The gap suggests our local CV is NOT comparable to the LB metric. Possible reasons:
1. **Different CV scheme**: We use leave-one-out (24/13 folds), but LB might weight differently
2. **Different metric**: Our MSE calculation might differ from `catechol_hackathon_metric`
3. **The target of 0.017270 might be achievable** - it's much better than any public kernel

## MANDATORY: Submission Structure Requirements

**The submission MUST follow the exact template structure:**
- Last 3 cells must match the template exactly
- Only the `model = MLPModel()` line can be changed
- Model class must have `train_model(X, Y)` and `predict(X)` methods
- predict() must return a tensor/array of shape [N, 3]

## Data Understanding

**Reference notebooks:**
- `exploration/eda.ipynb` - Feature distributions, target statistics
- `exploration/evolver_loop1_lb_feedback.ipynb` - CV-LB gap analysis

**Key Data Facts:**
- Single solvent: 656 samples, 24 solvents, leave-one-solvent-out CV
- Full/mixed solvent: 1227 samples, 13 solvent pairs, leave-one-ramp-out CV
- Targets: SM, Product 2, Product 3 (yields as fractions 0-1)
- Targets do NOT sum to 1 (mean ~0.8) - mass loss in reaction

## Recommended Approaches (Priority Order)

### 1. FIRST: Understand the Actual Metric
Before optimizing further, we need to understand what `catechol_hackathon_metric` actually measures.
- The target of 0.017270 is 6x better than best public kernel (0.098)
- This suggests either: (a) a different metric, or (b) significant room for improvement

### 2. Try Ensemble Approaches (from public kernels)
The "catechol strategy to get 0.11161" kernel uses:
- Per-target models (different model for SM vs Product 2 vs Product 3)
- HistGradientBoostingRegressor for SM
- ExtraTreesRegressor for Products
- Ensemble of acs_pca_descriptors and spange_descriptors features
- Weighted ensemble (0.65 * model1 + 0.35 * model2)

### 3. Try the "mixall" Approach
Uses ensemble of MLP + XGBoost + RandomForest + LightGBM with:
- StandardScaler preprocessing
- Weighted ensemble (optimized via Optuna)
- GroupKFold (5 splits) instead of leave-one-out

### 4. Simpler Models May Generalize Better
Given the small dataset and leave-one-out CV:
- Tree-based models (LightGBM, XGBoost) may generalize better
- Fewer parameters = less overfitting
- Consider regularization: early stopping, max_depth limits

### 5. Physics-Informed Features (Keep Using)
The Arrhenius kinetics features are well-motivated:
- inv_temp = 1000 / (Temperature + 273.15)
- log_time = log(Residence Time)
- interaction = inv_temp * log_time

## What NOT to Try
- Complex deep learning architectures (small data, risk of overfitting)
- High-dimensional features (drfps: 2048, fragprints: 2133) without PCA
- Normalizing targets to sum to 1 (they naturally don't)

## Validation Notes
- Our local CV of 0.0113 is NOT comparable to LB
- Focus on LB score as the true measure of progress
- The target of 0.017270 is ambitious but may be achievable

## Code Structure Reminder

```python
# Model class must follow this interface:
class YourModel:
    def __init__(self, data='single'):
        # data='single' for single solvent, data='full' for mixtures
        pass
    
    def train_model(self, X_train, y_train):
        # X_train: DataFrame with columns from utils
        # y_train: DataFrame with ['Product 2', 'Product 3', 'SM']
        pass
    
    def predict(self, X_test):
        # Returns tensor/array of shape [N, 3]
        pass

# Third-to-last cell:
model = YourModel(data='single')  # ONLY change this line
model.train_model(train_X, train_Y)
predictions = model.predict(test_X)

# Second-to-last cell:
model = YourModel(data='full')  # ONLY change this line
model.train_model(train_X, train_Y)
predictions = model.predict(test_X)
```

## Key Insights from Public Kernels

1. **Arrhenius kinetics kernel (LB 0.098):** Physics-informed features, symmetry TTA, bagging MLPs
2. **Per-target ensemble (LB 0.111):** Different models per target, tree-based, feature ensemble
3. **mixall kernel:** Ensemble of MLP + XGBoost + RF + LightGBM, Optuna optimization

## Next Steps

1. **Implement a tree-based ensemble** following the "catechol strategy" kernel
2. **Compare LB scores** to understand which approaches work best
3. **Investigate the metric** - the target of 0.017270 suggests significant room for improvement
