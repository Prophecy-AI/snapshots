{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a43303",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline with Arrhenius Kinetics + TTA\n",
    "\n",
    "Implementing the best known approach from public kernels:\n",
    "- Physics-informed features (1/T, ln(t), interaction)\n",
    "- Chemical symmetry TTA for mixed solvents\n",
    "- 7 bagged MLP models\n",
    "- HuberLoss, BatchNorm, Dropout, Sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868acec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:15.286824Z",
     "iopub.status.busy": "2026-01-13T10:16:15.286248Z",
     "iopub.status.idle": "2026-01-13T10:16:16.527426Z",
     "shell.execute_reply": "2026-01-13T10:16:16.526986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "Memory: 85.0 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from abc import ABC\n",
    "import sys\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f4453b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:16.528712Z",
     "iopub.status.busy": "2026-01-13T10:16:16.528529Z",
     "iopub.status.idle": "2026-01-13T10:16:16.536035Z",
     "shell.execute_reply": "2026-01-13T10:16:16.535653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spange descriptors shape: (26, 13)\n",
      "Solvents: ['Cyclohexane', 'Ethyl Acetate', 'Acetic Acid', '2-Methyltetrahydrofuran [2-MeTHF]', '1,1,1,3,3,3-Hexafluoropropan-2-ol', 'IPA [Propan-2-ol]', 'Ethanol', 'Methanol', 'Ethylene Glycol [1,2-Ethanediol]', 'Acetonitrile', 'Water', 'Diethyl Ether [Ether]', 'MTBE [tert-Butylmethylether]', 'Dimethyl Carbonate', 'tert-Butanol [2-Methylpropan-2-ol]', 'DMA [N,N-Dimethylacetamide]', '2,2,2-Trifluoroethanol', 'Dihydrolevoglucosenone (Cyrene)', 'Decanol', 'Butanone [MEK]', 'Ethyl Lactate', 'Methyl Propionate', 'THF [Tetrahydrofuran]', 'Water.Acetonitrile', 'Acetonitrile.Acetic Acid', 'Water.2,2,2-Trifluoroethanol']\n"
     ]
    }
   ],
   "source": [
    "# Data paths for local environment\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_FULL_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT A NAME\",\n",
    "    \"SOLVENT B NAME\",\n",
    "    \"SolventB%\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "    \"SOLVENT NAME\",\n",
    "]\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\n",
    "    \"Residence Time\",\n",
    "    \"Temperature\",\n",
    "]\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"Product 2\",\n",
    "    \"Product 3\",\n",
    "    \"SM\",\n",
    "]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    assert name in [\"full\", \"single_solvent\"]\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[TARGET_LABELS]\n",
    "    return X, Y\n",
    "\n",
    "def load_features(name=\"spange_descriptors\"):\n",
    "    features = pd.read_csv(f'{DATA_PATH}/{name}_lookup.csv', index_col=0)\n",
    "    return features\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "# Load spange descriptors\n",
    "SPANGE_DF = load_features('spange_descriptors')\n",
    "print(f\"Spange descriptors shape: {SPANGE_DF.shape}\")\n",
    "print(f\"Solvents: {list(SPANGE_DF.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed9625c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:16.537108Z",
     "iopub.status.busy": "2026-01-13T10:16:16.537009Z",
     "iopub.status.idle": "2026-01-13T10:16:16.550768Z",
     "shell.execute_reply": "2026-01-13T10:16:16.550386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent data: (656, 3), (656, 3)\n",
      "Full data: (1227, 5), (1227, 3)\n",
      "\n",
      "Unique solvents (single): 24\n",
      "Unique solvent ramps (full): 13\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect data\n",
    "X_single, Y_single = load_data('single_solvent')\n",
    "X_full, Y_full = load_data('full')\n",
    "\n",
    "print(f\"Single solvent data: {X_single.shape}, {Y_single.shape}\")\n",
    "print(f\"Full data: {X_full.shape}, {Y_full.shape}\")\n",
    "print(f\"\\nUnique solvents (single): {X_single['SOLVENT NAME'].nunique()}\")\n",
    "print(f\"Unique solvent ramps (full): {X_full[['SOLVENT A NAME', 'SOLVENT B NAME']].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a22674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:20.159210Z",
     "iopub.status.busy": "2026-01-13T10:16:20.159040Z",
     "iopub.status.idle": "2026-01-13T10:16:20.171510Z",
     "shell.execute_reply": "2026-01-13T10:16:20.171123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the model classes following the template structure\n",
    "\n",
    "class SmilesFeaturizer(ABC):\n",
    "    def featurize(self, X, flip=False): \n",
    "        raise NotImplementedError\n",
    "\n",
    "class KineticMixingFeaturizer(SmilesFeaturizer):\n",
    "    \"\"\"Featurizer with Arrhenius kinetics features\"\"\"\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.featurizer = SPANGE_DF\n",
    "        # 2 numeric + 3 kinetic + 13 spange = 18 features\n",
    "        self.feats_dim = self.featurizer.shape[1] + 2 + 3\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        \n",
    "        # --- ARRHENIUS KINETIC FEATURES ---\n",
    "        temp_c = X_vals[:, 1:2]  # Temperature in Celsius\n",
    "        time_m = X_vals[:, 0:1]  # Residence time in minutes\n",
    "        \n",
    "        temp_k = temp_c + 273.15  # Convert to Kelvin\n",
    "        inv_temp = 1000.0 / temp_k  # Inverse temperature (Arrhenius)\n",
    "        log_time = np.log(time_m + 1e-6)  # Log time\n",
    "        interaction = inv_temp * log_time  # Interaction term\n",
    "        \n",
    "        X_kinetic = torch.tensor(np.hstack([X_vals, inv_temp, log_time, interaction]))\n",
    "        \n",
    "        # --- CHEMICAL FEATURES ---\n",
    "        if self.mixed:\n",
    "            A = torch.tensor(self.featurizer.loc[X[\"SOLVENT A NAME\"]].values)\n",
    "            B = torch.tensor(self.featurizer.loc[X[\"SOLVENT B NAME\"]].values)\n",
    "            pct = torch.tensor(X[\"SolventB%\"].values.reshape(-1, 1))\n",
    "            \n",
    "            if flip:\n",
    "                # SYMMETRY FLIP: Swap A and B\n",
    "                X_chem = B * (1 - (1-pct)) + A * (1-pct)\n",
    "            else:\n",
    "                X_chem = A * (1 - pct) + B * pct\n",
    "        else:\n",
    "            X_chem = torch.tensor(self.featurizer.loc[X[\"SOLVENT NAME\"]].values)\n",
    "            \n",
    "        return torch.cat([X_kinetic, X_chem], dim=1)\n",
    "\n",
    "\n",
    "class MLPInternal(nn.Module):\n",
    "    \"\"\"MLP with BatchNorm, Dropout, Sigmoid output\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPInternal, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(64, 3),\n",
    "            nn.Sigmoid()  # Constrain output to [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SymmetricBaggedModel(nn.Module):\n",
    "    \"\"\"Bagged MLP with TTA for chemical symmetry\"\"\"\n",
    "    def __init__(self, data='single', n_models=7, epochs=300, verbose=False):\n",
    "        super().__init__()\n",
    "        self.data_type = data\n",
    "        self.featurizer = KineticMixingFeaturizer(mixed=(data=='full'))\n",
    "        self.n_models = n_models\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        self.models = nn.ModuleList()\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        # 1. Standard Data\n",
    "        X_std = self.featurizer.featurize(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            # 2. Augmented Data (Train on both symmetries)\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            model = MLPInternal(input_dim).to(device)\n",
    "            model.train()\n",
    "            self.models.append(model)\n",
    "            \n",
    "            dataset = TensorDataset(X_all, y_all)\n",
    "            loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "            criterion = nn.HuberLoss()  # Robust to outliers\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=20\n",
    "            )\n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0.0\n",
    "                for inputs, targets in loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                scheduler.step(epoch_loss / len(dataset))\n",
    "\n",
    "    def predict(self, X):\n",
    "        device = next(self.models[0].parameters()).device\n",
    "        \n",
    "        # --- TEST TIME AUGMENTATION (TTA) ---\n",
    "        if self.data_type == 'full':\n",
    "            # Path A: Standard\n",
    "            X_std = self.featurizer.featurize(X, flip=False).to(device)\n",
    "            # Path B: Flipped (Symmetry)\n",
    "            X_flip = self.featurizer.featurize(X, flip=True).to(device)\n",
    "            \n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    # Average the model's prediction on A and B views\n",
    "                    p1 = model(X_std)\n",
    "                    p2 = model(X_flip)\n",
    "                    pred_sum += (p1 + p2) * 0.5 \n",
    "            \n",
    "            avg_pred = pred_sum / self.n_models\n",
    "            \n",
    "        else:\n",
    "            X_std = self.featurizer.featurize(X).to(device)\n",
    "            pred_sum = torch.zeros((len(X), 3)).to(device)\n",
    "            with torch.no_grad():\n",
    "                for model in self.models:\n",
    "                    model.eval()\n",
    "                    pred_sum += model(X_std)\n",
    "            avg_pred = pred_sum / self.n_models\n",
    "\n",
    "        return avg_pred.cpu()\n",
    "\n",
    "print(\"Model classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fe4e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:20.172449Z",
     "iopub.status.busy": "2026-01-13T10:16:20.172354Z",
     "iopub.status.idle": "2026-01-13T10:16:21.157381Z",
     "shell.execute_reply": "2026-01-13T10:16:21.156957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on a small subset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single solvent test predictions shape: torch.Size([10, 3])\n",
      "Predictions range: [0.399, 0.566]\n",
      "\n",
      "Full data test predictions shape: torch.Size([10, 3])\n",
      "Predictions range: [0.351, 0.840]\n"
     ]
    }
   ],
   "source": [
    "# Quick test to verify model works\n",
    "print(\"Testing model on a small subset...\")\n",
    "\n",
    "# Test single solvent\n",
    "X_test, Y_test = load_data('single_solvent')\n",
    "test_model = SymmetricBaggedModel(data='single', n_models=1, epochs=5)\n",
    "test_model.train_model(X_test.head(100), Y_test.head(100))\n",
    "preds = test_model.predict(X_test.head(10))\n",
    "print(f\"Single solvent test predictions shape: {preds.shape}\")\n",
    "print(f\"Predictions range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "\n",
    "# Test full data\n",
    "X_test_full, Y_test_full = load_data('full')\n",
    "test_model_full = SymmetricBaggedModel(data='full', n_models=1, epochs=5)\n",
    "test_model_full.train_model(X_test_full.head(100), Y_test_full.head(100))\n",
    "preds_full = test_model_full.predict(X_test_full.head(10))\n",
    "print(f\"\\nFull data test predictions shape: {preds_full.shape}\")\n",
    "print(f\"Predictions range: [{preds_full.min():.3f}, {preds_full.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5d686b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T10:16:24.946822Z",
     "iopub.status.busy": "2026-01-13T10:16:24.946248Z",
     "iopub.status.idle": "2026-01-13T10:30:47.452907Z",
     "shell.execute_reply": "2026-01-13T10:30:47.452437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK 0: Single Solvent (Leave-One-Solvent-Out CV)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:35<13:39, 35.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [01:11<13:05, 35.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [01:45<12:13, 34.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [02:19<11:35, 34.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [02:56<11:12, 35.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [03:32<10:43, 35.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [04:09<10:10, 35.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [04:44<09:33, 35.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [05:20<08:56, 35.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [05:55<08:19, 35.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [06:31<07:43, 35.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [07:07<07:07, 35.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [07:42<06:31, 35.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [08:18<05:55, 35.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [08:54<05:21, 35.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [09:29<04:45, 35.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [10:07<04:14, 36.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [10:43<03:38, 36.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [11:20<03:02, 36.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [11:56<02:25, 36.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [12:33<01:49, 36.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [13:09<01:12, 36.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 23/24 [13:46<00:36, 36.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [14:22<00:00, 36.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 24/24 [14:22<00:00, 35.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single Solvent CV MSE: 0.009893 ± 0.009636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run full cross-validation for single solvent task\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 0: Single Solvent (Leave-One-Solvent-Out CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "fold_mses = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=24):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    # Use fewer models and epochs for faster iteration\n",
    "    model = SymmetricBaggedModel(data='single', n_models=5, epochs=200)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    actuals = test_Y.values\n",
    "    \n",
    "    # Calculate fold MSE\n",
    "    fold_mse = np.mean((predictions - actuals) ** 2)\n",
    "    fold_mses.append(fold_mse)\n",
    "    \n",
    "    # Store predictions\n",
    "    for row_idx, row in enumerate(predictions):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "    all_actuals.extend(actuals.tolist())\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)\n",
    "print(f\"\\nSingle Solvent CV MSE: {np.mean(fold_mses):.6f} ± {np.std(fold_mses):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full cross-validation for full data task\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 1: Full Data (Leave-One-Ramp-Out CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions_full = []\n",
    "all_actuals_full = []\n",
    "fold_mses_full = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator), total=13):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "    \n",
    "    model = SymmetricBaggedModel(data='full', n_models=5, epochs=200)\n",
    "    model.train_model(train_X, train_Y)\n",
    "    \n",
    "    predictions = model.predict(test_X).numpy()\n",
    "    actuals = test_Y.values\n",
    "    \n",
    "    # Calculate fold MSE\n",
    "    fold_mse = np.mean((predictions - actuals) ** 2)\n",
    "    fold_mses_full.append(fold_mse)\n",
    "    \n",
    "    # Store predictions\n",
    "    for row_idx, row in enumerate(predictions):\n",
    "        all_predictions_full.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "    all_actuals_full.extend(actuals.tolist())\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions_full)\n",
    "print(f\"\\nFull Data CV MSE: {np.mean(fold_mses_full):.6f} ± {np.std(fold_mses_full):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine all predictions\n",
    "all_preds_combined = submission_single_solvent[['target_1', 'target_2', 'target_3']].values.tolist() + \\\n",
    "                     submission_full_data[['target_1', 'target_2', 'target_3']].values.tolist()\n",
    "all_actuals_combined = all_actuals + all_actuals_full\n",
    "\n",
    "all_preds_arr = np.array(all_preds_combined)\n",
    "all_actuals_arr = np.array(all_actuals_combined)\n",
    "\n",
    "overall_mse = np.mean((all_preds_arr - all_actuals_arr) ** 2)\n",
    "\n",
    "print(f\"Single Solvent MSE: {np.mean(fold_mses):.6f}\")\n",
    "print(f\"Full Data MSE: {np.mean(fold_mses_full):.6f}\")\n",
    "print(f\"\\nOverall MSE: {overall_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a196c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "print(f\"Submission saved to /home/submission/submission.csv\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
