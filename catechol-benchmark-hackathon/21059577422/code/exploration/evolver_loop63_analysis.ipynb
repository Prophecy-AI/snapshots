{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bb8a79",
   "metadata": {},
   "source": [
    "# Loop 63 Analysis - Final Push\n",
    "\n",
    "## Situation\n",
    "- Best LB: 0.0873 (exp_032)\n",
    "- Target: 0.0702\n",
    "- Gap: 24.3%\n",
    "- 4 submissions remaining\n",
    "\n",
    "## Key Insights from Kernels\n",
    "1. matthewmaree: CatBoost + XGBoost ensemble with correlation-filtered features\n",
    "2. mixall: MLP + XGB + RF + LGBM ensemble\n",
    "3. Both use multiple feature sources with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6e8dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:37:19.166832Z",
     "iopub.status.busy": "2026-01-16T18:37:19.166137Z",
     "iopub.status.idle": "2026-01-16T18:37:20.123138Z",
     "shell.execute_reply": "2026-01-16T18:37:20.122393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "  exp_000: CV=0.0111, LB=0.0982\n",
      "  exp_001: CV=0.0123, LB=0.1065\n",
      "  exp_003: CV=0.0105, LB=0.0972\n",
      "  exp_005: CV=0.0104, LB=0.0969\n",
      "  exp_006: CV=0.0097, LB=0.0946\n",
      "  exp_007: CV=0.0093, LB=0.0932\n",
      "  exp_009: CV=0.0092, LB=0.0936\n",
      "  exp_012: CV=0.0090, LB=0.0913\n",
      "  exp_024: CV=0.0087, LB=0.0893\n",
      "  exp_026: CV=0.0085, LB=0.0887\n",
      "  exp_030: CV=0.0083, LB=0.0877\n",
      "  exp_035: CV=0.0098, LB=0.0970\n",
      "  exp_032: CV=0.0082, LB=0.0873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV-LB Relationship: LB = 4.34*CV + 0.0523 (R²=0.958)\n",
      "To hit target 0.0702: Need CV = 0.004136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state to see all experiments\n",
    "with open('/home/code/session_state.json') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Get submission history\n",
    "submissions = state.get('submissions', [])\n",
    "print('Submission History:')\n",
    "for s in submissions:\n",
    "    print(f\"  {s.get('experiment_id', 'N/A')}: CV={s.get('cv_score', 'N/A'):.4f}, LB={s.get('lb_score', 'N/A'):.4f}\")\n",
    "\n",
    "# Calculate CV-LB relationship\n",
    "cv_scores = [s.get('cv_score', 0) for s in submissions if s.get('cv_score')]\n",
    "lb_scores = [s.get('lb_score', 0) for s in submissions if s.get('lb_score')]\n",
    "\n",
    "if len(cv_scores) >= 2:\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "    print(f'\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f} (R²={r_value**2:.3f})')\n",
    "    print(f'To hit target 0.0702: Need CV = {(0.0702 - intercept) / slope:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8434a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:37:20.126441Z",
     "iopub.status.busy": "2026-01-16T18:37:20.125653Z",
     "iopub.status.idle": "2026-01-16T18:37:20.130938Z",
     "shell.execute_reply": "2026-01-16T18:37:20.130418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV achieved: 0.008194\n",
      "\n",
      "Experiments with CV < 0.009:\n",
      "  exp_010: Diverse Ensemble: MLP[32,16] + LightGBM + MLP[64,32] - CV=0.008829\n",
      "  exp_011: Simple Ensemble: [32,16] MLP + LightGBM Only - CV=0.008785\n",
      "  exp_022: ACS PCA Features - 4.47% CV Improvement - CV=0.008601\n",
      "  exp_023: ACS PCA Compliant Submission - CV=0.008964\n",
      "  exp_024: ACS PCA Fixed Compliant - HuberLoss + Scheduler - CV=0.008689\n",
      "  exp_026: Weighted Loss Joint Model - 2.58% Improvement - CV=0.008465\n",
      "  exp_028: Four-Model Ensemble (MLP+LGBM+XGB+CatBoost) - 2.47% Worse - CV=0.008674\n",
      "  exp_030: GP+MLP+LGBM Ensemble - 1.97% Improvement - CV=0.008298\n",
      "  exp_032: Lower GP Weight (0.15) + Higher MLP (0.55) - NEW BEST CV! - CV=0.008194\n",
      "  exp_033: No GP (MLP 0.6 + LGBM 0.4) - 3.29% WORSE - CV=0.008463\n",
      "  exp_036: exp_035 Regenerated - Best CV Model (SUBMIT) - CV=0.008194\n",
      "  exp_038: exp_035 Best Model - Ready for Submission - CV=0.008194\n",
      "  exp_039: exp_035 Regenerated - Best CV Model for Submission - CV=0.008194\n",
      "  exp_044: Hybrid Model (baseline single + non-linear mixture) - CV=0.008597\n",
      "  exp_045: Mean Reversion - CV=0.008840\n",
      "  exp_046: Adaptive Weighted Training - CV=0.008597\n",
      "  exp_048: Hybrid Feature Ensemble - CV=0.008884\n",
      "  exp_062: FINAL STATUS - Competition Complete - CV=0.008194\n"
     ]
    }
   ],
   "source": [
    "# Analyze what worked and what didn't\n",
    "experiments = state.get('experiments', [])\n",
    "\n",
    "# Group by score\n",
    "best_cv = min([e.get('score', 1.0) for e in experiments])\n",
    "print(f'Best CV achieved: {best_cv:.6f}')\n",
    "\n",
    "# Find experiments with best CV\n",
    "best_exps = [e for e in experiments if e.get('score', 1.0) < 0.009]\n",
    "print(f'\\nExperiments with CV < 0.009:')\n",
    "for e in best_exps:\n",
    "    print(f\"  {e.get('id')}: {e.get('name')} - CV={e.get('score', 'N/A'):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfcc75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:37:20.132834Z",
     "iopub.status.busy": "2026-01-16T18:37:20.132477Z",
     "iopub.status.idle": "2026-01-16T18:37:20.140512Z",
     "shell.execute_reply": "2026-01-16T18:37:20.139843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key differences in matthewmaree kernel:\n",
      "1. Uses ALL feature sources with correlation filtering\n",
      "2. CatBoost with MultiRMSE loss\n",
      "3. Different ensemble weights for single vs full\n",
      "4. Clipping + normalization of predictions\n"
     ]
    }
   ],
   "source": [
    "# Key question: What approaches haven't been tried?\n",
    "# From kernels:\n",
    "# 1. CatBoost with MultiRMSE loss (matthewmaree)\n",
    "# 2. Correlation-based feature filtering (matthewmaree)\n",
    "# 3. Different ensemble weights for single vs full (matthewmaree)\n",
    "# 4. Clipping + normalization (matthewmaree)\n",
    "\n",
    "# Our experiments tried:\n",
    "# - MLP, LightGBM, XGBoost, CatBoost, RandomForest, GP\n",
    "# - Various feature combinations\n",
    "# - Various ensemble weights\n",
    "\n",
    "# What's different in matthewmaree?\n",
    "# 1. Uses ALL feature sources (spange, acs_pca, drfps, fragprints, smiles)\n",
    "# 2. Correlation filtering with threshold 0.90\n",
    "# 3. CatBoost with specific hyperparameters\n",
    "# 4. Different weights for single (7:6) vs full (1:2)\n",
    "\n",
    "print('Key differences in matthewmaree kernel:')\n",
    "print('1. Uses ALL feature sources with correlation filtering')\n",
    "print('2. CatBoost with MultiRMSE loss')\n",
    "print('3. Different ensemble weights for single vs full')\n",
    "print('4. Clipping + normalization of predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904f0c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:37:20.142778Z",
     "iopub.status.busy": "2026-01-16T18:37:20.142543Z",
     "iopub.status.idle": "2026-01-16T18:37:20.221067Z",
     "shell.execute_reply": "2026-01-16T18:37:20.220349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available data files:\n",
      "  smiles_lookup.csv\n",
      "  drfps_catechol_lookup.csv\n",
      "  acs_pca_descriptors_lookup.csv\n",
      "  catechol_single_solvent_yields.csv\n",
      "  instructions.txt\n",
      "  catechol_full_data_yields.csv\n",
      "  fragprints_lookup.csv\n",
      "  description.md\n",
      "  spange_descriptors_lookup.csv\n",
      "  utils.py\n",
      "\n",
      "Feature dimensions:\n",
      "  Spange: (26, 14)\n",
      "  DRFP: (24, 2049)\n",
      "  ACS PCA: (24, 6)\n",
      "  Fragprints: (24, 2134)\n"
     ]
    }
   ],
   "source": [
    "# Let's check what features we have available\n",
    "import os\n",
    "\n",
    "data_path = '/home/data'\n",
    "print('Available data files:')\n",
    "for f in os.listdir(data_path):\n",
    "    print(f'  {f}')\n",
    "\n",
    "# Load and check feature dimensions\n",
    "spange = pd.read_csv(f'{data_path}/spange_descriptors_lookup.csv')\n",
    "drfp = pd.read_csv(f'{data_path}/drfps_catechol_lookup.csv')\n",
    "acs_pca = pd.read_csv(f'{data_path}/acs_pca_descriptors_lookup.csv')\n",
    "fragprints = pd.read_csv(f'{data_path}/fragprints_lookup.csv')\n",
    "\n",
    "print(f'\\nFeature dimensions:')\n",
    "print(f'  Spange: {spange.shape}')\n",
    "print(f'  DRFP: {drfp.shape}')\n",
    "print(f'  ACS PCA: {acs_pca.shape}')\n",
    "print(f'  Fragprints: {fragprints.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0606b95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:37:20.223617Z",
     "iopub.status.busy": "2026-01-16T18:37:20.223009Z",
     "iopub.status.idle": "2026-01-16T18:37:20.227418Z",
     "shell.execute_reply": "2026-01-16T18:37:20.226783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final strategy options:\n",
      "1. CatBoost + XGBoost ensemble (matthewmaree style)\n",
      "2. Try fragprints features (not used in our best model)\n",
      "3. Try correlation filtering (not used in our best model)\n",
      "4. Try different ensemble weights for single vs full\n"
     ]
    }
   ],
   "source": [
    "# Strategy for final push:\n",
    "# 1. Try CatBoost + XGBoost ensemble like matthewmaree\n",
    "# 2. Use correlation-filtered features\n",
    "# 3. Different weights for single vs full\n",
    "\n",
    "# But first, let's understand the CV-LB gap better\n",
    "# The gap is structural - improving CV alone won't help\n",
    "# We need to reduce the intercept\n",
    "\n",
    "# Options:\n",
    "# 1. Try a fundamentally different approach (GNN failed)\n",
    "# 2. Try different feature engineering\n",
    "# 3. Try different model architecture\n",
    "# 4. Try different ensemble strategy\n",
    "\n",
    "print('Final strategy options:')\n",
    "print('1. CatBoost + XGBoost ensemble (matthewmaree style)')\n",
    "print('2. Try fragprints features (not used in our best model)')\n",
    "print('3. Try correlation filtering (not used in our best model)')\n",
    "print('4. Try different ensemble weights for single vs full')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
