{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bb8a79",
   "metadata": {},
   "source": [
    "# Loop 63 Analysis - Final Push\n",
    "\n",
    "## Situation\n",
    "- Best LB: 0.0873 (exp_032)\n",
    "- Target: 0.0702\n",
    "- Gap: 24.3%\n",
    "- 4 submissions remaining\n",
    "\n",
    "## Key Insights from Kernels\n",
    "1. matthewmaree: CatBoost + XGBoost ensemble with correlation-filtered features\n",
    "2. mixall: MLP + XGB + RF + LGBM ensemble\n",
    "3. Both use multiple feature sources with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state to see all experiments\n",
    "with open('/home/code/session_state.json') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Get submission history\n",
    "submissions = state.get('submissions', [])\n",
    "print('Submission History:')\n",
    "for s in submissions:\n",
    "    print(f\"  {s.get('experiment_id', 'N/A')}: CV={s.get('cv_score', 'N/A'):.4f}, LB={s.get('lb_score', 'N/A'):.4f}\")\n",
    "\n",
    "# Calculate CV-LB relationship\n",
    "cv_scores = [s.get('cv_score', 0) for s in submissions if s.get('cv_score')]\n",
    "lb_scores = [s.get('lb_score', 0) for s in submissions if s.get('lb_score')]\n",
    "\n",
    "if len(cv_scores) >= 2:\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(cv_scores, lb_scores)\n",
    "    print(f'\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f} (RÂ²={r_value**2:.3f})')\n",
    "    print(f'To hit target 0.0702: Need CV = {(0.0702 - intercept) / slope:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8434a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what worked and what didn't\n",
    "experiments = state.get('experiments', [])\n",
    "\n",
    "# Group by score\n",
    "best_cv = min([e.get('score', 1.0) for e in experiments])\n",
    "print(f'Best CV achieved: {best_cv:.6f}')\n",
    "\n",
    "# Find experiments with best CV\n",
    "best_exps = [e for e in experiments if e.get('score', 1.0) < 0.009]\n",
    "print(f'\\nExperiments with CV < 0.009:')\n",
    "for e in best_exps:\n",
    "    print(f\"  {e.get('id')}: {e.get('name')} - CV={e.get('score', 'N/A'):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key question: What approaches haven't been tried?\n",
    "# From kernels:\n",
    "# 1. CatBoost with MultiRMSE loss (matthewmaree)\n",
    "# 2. Correlation-based feature filtering (matthewmaree)\n",
    "# 3. Different ensemble weights for single vs full (matthewmaree)\n",
    "# 4. Clipping + normalization (matthewmaree)\n",
    "\n",
    "# Our experiments tried:\n",
    "# - MLP, LightGBM, XGBoost, CatBoost, RandomForest, GP\n",
    "# - Various feature combinations\n",
    "# - Various ensemble weights\n",
    "\n",
    "# What's different in matthewmaree?\n",
    "# 1. Uses ALL feature sources (spange, acs_pca, drfps, fragprints, smiles)\n",
    "# 2. Correlation filtering with threshold 0.90\n",
    "# 3. CatBoost with specific hyperparameters\n",
    "# 4. Different weights for single (7:6) vs full (1:2)\n",
    "\n",
    "print('Key differences in matthewmaree kernel:')\n",
    "print('1. Uses ALL feature sources with correlation filtering')\n",
    "print('2. CatBoost with MultiRMSE loss')\n",
    "print('3. Different ensemble weights for single vs full')\n",
    "print('4. Clipping + normalization of predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check what features we have available\n",
    "import os\n",
    "\n",
    "data_path = '/home/data'\n",
    "print('Available data files:')\n",
    "for f in os.listdir(data_path):\n",
    "    print(f'  {f}')\n",
    "\n",
    "# Load and check feature dimensions\n",
    "spange = pd.read_csv(f'{data_path}/spange_descriptors_lookup.csv')\n",
    "drfp = pd.read_csv(f'{data_path}/drfps_catechol_lookup.csv')\n",
    "acs_pca = pd.read_csv(f'{data_path}/acs_pca_descriptors_lookup.csv')\n",
    "fragprints = pd.read_csv(f'{data_path}/fragprints_lookup.csv')\n",
    "\n",
    "print(f'\\nFeature dimensions:')\n",
    "print(f'  Spange: {spange.shape}')\n",
    "print(f'  DRFP: {drfp.shape}')\n",
    "print(f'  ACS PCA: {acs_pca.shape}')\n",
    "print(f'  Fragprints: {fragprints.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy for final push:\n",
    "# 1. Try CatBoost + XGBoost ensemble like matthewmaree\n",
    "# 2. Use correlation-filtered features\n",
    "# 3. Different weights for single vs full\n",
    "\n",
    "# But first, let's understand the CV-LB gap better\n",
    "# The gap is structural - improving CV alone won't help\n",
    "# We need to reduce the intercept\n",
    "\n",
    "# Options:\n",
    "# 1. Try a fundamentally different approach (GNN failed)\n",
    "# 2. Try different feature engineering\n",
    "# 3. Try different model architecture\n",
    "# 4. Try different ensemble strategy\n",
    "\n",
    "print('Final strategy options:')\n",
    "print('1. CatBoost + XGBoost ensemble (matthewmaree style)')\n",
    "print('2. Try fragprints features (not used in our best model)')\n",
    "print('3. Try correlation filtering (not used in our best model)')\n",
    "print('4. Try different ensemble weights for single vs full')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
