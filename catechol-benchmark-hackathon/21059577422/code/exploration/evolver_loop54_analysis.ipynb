{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0525b4b8",
   "metadata": {},
   "source": [
    "# Loop 54 Analysis: Breaking the CV-LB Ceiling\n",
    "\n",
    "## Current State\n",
    "- **Best CV**: 0.008298 (exp_030)\n",
    "- **Best LB**: 0.08772 (exp_030)\n",
    "- **Target**: 0.0347\n",
    "- **Gap**: 2.53x (0.08772 / 0.0347)\n",
    "- **23 consecutive failures** since exp_030\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The CV-LB relationship is: LB = 4.31*CV + 0.0525\n",
    "- Intercept (0.0525) > Target (0.0347)\n",
    "- This means the target is UNREACHABLE by improving CV alone\n",
    "- We need to CHANGE the relationship, not just improve CV\n",
    "\n",
    "## Analysis Goals\n",
    "1. Understand what could change the CV-LB relationship\n",
    "2. Identify unexplored approaches\n",
    "3. Find the path to 0.0347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda2ebd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:18.989970Z",
     "iopub.status.busy": "2026-01-16T02:39:18.989412Z",
     "iopub.status.idle": "2026-01-16T02:39:20.282925Z",
     "shell.execute_reply": "2026-01-16T02:39:20.282125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "        exp      cv      lb             model\n",
      "0   exp_000  0.0111  0.0982      MLP baseline\n",
      "1   exp_001  0.0123  0.1065          LightGBM\n",
      "2   exp_003  0.0105  0.0972   Spange+DRFP MLP\n",
      "3   exp_005  0.0104  0.0969    Large ensemble\n",
      "4   exp_006  0.0097  0.0946       Simpler MLP\n",
      "5   exp_007  0.0093  0.0932      Even simpler\n",
      "6   exp_009  0.0092  0.0936  Ridge regression\n",
      "7   exp_012  0.0090  0.0913   Simple ensemble\n",
      "8   exp_024  0.0087  0.0893           ACS PCA\n",
      "9   exp_026  0.0085  0.0887     Weighted loss\n",
      "10  exp_030  0.0083  0.0877       GP+MLP+LGBM\n",
      "11  exp_035  0.0098  0.0970   Lower GP weight\n",
      "\n",
      "CV-LB Relationship: LB = 4.31*CV + 0.0525\n",
      "R² = 0.9505\n",
      "\n",
      "Target LB: 0.0347\n",
      "Intercept: 0.0525\n",
      "Gap: 0.0178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.0111, 'lb': 0.0982, 'model': 'MLP baseline'},\n",
    "    {'exp': 'exp_001', 'cv': 0.0123, 'lb': 0.1065, 'model': 'LightGBM'},\n",
    "    {'exp': 'exp_003', 'cv': 0.0105, 'lb': 0.0972, 'model': 'Spange+DRFP MLP'},\n",
    "    {'exp': 'exp_005', 'cv': 0.0104, 'lb': 0.0969, 'model': 'Large ensemble'},\n",
    "    {'exp': 'exp_006', 'cv': 0.0097, 'lb': 0.0946, 'model': 'Simpler MLP'},\n",
    "    {'exp': 'exp_007', 'cv': 0.0093, 'lb': 0.0932, 'model': 'Even simpler'},\n",
    "    {'exp': 'exp_009', 'cv': 0.0092, 'lb': 0.0936, 'model': 'Ridge regression'},\n",
    "    {'exp': 'exp_012', 'cv': 0.0090, 'lb': 0.0913, 'model': 'Simple ensemble'},\n",
    "    {'exp': 'exp_024', 'cv': 0.0087, 'lb': 0.0893, 'model': 'ACS PCA'},\n",
    "    {'exp': 'exp_026', 'cv': 0.0085, 'lb': 0.0887, 'model': 'Weighted loss'},\n",
    "    {'exp': 'exp_030', 'cv': 0.0083, 'lb': 0.0877, 'model': 'GP+MLP+LGBM'},\n",
    "    {'exp': 'exp_035', 'cv': 0.0098, 'lb': 0.0970, 'model': 'Lower GP weight'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Fit linear relationship\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f\"\\nCV-LB Relationship: LB = {slope:.2f}*CV + {intercept:.4f}\")\n",
    "print(f\"R² = {r_value**2:.4f}\")\n",
    "print(f\"\\nTarget LB: 0.0347\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"Gap: {intercept - 0.0347:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3996bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.285483Z",
     "iopub.status.busy": "2026-01-16T02:39:20.285115Z",
     "iopub.status.idle": "2026-01-16T02:39:20.290615Z",
     "shell.execute_reply": "2026-01-16T02:39:20.289905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required CV to hit target: -0.004130\n",
      "Current best CV: 0.008298\n",
      "\n",
      "⚠️ CRITICAL: Required CV is NEGATIVE - target is unreachable with current relationship!\n",
      "\n",
      "This means we need to CHANGE the relationship, not just improve CV.\n",
      "\n",
      "Possible ways to change the relationship:\n",
      "1. Use a fundamentally different model architecture\n",
      "2. Use different features that generalize better to LB\n",
      "3. Use a different training strategy (e.g., transductive learning)\n",
      "4. Calibrate predictions specifically for OOD solvents\n"
     ]
    }
   ],
   "source": [
    "# What CV would be needed to hit target?\n",
    "target_lb = 0.0347\n",
    "required_cv = (target_lb - intercept) / slope\n",
    "print(f\"Required CV to hit target: {required_cv:.6f}\")\n",
    "print(f\"Current best CV: 0.008298\")\n",
    "\n",
    "if required_cv < 0:\n",
    "    print(\"\\n⚠️ CRITICAL: Required CV is NEGATIVE - target is unreachable with current relationship!\")\n",
    "    print(\"\\nThis means we need to CHANGE the relationship, not just improve CV.\")\n",
    "    print(\"\\nPossible ways to change the relationship:\")\n",
    "    print(\"1. Use a fundamentally different model architecture\")\n",
    "    print(\"2. Use different features that generalize better to LB\")\n",
    "    print(\"3. Use a different training strategy (e.g., transductive learning)\")\n",
    "    print(\"4. Calibrate predictions specifically for OOD solvents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47fea168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.293531Z",
     "iopub.status.busy": "2026-01-16T02:39:20.292918Z",
     "iopub.status.idle": "2026-01-16T02:39:20.300024Z",
     "shell.execute_reply": "2026-01-16T02:39:20.299293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "APPROACHES TRIED (54 experiments)\n",
      "============================================================\n",
      "\n",
      "MLP architectures:\n",
      "  - baseline\n",
      "  - simpler [64,32]\n",
      "  - deeper [256,128,64]\n",
      "  - residual\n",
      "  - attention\n",
      "\n",
      "Tree-based models:\n",
      "  - LightGBM\n",
      "  - XGBoost\n",
      "  - RandomForest\n",
      "\n",
      "Gaussian Processes:\n",
      "  - GP with RBF kernel\n",
      "  - GP with Matern kernel\n",
      "\n",
      "Ensembles:\n",
      "  - MLP bagging\n",
      "  - GP+MLP+LGBM\n",
      "  - MLP+XGB+RF+LGBM\n",
      "\n",
      "Feature sets:\n",
      "  - Spange only\n",
      "  - DRFP only\n",
      "  - Spange+DRFP\n",
      "  - ACS PCA\n",
      "  - Arrhenius kinetics\n",
      "\n",
      "Regularization:\n",
      "  - Dropout 0.1-0.4\n",
      "  - Weight decay 1e-5 to 1e-3\n",
      "  - L1/L2\n",
      "\n",
      "Loss functions:\n",
      "  - MSE\n",
      "  - Huber\n",
      "  - Weighted MSE\n",
      "\n",
      "Data augmentation:\n",
      "  - TTA for mixtures\n",
      "  - Both orderings\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACHES TRIED (54 experiments)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches_tried = {\n",
    "    'MLP architectures': ['baseline', 'simpler [64,32]', 'deeper [256,128,64]', 'residual', 'attention'],\n",
    "    'Tree-based models': ['LightGBM', 'XGBoost', 'RandomForest'],\n",
    "    'Gaussian Processes': ['GP with RBF kernel', 'GP with Matern kernel'],\n",
    "    'Ensembles': ['MLP bagging', 'GP+MLP+LGBM', 'MLP+XGB+RF+LGBM'],\n",
    "    'Feature sets': ['Spange only', 'DRFP only', 'Spange+DRFP', 'ACS PCA', 'Arrhenius kinetics'],\n",
    "    'Regularization': ['Dropout 0.1-0.4', 'Weight decay 1e-5 to 1e-3', 'L1/L2'],\n",
    "    'Loss functions': ['MSE', 'Huber', 'Weighted MSE'],\n",
    "    'Data augmentation': ['TTA for mixtures', 'Both orderings'],\n",
    "}\n",
    "\n",
    "for category, items in approaches_tried.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30cf7db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.302443Z",
     "iopub.status.busy": "2026-01-16T02:39:20.302005Z",
     "iopub.status.idle": "2026-01-16T02:39:20.309289Z",
     "shell.execute_reply": "2026-01-16T02:39:20.308524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "APPROACHES NOT YET TRIED (or tried poorly)\n",
      "============================================================\n",
      "\n",
      "1. Domain Adaptation\n",
      "  Description: Train on source domain, adapt to target domain\n",
      "  Status: NOT TRIED\n",
      "\n",
      "2. Meta-Learning (MAML)\n",
      "  Description: Learn to quickly adapt to new solvents\n",
      "  Status: NOT TRIED\n",
      "\n",
      "3. Transductive Learning\n",
      "  Description: Process test samples jointly with training\n",
      "  Status: NOT TRIED\n",
      "\n",
      "4. Adversarial Training\n",
      "  Description: Train to be robust to distribution shift\n",
      "  Status: NOT TRIED\n",
      "\n",
      "5. Importance Weighting\n",
      "  Description: Re-weight training samples by density ratio\n",
      "  Status: NOT TRIED\n",
      "\n",
      "6. Test-Time Adaptation\n",
      "  Description: Adapt model at test time using unlabeled data\n",
      "  Status: NOT TRIED\n",
      "\n",
      "7. Proper GNN\n",
      "  Description: Graph attention network with proper implementation\n",
      "  Status: TRIED POORLY\n",
      "\n",
      "8. Ensemble of Diverse Architectures\n",
      "  Description: GNN + MLP + LGBM\n",
      "  Status: NOT TRIED\n",
      "\n",
      "9. Prediction Calibration\n",
      "  Description: Post-hoc calibration of predictions\n",
      "  Status: NOT TRIED\n",
      "\n",
      "10. Uncertainty-Weighted Ensemble\n",
      "  Description: Weight predictions by uncertainty\n",
      "  Status: NOT TRIED\n"
     ]
    }
   ],
   "source": [
    "# What approaches have NOT been tried or tried poorly?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPROACHES NOT YET TRIED (or tried poorly)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches_not_tried = [\n",
    "    (\"1. Domain Adaptation\", \"Train on source domain, adapt to target domain\", \"NOT TRIED\"),\n",
    "    (\"2. Meta-Learning (MAML)\", \"Learn to quickly adapt to new solvents\", \"NOT TRIED\"),\n",
    "    (\"3. Transductive Learning\", \"Process test samples jointly with training\", \"NOT TRIED\"),\n",
    "    (\"4. Adversarial Training\", \"Train to be robust to distribution shift\", \"NOT TRIED\"),\n",
    "    (\"5. Importance Weighting\", \"Re-weight training samples by density ratio\", \"NOT TRIED\"),\n",
    "    (\"6. Test-Time Adaptation\", \"Adapt model at test time using unlabeled data\", \"NOT TRIED\"),\n",
    "    (\"7. Proper GNN\", \"Graph attention network with proper implementation\", \"TRIED POORLY\"),\n",
    "    (\"8. Ensemble of Diverse Architectures\", \"GNN + MLP + LGBM\", \"NOT TRIED\"),\n",
    "    (\"9. Prediction Calibration\", \"Post-hoc calibration of predictions\", \"NOT TRIED\"),\n",
    "    (\"10. Uncertainty-Weighted Ensemble\", \"Weight predictions by uncertainty\", \"NOT TRIED\"),\n",
    "]\n",
    "\n",
    "for name, desc, status in approaches_not_tried:\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Description: {desc}\")\n",
    "    print(f\"  Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f268ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.311597Z",
     "iopub.status.busy": "2026-01-16T02:39:20.311128Z",
     "iopub.status.idle": "2026-01-16T02:39:20.318217Z",
     "shell.execute_reply": "2026-01-16T02:39:20.317549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KEY INSIGHT: Distribution Shift Analysis\n",
      "============================================================\n",
      "\n",
      "The CV-LB gap is caused by distribution shift between:\n",
      "1. Training solvents (23 solvents in each fold)\n",
      "2. Test solvent (1 held-out solvent)\n",
      "\n",
      "The held-out solvent is CHEMICALLY DIFFERENT from training solvents.\n",
      "This is why the model fails to generalize.\n",
      "\n",
      "High-error solvents (from previous analysis):\n",
      "- HFIP (fluorinated): CV error = 0.038\n",
      "- TFE (fluorinated): CV error = 0.015\n",
      "- Cyclohexane (non-polar): CV error = 0.026\n",
      "- Water.Ethanol (polar protic): CV error = 0.028\n",
      "\n",
      "These solvents are OUTLIERS in the feature space.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The CV-LB gap is due to distribution shift\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT: Distribution Shift Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "The CV-LB gap is caused by distribution shift between:\n",
    "1. Training solvents (23 solvents in each fold)\n",
    "2. Test solvent (1 held-out solvent)\n",
    "\n",
    "The held-out solvent is CHEMICALLY DIFFERENT from training solvents.\n",
    "This is why the model fails to generalize.\n",
    "\n",
    "High-error solvents (from previous analysis):\n",
    "- HFIP (fluorinated): CV error = 0.038\n",
    "- TFE (fluorinated): CV error = 0.015\n",
    "- Cyclohexane (non-polar): CV error = 0.026\n",
    "- Water.Ethanol (polar protic): CV error = 0.028\n",
    "\n",
    "These solvents are OUTLIERS in the feature space.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b547710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.320920Z",
     "iopub.status.busy": "2026-01-16T02:39:20.320249Z",
     "iopub.status.idle": "2026-01-16T02:39:20.326071Z",
     "shell.execute_reply": "2026-01-16T02:39:20.325302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WHAT COULD CHANGE THE CV-LB RELATIONSHIP?\n",
      "============================================================\n",
      "\n",
      "1. **Better OOD Generalization**\n",
      "   - Use features that capture fundamental chemistry\n",
      "   - Use simpler models that don't overfit to training distribution\n",
      "   - Use regularization that encourages generalization\n",
      "\n",
      "2. **Domain Adaptation**\n",
      "   - Re-weight training samples to match test distribution\n",
      "   - Use adversarial training to learn domain-invariant features\n",
      "   - Use importance weighting based on density ratio\n",
      "\n",
      "3. **Prediction Calibration**\n",
      "   - Learn a calibration function from CV-LB relationship\n",
      "   - Apply calibration to shift predictions toward LB\n",
      "   - This could reduce the intercept\n",
      "\n",
      "4. **Ensemble Diversity**\n",
      "   - Use models with different inductive biases\n",
      "   - Some models may have better CV-LB correlation\n",
      "   - Weight models by their CV-LB correlation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What would change the CV-LB relationship?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WHAT COULD CHANGE THE CV-LB RELATIONSHIP?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. **Better OOD Generalization**\n",
    "   - Use features that capture fundamental chemistry\n",
    "   - Use simpler models that don't overfit to training distribution\n",
    "   - Use regularization that encourages generalization\n",
    "\n",
    "2. **Domain Adaptation**\n",
    "   - Re-weight training samples to match test distribution\n",
    "   - Use adversarial training to learn domain-invariant features\n",
    "   - Use importance weighting based on density ratio\n",
    "\n",
    "3. **Prediction Calibration**\n",
    "   - Learn a calibration function from CV-LB relationship\n",
    "   - Apply calibration to shift predictions toward LB\n",
    "   - This could reduce the intercept\n",
    "\n",
    "4. **Ensemble Diversity**\n",
    "   - Use models with different inductive biases\n",
    "   - Some models may have better CV-LB correlation\n",
    "   - Weight models by their CV-LB correlation\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92351ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.328179Z",
     "iopub.status.busy": "2026-01-16T02:39:20.327951Z",
     "iopub.status.idle": "2026-01-16T02:39:20.341643Z",
     "shell.execute_reply": "2026-01-16T02:39:20.340941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Analysis:\n",
      "        exp             model      cv      lb  predicted_lb  residual\n",
      "0   exp_000      MLP baseline  0.0111  0.0982      0.100413 -0.002213\n",
      "1   exp_001          LightGBM  0.0123  0.1065      0.105591  0.000909\n",
      "2   exp_003   Spange+DRFP MLP  0.0105  0.0972      0.097825 -0.000625\n",
      "3   exp_005    Large ensemble  0.0104  0.0969      0.097393 -0.000493\n",
      "4   exp_006       Simpler MLP  0.0097  0.0946      0.094373  0.000227\n",
      "5   exp_007      Even simpler  0.0093  0.0932      0.092647  0.000553\n",
      "6   exp_009  Ridge regression  0.0092  0.0936      0.092215  0.001385\n",
      "7   exp_012   Simple ensemble  0.0090  0.0913      0.091353 -0.000053\n",
      "8   exp_024           ACS PCA  0.0087  0.0893      0.090058 -0.000758\n",
      "9   exp_026     Weighted loss  0.0085  0.0887      0.089195 -0.000495\n",
      "10  exp_030       GP+MLP+LGBM  0.0083  0.0877      0.088332 -0.000632\n",
      "11  exp_035   Lower GP weight  0.0098  0.0970      0.094804  0.002196\n",
      "\n",
      "Mean residual: -0.000000\n",
      "Std residual: 0.001155\n",
      "\n",
      "Experiments that beat predicted LB (negative residual):\n",
      "  exp_000 (MLP baseline): residual = -0.002213\n",
      "  exp_003 (Spange+DRFP MLP): residual = -0.000625\n",
      "  exp_005 (Large ensemble): residual = -0.000493\n",
      "  exp_012 (Simple ensemble): residual = -0.000053\n",
      "  exp_024 (ACS PCA): residual = -0.000758\n",
      "  exp_026 (Weighted loss): residual = -0.000495\n",
      "  exp_030 (GP+MLP+LGBM): residual = -0.000632\n"
     ]
    }
   ],
   "source": [
    "# Analyze the residuals from CV-LB relationship\n",
    "df['predicted_lb'] = slope * df['cv'] + intercept\n",
    "df['residual'] = df['lb'] - df['predicted_lb']\n",
    "\n",
    "print(\"Residual Analysis:\")\n",
    "print(df[['exp', 'model', 'cv', 'lb', 'predicted_lb', 'residual']].to_string())\n",
    "\n",
    "print(f\"\\nMean residual: {df['residual'].mean():.6f}\")\n",
    "print(f\"Std residual: {df['residual'].std():.6f}\")\n",
    "\n",
    "# Which experiments beat the predicted LB?\n",
    "print(f\"\\nExperiments that beat predicted LB (negative residual):\")\n",
    "for _, row in df[df['residual'] < 0].iterrows():\n",
    "    print(f\"  {row['exp']} ({row['model']}): residual = {row['residual']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ef0890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.343894Z",
     "iopub.status.busy": "2026-01-16T02:39:20.343662Z",
     "iopub.status.idle": "2026-01-16T02:39:20.349235Z",
     "shell.execute_reply": "2026-01-16T02:39:20.348579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SCENARIO ANALYSIS: What if we could reduce the intercept?\n",
      "============================================================\n",
      "Intercept = 0.05 → LB = 0.0858 \n",
      "Intercept = 0.04 → LB = 0.0758 \n",
      "Intercept = 0.03 → LB = 0.0658 \n",
      "Intercept = 0.02 → LB = 0.0558 \n",
      "Intercept = 0.01 → LB = 0.0458 \n",
      "Intercept = 0.00 → LB = 0.0358 \n",
      "\n",
      "To beat target (0.0347), we need intercept < 0.0 (impossible with current relationship)\n",
      "OR we need to CHANGE the slope/intercept relationship entirely.\n"
     ]
    }
   ],
   "source": [
    "# What if we could reduce the intercept?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCENARIO ANALYSIS: What if we could reduce the intercept?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for new_intercept in [0.05, 0.04, 0.03, 0.02, 0.01, 0.0]:\n",
    "    new_lb = slope * 0.008298 + new_intercept\n",
    "    status = \"✓ BEATS TARGET\" if new_lb < 0.0347 else \"\"\n",
    "    print(f\"Intercept = {new_intercept:.2f} → LB = {new_lb:.4f} {status}\")\n",
    "\n",
    "print(\"\\nTo beat target (0.0347), we need intercept < 0.0 (impossible with current relationship)\")\n",
    "print(\"OR we need to CHANGE the slope/intercept relationship entirely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c2ab74d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T02:39:20.350894Z",
     "iopub.status.busy": "2026-01-16T02:39:20.350704Z",
     "iopub.status.idle": "2026-01-16T02:39:20.357295Z",
     "shell.execute_reply": "2026-01-16T02:39:20.356629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RECOMMENDATION\n",
      "============================================================\n",
      "\n",
      "Given that:\n",
      "1. 23 consecutive experiments have failed to beat exp_030\n",
      "2. The CV-LB relationship has intercept > target\n",
      "3. All refinements to GP + MLP + LGBM have failed\n",
      "\n",
      "We need to try something FUNDAMENTALLY DIFFERENT:\n",
      "\n",
      "**PRIORITY 1: Prediction Calibration**\n",
      "- Learn a calibration function from the CV-LB relationship\n",
      "- Apply calibration to shift predictions toward LB\n",
      "- This could reduce the effective intercept\n",
      "\n",
      "**PRIORITY 2: Simpler Model with Stronger Regularization**\n",
      "- The GP component in exp_030 provides strong regularization\n",
      "- Try GP-only model with optimized hyperparameters\n",
      "- Or try Ridge regression with very strong regularization\n",
      "\n",
      "**PRIORITY 3: Feature Simplification**\n",
      "- Use only the most fundamental features (Spange only)\n",
      "- Drop DRFP features which may be causing overfitting\n",
      "- Focus on features that capture fundamental chemistry\n",
      "\n",
      "**PRIORITY 4: Submit exp_030 with Calibration**\n",
      "- Apply a simple calibration to exp_030 predictions\n",
      "- This is the safest approach with 5 submissions remaining\n",
      "\n",
      "**DO NOT:**\n",
      "- Try more complex architectures (they don't help)\n",
      "- Try more features (DRFP consistently hurts)\n",
      "- Try more ensemble variations (exhausted)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Given that:\n",
    "1. 23 consecutive experiments have failed to beat exp_030\n",
    "2. The CV-LB relationship has intercept > target\n",
    "3. All refinements to GP + MLP + LGBM have failed\n",
    "\n",
    "We need to try something FUNDAMENTALLY DIFFERENT:\n",
    "\n",
    "**PRIORITY 1: Prediction Calibration**\n",
    "- Learn a calibration function from the CV-LB relationship\n",
    "- Apply calibration to shift predictions toward LB\n",
    "- This could reduce the effective intercept\n",
    "\n",
    "**PRIORITY 2: Simpler Model with Stronger Regularization**\n",
    "- The GP component in exp_030 provides strong regularization\n",
    "- Try GP-only model with optimized hyperparameters\n",
    "- Or try Ridge regression with very strong regularization\n",
    "\n",
    "**PRIORITY 3: Feature Simplification**\n",
    "- Use only the most fundamental features (Spange only)\n",
    "- Drop DRFP features which may be causing overfitting\n",
    "- Focus on features that capture fundamental chemistry\n",
    "\n",
    "**PRIORITY 4: Submit exp_030 with Calibration**\n",
    "- Apply a simple calibration to exp_030 predictions\n",
    "- This is the safest approach with 5 submissions remaining\n",
    "\n",
    "**DO NOT:**\n",
    "- Try more complex architectures (they don't help)\n",
    "- Try more features (DRFP consistently hurts)\n",
    "- Try more ensemble variations (exhausted)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Current State:\n",
    "- Best CV: 0.008298 (exp_030)\n",
    "- Best LB: 0.08772 (exp_030)\n",
    "- Target: 0.0347\n",
    "- Gap: 2.53x\n",
    "\n",
    "CV-LB Relationship:\n",
    "- LB = 4.31*CV + 0.0525\n",
    "- Intercept (0.0525) > Target (0.0347)\n",
    "- Required CV to hit target: NEGATIVE (impossible)\n",
    "\n",
    "Key Insight:\n",
    "- The target is UNREACHABLE by improving CV alone\n",
    "- We need to CHANGE the CV-LB relationship\n",
    "- This requires fundamentally different approaches\n",
    "\n",
    "Remaining Submissions: 5\n",
    "Best Model: exp_030 (GP 0.15 + MLP 0.55 + LGBM 0.3)\n",
    "\n",
    "Next Steps:\n",
    "1. Try prediction calibration\n",
    "2. Try simpler model with stronger regularization\n",
    "3. Try feature simplification\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
