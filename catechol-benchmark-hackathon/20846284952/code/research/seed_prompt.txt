## Current Status
- Best CV score: 0.009004 from exp_012 (MLP[32,16] + LightGBM ensemble)
- Best LB score: 0.0913 (exp_012)
- CV-LB gap: ~10.14x ratio → significant distribution shift between CV and LB
- Target: 0.0333 (2.74x gap from best LB)

## Response to Evaluator

**Technical verdict was TRUSTWORTHY.** The evaluator confirmed exp_018 (Fragprints) was executed correctly but performed 8.28% worse than DRFP features.

**Evaluator's top priority**: Execute attention model (exp_017) and try ACS PCA features.
- **AGREE**: The attention model code is ready and should be executed to close this loose end.
- **AGREE**: ACS PCA features (5 features) are unexplored and could provide marginal improvement.

**Key concerns raised**:
1. Attention model (exp_017) still NOT executed → Will prioritize this
2. ACS PCA descriptors unexplored → Will try adding to feature set
3. Per-target models unexplored → Lower priority but worth trying
4. Stacking instead of weighted averaging → Lower priority

**My synthesis**: The evaluator is correct that we have unexplored approaches. The linear CV-LB fit (LB = 4.05*CV + 0.0551) suggests the target may be unreachable with current approaches, BUT this is based on only 8 data points and may not be linear. We must continue exploring.

## Data Understanding

Reference notebooks:
- `exploration/evolver_loop21_analysis.ipynb` - CV-LB relationship analysis
- `experiments/012_simple_ensemble/simple_ensemble.ipynb` - Best model (CV 0.009004, LB 0.0913)
- `experiments/017_attention_model/attention_model.ipynb` - Attention model (NOT EXECUTED)
- `experiments/018_fragprints/fragprints_ensemble.ipynb` - Fragprints (8.28% worse than DRFP)

Key patterns to exploit:
1. **DRFP > Fragprints**: DRFP captures reaction-level information better than fragment fingerprints
2. **MLP + LightGBM ensemble**: Diversity helps (exp_012 beat single models)
3. **Simple architectures work best**: [32,16] outperforms deeper networks
4. **TTA for mixtures**: Averaging both orderings improves predictions
5. **Arrhenius kinetics features**: 1/T, ln(t), interaction term are valuable

Available features NOT yet combined:
- ACS PCA descriptors (5 features) - NOT TRIED
- Combined DRFP + Fragprints - NOT TRIED

## Recommended Approaches

Priority-ordered list of what to try next:

### 1. Execute Attention Model (exp_017) - HIGH PRIORITY
**Why**: Code is ready, just needs execution. Closes a loose end.
**How**: Open `/home/code/experiments/017_attention_model/attention_model.ipynb` and execute cells 7-9.
**Expected time**: ~2 hours
**Success criteria**: CV < 0.0081 (>10% improvement) → submit to LB

### 2. Try ACS PCA Features - HIGH PRIORITY
**Why**: 5 additional features from ACS Green Chemistry, never tried.
**How**: Add ACS PCA (5 features) to current best feature set:
- Spange (13) + DRFP (122) + Arrhenius (5) + ACS PCA (5) = 145 features
**Expected time**: ~1.5 hours
**Success criteria**: CV < 0.0081 (>10% improvement) → submit to LB

### 3. Per-Target Models - MEDIUM PRIORITY
**Why**: SM (starting material) may have different dynamics than products.
**How**: Train separate MLP[32,16] + LightGBM ensembles for each target (Product 2, Product 3, SM).
**Expected time**: ~3 hours
**Success criteria**: CV < 0.0081

### 4. Feature Interactions - MEDIUM PRIORITY
**Why**: Kernel research showed `Reaction_Energy = Temperature * Residence Time` and `B_Conc_Temp = SolventB% * Temperature` as useful features.
**How**: Add polynomial features of kinetic variables.
**Expected time**: ~1.5 hours

### 5. Combined DRFP + Fragprints - LOW PRIORITY
**Why**: Fragprints alone was worse, but combined might capture complementary information.
**How**: Use both fingerprint types: Spange (13) + DRFP (122) + Fragprints (144) + Arrhenius (5) = 284 features
**Expected time**: ~2 hours

### 6. Stacking Meta-Learner - LOW PRIORITY
**Why**: Could learn optimal combination weights instead of fixed 0.6/0.4.
**How**: Train Ridge regression on out-of-fold predictions from MLP and LightGBM.
**Expected time**: ~2 hours

## What NOT to Try

- **Deep residual networks**: 5x worse than baseline (exp_004)
- **DRFP with PCA**: Much worse than variance-based selection (exp_002)
- **Fragprints alone**: 8.28% worse than DRFP (exp_018)
- **Very simple models [16]**: Underfitting
- **Large ensembles (15+ models)**: Marginal improvement, not worth compute

## Validation Notes

- CV scheme: Leave-one-solvent-out for single solvents (24 folds), leave-one-ramp-out for mixtures (13 folds)
- CV-LB relationship: LB = 4.05*CV + 0.0551 (R²=0.948) based on 8 submissions
- The intercept (0.0551) > target (0.0333) suggests the target may be unreachable with current approaches
- BUT this is based on only 8 data points - the relationship may not be linear
- **DO NOT GIVE UP** - continue exploring unexplored approaches

## Submission Strategy

- 4 submissions remaining
- Only submit if CV improves by >10% (CV < 0.0081)
- Or if trying a fundamentally different approach for diversity check
- Current best: exp_012 (CV 0.009004, LB 0.0913)

## Key Insight from Kernel Research

From `lakhindarpal/catechol-benchmark-hackathon-neurips-2025-dnb`:
- Uses SmoothL1Loss (beta=0.3) instead of HuberLoss
- Uses 9 models bagged
- Adds noise injection: `X_kinetic = X_kinetic + 0.01 * torch.randn_like(X_kinetic)`

From `mr0106/catechol`:
- Feature engineering: `Reaction_Energy = Temperature * Residence Time`
- Feature engineering: `B_Conc_Temp = SolventB% * Temperature`

These techniques could be combined with our best approach.

## THE TARGET IS REACHABLE. DO NOT GIVE UP.