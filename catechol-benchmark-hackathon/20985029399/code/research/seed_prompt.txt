# Catechol Reaction Yield Prediction - Evolved Seed Prompt (Loop 3)

## Current Status
- Best CV score: **0.08819** from exp_000 (Physics-Informed MLP Baseline)
- Best LB score: Not yet submitted (0/5 submissions used)
- Target: **0.04740** (need ~46% improvement)
- CV-LB gap: Unknown - NEED TO SUBMIT to calibrate

## Response to Evaluator

**Technical verdict was TRUSTWORTHY** - the evaluator confirmed that validation methodology is sound and scores are verified.

**Evaluator's top priority: IMPLEMENT TabPFN**
- I AGREE this was a good recommendation, but TabPFN requires HuggingFace authentication which failed in exp_001
- The executor noted: "TabPFN was attempted but requires HuggingFace authentication for the gated model"
- **Alternative approach needed**: Try Gaussian Process regression instead, which is also designed for small data

**Key concerns raised by evaluator:**
1. Feature expansion backfired (22% degradation) - ADDRESSED: Abandon fingerprint features
2. Deeper network may have overfit - ADDRESSED: Return to simpler architecture
3. Large gap to target remains - ADDRESSED: Need fundamentally different approaches

**My synthesis:**
The evaluator correctly identified that incremental MLP improvements won't close the 46% gap. However, since TabPFN has authentication issues, we need alternative approaches:
1. **Gaussian Process Regression** - designed for small data, provides uncertainty
2. **Non-linear solvent mixing** - current linear mixing may be limiting
3. **Per-target optimization** - SM follows different kinetics than products
4. **Stronger regularization** - prevent overfitting on small data

## Data Understanding

**Reference notebooks:**
- `exploration/eda.ipynb` - Data structure, feature distributions
- `exploration/evolver_loop3_analysis.ipynb` - Target correlations, solvent isolation analysis

**Key patterns to exploit:**
1. **Strong process-target correlations:**
   - SM: -0.817 with Temperature, -0.275 with Residence Time
   - Products: +0.723 (P2), +0.573 (P3) with Temperature
   - This confirms Arrhenius kinetics features are valuable

2. **Isolated solvents are hardest to predict:**
   - Cyclohexane (NN distance = 4.06) - very different from others
   - Ethylene Glycol (3.32), Decanol (2.72), Water (2.61)
   - These likely contribute most to CV error

3. **Spange descriptors capture key solvent effects:**
   - ET(30), SA, alpha have highest correlations with targets
   - These are polarity/hydrogen-bonding parameters

## CRITICAL SUBMISSION CONSTRAINTS

**MANDATORY STRUCTURE:**
- The submission MUST follow the template notebook structure
- Only the last 3 cells can be modified, and ONLY the `model = MLPModel()` line can be changed
- Model must implement: `train_model(X_train, y_train)` and `predict(X_test)` methods
- Two tasks: single_solvent (leave-one-solvent-out CV, 24 folds) and full (leave-one-ramp-out CV, 13 folds)

## Recommended Approaches (Priority Order)

### Priority 1: Gaussian Process Regression with RBF Kernel
**Rationale:** GP is specifically designed for small datasets and provides uncertainty estimates. The GAUCHE library has chemistry-specific kernels, but even a simple RBF kernel on Spange descriptors could work well.

**Implementation:**
```python
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel

class GPModel:
    def __init__(self, data='single'):
        self.data_type = data
        self.featurizer = KineticFeaturizer(mixed=(data=='full'))
        self.models = []  # One per target
        
    def train_model(self, X_train, y_train):
        X_feats = self.featurizer.featurize(X_train)
        y_vals = y_train.values
        
        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)
        
        for i in range(3):  # 3 targets
            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, normalize_y=True)
            gp.fit(X_feats, y_vals[:, i])
            self.models.append(gp)
    
    def predict(self, X_test):
        X_feats = self.featurizer.featurize(X_test)
        preds = []
        for model in self.models:
            pred, _ = model.predict(X_feats, return_std=True)
            preds.append(pred)
        return torch.tensor(np.column_stack(preds))
```

### Priority 2: Non-linear Solvent Mixing for Full Data
**Rationale:** Current approach uses linear interpolation: `A*(1-pct) + B*pct`. This may not capture non-linear mixing effects.

**Implementation options:**
1. **Concatenate features:** `[A_features, B_features, pct]` instead of interpolating
2. **Add interaction terms:** `A_features * B_features * pct`
3. **Separate models:** Train different models for different mixing ratios

```python
class NonLinearMixingFeaturizer:
    def featurize(self, X, flip=False):
        # ... kinetic features ...
        
        if self.mixed:
            A_feats = self.spange.loc[X["SOLVENT A NAME"]].values
            B_feats = self.spange.loc[X["SOLVENT B NAME"]].values
            pct = X["SolventB%"].values.reshape(-1, 1)
            
            # Concatenate instead of interpolate
            X_solvent = np.hstack([A_feats, B_feats, pct, A_feats * B_feats])
            # Or add interaction: A_feats * pct, B_feats * (1-pct), A_feats * B_feats
```

### Priority 3: Per-Target Optimization
**Rationale:** SM follows different kinetics than products. SM decreases monotonically with reaction progress, while products have more complex behavior.

**Implementation:**
- Train separate models for SM vs Products
- Use different architectures/hyperparameters per target
- SM: simpler model (more predictable)
- Products: more complex model (non-linear behavior)

### Priority 4: Stronger Regularization on MLP
**Rationale:** With only 656/1227 samples and 18 features, overfitting is a risk.

**Changes to try:**
- Increase dropout: 0.3 or 0.4 instead of 0.2
- Increase weight decay: 1e-4 instead of 1e-5
- Simpler architecture: [64, 64] instead of [128, 128, 64]
- Earlier stopping: patience=10 instead of 20

### Priority 5: Submit Best Model for LB Calibration
**Rationale:** We have 5 submissions remaining and 0 used. We need to verify CV-LB correlation.

**Action:** After trying GP or non-linear mixing, submit the best result to calibrate.

## What NOT to Try

1. **Feature expansion with DRFP/Fragprints** - Already tried, made things worse (0.10767)
2. **Deeper networks** - More capacity = more overfitting on small data
3. **TabPFN** - Requires HuggingFace authentication which failed
4. **Pure tree-based models** - LightGBM/XGBoost alone performed worse than MLP

## Validation Notes

- **Single Solvent:** Leave-one-solvent-out CV (24 folds)
- **Full Data:** Leave-one-ramp-out CV (13 folds)
- **Overall score:** Average of both task scores
- **Key insight:** This tests GENERALIZATION to unseen solvents, not interpolation

## Implementation Order

1. **First:** Try Gaussian Process with RBF kernel on baseline features
2. **Second:** If GP doesn't improve, try non-linear solvent mixing
3. **Third:** Try stronger regularization on MLP
4. **Fourth:** Submit best result for LB feedback

## Key Code References

- Baseline MLP: `/home/code/experiments/001_baseline/baseline.ipynb`
- Featurizer with Arrhenius: Same notebook, `KineticFeaturizer` class
- Template structure: Must follow Kaggle template exactly