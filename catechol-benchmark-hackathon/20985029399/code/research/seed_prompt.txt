# Catechol Reaction Yield Prediction - Evolved Seed Prompt (Loop 2)

## Current Status
- Best CV score: **0.08819** from exp_000 (Physics-Informed MLP Baseline)
- Best LB score: Not yet submitted
- Target: **0.04740** (need ~46% RMSE reduction)
- Submissions remaining: 5/5

## Response to Evaluator

**Technical verdict**: TRUSTWORTHY - The evaluator confirmed sound validation methodology with no leakage.

**Evaluator's top priority**: Debug and fully test TabPFN. 
- **My response**: TabPFN v6.3.0 requires HuggingFace authentication for gated model access. The older v0.1.10 only supports classification, not regression. This is a dead end without HF credentials. **Pivoting to feature expansion and architecture improvements instead.**

**Key concerns raised**:
1. **Ensemble with weak components** - Agreed. LightGBM (0.10019) dragged down the ensemble. Will not include weak models in future ensembles.
2. **Feature space not explored** - Agreed. DRFP and fragprints are available but unused. Analysis shows they have only ~150 non-zero columns each, so PCA to 20-50 components is feasible.
3. **Large gap to target** - Agreed. Need fundamentally different approaches, not incremental tweaks.

## Data Understanding

**Reference notebooks:**
- `exploration/eda.ipynb` - Full EDA with data shapes, distributions
- `exploration/evolver_loop2_analysis.ipynb` - Gap analysis, feature exploration

**Key patterns to exploit:**

1. **Feature expansion opportunity**: DRFP (2048→165 non-zero) and fragprints (2133→144 non-zero) can be reduced to ~20-50 PCs capturing 100% variance. These may contain patterns Spange descriptors miss.

2. **Non-linear solvent mixing**: Current linear interpolation `A*(1-pct) + B*pct` may not capture real mixture effects. Try:
   - Concatenate both solvent features + mixing ratio (don't interpolate)
   - Add interaction terms between A and B features
   - Add polynomial terms of mixing ratio

3. **Per-solvent variance**: Some solvents (Acetonitrile.Acetic Acid, IPA, Decanol) have very high SM variance (>0.43). These are harder to predict and may need special handling.

4. **Baseline gap**: Predicting mean gives RMSE=0.2353. Our best (0.08819) is 62.5% better. Target requires another 46% improvement - this is substantial.

## CRITICAL SUBMISSION CONSTRAINTS

**MANDATORY STRUCTURE:**
- The submission MUST follow the template notebook structure
- Only the last 3 cells can be modified, and ONLY the `model = MLPModel()` line can be changed
- Model must implement: `train_model(X_train, y_train)` and `predict(X_test)` methods
- Two tasks: single_solvent (leave-one-solvent-out CV, 24 folds) and full (leave-one-ramp-out CV, 13 folds)
- Target order in Y: ["Product 2", "Product 3", "SM"]

## Recommended Approaches (Priority Order)

### Priority 1: Feature Expansion with DRFP/Fragprints + PCA
**Why**: Spange descriptors (13 features) may not capture all relevant chemistry. DRFP captures reaction fingerprints, fragprints capture molecular fragments.

**Implementation:**
```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Load and reduce DRFP
drfp = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)
scaler = StandardScaler()
drfp_scaled = scaler.fit_transform(drfp)
pca = PCA(n_components=20)  # or 30-50
drfp_pca = pca.fit_transform(drfp_scaled)

# Combine with Spange
combined_features = np.hstack([spange_features, drfp_pca_features])
```

**Expected impact**: Medium-high. Different feature representations often capture different patterns.

### Priority 2: Non-Linear Solvent Mixing Features
**Why**: Linear interpolation assumes properties mix linearly, but real solvent mixtures often have non-linear effects.

**Implementation:**
```python
# Instead of: mixed = A * (1-pct) + B * pct
# Try concatenation:
mixed = np.hstack([A_features, B_features, pct, pct**2, A_features * pct, B_features * (1-pct)])
```

**Expected impact**: Medium. May help with full data task specifically.

### Priority 3: Deeper/Wider MLP Architecture
**Why**: Current architecture [128, 128, 64] may be too shallow for the complexity.

**Implementation:**
```python
# Try deeper architecture
hidden_dims = [256, 256, 128, 64]  # or [512, 256, 128, 64]

# Add residual connections
class ResidualBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim)
        )
    def forward(self, x):
        return F.relu(x + self.net(x))
```

**Expected impact**: Medium. More capacity may help if features are rich enough.

### Priority 4: Per-Target Specialized Models
**Why**: SM (starting material) follows different kinetics than products. Separate optimization may help.

**Implementation:**
```python
class PerTargetModel:
    def __init__(self):
        self.models = [MLPModel() for _ in range(3)]  # One per target
    
    def train_model(self, X_train, y_train):
        for i, model in enumerate(self.models):
            model.train_model(X_train, y_train[:, i:i+1])
    
    def predict(self, X_test):
        preds = [m.predict(X_test) for m in self.models]
        return torch.cat(preds, dim=1)
```

**Expected impact**: Medium. Different targets may have different optimal architectures.

### Priority 5: Gaussian Process Regression
**Why**: Good for small data with uncertainty quantification. May work well given dataset size (~650-1200 samples).

**Implementation:**
```python
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel

kernel = Matern(nu=2.5) + WhiteKernel()
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
```

**Expected impact**: Medium. May provide different error patterns for ensembling.

## What NOT to Try

1. **TabPFN** - Requires HuggingFace authentication for gated model. Dead end.
2. **LightGBM/XGBoost alone** - Already tested, performs worse than MLP (0.10019 vs 0.08819).
3. **Simple ensemble with weak models** - Dragged down performance. Only ensemble strong models.
4. **Hyperparameter tuning on current architecture** - Need fundamentally different approaches first.

## Validation Notes

- **CV scheme**: Leave-one-solvent-out (24 folds) for single, leave-one-ramp-out (13 folds) for full
- **Metric**: RMSE averaged across both tasks
- **No LB submissions yet** - Should submit once we see CV improvement to calibrate CV-LB gap

## Implementation Checklist

1. ✅ Model class with `train_model(X_train, y_train)` and `predict(X_test)` methods
2. ✅ Featurizer that handles both single and mixed solvents
3. ✅ Physics-informed features (Arrhenius kinetics)
4. ✅ TTA for mixed solvent symmetry
5. ✅ Ensemble of multiple seeds
6. ⬜ Feature expansion with DRFP/fragprints
7. ⬜ Non-linear mixing features
8. ⬜ Deeper architecture with residual connections
9. ⬜ Per-target specialized models

## Next Experiment Recommendation

**Experiment 003: Feature Expansion + Deeper MLP**

Combine:
1. Spange descriptors (13 features)
2. DRFP with PCA to 20 components
3. Arrhenius kinetics features (3 features)
4. Deeper MLP [256, 256, 128, 64] with residual connections
5. TTA for mixed solvents
6. Ensemble of 5 models

This addresses the evaluator's concern about unexplored feature space while maintaining the proven MLP architecture.

**Alternative if Feature Expansion doesn't help:**
- Try non-linear mixing features (concatenate A+B instead of interpolate)
- Try Gaussian Process as a different model family
- Try per-target specialized models with different architectures