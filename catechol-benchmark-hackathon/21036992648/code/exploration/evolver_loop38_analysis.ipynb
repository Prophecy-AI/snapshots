{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47c6c43",
   "metadata": {},
   "source": [
    "# Loop 38 Analysis: k-NN Failed - What Next?\n",
    "\n",
    "**Current State:**\n",
    "- Best CV: 0.008194 (exp_032)\n",
    "- Best LB: 0.0877 (exp_030)\n",
    "- Target: 0.0347\n",
    "- CV-LB relationship: LB = 4.27×CV + 0.0527 (R²=0.967)\n",
    "\n",
    "**Latest Experiment (exp_040):**\n",
    "- k-NN with k=5, distance-weighted\n",
    "- CV: 0.026414 (222% WORSE than best)\n",
    "- k-NN is NOT suitable for this problem\n",
    "\n",
    "**Key Insight from Public Kernels:**\n",
    "The 'mixall' kernel uses GroupKFold(5) instead of leave-one-out CV. This might explain the CV-LB gap - the evaluation might use a different CV scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9e35e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:57.188493Z",
     "iopub.status.busy": "2026-01-15T00:30:57.187935Z",
     "iopub.status.idle": "2026-01-15T00:30:57.994056Z",
     "shell.execute_reply": "2026-01-15T00:30:57.993662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submissions: 11\n",
      "        exp        cv       lb\n",
      "0   exp_000  0.011081  0.09816\n",
      "1   exp_001  0.012297  0.10649\n",
      "2   exp_003  0.010501  0.09719\n",
      "3   exp_005  0.010430  0.09691\n",
      "4   exp_006  0.009749  0.09457\n",
      "5   exp_007  0.009262  0.09316\n",
      "6   exp_009  0.009192  0.09364\n",
      "7   exp_012  0.009004  0.09134\n",
      "8   exp_024  0.008689  0.08929\n",
      "9   exp_026  0.008465  0.08875\n",
      "10  exp_030  0.008298  0.08772\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# All submissions data\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 0.011081, 'lb': 0.09816},\n",
    "    {'exp': 'exp_001', 'cv': 0.012297, 'lb': 0.10649},\n",
    "    {'exp': 'exp_003', 'cv': 0.010501, 'lb': 0.09719},\n",
    "    {'exp': 'exp_005', 'cv': 0.010430, 'lb': 0.09691},\n",
    "    {'exp': 'exp_006', 'cv': 0.009749, 'lb': 0.09457},\n",
    "    {'exp': 'exp_007', 'cv': 0.009262, 'lb': 0.09316},\n",
    "    {'exp': 'exp_009', 'cv': 0.009192, 'lb': 0.09364},\n",
    "    {'exp': 'exp_012', 'cv': 0.009004, 'lb': 0.09134},\n",
    "    {'exp': 'exp_024', 'cv': 0.008689, 'lb': 0.08929},\n",
    "    {'exp': 'exp_026', 'cv': 0.008465, 'lb': 0.08875},\n",
    "    {'exp': 'exp_030', 'cv': 0.008298, 'lb': 0.08772},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(f'Total submissions: {len(df)}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde8e7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:57.995505Z",
     "iopub.status.busy": "2026-01-15T00:30:57.995329Z",
     "iopub.status.idle": "2026-01-15T00:30:58.000571Z",
     "shell.execute_reply": "2026-01-15T00:30:58.000162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV-LB Relationship:\n",
      "  LB = 4.27 × CV + 0.0527\n",
      "  R² = 0.9671\n",
      "  Intercept = 0.0527\n",
      "  Target = 0.0347\n",
      "  Intercept / Target = 1.52x\n",
      "\n",
      "To reach target LB = 0.0347:\n",
      "  CV needed = -0.004218\n",
      "  IMPOSSIBLE with current approach (would need negative CV)\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['cv'], df['lb'])\n",
    "print(f'\\nCV-LB Relationship:')\n",
    "print(f'  LB = {slope:.2f} × CV + {intercept:.4f}')\n",
    "print(f'  R² = {r_value**2:.4f}')\n",
    "print(f'  Intercept = {intercept:.4f}')\n",
    "print(f'  Target = 0.0347')\n",
    "print(f'  Intercept / Target = {intercept / 0.0347:.2f}x')\n",
    "\n",
    "# What CV would we need to reach target?\n",
    "cv_needed = (0.0347 - intercept) / slope\n",
    "print(f'\\nTo reach target LB = 0.0347:')\n",
    "print(f'  CV needed = {cv_needed:.6f}')\n",
    "if cv_needed < 0:\n",
    "    print(f'  IMPOSSIBLE with current approach (would need negative CV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2887f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:58.001486Z",
     "iopub.status.busy": "2026-01-15T00:30:58.001382Z",
     "iopub.status.idle": "2026-01-15T00:30:58.005154Z",
     "shell.execute_reply": "2026-01-15T00:30:58.004787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEY INSIGHT FROM PUBLIC KERNELS ===\n",
      "\n",
      "The \"mixall\" kernel uses GroupKFold(5) instead of leave-one-out CV.\n",
      "This is a significant change to the validation strategy.\n",
      "\n",
      "Possible explanations for CV-LB gap:\n",
      "1. The evaluation uses a different CV procedure than leave-one-out\n",
      "2. There is additional test data not in our training set\n",
      "3. The evaluation uses a different random seed\n",
      "\n",
      "If the evaluation uses GroupKFold(5), our leave-one-out CV might be\n",
      "overly pessimistic (more folds = more variance in estimates).\n"
     ]
    }
   ],
   "source": [
    "# Key insight: The 'mixall' kernel uses GroupKFold(5) instead of leave-one-out\n",
    "# This might explain the CV-LB gap\n",
    "\n",
    "print('=== KEY INSIGHT FROM PUBLIC KERNELS ===')\n",
    "print()\n",
    "print('The \"mixall\" kernel uses GroupKFold(5) instead of leave-one-out CV.')\n",
    "print('This is a significant change to the validation strategy.')\n",
    "print()\n",
    "print('Possible explanations for CV-LB gap:')\n",
    "print('1. The evaluation uses a different CV procedure than leave-one-out')\n",
    "print('2. There is additional test data not in our training set')\n",
    "print('3. The evaluation uses a different random seed')\n",
    "print()\n",
    "print('If the evaluation uses GroupKFold(5), our leave-one-out CV might be')\n",
    "print('overly pessimistic (more folds = more variance in estimates).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c643827a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:58.006544Z",
     "iopub.status.busy": "2026-01-15T00:30:58.006302Z",
     "iopub.status.idle": "2026-01-15T00:30:58.010456Z",
     "shell.execute_reply": "2026-01-15T00:30:58.010094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPROACHES TRIED ===\n",
      "\n",
      "exp_000: MLP (baseline)\n",
      "  CV=0.011081 - Works well\n",
      "\n",
      "exp_001: LightGBM\n",
      "  CV=0.012297 - Slightly worse than MLP\n",
      "\n",
      "exp_002: DRFP + PCA\n",
      "  CV=0.016948 - Much worse\n",
      "\n",
      "exp_003: Spange + DRFP combined\n",
      "  CV=0.010501 - Better than baseline\n",
      "\n",
      "exp_004: Deep Residual MLP\n",
      "  CV=0.051912 - FAILED - too complex\n",
      "\n",
      "exp_005: Large Ensemble (15 models)\n",
      "  CV=0.010430 - Marginal improvement\n",
      "\n",
      "exp_006: Simpler MLP [64, 32]\n",
      "  CV=0.009749 - BETTER - simpler is better\n",
      "\n",
      "exp_008: Even Simpler [32, 16]\n",
      "  CV=0.009262 - BETTER\n",
      "\n",
      "exp_009: Ridge Regression\n",
      "  CV=0.009192 - Comparable to MLP\n",
      "\n",
      "exp_012: MLP + LGBM ensemble\n",
      "  CV=0.009004 - BETTER\n",
      "\n",
      "exp_024: ACS PCA features\n",
      "  CV=0.008689 - BETTER\n",
      "\n",
      "exp_026: Weighted loss\n",
      "  CV=0.008465 - BETTER\n",
      "\n",
      "exp_030: GP + MLP + LGBM\n",
      "  CV=0.008298 - BEST LB\n",
      "\n",
      "exp_031: Higher GP weight\n",
      "  CV=0.009174 - WORSE\n",
      "\n",
      "exp_032: Pure GP\n",
      "  CV=0.008194 - BEST CV\n",
      "\n",
      "exp_036: Feature selection\n",
      "  CV=0.009573 - WORSE\n",
      "\n",
      "exp_040: k-NN\n",
      "  CV=0.026414 - MUCH WORSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have been tried\n",
    "print('=== APPROACHES TRIED ===')\n",
    "print()\n",
    "approaches = [\n",
    "    ('MLP (baseline)', 'exp_000', 0.011081, 'Works well'),\n",
    "    ('LightGBM', 'exp_001', 0.012297, 'Slightly worse than MLP'),\n",
    "    ('DRFP + PCA', 'exp_002', 0.016948, 'Much worse'),\n",
    "    ('Spange + DRFP combined', 'exp_003', 0.010501, 'Better than baseline'),\n",
    "    ('Deep Residual MLP', 'exp_004', 0.051912, 'FAILED - too complex'),\n",
    "    ('Large Ensemble (15 models)', 'exp_005', 0.010430, 'Marginal improvement'),\n",
    "    ('Simpler MLP [64, 32]', 'exp_006', 0.009749, 'BETTER - simpler is better'),\n",
    "    ('Even Simpler [32, 16]', 'exp_008', 0.009262, 'BETTER'),\n",
    "    ('Ridge Regression', 'exp_009', 0.009192, 'Comparable to MLP'),\n",
    "    ('MLP + LGBM ensemble', 'exp_012', 0.009004, 'BETTER'),\n",
    "    ('ACS PCA features', 'exp_024', 0.008689, 'BETTER'),\n",
    "    ('Weighted loss', 'exp_026', 0.008465, 'BETTER'),\n",
    "    ('GP + MLP + LGBM', 'exp_030', 0.008298, 'BEST LB'),\n",
    "    ('Higher GP weight', 'exp_031', 0.009174, 'WORSE'),\n",
    "    ('Pure GP', 'exp_032', 0.008194, 'BEST CV'),\n",
    "    ('Feature selection', 'exp_036', 0.009573, 'WORSE'),\n",
    "    ('k-NN', 'exp_040', 0.026414, 'MUCH WORSE'),\n",
    "]\n",
    "\n",
    "for name, exp, cv, result in approaches:\n",
    "    print(f'{exp}: {name}')\n",
    "    print(f'  CV={cv:.6f} - {result}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ace1c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:58.011339Z",
     "iopub.status.busy": "2026-01-15T00:30:58.011221Z",
     "iopub.status.idle": "2026-01-15T00:30:58.014719Z",
     "shell.execute_reply": "2026-01-15T00:30:58.014376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STRATEGIC OPTIONS ===\n",
      "\n",
      "OPTION 1: Try GroupKFold(5) locally\n",
      "  - If CV scores change significantly, this might explain the CV-LB gap\n",
      "  - Could reveal that our leave-one-out CV is overly pessimistic\n",
      "\n",
      "OPTION 2: Submit exp_032 (best CV)\n",
      "  - CV: 0.008194 (best)\n",
      "  - Predicted LB: 4.27 × 0.008194 + 0.0527 = 0.0877\n",
      "  - This is the same as exp_030 LB, so unlikely to improve\n",
      "\n",
      "OPTION 3: Try a completely different approach\n",
      "  - Solvent clustering + per-cluster models\n",
      "  - Adversarial validation to identify distribution shift\n",
      "  - Meta-learning / MAML\n",
      "\n",
      "OPTION 4: Focus on reducing the intercept\n",
      "  - The intercept (0.0527) is the bottleneck\n",
      "  - Need to find an approach that has a lower intercept\n",
      "  - This requires understanding WHY the intercept exists\n"
     ]
    }
   ],
   "source": [
    "# What's the best path forward?\n",
    "print('=== STRATEGIC OPTIONS ===')\n",
    "print()\n",
    "print('OPTION 1: Try GroupKFold(5) locally')\n",
    "print('  - If CV scores change significantly, this might explain the CV-LB gap')\n",
    "print('  - Could reveal that our leave-one-out CV is overly pessimistic')\n",
    "print()\n",
    "print('OPTION 2: Submit exp_032 (best CV)')\n",
    "print('  - CV: 0.008194 (best)')\n",
    "print('  - Predicted LB: 4.27 × 0.008194 + 0.0527 = 0.0877')\n",
    "print('  - This is the same as exp_030 LB, so unlikely to improve')\n",
    "print()\n",
    "print('OPTION 3: Try a completely different approach')\n",
    "print('  - Solvent clustering + per-cluster models')\n",
    "print('  - Adversarial validation to identify distribution shift')\n",
    "print('  - Meta-learning / MAML')\n",
    "print()\n",
    "print('OPTION 4: Focus on reducing the intercept')\n",
    "print('  - The intercept (0.0527) is the bottleneck')\n",
    "print('  - Need to find an approach that has a lower intercept')\n",
    "print('  - This requires understanding WHY the intercept exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ca02ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:58.015601Z",
     "iopub.status.busy": "2026-01-15T00:30:58.015499Z",
     "iopub.status.idle": "2026-01-15T00:30:58.018866Z",
     "shell.execute_reply": "2026-01-15T00:30:58.018488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WHAT CAUSES THE INTERCEPT? ===\n",
      "\n",
      "The intercept (0.0527) represents the LB score when CV = 0.\n",
      "This is impossible in practice, but it tells us something important:\n",
      "\n",
      "Possible causes:\n",
      "1. Distribution shift between train and test solvents\n",
      "   - The test solvents are fundamentally different from training solvents\n",
      "   - Our models learn patterns that dont generalize\n",
      "\n",
      "2. Different CV procedure in evaluation\n",
      "   - If evaluation uses GroupKFold(5), our leave-one-out CV is different\n",
      "   - The intercept might be an artifact of this mismatch\n",
      "\n",
      "3. Additional test data not in our training set\n",
      "   - The evaluation might include solvents we havent seen\n",
      "   - Our models cant extrapolate to these new solvents\n",
      "\n",
      "4. Overfitting to the training distribution\n",
      "   - Our models are too specialized to the training solvents\n",
      "   - Need more regularization or simpler models\n"
     ]
    }
   ],
   "source": [
    "# The key question: What causes the intercept?\n",
    "print('=== WHAT CAUSES THE INTERCEPT? ===')\n",
    "print()\n",
    "print('The intercept (0.0527) represents the LB score when CV = 0.')\n",
    "print('This is impossible in practice, but it tells us something important:')\n",
    "print()\n",
    "print('Possible causes:')\n",
    "print('1. Distribution shift between train and test solvents')\n",
    "print('   - The test solvents are fundamentally different from training solvents')\n",
    "print('   - Our models learn patterns that dont generalize')\n",
    "print()\n",
    "print('2. Different CV procedure in evaluation')\n",
    "print('   - If evaluation uses GroupKFold(5), our leave-one-out CV is different')\n",
    "print('   - The intercept might be an artifact of this mismatch')\n",
    "print()\n",
    "print('3. Additional test data not in our training set')\n",
    "print('   - The evaluation might include solvents we havent seen')\n",
    "print('   - Our models cant extrapolate to these new solvents')\n",
    "print()\n",
    "print('4. Overfitting to the training distribution')\n",
    "print('   - Our models are too specialized to the training solvents')\n",
    "print('   - Need more regularization or simpler models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c89a7f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T00:30:58.019855Z",
     "iopub.status.busy": "2026-01-15T00:30:58.019753Z",
     "iopub.status.idle": "2026-01-15T00:30:58.023482Z",
     "shell.execute_reply": "2026-01-15T00:30:58.023098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RECOMMENDATION ===\n",
      "\n",
      "Given the current state:\n",
      "- Best CV: 0.008194 (exp_032)\n",
      "- Best LB: 0.0877 (exp_030)\n",
      "- Target: 0.0347\n",
      "- Gap: 2.53x\n",
      "- Submissions remaining: 5\n",
      "\n",
      "The CV-LB relationship is highly linear (R² = 0.967).\n",
      "All approaches follow the same pattern.\n",
      "The intercept (0.0527) > target (0.0347) means we CANNOT reach target\n",
      "with the current approach, no matter how much we improve CV.\n",
      "\n",
      "PRIORITY 1: Try GroupKFold(5) locally\n",
      "  - This is a quick experiment that could reveal the CV-LB gap cause\n",
      "  - If CV scores change significantly, we might have found the issue\n",
      "\n",
      "PRIORITY 2: Try a fundamentally different approach\n",
      "  - Solvent clustering + per-cluster models\n",
      "  - Domain adaptation techniques\n",
      "  - Meta-learning / MAML\n",
      "\n",
      "PRIORITY 3: Submit exp_032 (best CV) to verify CV-LB relationship\n",
      "  - This uses 1 submission but gives us more data points\n",
      "  - Could reveal if the relationship has changed\n"
     ]
    }
   ],
   "source": [
    "# Recommendation\n",
    "print('=== RECOMMENDATION ===')\n",
    "print()\n",
    "print('Given the current state:')\n",
    "print('- Best CV: 0.008194 (exp_032)')\n",
    "print('- Best LB: 0.0877 (exp_030)')\n",
    "print('- Target: 0.0347')\n",
    "print('- Gap: 2.53x')\n",
    "print('- Submissions remaining: 5')\n",
    "print()\n",
    "print('The CV-LB relationship is highly linear (R² = 0.967).')\n",
    "print('All approaches follow the same pattern.')\n",
    "print('The intercept (0.0527) > target (0.0347) means we CANNOT reach target')\n",
    "print('with the current approach, no matter how much we improve CV.')\n",
    "print()\n",
    "print('PRIORITY 1: Try GroupKFold(5) locally')\n",
    "print('  - This is a quick experiment that could reveal the CV-LB gap cause')\n",
    "print('  - If CV scores change significantly, we might have found the issue')\n",
    "print()\n",
    "print('PRIORITY 2: Try a fundamentally different approach')\n",
    "print('  - Solvent clustering + per-cluster models')\n",
    "print('  - Domain adaptation techniques')\n",
    "print('  - Meta-learning / MAML')\n",
    "print()\n",
    "print('PRIORITY 3: Submit exp_032 (best CV) to verify CV-LB relationship')\n",
    "print('  - This uses 1 submission but gives us more data points')\n",
    "print('  - Could reveal if the relationship has changed')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
