{
  "query": "What is the best achievable score for catechol reaction yield prediction with tabular machine learning methods?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The provided sources do not contain a reported quantitative score (e.g., R\u00b2, MAE) for the highest\u2011performing tabular machine\u2011learning model on the catechol yield benchmark. ([openreview.net](https://openreview.net/pdf?id=6l8q74TabE), [arxiv.org](https://arxiv.org/html/2506.07619v1))",
      "url": ""
    },
    {
      "title": "",
      "text": "The Catechol Benchmark: Time-series Solvent\nSelection Data for Few-shot Machine Learning\nToby Boyne1\u2217, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College London, London, UK1\nDepartment of Chemistry, Imperial College London, London, UK2\nSOLVE Chemistry, London, UK3\nAbstract\n1 Machine learning has promised to change the landscape of laboratory chem\u00022 istry, with impressive results in molecular property prediction and reaction retro\u00023 synthesis. However, chemical datasets are often inaccessible to the machine\n4 learning community as they tend to require cleaning, thorough understanding of the\n5 chemistry, or are simply not available. In this paper, we introduce a novel dataset\n6 for yield prediction, providing the first-ever transient flow dataset for machine\n7 learning benchmarking, covering over 1200 process conditions. While previous\n8 datasets focus on discrete parameters, our experimental set-up allow us to sample\n9 a large number of continuous process conditions, generating new challenges for\n10 machine learning models. We focus on solvent selection, a task that is particularly\n11 difficult to model theoretically and therefore ripe for machine learning applica\u000212 tions. We showcase benchmarking for regression algorithms, transfer-learning\n13 approaches, feature engineering, and active learning, with important applications\n14 towards solvent replacement and sustainable manufacturing.\n15 1 Introduction\n16 Machine learning (ML) and artificial intelligence (AI) have showcased enormous potential in em\u000217 powering the world of the natural sciences: from famous examples such as AlphaFold for protein\n18 predictions [1], to fusion reactor control [2], disease detection [3], battery design [4], and material\n19 discovery [5], among many more. However, we seldom see the machine learning community bench\u000220 mark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world\n21 data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how\n22 expensive the data can be to produce, resulting in many datasets being locked behind closed doors by\n23 large companies.\n24 AIchemy (https://aichemy.ac.uk) is an interdisciplinary UK hub with the mission of transform\u000225 ing the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as\n26 addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE\n27 Chemistry (https://www.solvechemistry.com), we present a first important step into addressing\n28 the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data\n29 machine learning algorithms for chemistry.\n30 Solvent selection is one of the biggest challenges for chemical manufacturing, with solvents often\n31 being the main source of waste in the manufacturing process [6]. Increased regulation on solvents and\n32 a drive to making process manufacturing more sustainable led to an interest in the discovery of greener\n\u2217\nt.boyne23@imperial.ac.uk ;\n\u2020\njose@solvechemistry.com\nSubmitted to 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Do not distribute.\nFigure 1: Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the\nreaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement\nproducts. We investigate the yield of the reaction for a range of different solvents. Product 1 was not\nobserved and reacted immediately to form Product 2 and later 3.\n33 solvents and for improved solvent replacement tools. However, most of the solvent replacement tools\n34 focus purely on learning unsupervised representations of solvents, with the hope that experimentalists\n35 can find solvents with similar properties to replace those with environmental concerns. A much\n36 stronger approach would consider the interaction of a variety of different solvents with a reaction of\n37 interest to directly predict reaction yields, in such a way that the best possible solvent can be selected\n38 according to a yield-sustainability trade-off.\n39 Machine learning approaches have been shown to be a powerful tool for the prediction of chemical\n40 reaction conditions. Success has been reported in retro-synthesis [7, 8], condition recommendations\n41 [9], product predictions [10, 11], among others. While yield prediction has proven to be more difficult\n42 due to large inconsistencies in procedure and data reporting [12], we have still seen promising yield\n43 prediction results for smaller and more carefully curated datasets [13\u201316]. However, these datasets\n44 lack the continuous reaction conditions, such as temperature and residence time, that are required to\n45 scale-up processes to practical manufacturing conditions.\n46 In this paper, we release the first machine-learning-ready transient flow dataset, a framework that\n47 allows for quick and efficient screening of continuous reaction conditions. We specifically provide\n48 yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure 1, with dense\n49 measurements across the residence time, temperature, and solvent space. We answer the call for\n50 more flow chemistry reaction data [17], further showcase how this type of kinetic data poses new\n51 challenges to current machine learning methods for chemistry, and identify potential solutions.\n52 1.1 Related works\n53 Reaction datasets are common in chemistry research, but their suitability for machine learning\n54 benchmarking tends to be poor. This can be a result of improper formatting or documentation,\n55 incomplete information about reaction conditions or the experimental set-up, or the lack of machine\n56 readability, leading to limited usage by the ML community. However, some effort has been made\n57 to address this, with the biggest example being the creation of the Open Reaction Database (ORD)\n58 [18], a repository containing over 2M different reactions, many of which come from US patent data\n59 (USPTO) [19]. However, the dataset falls short in some aspects, in particular with respect to machine\n60 learning readiness and data inconsistencies across reactions.\n61 ORDerly [12] allows for easy cleaning and preparation of ORD data, showing the promise of the\n62 dataset for forward and retro-synthetic prediction using transformers; however, it also shows that\n63 yield prediction cannot be done well due to data inconsistencies. Schwaller et al. [13] drew similar\n64 conclusions when using the USPTO dataset, stating that reaction conditions such as temperature,\n65 concentrations, and duration have a significant effect on yield. The assumption that every reaction in\n66 the dataset is optimized for reaction parameters proved too loose, resulting in inaccurate predictive\n67 models for yield, and highlighting the importance of creating datasets with full (including potentially\n68 sub-optimal) reaction conditions.\n69 More relevant to our work, Perera et al. [20] introduced a dataset of 5760 Suzuki-Miyaura cross\u000270 coupling reactions, Ahneman et al. [21] introduced a dataset of 3956 Buchwald\u2013Hartwig aminations,\n71 and Prieto Kullmer et al. [22] investigated screening additives for Ni-catalysed reactions, all for the\n72 purposes of yield prediction. The datasets have been used in the benchmarking of Gaussian processes\n73 and Bayesian neural networks [14], deep learning models [13], language-model-based embeddings\n2\n74 [16], data augmentation techniques [23], and Bayesian optimisation [15]. In each case, the datasets\n75 focus on discrete reaction variables, such as ligand, base, additives, or reactants at fixed temperatures\n76 and residence times. We are instead introducing a dataset rich in continuous reaction conditions (in\n77 our case temperature ...",
      "url": "https://openreview.net/pdf?id=6l8q74TabE"
    },
    {
      "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning",
      "text": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\n# The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\nToby Boyne1, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College, London, UK1\nDepartment of Chemistry, Imperial College, London, UK2\nSOLVE Chemistry, London, UK3t.boyne23@imperial.ac.uk;\u2020jose@solvechemistry.com\n###### Abstract\nMachine learning has promised to change the landscape of laboratory chemistry, with impressive results in molecular property prediction and reaction retro-synthesis. However, chemical datasets are often inaccessible to the machine learning community as they tend to require cleaning, thorough understanding of the chemistry, or are simply not available. In this paper, we introduce a novel dataset for yield prediction, providing the first-ever transient flow dataset for machine learning benchmarking, covering over 1200 process conditions. While previous datasets focus on discrete parameters, our experimental set-up allow us to sample a large number of continuous process conditions, generating new challenges for machine learning models. We focus on solvent selection, a task that is particularly difficult to model theoretically and therefore ripe for machine learning applications. We showcase benchmarking for regression algorithms, transfer-learning approaches, feature engineering, and active learning, with important applications towards solvent replacement and sustainable manufacturing.\n## 1Introduction\nMachine learning (ML) and artificial intelligence (AI) have showcased enormous potential in empowering the world of the natural sciences: from famous examples such as AlphaFold for protein predictions> [\n[> 1\n](https://arxiv.org/html/2506.07619v1#bib.bib1)> ]\n, to fusion reactor control> [\n[> 2\n](https://arxiv.org/html/2506.07619v1#bib.bib2)> ]\n, disease detection> [\n[> 3\n](https://arxiv.org/html/2506.07619v1#bib.bib3)> ]\n, battery design> [\n[> 4\n](https://arxiv.org/html/2506.07619v1#bib.bib4)> ]\n, and material discovery> [\n[> 5\n](https://arxiv.org/html/2506.07619v1#bib.bib5)> ]\n, among many more. However, we seldom see the machine learning community benchmark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how expensive the data can be to produce, resulting in many datasets being locked behind closed doors by large companies.\nAIchemy ([https://aichemy.ac.uk](https://aichemy.ac.uk)) is an interdisciplinary UK hub with the mission of transforming the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE Chemistry ([https://www.solvechemistry.com](https://www.solvechemistry.com)), we present a first important step into addressing the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data machine learning algorithms for chemistry.\nSolvent selection is one of the biggest challenges for chemical manufacturing, with solvents often being the main source of waste in the manufacturing process> [\n[> 6\n](https://arxiv.org/html/2506.07619v1#bib.bib6)> ]\n. Increased regulation on solvents and a drive to making process manufacturing more sustainable led to an interest in the discovery of greener solvents and for improved solvent replacement tools. However, most of the solvent replacement tools focus purely on learning unsupervised representations of solvents, with the hope that experimentalists can find solvents with similar properties to replace those with environmental concerns. A much stronger approach would consider the interaction of a variety of different solvents with a reaction of interest to directly predict reaction yields, in such a way that the best possible solvent can be selected according to a yield-sustainability trade-off.\nMachine learning approaches have been shown to be a powerful tool for the prediction of chemical reaction conditions. Success has been reported in retro-synthesis> [\n[> 7\n](https://arxiv.org/html/2506.07619v1#bib.bib7)> , [> 8\n](https://arxiv.org/html/2506.07619v1#bib.bib8)> ]\n, condition recommendations> [\n[> 9\n](https://arxiv.org/html/2506.07619v1#bib.bib9)> ]\n, product predictions> [\n[> 10\n](https://arxiv.org/html/2506.07619v1#bib.bib10)> , [> 11\n](https://arxiv.org/html/2506.07619v1#bib.bib11)> ]\n, among others. While yield prediction has proven to be more difficult due to large inconsistencies in procedure and data reporting> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\n, we have still seen promising yield prediction results for smaller and more carefully curated datasets> [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> , [> 14\n](https://arxiv.org/html/2506.07619v1#bib.bib14)> , [> 15\n](https://arxiv.org/html/2506.07619v1#bib.bib15)> , [> 16\n](https://arxiv.org/html/2506.07619v1#bib.bib16)> ]\n. However, these datasets lack the continuous reaction conditions, such as temperature and residence time, that are required to scale-up processes to practical manufacturing conditions.\nIn this paper, we release the first machine-learning-ready transient flow dataset, a framework that allows for quick and efficient screening of continuous reaction conditions. We specifically provide yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure[1](https://arxiv.org/html/2506.07619v1#S1.F1), with dense measurements across the residence time, temperature, and solvent space. We further showcase how this type ofkinetic dataposes new challenges to current machine learning methods for chemistry, and identify how the challenges can potentially be tackled by the community.\n![Refer to caption](extracted/6524982/figures/Project2_rxn.png)Figure 1:Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the reaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement products. We investigate the yield of the reaction for a range of different solvents. Product 1 was not observed and reacted immediately to form Product 2 and later 3.\n### 1.1Related works\nReaction datasets are common in chemistry research, but their suitability for machine learning benchmarking tends to be poor. This can be a result of improper formatting or documentation, incomplete information about reaction conditions or the experimental set-up, or the lack of machine readability, leading to limited usage by the ML community. However, some effort has been made to address this, with the biggest example being the creation of the Open Reaction Database (ORD)> [\n[> 17\n](https://arxiv.org/html/2506.07619v1#bib.bib17)> ]\n, a repository containing over 2M different reactions, many of which come from US patent data (USPTO)> [\n[> 18\n](https://arxiv.org/html/2506.07619v1#bib.bib18)> ]\n. However, the dataset falls short in some aspects, in particular with respect to machine learning readiness and data inconsistencies across reactions.\nORDerly> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\nallows for easy cleaning and preparation of ORD data, showing the promise of the dataset for forward and retro-synthetic prediction using transformers; however, it also shows that yield prediction cannot be done well due to data inconsistencies.> Schwaller et\u00a0al. [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> ]\ndrew similar conclusions when using the USPTO dataset, stating that reaction conditions such as temperature, concentrations, and duration have a significant effect on yield. The assumption that every reaction in the dataset is optimized for reaction param...",
      "url": "https://arxiv.org/html/2506.07619v1"
    },
    {
      "title": "Computer Science > Machine Learning",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions",
      "text": "[View\u00a0PDF\u00a0Version](https://pubs.rsc.org/en/content/articlepdf/2023/sc/d3sc03902a)[Previous\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03539e)[Next\u00a0Article](https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03641c)\n\nOpen Access Article\nThis Open Access Article is licensed under a [Creative Commons Attribution 3.0 Unported Licence](http://creativecommons.org/licenses/by/3.0/)\n\nDOI:\u00a0[10.1039/D3SC03902A](https://doi.org/10.1039/D3SC03902A)\n(Edge Article)\n[Chem. Sci.](https://doi.org/10.1039/2041-6539/2010), 2023, **14**, 10835-10846\n\n# The challenge of balancing model sensitivity and robustness in predicting yields: a benchmarking study of amide coupling reactions [\u2020](https://pubs.rsc.org/pubs.rsc.org\\#fn1)\n\nZhen\nLiu\na,\nYurii S.\nMoroz\nbcd and Olexandr\nIsayev\n\\*aaDepartment of Chemistry, Mellon College of Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA. E-mail: [olexandr@olexandrisayev.com](mailto:olexandr@olexandrisayev.com)bEnamine Ltd, Ky\u00efv, 02660, UkrainecChemspace LLC, Ky\u00efv, 02094, UkrainedTaras Shevchenko National University of Ky\u00efv, Ky\u00efv, 01601, Ukraine\n\nReceived\n27th July 2023\n, Accepted 12th September 2023\n\nFirst published on 13th September 2023\n\n## Abstract\n\nAccurate prediction of reaction yield is the holy grail for computer-assisted synthesis prediction, but current models have failed to generalize to large literature datasets. To understand the causes and inspire future design, we systematically benchmarked the yield prediction task. We carefully curated and augmented a literature dataset of 41239 amide coupling reactions, each with information on reactants, products, intermediates, yields, and reaction contexts, and provided 3D structures for the molecules. We calculated molecular features related to 2D and 3D structure information, as well as physical and electronic properties. These descriptors were paired with 4 categories of machine learning methods (linear, kernel, ensemble, and neural network), yielding valuable benchmarks about feature and model performance. Despite the excellent performance on a high-throughput experiment (HTE) dataset (R2 around 0.9), no method gave satisfactory results on the literature data. The best performance was an R2 of 0.395 \u00b1 0.020 using the stack technique. Error analysis revealed that reactivity cliff and yield uncertainty are among the main reasons for incorrect predictions. Removing reactivity cliffs and uncertain reactions boosted the R2 to 0.457 \u00b1 0.006. These results highlight that yield prediction models must be sensitive to the reactivity change due to the subtle structure variance, as well as be robust to the uncertainty associated with yield measurements.\n\n## Introduction\n\nComputer-assisted synthesis prediction (CASP) is a field of computational chemistry that aims to develop algorithms and software tools to assist chemists in predicting the outcomes of chemical reactions. CASP uses machine learning (ML) and artificial intelligence (AI) techniques to predict the feasibility, yield, and optimal conditions for a chemical reaction. Recent exploratory studies in the field of reaction predictions, show applications in retrosynthesis, [1,2](https://pubs.rsc.org/pubs.rsc.org#cit1) product prediction, [3\u20135](https://pubs.rsc.org/pubs.rsc.org#cit3) selectivity, [6](https://pubs.rsc.org/pubs.rsc.org#cit6) and other relevant tasks. [7,8](https://pubs.rsc.org/pubs.rsc.org#cit7) Accurately predicting reaction yields is one of the key objectives in CASP as many reaction-related tasks can be framed as yield optimization problems. Yield serves as the ultimate metric for selecting reagents in a single reaction or planning a synthesis pathway. However, despite its importance, predicting the theoretical yield remains challenging because the yield depends on many observable and unobservable factors throughout the reaction process, including the interaction between molecules, environment conditions, and human operations.\n\nWhile impressive yield prediction performance (R2 is around 0.9) has been achieved in many high-throughput experiment (HTE) datasets, the yield prediction R2 score on large literature datasets is usually unsatisfactory. [9\u201316](https://pubs.rsc.org/pubs.rsc.org#cit9) For example, the Doyle group reported an example of predicting reaction yields with a random forest model on the Buchwald\u2013Hartwig HTE dataset. [9](https://pubs.rsc.org/pubs.rsc.org#cit9) The dataset contains 4608 C\u2013N cross-coupling reactions and the R2 score and mean absolute error (MAE) were 0.92 and 7.8%, respectively. Since then, the dataset has become a standard benchmark dataset for many yield prediction models. Schwaller et al. reported a Yield-BERT model for reaction yield predictions. [10](https://pubs.rsc.org/pubs.rsc.org#cit10) Although the R2 score for the yield prediction task was as high as 0.94 on the Buchwald\u2013Hartwig dataset, [9](https://pubs.rsc.org/pubs.rsc.org#cit9) the performance dropped sharply (i.e., R2 around 0.2) on the literature dataset. [17,18](https://pubs.rsc.org/pubs.rsc.org#cit17) The staggering performance difference of yield prediction on the HTE dataset and the literature dataset is widespread. Recently, Grzybowski [11](https://pubs.rsc.org/pubs.rsc.org#cit11) and Glorius [15](https://pubs.rsc.org/pubs.rsc.org#cit15) studied this phenomenon, suggesting that the unsatisfactory ML performance may be due to the popular trend in the literature dataset induced by human bias in experiment design and result reporting. However, augmenting the dataset with zero or low-yield reactions did not significantly improve the performance, indicating that additional factors might degrade the model performance.\n\nTo understand the causes for failures in a large literature dataset, we systematically investigated the yield prediction task. We tested 4 categories of ML models (i.e., linear methods, kernel methods, ensemble methods, and neural networks) on an HTE yield dataset and a large literature yield dataset. We utilized a set of 4608 Buchwald\u2013Hartwig reactions from Doyle [9](https://pubs.rsc.org/pubs.rsc.org#cit9) et al. to represent the HTE dataset, given its extensive prior modeling. We curated 41239 amide coupling reactions from Reaxys [19](https://pubs.rsc.org/pubs.rsc.org#cit19) to represent the literature dataset. These reactions were chosen due to their significance in medicinal chemistry and the substantial volume of available data. While the Buchwald\u2013Hartwig reactions and the amide coupling reactions are very different, they possess characteristics inherent to the HTE and large literature datasets, respectively. The phenomena observed in the context of Buchwald\u2013Hartwig reactions and amide coupling reactions can be extrapolated to typical HTE datasets and large literature datasets, respectively. Besides the SMILES of reactants and products, the reaction context (i.e., time, temperature, reagents, condition, and solvent) was also extracted where possible from Reaxys to construct the amide coupling dataset. Please note that the reaction yields were extracted as they appeared in the Reaxys database, regardless of the reaction scale. Also, we augmented the literature dataset with reaction intermediates, optimized 3D structures of the molecules, and 2D/3D descriptors derived from the SMILES and conformers. All amide coupling reactions were catalyzed by carbodiimides to minimize irrelevant variables in this investigation. The carbodiimides include 1-ethyl-3-(3-dimethylaminopropyl)carbodiimide (EDC), N,N\u2032-dicyclohexylcarbodiimide (DCC), and N,N\u2032-diisopropylcarbodiimide (DIC). The combination of different reaction descriptors and model categories enabled a systematic yield prediction benchmark, providing insights into the key factors that influence the reaction yield prediction challenge.\n\nOur results demonstrated that most models gave unsatisfactory predictions (R2 < 0.5) in a large and diverse literature dataset even if they achieved excellent predictions (R2 \\> 0.9) on a caref...",
      "url": "https://pubs.rsc.org/en/content/articlehtml/2023/sc/d3sc03902a"
    },
    {
      "title": "Predicting the outcomes of organic reactions via machine learning: are current descriptors sufficient?",
      "text": "Scientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 1\nwww.nature.com/scientificreports\nPredicting the outcomes of organic \nreactions via machine learning: are \ncurrent descriptors sufficient?\nG. Skoraczy\u0144ski1, P. Dittwald2, B. Miasojedow1, S. Szymku\u01072, E. P. Gajewska2, \nB. A. Grzybowski2,3 & A. Gambin1\nAs machine learning/artificial intelligence algorithms are defeating chess masters and, most recently, \nGO champions, there is interest \u2013 and hope \u2013 that they will prove equally useful in assisting chemists \nin predicting outcomes of organic reactions. This paper demonstrates, however, that the applicability \nof machine learning to the problems of chemical reactivity over diverse types of chemistries remains \nlimited \u2013 in particular, with the currently available chemical descriptors, fundamental mathematical \ntheorems impose upper bounds on the accuracy with which raction yields and times can be predicted. \nImproving the performance of machine-learning methods calls for the development of fundamentally \nnew chemical descriptors.\nWith the dawn of the big-data era1\u20134\n, high hopes have been pinned at the ability of machine learning, ML, algo\u0002rithms5\n to analyze the large body of existing chemical data, and to derive from it models predictive of various \naspects of chemical reactivity. ML methods have already proven very successful in applications ranging from \nspeech or image recognition6\n, to medical diagnostics7, bioinformatics8, and economics9. There have also been \nsome encouraging examples of using ML to predict biological activities of small molecules10\u201312, solubilities13, \ncrystal structures14, properties of organic photovoltaics15 and, recently, compositions of reaction mixtures and/\nor reaction conditions leading to templated vanadium selenites16. This last example is quite spectacular in that \nmachine-learning performed better than the collective knowledge and intuition of chemists who had previously \nworked on the problem. On the other hand, demonstrations in organic synthetic chemistry are few in number \nand limited to narrow datasets of similar and/or very simple reaction classes17\u201321. What is largely missing are \nstudies that would quantify the general applicability of ML methods to diverse chemistries.\nThe main objective of this work is therefore to assess in a quantitative manner whether ML methods can pre\u0002dict the outcomes of diverse organic reaction with practically-relevant accuracy. In particular, we use a wide range \nof currently available chemical descriptors and various ML algorithms to examine whether they can predictively \ncategorize two quantities which are important in organic-synthetic practice and for which ample training exam\u0002ples are available (here, close to 0.5 million reactions each): (i) reaction yields (binary classification high vs. low) \nand (ii) reaction times (binary classification rapid vs. slow). It is important to note that the training set we use \ncomprises reactions not necessarily accounting for full stoichiometry (i.e., no atomically balanced; see examples \nin Fig.\u00a01). For reactions with manually curated full stoichiometry, thermodynamic models have recently been \nshown22 to achieve\u00b115% accuracy of yield prediction, However, organic reactions are typically drawn by chem\u0002ists without accounting for all small reagents or side-products \u2013 in this light, the current work is a real-world test \nfor the machine learning methods to extract reactivity trends from reactions as they are deposited in the chemical \nliterature or in reaction databases.\nThe results of our work are somewhat negative but, we believe, thought-provoking. Irrespective of the spe\u0002cific ML method applied, the number of molecules in the training set, or the nature and the number of features/\ndescriptors used to train the model, the accuracy of binary yield prediction is only c.a. 65\u00b15% (i.e., error ~35%) \nand that of reaction-time prediction, c.a. 75\u00b15% (error ~25%). Another important conclusion of this work is \n1Faculty of Mathematics, Informatics, and Mechanics, University of Warsaw, 02-097, Warsaw, Poland. 2DARPA \nMake-It Program & the Institute of Organic Chemistry, Polish Academy of Sciences, Warsaw, Poland. 3\nCenter for \nSoft and Living Matter of Korea\u2019s Institute for Basic Science (IBS), Department of Chemistry, Ulsan National Institute \nof Science and Technology, Ulsan, South Korea. G. Skoraczy\u0144ski and P. Dittwald contributed equally to this work. \nCorrespondence and requests for materials should be addressed to B.A.G. (email: grzybor72@unist.ac.kr) or A.G. \n(email: aniag@mimuw.edu.pl)\nReceived: 16 December 2016\nAccepted: 6 April 2017\nPublished: xx xx xxxx\nOPEN\nwww.nature.com/scientificreports/\nScientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 2\nthat it can be proven rigorously \u2013 by the so-called Bayes classifier error estimates \u2013 that with the currently avail\u0002able representations of molecules, (i.e., chemical descriptors), these outcomes cannot be significantly improved. \nNaturally, it can always be argued that \u201cbetter\u201d representations of molecules can be developed, though it is some\u0002what unclear how to account for the immense structural and mechanistic diversity of organic reactions23, their \noften-encountered sensitivity to reaction conditions, or even inherent day-to-day irreproducibilities in reaction \noutcomes. We will touch upon these interesting issues in the last part of the paper. In the meantime, we see the \nmain virtue of our work in potentially stimulating new research on molecular representations and their use in \nchemical machine-learning24.\nMethods\nDatasets. The initial datasets, courtesy of GSI and Reaxys, comprised ~1,000,000 reactions for which the \nyields were reported and ~600,000 reactions reporting reaction times. These sets were pruned for incomplete \nentries and duplicate reactions. When the same reaction was reported with multiple yields, the highest value \nwas taken; if the same reaction was reported with multiple times, the shortest one was chosen. Ultimately, each \nset comprised ~450,000 reaction entries of which 325,000 had both the yields and times reported (within this \ncommon subset, the values of yields and times had a nearly zero correlation, see Supplementary Information, SI, \nFigure\u00a0S5).\nML methods. Various ML methods were implemented and tested including logistic regression25, support \nvector machines (SVM)26, neural networks27, 28, extremely randomized trees (ERT)29 and random forests (RF)30, 31. \nOf these, RF and ERT gave the best \u2013 and similar \u2013 results (i.e., highest accuracy of classification). For clarity and \nconsistency, RF is described in detail in the discussion that follows (for the results obtained with other methods, \nsee SI).\nDescriptors and fingerprints. In most calculations, two distinct and commonly accepted types of features \nwere used to train the models: (1) Molecular descriptors, summarized in RDKit32 and capturing various charac\u0002teristics of individual molecules (from molecular weight, to the numbers of specific atoms, rings and structural \nmotifs, to various topological indices, etc.; see list at the end of the SI) along with experimental parameters such \nFigure 1. Illustrative reactions from the training set. A small sample of eleven reactions chosen at random \nfrom the set of 450,000 reactions analyzed by machine learning methods. The reactions are diverse and span \ndifferent types of chemistries. Shown here are: cycloaddition, synthesis of guanidines, alkylation of ketones, \nalpha-bromination of nitriles, substitution of primary alkyl chlorides with thiocyanate anion via SN2, synthesis \nof isatins, ester hydrolysis (in two reactions), fluorination of primary alcohols, reduction of nitro compounds, \nand esterification of carboxylic acids).\nwww.nature.com/scientificreports/\nScientific Reports | 7: 3582 | DOI:10.1038/s41598-017-02303-0 3\nas solvents and temperature. Models up to almost 400 RDKit descriptors (~200 for substrates and ~200 for prod\u0002ucts) were c...",
      "url": "https://www.nature.com/articles/s41598-017-02303-0.pdf?error=cookies_not_supported&code=796c30e4-926f-4707-8dfd-649650f14832"
    },
    {
      "title": "Machine Learning Yield Prediction from NiCOlit, a Small-Size Literature Data Set of Nickel Catalyzed C\u2013O Couplings",
      "text": "HAL Id: hal-03790865\nhttps://hal.sorbonne-universite.fr/hal-03790865v1\nSubmitted on 28 Sep 2022\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci\u0002entific research documents, whether they are pub\u0002lished or not. The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\nL\u2019archive ouverte pluridisciplinaire HAL, est\ndestin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents\nscientifiques de niveau recherche, publi\u00e9s ou non,\n\u00e9manant des \u00e9tablissements d\u2019enseignement et de\nrecherche fran\u00e7ais ou \u00e9trangers, des laboratoires\npublics ou priv\u00e9s.\nMachine Learning Yield Prediction from NiCOlit, a\nSmall-Size Literature Data Set of Nickel Catalyzed C\u2013O\nCouplings\nJules Schleinitz, Maxime Langevin, Yanis Smail, Benjamin Wehnert, Laurence\nGrimaud, Rodolphe Vuilleumier\nTo cite this version:\nJules Schleinitz, Maxime Langevin, Yanis Smail, Benjamin Wehnert, Laurence Grimaud, et al..\nMachine Learning Yield Prediction from NiCOlit, a Small-Size Literature Data Set of Nickel Cat\u0002alyzed C\u2013O Couplings. Journal of the American Chemical Society, 2022, 144 (32), pp.14722-14730.\nff10.1021/jacs.2c05302ff. ffhal-03790865ff\nMachine Learning Yield Prediction from\nNiCOlit, a Small-Size Literature Dataset of\nNickel Catalyzed C-O Couplings\nJ. Schleinitz,\u2217,\u2020,\u2021 M. Langevin,\u2217,\u2020,\u00b6,\u00a7 Y. Smail,\u2225 B. Wehnert,\u2225 L. Grimaud,\u2217,\u2021and R.\nVuilleumier\u2217,\u00b6\n\u2020Those authors contributed equally to this work\n\u2021LBM, D\u00e9partement de chimie, \u00c9cole Normale Sup\u00e9rieure, PSL University, Sorbonne\nUniversit\u00e9, CNRS, 75005, Paris, France\n\u00b6PASTEUR, D\u00e9partement de chimie, \u00c9cole Normale Sup\u00e9rieure, PSL University, Sorbonne\nUniversit\u00e9, CNRS, 75005, Paris, France\n\u00a7Molecular Design Sciences - Integrated Drug Discovery, Sanofi R&D, 94400,\nVitry-Sur-Seine, France\n\u2225UPMC, PSL University, Sorbonne Universit\u00e9, CNRS, 75005, Paris, France\nE-mail: jules.schleinitz@ens.psl.eu; maxime.langevin@sanofi.com; laurence.grimaud@ens.psl.eu;\nrodolphe.vuilleumier@ens.psl.eu\nAbstract\nSynthetic yield prediction using machine learning is intensively studied. Previous\nwork focused on two categories of datasets: High-Throughput Experimentation data,\nas an ideal case study and datasets extracted from proprietary databases, which are\nknown to have a strong reporting bias towards high yields. However, predicting yields\nusing published reaction data remains elusive. To fill the gap, we built a dataset on\n1\nnickel-catalyzed cross-couplings extracted from organic reaction publications, including\nscope and optimization information. We demonstrate the importance of including\noptimization data as a source of failed experiments and emphasize how publication\nconstraints shape the exploration of the chemical space by the synthetic community.\nWhile machine learning models still fail to perform out-of-sample predictions, this work\nshows that adding chemical knowledge enables fair predictions in a low-data regime.\nEventually, we hope that this unique public database will foster further improvements\nof machine learning methods for reaction yield prediction in a more realistic context.\nIntroduction\nMachine learning (ML) algorithms learn complex functions from data. As it can leverage\nexisting data to perform in silico approximations of costly experimental processes, ML\napplications have sparked strong interest in chemical sciences. While ML has already made a\nsignificant impact in drug development, 1,2 synthetizability assessment of small molecules 3 or\nComputer Aided Synthesis Planning, 4the ability of ML to predict a reaction yield from its\nexperimental conditions remains a major challenge 5that is intensively studied. 6,7 Advances\non reaction yield prediction would have a major impact on organic synthesis by significantly\nreducing cost, time and resources necessary to synthesize new chemicals.\nProgress in ML is markedly driven by the increasing access to data. Thus, currently\navailable datasets shape the evolution of ML for reaction yield prediction. Despite this,\nthere are very few publicly available and easily operable datasets of chemical reactions with\nassociated yields (Table S1). One of those few public datasets is the United State Patent\nand Trademark Office (USPTO) dataset, 8that covers a wide range of chemical reactions\nextracted from patents. USPTO data is extremely diverse and suffers from a selection bias\nas only successful reactions tend to be reported in patents. ML has shown poor performance\npredicting yields on this dataset (R2 < 0.2).7In addition, two sets of High Throughput\nExperimentation (HTE) data, one of a Suzuki-Miyaura coupling, 9 and one of a palladium\u00022\ncatalyzed Buchwald-Hartwig cross-coupling, 10 are available in the literature. State-of-the-art\nmodeling performs extremely well on those high-quality datasets (R2 > 0.8),7,10 but the\nextremely focused chemical reaction space covered by HTE limits the predictions to a narrow\nscope of experimental conditions and reactants.\nWhile these datasets have enabled rapid progress of ML for yield prediction, there is a\nneed for publicly available datasets 11,12 more representative of published reaction data or\nused by chemists in their everyday work. To the best of our knowledge, the most recent\nworks on predicting reaction yields 5,13 rely on datasets extracted from Reaxys or Sci-Findern,\nwhich are not representative of the whole information contained in published reaction data.\nThe main hurdle to gather a machine readable reaction database is the difficulty to automate\ndata extraction from publications. One of the solution to overcome this issue would be\na change toward a numerical data storage in the chemistry community, an option being\nthe use of electronic laboratory notebooks 14 (ELN) interfaced with open-access database. 15\nNevertheless, the implementation of such tools requires significant time and investment. It\nalso requires to convince the chemistry community of the merits of gathering data in a\nmachine-readable format. Thus, we believe that showing the potentiality of a dataset derived\nfrom published reaction data to predict reaction yield would encourage chemists to embrace\nthe new technologies available. Such a change would benefit the whole chemistry community.\nTo address this, we built a literature-mined, open-access reaction dataset that focuses on\nthe Ni-catalyzed C\u2013O bond activation to form C\u2013C and C\u2013N bonds: the NiCOlit dataset. 16 It\ngathers more than two thousand peer-reviewed reactions with detailed experimental conditions.\nAs a singular literature representative dataset, NiCOlit stands as a benchmark for machine\nlearning prediction of chemical yields found in published reaction data.\n3\nFigure 1: (A) Chemical space of NiCOlit, (B) Diversity of NiCOlit in terms of coupling\npartners, substrates and ligands combinations, the color map is proportional to the number of\nreactions encountered for each combination. (C) t-SNE projection of NiCOlit obtained with\na DFT-featurization of the dataset, reaction data points are coloured by coupling partner\ncategory (left figure) and by publication origin (right figure).\n4\nResults and Discussion\nDescription of NiCOlit\nNiCOlit was manually extracted from published reaction data cited in a recent review from\nDiao and co-workers. 17 In this review, the authors focus on the activation of carbon-oxygen\nbonds of phenol derivatives with nickel catalysts for coupling reactions. In order to reduce\nthe size and the diversity of the dataset we arbitrarily restrained the study to challenging\nelectrophiles towards the oxidative addition: sulfonates, 18 phosphates and in situ activated\nphenols were left aside.\nThe reactions displayed in both the main articles and their SI were extracted. For each\nreaction, the Simplified Molecular-Input Line-Entry System (SMILES) 19 chains of substrates,\ncoupling partners, precursors, ligands, bases, additives, solvents, and products were gathered\nas well as experimental variables: reaction time, temperature and molar ratios of ...",
      "url": "https://hal.sorbonne-universite.fr/hal-03790865v1/preview/Predicting_reaction_yields___JACS_Format_changes.pdf"
    },
    {
      "title": "Predicting Chemical Reaction Yields",
      "text": "Predicting Chemical Reaction Yields | RXN yield prediction\n* * [rxn\\_yields](#)\n* [Overview](https://rxn4chemistry.github.io/rxn_yields//)\n* [Data](https://rxn4chemistry.github.io/rxn_yields/data)\n* [Training Tutorial](https://rxn4chemistry.github.io/rxn_yields/model_training)\n* [Evaluation Buchwald Hartwig](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_buchwald_hartwig_yields_prediction)\n* [Evaluation Suzuki Miyaura](https://rxn4chemistry.github.io/rxn_yields/results_evaluation_of_suzuki_miyaura_yields_prediction)\n* [USPTO Exploration](https://rxn4chemistry.github.io/rxn_yields/uspto_data_exploration)\n# Predicting Chemical Reaction Yields\nPredicting the yield of a chemical reaction from a reaction SMILES using Transformers\nArtificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, successfully became part of the organic chemists\u2019 daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, reaction yields models have been less investigated, despite the enormous potential of accurately predicting them. Reaction yields models, describing the percentage of the reactants that is converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the dataset applicability in reaction yields predictions.\nThis repository complements our studies on[predicting chemical reaction yields](https://iopscience.iop.org/article/10.1088/2632-2153/abc81d)(published in Machine Learning: Science and Technology) and[data augmentation and uncertainty estimation for yield predictions](https://doi.org/10.26434/chemrxiv.13286741)(presented at the Machine Learning for Molecules Workshop at NeurIPS 2020).\n## Install[](#Install)\nAs the library is based on the chemoinformatics toolkit[RDKit](http://www.rdkit.org)it is best installed using the[Anaconda](https://docs.conda.io/en/latest/miniconda.html)package manager. Once you have conda, you can simply run:\n```\n`conda create -n yields python=3.6 -y\nconda activate yields\nconda install -c rdkit rdkit=2020.03.3.0 -y\nconda install -c tmap tmap -y`\n```\n```\n`git clone https://github.com/rxn4chemistry/rxn\\_yields.git\ncd rxn\\_yields\npip install -e .`\n```\n**NOTE:**\nIf you are fine-tuning your own models. Make sure that the pretrained model (from which you start training) is loaded from a folder with the same structure as for our[rxnfp models](https://github.com/rxn4chemistry/rxnfp/tree/master/rxnfp/models/transformers/bert_pretrained).\n## Approach - predicting yields from reaction SMILES[](#Approach---predicting-yields-from-reaction-SMILES)\nTransformer models have recently revolutionised Natural Language Processing and were also successfully applied to task in chemistry, using a text-based representation of molecules and chemical reactions called Simplified molecular-input line-entry system (SMILES).\nSequence-2-Sequence transformers as in[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)were used for:\n* Chemical Reaction Prediction\n* [Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction](https://pubs.acs.org/doi/full/10.1021/acscentsci.9b00576)\n* [Carbohydrate Transformer: Predicting Regio- and Stereoselective Reactions Using Transfer Learning](http://dx.doi.org/10.26434/chemrxiv.11935635)\n* Multi-step retrosynthesis\n* [Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy](http://dx.doi.org/10.1039/c9sc05704h)\n* [Unassisted Noise-Reduction of Chemical Reactions Data Sets](https://chemrxiv.org/articles/Unassisted_Noise-Reduction_of_Chemical_Reactions_Data_Sets/12395120/1)\nEncoder Transformers like[BERT](https://openreview.net/forum?id=SkZmKmWOWH)and[ALBERT](https://openreview.net/forum?id=H1eA7AEtvS)for:\n* Reaction fingerprints and classification\n* [Mapping the Space of Chemical Reactions using Attention-Based Neural Networks](https://chemrxiv.org/articles/Data-Driven_Chemical_Reaction_Classification_with_Attention-Based_Neural_Networks/9897365)\n* Atom rearrangements during chemical reactions\n* [Unsupervised Attention-Guided Atom-Mapping](https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559)\nThose studies show that Transformer models are able to learn organic chemistry and chemical reactions from SMILES.\nHere we asked the question, how well a**BERT**model would perform when applied to a**yield prediction**task:\n![](https://rxn4chemistry.github.io/rxn_yields/images/pipeline.jpg)\n**Figure:**Pipeline and task description.\nTo do so, we started with the reaction fingerprint models from the[rxnfp](https://rxn4chemistry.github.io/rxnfp/)library and added a fine-tuning regression head through[SimpleTransformers.ai](https://simpletransformers.ai). As we don't need to change the hyperparameters of the base model, we only tune the learning rate for the training and the dropout probability.\nWe explored two high-throughput experiment (HTE) data sets and then also the yields data found in the USPTO data base.\n## Buchwald-Hartwig HTE data set[](#Buchwald-Hartwig-HTE-data-set)\n### Canonical reaction representation[](#Canonical-reaction-representation)\nOne of the best studied reaction yield is the one that was published by Ahneman et al. in[Predicting reaction performance in C\u2013N cross-coupling using machine learning](https://science.sciencemag.org/content/360/6385/186.full), where the authors have used DFT-computed descriptors as inputs to different machine learning descriptors. There best model was a random forest model. More recently,[one-hot encodings](https://science.sciencemag.org/content/362/6416/eaat8603)and[multi-fingerprint features (MFF)](https://www.sciencedirect.com/science/article/pii/S2451929420300851)as input representations were investigated. Here, we show competitive results starting simply from a text-based reaction SMILES input to our models.\n![](https://rxn4chemistry.github.io/rxn_yields/images/buchwald_hartwig.jpg)\n**Figure:**a) Summary of the results on the Buchwald\u2013Hartwig data set. b) Example regression plot for the first random-split.\n### Augmentated reaction representations[](#Augmentated-reaction-representations)\nWe were able to further improve the results on this data set using data augmentation on reaction SMILES (molecule order permuations and SMILES randomisations). This extension will be presented at the NeurIPS 2020[Machine Learning for Molecules Workshop](https://nips.cc/Conferences/2020/ScheduleMultitrack?event=16136).\n![](https://rxn4chemistry.github.io/rxn_yields/images/rxn_randomizations.png)\n**Figure:**The two different data augmentation techniques investigated in the NeurIPS workshop paper.\n#### Results[](#Results)\n![](https://rxn4chemistry.github.io/rxn_yields/images/results_augm.png)\n**Figure:**a) Results on the 70/30 random splits, averaged over 10 splits. b) Comparison of DFT descriptors + RF, canonical SMILES and data augmented randomized SMILES on reduced training sets. c) Out-of-sample test sets\nOn random splits 70/30 in a), the data augmented Yield-BERT models perform better than ...",
      "url": "https://rxn4chemistry.github.io/rxn_yields"
    },
    {
      "title": "Reaction Yields Prediction",
      "text": "Dataset Index\n\n- [Buchwald-Hartwig](https://tdcommons.ai/single_pred_tasks/yields/#buchwald-hartwig)\n- [USPTO](https://tdcommons.ai/single_pred_tasks/yields/#uspto)\n\n# Reaction Yields Prediction Task Overview\n\n**Definition:** Vast majority of small-molecule drugs are synthesized through chemical reactions. Many factors during reactions could lead to suboptimal reactants-products conversion rate, i.e. yields. Formally, it is defined as the percentage of the reactants successfully converted to the target product. This learning task aims to predict the yield of a given single chemical reaction.\n\n**Impact:** To maximize the synthesis efficiency of interested products, an accurate prediction of the reaction yield could help chemists to plan ahead and switch to alternate reaction routes, by which avoiding investing hours and materials in wet-lab experiments and reducing the number of attempts.\n\n**Generalization:** The models are expected to extrapolate to unseen reactions with diverse chemical structures and reaction types.\n\n**Product:** Small-molecule.\n\n**Pipeline:** Manufacturing - Synthesis planning.\n\n### Buchwald-Hartwig\n\n**Dataset Description:** Ahneman et al. performed high-throughput experiments on Pd-catalysed Buchwald\u2013Hartwig C-N cross coupling reactions, measuring the yields for each reaction.\n\n**Task Description:** Given reactant and product set X, predict the yields Y.\n\n**Dataset Statistics:** 55,370 reactions.\n\n**Dataset Split:** Random Split\n\n```\nfrom tdc.single_pred import Yields\ndata = Yields(name = 'Buchwald-Hartwig')\nsplit = data.get_split()\n\n```\n\n**References:**\n\n[\\[1\\] Sandfort et al. \u201cA structure-based platform for predicting chemical reactivity.\u201d Chem (2020).](https://www.sciencedirect.com/science/article/pii/S2451929420300851)\n\n[\\[2\\] Ahneman et al. \u201cPredicting reaction performance in C\u2013N cross-coupling using machine learning.\u201d Science 360.6385 (2018): 186-190.](https://science.sciencemag.org/content/360/6385/186.abstract?casa_token=Y1YYm8zLW4YAAAAA:U2B1Mqw-wjgZuqf2jd5eDUSmOCHm9dKMIqrMR5aGs4Js6eCwXV4gGPvA95wgqF-Gf6UjomO9FaAFeJQ)\n\n[\\[3\\] Schwaller, Philippe, et al. \u201cPrediction of Chemical Reaction Yields using Deep Learning.\u201d (2020). ChemRxiv.](https://chemrxiv.org/ndownloader/files/25011413)\n\n**Dataset License:** Not Specified. [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n\n* * *\n\n### USPTO\n\n**Dataset Description:** TDC parses the yields outcome from the full USPTO (United States Patent and Trademark Office) dataset.\n\n**Task Description:** Given reactant and product set X, predict the yields Y.\n\n**Dataset Statistics:** 853,638 reactions.\n\n**Dataset Split:** Random Split\n\n```\nfrom tdc.single_pred import Yields\ndata = Yields(name = 'USPTO_Yields')\nsplit = data.get_split()\n\n```\n\n**References:**\n\n[\\[1\\] Lowe, Daniel Mark. Extraction of chemical structures and reactions from the literature. Diss. University of Cambridge, 2012.](https://aspace.repository.cam.ac.uk/handle/1810/244727)\n\n**Dataset License:** [CC0](https://creativecommons.org/share-your-work/public-domain/cc0/).\n\n* * *",
      "url": "https://tdcommons.ai/single_pred_tasks/yields"
    }
  ]
}