{
  "query": "What is the GNN benchmark score for catechol reaction yield prediction and how was it achieved?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The latest arXiv paper that introduces the Catechol Benchmark (submitted\u202f22\u202fDec\u202f2025) describes evaluating graph neural networks on the 1,227\u2011reaction yield dataset but does not provide a specific numeric GNN benchmark score for catechol reaction yield prediction in the available abstract or summary\u202f([arxiv.org](https://arxiv.org/abs/2512.19530)).",
      "url": ""
    },
    {
      "title": "Learning Continuous Solvent Effects from Transient Flow Data - arXiv",
      "text": "[2512.19530] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2512.19530\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2512.19530**(cs)\n[Submitted on 22 Dec 2025]\n# Title:Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement\nAuthors:[Hongsheng Xing](https://arxiv.org/search/cs?searchtype=author&amp;query=Xing,+H),[Qiuxin Si](https://arxiv.org/search/cs?searchtype=author&amp;query=Si,+Q)\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n[View PDF](https://arxiv.org/pdf/2512.19530)[HTML (experimental)](https://arxiv.org/html/2512.19530v1)> > Abstract:\n> Predicting reaction outcomes across continuous solvent composition ranges remains a critical challenge in organic synthesis and process chemistry. Traditional machine learning approaches often treat solvent identity as a discrete categorical variable, which prevents systematic interpolation and extrapolation across the solvent space. This work introduces the \\textbf{Catechol Benchmark}, a high-throughput transient flow chemistry dataset comprising 1,227 experimental yield measurements for the rearrangement of allyl-substituted catechol in 24 pure solvents and their binary mixtures, parameterized by continuous volume fractions ($\\% B$). We evaluate various architectures under rigorous leave-one-solvent-out and leave-one-mixture-out protocols to test generalization to unseen chemical environments.\n> Our results demonstrate that classical tabular methods (e.g., Gradient-Boosted Decision Trees) and large language model embeddings (e.g., Qwen-7B) struggle with quantitative precision, yielding Mean Squared Errors (MSE) of 0.099 and 0.129, respectively. In contrast, we propose a hybrid GNN-based architecture that integrates Graph Attention Networks (GATs) with Differential Reaction Fingerprints (DRFP) and learned mixture-aware solvent encodings. This approach achieves an \\textbf{MSE of 0.0039} ($\\pm$ 0.0003), representing a 60\\% error reduction over competitive baselines and a $&gt;25\\times$ improvement over tabular ensembles. Ablation studies confirm that explicit molecular graph message-passing and continuous mixture encoding are essential for robust generalization. The complete dataset, evaluation protocols, and reference implementations are released to facilitate data-efficient reaction prediction and continuous solvent representation learning. Comments:|13 pages, 6 figures|\nSubjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI)|\nMSCclasses:|68T07, 92E20, 62M45|\nACMclasses:|I.2.1; I.2.6; J.2|\nCite as:|[arXiv:2512.19530](https://arxiv.org/abs/2512.19530)[cs.LG]|\n|(or[arXiv:2512.19530v1](https://arxiv.org/abs/2512.19530v1)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.19530](https://doi.org/10.48550/arXiv.2512.19530)\nFocus to learn more\narXiv-issued DOI via DataCite (pending registration)\n|\n## Submission history\nFrom: Hongsheng Xing [[view email](https://arxiv.org/show-email/9dc7457b/2512.19530)]\n**[v1]**Mon, 22 Dec 2025 16:19:01 UTC (2,198 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement, by Hongsheng Xing and Qiuxin Si\n* [View PDF](https://arxiv.org/pdf/2512.19530)\n* [HTML (experimental)](https://arxiv.org/html/2512.19530v1)\n* [TeX Source](https://arxiv.org/src/2512.19530)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.19530&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.19530&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2025-12](https://arxiv.org/list/cs.LG/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.19530?context=cs)\n[cs.AI](https://arxiv.org/abs/2512.19530?context=cs.AI)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.19530)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.19530)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.19530)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.19530&amp;description=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.19530&amp;title=Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.or...",
      "url": "https://arxiv.org/abs/2512.19530"
    },
    {
      "title": "Improving chemical reaction yield prediction using pre-trained graph ...",
      "text": "<div><div>\n \n <main>\n \n <article><section></section><section><section><h2>Abstract</h2>\n<p>Graph neural networks (GNNs) have proven to be effective in the prediction of chemical reaction yields. However, their performance tends to deteriorate when they are trained using an insufficient training dataset in terms of quantity or diversity. A promising solution to alleviate this issue is to pre-train a GNN on a large-scale molecular database. In this study, we investigate the effectiveness of GNN pre-training in chemical reaction yield prediction. We present a novel GNN pre-training method for performance improvement.Given a molecular database consisting of a large number of molecules, we calculate molecular descriptors for each molecule and reduce the dimensionality of these descriptors by applying principal component analysis. We define a pre-text task by assigning a vector of principal component scores as the pseudo-label to each molecule in the database. A GNN is then pre-trained to perform the pre-text task of predicting the pseudo-label for the input molecule. For chemical reaction yield prediction, a prediction model is initialized using the pre-trained GNN and then fine-tuned with the training dataset containing chemical reactions and their yields. We demonstrate the effectiveness of the proposed method through experimental evaluation on benchmark datasets.</p>\n<section><h3>Supplementary Information</h3>\n<p>The online version contains supplementary material available at 10.1186/s13321-024-00818-z.</p></section><section><p><strong>Keywords:</strong> Chemical reaction yield prediction, Graph neural network, Pre-training, Deep learning</p></section></section><section><h2>Introduction</h2>\n<p>A chemical reaction is a process in which reactants are changed into products through chemical transformations. The percentage of products obtained relative to the reactants consumed is referred to as the chemical reaction yield. The prediction of the chemical reaction yields provides clues for exploring high-yield chemical reactions without the need for conducting direct experiments. This is crucial for accelerating synthesis planning in organic chemistry by significantly reducing time and cost. Machine learning has been actively utilized for the fast and accurate prediction of chemical reaction yields in a data-driven manner [<a href=\"#CR1\">1</a>\u2013<a href=\"#CR8\">8</a>].</p>\n<p>Recently, deep learning has shown remarkable performance in predicting chemical reaction yields by effectively modeling the intricate relationships between chemical reactions and their yields using neural networks. Schwaller et al. [<a href=\"#CR6\">6</a>, <a href=\"#CR7\">7</a>] represented a chemical reaction as a series of simplified molecular-input line-entry system (SMILES) strings and built a bidirectional encoder representations from transformers (BERT) as the prediction model. Kwon et al. [<a href=\"#CR8\">8</a>] represented a chemical reaction as a set of molecular graphs and built a graph neural network (GNN) that operates directly on the molecular graphs as the prediction model. The use of GNNs led to a significant improvement in the predictive performance owing to their high expressive power on molecular graphs [<a href=\"#CR9\">9</a>, <a href=\"#CR10\">10</a>].</p>\n<p>Despite its effectiveness, the predictive performance of a GNN can suffer when it is trained on an insufficient training dataset in terms of quantity or diversity. For example, a GNN may not generalize well to query reactions involving substances that are not considered in the training dataset. Although the performance can be significantly improved by securing a large-scale training dataset, this is difficult in practice because of the high cost associated with conducting direct experiments to acquire the yields for a large number of chemical reactions.</p>\n<p>To alleviate this issue, a promising solution is to pre-train a GNN on a large-scale molecular database and use it to adapt to chemical reaction yield prediction. Various pre-training methods have been studied in the literature, which can be categorized into contrastive learning and pre-text task approaches [<a href=\"#CR11\">11</a>, <a href=\"#CR12\">12</a>]. The contrastive learning approach pre-trains a GNN by learning molecular representations such that different views of the same molecule are mapped close together, and views of different molecules are mapped far apart [<a href=\"#CR13\">13</a>\u2013<a href=\"#CR18\">18</a>]. Most existing methods based on this approach have utilized data augmentation techniques to generate different views of each molecule. Data augmentation may potentially alter the properties of the molecules being represented [<a href=\"#CR19\">19</a>, <a href=\"#CR20\">20</a>]. The pre-text task approach acquires the pseudo-labels of molecules and pre-trains a GNN to predict them [<a href=\"#CR21\">21</a>\u2013<a href=\"#CR25\">25</a>]. Existing methods have attempted to define appropriate pre-text tasks in various ways to effectively learn molecular representations. The process of acquiring pseudo-labels can be costly and time-consuming depending on how the pre-text task is defined. Since both approaches have their own advantages and drawbacks, it is important to choose the most suitable pre-training method that best aligns with the objective of a specific downstream task that needs to be addressed.</p>\n<p>In this study, we propose a novel pre-training method, <strong>MolDescPred</strong>, to improve the performance in predicting chemical reaction yields. <strong>MolDescPred</strong> is based on the pre-text task approach to pre-train a GNN. Given a molecular database containing a substantial number of molecules, we calculate the molecular descriptors for the molecules and reduce their dimensionality by applying principal component analysis (PCA). Each molecule is then pseudo-labeled with a vector of its principal component scores. The GNN is then pre-trained to predict the pseudo-label of its input molecule. For chemical reaction yield prediction, a prediction model is initialized using the pre-trained GNN and then is fine-tuned with a training dataset composed of chemical reactions and their corresponding yields. Through experiments on benchmark datasets, we demonstrate the effectiveness of the proposed method compared to existing methods, especially when the training dataset is insufficient.</p></section><section><h2>Method</h2>\n<section><h3>Problem definition</h3>\n<p>For chemical reaction yield prediction, we aim to build an accurate prediction model <em>f</em> which takes a chemical reaction <span></span> as the input to predict the yield <em>y</em> by learning from the training dataset <span></span>. Given a query chemical reaction <span></span>, the prediction model <em>f</em> can be used to make a prediction for the yield <span></span> as:</p>\n<p>It should be noted that additional information, such as the operating conditions for chemical reactions, can be utilized as extra input for the model <em>f</em>. If we denote this additional information by <span></span>, the problem can be formulated as learning the model <em>f</em> from the dataset <span></span>. The input and output of the model <em>f</em> can be described as:</p>\n<p>The data representation used for the prediction model <em>f</em> is as follows. In a chemical reaction <span></span>, <span></span> and <span></span> denote the sets of reactants and products, respectively. The set <span></span> contains <em>m</em> reactant molecules represented as molecular graphs, where <em>m</em> can vary for each reaction. The set <span></span> contains a single molecular graph representing a product molecule. Each molecular graph <span></span> represents the topology of a molecule. Here, <span></span> and <span></span> are the sets of nodes and edges associated with heavy atoms and their chemical bonds within the molecule. Hydrogen atoms are implicitly handled as node features of their neighboring heavy atoms. ...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10905905"
    },
    {
      "title": "[PDF] Graph Neural Networks for Predicting Chemical Reaction Performance",
      "text": "Graph Neural Networks for Predicting Chemical Reaction\nPerformance\nMANDANA SAEBI, BOZHAO NAN, JOHN HERR, JESSICA WAHLERS, OLAF WIEST,\nand NITESH V. CHAWLA, University of Notre Dame\nChemical reactions are a complex process, as they involve interaction between several molecu\u0002lar compounds. As a result, predicting the success of a reaction is a non-trivial task, which often\nrequires running several experiments in the lab. This process is is expensive, time consuming, and\ninefficient. As a result, in recent years, researchers have explored the use of machine learning al\u0002gorithms to predict reaction success. These methods mainly rely on chemical properties of the\nmolecules involved in the reactions. Despite their promising success, none of existing methods\nexplored the use of structural properties of molecules in predicting reaction success. In this work,\nwe develop an Attributed Graph Neural Network model that integrates both structural properties\nas well as chemical properties of molecules for predicting reaction success.\n1 INTRODUCTION\nPredicting the Performance of chemical reactions is a fundamental problem in organic chemistry.\nThe ability to predict whether a reaction will be successful or not can save significant time and effort\nof organic chemists and expedite the process of generating chemical compounds. Existing methods\nstill depend on handcrafted reaction rules [2, 6] or heuristically extracted reaction templates [3, 9],\nand therefore, are not well generalizable to unseen reactions. Another major challenge is the\navailability of data on both failed and successful experiments. Existing research in the literature\nhas mainly focused on successful experiments (i.e., reactions with a high yield), thus making it\nhard for a machine learning model to infer what makes a reaction successful. Recently, machine\nlearning models have been proposed to predict the reaction performance based on molecular\nfeatures [8, 10]. Ahneman et al. [1] advanced the field by proposing a regression model based on\nthe synthetic reaction data obtained from high-throughput experiments [1, 7? ]. However, these\nmethods only consider features such as molecular, atomic, and vibrational properties and do not\nuse any information about the complex structure of molecular graphs. We argue that in order\nto solve this problem effectively, an intelligent AI system should have two key capabilities: (1)\nUnderstanding the molecular graph structure of the input reactants to identify complex interactions\nbetween reaction components, and (2) Incorporating domain knowledge of organic chemists in the\nform of molecular, atomic, and vibrations characteristics of reactants to learn the rules that organic\nchemists use for predicting reaction success. To this end, we propose an framework which combines\nAttributed Graph Neural Network (AGNN) and chemical properties about reaction compounds\nto predict reaction performance. The chemical properties are incorporated into the model both\ndirectly (via the domain module) and indirectly (via attributed graphs of molecules).\n2 MODEL DESIGN\n2.1 Problem formulation\nWe define a chemical reaction as a combination of molecular graphs (\ud835\udc3a\ud835\udc5f,\ud835\udc3a\ud835\udc59,\ud835\udc3a\ud835\udc60,\ud835\udc3a\ud835\udc4f,\ud835\udc3a\ud835\udc5d ), where\n\ud835\udc3a\ud835\udc5f, \ud835\udc3a\ud835\udc59, \ud835\udc3a\ud835\udc60, \ud835\udc3a\ud835\udc4f, and \ud835\udc3a\ud835\udc5d represent the reactant, ligand, solvent, base, and the products [5] graph,\nrespectively. A molecular graph is described as \ud835\udc3a = (\ud835\udc49 , \ud835\udc38), where \ud835\udc49 = \ud835\udc4e1, \ud835\udc4e2, \u00b7 \u00b7 \u00b7 , \ud835\udc4e\ud835\udc5b is the set\nof atoms and \ud835\udc38 = \ud835\udc4f1, \ud835\udc4f2, \u00b7 \u00b7 \u00b7 , \ud835\udc4f\ud835\udc5a is the set of associated bonds of varying types (single, double,\nAuthors\u2019 address: Mandana Saebi, msaebi@nd.edu; Bozhao Nan, bnan@nd.edu; John Herr, ; Jessica Wahlers, jwahlers@nd.\nedu; Olaf Wiest, owiest@nd.edu; Nitesh V. Chawla, nchawla@nd.edu, University of Notre Dame, Notre Dame, Notre Dame,\nIN, 46556.\n, Vol. 1, No. 1, Article . Publication date: June 2021.\n2 Mandana Saebi, Bozhao Nan, John Herr, Jessica Wahlers, Olaf Wiest, and Nitesh V. Chawla\nFig. 1. Pd-catalysed Buchwald\u2013Hartwig C-N cross coupling reaction\nFig. 2. Suzuki\u2013Miyaura cross-coupling reaction\nFig. 3. Model Overview. (A) The Pd-catalyzed Buchwald-Hartwig reaction which is used as a model\nreaction for the yield prediction task. The bond changes in the highlighted components under the\nPd catalyst results in the generation of the final product. (B) For each reaction, we extract structural\nfeatures by aggregating atom and bond features over the neighborhoods. We concatenate struc\u0002tural features to the domain-features to obtain the final reaction features. We obtain two yield\nscores by feeding structural features and domain-based features. We average these two scores to\ngenerate the reaction yield predictions.\naromatic, etc.). Note that\ud835\udc3a\ud835\udc5f normally consists of two or more connected components since reactants\ncontain multiple molecules. Given a reaction (\ud835\udc3a\ud835\udc5f,\ud835\udc3a\ud835\udc59,\ud835\udc3a\ud835\udc60,\ud835\udc3a\ud835\udc4f,\ud835\udc3a\ud835\udc5d ), our objective is to predict the\nreaction yield (i.e., reaction performance) based on molecular properties and interactions between\nthe molecular graphs of reactants. We treat this problem as a regression task. For this work, we\nfocus on Pd-catalyzed Buchwald-Hartwig reaction [1] (as shown in Figure 1 and Suzuki\u2013Miyaura\nreactions (as shown in Figure 2) because of their broad value in pharmaceutical synthesis. Below\nwe detail our model design.\n2.2 Model Architecture\nOur model incorporates the domain knowledge about molecular properties and the complex\ninteraction between molecular graphs using an attributed graph neural network (AGNN). An\noverview of the model is shown in Figure 3. The top module represents the AGNN which learns the\nstructural features and the bottom module captures the chemical properties. We detail the process\nof feature selection in subsection 4.1.\nMolecular Graph Neural Networks. We propose AGNN for capturing the complex interactions\nbetween molecular components. GNNs have been shown to be very successful in capturing the\n, Vol. 1, No. 1, Article . Publication date: June 2021.\nGraph Neural Networks for Predicting Chemical Reaction Performance 3\nhigher-order interactions between neighboring components of a graph [11]. During a reaction,\nparticular components of two molecules interact with each other, resulting in changes in atoms\nand bonds. Under favorable experimental conditions (temperature, pressure) these interactions\ntransfer the reactants into the final product. Predicting the efficiency of these complex interactions\nrelies on understating the substructures that are likely to interact.\nWe use Weisfeiler-Lehman Network (WLN) ?? for the GNN component to capture these sub\u0002structural features. We then apply attention mechanism to capture the global context and improve\nmodel performance.\nFor each reaction, we extract structural features by aggregating atom and bond features over\nthe higher-order neighborhoods by passing the molecules through the GNN and attention layer.\nWe concatenate structural features to the domain-features to obtain the final reaction features. We\nobtain two yield scores from the structural features and domain-based features, and then feed the\ntwo scores to a linear layer to generate the final reaction yield predictions. Our model is in part\ninspired by [4]. However, in this work we focus on prediction reaction yield by combining both\nstructural graph-based features as well as chemical properties.\n3 DATA\n3.1 Buchwald\u2013Hartwig reactions\nWe use two datasets that contain a collection of Buchwald\u2013Hartwig reactions:\n3.1.1 B-H. reactions from Ahneman et al.[1]. Obtained from high-throughput experiments (HTE)\non Pd-catalysed Buchwald\u2013 Hartwig C-N cross coupling reactions. This dataset contains 4140\nreactions covering 15 aryl and heteroaryl halides, 4 Buchwald ligands, 3 bases, and 23 isoxazole\nadditives.\n3.1.2 B-H. reactions from AstraZeneca. The AstraZeneca dataset used in this work is an unpublished\ndataset containing 1000 Buchwald-Hartwig reactions generated by AstraZeneca from the Electronic\nLaboratory Notebooks (ELN). Compared with the well-designed HTE datasets, the AstraZeneca\ndataset from industrial ELN can be reg...",
      "url": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c9e3f37792a23bfdb2d471/original/graph-neural-networks-for-predicting-chemical-reaction-performance.pdf"
    },
    {
      "title": "GitHub - hjm9702/reaction_yield_pretrained_gnn: Source code for \"Improving Chemical Reaction Yield Prediction Using Pre-Trained Graph Neural Networks\"",
      "text": "[Skip to content](https://github.com/github.com#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n[hjm9702](https://github.com/hjm9702)/ **[reaction\\_yield\\_pretrained\\_gnn](https://github.com/hjm9702/reaction_yield_pretrained_gnn)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fhjm9702%2Freaction_yield_pretrained_gnn) You must be signed in to change notification settings\n- [Fork\\\n6](https://github.com/login?return_to=%2Fhjm9702%2Freaction_yield_pretrained_gnn)\n- [Star\\\n16](https://github.com/login?return_to=%2Fhjm9702%2Freaction_yield_pretrained_gnn)\n\n\nSource code for \"Improving Chemical Reaction Yield Prediction Using Pre-Trained Graph Neural Networks\"\n\n[16\\\nstars](https://github.com/hjm9702/reaction_yield_pretrained_gnn/stargazers) [6\\\nforks](https://github.com/hjm9702/reaction_yield_pretrained_gnn/forks) [Branches](https://github.com/hjm9702/reaction_yield_pretrained_gnn/branches) [Tags](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tags) [Activity](https://github.com/hjm9702/reaction_yield_pretrained_gnn/activity)\n\n[Star](https://github.com/login?return_to=%2Fhjm9702%2Freaction_yield_pretrained_gnn)\n\n[Notifications](https://github.com/login?return_to=%2Fhjm9702%2Freaction_yield_pretrained_gnn) You must be signed in to change notification settings\n\n# hjm9702/reaction\\_yield\\_pretrained\\_gnn\n\nmain\n\n[Branches](https://github.com/hjm9702/reaction_yield_pretrained_gnn/branches) [Tags](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[22 Commits](https://github.com/hjm9702/reaction_yield_pretrained_gnn/commits/main/) |\n| [data](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/data) | [data](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/data) |\n| [model](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/model) | [model](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/model) |\n| [src](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/src) | [src](https://github.com/hjm9702/reaction_yield_pretrained_gnn/tree/main/src) |\n| [README.md](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/README.md) | [README.md](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/README.md) |\n| [main\\_finetune.py](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/main_finetune.py) | [main\\_finetune.py](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/main_finetune.py) |\n| [main\\_pretrain.py](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/main_pretrain.py) | [main\\_pretrain.py](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/main_pretrain.py) |\n| [run.sh](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/run.sh) | [run.sh](https://github.com/hjm9702/reaction_yield_pretrained_gnn/blob/main/run.sh) |\n| View all files |\n\n## Repository files navigation\n\n# reaction\\_yield\\_pretrained\\_gnn\n\nSource code for the paper: Improving Chemical Reaction Yield Prediction Using Pre-Trained Graph Neural Networks\n\n## Data\n\n- The datasets used in the paper\n  - Pre-Training Dataset (10M mols collected from Pubchem) - [https://arxiv.org/pdf/2010.09885.pdf](https://arxiv.org/pdf/2010.09885.pdf)\n  - Chemical Reaction Yield Benchmark Datasets - [https://github.com/rxn4chemistry/rxn\\_yields/](https://github.com/rxn4chemistry/rxn_yields/)\n\n## Components\n\n- **data/get\\_pretraining\\_data.py** \\- pre-training dataset preprocessing functions\n- **data/get\\_reaction\\_yield\\_data.py** \\- chemical reaction yield benchmark dataset preprocessing functions\n- **src/dataset.py** \\- data structure & functions\n- **src/model.py** \\- model architecture & training / inference functions\n- **src/pretrain.py** \\- pre-training functions\n- **src/finetune.py** \\- fine-tuning functions\n- **src/preprocess\\_util.py** \\- util functions for data preprocessing\n- **src/util.py** \\- util functions for model training / inference\n- **main\\_pretrain.py** \\- script for pre-training\n- **main\\_finetune.py** \\- script for fine-tuning\n- **run.sh** \\- run code example\n\n## Dependencies\n\n- **Python**\n- **Pytorch**\n- **DGL**\n- **RDKit**\n- **Mordred**\n\n## Citation\n\n```\n@Article{reaction_yield_pretrained_gnn,\n  title={Improving chemical reaction yield prediction using pre-trained graph neural networks},\n  author={Han, Jongmin and Kwon, Youngchun and Choi, Youn-Suk and Kang, Seokho},\n  journal={Journal of Cheminformatics},\n  volume={16},\n  number={25}\n  year={2024},\n  doi={10.1186/s13321-024-00818-z}\n}\n\n```\n\n## About\n\nSource code for \"Improving Chemical Reaction Yield Prediction Using Pre-Trained Graph Neural Networks\"\n\n### Resources\n\n[Readme](https://github.com/github.com#readme-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](https://github.com/hjm9702/reaction_yield_pretrained_gnn/activity)\n\n### Stars\n\n[**16**\\\nstars](https://github.com/hjm9702/reaction_yield_pretrained_gnn/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/hjm9702/reaction_yield_pretrained_gnn/watchers)\n\n### Forks\n\n[**6**\\\nforks](https://github.com/hjm9702/reaction_yield_pretrained_gnn/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhjm9702%2Freaction_yield_pretrained_gnn&report=hjm9702+%28user%29)\n\n## [Releases](https://github.com/hjm9702/reaction_yield_pretrained_gnn/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/hjm9702/packages?repo_name=reaction_yield_pretrained_gnn)\n\nNo packages published\n\n## Languages\n\n- [Python99.4%](https://github.com/hjm9702/reaction_yield_pretrained_gnn/search?l=python)\n- [Shell0.6%](https://github.com/hjm9702/reaction_yield_pretrained_gnn/search?l=shell)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/hjm9702/reaction_yield_pretrained_gnn"
    },
    {
      "title": "GitHub - seokhokang/reaction_yield_nn: Uncertainty-aware prediction of chemical reaction yields with graph neural networks",
      "text": "[Skip to content](https://github.com/seokhokang/reaction_yield_nn#start-of-content)\n\nYou signed in with another tab or window. [Reload](https://github.com/seokhokang/reaction_yield_nn) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/seokhokang/reaction_yield_nn) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/seokhokang/reaction_yield_nn) to refresh your session.Dismiss alert\n\n{{ message }}\n\n[seokhokang](https://github.com/seokhokang)/ **[reaction\\_yield\\_nn](https://github.com/seokhokang/reaction_yield_nn)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fseokhokang%2Freaction_yield_nn) You must be signed in to change notification settings\n- [Fork\\\n7](https://github.com/login?return_to=%2Fseokhokang%2Freaction_yield_nn)\n- [Star\\\n19](https://github.com/login?return_to=%2Fseokhokang%2Freaction_yield_nn)\n\n\nUncertainty-aware prediction of chemical reaction yields with graph neural networks\n\n### License\n\n[Apache-2.0 license](https://github.com/seokhokang/reaction_yield_nn/blob/main/LICENSE)\n\n[19\\\nstars](https://github.com/seokhokang/reaction_yield_nn/stargazers) [7\\\nforks](https://github.com/seokhokang/reaction_yield_nn/forks) [Branches](https://github.com/seokhokang/reaction_yield_nn/branches) [Tags](https://github.com/seokhokang/reaction_yield_nn/tags) [Activity](https://github.com/seokhokang/reaction_yield_nn/activity)\n\n[Star](https://github.com/login?return_to=%2Fseokhokang%2Freaction_yield_nn)\n\n[Notifications](https://github.com/login?return_to=%2Fseokhokang%2Freaction_yield_nn) You must be signed in to change notification settings\n\n# seokhokang/reaction\\_yield\\_nn\n\nThis commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.\n\nmain\n\n[Branches](https://github.com/seokhokang/reaction_yield_nn/branches) [Tags](https://github.com/seokhokang/reaction_yield_nn/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit<br>## History<br>[11 Commits](https://github.com/seokhokang/reaction_yield_nn/commits/main/) |\n| [data](https://github.com/seokhokang/reaction_yield_nn/tree/main/data) | [data](https://github.com/seokhokang/reaction_yield_nn/tree/main/data) |  |  |\n| [LICENSE](https://github.com/seokhokang/reaction_yield_nn/blob/main/LICENSE) | [LICENSE](https://github.com/seokhokang/reaction_yield_nn/blob/main/LICENSE) |  |  |\n| [README.md](https://github.com/seokhokang/reaction_yield_nn/blob/main/README.md) | [README.md](https://github.com/seokhokang/reaction_yield_nn/blob/main/README.md) |  |  |\n| [dataset.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/dataset.py) | [dataset.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/dataset.py) |  |  |\n| [model.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/model.py) | [model.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/model.py) |  |  |\n| [run\\_code.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/run_code.py) | [run\\_code.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/run_code.py) |  |  |\n| [util.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/util.py) | [util.py](https://github.com/seokhokang/reaction_yield_nn/blob/main/util.py) |  |  |\n| View all files |\n\n## Repository files navigation\n\n# reaction\\_yield\\_nn\n\nPyTorch implementation of the model described in the paper [Uncertainty-Aware Prediction of Chemical Reaction Yields with Graph Neural Networks](https://doi.org/10.1186/s13321-021-00579-z)\n\n## Components\n\n- **data/**\\\\* \\- dataset files used\n- **data/get\\_data.py** \\- script for dataset file generation\n- **model/**\\\\* \\- model files used\n- **run\\_code.py** \\- script for model training/evaluation\n- **dataset.py** \\- data structure & functions\n- **model.py** \\- model architecture & functions\n- **util.py**\n\n## Data\n\n- The datasets used in the paper can be downloaded from\n  - [https://github.com/rxn4chemistry/rxn\\_yields/](https://github.com/rxn4chemistry/rxn_yields/)\n\n## Dependencies\n\n- **Python**\n- **PyTorch**\n- **DGL**\n- **RDKit**\n\n## Citation\n\n```\n@Article{Kwon2022,\n  title={Uncertainty-aware prediction of chemical reaction yields with graph neural networks},\n  author={Kwon, Youngchun and Lee, Dongseon and Choi, Youn-Suk and Kang, Seokho},\n  journal={Journal of Cheminformatics},\n  volume={14},\n  pages={2},\n  year={2022},\n  doi={10.1186/s13321-021-00579-z}\n}\n\n```\n\n## About\n\nUncertainty-aware prediction of chemical reaction yields with graph neural networks\n\n### Resources\n\n[Readme](https://github.com/seokhokang/reaction_yield_nn#readme-ov-file)\n\n### License\n\n[Apache-2.0 license](https://github.com/seokhokang/reaction_yield_nn#Apache-2.0-1-ov-file)\n\n[Activity](https://github.com/seokhokang/reaction_yield_nn/activity)\n\n### Stars\n\n[**19**\\\nstars](https://github.com/seokhokang/reaction_yield_nn/stargazers)\n\n### Watchers\n\n[**1**\\\nwatching](https://github.com/seokhokang/reaction_yield_nn/watchers)\n\n### Forks\n\n[**7**\\\nforks](https://github.com/seokhokang/reaction_yield_nn/forks)\n\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fseokhokang%2Freaction_yield_nn&report=seokhokang+%28user%29)\n\n## [Releases](https://github.com/seokhokang/reaction_yield_nn/releases)\n\nNo releases published\n\n## [Packages\\ 0](https://github.com/users/seokhokang/packages?repo_name=reaction_yield_nn)\n\nNo packages published\n\n## Languages\n\n- [Python100.0%](https://github.com/seokhokang/reaction_yield_nn/search?l=python)\n\nYou can\u2019t perform that action at this time.",
      "url": "https://github.com/seokhokang/reaction_yield_nn"
    },
    {
      "title": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning",
      "text": "The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\n# The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning\nToby Boyne1, Juan S. Campos1, Becky D. Langdon1, Jixiang Qing1, Yilin Xie1\nShiqiang Zhang1, Calvin Tsay1, Ruth Misener1, Daniel W. Davies2, Kim E. Jelfs2\nSarah Boyall3, Thomas M. Dixon3, Linden Schrecker3, Jose Pablo Folch3\u2020\nDepartment of Computing, Imperial College, London, UK1\nDepartment of Chemistry, Imperial College, London, UK2\nSOLVE Chemistry, London, UK3t.boyne23@imperial.ac.uk;\u2020jose@solvechemistry.com\n###### Abstract\nMachine learning has promised to change the landscape of laboratory chemistry, with impressive results in molecular property prediction and reaction retro-synthesis. However, chemical datasets are often inaccessible to the machine learning community as they tend to require cleaning, thorough understanding of the chemistry, or are simply not available. In this paper, we introduce a novel dataset for yield prediction, providing the first-ever transient flow dataset for machine learning benchmarking, covering over 1200 process conditions. While previous datasets focus on discrete parameters, our experimental set-up allow us to sample a large number of continuous process conditions, generating new challenges for machine learning models. We focus on solvent selection, a task that is particularly difficult to model theoretically and therefore ripe for machine learning applications. We showcase benchmarking for regression algorithms, transfer-learning approaches, feature engineering, and active learning, with important applications towards solvent replacement and sustainable manufacturing.\n## 1Introduction\nMachine learning (ML) and artificial intelligence (AI) have showcased enormous potential in empowering the world of the natural sciences: from famous examples such as AlphaFold for protein predictions> [\n[> 1\n](https://arxiv.org/html/2506.07619v1#bib.bib1)> ]\n, to fusion reactor control> [\n[> 2\n](https://arxiv.org/html/2506.07619v1#bib.bib2)> ]\n, disease detection> [\n[> 3\n](https://arxiv.org/html/2506.07619v1#bib.bib3)> ]\n, battery design> [\n[> 4\n](https://arxiv.org/html/2506.07619v1#bib.bib4)> ]\n, and material discovery> [\n[> 5\n](https://arxiv.org/html/2506.07619v1#bib.bib5)> ]\n, among many more. However, we seldom see the machine learning community benchmark new methods in physical science datasets, mostly due to the difficulty in cleaning real-world data, the need for interdisciplinary understanding to correctly benchmark, and most importantly, how expensive the data can be to produce, resulting in many datasets being locked behind closed doors by large companies.\nAIchemy ([https://aichemy.ac.uk](https://aichemy.ac.uk)) is an interdisciplinary UK hub with the mission of transforming the chemistry-AI interface via aiding the collaboration of chemists and AI researchers, as well as addressing gaps in data standards, curation, and availability for AI use. In partnership with SOLVE Chemistry ([https://www.solvechemistry.com](https://www.solvechemistry.com)), we present a first important step into addressing the dataset gap with the introduction of a new and unique open dataset for benchmarking low-data machine learning algorithms for chemistry.\nSolvent selection is one of the biggest challenges for chemical manufacturing, with solvents often being the main source of waste in the manufacturing process> [\n[> 6\n](https://arxiv.org/html/2506.07619v1#bib.bib6)> ]\n. Increased regulation on solvents and a drive to making process manufacturing more sustainable led to an interest in the discovery of greener solvents and for improved solvent replacement tools. However, most of the solvent replacement tools focus purely on learning unsupervised representations of solvents, with the hope that experimentalists can find solvents with similar properties to replace those with environmental concerns. A much stronger approach would consider the interaction of a variety of different solvents with a reaction of interest to directly predict reaction yields, in such a way that the best possible solvent can be selected according to a yield-sustainability trade-off.\nMachine learning approaches have been shown to be a powerful tool for the prediction of chemical reaction conditions. Success has been reported in retro-synthesis> [\n[> 7\n](https://arxiv.org/html/2506.07619v1#bib.bib7)> , [> 8\n](https://arxiv.org/html/2506.07619v1#bib.bib8)> ]\n, condition recommendations> [\n[> 9\n](https://arxiv.org/html/2506.07619v1#bib.bib9)> ]\n, product predictions> [\n[> 10\n](https://arxiv.org/html/2506.07619v1#bib.bib10)> , [> 11\n](https://arxiv.org/html/2506.07619v1#bib.bib11)> ]\n, among others. While yield prediction has proven to be more difficult due to large inconsistencies in procedure and data reporting> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\n, we have still seen promising yield prediction results for smaller and more carefully curated datasets> [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> , [> 14\n](https://arxiv.org/html/2506.07619v1#bib.bib14)> , [> 15\n](https://arxiv.org/html/2506.07619v1#bib.bib15)> , [> 16\n](https://arxiv.org/html/2506.07619v1#bib.bib16)> ]\n. However, these datasets lack the continuous reaction conditions, such as temperature and residence time, that are required to scale-up processes to practical manufacturing conditions.\nIn this paper, we release the first machine-learning-ready transient flow dataset, a framework that allows for quick and efficient screening of continuous reaction conditions. We specifically provide yield data over the uni-molecular allyl substituted catechol reaction, shown in Figure[1](https://arxiv.org/html/2506.07619v1#S1.F1), with dense measurements across the residence time, temperature, and solvent space. We further showcase how this type ofkinetic dataposes new challenges to current machine learning methods for chemistry, and identify how the challenges can potentially be tackled by the community.\n![Refer to caption](extracted/6524982/figures/Project2_rxn.png)Figure 1:Data was gathered on the rearrangement of allyl substituted catechol. By subjecting the reaction mixture to high temperatures, we begin a cascade reaction forming multiple rearrangement products. We investigate the yield of the reaction for a range of different solvents. Product 1 was not observed and reacted immediately to form Product 2 and later 3.\n### 1.1Related works\nReaction datasets are common in chemistry research, but their suitability for machine learning benchmarking tends to be poor. This can be a result of improper formatting or documentation, incomplete information about reaction conditions or the experimental set-up, or the lack of machine readability, leading to limited usage by the ML community. However, some effort has been made to address this, with the biggest example being the creation of the Open Reaction Database (ORD)> [\n[> 17\n](https://arxiv.org/html/2506.07619v1#bib.bib17)> ]\n, a repository containing over 2M different reactions, many of which come from US patent data (USPTO)> [\n[> 18\n](https://arxiv.org/html/2506.07619v1#bib.bib18)> ]\n. However, the dataset falls short in some aspects, in particular with respect to machine learning readiness and data inconsistencies across reactions.\nORDerly> [\n[> 12\n](https://arxiv.org/html/2506.07619v1#bib.bib12)> ]\nallows for easy cleaning and preparation of ORD data, showing the promise of the dataset for forward and retro-synthetic prediction using transformers; however, it also shows that yield prediction cannot be done well due to data inconsistencies.> Schwaller et\u00a0al. [\n[> 13\n](https://arxiv.org/html/2506.07619v1#bib.bib13)> ]\ndrew similar conclusions when using the USPTO dataset, stating that reaction conditions such as temperature, concentrations, and duration have a significant effect on yield. The assumption that every reaction in the dataset is optimized for reaction param...",
      "url": "https://arxiv.org/html/2506.07619v1"
    }
  ]
}