{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799dff81",
   "metadata": {},
   "source": [
    "# ACS PCA Ensemble - Submission Compliant\n",
    "\n",
    "**Model**: ACSPCAEnsemble = [32,16] MLP (0.6) + LightGBM (0.4) with ACS PCA features\n",
    "**Best CV**: 0.008601 from exp_022 (4.47% better than exp_012)\n",
    "\n",
    "**CRITICAL**: This notebook follows the EXACT template structure required by the competition.\n",
    "- Last 3 cells are IDENTICAL to the template\n",
    "- Only the model definition line is changed\n",
    "- Model class has `train_model(X_train, y_train)` and `predict(X)` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a77984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions (matching template)\n",
    "DATA_PATH = '/home/data'\n",
    "\n",
    "INPUT_LABELS_NUMERIC = [\"Residence Time\", \"Temperature\"]\n",
    "INPUT_LABELS_SINGLE_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT NAME\"]\n",
    "INPUT_LABELS_FULL_SOLVENT = [\"Residence Time\", \"Temperature\", \"SOLVENT A NAME\", \"SOLVENT B NAME\", \"SolventB%\"]\n",
    "\n",
    "def load_data(name=\"full\"):\n",
    "    if name == \"full\":\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_full_data_yields.csv')\n",
    "        X = df[INPUT_LABELS_FULL_SOLVENT]\n",
    "    else:\n",
    "        df = pd.read_csv(f'{DATA_PATH}/catechol_single_solvent_yields.csv')\n",
    "        X = df[INPUT_LABELS_SINGLE_SOLVENT]\n",
    "    Y = df[[\"Product 2\", \"Product 3\", \"SM\"]]\n",
    "    return X, Y\n",
    "\n",
    "def generate_leave_one_out_splits(X, Y):\n",
    "    for solvent in sorted(X[\"SOLVENT NAME\"].unique()):\n",
    "        mask = X[\"SOLVENT NAME\"] != solvent\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])\n",
    "\n",
    "def generate_leave_one_ramp_out_splits(X, Y):\n",
    "    ramps = X[[\"SOLVENT A NAME\", \"SOLVENT B NAME\"]].drop_duplicates()\n",
    "    for _, row in ramps.iterrows():\n",
    "        mask = ~((X[\"SOLVENT A NAME\"] == row[\"SOLVENT A NAME\"]) & (X[\"SOLVENT B NAME\"] == row[\"SOLVENT B NAME\"]))\n",
    "        yield (X[mask], Y[mask]), (X[~mask], Y[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature lookups\n",
    "SPANGE_DF = pd.read_csv(f'{DATA_PATH}/spange_descriptors_lookup.csv', index_col=0)\n",
    "DRFP_DF = pd.read_csv(f'{DATA_PATH}/drfps_catechol_lookup.csv', index_col=0)\n",
    "drfp_variance = DRFP_DF.var()\n",
    "nonzero_variance_cols = drfp_variance[drfp_variance > 0].index.tolist()\n",
    "DRFP_FILTERED = DRFP_DF[nonzero_variance_cols]\n",
    "ACS_PCA_DF = pd.read_csv(f'{DATA_PATH}/acs_pca_descriptors_lookup.csv', index_col=0)\n",
    "\n",
    "print(f'Spange: {SPANGE_DF.shape}, DRFP filtered: {DRFP_FILTERED.shape}, ACS PCA: {ACS_PCA_DF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Featurizer with ACS PCA and Arrhenius kinetics\n",
    "class ACSPCAFeaturizer:\n",
    "    def __init__(self, mixed=False):\n",
    "        self.mixed = mixed\n",
    "        self.spange_df = SPANGE_DF\n",
    "        self.drfp_df = DRFP_FILTERED\n",
    "        self.acs_pca_df = ACS_PCA_DF\n",
    "        self.feats_dim = 2 + 3 + self.spange_df.shape[1] + self.drfp_df.shape[1] + self.acs_pca_df.shape[1]\n",
    "\n",
    "    def featurize(self, X, flip=False):\n",
    "        X_vals = X[INPUT_LABELS_NUMERIC].values.astype(np.float64)\n",
    "        temp_c = X_vals[:, 1:2]\n",
    "        time_m = X_vals[:, 0:1]\n",
    "        temp_k = temp_c + 273.15\n",
    "        inv_temp = 1000.0 / temp_k\n",
    "        log_time = np.log(time_m + 1e-6)\n",
    "        interaction = inv_temp * log_time\n",
    "        X_kinetic = np.hstack([X_vals, inv_temp, log_time, interaction])\n",
    "        \n",
    "        if self.mixed:\n",
    "            A_spange = self.spange_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_spange = self.spange_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_drfp = self.drfp_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_drfp = self.drfp_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            A_acs = self.acs_pca_df.loc[X[\"SOLVENT A NAME\"]].values\n",
    "            B_acs = self.acs_pca_df.loc[X[\"SOLVENT B NAME\"]].values\n",
    "            \n",
    "            pct = X[\"SolventB%\"].values.reshape(-1, 1) / 100.0\n",
    "            if flip:\n",
    "                pct = 1.0 - pct\n",
    "                A_spange, B_spange = B_spange, A_spange\n",
    "                A_drfp, B_drfp = B_drfp, A_drfp\n",
    "                A_acs, B_acs = B_acs, A_acs\n",
    "            \n",
    "            X_spange = A_spange * (1 - pct) + B_spange * pct\n",
    "            X_drfp = A_drfp * (1 - pct) + B_drfp * pct\n",
    "            X_acs = A_acs * (1 - pct) + B_acs * pct\n",
    "        else:\n",
    "            X_spange = self.spange_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_drfp = self.drfp_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "            X_acs = self.acs_pca_df.loc[X[\"SOLVENT NAME\"]].values\n",
    "        \n",
    "        return np.hstack([X_kinetic, X_spange, X_drfp, X_acs])\n",
    "    \n",
    "    def featurize_torch(self, X, flip=False):\n",
    "        return torch.tensor(self.featurize(X, flip), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model [32,16] with BatchNorm\n",
    "class MLPModelInternal(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[32, 16], output_dim=3, dropout=0.05):\n",
    "        super(MLPModelInternal, self).__init__()\n",
    "        layers = [nn.BatchNorm1d(input_dim)]\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MLPEnsemble:\n",
    "    def __init__(self, hidden_dims=[32, 16], n_models=5, data='single'):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_models = n_models\n",
    "        self.data_type = data\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "\n",
    "    def train_model(self, X_train, y_train, epochs=200, batch_size=32, lr=5e-4):\n",
    "        X_std = self.featurizer.featurize_torch(X_train, flip=False)\n",
    "        y_vals = torch.tensor(y_train.values)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X_train, flip=True)\n",
    "            X_all = torch.cat([X_std, X_flip], dim=0)\n",
    "            y_all = torch.cat([y_vals, y_vals], dim=0)\n",
    "        else:\n",
    "            X_all = X_std\n",
    "            y_all = y_vals\n",
    "            \n",
    "        input_dim = X_all.shape[1]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for i in range(self.n_models):\n",
    "            torch.manual_seed(42 + i)\n",
    "            model = MLPModelInternal(input_dim, self.hidden_dims).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "            criterion = nn.HuberLoss(delta=0.1)\n",
    "            \n",
    "            dataset = TensorDataset(X_all.to(device), y_all.to(device))\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                epoch_loss = 0\n",
    "                for batch_X, batch_y in loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "                scheduler.step(epoch_loss / len(loader))\n",
    "            \n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize_torch(X, flip=False).to(device)\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(X_feat)\n",
    "                predictions.append(pred.cpu().numpy())\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize_torch(X, flip=True).to(device)\n",
    "            for model in self.models:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    pred = model(X_flip)\n",
    "                    predictions.append(pred.cpu().numpy())\n",
    "            return torch.tensor(np.mean(predictions, axis=0))\n",
    "        else:\n",
    "            return torch.tensor(np.mean(predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ddd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Model with ACS PCA\n",
    "class LGBMModel:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data_type = data\n",
    "        self.featurizer = ACSPCAFeaturizer(mixed=(data=='full'))\n",
    "        self.models = []\n",
    "        self.params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "    def train_model(self, X_train, y_train, num_boost_round=200):\n",
    "        X_feat = self.featurizer.featurize(X_train)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X_train, flip=True)\n",
    "            X_all = np.vstack([X_feat, X_flip])\n",
    "            y_all = np.vstack([y_train.values, y_train.values])\n",
    "        else:\n",
    "            X_all, y_all = X_feat, y_train.values\n",
    "        \n",
    "        self.models = []\n",
    "        for i in range(3):\n",
    "            train_data = lgb.Dataset(X_all, label=y_all[:, i])\n",
    "            model = lgb.train(self.params, train_data, num_boost_round=num_boost_round)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_feat = self.featurizer.featurize(X)\n",
    "        predictions = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred = model.predict(X_feat, num_iteration=model.best_iteration)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        if self.data_type == 'full':\n",
    "            X_flip = self.featurizer.featurize(X, flip=True)\n",
    "            for i, model in enumerate(self.models):\n",
    "                pred = model.predict(X_flip, num_iteration=model.best_iteration)\n",
    "                predictions[i] = (predictions[i] + pred) / 2.0\n",
    "        \n",
    "        return torch.tensor(np.column_stack(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACSPCAEnsemble: [32,16] MLP (0.6) + LightGBM (0.4) with ACS PCA features\n",
    "class ACSPCAEnsemble:\n",
    "    \"\"\"Competition-compliant ensemble model with ACS PCA features.\n",
    "    \n",
    "    Has train_model(X_train, y_train) and predict(X) methods.\n",
    "    Accepts data='single' or data='full' parameter.\n",
    "    \"\"\"\n",
    "    def __init__(self, data='single', mlp_weight=0.6, lgbm_weight=0.4):\n",
    "        self.data_type = data\n",
    "        self.mlp_weight = mlp_weight\n",
    "        self.lgbm_weight = lgbm_weight\n",
    "        self.mlp = None\n",
    "        self.lgbm = None\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train both MLP and LightGBM models.\"\"\"\n",
    "        # Train MLP [32,16] - best LB model\n",
    "        self.mlp = MLPEnsemble(hidden_dims=[32, 16], n_models=5, data=self.data_type)\n",
    "        self.mlp.train_model(X_train, y_train, epochs=200)\n",
    "        \n",
    "        # Train LightGBM\n",
    "        self.lgbm = LGBMModel(data=self.data_type)\n",
    "        self.lgbm.train_model(X_train, y_train, num_boost_round=200)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred_mlp = self.mlp.predict(X)\n",
    "        pred_lgbm = self.lgbm.predict(X)\n",
    "        ensemble_pred = self.mlp_weight * pred_mlp + self.lgbm_weight * pred_lgbm\n",
    "        return torch.tensor(np.clip(ensemble_pred, 0, 1))\n",
    "\n",
    "print('ACSPCAEnsemble defined: MLP[32,16] (0.6) + LightGBM (0.4) with ACS PCA features')\n",
    "print('Model interface: train_model(X_train, y_train), predict(X)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7114dc2",
   "metadata": {},
   "source": [
    "---\n",
    "## COMPETITION TEMPLATE CELLS BELOW\n",
    "\n",
    "**The following 3 cells are EXACTLY as required by the competition template.**\n",
    "**Only the model definition line is changed.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b276b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE THIRD LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "import tqdm\n",
    "\n",
    "X, Y = load_data(\"single_solvent\")\n",
    "\n",
    "split_generator = generate_leave_one_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ACSPCAEnsemble(data='single')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 0,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_single_solvent = pd.DataFrame(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL OTHER THAN THE MODEL #################\n",
    "########### THIS MUST BE THE SECOND LAST CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "X, Y = load_data(\"full\")\n",
    "\n",
    "split_generator = generate_leave_one_ramp_out_splits(X, Y)\n",
    "all_predictions = []\n",
    "\n",
    "for fold_idx, split in tqdm.tqdm(enumerate(split_generator)):\n",
    "    (train_X, train_Y), (test_X, test_Y) = split\n",
    "\n",
    "    model = ACSPCAEnsemble(data='full')  # CHANGE THIS LINE ONLY\n",
    "    model.train_model(train_X, train_Y)\n",
    "\n",
    "    predictions = model.predict(test_X)  # Shape: [N, 3]\n",
    "\n",
    "    # Move to CPU and convert to numpy\n",
    "    predictions_np = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Add metadata and flatten to long format\n",
    "    for row_idx, row in enumerate(predictions_np):\n",
    "        all_predictions.append({\n",
    "            \"task\": 1,\n",
    "            \"fold\": fold_idx,\n",
    "            \"row\": row_idx,\n",
    "            \"target_1\": row[0],\n",
    "            \"target_2\": row[1],\n",
    "            \"target_3\": row[2]\n",
    "        })\n",
    "\n",
    "submission_full_data = pd.DataFrame(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################\n",
    "\n",
    "submission = pd.concat([submission_single_solvent, submission_full_data])\n",
    "submission = submission.reset_index()\n",
    "submission.index.name = \"id\"\n",
    "submission.to_csv(\"/home/submission/submission.csv\", index=True)\n",
    "\n",
    "########### DO NOT CHANGE ANYTHING IN THIS CELL #################\n",
    "########### THIS MUST BE THE FINAL CELL IN YOUR NOTEBOOK FOR A VALID SUBMISSION #################"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
