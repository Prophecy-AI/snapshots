## Current Status
- **Best CV score**: 77.37% from exp_000 (baseline CNN)
- **Target score**: 91.32%
- **Gap to close**: 13.95 points
- **Submissions**: None yet (5 remaining)

## Response to Evaluator
The evaluator correctly identified the critical flaw: custom CNN from scratch cannot reach the target. Their verdict was TRUSTWORTHY (validation sound) but they flagged the architecture as wrong. **I fully agree with their top priority** - we must switch to transfer learning immediately. The 13.95 point gap is primarily due to using a from-scratch model vs. pretrained models that start at 85%+ accuracy.

## Data Understanding
- **Dataset**: 21,397 clean RGB images, ~800x600 average dimensions
- **Class imbalance**: CMD (class 3) = 61.5%, CBB (class 0) = 5.1% (12.1x ratio)
- **Class weights**: [3.94, 1.95, 1.79, 0.33, 1.66] for classes 0-4
- **Reference**: See `exploration/evolver_loop2_analysis.ipynb` for distribution analysis

## Winning Solution Insights (from research/writeups/)

### 1st Place (Golddiggaz - 91.32% private LB)
- **Ensemble**: ResNeXt50 + ViT-B/16 + EfficientNet-B4 (NoisyStudent) + CropNet (MobileNetV3)
- **Key breakthrough**: CropNet from TF Hub (pretrained on cassava) added crucial diversity
- **Augmentation**: Heavy Albumentations (RandomResizedCrop, Transpose, flips, ShiftScaleRotate, color transforms, CoarseDropout, Cutout)
- **Loss**: Bit Tempered Logistic Loss (t1=0.8, t2=1.4) + label smoothing (0.06-0.1)
- **Training**: Cosine annealing with warmup, 5-fold CV, 10-20 epochs
- **TTA**: 4 overlapping 512x512 crops + augmentations = 10 predictions/image

### 2nd Place (Devon Stanfield - 90.25%)
- **Simple approach**: Just CropNet from TF Hub
- **Proves**: Domain-specific pretrained model is extremely powerful

## Recommended Approaches (Priority Order)

### 1. Transfer Learning with CropNet + EfficientNet (CRITICAL - 8-12 point gain)
**Why**: Winners proved pretrained models dominate. CropNet is domain-specific cassava model.
**Implementation**:
- Model 1: CropNet from TF Hub (cache for offline inference)
- Model 2: EfficientNet-B4 with NoisyStudent weights
- Input size: 512x512 (balance quality vs. memory)
- Replace final layer: 5 classes with class weights [3.94, 1.95, 1.79, 0.33, 1.66]
- Keep existing 5-fold stratified CV framework

### 2. Heavy Augmentation Pipeline (2-3 point gain)
**Why**: Winners used extensive augmentation to prevent overfitting on 21K images
**Implementation**:
- Train: RandomResizedCrop(512,512), Transpose, HorizontalFlip, VerticalFlip, ShiftScaleRotate
- Color: HueSaturationValue, RandomBrightnessContrast
- Regularization: CoarseDropout, Cutout
- Valid: Resize(512,512), Normalize
- Normalize with dataset statistics (not ImageNet)

### 3. Class Imbalance Handling (1-2 point gain)
**Why**: CMD is 61.5% of data - model will be biased without correction
**Implementation**:
- Loss: Weighted CrossEntropyLoss with calculated class weights
- Alternative: Focal Loss (gamma=2.0, alpha=0.25) as used by 1st place
- Label smoothing: 0.06-0.1 to prevent overconfidence
- Monitor per-class accuracy to verify improvement

### 4. Advanced Training Recipe (1-2 point gain)
**Why**: Fixed LR and 10 epochs undertrained the baseline
**Implementation**:
- Optimizer: AdamW with weight decay (1e-2)
- Scheduler: Cosine annealing with warmup
  - Warmup: 1e-6 → 2e-4 (5 epochs)
  - Anneal: 2e-4 → 3e-6 (15 epochs)
- Epochs: 20 with early stopping (patience=5)
- Batch size: 16-32 (depending on GPU memory)

### 5. Test-Time Augmentation (1-2 point gain)
**Why**: Winners gained 0.5-1% from TTA
**Implementation**:
- Multi-scale: 4 overlapping 512x512 crops from 800x600 images
- Augmentations: Flip, rotate, transpose on each crop
- Average predictions across all crops

### 6. Ensembling Strategy (2-3 point gain)
**Why**: Single models plateau ~89-90%, ensembles reach 91.3%+
**Phase 1**: Train CropNet and EfficientNet-B4 separately
**Phase 2**: Add ResNeXt50 or ViT-B/16 for architectural diversity
**Final**: Weighted average or stacking with meta-learner

## What NOT to Try
- ❌ Custom CNN architectures (proven inferior)
- ❌ Basic augmentation only (leaves 2-3 points on table)
- ❌ Fixed learning rates (suboptimal convergence)
- ❌ Single model only (ensembles proven necessary)
- ❌ ImageNet normalization (use dataset stats)

## Validation Notes
- **CV Scheme**: Keep existing 5-fold stratified CV (sound methodology)
- **Metric**: Mean accuracy across folds (match competition metric)
- **Target per-model CV**: 88-89% (ensemble should reach 91%+)
- **LB Calibration**: Submit first model to verify CV-LB correlation

## Implementation Order
1. Implement CropNet model with heavy augmentation
2. Train with class weights and focal loss
3. Add EfficientNet-B4 as second model
4. Implement TTA for inference
5. Create ensemble and optimize weights
6. Submit for LB verification