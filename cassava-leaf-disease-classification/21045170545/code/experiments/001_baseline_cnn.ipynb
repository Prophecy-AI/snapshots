{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba03fb4",
   "metadata": {},
   "source": [
    "# Cassava Leaf Disease Classification - Baseline CNN\n",
    "\n",
    "This notebook implements a simple CNN baseline for the cassava leaf disease classification competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0f7830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:01:07.335880Z",
     "iopub.status.busy": "2026-01-15T23:01:07.335007Z",
     "iopub.status.idle": "2026-01-15T23:01:07.342996Z",
     "shell.execute_reply": "2026-01-15T23:01:07.342148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "GPU Memory: 85.1 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8071b2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T23:01:07.345830Z",
     "iopub.status.busy": "2026-01-15T23:01:07.345523Z",
     "iopub.status.idle": "2026-01-15T23:01:07.353781Z",
     "shell.execute_reply": "2026-01-15T23:01:07.353101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, has_labels=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.has_labels = has_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image_id'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.has_labels:\n",
    "            label = row['label']\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, row['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd0cb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:20:59.963149Z",
     "iopub.status.busy": "2026-01-15T21:20:59.962814Z",
     "iopub.status.idle": "2026-01-15T21:20:59.971675Z",
     "shell.execute_reply": "2026-01-15T21:20:59.970932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_DIR = '/home/data'\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, 'train.csv')\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, 'train_images')\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, 'test_images')\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Classes: {train_df['label'].nunique()}\")\n",
    "print(f\"Class distribution:\\n{train_df['label'].value_counts().sort_index()}\")\n",
    "\n",
    "# Load label mapping\n",
    "with open(os.path.join(DATA_DIR, 'label_num_to_disease_map.json'), 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "print(f\"\\nLabel mapping: {label_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aaa4b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:20:59.974265Z",
     "iopub.status.busy": "2026-01-15T21:20:59.973990Z",
     "iopub.status.idle": "2026-01-15T21:21:01.283291Z",
     "shell.execute_reply": "2026-01-15T21:21:01.282565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 26,081,605\n",
      "Model size (MB): 99.5\n"
     ]
    }
   ],
   "source": [
    "# Define data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc66a861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T21:21:01.285849Z",
     "iopub.status.busy": "2026-01-15T21:21:01.285190Z",
     "iopub.status.idle": "2026-01-15T21:21:01.293023Z",
     "shell.execute_reply": "2026-01-15T21:21:01.292448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN(num_classes=5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model size (MB): {sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d509aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation training\n",
    "NUM_FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Prepare stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"Starting {NUM_FOLDS}-fold cross-validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "    \n",
    "    # Create fold datasets\n",
    "    train_fold = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = CassavaDataset(train_fold, TRAIN_IMG_DIR, transform=train_transform)\n",
    "    val_dataset = CassavaDataset(val_fold, TRAIN_IMG_DIR, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Initialize model for this fold\n",
    "    model = SimpleCNN(num_classes=5)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    fold_scores.append(best_val_acc)\n",
    "    print(f\"Fold {fold + 1} Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "# Report cross-validation results\n",
    "print(f\"\\nCross-validation results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in fold_scores]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "print(\"Training final model on full training data...\")\n",
    "\n",
    "full_train_dataset = CassavaDataset(train_df, TRAIN_IMG_DIR, transform=train_transform)\n",
    "full_train_loader = DataLoader(full_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "final_model = SimpleCNN(num_classes=5)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(final_model, full_train_loader, criterion, optimizer, device)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "print(\"Final model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "print(\"Generating predictions on test set...\")\n",
    "\n",
    "test_images = [f for f in os.listdir(TEST_IMG_DIR) if f.endswith('.jpg')]\n",
    "test_df = pd.DataFrame({'image_id': test_images})\n",
    "\n",
    "test_dataset = CassavaDataset(test_df, TEST_IMG_DIR, transform=val_transform, has_labels=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "final_model.eval()\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = final_model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        image_ids.extend(ids)\n",
    "\n",
    "# Create submission\n",
    "test_df = pd.DataFrame({'image_id': image_ids, 'label': predictions})\n",
    "submission = test_df.sort_values('image_id')\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to {submission_path}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Predicted class distribution:\\n{submission['label'].value_counts().sort_index()}\")\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(submission.head(10))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
