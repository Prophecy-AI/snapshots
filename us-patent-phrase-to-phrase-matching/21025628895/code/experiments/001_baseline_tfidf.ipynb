{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1bbd96",
   "metadata": {},
   "source": [
    "# Baseline Model: TF-IDF + Gradient Boosting\n",
    "\n",
    "This is the first baseline experiment using simple TF-IDF features on anchor and target phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b1c887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:47:27.689774Z",
     "iopub.status.busy": "2026-01-15T13:47:27.689535Z",
     "iopub.status.idle": "2026-01-15T13:47:28.718413Z",
     "shell.execute_reply": "2026-01-15T13:47:28.717793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36473, 5)\n",
      "Test shape: (36, 4)\n",
      "Score distribution:\n",
      "score\n",
      "0.00     7471\n",
      "0.25    11519\n",
      "0.50    12300\n",
      "0.75     4029\n",
      "1.00     1154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Score distribution:\\n{train_df['score'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4b21bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:47:28.720460Z",
     "iopub.status.busy": "2026-01-15T13:47:28.720269Z",
     "iopub.status.idle": "2026-01-15T13:47:29.530025Z",
     "shell.execute_reply": "2026-01-15T13:47:29.529465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (36473, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF features for anchor and target\n",
    "# Use a subset of features for speed in baseline\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "\n",
    "# Fit on both anchor and target to get shared vocabulary\n",
    "all_text = pd.concat([train_df['anchor'], train_df['target']], ignore_index=True)\n",
    "vectorizer.fit(all_text)\n",
    "\n",
    "# Transform anchor and target separately\n",
    "anchor_tfidf = vectorizer.transform(train_df['anchor'])\n",
    "target_tfidf = vectorizer.transform(train_df['target'])\n",
    "\n",
    "# For test set\n",
    "test_anchor_tfidf = vectorizer.transform(test_df['anchor'])\n",
    "test_target_tfidf = vectorizer.transform(test_df['target'])\n",
    "\n",
    "print(f\"TF-IDF feature shape: {anchor_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5b2fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:47:29.531798Z",
     "iopub.status.busy": "2026-01-15T13:47:29.531612Z",
     "iopub.status.idle": "2026-01-15T13:47:35.900169Z",
     "shell.execute_reply": "2026-01-15T13:47:35.899576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train abs diff shape: (36473, 5000)\n",
      "Test abs diff shape: (36, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create similarity features from TF-IDF vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cosine similarity between anchor and target vectors\n",
    "train_cosine_sim = cosine_similarity(anchor_tfidf, target_tfidf).diagonal()\n",
    "test_cosine_sim = cosine_similarity(test_anchor_tfidf, test_target_tfidf).diagonal()\n",
    "\n",
    "# Also create absolute difference features\n",
    "anchor_dense = anchor_tfidf.toarray()\n",
    "target_dense = target_tfidf.toarray()\n",
    "test_anchor_dense = test_anchor_tfidf.toarray()\n",
    "test_target_dense = test_target_tfidf.toarray()\n",
    "\n",
    "# Absolute difference\n",
    "train_abs_diff = np.abs(anchor_dense - target_dense)\n",
    "test_abs_diff = np.abs(test_anchor_dense - test_target_dense)\n",
    "\n",
    "print(f\"Train abs diff shape: {train_abs_diff.shape}\")\n",
    "print(f\"Test abs diff shape: {test_abs_diff.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc003c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:47:35.902181Z",
     "iopub.status.busy": "2026-01-15T13:47:35.901973Z",
     "iopub.status.idle": "2026-01-15T13:47:36.437123Z",
     "shell.execute_reply": "2026-01-15T13:47:36.436561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training feature shape: (36473, 5001)\n",
      "Final test feature shape: (36, 5001)\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "# Combine cosine similarity with absolute difference features\n",
    "X_train = np.column_stack([\n",
    "    train_cosine_sim,\n",
    "    train_abs_diff\n",
    "])\n",
    "\n",
    "X_test = np.column_stack([\n",
    "    test_cosine_sim,\n",
    "    test_abs_diff\n",
    "])\n",
    "\n",
    "y_train = train_df['score'].values\n",
    "\n",
    "print(f\"Final training feature shape: {X_train.shape}\")\n",
    "print(f\"Final test feature shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59793ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:47:36.439116Z",
     "iopub.status.busy": "2026-01-15T13:47:36.438924Z",
     "iopub.status.idle": "2026-01-15T17:20:50.313241Z",
     "shell.execute_reply": "2026-01-15T17:20:50.312630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Pearson correlation: 0.4618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Pearson correlation: 0.4582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Pearson correlation: 0.4703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Pearson correlation: 0.4589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Pearson correlation: 0.4601\n",
      "\n",
      "Mean Pearson correlation: 0.4619 ± 0.0044\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        n_iter_no_change=20\n",
    "    )\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate Pearson correlation\n",
    "    corr = np.corrcoef(y_val, val_pred)[0, 1]\n",
    "    scores.append(corr)\n",
    "    print(f\"Fold {fold+1} Pearson correlation: {corr:.4f}\")\n",
    "\n",
    "print(f\"\\nMean Pearson correlation: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fd9d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T17:20:50.315615Z",
     "iopub.status.busy": "2026-01-15T17:20:50.315426Z",
     "iopub.status.idle": "2026-01-15T18:10:02.031284Z",
     "shell.execute_reply": "2026-01-15T18:10:02.030599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (36,)\n",
      "Test predictions range: [0.1653, 0.7200]\n",
      "Test predictions distribution:\n",
      "  0: 0\n",
      "  0.25: 21\n",
      "  0.5: 13\n",
      "  0.75: 2\n",
      "  1.0: 0\n"
     ]
    }
   ],
   "source": [
    "# Train on full data and make predictions\n",
    "final_model = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_iter_no_change=20\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Clip predictions to valid range [0, 1]\n",
    "test_predictions = np.clip(test_predictions, 0, 1)\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Test predictions range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "print(f\"Test predictions distribution:\")\n",
    "for val in [0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    count = np.sum((test_predictions >= val - 0.125) & (test_predictions < val + 0.125))\n",
    "    print(f\"  {val}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'score': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"Submission file created at /home/submission/submission.csv\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
