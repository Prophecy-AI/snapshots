{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ac86e",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Analyzing the competition data and winning solutions to guide the next experiments.\n",
    "\n",
    "**Current Status:**\n",
    "- Best CV: 0.4619 (TF-IDF + Gradient Boosting)\n",
    "- Target: 0.8782\n",
    "- Gap: 0.4163 points\n",
    "\n",
    "**Goal:** Understand what winning solutions did and identify the most promising directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19ed1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:20.968053Z",
     "iopub.status.busy": "2026-01-15T18:58:20.967492Z",
     "iopub.status.idle": "2026-01-15T18:58:22.365390Z",
     "shell.execute_reply": "2026-01-15T18:58:22.364796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36473, 5)\n",
      "Test shape: (36, 4)\n",
      "\n",
      "Columns: ['id', 'anchor', 'target', 'context', 'score']\n",
      "\n",
      "Score distribution:\n",
      "score\n",
      "0.00     7471\n",
      "0.25    11519\n",
      "0.50    12300\n",
      "0.75     4029\n",
      "1.00     1154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(train_df['score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c3f778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:22.369841Z",
     "iopub.status.busy": "2026-01-15T18:58:22.369652Z",
     "iopub.status.idle": "2026-01-15T18:58:22.406010Z",
     "shell.execute_reply": "2026-01-15T18:58:22.405511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (CPC) distribution:\n",
      "context\n",
      "H01    2186\n",
      "H04    2177\n",
      "G01    1812\n",
      "A61    1477\n",
      "F16    1091\n",
      "C07    1069\n",
      "G06    1063\n",
      "B60     916\n",
      "B01     891\n",
      "G02     877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique contexts: 106\n",
      "\n",
      "Sample rows with different contexts:\n",
      "\n",
      "Context: A47\n",
      "      anchor                  target  score\n",
      "0  abatement  abatement of pollution   0.50\n",
      "1  abatement          act of abating   0.75\n",
      "2  abatement         active catalyst   0.25\n",
      "\n",
      "Context: A61\n",
      "       anchor              target  score\n",
      "21  abatement  emission abatement   0.50\n",
      "22  abatement          prevention   0.50\n",
      "23  abatement         prophylaxis   0.25\n",
      "\n",
      "Context: A62\n",
      "          anchor               target  score\n",
      "24     abatement  pollution abatement    0.5\n",
      "14280   gas leak                fault    0.5\n",
      "14281   gas leak    gas leak detector    0.5\n",
      "\n",
      "Context: C01\n",
      "                anchor                 target  score\n",
      "25           abatement    abatement apparatus    0.5\n",
      "1261  ammonia recovery                ammonia    0.5\n",
      "1262  ammonia recovery  ammonia concentration    0.5\n",
      "\n",
      "Context: F16\n",
      "                      anchor         target  score\n",
      "26                 abatement      treatment    0.0\n",
      "1068  align with input shaft  alight motion    0.0\n",
      "1069  align with input shaft    align shaft    0.5\n"
     ]
    }
   ],
   "source": [
    "# Analyze the context feature\n",
    "print(\"Context (CPC) distribution:\")\n",
    "print(train_df['context'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nNumber of unique contexts: {train_df['context'].nunique()}\")\n",
    "\n",
    "# Look at examples with different contexts\n",
    "print(\"\\nSample rows with different contexts:\")\n",
    "sample_contexts = train_df['context'].unique()[:5]\n",
    "for ctx in sample_contexts:\n",
    "    print(f\"\\nContext: {ctx}\")\n",
    "    print(train_df[train_df['context'] == ctx][['anchor', 'target', 'score']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac19f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:40.069014Z",
     "iopub.status.busy": "2026-01-15T18:58:40.068454Z",
     "iopub.status.idle": "2026-01-15T18:58:40.228341Z",
     "shell.execute_reply": "2026-01-15T18:58:40.227817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor length statistics:\n",
      "count    36473.000000\n",
      "mean        15.991720\n",
      "std          5.538241\n",
      "min          3.000000\n",
      "25%         12.000000\n",
      "50%         15.000000\n",
      "75%         19.000000\n",
      "max         38.000000\n",
      "Name: anchor_len, dtype: float64\n",
      "\n",
      "Target length statistics:\n",
      "count    36473.000000\n",
      "mean        15.758780\n",
      "std          6.872403\n",
      "min          2.000000\n",
      "25%         11.000000\n",
      "50%         15.000000\n",
      "75%         20.000000\n",
      "max         98.000000\n",
      "Name: target_len, dtype: float64\n",
      "\n",
      "Anchor word count statistics:\n",
      "count    36473.000000\n",
      "mean         2.177885\n",
      "std          0.641176\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max          5.000000\n",
      "Name: anchor_word_count, dtype: float64\n",
      "\n",
      "Target word count statistics:\n",
      "count    36473.000000\n",
      "mean         2.171195\n",
      "std          0.849613\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max         15.000000\n",
      "Name: target_word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze phrase lengths\n",
    "train_df['anchor_len'] = train_df['anchor'].str.len()\n",
    "train_df['target_len'] = train_df['target'].str.len()\n",
    "train_df['anchor_word_count'] = train_df['anchor'].str.split().str.len()\n",
    "train_df['target_word_count'] = train_df['target'].str.split().str.len()\n",
    "\n",
    "print(\"Anchor length statistics:\")\n",
    "print(train_df['anchor_len'].describe())\n",
    "print(\"\\nTarget length statistics:\")\n",
    "print(train_df['target_len'].describe())\n",
    "\n",
    "print(\"\\nAnchor word count statistics:\")\n",
    "print(train_df['anchor_word_count'].describe())\n",
    "print(\"\\nTarget word count statistics:\")\n",
    "print(train_df['target_word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f0fd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:40.230296Z",
     "iopub.status.busy": "2026-01-15T18:58:40.229875Z",
     "iopub.status.idle": "2026-01-15T18:58:40.244925Z",
     "shell.execute_reply": "2026-01-15T18:58:40.244446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 contexts by average score:\n",
      "   context      mean       std  count\n",
      "12     A62  0.445652  0.212621     23\n",
      "75     F15  0.437500  0.314140     96\n",
      "69     E06  0.435294  0.256327     85\n",
      "40     B81  0.421053  0.334604     57\n",
      "15     B02  0.416667  0.314309     63\n",
      "82     F25  0.415441  0.196092     68\n",
      "17     B05  0.413961  0.298449    308\n",
      "95     G08  0.411850  0.233069    173\n",
      "2      A22  0.410714  0.237116     70\n",
      "38     B66  0.403766  0.283745    239\n",
      "\n",
      "Bottom 10 contexts by average score:\n",
      "   context      mean       std  count\n",
      "63     D21  0.327500  0.234988    300\n",
      "54     C21  0.326705  0.246696     88\n",
      "44     C04  0.326149  0.245167    348\n",
      "58     D01  0.325826  0.253873    333\n",
      "57     C25  0.322222  0.209482     90\n",
      "46     C07  0.322030  0.235693   1069\n",
      "45     C06  0.319672  0.242088     61\n",
      "48     C09  0.319620  0.236289    553\n",
      "51     C12  0.311216  0.247025    633\n",
      "43     C03  0.308282  0.234998    163\n"
     ]
    }
   ],
   "source": [
    "# Analyze score distribution by context\n",
    "score_by_context = train_df.groupby('context')['score'].agg(['mean', 'std', 'count']).reset_index()\n",
    "score_by_context = score_by_context.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Top 10 contexts by average score:\")\n",
    "print(score_by_context.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 contexts by average score:\")\n",
    "print(score_by_context.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96279ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:40.246907Z",
     "iopub.status.busy": "2026-01-15T18:58:40.246509Z",
     "iopub.status.idle": "2026-01-15T18:58:40.256049Z",
     "shell.execute_reply": "2026-01-15T18:58:40.255524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with score = 1.0 (perfect match):\n",
      "Context: C04 | Anchor: 'provide in amounts' | Target: 'provide amounts'\n",
      "Context: H01 | Anchor: 'hinge mechanisms' | Target: 'hinging mechanisms'\n",
      "Context: F03 | Anchor: 'pushing pin' | Target: 'pushing up pin'\n",
      "Context: G01 | Anchor: 'microchambers' | Target: 'micro chambers'\n",
      "Context: H04 | Anchor: 'fiber slack' | Target: 'fiber slacks'\n",
      "\n",
      "Examples with score = 0.0 (no match):\n",
      "Context: A46 | Anchor: 'opposing walls' | Target: 'handles'\n",
      "Context: C07 | Anchor: 'azabicyclo' | Target: 'nitrogen oxide'\n",
      "Context: H04 | Anchor: 'network load information' | Target: 'vehicle load'\n",
      "Context: G01 | Anchor: 'electrical current distribution' | Target: 'wholesale distribution'\n",
      "Context: F24 | Anchor: 'indoor room' | Target: 'indoor games'\n"
     ]
    }
   ],
   "source": [
    "# Look at examples with high and low scores to understand patterns\n",
    "print(\"Examples with score = 1.0 (perfect match):\")\n",
    "high_score = train_df[train_df['score'] == 1.0].sample(5, random_state=42)\n",
    "for _, row in high_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")\n",
    "\n",
    "print(\"\\nExamples with score = 0.0 (no match):\")\n",
    "low_score = train_df[train_df['score'] == 0.0].sample(5, random_state=42)\n",
    "for _, row in low_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386fe15b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:59:04.126889Z",
     "iopub.status.busy": "2026-01-15T18:59:04.126239Z",
     "iopub.status.idle": "2026-01-15T18:59:05.771974Z",
     "shell.execute_reply": "2026-01-15T18:59:05.771439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples showing semantic similarity (score >= 0.75):\n",
      "Score: 0.75 | Context: B29\n",
      "  Anchor: 'toolpaths'\n",
      "  Target: 'tool position'\n",
      "\n",
      "Score: 0.75 | Context: H04\n",
      "  Anchor: 'ecn'\n",
      "  Target: 'electronic communication network'\n",
      "\n",
      "Score: 0.75 | Context: F28\n",
      "  Anchor: 'battery cell assembly'\n",
      "  Target: 'battery assembly'\n",
      "\n",
      "Score: 0.75 | Context: F21\n",
      "  Anchor: 'resilient spring clip'\n",
      "  Target: 'flexible retaining member'\n",
      "\n",
      "Score: 1.0 | Context: B63\n",
      "  Anchor: 'water intake'\n",
      "  Target: 'water intake'\n",
      "\n",
      "Score: 0.75 | Context: G11\n",
      "  Anchor: 'lifting finger'\n",
      "  Target: 'lifter member'\n",
      "\n",
      "Score: 0.75 | Context: H05\n",
      "  Anchor: 'moisture proof film'\n",
      "  Target: 'waterproofing layer'\n",
      "\n",
      "Score: 0.75 | Context: B29\n",
      "  Anchor: 'project onto surface'\n",
      "  Target: 'project onto exterior'\n",
      "\n",
      "Score: 1.0 | Context: B27\n",
      "  Anchor: 'pneumatic logic'\n",
      "  Target: 'pneumatic logic'\n",
      "\n",
      "Score: 0.75 | Context: A61\n",
      "  Anchor: 'morpholin'\n",
      "  Target: 'diethylenimide oxide'\n",
      "\n",
      "\n",
      "Examples requiring context understanding:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 674 anchor-target pairs with context-dependent scores\n",
      "\n",
      "Sample context-dependent pairs:\n",
      "Pair 1: 'abnormal position' - 'open position'\n",
      "  Context B23: score = 0.25\n",
      "  Context E03: score = 0.5\n",
      "\n",
      "Pair 2: 'absorbent properties' - 'physical properties'\n",
      "  Context C08: score = 0.25\n",
      "  Context D01: score = 0.5\n",
      "\n",
      "Pair 3: 'absorbent properties' - 'properties'\n",
      "  Context C08: score = 0.25\n",
      "  Context D01: score = 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze semantic relationships - look for synonyms and paraphrases\n",
    "print(\"Examples showing semantic similarity (score >= 0.75):\")\n",
    "high_sim = train_df[train_df['score'] >= 0.75].sample(10, random_state=42)\n",
    "for _, row in high_sim.iterrows():\n",
    "    print(f\"Score: {row['score']} | Context: {row['context']}\")\n",
    "    print(f\"  Anchor: '{row['anchor']}'\")\n",
    "    print(f\"  Target: '{row['target']}'\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nExamples requiring context understanding:\")\n",
    "# Find examples where same anchor-target pair has different scores in different contexts\n",
    "from collections import defaultdict\n",
    "pair_scores = defaultdict(list)\n",
    "for _, row in train_df.iterrows():\n",
    "    pair = (row['anchor'], row['target'])\n",
    "    pair_scores[pair].append((row['context'], row['score']))\n",
    "\n",
    "context_dependent = {k: v for k, v in pair_scores.items() if len(v) > 1 and len(set([s for _, s in v])) > 1}\n",
    "print(f\"Found {len(context_dependent)} anchor-target pairs with context-dependent scores\")\n",
    "\n",
    "if context_dependent:\n",
    "    print(\"\\nSample context-dependent pairs:\")\n",
    "    for i, (pair, scores) in enumerate(list(context_dependent.items())[:3]):\n",
    "        print(f\"Pair {i+1}: '{pair[0]}' - '{pair[1]}'\")\n",
    "        for ctx, score in scores:\n",
    "            print(f\"  Context {ctx}: score = {score}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
