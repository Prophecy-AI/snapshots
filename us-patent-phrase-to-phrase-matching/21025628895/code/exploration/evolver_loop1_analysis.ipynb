{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ac86e",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Analyzing the competition data and winning solutions to guide the next experiments.\n",
    "\n",
    "**Current Status:**\n",
    "- Best CV: 0.4619 (TF-IDF + Gradient Boosting)\n",
    "- Target: 0.8782\n",
    "- Gap: 0.4163 points\n",
    "\n",
    "**Goal:** Understand what winning solutions did and identify the most promising directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19ed1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:20.968053Z",
     "iopub.status.busy": "2026-01-15T18:58:20.967492Z",
     "iopub.status.idle": "2026-01-15T18:58:22.365390Z",
     "shell.execute_reply": "2026-01-15T18:58:22.364796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36473, 5)\n",
      "Test shape: (36, 4)\n",
      "\n",
      "Columns: ['id', 'anchor', 'target', 'context', 'score']\n",
      "\n",
      "Score distribution:\n",
      "score\n",
      "0.00     7471\n",
      "0.25    11519\n",
      "0.50    12300\n",
      "0.75     4029\n",
      "1.00     1154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(train_df['score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c3f778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T18:58:22.369841Z",
     "iopub.status.busy": "2026-01-15T18:58:22.369652Z",
     "iopub.status.idle": "2026-01-15T18:58:22.406010Z",
     "shell.execute_reply": "2026-01-15T18:58:22.405511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (CPC) distribution:\n",
      "context\n",
      "H01    2186\n",
      "H04    2177\n",
      "G01    1812\n",
      "A61    1477\n",
      "F16    1091\n",
      "C07    1069\n",
      "G06    1063\n",
      "B60     916\n",
      "B01     891\n",
      "G02     877\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unique contexts: 106\n",
      "\n",
      "Sample rows with different contexts:\n",
      "\n",
      "Context: A47\n",
      "      anchor                  target  score\n",
      "0  abatement  abatement of pollution   0.50\n",
      "1  abatement          act of abating   0.75\n",
      "2  abatement         active catalyst   0.25\n",
      "\n",
      "Context: A61\n",
      "       anchor              target  score\n",
      "21  abatement  emission abatement   0.50\n",
      "22  abatement          prevention   0.50\n",
      "23  abatement         prophylaxis   0.25\n",
      "\n",
      "Context: A62\n",
      "          anchor               target  score\n",
      "24     abatement  pollution abatement    0.5\n",
      "14280   gas leak                fault    0.5\n",
      "14281   gas leak    gas leak detector    0.5\n",
      "\n",
      "Context: C01\n",
      "                anchor                 target  score\n",
      "25           abatement    abatement apparatus    0.5\n",
      "1261  ammonia recovery                ammonia    0.5\n",
      "1262  ammonia recovery  ammonia concentration    0.5\n",
      "\n",
      "Context: F16\n",
      "                      anchor         target  score\n",
      "26                 abatement      treatment    0.0\n",
      "1068  align with input shaft  alight motion    0.0\n",
      "1069  align with input shaft    align shaft    0.5\n"
     ]
    }
   ],
   "source": [
    "# Analyze the context feature\n",
    "print(\"Context (CPC) distribution:\")\n",
    "print(train_df['context'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nNumber of unique contexts: {train_df['context'].nunique()}\")\n",
    "\n",
    "# Look at examples with different contexts\n",
    "print(\"\\nSample rows with different contexts:\")\n",
    "sample_contexts = train_df['context'].unique()[:5]\n",
    "for ctx in sample_contexts:\n",
    "    print(f\"\\nContext: {ctx}\")\n",
    "    print(train_df[train_df['context'] == ctx][['anchor', 'target', 'score']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac19f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze phrase lengths\n",
    "train_df['anchor_len'] = train_df['anchor'].str.len()\n",
    "train_df['target_len'] = train_df['target'].str.len()\n",
    "train_df['anchor_word_count'] = train_df['anchor'].str.split().str.len()\n",
    "train_df['target_word_count'] = train_df['target'].str.split().str.len()\n",
    "\n",
    "print(\"Anchor length statistics:\")\n",
    "print(train_df['anchor_len'].describe())\n",
    "print(\"\\nTarget length statistics:\")\n",
    "print(train_df['target_len'].describe())\n",
    "\n",
    "print(\"\\nAnchor word count statistics:\")\n",
    "print(train_df['anchor_word_count'].describe())\n",
    "print(\"\\nTarget word count statistics:\")\n",
    "print(train_df['target_word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution by context\n",
    "score_by_context = train_df.groupby('context')['score'].agg(['mean', 'std', 'count']).reset_index()\n",
    "score_by_context = score_by_context.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Top 10 contexts by average score:\")\n",
    "print(score_by_context.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 contexts by average score:\")\n",
    "print(score_by_context.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96279ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at examples with high and low scores to understand patterns\n",
    "print(\"Examples with score = 1.0 (perfect match):\")\n",
    "high_score = train_df[train_df['score'] == 1.0].sample(5, random_state=42)\n",
    "for _, row in high_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")\n",
    "\n",
    "print(\"\\nExamples with score = 0.0 (no match):\")\n",
    "low_score = train_df[train_df['score'] == 0.0].sample(5, random_state=42)\n",
    "for _, row in low_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fe15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze semantic relationships - look for synonyms and paraphrases\n",
    "print(\"Examples showing semantic similarity (score >= 0.75):\")\n",
    "high_sim = train_df[train_df['score'] >= 0.75].sample(10, random_state=42)\n",
    "for _, row in high_sim.iterrows():\n",
    "    print(f\"Score: {row['score']} | Context: {row['context']}\")\n",
    "    print(f\"  Anchor: '{row['anchor']}'\")\n",
    "    print(f\"  Target: '{row['target']}'\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nExamples requiring context understanding:\")\n",
    "# Find examples where same anchor-target pair has different scores in different contexts\n",
    "from collections import defaultdict\n",
    "pair_scores = defaultdict(list)\n",
    "for _, row in train_df.iterrows():\n",
    "    pair = (row['anchor'], row['target'])\n",
    "    pair_scores[pair].append((row['context'], row['score']))\n",
    "\n",
    "context_dependent = {k: v for k, v in pair_scores.items() if len(v) > 1 and len(set([s for _, s in v])) > 1}\n",
    "print(f\"Found {len(context_dependent)} anchor-target pairs with context-dependent scores\")\n",
    "\n",
    "if context_dependent:\n",
    "    print(\"\\nSample context-dependent pairs:\")\n",
    "    for i, (pair, scores) in enumerate(list(context_dependent.items())[:3]):\n",
    "        print(f\"Pair {i+1}: '{pair[0]}' - '{pair[1]}'\")\n",
    "        for ctx, score in scores:\n",
    "            print(f\"  Context {ctx}: score = {score}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
