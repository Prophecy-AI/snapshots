{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ac86e",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Analyzing the competition data and winning solutions to guide the next experiments.\n",
    "\n",
    "**Current Status:**\n",
    "- Best CV: 0.4619 (TF-IDF + Gradient Boosting)\n",
    "- Target: 0.8782\n",
    "- Gap: 0.4163 points\n",
    "\n",
    "**Goal:** Understand what winning solutions did and identify the most promising directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "print(f\"\\nScore distribution:\")\n",
    "print(train_df['score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the context feature\n",
    "print(\"Context (CPC) distribution:\")\n",
    "print(train_df['context'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nNumber of unique contexts: {train_df['context'].nunique()}\")\n",
    "\n",
    "# Look at examples with different contexts\n",
    "print(\"\\nSample rows with different contexts:\")\n",
    "sample_contexts = train_df['context'].unique()[:5]\n",
    "for ctx in sample_contexts:\n",
    "    print(f\"\\nContext: {ctx}\")\n",
    "    print(train_df[train_df['context'] == ctx][['anchor', 'target', 'score']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac19f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze phrase lengths\n",
    "train_df['anchor_len'] = train_df['anchor'].str.len()\n",
    "train_df['target_len'] = train_df['target'].str.len()\n",
    "train_df['anchor_word_count'] = train_df['anchor'].str.split().str.len()\n",
    "train_df['target_word_count'] = train_df['target'].str.split().str.len()\n",
    "\n",
    "print(\"Anchor length statistics:\")\n",
    "print(train_df['anchor_len'].describe())\n",
    "print(\"\\nTarget length statistics:\")\n",
    "print(train_df['target_len'].describe())\n",
    "\n",
    "print(\"\\nAnchor word count statistics:\")\n",
    "print(train_df['anchor_word_count'].describe())\n",
    "print(\"\\nTarget word count statistics:\")\n",
    "print(train_df['target_word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution by context\n",
    "score_by_context = train_df.groupby('context')['score'].agg(['mean', 'std', 'count']).reset_index()\n",
    "score_by_context = score_by_context.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"Top 10 contexts by average score:\")\n",
    "print(score_by_context.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 contexts by average score:\")\n",
    "print(score_by_context.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96279ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at examples with high and low scores to understand patterns\n",
    "print(\"Examples with score = 1.0 (perfect match):\")\n",
    "high_score = train_df[train_df['score'] == 1.0].sample(5, random_state=42)\n",
    "for _, row in high_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")\n",
    "\n",
    "print(\"\\nExamples with score = 0.0 (no match):\")\n",
    "low_score = train_df[train_df['score'] == 0.0].sample(5, random_state=42)\n",
    "for _, row in low_score.iterrows():\n",
    "    print(f\"Context: {row['context']} | Anchor: '{row['anchor']}' | Target: '{row['target']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fe15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze semantic relationships - look for synonyms and paraphrases\n",
    "print(\"Examples showing semantic similarity (score >= 0.75):\")\n",
    "high_sim = train_df[train_df['score'] >= 0.75].sample(10, random_state=42)\n",
    "for _, row in high_sim.iterrows():\n",
    "    print(f\"Score: {row['score']} | Context: {row['context']}\")\n",
    "    print(f\"  Anchor: '{row['anchor']}'\")\n",
    "    print(f\"  Target: '{row['target']}'\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nExamples requiring context understanding:\")\n",
    "# Find examples where same anchor-target pair has different scores in different contexts\n",
    "from collections import defaultdict\n",
    "pair_scores = defaultdict(list)\n",
    "for _, row in train_df.iterrows():\n",
    "    pair = (row['anchor'], row['target'])\n",
    "    pair_scores[pair].append((row['context'], row['score']))\n",
    "\n",
    "context_dependent = {k: v for k, v in pair_scores.items() if len(v) > 1 and len(set([s for _, s in v])) > 1}\n",
    "print(f\"Found {len(context_dependent)} anchor-target pairs with context-dependent scores\")\n",
    "\n",
    "if context_dependent:\n",
    "    print(\"\\nSample context-dependent pairs:\")\n",
    "    for i, (pair, scores) in enumerate(list(context_dependent.items())[:3]):\n",
    "        print(f\"Pair {i+1}: '{pair[0]}' - '{pair[1]}'\")\n",
    "        for ctx, score in scores:\n",
    "            print(f\"  Context {ctx}: score = {score}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
