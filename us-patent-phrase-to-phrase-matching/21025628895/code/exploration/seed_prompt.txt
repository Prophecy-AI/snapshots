## Current Status
- Best CV score: 0.4619 from exp_000 (TF-IDF + Gradient Boosting)
- Target score: 0.8782
- Performance gap: 0.4163 points (we're at 53% of target)

## Response to Evaluator
- **Technical verdict was CONCERNS**: The evaluator correctly identified that TF-IDF approach is fundamentally misaligned with this semantic similarity problem. The massive 0.4163 point gap confirms this.
- **Evaluator's top priority**: Implement transformer-based baseline using context feature. **I fully agree** - this is the only viable path forward.
- **Key concerns raised**:
  1. Context feature ignored → **Will address by including CPC context in input format**
  2. Wrong model architecture (bag-of-words) → **Pivoting to DeBERTa-v3-large and BERT-for-patents**
  3. No semantic understanding → **Transformers capture synonyms, paraphrases, domain-specific relationships**
  4. Massive performance gap → **Winning solutions score ~0.86-0.87, transformers are proven to work**

## Data Understanding
- **Reference notebooks**: See `exploration/evolver_loop1_analysis.ipynb` for feature analysis
- **Key patterns discovered**:
  - Context (CPC) is CRITICAL: Found 674 anchor-target pairs with context-dependent scores (same phrases, different scores in different technical domains)
  - Semantic similarity requires understanding beyond lexical overlap: High scores involve synonyms, abbreviations, paraphrases
  - Winning solutions exploit correlations between targets sharing same anchor/context

## Recommended Approaches (Priority Order)

### 1. Transformer Baseline with Context (HIGHEST PRIORITY)
**Why**: All top-3 solutions use transformers. TF-IDF cannot capture semantic relationships or context-dependent meaning.

**Implementation**:
- Model: DeBERTa-v3-large (best single model per 1st place) or BERT-for-patents (domain-specific)
- Input format: `anchor [SEP] target [SEP] CPC_TEXT [SEP] targets` 
  - CPC_TEXT: Text description of CPC context code
  - targets: Other targets sharing same anchor/context (comma-separated)
- Training: Pearson correlation loss (worked best for winners)
- Validation: GroupKFold or StratifiedGroupKFold grouping by anchor (prevents leakage)

**Expected improvement**: Jump from 0.46 to ~0.85+ (based on winning solutions)

### 2. Advanced Training Techniques (SECOND PRIORITY)
**Why**: Winners used these to gain additional 0.01-0.02 points

**Techniques to implement**:
- AWP (Adversarial Weight Perturbation): Start from epoch 2, eps=0.1
- EMA (Exponential Moving Average): decay=0.999
- Bi-LSTM header on top of transformer: Helps capture sequence relationships
- Different learning rates: 2e-5 for transformer, 1e-3 for LSTM/head
- Freeze embedding layers (optional, minimal impact)

### 3. Ensemble Strategy (THIRD PRIORITY)
**Why**: Single models score ~0.85-0.86, ensembles reach 0.87-0.878

**Diversity sources**:
- Different backbones: DeBERTa-v3-large, BERT-for-patents, Electra-large
- Different grouping strategies: groupby anchor, anchor+context, anchor+sector(context[0])
- Different loss functions: Pearson, MSE (creates prediction distribution diversity)
- Different CV splits: GroupKFold vs StratifiedGroupKFold

**Ensemble method**: Weighted average (deberta-v3-large weight ~2x others based on CV)

### 4. Data Augmentation & Additional Features (FOURTH PRIORITY)
**Why**: Marginal gains after establishing strong baseline

**Ideas**:
- Shuffle target order during training (1st place found this helped)
- Add OOF scores as features in second stage (2nd place technique)
- Use CPC text descriptions to provide context meaning
- Group targets at sector level (context[0] - first letter of CPC code)

## What NOT to Try
- ❌ TF-IDF or bag-of-words approaches (exhausted, proven insufficient)
- ❌ Gradient boosting on lexical features (cannot capture semantics)
- ❌ Ignoring context column (critical for domain-specific meaning)
- ❌ Simple mean ensemble (need weighted ensemble based on model strength)
- ❌ BCE loss (winners found it didn't work well)

## Validation Notes
- **CV scheme**: GroupKFold or StratifiedGroupKFold with 5 folds, group by anchor
- **Metric**: Pearson correlation coefficient
- **Leakage prevention**: Ensure same anchor doesn't appear in both train/val
- **Test set**: Real test set has ~12k samples (not the 36-sample public test set)

## Implementation Order
1. Start with DeBERTa-v3-large + basic context inclusion (anchor[SEP]target[SEP]context)
2. Add target grouping (anchor[SEP]target[SEP]context[SEP]targets)
3. Implement Pearson loss and proper CV
4. Add Bi-LSTM header and AWP training
5. Create ensemble with 2-3 diverse models
6. Fine-tune weights and submit

**Target for next experiment**: 0.85+ CV score with transformer baseline