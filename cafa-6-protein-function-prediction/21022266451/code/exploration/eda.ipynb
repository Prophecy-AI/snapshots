{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8cce63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:50:30.569986Z",
     "iopub.status.busy": "2026-01-15T06:50:30.569460Z",
     "iopub.status.idle": "2026-01-15T06:50:31.163184Z",
     "shell.execute_reply": "2026-01-15T06:50:31.162749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train terms shape: (537027, 3)\n",
      "  EntryID        term aspect\n",
      "0  Q5W0B1  GO:0000785      C\n",
      "1  Q5W0B1  GO:0004842      F\n",
      "2  Q5W0B1  GO:0051865      P\n",
      "3  Q5W0B1  GO:0006275      P\n",
      "4  Q5W0B1  GO:0006513      P\n",
      "\n",
      "Columns: ['EntryID', 'term', 'aspect']\n",
      "\n",
      "Unique proteins: 82404\n",
      "Unique GO terms: 26125\n",
      "\n",
      "Aspect distribution:\n",
      "aspect\n",
      "P    250805\n",
      "C    157770\n",
      "F    128452\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "\n",
    "# Load training terms\n",
    "train_terms = pd.read_csv('/home/data/Train/train_terms.tsv', sep='\\t')\n",
    "print(\"Train terms shape:\", train_terms.shape)\n",
    "print(train_terms.head())\n",
    "print(\"\\nColumns:\", train_terms.columns.tolist())\n",
    "print(\"\\nUnique proteins:\", train_terms['EntryID'].nunique())\n",
    "print(\"Unique GO terms:\", train_terms['term'].nunique())\n",
    "print(\"\\nAspect distribution:\")\n",
    "print(train_terms['aspect'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3d4936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:51:10.283752Z",
     "iopub.status.busy": "2026-01-15T06:51:10.283277Z",
     "iopub.status.idle": "2026-01-15T06:51:10.312484Z",
     "shell.execute_reply": "2026-01-15T06:51:10.312054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA weights shape: (40122, 2)\n",
      "         term        ia\n",
      "0  GO:0000001  0.000000\n",
      "1  GO:0000002  2.849666\n",
      "2  GO:0000011  0.137504\n",
      "3  GO:0000012  6.038630\n",
      "4  GO:0000017  0.514573\n",
      "\n",
      "IA statistics:\n",
      "count    40122.000000\n",
      "mean         2.647186\n",
      "std          3.191901\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.201634\n",
      "75%          4.584963\n",
      "max         15.879703\n",
      "Name: ia, dtype: float64\n",
      "\n",
      "Sample submission shape: (20000, 3)\n",
      "   protein_id     go_term  confidence\n",
      "0  A0A0C5B5G6  GO:0000001       0.123\n",
      "1  A0A0C5B5G6  GO:0000002       0.456\n",
      "2  A0A1B0GTW7  GO:0000001       0.123\n",
      "3  A0A1B0GTW7  GO:0000002       0.456\n",
      "4      A0JNW5  GO:0000001       0.123\n"
     ]
    }
   ],
   "source": [
    "# Check IA weights (Information Accretion)\n",
    "ia_df = pd.read_csv('/home/data/IA.tsv', sep='\\t', header=None, names=['term', 'ia'])\n",
    "print(\"IA weights shape:\", ia_df.shape)\n",
    "print(ia_df.head())\n",
    "print(\"\\nIA statistics:\")\n",
    "print(ia_df['ia'].describe())\n",
    "\n",
    "# Check sample submission format - handle potential parsing issues\n",
    "import csv\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.tsv', sep='\\t', header=None, \n",
    "                          names=['protein_id', 'go_term', 'confidence'], \n",
    "                          on_bad_lines='skip')\n",
    "print(\"\\nSample submission shape:\", sample_sub.shape)\n",
    "print(sample_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e8e7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T06:51:30.409620Z",
     "iopub.status.busy": "2026-01-15T06:51:30.409126Z",
     "iopub.status.idle": "2026-01-15T06:51:32.965727Z",
     "shell.execute_reply": "2026-01-15T06:51:32.965264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test superset proteins: 224309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train proteins: 82404\n",
      "\n",
      "Train sequence lengths:\n",
      "  Min: 3\n",
      "  Max: 35213\n",
      "  Mean: 525.8\n",
      "  Median: 409.0\n"
     ]
    }
   ],
   "source": [
    "# Check test superset size\n",
    "test_seqs = list(SeqIO.parse('/home/data/Test/testsuperset.fasta', 'fasta'))\n",
    "print(f\"Test superset proteins: {len(test_seqs)}\")\n",
    "\n",
    "# Check train sequences\n",
    "train_seqs = list(SeqIO.parse('/home/data/Train/train_sequences.fasta', 'fasta'))\n",
    "print(f\"Train proteins: {len(train_seqs)}\")\n",
    "\n",
    "# Sequence length distribution\n",
    "train_lens = [len(seq.seq) for seq in train_seqs]\n",
    "print(f\"\\nTrain sequence lengths:\")\n",
    "print(f\"  Min: {min(train_lens)}\")\n",
    "print(f\"  Max: {max(train_lens)}\")\n",
    "print(f\"  Mean: {np.mean(train_lens):.1f}\")\n",
    "print(f\"  Median: {np.median(train_lens):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GO term frequency distribution\n",
    "term_counts = train_terms['term'].value_counts()\n",
    "print(\"GO term frequency distribution:\")\n",
    "print(f\"  Most common: {term_counts.iloc[0]} occurrences\")\n",
    "print(f\"  Least common: {term_counts.iloc[-1]} occurrences\")\n",
    "print(f\"  Top 10 terms cover {term_counts.head(10).sum()} annotations\")\n",
    "print(f\"  Top 100 terms cover {term_counts.head(100).sum()} annotations\")\n",
    "print(f\"  Top 500 terms cover {term_counts.head(500).sum()} annotations\")\n",
    "print(f\"  Top 1000 terms cover {term_counts.head(1000).sum()} annotations\")\n",
    "\n",
    "# Terms per protein\n",
    "terms_per_protein = train_terms.groupby('EntryID').size()\n",
    "print(f\"\\nTerms per protein:\")\n",
    "print(f\"  Min: {terms_per_protein.min()}\")\n",
    "print(f\"  Max: {terms_per_protein.max()}\")\n",
    "print(f\"  Mean: {terms_per_protein.mean():.1f}\")\n",
    "print(f\"  Median: {terms_per_protein.median():.1f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
