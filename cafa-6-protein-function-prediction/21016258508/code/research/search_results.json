{
  "query": "What are the best approaches for protein function prediction using Gene Ontology terms?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Protein function prediction with Gene Ontology (GO) terms builds on the hierarchical DAG that organizes\u202f\u2248\u202f40\u202f000 GO classes into molecular\u2011function, biological\u2011process and cellular\u2011component domains.  Early pipelines relied on **homology\u2011based transfer** (e.g., BLAST) and classic machine\u2011learning classifiers that combine sequence similarity, domain architecture or protein\u2011protein interaction (PPI) networks\u202f\u2013\u202fapproaches that remain useful for well\u2011studied families but struggle with remote homologs and multi\u2011label prediction\u202f([ncbi.nlm.nih.gov](https://ncbi.nlm.nih.gov/pmc/articles/PMC8395570)).  These \u201ctraditional\u201d methods set the baseline for community challenges such as CAFA\u202f3, but their performance is limited by the need for explicit feature engineering and by ignoring the GO hierarchy.\n\nSince 2017, **deep learning** has become the dominant strategy.  **DeepGO** introduced an ontology\u2011aware deep classifier that jointly consumes raw amino\u2011acid sequences and interaction graphs, explicitly modelling GO dependencies to improve multi\u2011label accuracy\u202f([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC5860606)).  Subsequent work (Kulmanov\u202fet\u202fal., 2017) combined sequence\u2011derived embeddings with a cross\u2011species PPI network in a neural architecture that outperformed BLAST on CAFA metrics\u202f([arxiv.org](https://arxiv.org/abs/1705.05919)).  More recent transformer\u2011based systems such as **GOProFormer** treat GO prediction as a multi\u2011modal sequence\u2011to\u2011graph task, integrating protein language\u2011model embeddings, structural features and the GO DAG within a unified attention framework\u202f([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818);\u202f[ biorxiv.org](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full)).  **POSA\u2011GO** further fuses hierarchical GO information with large\u2011scale protein language models, achieving state\u2011of\u2011the\u2011art results on recent benchmark sets\u202f([pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC12250456)).\n\nThe newest trend leverages **graph representation learning** and hierarchical semantic embeddings.  Methods such as **STAR\u2011GO** learn ontology\u2011informed embeddings that respect the DAG structure and integrate them with graph neural networks to capture both sequence\u2011level and network\u2011level signals\u202f([arxiv.org](https://arxiv.org/abs/2512.05245)).  An experimental analysis on GO\u2011based prediction confirms that graph\u2011based encodings of proteins and GO terms consistently improve recall across MF, BP and CC categories\u202f([peerj.com](https://peerj.com/articles/18509)).  Collectively, the best-performing pipelines today combine (i) deep protein language\u2011model embeddings, (ii) multi\u2011modal inputs (sequence, structure, PPI), (iii) transformer or GNN architectures that respect GO\u2019s hierarchical DAG, and (iv) training on large, curated benchmark datasets such as CAFA\u202f3.  These components together deliver the most accurate and scalable GO term predictions for newly sequenced proteins.",
      "url": ""
    },
    {
      "title": "Protein function prediction with gene ontology: from traditional to deep learning models",
      "text": "## Abstract\n\nProtein function prediction is a crucial part of genome annotation. Prediction methods have recently witnessed rapid development, owing to the emergence of high-throughput sequencing technologies. Among the available databases for identifying protein function terms, Gene Ontology (GO) is an important resource that describes the functional properties of proteins. Researchers are employing various approaches to efficiently predict the GO terms. Meanwhile, deep learning, a fast-evolving discipline in data-driven approach, exhibits impressive potential with respect to assigning GO terms to amino acid sequences. Herein, we reviewed the currently available computational GO annotation methods for proteins, ranging from conventional to deep learning approach. Further, we selected some suitable predictors from among the reviewed tools and conducted a mini comparison of their performance using a worldwide challenge dataset. Finally, we discussed the remaining major challenges in the field, and emphasized the future directions for protein function prediction with GO.\n\n**Keywords:** Gene Ontology, Protein function prediction, Machine learning, Deep learning, CAFA3, Annotation\n\n## Introduction\n\nProteins are organic macromolecules that are fundamental determinants of the structure and function of living organisms. They play a role in numerous processes, including biochemical reactions, transmission of signals, nutrient transport, immune system boosting, etc. Therefore, understanding protein properties is essential not only from the biological and evolutionary perspectives, but also from the viewpoint of leveraging their potential in biomedical and pharmaceutical applications, and other areas\u00a0( [Amiri-Dashatan et al., 2018](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-3)).\n\nGenerally, protein function identification is accomplished through manual or computational annotation. The former approach is the gold standard for functional annotation, because it is implemented by expert annotators and yields high quality curated results. Nonetheless, this approach is expensive and laborious, and thus, it is difficult to scale. Furthermore, because of the development of high-throughput sequencing technologies, such as next-generation sequencing (NGS), the amount of sequences to be annotated has increased dramatically. Thus, computational annotation methods have been developed as a must to automatically process the high volume of newly generated sequences, and also to improve the accuracy of the annotated data\u00a0( [Sleator & Walsh, 2010](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-63)).\n\nBecause of the variability in the vocabulary used to define protein function, which makes the annotation process confusing to both humans and machines, various databases have been proposed to provide a standardized scheme, such as the Enzyme Commission (EC)\u00a0( [Webb, 1992](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-74)), Functional Catalogue (FunCat)\u00a0( [Ruepp et al., 2004](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)), and Kyoto Encyclopedia of Genes and Genomes (KEGG)\u00a0( [Kanehisa et al., 2004](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-30)). Currently, Gene Ontology (GO)\u00a0( [Ashburner et al., 2000](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-4); [Consortium, 2015](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-11)) is the most comprehensive resource, as it possesses all the desirable properties of a functional classification system\u00a0( [Pandey, Kumar & Steinbach, 2006](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-48)). The GO consortium created a database for a controlled vocabulary describing the functional properties of genomic products ( _e.g._,\u00a0genes, proteins, and RNA). Each ontology (vocabulary) belongs to one of three categories: molecular function (MF), biological process (BP), and cellular component (CC). In terms of structure, the GO follows a hierarchical organization as a directed acyclic graph (DAG), in which each term is a node and each edge connected to two nodes represents a parent\u2013child relationship. It can be used to infer many types of information, such as \u201cis-a\u201d or \u201cpart-of\u201d. For instance, if term A is denoted as \u201cis-a\u201d of term B, it means that A is a sub-type of B. Further, \u201cpart-of\u201d implies that the child node is necessarily part of the parent. This allows the flexible annotation of proteins with respect to the various levels of function\u2014from general to specific terms\u2014depending on the available evidence\u00a0( [Stein, 2001](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)).\n\nAutomated function prediction (AFP) based on the GO system is a challenging problem in bioinformatics. Many studies have discussed protein functional annotation from different perspectives. Previous reviews focused on AFP\u00a0( [Rost et al., 2003](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-56)) in terms of the data type used\u00a0( [Watson, Laskowski & Thornton, 2005](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-73); [Pandey, Kumar & Steinbach, 2006](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-48); [Sleator & Walsh, 2010](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-63); [Shehu, Barbar\u00e1 & Molloy, 2016](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-62)), drawbacks and corresponding solutions\u00a0( [Friedberg, 2006](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-19)), protein interaction networks\u00a0( [Sharan, Ulitsky & Shamir, 2007](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-61)), types of classified function\u00a0( [Rentzsch & Orengo, 2009](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-54)), and GO assignment based on sequence information\u00a0( [Cozzetto & Jones, 2017](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-12)). The two latest reviews are prepared by\u00a0[Bonetta & Valentino (2020)](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-6) and\u00a0[Zhao et al. (2020)](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-83).\u00a0[Bonetta & Valentino (2020)](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-6) demonstrate protein function prediction in the machine learning workflow. Meanwhile,\u00a0[Zhao et al. (2020)](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-83) discuss prediction of gene function prediction from the GO modeling perspective. All these researches provided independent perspectives to the issue, but we observed that there has not been any detailed review about deep learning, which is an emerging approach for protein function prediction with GO terms. Therefore, our paper suggests the possibility of predicting protein function using both conventional learning and deep learning, further indicating that better predictive performance can be expected by comparing several methods with each other.\n\nHerein, we reviewed automated protein function prediction using GO terms (ranging from traditional solutions to the most recently developed deep learning-based tools). We presented not only an overview of the literature, but also, a performance comparison of the emerging solutions. Further, we highlighted the challenges and future prospects of the field. We hope that this review will provide bioinformaticians, computer scientists or any researchers who are interested in this topic, with the latest updates in terms of protein features used, models, and evaluation criteria, hoping to contribute to further improvements in the future.\n\n## Survey Methodology\n\nBased on previous studies\u00a0( [Jung & Thon, 2006](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-28); [Jung et al., 2010](http://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29)) and the aforementioned surveys, our review is divided in two main parts offering an overview of the field (from its inception to its present state). The first parts covers the conventional approach and includes solutions that do not use deep learning, while the second part describes methods that rely on deep learning to address the prob...",
      "url": "https://ncbi.nlm.nih.gov/pmc/articles/PMC8395570"
    },
    {
      "title": "GOProFormer: A Multi-Modal Transformer Method for Gene Ontology Protein Function Prediction",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#main-content)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n\n**Official websites use .gov**\n\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n\n**Secure .gov websites use HTTPS**\n\nA **lock** (\nLock\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n\n- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\n\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\n![Biomolecules logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-biomol.png)\n\nBiomolecules\n\n. 2022 Nov 18;12(11):1709. doi: [10.3390/biom12111709](https://doi.org/10.3390/biom12111709)\n\n# GOProFormer: A Multi-Modal Transformer Method for Gene Ontology Protein Function Prediction\n\n[Anowarul Kabir](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kabir%20A%22%5BAuthor%5D)\n\n### Anowarul Kabir\n\n1Department of Computer Science, George Mason University, Fairfax, VA 22030, USA\n\nConceptualization, Data curation, Formal analysis, Methodology, Validation, Visualization, Writing \u2013 original draft\n\nFind articles by [Anowarul Kabir](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kabir%20A%22%5BAuthor%5D)\n\n1,\u2020, [Amarda Shehu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Shehu%20A%22%5BAuthor%5D)\n\n### Amarda Shehu\n\n1Department of Computer Science, George Mason University, Fairfax, VA 22030, USA\n\n2Center for Advancing Human-Machine Partnerships, George Mason University, Fairfax, VA 22030, USA\n\n3Department of Bioengineering, George Mason University, Fairfax, VA 22030, USA\n\n4School of Systems Biology, George Mason University, Fairfax, VA 22030, USA\n\nConceptualization, Formal analysis, Funding acquisition, Project administration, Supervision, Writing \u2013 original draft, Writing \u2013 review & editing\n\nFind articles by [Amarda Shehu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Shehu%20A%22%5BAuthor%5D)\n\n1,2,3,4,\\*,\u2020\n\nEditor: Andrzej Koli\u0144ski\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1Department of Computer Science, George Mason University, Fairfax, VA 22030, USA\n\n2Center for Advancing Human-Machine Partnerships, George Mason University, Fairfax, VA 22030, USA\n\n3Department of Bioengineering, George Mason University, Fairfax, VA 22030, USA\n\n4School of Systems Biology, George Mason University, Fairfax, VA 22030, USA\n\n\\*\n\nCorrespondence: amarda@gmu.edu\n\n\u2020\n\nCurrent address: Department of Computer Science, 4400 University Drive, MS 4A5, Fairfax, VA 22030, USA.\n\n#### Roles\n\n**Anowarul Kabir**: Conceptualization, Data curation, Formal analysis, Methodology, Validation, Visualization, Writing \u2013 original draft\n\n**Amarda Shehu**: Conceptualization, Formal analysis, Funding acquisition, Project administration, Supervision, Writing \u2013 original draft, Writing \u2013 review & editing\n\n**Andrzej Koli\u0144ski**: Academic Editor\n\nReceived 2022 Oct 24; Accepted 2022 Nov 15; Collection date 2022 Nov.\n\n\u00a9 2022 by the authors.\n\nLicensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC9687818\u00a0\u00a0PMID: [36421723](https://pubmed.ncbi.nlm.nih.gov/36421723/)\n\n## Abstract\n\nProtein Language Models (PLMs) are shown to be capable of learning sequence representations useful for various prediction tasks, from subcellular localization, evolutionary relationships, family membership, and more. They have yet to be demonstrated useful for protein function prediction. In particular, the problem of automatic annotation of proteins under the Gene Ontology (GO) framework remains open. This paper makes two key contributions. It debuts a novel method that leverages the transformer architecture in two ways. A sequence transformer encodes protein sequences in a task-agnostic feature space. A graph transformer learns a representation of GO terms while respecting their hierarchical relationships. The learned sequence and GO terms representations are combined and utilized for multi-label classification, with the labels corresponding to GO terms. The method is shown superior over recent representative GO prediction methods. The second major contribution in this paper is a deep investigation of different ways of constructing training and testing datasets. The paper shows that existing approaches under- or over-estimate the generalization power of a model. A novel approach is proposed to address these issues, resulting in a new benchmark dataset to rigorously evaluate and compare methods and advance the state-of-the-art.\n\n**Keywords:** multi-modal transformer, gene ontology, protein function\n\n## 1\\. Introduction\n\nAn explosion in the number of known protein sequences is now allowing us to leverage the Transformer \\[ [1](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B1-biomolecules-12-01709)\\] architecture to build Protein Language Models (PLMS) \\[ [2](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B2-biomolecules-12-01709), [3](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B3-biomolecules-12-01709), [4](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B4-biomolecules-12-01709)\\]. PLMs are highly appealing due to their ability to learn task-agnostic representations of proteins. In particular, they provide an alternative framework to link protein sequence to function without relying on sequence similarity. Sequence representations learned via PLMs have been shown useful for various prediction tasks, from predicting secondary structure \\[ [4](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B4-biomolecules-12-01709)\\], subcellular localization \\[ [4](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B4-biomolecules-12-01709), [5](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B5-biomolecules-12-01709)\\], evolutionary relationships within protein families \\[ [6](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B6-biomolecules-12-01709)\\], superfamily \\[ [7](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B7-biomolecules-12-01709)\\], and family \\[ [8](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B8-biomolecules-12-01709)\\] membership.\n\nPLMs have yet to be demonstrated as useful for protein function prediction, which remains a hallmark problem in molecular biology \\[ [9](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B9-biomolecules-12-01709)\\]. In particular, throughput technologies have greatly increased the number of protein sequences in public repositories, but only about 1% of the sequences in the UniProtKB database have been functionally characterized \\[ [10](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B10-biomolecules-12-01709)\\]. This gap motivates computational approaches \\[ [11](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B11-biomolecules-12-01709)\\], and the computational literature on protein function prediction is rich \\[ [12](https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818/#B12-biomolecules-12-01709)\\].\n\nIn this paper we focus on challenging, community-driven instantiation of protein function prediction that utilizes the gene ontology (GO) hierarchy. The GO...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9687818"
    },
    {
      "title": "DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/us_flag.svg)\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\n[![                                   NCBI home page                               ](https://pmc.ncbi.nlm.nih.gov/static/img/ncbi-logos/nih-nlm-ncbi--white.svg)](https://www.ncbi.nlm.nih.gov/)\n\n![Close](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons/close.svg)![Search](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg==)\n\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n\n- [Advanced Search](https://www.ncbi.nlm.nih.gov/pmc/advanced/)\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\n![Bioinformatics logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-bioinfo.png)\n\nBioinformatics\n\n. 2017 Oct 3;34(4):660\u2013668. doi: [10.1093/bioinformatics/btx624](https://doi.org/10.1093/bioinformatics/btx624)\n\n# DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier\n\n[Maxat Kulmanov](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kulmanov%20M%22%5BAuthor%5D)\n\n### Maxat Kulmanov\n\n1Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia\n\nFind articles by [Maxat Kulmanov](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kulmanov%20M%22%5BAuthor%5D)\n\n1, [Mohammed Asif Khan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20MA%22%5BAuthor%5D)\n\n### Mohammed Asif Khan\n\n1Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia\n\nFind articles by [Mohammed Asif Khan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20MA%22%5BAuthor%5D)\n\n1, [Robert Hoehndorf](https://pubmed.ncbi.nlm.nih.gov/?term=%22Hoehndorf%20R%22%5BAuthor%5D)\n\n### Robert Hoehndorf\n\n1Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia\n\nFind articles by [Robert Hoehndorf](https://pubmed.ncbi.nlm.nih.gov/?term=%22Hoehndorf%20R%22%5BAuthor%5D)\n\n1,\u2709\n\nEditor: Jonathan Wren\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1Computer, Electrical and Mathematical Sciences & Engineering Division, Computational Bioscience Research Center, King Abdullah University of Science and Technology, Thuwal, Kingdom of Saudi Arabia\n\n\u2709\n\nTo whom correspondence should be addressed. Email: robert.hoehndorf@kaust.edu.sa\n\n#### Roles\n\n**Jonathan Wren**: Associate Editor\n\nReceived 2017 May 10; Revised 2017 Sep 23; Accepted 2017 Sep 27; Issue date 2018 Feb 15.\n\n\u00a9 The Author 2017. Published by Oxford University Press.\n\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License ( [http://creativecommons.org/licenses/by/4.0/](http://creativecommons.org/licenses/by/4.0/)), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC5860606\u00a0\u00a0PMID: [29028931](https://pubmed.ncbi.nlm.nih.gov/29028931/)\n\n## Abstract\n\n### Motivation\n\nA large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. Computational function prediction approaches have been suggested to fill this gap. The functions of proteins are classified using the Gene Ontology (GO), which contains over 40\u2009000 classes. Additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem.\n\n### Results\n\nWe have developed a novel method to predict protein function from sequence. We use deep learning to learn features from protein sequences as well as a cross-species protein\u2013protein interaction network. Our approach specifically outputs information in the structure of the GO and utilizes the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and demonstrate a significant improvement over baseline methods such as BLAST, in particular for predicting cellular locations.\n\n### Availability and implementation\n\nWeb server: [http://deepgo.bio2vec.net](http://deepgo.bio2vec.net), Source code: [https://github.com/bio-ontology-research-group/deepgo](https://github.com/bio-ontology-research-group/deepgo)\n\n### Supplementary information\n\n[Supplementary data](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#sup1) are available at _Bioinformatics_ online.\n\n## 1 Introduction\n\nAdvances in sequencing technology have led to a large and rapidly increasing amount of genetic and protein sequences, and the amount is expected to increase further through sequencing of additional organisms as well as metagenomics. Although knowledge of protein sequences is useful for many applications, such as phylogenetics and evolutionary biology, understanding the behavior of biological systems additionally requires knowledge of the proteins\u2019 functions. Identifying protein functions is challenging and commonly requires _in vitro_ or _in vivo_ experiments ( [Costanzo _et al._, 2016](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B13)), and it is obvious that experimental functional annotation of proteins will not scale with the amount of novel protein sequences becoming available.\n\nOne approach to address the challenge of identifying proteins\u2019 functions is the computational prediction of protein functions ( [Radivojac _et al._, 2013](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B31)). Function prediction can use several sources of information, including protein\u2013protein interactions ( [Hou, 2017](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B23); [Jiang and McQuay, 2012](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B25); [Kirac and Ozsoyoglu, 2008](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B26); [Nguyen _et al._, 2011](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B29); [Sharan _et al._, 2007](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#btx624-B33)), genetic interactions ( [Costanzo _et al...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC5860606"
    },
    {
      "title": "POSA-GO: Fusion of Hierarchical Gene Ontology and Protein Language Models for Protein Function Prediction",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nInt J Mol Sci\n\n. 2025 Jul 1;26(13):6362. doi: [10.3390/ijms26136362](https://doi.org/10.3390/ijms26136362)\n\n# POSA-GO: Fusion of Hierarchical Gene Ontology and Protein Language Models for Protein Function Prediction\n\n[Yubao Liu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20Y%22%5BAuthor%5D)\n\n### Yubao Liu\n\n1College of Computer Science and Technology, Changchun University, Changchun 130012, China; liuyb@ccu.edu.cn (Y.L.); 231501522@mails.ccu.edu.cn (B.W.); 231502539@mails.ccu.edu.cn (B.Y.); 241501500@mails.ccu.edu.cn (H.J.)\n\nConceptualization, Writing \u2013 original draft, Writing \u2013 review & editing\n\nFind articles by [Yubao Liu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20Y%22%5BAuthor%5D)\n\n1, [Benrui Wang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20B%22%5BAuthor%5D)\n\n### Benrui Wang\n\n1College of Computer Science and Technology, Changchun University, Changchun 130012, China; liuyb@ccu.edu.cn (Y.L.); 231501522@mails.ccu.edu.cn (B.W.); 231502539@mails.ccu.edu.cn (B.Y.); 241501500@mails.ccu.edu.cn (H.J.)\n\nConceptualization, Data curation, Writing \u2013 original draft, Writing \u2013 review & editing\n\nFind articles by [Benrui Wang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20B%22%5BAuthor%5D)\n\n1, [Bocheng Yan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yan%20B%22%5BAuthor%5D)\n\n### Bocheng Yan\n\n1College of Computer Science and Technology, Changchun University, Changchun 130012, China; liuyb@ccu.edu.cn (Y.L.); 231501522@mails.ccu.edu.cn (B.W.); 231502539@mails.ccu.edu.cn (B.Y.); 241501500@mails.ccu.edu.cn (H.J.)\n\nValidation, Writing \u2013 review & editing\n\nFind articles by [Bocheng Yan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yan%20B%22%5BAuthor%5D)\n\n1, [Haiyue Jiang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Jiang%20H%22%5BAuthor%5D)\n\n### Haiyue Jiang\n\n1College of Computer Science and Technology, Changchun University, Changchun 130012, China; liuyb@ccu.edu.cn (Y.L.); 231501522@mails.ccu.edu.cn (B.W.); 231502539@mails.ccu.edu.cn (B.Y.); 241501500@mails.ccu.edu.cn (H.J.)\n\nData curation, Writing \u2013 review & editing\n\nFind articles by [Haiyue Jiang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Jiang%20H%22%5BAuthor%5D)\n\n1, [Yinfei Dai](https://pubmed.ncbi.nlm.nih.gov/?term=%22Dai%20Y%22%5BAuthor%5D)\n\n### Yinfei Dai\n\n2College of Computer Science and Technology, Jilin University, Changchun 130025, China\n\nMethodology, Writing \u2013 review & editing\n\nFind articles by [Yinfei Dai](https://pubmed.ncbi.nlm.nih.gov/?term=%22Dai%20Y%22%5BAuthor%5D)\n\n2,\\*\n\nEditor: Fei Guo\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1College of Computer Science and Technology, Changchun University, Changchun 130012, China; liuyb@ccu.edu.cn (Y.L.); 231501522@mails.ccu.edu.cn (B.W.); 231502539@mails.ccu.edu.cn (B.Y.); 241501500@mails.ccu.edu.cn (H.J.)\n\n2College of Computer Science and Technology, Jilin University, Changchun 130025, China\n\n\\*\n\nCorrespondence: daiyf23@mails.jlu.edu.cn\n\n#### Roles\n\n**Yubao Liu**: Conceptualization, Writing \u2013 original draft, Writing \u2013 review & editing\n\n**Benrui Wang**: Conceptualization, Data curation, Writing \u2013 original draft, Writing \u2013 review & editing\n\n**Bocheng Yan**: Validation, Writing \u2013 review & editing\n\n**Haiyue Jiang**: Data curation, Writing \u2013 review & editing\n\n**Yinfei Dai**: Methodology, Writing \u2013 review & editing\n\n**Fei Guo**: Academic Editor\n\nReceived 2025 May 20; Revised 2025 Jun 24; Accepted 2025 Jun 26; Collection date 2025 Jul.\n\n\u00a9 2025 by the authors.\n\nLicensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ( [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC12250456\u00a0\u00a0PMID: [40650140](https://pubmed.ncbi.nlm.nih.gov/40650140/)\n\n## Abstract\n\nProtein function prediction plays a crucial role in uncovering the molecular mechanisms underlying life processes in the post-genomic era. However, with the widespread adoption of high-throughput sequencing technologies, the pace of protein function annotation significantly lags behind that of sequence discovery, highlighting the urgent need for more efficient and reliable predictive methods. To address the problem of existing methods ignoring the hierarchical structure of gene ontology terms and making it challenging to dynamically associate protein features with functional contexts, we propose a novel protein function prediction framework, termed Partial Order-Based Self-Attention for Gene Ontology (POSA-GO). This cross-modal collaborative modelling approach fuses GO terms with protein sequences. The model leverages the pre-trained language model ESM-2 to extract deep semantic features from protein sequences. Meanwhile, it transforms the partial order relationships among Gene Ontology (GO) terms into topological embeddings to capture their biological hierarchical dependencies. Furthermore, a multi-head self-attention mechanism is employed to dynamically model the association weights between proteins and GO terms, thereby enabling context-aware functional annotation. Comparative experiments on the CAFA3 and SwissProt datasets demonstrate that POSA-GO outperforms existing state-of-the-art methods in terms of Fmax and AUPR metrics, offering a promising solution for protein functional studies.\n\n**Keywords:** protein function prediction, gene ontology, multiple self-attention mechanisms, protein language model\n\n## 1\\. Introduction\n\nProteins are at the core of life activities and are involved in key processes such as signaling, metabolic regulation, and maintenance of the cellular structure. Defining their functions reveals disease mechanisms and drug targets and is the key to understanding the operation of biomolecules \\[ [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B1-ijms-26-06362)\\]. However, traditional biochemical experiments are costly, lengthy, and low-throughput \\[ [2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B2-ijms-26-06362)\\], resulting in reliable functional annotation of only approximately 0.23% of protein sequences \\[ [3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B3-ijms-26-06362)\\]. With the rapid development of high-throughput sequencing technology, the number of unannotated proteins has proliferated, and it is difficult to match the experimental validation capability; so there is an urgent need for efficient and accurate protein function annotation methods to break through the experimental limitations \\[ [4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B4-ijms-26-06362)\\].\n\nTraditional protein function prediction methods mainly rely on homology-based transfer \\[ [5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B5-ijms-26-06362)\\]. For example, BLAST (version 2.13.0) \\[ [6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B6-ijms-26-06362)\\] (BLAST: Basic Local Alignment Search Tool) and Diamond \\[ [7](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B7-ijms-26-06362)\\] (Diam...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC12250456"
    },
    {
      "title": "GOProFormer: A Multi-modal Transformer Method for Gene Ontology Protein Function Prediction",
      "text": "[Skip to main content](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#main-content)\n\nNew Results\n\n# GOProFormer: A Multi-modal Transformer Method for Gene Ontology Protein Function Prediction\n\nAnowarulKabir, [View ORCID Profile](http://orcid.org/0000-0001-5230-4610) AmardaShehu\n\ndoi: https://doi.org/10.1101/2022.10.20.513033\n\nAnowarul Kabir\n\n1Department of Computer Science, George Mason University\n\n- [Find this author on Google Scholar](https://www.biorxiv.org/lookup/google-scholar?link_type=googlescholar&gs_type=author&author%5B0%5D=Anowarul%2BKabir%2B)\n- [Find this author on PubMed](https://www.biorxiv.org/lookup/external-ref?access_num=Kabir%20A&link_type=AUTHORSEARCH)\n- [Search for this author on this site](https://www.biorxiv.org/search/author1%3AAnowarul%2BKabir%2B)\n\nAmarda Shehu\n\n1Department of Computer Science, George Mason University\n\n- [Find this author on Google Scholar](https://www.biorxiv.org/lookup/google-scholar?link_type=googlescholar&gs_type=author&author%5B0%5D=Amarda%2BShehu%2B)\n- [Find this author on PubMed](https://www.biorxiv.org/lookup/external-ref?access_num=Shehu%20A&link_type=AUTHORSEARCH)\n- [Search for this author on this site](https://www.biorxiv.org/search/author1%3AAmarda%2BShehu%2B)\n- [ORCID record for Amarda Shehu](http://orcid.org/0000-0001-5230-4610)\n- For correspondence:\n[ashehu{at}gmu.edu](https://www.biorxiv.org/cdn-cgi/l/email-protection#315042595459444a50454c565c441f545544)\n\n- [Abstract](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1)\n- [Full Text](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full-text)\n- [Info/History](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.article-info)\n- [Metrics](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.article-metrics)\n- [Preview PDF](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full.pdf+html)\n\n![Loading](https://www.biorxiv.org/sites/all/modules/contrib/panels_ajax_tab/images/loading.gif)\n\n## Abstract\n\nProtein Language Models (PLMs) are shown capable of learning sequence representations useful for various prediction tasks, from subcellular localization, evolutionary relationships, family membership, and more. They have yet to be demonstrated useful for protein function prediction. In particular, the problem of automatic annotation of proteins under the Gene Ontology (GO) framework remains open. This paper makes two key contributions. It debuts a novel method that leverages the transformer architecture in two ways. A sequence transformer encodes protein sequences in a task-agnostic feature space. A graph transformer learns a representation of GO terms while respecting their hierarchical relationships. The learned sequence and GO terms representations are combined and utilized for multi-label classification, with the labels corresponding to GO terms. The method is shown superior over recent representative GO prediction methods. The second major contribution in this paper is a deep investigation of different ways of constructing training and testing datasets. The paper shows that existing approaches under- or over-estimate the generalization power of a model. A novel approach is proposed to address these issues, resulting a new benchmark dataset to rigorously evaluate and compare methods and advance the state-of-the-art.\n\n## I. Introduction\n\nAn explosion in the number of known protein sequences is now allowing us to leverage the Transformer \\[ [1](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-1)\\] architecture to build Protein Language Models (PLMS) \\[ [2](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-2)\\]\u2013\\[ [4](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-4)\\]. PLMs are highly appealing due to their ability to learn task-agnostic representations of proteins. In particular, they provide an alternative framework to link protein sequence to function without relying on sequence similarity. Sequence representations learned via PLMs have been shown useful for various prediction tasks, from predicting secondary structure \\[ [4](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-4)\\], subcellular localization \\[ [4](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-4)\\], \\[ [5](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-5)\\], evolutionary relationships within protein families \\[ [6](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-6)\\], superfamily \\[ [7](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-7)\\], and family \\[ [8](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-8)\\] membership.\n\nPLMs have yet to be demonstrated useful for protein function prediction, which remains a hallmark problem in molecular biology \\[ [9](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-9)\\]. and challenges both wet and dry laboratories. Throughput technologies have greatly increased the number of protein sequences in public repositories, but only about 1% of the sequences in the UniProtKB database have been functionally characterized \\[ [10](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-10)\\]. This gap motivates computational approaches \\[ [11](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-11)\\], and the computational literature on protein function prediction is rich \\[ [12](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-12)\\].\n\nIn this paper we focus on challenging, community-driven instantiation of protein function prediction that utilizes the gene ontology (GO) hierarchy. The GO hierarchy consists of terms/concepts via which one can describe protein functions at varying resolution \\[ [13](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-13)\\]. The GO framework is split into three sub-ontologies: the Cellular Component (CC), the Molecular Function (MF) and the Biological Process (BP). Each subontology is organized as a directed acyclic graph (DAG) that encodes the relationships between the GO terms in a subontology. The True Path rule is used \\[ [13](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-13)\\] to associate proteins to GO terms. If a protein is annotated with a particular GO term _t_, it is also annotated with all the ancestor terms of _t_ in the DAG of the sub-ontology to which t belongs. If a protein is not annotated with a particular GO term t, it is then also not annotated with any of the descendants of t.\n\nGO annotation is a well-formulated instantiation of protein function prediction. It remains an open problem, though much progress has been made over the years, particularly due to deep models \\[ [14](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-14)\\]\u2013\\[ [17](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-17)\\]. However, PLMs have yet to be demon-strated useful for GO annotation prediction. DeepChoi \\[ [18](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-18)\\], a method presented in an article that remains in preprint, is the only occurrence of a PLM-based GO annotation method.\n\nCurrently, there is little to no understanding of how transformer-based approaches perform compared to the state- of-art for GO term prediction. This paper addresses this gap in the research literature. In particular, the paper makes two key contributions, one regarding methodology, and the other regarding rigorous training and testing data construction.\n\nThe paper debuts a novel method, GOProFormer, which leverages the Transformer \\[ [1](https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full#ref-1)\\] architecture in two ways. First, a sequence transformer, encodes protein sequences in a taskagnostic feature space. Second, a graph transformer model learns a representation of the various GO terms that respects the hierarchical re...",
      "url": "https://www.biorxiv.org/content/10.1101/2022.10.20.513033v1.full"
    },
    {
      "title": "Quantitative Biology > Biomolecules",
      "text": "[2512.05245] STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[q-bio](https://arxiv.org/list/q-bio/recent)&gt;arXiv:2512.05245\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Quantitative Biology \\> Biomolecules\n**arXiv:2512.05245**(q-bio)\n[Submitted on 4 Dec 2025]\n# Title:STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings\nAuthors:[Mehmet Efe Ak\u00e7a](https://arxiv.org/search/q-bio?searchtype=author&amp;query=Ak\u00e7a,+M+E),[G\u00f6k\u00e7e Uludo\u011fan](https://arxiv.org/search/q-bio?searchtype=author&amp;query=Uludo\u011fan,+G),[Arzucan \u00d6zg\u00fcr](https://arxiv.org/search/q-bio?searchtype=author&amp;query=\u00d6zg\u00fcr,+A),[\u0130nci M. Bayta\u015f](https://arxiv.org/search/q-bio?searchtype=author&amp;query=Bayta\u015f,+\u0130+M)\nView a PDF of the paper titled STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings, by Mehmet Efe Ak\\\\c{c}a and G\\\\&#34;&#34;ok\\\\c{c}e Uludo\\\\u{g}an and Arzucan \\\\&#34;&#34;Ozg\\\\&#34;&#34;ur and \\\\.Inci M. Bayta\\\\c{s}\n[View PDF](https://arxiv.org/pdf/2512.05245)[HTML (experimental)](https://arxiv.org/html/2512.05245v1)> > Abstract:\n> Accurate prediction of protein function is essential for elucidating molecular mechanisms and advancing biological and therapeutic discovery. Yet experimental annotation lags far behind the rapid growth of protein sequence data. Computational approaches address this gap by associating proteins with Gene Ontology (GO) terms, which encode functional knowledge through hierarchical relations and textual definitions. However, existing models often emphasize one modality over the other, limiting their ability to generalize, particularly to unseen or newly introduced GO terms that frequently arise as the ontology evolves, and making the previously trained models outdated. We present STAR-GO, a Transformer-based framework that jointly models the semantic and structural characteristics of GO terms to enhance zero-shot protein function prediction. STAR-GO integrates textual definitions with ontology graph structure to learn unified GO representations, which are processed in hierarchical order to propagate information from general to specific terms. These representations are then aligned with protein sequence embeddings to capture sequence-function relationships. STAR-GO achieves state-of-the-art performance and superior zero-shot generalization, demonstrating the utility of integrating semantics and structure for robust and adaptable protein function prediction. Code is available at [> this https URL\n](https://github.com/boun-tabi-lifelu/stargo)> . Comments:|14 pages, 2 figures, 6 tables|\nSubjects:|Biomolecules (q-bio.BM); Machine Learning (cs.LG)|\nCite as:|[arXiv:2512.05245](https://arxiv.org/abs/2512.05245)[q-bio.BM]|\n|(or[arXiv:2512.05245v1](https://arxiv.org/abs/2512.05245v1)[q-bio.BM]for this version)|\n|[https://doi.org/10.48550/arXiv.2512.05245](https://doi.org/10.48550/arXiv.2512.05245)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: G\u00f6k\u00e7e Uludo\u011fan [[view email](https://arxiv.org/show-email/d1c110fa/2512.05245)]\n**[v1]**Thu, 4 Dec 2025 20:48:08 UTC (215 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings, by Mehmet Efe Ak\\\\c{c}a and G\\\\&#34;&#34;ok\\\\c{c}e Uludo\\\\u{g}an and Arzucan \\\\&#34;&#34;Ozg\\\\&#34;&#34;ur and \\\\.Inci M. Bayta\\\\c{s}\n* [View PDF](https://arxiv.org/pdf/2512.05245)\n* [HTML (experimental)](https://arxiv.org/html/2512.05245v1)\n* [TeX Source](https://arxiv.org/src/2512.05245)\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\nCurrent browse context:\nq-bio.BM\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2512.05245&amp;function=prev&amp;context=q-bio.BM) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2512.05245&amp;function=next&amp;context=q-bio.BM)\n[new](https://arxiv.org/list/q-bio.BM/new)|[recent](https://arxiv.org/list/q-bio.BM/recent)|[2025-12](https://arxiv.org/list/q-bio.BM/2025-12)\nChange to browse by:\n[cs](https://arxiv.org/abs/2512.05245?context=cs)\n[cs.LG](https://arxiv.org/abs/2512.05245?context=cs.LG)\n[q-bio](https://arxiv.org/abs/2512.05245?context=q-bio)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2512.05245)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2512.05245)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2512.05245)\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](<http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/2512.05245&amp;description=STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings>)[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](<https://reddit.com/submit?url=https://arxiv.org/abs/2512.05245&amp;title=STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings>)\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender ...",
      "url": "https://arxiv.org/abs/2512.05245"
    },
    {
      "title": "",
      "text": "<div><div>\n \n \n \n \n \n \n <p><a href=\"/pdf/1705.05919\">Download PDF</a></p><blockquote>\n Abstract: A large number of protein sequences are becoming available through the\napplication of novel high-throughput sequencing technologies. Experimental\nfunctional characterization of these proteins is time-consuming and expensive,\nand is often only done rigorously for few selected model organisms.\nComputational function prediction approaches have been suggested to fill this\ngap. The functions of proteins are classified using the Gene Ontology (GO),\nwhich contains over 40,000 classes. Additionally, proteins have multiple\nfunctions, making function prediction a large-scale, multi-class, multi-label\nproblem.\n<br />We have developed a novel method to predict protein function from sequence.\nWe use deep learning to learn features from protein sequences as well as a\ncross-species protein-protein interaction network. Our approach specifically\noutputs information in the structure of the GO and utilizes the dependencies\nbetween GO classes as background information to construct a deep learning\nmodel. We evaluate our method using the standards established by the\nComputational Assessment of Function Annotation (CAFA) and demonstrate a\nsignificant improvement over baseline methods such as BLAST, with significant\nimprovement for predicting cellular locations.\n </blockquote>\n \n \n </div><div>\n <h2>Submission history</h2><p> From: Maxat Kulmanov [<a href=\"/show-email/4bca0e17/1705.05919\">view email</a>]\n <br /><strong>[v1]</strong>\nMon, 15 May 2017 06:04:08 UTC (149 KB)<br /></p></div>||||I|||| Skip to main content\n We gratefully acknowledge support from\n the Simons Foundation and member institutions.\n > q-bio > arXiv:1705.05919\n\n Help | Advanced Search\n\n All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\n Search\n GO\n\n quick links\n\n * Login\n * Help Pages\n * About\n\n Quantitative Biology > Genomics\n\n arXiv:1705.05919 (q-bio)\n [Submitted on 15 May 2017]\n\n Title: DeepGO: Predicting protein functions from sequence and interactions using a deep ontology-aware classifier\n\n Authors: Maxat Kulmanov, Mohammed Asif Khan, Robert Hoehndorf\n Download PDF\n Abstract: A large number of protein sequences are becoming available through the application of novel high-throughput sequencing technologies. Experimental functional characterization of these proteins is time-consuming and expensive, and is often only done rigorously for few selected model organisms. Computational function prediction approaches have been suggested to fill this gap. The functions of proteins are classified using the Gene Ontology (GO), which contains over 40,000 classes. Additionally, proteins have multiple functions, making function prediction a large-scale, multi-class, multi-label problem.\n We have developed a novel method to predict protein function from sequence. We use deep learning to learn features from protein sequences as well as a cross-species protein-protein interaction network. Our approach specifically outputs information in the structure of the GO and utilizes the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and demonstrate a significant improvement over baseline methods such as BLAST, with significant improvement for predicting cellular locations.\n Subjects: Genomics (q-bio.GN) ; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)\n Cite as: arXiv:1705.05919 [q-bio.GN] \n (or arXiv:1705.05919v1 [q-bio.GN] for this version) \n https://doi.org/10.48550/arXiv.1705.05919 \n Focus to learn more \n arXiv-issued DOI via DataCite \n https://doi.org/10.1093/bioinformatics/btx624 \n Related DOI: Focus to learn more \n DOI(s) linking to related resources \n \n\n Submission history\n\n From: Maxat Kulmanov [view email]\n [v1] Mon, 15 May 2017 06:04:08 UTC (149 KB)\n Full-text links:\n\n Download:\n\n * PDF\n * Other formats\n (license)\n Current browse context:\n q-bio.GN\n < prev | next >\n new | recent | 1705\n Change to browse by:\n cs\n cs.LG\n q-bio\n q-bio.QM\n\n References & Citations\n\n * NASA ADS\n * Google Scholar\n * Semantic Scholar\n\n 1 blog link\n\n (what is this?)\n a export bibtex citation Loading...\n\n Bibtex formatted citation\n\n \u00d7\n loading...\n Data provided by:\n\n Bookmark\n\n Bibliographic Tools\n\n Bibliographic and Citation Tools\n\n Bibliographic Explorer Toggle\n Bibliographic Explorer (What is the Explorer?)\n Litmaps Toggle\n Litmaps (What is Litmaps?)\n scite.ai Toggle\n scite Smart Citations (What are Smart Citations?)\n Code, Data, Media\n\n Code, Data and Media Associated with this Article\n\n Links to Code Toggle\n Papers with Code (What is Papers with Code?)\n ScienceCast Toggle\n ScienceCast (What is ScienceCast?)\n Demos\n\n Demos\n\n Replicate Toggle\n Replicate (What is Replicate?)\n Spaces Toggle\n Hugging Face Spaces (What is Spaces?)\n Related Papers\n\n Recommenders and Search Tools\n\n Connected Papers Toggle\n Connected Papers (What is Connected Papers?)\n Core recommender toggle\n CORE Recommender (What is CORE?)\n About arXivLabs\n\n arXivLabs: experimental projects with community collaborators\n\n arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\n Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\n Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\n Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n * About\n * Help\n * Click here to contact arXiv Contact\n * Click here to subscribe Subscribe\n * Copyright\n * Privacy Policy\n * Web Accessibility Assistance\n\n * arXiv Operational Status\n Get status notifications via email or slack",
      "url": "https://arxiv.org/abs/1705.05919"
    },
    {
      "title": "An experimental analysis of graph representation learning for Gene Ontology based protein function prediction",
      "text": "## Introduction\n\nProtein function annotation is one of the most fundamental research topics in bioinformatics. Proteins are known as the building blocks of life, as they are responsible for a diverse range of activities in living organisms, such as catalyzing biochemical reactions, providing cellular structures, transporting nutrients, and regulating processes like gene expression and signal transduction. The identification of protein roles is not only crucial for biological systems, but can also enhance other aspects, such as drug discovery, disease therapies, agriculture or manufacturing. However, current manual protein annotation performed by experts is costly and time-consuming, which could not keep up with the huge number of new proteins generated from high-throughput sequencing techniques. Specifically, there are more than 249 million unreviewed proteins in the UniProtKB database ( [The UniProt Consortium, 2023](https://doi.org/10.1093%2Fnar%2Fgkac1052)), only around 570 thousand sequences are manually annotated until April 2024. Thus, the development of accurate and effective computational predictors for protein function prediction (PFP) is imperative to bridge this gap.\n\nThere are several standardized schemes describing protein functions, such as the Functional Catalogue (FunCat) ( [Ruepp et al., 2004](https://doi.org/10.1093%2Fnar%2Fgkh894)), Kyoto Encyclopedia of Genes and Genomes (KEGG) ( [Kanehisa et al., 2023](https://doi.org/10.1093%2Fnar%2Fgkac963)) and Gene Ontology (GO) ( [Ashburner et al., 2000](https://doi.org/10.1038%2F75556); [Consortium et al., 2023](https://doi.org/10.1093%2Fgenetics%2Fiyad031)). At present, the GO database is the most widely system used for protein functional annotation. The GO knowledgebase describes functions of genes and gene products in three domains: molecular function (MF), biological process (BP), cellular component (CC). GO terms (also known as GO classes) are organized in a hierarchical directed acyclic graph (DAG), where an edge denotes a specific parent-child relationship between two GO terms, such as _is a_, _part of_, _has part_, _regulates_. Thus, protein annotation is propagated by a principle called true path rule ( [Valentini, 2010](https://doi.org/10.1109%2FTCBB.2010.38)), in which if a protein is associated with a GO class, the protein is annotated with all of that GO term\u2019s parents.\n\nThe research community has witnessed several computational methods for annotating GO functions for proteins over the last few decades ( [Makrodimitris, Van Ham & Reinders, 2020](https://doi.org/10.3390%2Fgenes11111264); [Vu & Jung, 2021](https://doi.org/10.7717%2Fpeerj.12019)), ranging from conventional to machine learning based solutions. Homology based function annotation marked the early stages of automated protein function prediction. This approach assumes that proteins with similar sequences are likely to perform similar roles. In a typical workflow, a query protein sequence is compared against a database of annotated proteins. GO terms associated with the top sequence matches are scored and selected for transfer to the query protein. Various studies following this approach have utilized different sequence search tools, such as BLAST ( [Altschul et al., 1997](https://doi.org/10.1093%2Fnar%2F25.17.3389)), PSI-BLAST ( [Altschul et al., 1997](https://doi.org/10.1093%2Fnar%2F25.17.3389)), and DIAMOND ( [Buchfink, Xie & Huson, 2015](https://doi.org/10.1038%2Fnmeth.3176)), and have proposed multiple ways for scoring GO terms ( [Martin, Berriman & Barton, 2004](https://doi.org/10.1186%2F1471-2105-5-178); [Hawkins et al., 2009](https://doi.org/10.1002%2Fprot.22172); [Gong, Ning & Tian, 2016](https://doi.org/10.1016%2Fj.ymeth.2015.08.009)). Determining protein characteristics through sequence homology is straightforward, but it has drawbacks that can lead to inaccurate function transfer. For example, there are proteins with similar amino acid sequences that may perform different functions, while others with little sequence similarity might share the same biological roles ( [Sasson, Kaplan & Linial, 2006](https://doi.org/10.1110%2Fps.062185706)). Advances in machine learning have opened new avenues for computational PFP. In this context, protein function annotation is framed as a multi-label classification problem, as a single protein can exhibit more than one function. Studies employing machine learning models, such as logistic regression, support vector machines (SVM), and -nearest neighbors (-NN), often rely on extensive feature engineering from several sources to extract relevant protein features ( [Lobley et al., 2008](https://doi.org/10.1093%2Fnar%2Fgkn193)). Also, predictions are typically generated by component classifiers, which are then ensembled to ultimately assign GO terms to proteins ( [You et al., 2018](https://doi.org/10.1093%2Fbioinformatics%2Fbty130), [2019](https://doi.org/10.1093%2Fnar%2Fgkz388)). It is noteworthy that homology based function annotation is still extensively utilized, particularly as an important component in lately proposed methods ( [Zhang & Freddolino, 2024](https://doi.org/10.1093%2Fbib%2Fbbae349)).\n\nRecent studies have increasingly focused on deep learning based models that leverage vast amounts of biological data, computational resources, and sophisticated algorithms designed to automatically capture features from raw data ( [Bonetta & Valentino, 2020](https://doi.org/10.1002%2Fprot.25832); [Dhanuka, Singh & Tripathi, 2023](https://doi.org/10.1109%2FTCBB.2023.3247634); [Yan et al., 2023](https://doi.org/10.1016%2Fj.compbiomed.2022.106446)). In terms of input data, there have been two main approaches. On one hand, researchers focus on inferring associated functions using only protein sequences ( [Cao et al., 2017](https://doi.org/10.3390%2Fmolecules22101732); [Sureyya Rifaioglu et al., 2019](https://doi.org/10.1038%2Fs41598-019-43708-3); [Nauman et al., 2019](https://doi.org/10.1007%2Fs10723-018-9450-6); [Kulmanov & Hoehndorf, 2020](https://doi.org/10.1093%2Fbioinformatics%2Fbtz595); [Wu et al., 2023](https://doi.org/10.1093%2Fbib%2Fbbad311)), as this is the only information available for all proteins. On the other hand, integrating multiple biological information sources has become a prominent research direction, and this approach yields the best performance in the latest Critical Assessment of protein Function Annotation, CAFA5 ( [Zhou et al., 2019b](https://doi.org/10.1186%2Fs13059-019-1835-8); [Friedberg et al., 2023](https://kaggle.com/competitions/cafa-5-protein-function-prediction)). In addition to learning protein sequence representations ( [Cui, Zhang & Zou, 2021](https://doi.org/10.1093%2Fbfgp%2Felaa030)) using large protein language models ( [Elnaggar et al., 2022](https://doi.org/10.1109%2FTPAMI.2021.3095381)), deep graph learning models have recently gained popularity for capturing complex relationships within diverse biological networks, including protein-protein interaction (PPI) network, protein structures, the GO tree, and protein annotations, thereby enhancing the inference of protein characteristics ( [You et al., 2021](https://doi.org/10.1093%2Fbioinformatics%2Fbtab270); [Lai & Xu, 2022](https://doi.org/10.1093%2Fbib%2Fbbab502)).\n\nIt is necessary to conduct a systematic review of the advances in graph representation learning strategies for protein function prediction. Several surveys summarized a few years ago ( [Makrodimitris, Van Ham & Reinders, 2020](https://doi.org/10.3390%2Fgenes11111264); [Bonetta & Valentino, 2020](https://doi.org/10.1002%2Fprot.25832)) may not reflect the latest developments in the field. The most recent reviews we found are from [Dhanuka, Singh & Tripathi (2023)](https://doi.org/10.1109%2FTCBB.2023.3247634) and [Yan et al. (2023)](https://doi.org/10.1016%2Fj.compbiomed.2022.106446), but they primarily focus on protein sequence based methods and machine learning models, respectively. In this study, we review state-of-the-art appl...",
      "url": "https://peerj.com/articles/18509"
    }
  ]
}