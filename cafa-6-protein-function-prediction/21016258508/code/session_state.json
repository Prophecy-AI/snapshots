{
  "workspace_dir": "/home/code",
  "competition_id": "cafa-6-protein-function-prediction",
  "metric_direction": false,
  "start_time": "2026-01-15T01:30:19.249816",
  "time_limit_minutes": 2100,
  "experiments": [],
  "candidates": [],
  "submissions": [],
  "strategy_history": [],
  "feedback_history": [],
  "data_findings": [
    {
      "finding": "Key approach: Use protein language model embeddings (ProtBERT 1024-dim, T5 1024-dim, ESM2 1280-dim) as features, then train MLP classifier on top for GO term prediction",
      "source": "../research/kernels/nihilisticneuralnet_protbert-ensemble/protbert-ensemble.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Neural network architecture: 3-layer MLP with BatchNorm, ReLU, Dropout. Hidden dims like [864, 712]. Use BCELoss for multi-label classification with sigmoid output",
      "source": "../research/kernels/taylorsamarel_cafa-6-protein-function-starter-eda-model/cafa-6-protein-function-starter-eda-model.ipynb",
      "agent": "explorer"
    },
    {
      "finding": "Ensemble strategy: Combine deep learning predictions with BLAST-based predictions using weighted averaging. DL_WEIGHT and BLAST_WEIGHT parameters for tuning",
      "source": "../research/kernels/taylorsamarel_cafa-6-protein-function-starter-eda-model/cafa-6-protein-function-starter-eda-model.ipynb",
      "agent": "explorer"
    }
  ],
  "web_research": [],
  "max_submissions": 5,
  "remaining_submissions": 5
}