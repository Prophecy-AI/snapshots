{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90274,"databundleVersionId":10951356,"sourceType":"competition"},{"sourceId":9198133,"sourceType":"datasetVersion","datasetId":5560970}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-02-04T12:10:53.455319Z","iopub.execute_input":"2025-02-04T12:10:53.455609Z","iopub.status.idle":"2025-02-04T12:10:53.824276Z","shell.execute_reply.started":"2025-02-04T12:10:53.455585Z","shell.execute_reply":"2025-02-04T12:10:53.8234Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#ffffff; font-size: 1%;\">[1] üéí Introduction</span>\n\n<div style=\" border-bottom: 8px solid #8CBED6; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n  <div style=\"height: 100%; width: 65%; background-color: #87CEFA; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n    <b><span style=\"color: #5F5F5F; padding: 20px 20px;\">[1] üéíüì¶ Introduction</span></b>\n  </div>\n  <div style=\"height: 100%; width: 35%; background-image: url('https://img.freepik.com/premium-photo/school-bag-backpack-with-supplies-school-blue-background-copy-space-text_188237-985.jpg'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n  </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"position: relative; height: 200px; background-image: url('https://hips.hearstapps.com/hmg-prod/images/ellehandbags-1560442103.jpg?crop=0.985xw:0.987xh;0,0&resize=640:*'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;\"></div>","metadata":{}},{"cell_type":"markdown","source":"Welcome to my notebook for the Backpack Price Prediction Challenge from the 2025 Kaggle Playground Series! üèÜ This competition presents an exciting opportunity to explore tabular data, refine our feature engineering, and experiment with different machine learning models to predict backpack prices.\n\nIn this notebook, we will:\n\n1. Perform Exploratory Data Analysis (EDA) üìä ‚Äì Uncover insights, visualize distributions, and handle missing values.\n2. Build and Compare Machine Learning Models ü§ñ ‚Äì Train different regression models to predict backpack prices. \n3. Optimize Hyperparameters ‚öôÔ∏è ‚Äì Fine-tune models for better performance.\n4. Generate and Submit Predictions üì§ ‚Äì Submit our best-performing model‚Äôs predictions to Kaggle.","metadata":{}},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\"> [1.1] üóÇ Dataset Description</span></b>","metadata":{}},{"cell_type":"markdown","source":"The dataset used in this competition has been synthetically generated from a deep learning model trained on the Student Bag Price Prediction Dataset. It contains various attributes related to backpacks, which we will use to predict the Price.\n\nüìÅ Files Provided:\n\n1. train.csv üìÑ ‚Äì The training dataset, containing various backpack features along with their corresponding prices (our target variable).\n2. test.csv üìÑ ‚Äì The test dataset, where we need to predict the price based on given features.\n3. sample_submission.csv üìÑ ‚Äì A sample submission file in the correct format","metadata":{}},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\"> [1.2] üìè Evaluation Metric ‚Äì Root Mean Squared Error (RMSE)</span></b>","metadata":{}},{"cell_type":"markdown","source":"Submissions in this competition are evaluated based on Root Mean Squared Error (RMSE), which is calculated as:\n\n![image.png](attachment:4e2c4c16-1c49-48d0-b817-b3ed88744565.png)\n\nü§î Why RMSE?\n\n1. Penalizes Large Errors More üö®: Since RMSE squares the errors before averaging, it gives more weight to larger deviations.\n2. Provides a Clear Measure of Accuracy üìâ: A lower RMSE indicates that the model's predictions are closer to actual values.\n3. Maintains Interpretability üìñ: Since RMSE is in the same unit as the target variable (Price), it's easy to understand its impact.\n\nOur goal is to minimize RMSE by selecting the best features, handling missing values effectively, and experimenting with different regression models","metadata":{},"attachments":{"4e2c4c16-1c49-48d0-b817-b3ed88744565.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"# <span style=\"color:#ffffff; font-size: 1%;\">[2] üîç Dataset Overview</span>\n\n<div style=\" border-bottom: 8px solid #8CBED6; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n  <div style=\"height: 100%; width: 65%; background-color: #87CEFA; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n    <b><span style=\"color: #5F5F5F; padding: 20px 20px;\">[2] üìäüîç Dataset Overview</span></b>\n  </div>\n  <div style=\"height: 100%; width: 35%; background-image: url('https://img.freepik.com/premium-photo/school-bag-backpack-with-supplies-school-blue-background-copy-space-text_188237-985.jpg'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n  </div>\n</div>","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport optuna\nimport xgboost as xgb\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, accuracy_score, median_absolute_error\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom scipy import stats\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport catboost as cb\nfrom scipy.optimize import minimize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:10:53.82515Z","iopub.execute_input":"2025-02-04T12:10:53.825513Z","iopub.status.idle":"2025-02-04T12:11:01.115647Z","shell.execute_reply.started":"2025-02-04T12:10:53.825491Z","shell.execute_reply":"2025-02-04T12:11:01.114937Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [2.1] Loading the Datasets & Libraries :</span></b>","metadata":{}},{"cell_type":"code","source":"# Reading .csv data file\n\ntrain_data = pd.read_csv(\"/kaggle/input/playground-series-s5e2/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s5e2/test.csv\")\noriginal_data = pd.read_csv('/kaggle/input/student-bag-price-prediction-dataset/Noisy_Student_Bag_Price_Prediction_Dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:01.116556Z","iopub.execute_input":"2025-02-04T12:11:01.117287Z","iopub.status.idle":"2025-02-04T12:11:02.188969Z","shell.execute_reply.started":"2025-02-04T12:11:01.117255Z","shell.execute_reply":"2025-02-04T12:11:02.188211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [2.2] Initial Observations or Trends :</span></b>","metadata":{}},{"cell_type":"code","source":" # Having a look at the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.189623Z","iopub.execute_input":"2025-02-04T12:11:02.189864Z","iopub.status.idle":"2025-02-04T12:11:02.19376Z","shell.execute_reply.started":"2025-02-04T12:11:02.189844Z","shell.execute_reply":"2025-02-04T12:11:02.192585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.194725Z","iopub.execute_input":"2025-02-04T12:11:02.194956Z","iopub.status.idle":"2025-02-04T12:11:02.242938Z","shell.execute_reply.started":"2025-02-04T12:11:02.194936Z","shell.execute_reply":"2025-02-04T12:11:02.241948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.246415Z","iopub.execute_input":"2025-02-04T12:11:02.24686Z","iopub.status.idle":"2025-02-04T12:11:02.278801Z","shell.execute_reply.started":"2025-02-04T12:11:02.246821Z","shell.execute_reply":"2025-02-04T12:11:02.277769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.280623Z","iopub.execute_input":"2025-02-04T12:11:02.280951Z","iopub.status.idle":"2025-02-04T12:11:02.304591Z","shell.execute_reply.started":"2025-02-04T12:11:02.280928Z","shell.execute_reply":"2025-02-04T12:11:02.303602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking the number of rows and columns\n\nnum_train_rows, num_train_columns = train_data.shape\n\nnum_test_rows, num_test_columns = test_data.shape\n\nnum_original_rows, num_original_columns = original_data.shape\n\nprint(\"Training Data:\")\nprint(f\"Number of Rows: {num_train_rows}\")\nprint(f\"Number of Columns: {num_train_columns}\\n\")\n\nprint(\"Test Data:\")\nprint(f\"Number of Rows: {num_test_rows}\")\nprint(f\"Number of Columns: {num_test_columns}\\n\")\n\nprint(\"Original Data:\")\nprint(f\"Number of Rows: {num_original_rows}\")\nprint(f\"Number of Columns: {num_original_columns}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.305514Z","iopub.execute_input":"2025-02-04T12:11:02.305879Z","iopub.status.idle":"2025-02-04T12:11:02.324826Z","shell.execute_reply.started":"2025-02-04T12:11:02.305838Z","shell.execute_reply":"2025-02-04T12:11:02.3235Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a table for missing values, unique values and data types of the features\n\nmissing_values_train = pd.DataFrame({'Feature': train_data.columns,\n                              '[TRAIN] No. of Missing Values': train_data.isnull().sum().values,\n                              '[TRAIN] % of Missing Values': ((train_data.isnull().sum().values)/len(train_data)*100)})\n\nmissing_values_test = pd.DataFrame({'Feature': test_data.columns,\n                             '[TEST] No.of Missing Values': test_data.isnull().sum().values,\n                             '[TEST] % of Missing Values': ((test_data.isnull().sum().values)/len(test_data)*100)})\n\nmissing_values_original = pd.DataFrame({'Feature': original_data.columns,\n                             '[ORIGINAL] No.of Missing Values': original_data.isnull().sum().values,\n                             '[ORIGINAL] % of Missing Values': ((original_data.isnull().sum().values)/len(original_data)*100)})\n\nunique_values = pd.DataFrame({'Feature': train_data.columns,\n                              'No. of Unique Values[FROM TRAIN]': train_data.nunique().values})\n\nfeature_types = pd.DataFrame({'Feature': train_data.columns,\n                              'DataType': train_data.dtypes})\n\nmerged_df = pd.merge(missing_values_train, missing_values_test, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, missing_values_original, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, unique_values, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, feature_types, on='Feature', how='left')\n\nmerged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.325777Z","iopub.execute_input":"2025-02-04T12:11:02.326012Z","iopub.status.idle":"2025-02-04T12:11:02.878782Z","shell.execute_reply.started":"2025-02-04T12:11:02.325992Z","shell.execute_reply":"2025-02-04T12:11:02.877742Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count duplicate rows in train_data\ntrain_duplicates = train_data.duplicated().sum()\n\n# Count duplicate rows in test_data\ntest_duplicates = test_data.duplicated().sum()\n\n# Count duplicate rows in original_data\noriginal_duplicates = original_data.duplicated().sum()\n\n# Print the results\nprint(f\"Number of duplicate rows in train_data: {train_duplicates}\")\nprint(f\"Number of duplicate rows in test_data: {test_duplicates}\")\nprint(f\"Number of duplicate rows in original_data: {original_duplicates}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:02.879614Z","iopub.execute_input":"2025-02-04T12:11:02.879887Z","iopub.status.idle":"2025-02-04T12:11:03.256857Z","shell.execute_reply.started":"2025-02-04T12:11:02.879865Z","shell.execute_reply":"2025-02-04T12:11:03.255774Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Having a look at the description of all the numerical columns present in the dataset\n\ntrain_data.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:03.257988Z","iopub.execute_input":"2025-02-04T12:11:03.258368Z","iopub.status.idle":"2025-02-04T12:11:03.327942Z","shell.execute_reply.started":"2025-02-04T12:11:03.258332Z","shell.execute_reply":"2025-02-04T12:11:03.32711Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color: #FEF9E7; border-top: 4px solid #D4AC0D; padding: 40px; border-radius: 8px;font-size: 18px;\">\n  <h3 style=\"color: #D4AC0D; font-size: 24px; margin-bottom: 10px;\">üìä Dataset Observations</h3>\n  <br>\n\n  <h3 style=\"color: #D4AC0D; font-size: 20px; margin-bottom: 10px;\">üìå Dataset Shape</h3>\n  <ul>\n    <li><strong>Training Data:</strong> 300,000 rows √ó 11 columns</li>\n    <li><strong>Test Data:</strong> 200,000 rows √ó 10 columns</li>\n    <li><strong>Original Data:</strong> 52,500 rows √ó 10 columns</li>\n  </ul>\n  <br>\n\n  <h3 style=\"color: #D4AC0D; font-size: 20px; margin-bottom: 10px;\">üìâ Missing Values Analysis</h3>\n  <p>Several features contain missing values in both the training and test sets. Proper handling of these missing values is crucial for maintaining data integrity and improving model performance. Below are the key observations:</p>\n\n  <ul>\n    <li><strong>Color:</strong> ~3.32% missing in train, ~3.39% in test</li>\n    <li><strong>Brand:</strong> ~3.24% missing in train, ~3.11% in test</li>\n    <li><strong>Material:</strong> ~2.78% missing in train, ~2.81% in test</li>\n    <li><strong>Size:</strong> ~2.20% missing in train, ~2.19% in test</li>\n    <li><strong>Style:</strong> ~2.66% missing in train, ~2.58% in test</li>\n    <li><strong>Laptop Compartment:</strong> ~2.48% missing in train, ~2.48% in test</li>\n    <li><strong>Waterproof:</strong> ~2.35% missing in train, ~2.41% in test</li>\n    <li><strong>Weight Capacity (kg):</strong> ~0.05% missing in train, ~0.04% in test</li>\n  </ul>\n\n  <p>Some features such as <strong>Compartments</strong> and <strong>Price</strong> have no missing values in the training set, while others like <strong>Original Data</strong> show variations in missing data proportions.</p>\n\n  <p>Strategies such as imputation (mean, median, mode) or predictive modeling can be applied to handle these missing values appropriately.</p>\n  <br>\n\n\n  <h3 style=\"color: #D4AC0D; font-size: 20px; margin-bottom: 10px;\">üßê Key Observations on Data</h3>\n  <ul>\n    <li><strong>ID:</strong> A unique identifier for each backpack.</li>\n    <li><strong>Brand, Material, Size, Style:</strong> Categorical variables that require encoding for machine learning models.</li>\n    <li><strong>Compartments:</strong> Numeric, ranges from 1 to 10.</li>\n    <li><strong>Laptop Compartment & Waterproof:</strong> Binary categorical features (Yes/No).</li>\n    <li><strong>Color:</strong> 6 unique values, with missing data.</li>\n    <li><strong>Weight Capacity (kg):</strong> A numerical feature with a wide range, possibly requiring scaling.</li>\n    <li><strong>Price:</strong> The target variable in the training set, ranging from 15 to 150.</li>\n  </ul>\n  <br>\n\n  <h3 style=\"color: #D4AC0D; font-size: 20px; margin-bottom: 10px;\">üìä Summary Statistics</h3>\n  <ul>\n    <li><strong>Compartments:</strong> Mean: ~5.44, Min: 1, Max: 10.</li>\n    <li><strong>Weight Capacity (kg):</strong> Mean: ~18.03, Min: 5, Max: 30.</li>\n    <li><strong>Price:</strong> Mean: ~81.41, Min: 15, Max: 150.</li>\n  </ul>\n  <br>\n\n  <h3 style=\"color: #D4AC0D; font-size: 20px; margin-bottom: 10px;\">üîç Key Takeaways</h3>\n  <ul>\n    <li>The dataset includes categorical and numerical features, requiring different preprocessing steps.</li>\n    <li>Handling missing values in categorical variables will be a priority.</li>\n    <li>Weight Capacity and Price have relatively wide distributions, suggesting possible feature scaling or transformation.</li>\n    <li>Feature engineering on categorical variables (like Brand and Material) may improve model performance.</li>\n  </ul>\n  <br>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#ffffff; font-size: 1%;\">[3] üí° Exploratory Data Analysis (EDA)</span>\n\n<div style=\" border-bottom: 8px solid #8CBED6; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n  <div style=\"height: 100%; width: 65%; background-color: #87CEFA; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n    <b><span style=\"color: #5F5F5F; padding: 20px 20px;\">[3] üìàüí°EDA</span></b>\n  </div>\n  <div style=\"height: 100%; width: 35%; background-image: url('https://img.freepik.com/premium-photo/school-bag-backpack-with-supplies-school-blue-background-copy-space-text_188237-985.jpg'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n  </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis (**EDA**) is like detective work for data! üïµÔ∏è‚Äç‚ôÇÔ∏è It helps us understand patterns, detect anomalies, and uncover relationships before diving into modeling. Through EDA, we can **visualize**, **clean**, and **transform** the dataset in meaningful ways.\n\n### üèóÔ∏è What We'll Do in Our EDA:\n\n1Ô∏è‚É£ **Numerical Feature Analysis** üìä  \n   - We'll use **boxplots** to check for outliers and distribution shape.  \n   - **Histograms** will help us visualize how the numerical data is spread.\n\n2Ô∏è‚É£ **Categorical Feature Analysis** üî†  \n   - **Countplots** will show the frequency of each category.  \n   - **Pie charts** will help us understand the proportion of different categories.\n\n3Ô∏è‚É£ **Target Variable Analysis** üéØ  \n   - Since the **target variable is continuous**, we'll use **histograms** to see its distribution.  \n   - **Boxplots** will help detect any extreme values or patterns.\n\n---","metadata":{}},{"cell_type":"markdown","source":"> **üìù NOTE:** Some features that appear as **numerical** in the dataset are actually more **categorical in nature** (since they have very few unique values). We‚Äôll treat them accordingly to ensure meaningful insights!","metadata":{}},{"cell_type":"code","source":"numerical_variables = ['Weight Capacity (kg)']\ntarget_variable = 'Price' \ncategorical_variables = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment','Waterproof', 'Style', 'Color']","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:03.328848Z","iopub.execute_input":"2025-02-04T12:11:03.32919Z","iopub.status.idle":"2025-02-04T12:11:03.333323Z","shell.execute_reply.started":"2025-02-04T12:11:03.329157Z","shell.execute_reply":"2025-02-04T12:11:03.332565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [3.1] Numerical Feature Analysis</span></b>","metadata":{}},{"cell_type":"code","source":"# Analysis of all NUMERICAL features\n\n# Define a custom color palette\ncustom_palette = ['#3498db', '#e74c3c','#2ecc71']\n\n# Add 'Dataset' column to distinguish between train and test data\ntrain_data['Dataset'] = 'Train'\ntest_data['Dataset'] = 'Test'\noriginal_data['Dataset'] = 'Original'\n\nvariables = [col for col in train_data.columns if col in numerical_variables]\n\n# Function to create and display a row of plots for a single variable\ndef create_variable_plots(variable):\n    sns.set_style('whitegrid')\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Box plot\n    plt.subplot(1, 2, 1)\n    sns.boxplot(data=pd.concat([train_data, test_data,original_data.dropna()]), x=variable, y=\"Dataset\", palette=custom_palette)\n    plt.xlabel(variable)\n    plt.title(f\"Box Plot for {variable}\")\n\n    # Separate Histograms\n    plt.subplot(1, 2, 2)\n    sns.histplot(data=train_data, x=variable, color=custom_palette[0], kde=True, bins=30, label=\"Train\")\n    sns.histplot(data=test_data, x=variable, color=custom_palette[1], kde=True, bins=30, label=\"Test\")\n    sns.histplot(data=original_data.dropna(), x=variable, color=custom_palette[2], kde=True, bins=30, label=\"Original\")\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"Histogram for {variable} [TRAIN, TEST & ORIGINAL]\")\n    plt.legend()\n\n    # Adjust spacing between subplots\n    plt.tight_layout()\n\n    # Show the plots\n    plt.show()\n\n# Perform univariate analysis for each variable\nfor variable in variables:\n    create_variable_plots(variable)\n\n# Drop the 'Dataset' column after analysis\ntrain_data.drop('Dataset', axis=1, inplace=True)\ntest_data.drop('Dataset', axis=1, inplace=True)\noriginal_data.drop('Dataset', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:03.334156Z","iopub.execute_input":"2025-02-04T12:11:03.334377Z","iopub.status.idle":"2025-02-04T12:11:06.331809Z","shell.execute_reply.started":"2025-02-04T12:11:03.334358Z","shell.execute_reply":"2025-02-04T12:11:06.331002Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [3.2] Categorical Feature Analysis</span></b>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\npie_chart_palette = ['#33638d', '#28ae80', '#d3eb0c', '#ff9a0b', '#7e03a8', '#35b779', '#fde725', '#440154', '#90d743', '#482173', '#22a884', '#f8961e']\n\ncountplot_color = '#5C67A3'\n\n# Function to create and display a row of plots for a single categorical variable\ndef create_categorical_plots(variable):\n    sns.set_style('whitegrid')\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Pie Chart\n    plt.subplot(1, 2, 1)\n    train_data[variable].value_counts().plot.pie(\n        autopct='%1.1f%%', colors=pie_chart_palette, wedgeprops=dict(width=0.3), startangle=140\n    )\n    plt.title(f\"Pie Chart for {variable}\")\n\n    # Bar Graph\n    plt.subplot(1, 2, 2)\n    sns.countplot(\n        data=pd.concat([train_data, test_data, original_data.dropna()]), \n        x=variable, \n        color=countplot_color,  # Using a single color for the countplot\n        alpha=0.8  # Setting 80% opacity\n    )\n    plt.xlabel(variable)\n    plt.ylabel(\"Count\")\n    plt.title(f\"Bar Graph for {variable} [TRAIN, TEST & ORIGINAL Combined]\")\n\n    # Adjust spacing between subplots\n    plt.tight_layout()\n    \n    # Show the plots\n    plt.show()\n\n# Perform univariate analysis for each categorical variable\nfor variable in categorical_variables:\n    create_categorical_plots(variable)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:06.332659Z","iopub.execute_input":"2025-02-04T12:11:06.332956Z","iopub.status.idle":"2025-02-04T12:11:12.494529Z","shell.execute_reply.started":"2025-02-04T12:11:06.332932Z","shell.execute_reply":"2025-02-04T12:11:12.49375Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [3.3] Target Feature Analysis</span></b>","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"# Analysis of the TARGET feature (Continuous)\n\n# Define a custom color palette\ntarget_palette = ['#3498db', '#e74c3c']\n\n# Add 'Dataset' column to distinguish between Train and Original data\ntrain_data['Dataset'] = 'Train'\noriginal_data['Dataset'] = 'Original'\n\n# Function to create and display a row of plots for the target variable\ndef create_target_plots(target_variable):\n    sns.set_style('whitegrid')\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Box Plot\n    plt.subplot(1, 2, 1)\n    sns.boxplot(data=pd.concat([train_data, original_data.dropna()]), x=target_variable, y=\"Dataset\", palette=target_palette)\n    plt.xlabel(target_variable)\n    plt.title(f\"Box Plot for Target Feature '{target_variable}'\")\n\n    # Histogram\n    plt.subplot(1, 2, 2)\n    sns.histplot(data=train_data, x=target_variable, color=target_palette[0], kde=True, bins=30, label=\"Train\")\n    sns.histplot(data=original_data.dropna(), x=target_variable, color=target_palette[1], kde=True, bins=30, label=\"Original\")\n    plt.xlabel(target_variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\"Histogram for Target Feature '{target_variable}' [TRAIN & ORIGINAL]\")\n    plt.legend()\n\n    # Adjust spacing between subplots\n    plt.tight_layout()\n\n    # Show the plots\n    plt.show()\n\n# Perform univariate analysis for the target variable\ncreate_target_plots(target_variable)\n\n# Drop the 'Dataset' column after analysis\ntrain_data.drop('Dataset', axis=1, inplace=True)\noriginal_data.drop('Dataset', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:12.495625Z","iopub.execute_input":"2025-02-04T12:11:12.495897Z","iopub.status.idle":"2025-02-04T12:11:14.576356Z","shell.execute_reply.started":"2025-02-04T12:11:12.495874Z","shell.execute_reply":"2025-02-04T12:11:14.575465Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [3.4] Bivariate Analysis</span></b>","metadata":{"execution":{"iopub.status.busy":"2025-02-01T00:44:24.036573Z","iopub.execute_input":"2025-02-01T00:44:24.036945Z","iopub.status.idle":"2025-02-01T00:44:24.043574Z","shell.execute_reply.started":"2025-02-01T00:44:24.036917Z","shell.execute_reply":"2025-02-01T00:44:24.042142Z"}}},{"cell_type":"code","source":"variables = [col for col in train_data.columns if col in numerical_variables]\n\ncat_variables_train = ['Compartments','Weight Capacity (kg)', 'Price']\ncat_variables_test = ['Compartments','Weight Capacity (kg)']\n\n# Adding variables to the existing list\ntrain_variables = variables + cat_variables_train\ntest_variables = variables + cat_variables_test\n\n# Calculate correlation matrices for train_data and test_data\ncorr_train = train_data[train_variables].corr()\ncorr_test = test_data[test_variables].corr()\n\n# Create masks for the upper triangle\nmask_train = np.triu(np.ones_like(corr_train, dtype=bool))\nmask_test = np.triu(np.ones_like(corr_test, dtype=bool))\n\n# Set the text size and rotation\nannot_kws = {\"size\": 8, \"rotation\": 45}\n\n# Generate heatmaps for train_data\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nax_train = sns.heatmap(corr_train, mask=mask_train, cmap='viridis', annot=True,\n                      square=True, linewidths=.5, xticklabels=1, yticklabels=1, annot_kws=annot_kws)\nplt.title('Correlation Heatmap - Train Data')\n\n# Generate heatmaps for test_data\nplt.subplot(1, 2, 2)\nax_test = sns.heatmap(corr_test, mask=mask_test, cmap='viridis', annot=True,\n                     square=True, linewidths=.5, xticklabels=1, yticklabels=1, annot_kws=annot_kws)\nplt.title('Correlation Heatmap - Test Data')\n\n# Adjust layout\nplt.tight_layout()\n\n# Show the plots\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:14.577295Z","iopub.execute_input":"2025-02-04T12:11:14.577551Z","iopub.status.idle":"2025-02-04T12:11:15.256195Z","shell.execute_reply.started":"2025-02-04T12:11:14.57753Z","shell.execute_reply":"2025-02-04T12:11:15.255242Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#ffffff; font-size: 1%;\">[4] üõ†Ô∏è Data Preprocessing</span>\n\n<div style=\" border-bottom: 8px solid #8CBED6; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n  <div style=\"height: 100%; width: 65%; background-color: #87CEFA; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n    <b><span style=\"color: #5F5F5F; padding: 20px 20px;\">[4] üõ†Ô∏èüßπ Data Preprocessing</span></b>\n  </div>\n  <div style=\"height: 100%; width: 35%; background-image: url('https://img.freepik.com/premium-photo/school-bag-backpack-with-supplies-school-blue-background-copy-space-text_188237-985.jpg'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n  </div>\n</div>","metadata":{}},{"cell_type":"code","source":"# Drop null values from original_data\n#original_data = original_data.dropna()\n\n# Print the count of null values in original_data\n#print(original_data.isnull().sum())\n\n# Combine original_data with train_data\n#train_data = pd.concat([train_data, original_data], axis=0).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:15.25721Z","iopub.execute_input":"2025-02-04T12:11:15.257465Z","iopub.status.idle":"2025-02-04T12:11:15.261095Z","shell.execute_reply.started":"2025-02-04T12:11:15.257444Z","shell.execute_reply":"2025-02-04T12:11:15.260083Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.1] Data Imputation (Handling missing values)</span></b>","metadata":{}},{"cell_type":"markdown","source":"### Understanding Each Feature and Missing Data Handling\n\n#### 1Ô∏è‚É£ Brand (`~3.24%` missing in train, `~3.11%` in test)\n- **Unique Values:** Jansport, Under Armour, Nike, Adidas, Puma, NaN  \n- **Imputation Strategy:** Since it's categorical with only 5 unique brands, we can impute missing values with the **mode** (most frequent brand).\n\n#### 2Ô∏è‚É£ Material (`~2.78%` missing in train, `~2.81%` in test)\n- **Unique Values:** Leather, Canvas, Nylon, Polyester, NaN  \n- **Imputation Strategy:** **Mode imputation** works best here since materials are limited categories.\n\n#### 3Ô∏è‚É£ Size (`~2.20%` missing in train, `~2.19%` in test)\n- **Unique Values:** Medium, Small, Large, NaN  \n- **Imputation Strategy:** Since it's a well-defined categorical variable, we use **mode imputation**.\n\n#### 4Ô∏è‚É£ Compartments (‚úÖ No missing values)\n- **Unique Values:** 10 unique numerical values  \n- **Imputation Strategy:** ‚úÖ No action needed.\n\n#### 5Ô∏è‚É£ Laptop Compartment (`~2.48%` missing in train, `~2.48%` in test)\n- **Unique Values:** Yes, No, NaN  \n- **Imputation Strategy:** Since it's a **binary categorical** variable, we use **mode imputation**.\n\n#### 6Ô∏è‚É£ Waterproof (`~2.35%` missing in train, `~2.41%` in test)\n- **Unique Values:** Yes, No, NaN  \n- **Imputation Strategy:** **Mode imputation** is best.\n\n#### 7Ô∏è‚É£ Style (`~2.66%` missing in train, `~2.58%` in test)\n- **Unique Values:** Tote, Messenger, Backpack, NaN  \n- **Imputation Strategy:** **Mode imputation**.\n\n#### 8Ô∏è‚É£ Color (`~3.32%` missing in train, `~3.39%` in test)\n- **Unique Values:** Black, Green, Red, Blue, Gray, Pink, NaN  \n- **Imputation Strategy:** **Mode imputation**.\n\n#### 9Ô∏è‚É£ Weight Capacity (kg) (`~0.05%` missing in train, `~0.04%` in test)\n- **Unique Values:** Numeric  \n- **Imputation Strategy:** Since it is a **continuous numerical variable**, we use **median imputation** to prevent extreme values from affecting the distribution.","metadata":{}},{"cell_type":"code","source":"# Define imputation strategies\ncategorical_features = [\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"]\nnumerical_features = [\"Weight Capacity (kg)\", \"Price\"]\n\n# Fill categorical missing values with mode (most frequent value)\nfor col in categorical_features:\n    train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n    test_data[col].fillna(test_data[col].mode()[0], inplace=True)\n\n# Fill numerical missing values with median\nfor col in numerical_features:\n    train_data[col].fillna(train_data[col].median(), inplace=True)\n\ntest_data[\"Weight Capacity (kg)\"].fillna(test_data[\"Weight Capacity (kg)\"].median(), inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:15.262021Z","iopub.execute_input":"2025-02-04T12:11:15.262332Z","iopub.status.idle":"2025-02-04T12:11:15.707249Z","shell.execute_reply.started":"2025-02-04T12:11:15.262308Z","shell.execute_reply":"2025-02-04T12:11:15.706467Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.2] Feature Engineering </span></b>","metadata":{}},{"cell_type":"markdown","source":"Imagine you're making a **smoothie**. You have **raw ingredients** like bananas, strawberries, and milk. But instead of using them as they are, you **blend them together** to create a delicious, more useful drink. üéâ\n\nFeature extraction in Machine Learning works the same way! Instead of using raw data directly, we **combine, transform, or derive new features** to make the data **more meaningful and powerful** for prediction models.\n\n---\n\n### üî• Why Feature Extraction is Important?\n- Helps the model **understand relationships** better.\n- **Reduces noise** by focusing on important aspects.\n- Improves **prediction accuracy** by making data more useful.\n- Helps in **dimensionality reduction** (fewer, better features = better performance).","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\ndef perform_feature_engineering(df):\n    # Brand Material Interaction - Certain materials may be common for specific brands\n    df['Brand_Material'] = df['Brand'] + '_' + df['Material']\n\n    # Brand & Size Interaction - Some brands may produce only specific sizes\n    df['Brand_Size'] = df['Brand'] + '_' + df['Size']\n\n    # Has Laptop Compartment - Convert Yes/No to 1/0 for easier analysis\n    df['Has_Laptop_Compartment'] = df['Laptop Compartment'].map({'Yes': 1, 'No': 0})\n\n    # Is Waterproof - Convert Yes/No to 1/0 for easier analysis\n    df['Is_Waterproof'] = df['Waterproof'].map({'Yes': 1, 'No': 0})\n\n    # Compartments Binning - Group compartments into categories\n    df['Compartments_Category'] = pd.cut(df['Compartments'], bins=[0, 2, 5, 10, np.inf], labels=['Few', 'Moderate', 'Many', 'Very Many'])\n\n    # Weight Capacity Ratio - Normalize weight capacity using the max value\n    df['Weight_Capacity_Ratio'] = df['Weight Capacity (kg)'] / df['Weight Capacity (kg)'].max()\n\n    # Interaction Feature: Weight vs. Compartments - Some bags may hold more with less compartments\n    df['Weight_to_Compartments'] = df['Weight Capacity (kg)'] / (df['Compartments'] + 1)  # Avoid division by zero\n\n    # Style and Size Interaction - Certain styles may correlate with sizes\n    df['Style_Size'] = df['Style'] + '_' + df['Size']\n\n    return df\n\n# Apply the function to the training data\ntrain_data = perform_feature_engineering(train_data)\n\n# Apply the function to the test data\ntest_data = perform_feature_engineering(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:15.708045Z","iopub.execute_input":"2025-02-04T12:11:15.708277Z","iopub.status.idle":"2025-02-04T12:11:16.166386Z","shell.execute_reply.started":"2025-02-04T12:11:15.708256Z","shell.execute_reply":"2025-02-04T12:11:16.165403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id_test = test_data['id']\n\ncolumns_to_drop = ['id']\ntrain_data.drop(columns_to_drop, axis=1, inplace=True)\ntest_data.drop(columns_to_drop, axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:16.170405Z","iopub.execute_input":"2025-02-04T12:11:16.170664Z","iopub.status.idle":"2025-02-04T12:11:16.261203Z","shell.execute_reply.started":"2025-02-04T12:11:16.170642Z","shell.execute_reply":"2025-02-04T12:11:16.260237Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.3] Outlier Detection </span></b>","metadata":{}},{"cell_type":"markdown","source":"Imagine you‚Äôre a teacher grading a math test. Most students score between **60 and 90**, but **one student scores 5 and another scores 100**. These are **outliers**‚Äîextreme values that don‚Äôt follow the usual trend. üìä\n\nOutlier detection helps us **identify and handle** these unusual values so that they don‚Äôt mislead our models.\n\n---\n\n### üî• Why is Outlier Detection Important?\n- **Prevents models from being biased** by extreme values.\n- **Improves accuracy** by focusing on realistic data.\n- **Avoids overfitting**, where the model learns from noise instead of real patterns.\n- **Helps in feature scaling**, ensuring values are within a reasonable range.\n\n---\n\n### üìâ Outlier Detection in Action! (Using IQR)\n\nOne of the most **common methods** for detecting outliers is the **Interquartile Range (IQR) method**.  \nHere‚Äôs how it works:\n\n1. **Find Q1 (10th percentile) and Q3 (90th percentile)** ‚Üí These define the middle range of the data.\n2. **Calculate the Interquartile Range (IQR)**:  \n   IQR = Q3 - Q1\n3. **Define Lower and Upper Boundaries**:  \n   Lower Bound = Q1 - 1.5 * IQR\n   Upper Bound = Q3 + 1.5 * IQR\n5. **Anything outside these bounds is considered an outlier!** üö®","metadata":{}},{"cell_type":"code","source":"columns_to_check = ['Weight Capacity (kg)','Weight_Capacity_Ratio','Weight_to_Compartments']\n\n# Function to remove outliers using IQR and visualize\ndef remove_outliers_iqr_with_plot(data, column):\n    Q1 = data[column].quantile(0.05)\n    Q3 = data[column].quantile(0.95)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    # Filter the data\n    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n    \n    # Calculate the number of rows deleted\n    rows_deleted = len(data) - len(filtered_data)\n    \n    # Plot the distribution with outliers\n    plt.figure(figsize=(8, 4))\n    sns.boxplot(x=data[column], color='lightblue', flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'red'})\n    \n    # Highlight Q1 and Q3\n    plt.axvline(Q1, color='green', linestyle='--', label='Q1 (10th Percentile)')\n    plt.axvline(Q3, color='blue', linestyle='--', label='Q3 (90th Percentile)')\n    \n    # Highlight lower and upper bounds\n    plt.axvline(lower_bound, color='red', linestyle='-', label='Lower Bound')\n    plt.axvline(upper_bound, color='red', linestyle='-', label='Upper Bound')\n\n    plt.title(f'Outlier Detection for {column}')\n    plt.legend()\n    plt.xlabel(column)\n    plt.show()\n    \n    return filtered_data, rows_deleted\n\n# Apply function to each numerical column and visualize\nrows_deleted_total = 0\n\nfor column in columns_to_check:\n    train_data, rows_deleted = remove_outliers_iqr_with_plot(train_data, column)\n    rows_deleted_total += rows_deleted\n    print(f\"Rows deleted for {column}: {rows_deleted}\")\n\nprint(f\"Total rows deleted: {rows_deleted_total}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:16.262944Z","iopub.execute_input":"2025-02-04T12:11:16.26323Z","iopub.status.idle":"2025-02-04T12:11:17.497607Z","shell.execute_reply.started":"2025-02-04T12:11:16.263206Z","shell.execute_reply":"2025-02-04T12:11:17.496582Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = train_data['Price']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:17.498741Z","iopub.execute_input":"2025-02-04T12:11:17.499135Z","iopub.status.idle":"2025-02-04T12:11:17.50342Z","shell.execute_reply.started":"2025-02-04T12:11:17.499085Z","shell.execute_reply":"2025-02-04T12:11:17.502509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.4] Transformation of Distributions </span></b>","metadata":{}},{"cell_type":"markdown","source":"Sometimes, numerical features in a dataset are **highly skewed**, meaning their distribution is **not symmetrical**.  \nA skewed distribution can **negatively impact** machine learning models, especially those that assume normality (like linear regression).\n\n---\n\n### üî• Why Do We Transform Skewed Data?\n- **Improves model performance** by making data closer to a normal distribution.\n- **Reduces the impact of extreme values** (outliers).\n- **Enhances interpretability** of data for statistical analysis.","metadata":{}},{"cell_type":"code","source":"# [FOR TRAIN]\n# Identify features with skewness greater than 0.75\nskewed_features = train_data[numerical_variables].skew()[train_data[numerical_variables].skew() > 0.75].index.values\n\n# Print the list of variables to be transformed\nprint(\"Features to be transformed (skewness > 0.75):\")\ndisplay(skewed_features)\n\n# Plot skewed features before transformation\nfor feature in skewed_features:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(train_data[feature], bins=50, kde=True, color='blue')\n    plt.title(f'Distribution of {feature} before log transformation')\n    plt.show()\n\n# Apply log1p transformation to skewed features\ntrain_data[skewed_features] = np.log1p(train_data[skewed_features])\n\n# Plot skewed features after transformation\nfor feature in skewed_features:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(train_data[feature], bins=50, kde=True, color='green')\n    plt.title(f'Distribution of {feature} after log transformation')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:17.504335Z","iopub.execute_input":"2025-02-04T12:11:17.504662Z","iopub.status.idle":"2025-02-04T12:11:17.5327Z","shell.execute_reply.started":"2025-02-04T12:11:17.504639Z","shell.execute_reply":"2025-02-04T12:11:17.531896Z"},"jupyter":{"source_hidden":true},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# [FOR TEST]\n# Identify features with skewness greater than 0.75\nskewed_features = test_data[numerical_variables].skew()[test_data[numerical_variables].skew() > 0.75].index.values\n\n# Print the list of variables to be transformed\nprint(\"Features to be transformed (skewness > 0.75):\")\ndisplay(skewed_features)\n\n# Plot skewed features before transformation\nfor feature in skewed_features:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(test_data[feature], bins=50, kde=True, color='blue')\n    plt.title(f'Distribution of {feature} before log transformation')\n    plt.show()\n\n# Apply log1p transformation to skewed features\ntest_data[skewed_features] = np.log1p(test_data[skewed_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:17.533759Z","iopub.execute_input":"2025-02-04T12:11:17.534103Z","iopub.status.idle":"2025-02-04T12:11:17.550171Z","shell.execute_reply.started":"2025-02-04T12:11:17.534071Z","shell.execute_reply":"2025-02-04T12:11:17.549329Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot skewed features after transformation\nfor feature in skewed_features:\n    plt.figure(figsize=(8, 4))\n    sns.histplot(test_data[feature], bins=50, kde=True, color='green')\n    plt.title(f'Distribution of {feature} after log transformation')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:17.551085Z","iopub.execute_input":"2025-02-04T12:11:17.551415Z","iopub.status.idle":"2025-02-04T12:11:17.555446Z","shell.execute_reply.started":"2025-02-04T12:11:17.551375Z","shell.execute_reply":"2025-02-04T12:11:17.554556Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.4] Feature Encoding </span></b>","metadata":{}},{"cell_type":"markdown","source":"Imagine you're teaching a **robot** about colors. It doesn‚Äôt understand words like **\"Red\" or \"Blue\"**, but it understands **numbers**! ü§ñ  \nFeature encoding helps us **convert categorical data** into a format that machine learning models can understand. üöÄ\n\n---\n\n### üî• Why Feature Encoding?\n- ML models **work with numbers, not text**.\n- Helps in **handling categorical data efficiently**.\n- Reduces complexity and improves **model performance**.","metadata":{}},{"cell_type":"code","source":"# Selecting specific columns for encoding\ncolumns_to_encode = ['Brand', 'Material', 'Size', 'Laptop Compartment','Waterproof', 'Style', 'Color','Brand_Material', 'Brand_Size', 'Has_Laptop_Compartment','Is_Waterproof', 'Compartments_Category', 'Style_Size']\ntrain_data_to_encode = train_data[columns_to_encode]\ntest_data_to_encode = test_data[columns_to_encode]\n\n# Dropping selected columns for scaling\ntrain_data_to_scale = train_data.drop(columns_to_encode, axis=1)\ntest_data_to_scale = test_data.drop(columns_to_encode, axis=1)\n\ntrain_data_encoded = pd.get_dummies(train_data_to_encode, columns=columns_to_encode, drop_first=True)\ntest_data_encoded = pd.get_dummies(test_data_to_encode, columns=columns_to_encode, drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:17.556214Z","iopub.execute_input":"2025-02-04T12:11:17.556451Z","iopub.status.idle":"2025-02-04T12:11:18.104135Z","shell.execute_reply.started":"2025-02-04T12:11:17.55643Z","shell.execute_reply":"2025-02-04T12:11:18.103091Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.105122Z","iopub.execute_input":"2025-02-04T12:11:18.105386Z","iopub.status.idle":"2025-02-04T12:11:18.128639Z","shell.execute_reply.started":"2025-02-04T12:11:18.105357Z","shell.execute_reply":"2025-02-04T12:11:18.127657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data_encoded.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.12963Z","iopub.execute_input":"2025-02-04T12:11:18.129999Z","iopub.status.idle":"2025-02-04T12:11:18.161271Z","shell.execute_reply.started":"2025-02-04T12:11:18.129974Z","shell.execute_reply":"2025-02-04T12:11:18.160378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\">  [4.5] Feature Scaling </span></b>","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"Imagine you're comparing the **height of buildings** and the **weight of apples**. One is in **meters**, the other in **grams**‚Äîthey have completely different scales! üìèüçè  \nFeature scaling helps us **standardize numerical data** so that all features have a similar range, preventing models from favoring one over another.\n\n---\n\n### üî• Why Feature Scaling?\n- **Prevents bias** toward larger values (e.g., `Weight Capacity (kg)` vs `Price`).\n- **Improves model convergence** (especially for gradient-based algorithms like Neural Networks & Logistic Regression).\n- **Enhances performance** of distance-based models (like KNN, SVM).","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Initialize MinMaxScaler\nminmax_scaler = MinMaxScaler()\n\n# Fit the scaler on the training data\nminmax_scaler.fit(train_data_to_scale.drop(['Price'], axis=1))\n\n# Scale the training data\nscaled_data_train = minmax_scaler.transform(train_data_to_scale.drop(['Price'], axis=1))\nscaled_train_df = pd.DataFrame(scaled_data_train, columns=train_data_to_scale.drop(['Price'], axis=1).columns)\n\n# Scale the test data using the parameters from the training data\nscaled_data_test = minmax_scaler.transform(test_data_to_scale)\nscaled_test_df = pd.DataFrame(scaled_data_test, columns=test_data_to_scale.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.162244Z","iopub.execute_input":"2025-02-04T12:11:18.162582Z","iopub.status.idle":"2025-02-04T12:11:18.215345Z","shell.execute_reply.started":"2025-02-04T12:11:18.162556Z","shell.execute_reply":"2025-02-04T12:11:18.214487Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaled_train_df.head()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.21605Z","iopub.execute_input":"2025-02-04T12:11:18.216313Z","iopub.status.idle":"2025-02-04T12:11:18.226521Z","shell.execute_reply.started":"2025-02-04T12:11:18.216291Z","shell.execute_reply":"2025-02-04T12:11:18.225626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaled_test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.227515Z","iopub.execute_input":"2025-02-04T12:11:18.227871Z","iopub.status.idle":"2025-02-04T12:11:18.248493Z","shell.execute_reply.started":"2025-02-04T12:11:18.227838Z","shell.execute_reply":"2025-02-04T12:11:18.247551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Concatenate train datasets\ntrain_data_combined = pd.concat([train_data_encoded.reset_index(drop=True), scaled_train_df.reset_index(drop=True)], axis=1)\n\n# Concatenate test datasets\ntest_data_combined = pd.concat([test_data_encoded.reset_index(drop=True), scaled_test_df.reset_index(drop=True)], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.249503Z","iopub.execute_input":"2025-02-04T12:11:18.249834Z","iopub.status.idle":"2025-02-04T12:11:18.312555Z","shell.execute_reply.started":"2025-02-04T12:11:18.24981Z","shell.execute_reply":"2025-02-04T12:11:18.311774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data_combined.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.313327Z","iopub.execute_input":"2025-02-04T12:11:18.313625Z","iopub.status.idle":"2025-02-04T12:11:18.333484Z","shell.execute_reply.started":"2025-02-04T12:11:18.313601Z","shell.execute_reply":"2025-02-04T12:11:18.332492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data_combined.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.334458Z","iopub.execute_input":"2025-02-04T12:11:18.334812Z","iopub.status.idle":"2025-02-04T12:11:18.363808Z","shell.execute_reply.started":"2025-02-04T12:11:18.334778Z","shell.execute_reply":"2025-02-04T12:11:18.362717Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# <span style=\"color:#ffffff; font-size: 1%;\">[5] üèóÔ∏è Model Building & Evaluation</span>\n\n<div style=\" border-bottom: 8px solid #8CBED6; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n  <div style=\"height: 100%; width: 65%; background-color: #87CEFA; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n    <b><span style=\"color: #5F5F5F; padding: 20px 20px;\">[5] üèóÔ∏èüìä Model Building & Evaluation</span></b>\n  </div>\n  <div style=\"height: 100%; width: 35%; background-image: url('https://img.freepik.com/premium-photo/school-bag-backpack-with-supplies-school-blue-background-copy-space-text_188237-985.jpg'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n  </div>\n</div>","metadata":{}},{"cell_type":"code","source":"# Define Cross-Validation strategy\nkf = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# CatBoost parameters (optimized)\ncatboost_params = {\n    \"iterations\": 300,\n    \"learning_rate\": 0.1,\n    \"depth\": 6,\n    \"verbose\": 0,\n    \"random_seed\": 42\n}\n\n# Lists to store results\nrmse_scores = []\nmae_scores = []\noof_preds = np.zeros(len(train_data_combined))\ntest_preds_cb = np.zeros(len(test_data_combined))\n\n# Store feature importances\nfeature_importance_list = np.zeros(train_data_combined.shape[1])\n\n# Perform K-Fold Cross Validation\nprint(\"Training using Cross-Validation...\")\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_data_combined)):\n    print(f\"\\nTraining Fold {fold+1}...\")\n\n    X_train, X_val = train_data_combined.iloc[train_idx], train_data_combined.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    # Define model\n    cb_model = cb.CatBoostRegressor(**catboost_params)\n\n    # Train model\n    cb_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=0)\n\n    # Predict on validation set\n    val_preds_cb = cb_model.predict(X_val)\n    oof_preds[val_idx] = val_preds_cb\n\n    # Calculate and store scores\n    rmse = np.sqrt(mean_squared_error(y_val, val_preds_cb))\n    mae = mean_absolute_error(y_val, val_preds_cb)\n    rmse_scores.append(rmse)\n    mae_scores.append(mae)\n\n    print(f\"Fold {fold+1} RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n\n    # Accumulate feature importances\n    feature_importance_list += cb_model.get_feature_importance() / kf.get_n_splits()\n\n    # Predict on test data and average across folds\n    test_preds_cb += cb_model.predict(test_data_combined) / kf.get_n_splits()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:18.364847Z","iopub.execute_input":"2025-02-04T12:11:18.365238Z","iopub.status.idle":"2025-02-04T12:11:49.315088Z","shell.execute_reply.started":"2025-02-04T12:11:18.365203Z","shell.execute_reply":"2025-02-04T12:11:49.314261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final evaluation\ncv_rmse = np.mean(rmse_scores)\ncv_mae = np.mean(mae_scores)\n\nprint(\"\\nCross-Validation Results:\")\nprint(f\"Mean RMSE: {cv_rmse:.4f}\")\nprint(f\"Mean MAE: {cv_mae:.4f}\")\n\n# Plot RMSE per fold if needed\nif len(rmse_scores) > 1:\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(1, len(rmse_scores) + 1), rmse_scores, marker='o', linestyle='--', color='b', label='RMSE per Fold')\n    plt.axhline(y=cv_rmse, color='r', linestyle='-', label=f'Avg RMSE: {cv_rmse:.4f}')\n    plt.xlabel('Fold')\n    plt.ylabel('RMSE')\n    plt.title('RMSE per Fold')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:49.315922Z","iopub.execute_input":"2025-02-04T12:11:49.31614Z","iopub.status.idle":"2025-02-04T12:11:49.595991Z","shell.execute_reply.started":"2025-02-04T12:11:49.316121Z","shell.execute_reply":"2025-02-04T12:11:49.595038Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature importance visualization\nfeature_importance_df = pd.DataFrame({\n    'Feature': train_data_combined.columns,\n    'Importance': feature_importance_list\n}).sort_values(by='Importance', ascending=False)\n\nplt.figure(figsize=(12, 6))\nplt.barh(feature_importance_df['Feature'][:20], feature_importance_df['Importance'][:20], color='skyblue')\nplt.xlabel('Importance Score')\nplt.ylabel('Features')\nplt.title('Top 20 Feature Importances - CatBoost')\nplt.gca().invert_yaxis()  # Highest importance at the top\nplt.show()\n\n# Determine threshold for feature selection\nmedian_importance = np.median(feature_importance_list)\nthreshold = max(median_importance, 0.05 * np.max(feature_importance_list))  # Keep features > 5% of max importance\n\nselected_features = feature_importance_df[feature_importance_df['Importance'] >= threshold]['Feature'].tolist()\n\nprint(f\"Selected {len(selected_features)} features out of {train_data_combined.shape[1]} using threshold: {threshold:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:49.596996Z","iopub.execute_input":"2025-02-04T12:11:49.59735Z","iopub.status.idle":"2025-02-04T12:11:50.180498Z","shell.execute_reply.started":"2025-02-04T12:11:49.597313Z","shell.execute_reply":"2025-02-04T12:11:50.179506Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b><span style=\"color: #FFFFFF; background-color: #8CBED6; padding: 20px; font-size: 18px; border-left: 8px solid #87CEFA\"> [5.1] üîÄ Twist: When Simplicity Wins Over Complexity ü§° </span></b>\n\n","metadata":{}},{"cell_type":"markdown","source":"So after hours of hyperparameter tuning, diving deep into EDA, feature engineering, trying fancy transformations, gradient boosting and stacking models ‚Äì what do we get?\n\nNot even close to two ridiculously simple baselines. (Credits : [@cdeotte](https://www.kaggle.com/code/cdeotte/two-baseline-models-lb-38-91))\n\nüîπ Moral of the Story?\nüëâ Sometimes, less is more. Or in our case: less effort, better results. ü§°\n\nAnd so, in the spirit of humility and with a tear of acceptance, we set aside our sophisticated methods and do the only logical thing ‚Äì use Chris's baseline method (with a few small tweaks) and generate our final submission.","metadata":{}},{"cell_type":"code","source":"from cuml.preprocessing import TargetEncoder  # RAPIDS Target Encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:50.181392Z","iopub.execute_input":"2025-02-04T12:11:50.181644Z","iopub.status.idle":"2025-02-04T12:11:56.038862Z","shell.execute_reply.started":"2025-02-04T12:11:50.181623Z","shell.execute_reply":"2025-02-04T12:11:56.038092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### [5.1.1] Baseline 1 ‚Äì Global Mean Prediction","metadata":{}},{"cell_type":"code","source":"# Compute the mean price from training data\ntrain_mean_price = train_data['Price'].mean()\n\n# Apply to test data\ntest_data['Baseline1_Price'] = train_mean_price\n\nprint(f\"Baseline 1 - Mean Price Prediction: {train_mean_price:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:56.03977Z","iopub.execute_input":"2025-02-04T12:11:56.040356Z","iopub.status.idle":"2025-02-04T12:11:56.047621Z","shell.execute_reply.started":"2025-02-04T12:11:56.040328Z","shell.execute_reply":"2025-02-04T12:11:56.046849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### [5.1.2] Baseline 2 ‚Äì Target Encoding on \"Weight Capacity (kg)\"","metadata":{}},{"cell_type":"code","source":"# Initialize RAPIDS Target Encoder\nTE = TargetEncoder(n_folds=25, smooth=20, split_method='random', stat='mean')\n\n# Fit on training data\ntrain_data['Baseline2_Price'] = TE.fit_transform(train_data['Weight Capacity (kg)'], train_data['Price'])\n\n# Apply transformation to test data\ntest_data['Baseline2_Price'] = TE.transform(test_data['Weight Capacity (kg)'])\n\nprint(\"Target Encoding on Weight Capacity Applied.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:11:56.048511Z","iopub.execute_input":"2025-02-04T12:11:56.048869Z","iopub.status.idle":"2025-02-04T12:11:59.369391Z","shell.execute_reply.started":"2025-02-04T12:11:56.048845Z","shell.execute_reply":"2025-02-04T12:11:59.368491Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### [5.1.3] Enhancement ‚Äì Averaging of Both Baselines","metadata":{}},{"cell_type":"code","source":"# For CB from Optuna\nbest_params = {'iterations': 272, 'learning_rate': 0.07831991170767265, 'depth': 4, 'l2_leaf_reg': 6.24363158355284, 'border_count': 142, 'bagging_temperature': 0.17647659016389794, 'random_seed': 42, 'verbose': 0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:12:40.92827Z","iopub.execute_input":"2025-02-04T12:12:40.928582Z","iopub.status.idle":"2025-02-04T12:12:40.932921Z","shell.execute_reply.started":"2025-02-04T12:12:40.928559Z","shell.execute_reply":"2025-02-04T12:12:40.931812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# üõ†Ô∏è Load predictions from previous steps\ncatboost_preds = test_preds_cb  # From trained CatBoost model\nte_preds = test_data['Baseline2_Price'].values  # From Target Encoding on \"Weight Capacity (kg)\"\n\n# üõ†Ô∏è Optimize Alpha for Blending\ndef optimize_blend(alpha, cb_preds, te_preds, y_true):\n    \"\"\" Function to compute RMSE given an alpha blend ratio. \"\"\"\n    blended_preds = alpha * te_preds + (1 - alpha) * cb_preds\n    return np.sqrt(mean_squared_error(y_true, blended_preds))\n\n# üõ†Ô∏è Use training data for optimization\nX_train, X_val, y_train, y_val = train_test_split(train_data_combined[selected_features], y, test_size=0.2, random_state=42)\n\n# Predict on validation data\ncb_val_preds = np.mean([cb.CatBoostRegressor(**best_params).fit(X_train, y_train).predict(X_val) for _ in range(3)], axis=0)\nte_val_preds = TE.transform(X_val['Weight Capacity (kg)'])\n\n# Find the best blending weight using scipy minimize\nresult = minimize(lambda a: optimize_blend(a, cb_val_preds, te_val_preds, y_val), x0=[0.5], bounds=[(0, 1)])\nbest_alpha = result.x[0]\n\nprint(f\"Optimal Blending Weight (alpha) Found: {best_alpha:.4f}\")\n\n# üõ†Ô∏è Apply Optimal Blending on Test Data\ntest_data['Final_Price'] = best_alpha * te_preds + (1 - best_alpha) * catboost_preds\n\nprint(f\"Final Predictions Created using Optimal Blending (Alpha = {best_alpha:.4f}).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:12:41.63181Z","iopub.execute_input":"2025-02-04T12:12:41.632129Z","iopub.status.idle":"2025-02-04T12:12:54.094967Z","shell.execute_reply.started":"2025-02-04T12:12:41.632097Z","shell.execute_reply":"2025-02-04T12:12:54.094059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission file\nsubmission_df = pd.DataFrame({\n    'id': id_test,\n    'Price': test_data['Final_Price'].values\n})\n\n# Save to CSV\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\nsubmission_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:12:54.095998Z","iopub.execute_input":"2025-02-04T12:12:54.096313Z","iopub.status.idle":"2025-02-04T12:12:54.477142Z","shell.execute_reply.started":"2025-02-04T12:12:54.096289Z","shell.execute_reply":"2025-02-04T12:12:54.476224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üìùSubmission Notes\n\n| Test Score  | Notes                                           | Version |\n|--------|-----------------------------------------------|---------|\n| 39.27571  | XGBoost, LightGBM, CatBoost, RandomForest (Simple Average Ensemble) | v6     |\n| 39.18808 | XGBoost, LightGBM, CatBoost, RandomForest (Weighted Average Ensemble) | v11     |\n| 39.18955 | XGBoost, LightGBM, CatBoost, RandomForest (Weighted Average Ensemble  with Feature Importance) | v12     |\n| 39.18618  | XGBoost, LightGBM, CatBoost, RandomForest (Weighted Average Ensemble  with Feature Importance) | v13     |\n| 39.15355  | ONLY CatBoost | v14     |\n| 39.14376  | ONLY CatBoost w 10 fold CV | v18     |\n| 39.14428 | ONLY CatBoost w 8 fold CV and Feature Selection | v20     |\n| 39.14335 | ONLY CatBoost w 8 fold CV, Feature Selection and Outlier Removal (10%) | v21     |\n| 39.14211 | ONLY CatBoost w 8 fold CV, Feature Selection (5% of highest)and Outlier Removal (10%) | v22     |\n| 39.10469 | Average of Two Simple Baselines | v23     |\n|  39.16466 | Simple baseline 1 ONLY w Outlier Removal (Accidental)| v24     |\n| 39.09411  | Simple baseline 2 ONLY w Outlier Removal (Accidental)| v26     |\n| 39.07753  | Simple baseline 2 ONLY wo Outlier Removal | v28     |\n| -  | Baseline 2 + CB | v30     |","metadata":{}},{"cell_type":"markdown","source":"### üôå Thank You!\n\nThanks for reading! üíô If you have any suggestions, feel free to drop a comment ‚Äì I‚Äôm eager to learn and grow in this amazing community! üå± I‚Äôll be continuously updating this notebook with feature engineering, modeling, and detailed EDA observations for this competition.\n\n### üì¢ If you found this helpful, please upvote to support! üëç Happy coding and best of luck! üöÄüòä","metadata":{"_kg_hide-input":false}}]}