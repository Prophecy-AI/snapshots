{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d08549f",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model\n",
    "\n",
    "Simple baseline following the competition strategy:\n",
    "- Load train.csv + training_extra.csv\n",
    "- Basic preprocessing (label encoding)\n",
    "- Simple Weight Capacity features\n",
    "- XGBoost with GPU acceleration\n",
    "- 20-fold CV\n",
    "- Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a599add7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:13.912338Z",
     "iopub.status.busy": "2026-01-15T09:27:13.912096Z",
     "iopub.status.idle": "2026-01-15T09:27:15.837725Z",
     "shell.execute_reply": "2026-01-15T09:27:15.837275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7982930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:15.838930Z",
     "iopub.status.busy": "2026-01-15T09:27:15.838701Z",
     "iopub.status.idle": "2026-01-15T09:27:19.456993Z",
     "shell.execute_reply": "2026-01-15T09:27:19.456540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training shape: (3994318, 11)\n",
      "Columns: ['id', 'Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)', 'Price']\n",
      "Test shape: (200000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train1 = pd.read_csv('/home/data/train.csv')\n",
    "train2 = pd.read_csv('/home/data/training_extra.csv')\n",
    "train = pd.concat([train1, train2], ignore_index=True)\n",
    "\n",
    "print(f\"Combined training shape: {train.shape}\")\n",
    "print(f\"Columns: {list(train.columns)}\")\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e006b45f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:19.458160Z",
     "iopub.status.busy": "2026-01-15T09:27:19.457881Z",
     "iopub.status.idle": "2026-01-15T09:27:20.458180Z",
     "shell.execute_reply": "2026-01-15T09:27:20.457782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target statistics:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.994318e+06\n",
      "mean     8.136217e+01\n",
      "std      3.893868e+01\n",
      "min      1.500000e+01\n",
      "25%      4.747002e+01\n",
      "50%      8.098495e+01\n",
      "75%      1.148550e+02\n",
      "max      1.500000e+02\n",
      "Name: Price, dtype: float64\n",
      "\n",
      "Missing values in train:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "Brand                   126758\n",
      "Material                110962\n",
      "Size                     87785\n",
      "Compartments                 0\n",
      "Laptop Compartment       98533\n",
      "Waterproof               94324\n",
      "Style                   104180\n",
      "Color                   133617\n",
      "Weight Capacity (kg)      1808\n",
      "Price                        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test:\n",
      "id                         0\n",
      "Brand                   6227\n",
      "Material                5613\n",
      "Size                    4381\n",
      "Compartments               0\n",
      "Laptop Compartment      4962\n",
      "Waterproof              4811\n",
      "Style                   5153\n",
      "Color                   6785\n",
      "Weight Capacity (kg)      77\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic EDA\n",
    "print(\"Target statistics:\")\n",
    "print(train['Price'].describe())\n",
    "\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test:\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c88be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:20.459414Z",
     "iopub.status.busy": "2026-01-15T09:27:20.459137Z",
     "iopub.status.idle": "2026-01-15T09:27:20.461795Z",
     "shell.execute_reply": "2026-01-15T09:27:20.461464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
      "Numerical features: ['Compartments', 'Weight Capacity (kg)']\n"
     ]
    }
   ],
   "source": [
    "# Identify feature types\n",
    "cat_features = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "num_features = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "print(f\"Categorical features: {cat_features}\")\n",
    "print(f\"Numerical features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885fa272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:20.462722Z",
     "iopub.status.busy": "2026-01-15T09:27:20.462484Z",
     "iopub.status.idle": "2026-01-15T09:27:25.686500Z",
     "shell.execute_reply": "2026-01-15T09:27:25.685975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding categorical features and handling missing values...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Brand: 6 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Material: 5 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Size: 4 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Laptop Compartment: 3 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Waterproof: 3 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Style: 4 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Color: 7 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Basic preprocessing - label encode categoricals and handle missing values\n",
    "print(\"Label encoding categorical features and handling missing values...\")\n",
    "le_dict = {}\n",
    "\n",
    "# Handle missing values first\n",
    "for col in cat_features:\n",
    "    # Fill missing values with a placeholder\n",
    "    train[col] = train[col].fillna('Missing')\n",
    "    test[col] = test[col].fillna('Missing')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined train + test to handle unseen categories\n",
    "    combined = pd.concat([train[col], test[col]], ignore_index=True)\n",
    "    le.fit(combined.astype(str))\n",
    "    \n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "    \n",
    "    le_dict[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} classes\")\n",
    "\n",
    "# Handle numerical missing values\n",
    "train['Compartments'] = train['Compartments'].fillna(train['Compartments'].median())\n",
    "test['Compartments'] = test['Compartments'].fillna(train['Compartments'].median())\n",
    "\n",
    "train['Weight Capacity (kg)'] = train['Weight Capacity (kg)'].fillna(train['Weight Capacity (kg)'].median())\n",
    "test['Weight Capacity (kg)'] = test['Weight Capacity (kg)'].fillna(train['Weight Capacity (kg)'].median())\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eeac71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:25.687748Z",
     "iopub.status.busy": "2026-01-15T09:27:25.687569Z",
     "iopub.status.idle": "2026-01-15T09:27:27.529007Z",
     "shell.execute_reply": "2026-01-15T09:27:27.528613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Weight Capacity features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape after feature engineering: (3994318, 28)\n",
      "New features: ['Weight Capacity (kg)', 'weight_round_1', 'weight_round_2', 'weight_round_3', 'weight_round_4', 'weight_round_5', 'weight_round_6', 'weight_round_7', 'weight_round_8', 'weight_round_9', 'weight_round_10', 'weight_digit_1', 'weight_digit_2', 'weight_digit_3', 'weight_digit_4', 'weight_digit_5', 'weight_int', 'weight_frac']\n"
     ]
    }
   ],
   "source": [
    "# Create basic features from Weight Capacity (kg) - most important feature per winning solutions\n",
    "print(\"Creating Weight Capacity features...\")\n",
    "\n",
    "def create_weight_capacity_features(df):\n",
    "    \"\"\"Create features from Weight Capacity (kg) - the most important feature\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure no missing values\n",
    "    df['Weight Capacity (kg)'] = df['Weight Capacity (kg)'].fillna(df['Weight Capacity (kg)'].median())\n",
    "    \n",
    "    # Round to different decimal places\n",
    "    for dec in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        df[f'weight_round_{dec}'] = df['Weight Capacity (kg)'].round(dec)\n",
    "    \n",
    "    # Extract digits\n",
    "    for k in range(1, 6):\n",
    "        df[f'weight_digit_{k}'] = ((df['Weight Capacity (kg)'] * 10**k) % 10).fillna(-1)\n",
    "    \n",
    "    # Basic stats - handle edge cases\n",
    "    df['weight_int'] = df['Weight Capacity (kg)'].astype(int)\n",
    "    df['weight_frac'] = df['Weight Capacity (kg)'] - df['weight_int']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_weight_capacity_features(train)\n",
    "test = create_weight_capacity_features(test)\n",
    "\n",
    "print(f\"New shape after feature engineering: {train.shape}\")\n",
    "print(f\"New features: {[col for col in train.columns if 'weight' in col.lower()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a71d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:27.529879Z",
     "iopub.status.busy": "2026-01-15T09:27:27.529778Z",
     "iopub.status.idle": "2026-01-15T09:27:27.776427Z",
     "shell.execute_reply": "2026-01-15T09:27:27.776026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (3994318, 26)\n",
      "Test features shape: (200000, 26)\n",
      "Number of features: 26\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "feature_cols = [col for col in train.columns if col not in ['id', 'Price']]\n",
    "X = train[feature_cols]\n",
    "y = train['Price']\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0fc124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:27:27.777422Z",
     "iopub.status.busy": "2026-01-15T09:27:27.777314Z",
     "iopub.status.idle": "2026-01-15T09:27:27.780391Z",
     "shell.execute_reply": "2026-01-15T09:27:27.780069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost parameters:\n",
      "  objective: reg:squarederror\n",
      "  eval_metric: rmse\n",
      "  tree_method: gpu_hist\n",
      "  device: cuda\n",
      "  learning_rate: 0.1\n",
      "  max_depth: 6\n",
      "  subsample: 0.8\n",
      "  colsample_bytree: 0.8\n",
      "  random_state: 42\n",
      "  n_estimators: 1000\n",
      "  early_stopping_rounds: 50\n",
      "  verbosity: 0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'gpu_hist',  # Use GPU\n",
    "    'device': 'cuda',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ec8412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:30:32.439188Z",
     "iopub.status.busy": "2026-01-15T09:30:32.438931Z",
     "iopub.status.idle": "2026-01-15T09:33:08.070626Z",
     "shell.execute_reply": "2026-01-15T09:33:08.070216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 20-fold CV training...\n",
      "Fold 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.766019\n",
      "Fold 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.791439\n",
      "Fold 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.697766\n",
      "Fold 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.771409\n",
      "Fold 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.699789\n",
      "Fold 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.778115\n",
      "Fold 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.790089\n",
      "Fold 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.732571\n",
      "Fold 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.786091\n",
      "Fold 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.762629\n",
      "Fold 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.871318\n",
      "Fold 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.853336\n",
      "Fold 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.789804\n",
      "Fold 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.800621\n",
      "Fold 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.731473\n",
      "Fold 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.769511\n",
      "Fold 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.720888\n",
      "Fold 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.848251\n",
      "Fold 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.832048\n",
      "Fold 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold RMSE: 38.827451\n",
      "\n",
      "Overall CV RMSE: 38.781061\n",
      "Mean Fold RMSE: 38.781031 ± 0.048003\n"
     ]
    }
   ],
   "source": [
    "# 20-fold CV as specified in winning strategies\n",
    "n_folds = 20\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "oof_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "\n",
    "print(f\"Starting {n_folds}-fold CV training...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Accumulate test predictions\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    print(f\"  Fold RMSE: {fold_rmse:.6f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_rmse = np.sqrt(mean_squared_error(y, oof_predictions))\n",
    "print(f\"\\nOverall CV RMSE: {cv_rmse:.6f}\")\n",
    "print(f\"Mean Fold RMSE: {np.mean(rmse_scores):.6f} ± {np.std(rmse_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd5bbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:34:45.994904Z",
     "iopub.status.busy": "2026-01-15T09:34:45.994667Z",
     "iopub.status.idle": "2026-01-15T09:34:46.224655Z",
     "shell.execute_reply": "2026-01-15T09:34:46.224219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission preview:\n",
      "       id      Price\n",
      "0  300000  79.434960\n",
      "1  300001  84.390175\n",
      "2  300002  87.350705\n",
      "3  300003  77.083186\n",
      "4  300004  83.603492\n",
      "\n",
      "Submission statistics:\n",
      "count    200000.000000\n",
      "mean         81.362155\n",
      "std           3.303805\n",
      "min          31.472881\n",
      "25%          79.578759\n",
      "50%          81.418643\n",
      "75%          83.254399\n",
      "max         107.692375\n",
      "Name: Price, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved to: /home/submission/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Price': test_predictions\n",
    "})\n",
    "\n",
    "# Clip predictions to reasonable range (based on target distribution)\n",
    "submission['Price'] = submission['Price'].clip(lower=train['Price'].min(), upper=train['Price'].max())\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission['Price'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4641cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Price': test_predictions\n",
    "})\n",
    "\n",
    "# Clip predictions to reasonable range (based on target distribution)\n",
    "submission['Price'] = submission['Price'].clip(lower=train['Price'].min(), upper=train['Price'].max())\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission['Price'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
