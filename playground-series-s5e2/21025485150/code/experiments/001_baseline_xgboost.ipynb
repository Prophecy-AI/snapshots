{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d08549f",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model\n",
    "\n",
    "Simple baseline following the competition strategy:\n",
    "- Load train.csv + training_extra.csv\n",
    "- Basic preprocessing (label encoding)\n",
    "- Simple Weight Capacity features\n",
    "- XGBoost with GPU acceleration\n",
    "- 20-fold CV\n",
    "- Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7982930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading training data...\")\n",
    "train1 = pd.read_csv('/home/data/train.csv')\n",
    "train2 = pd.read_csv('/home/data/training_extra.csv')\n",
    "train = pd.concat([train1, train2], ignore_index=True)\n",
    "\n",
    "print(f\"Combined training shape: {train.shape}\")\n",
    "print(f\"Columns: {list(train.columns)}\")\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "print(\"Target statistics:\")\n",
    "print(train['Price'].describe())\n",
    "\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test:\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c88be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "cat_features = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "num_features = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "print(f\"Categorical features: {cat_features}\")\n",
    "print(f\"Numerical features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fa272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing - label encode categoricals\n",
    "print(\"Label encoding categorical features...\")\n",
    "le_dict = {}\n",
    "\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined train + test to handle unseen categories\n",
    "    combined = pd.concat([train[col], test[col]], ignore_index=True)\n",
    "    le.fit(combined.astype(str))\n",
    "    \n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "    \n",
    "    le_dict[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} classes\")\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeac71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic features from Weight Capacity (kg) - most important feature per winning solutions\n",
    "print(\"Creating Weight Capacity features...\")\n",
    "\n",
    "def create_weight_capacity_features(df):\n",
    "    \"\"\"Create features from Weight Capacity (kg) - the most important feature\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Round to different decimal places\n",
    "    for dec in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        df[f'weight_round_{dec}'] = df['Weight Capacity (kg)'].round(dec)\n",
    "    \n",
    "    # Extract digits\n",
    "    for k in range(1, 6):\n",
    "        df[f'weight_digit_{k}'] = ((df['Weight Capacity (kg)'] * 10**k) % 10).fillna(-1)\n",
    "    \n",
    "    # Basic stats\n",
    "    df['weight_int'] = df['Weight Capacity (kg)'].astype(int)\n",
    "    df['weight_frac'] = df['Weight Capacity (kg)'] - df['weight_int']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_weight_capacity_features(train)\n",
    "test = create_weight_capacity_features(test)\n",
    "\n",
    "print(f\"New shape after feature engineering: {train.shape}\")\n",
    "print(f\"New features: {[col for col in train.columns if 'weight' in col.lower()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a71d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "feature_cols = [col for col in train.columns if col not in ['id', 'Price']]\n",
    "X = train[feature_cols]\n",
    "y = train['Price']\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'gpu_hist',  # Use GPU\n",
    "    'device': 'cuda',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 1000,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameters:\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20-fold CV as specified in winning strategies\n",
    "n_folds = 20\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "rmse_scores = []\n",
    "oof_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "\n",
    "print(f\"Starting {n_folds}-fold CV training...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Accumulate test predictions\n",
    "    test_predictions += test_pred / n_folds\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    rmse_scores.append(fold_rmse)\n",
    "    print(f\"  Fold RMSE: {fold_rmse:.6f}\")\n",
    "\n",
    "# Overall CV score\n",
    "cv_rmse = np.sqrt(mean_squared_error(y, oof_predictions))\n",
    "print(f\"\\nOverall CV RMSE: {cv_rmse:.6f}\")\n",
    "print(f\"Mean Fold RMSE: {np.mean(rmse_scores):.6f} Â± {np.std(rmse_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4641cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Price': test_predictions\n",
    "})\n",
    "\n",
    "# Clip predictions to reasonable range (based on target distribution)\n",
    "submission['Price'] = submission['Price'].clip(lower=train['Price'].min(), upper=train['Price'].max())\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission statistics:\")\n",
    "print(submission['Price'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
