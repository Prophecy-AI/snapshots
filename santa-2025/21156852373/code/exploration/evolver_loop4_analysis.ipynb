{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da76bafe",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: Finding Novel Approaches to Beat 68.919\n",
    "\n",
    "## Current Situation\n",
    "- Best CV/LB: 70.676102 (validated, no overlaps)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.76 points (2.49%)\n",
    "\n",
    "## What's Been Tried (All Failed)\n",
    "1. bbox3 optimizer - 80 rounds, 0 improvement\n",
    "2. tree_packer_v21 - 0 improvement\n",
    "3. Fractional translation - 0.000000003 improvement on N=128 only\n",
    "4. sa_v1_parallel - 4 generations, 0 improvement\n",
    "5. Ensemble from 731 CSV files - best 51.42 but 168/200 overlapping groups\n",
    "\n",
    "## Key Insight\n",
    "The baseline is at an EXTREMELY tight local optimum. Standard optimization cannot escape it.\n",
    "\n",
    "## Novel Approaches to Explore\n",
    "1. **Rebuild from corners** (chistyakov kernel) - Extract smaller layouts from larger ones\n",
    "2. **Grid-based SA with deletion cascade** (jiweiliu kernel) - Different starting point\n",
    "3. **Symmetric solutions** - Discussed in forums as key to winning\n",
    "4. **Analytical solutions for small N** - N=1,2,3 may have closed-form optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9772b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:45.091624Z",
     "iopub.status.busy": "2026-01-20T04:40:45.091054Z",
     "iopub.status.idle": "2026-01-20T04:40:45.683153Z",
     "shell.execute_reply": "2026-01-20T04:40:45.682710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return val[1:]\n",
    "    return str(val)\n",
    "\n",
    "def build_polygon(x, y, angle):\n",
    "    angle_rad = float(angle) * np.pi / 180.0\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "    vertices = [(TX[i] * cos_a - TY[i] * sin_a + float(x),\n",
    "                 TX[i] * sin_a + TY[i] * cos_a + float(y)) for i in range(15)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def get_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    if len(rows) != n:\n",
    "        return float('inf'), None\n",
    "    \n",
    "    all_points = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = float(parse_value(row['x']))\n",
    "        y = float(parse_value(row['y']))\n",
    "        deg = float(parse_value(row['deg']))\n",
    "        poly = build_polygon(x, y, deg)\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    \n",
    "    all_points = np.array(all_points)\n",
    "    side = max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "    return (side ** 2) / n, rows\n",
    "\n",
    "print('Functions loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "407506ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:45.684393Z",
     "iopub.status.busy": "2026-01-20T04:40:45.684219Z",
     "iopub.status.idle": "2026-01-20T04:40:47.861701Z",
     "shell.execute_reply": "2026-01-20T04:40:47.861274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total baseline score: 70.676102\n",
      "Target: 68.919154\n",
      "Gap: 1.756948\n",
      "\n",
      "Top 20 N values by score contribution:\n",
      "  N=  1: 0.661250\n",
      "  N=  2: 0.450779\n",
      "  N=  3: 0.434745\n",
      "  N=  5: 0.416850\n",
      "  N=  4: 0.416545\n",
      "  N=  7: 0.399897\n",
      "  N=  6: 0.399610\n",
      "  N=  9: 0.387415\n",
      "  N=  8: 0.385407\n",
      "  N= 15: 0.379203\n",
      "  N= 10: 0.376630\n",
      "  N= 21: 0.376451\n",
      "  N= 20: 0.376057\n",
      "  N= 11: 0.375736\n",
      "  N= 22: 0.375258\n",
      "  N= 16: 0.374128\n",
      "  N= 26: 0.373997\n",
      "  N= 12: 0.372724\n",
      "  N= 13: 0.372323\n",
      "  N= 25: 0.372144\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_df = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "\n",
    "# Calculate per-N scores\n",
    "scores = {}\n",
    "for n in range(1, 201):\n",
    "    score, _ = get_score_for_n(baseline_df, n)\n",
    "    scores[n] = score\n",
    "\n",
    "total_score = sum(scores.values())\n",
    "print(f'Total baseline score: {total_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap: {total_score - 68.919154:.6f}')\n",
    "\n",
    "# Find N values with highest scores (most room for improvement)\n",
    "scores_sorted = sorted(scores.items(), key=lambda x: -x[1])\n",
    "print('\\nTop 20 N values by score contribution:')\n",
    "for n, s in scores_sorted[:20]:\n",
    "    print(f'  N={n:3d}: {s:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8006d78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:47.862893Z",
     "iopub.status.busy": "2026-01-20T04:40:47.862779Z",
     "iopub.status.idle": "2026-01-20T04:40:47.866722Z",
     "shell.execute_reply": "2026-01-20T04:40:47.866356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency by N (higher = better packed):\n",
      "  N=  1: efficiency=0.8696, score=0.661250\n",
      "  N=  2: efficiency=1.0532, score=0.450779\n",
      "  N=  3: efficiency=1.0724, score=0.434745\n",
      "  N=  4: efficiency=1.0956, score=0.416545\n",
      "  N=  5: efficiency=1.0952, score=0.416850\n",
      "  N= 10: efficiency=1.1522, score=0.376630\n",
      "  N= 20: efficiency=1.1531, score=0.376057\n",
      "  N= 50: efficiency=1.1773, score=0.360753\n",
      "  N=100: efficiency=1.2029, score=0.345531\n",
      "  N=150: efficiency=1.2179, score=0.337065\n",
      "  N=200: efficiency=1.2167, score=0.337731\n"
     ]
    }
   ],
   "source": [
    "# Calculate efficiency for each N\n",
    "# Efficiency = (side_length^2 / n) / (theoretical_minimum)\n",
    "# For a single tree, theoretical minimum is when tree is rotated 45 degrees\n",
    "# Tree dimensions: width=0.7, height=1.0\n",
    "# At 45 degrees: diagonal = sqrt(0.7^2 + 1.0^2) = 1.22\n",
    "\n",
    "efficiencies = {}\n",
    "for n, score in scores.items():\n",
    "    # score = side^2 / n, so side = sqrt(score * n)\n",
    "    side = np.sqrt(score * n)\n",
    "    # Theoretical minimum for n trees packed perfectly\n",
    "    # For large n, approaches sqrt(n * tree_area) where tree_area ~ 0.5\n",
    "    tree_area = 0.5  # approximate\n",
    "    theoretical_side = np.sqrt(n * tree_area)\n",
    "    efficiency = theoretical_side / side if side > 0 else 0\n",
    "    efficiencies[n] = efficiency\n",
    "\n",
    "print('Efficiency by N (higher = better packed):')\n",
    "for n in [1, 2, 3, 4, 5, 10, 20, 50, 100, 150, 200]:\n",
    "    print(f'  N={n:3d}: efficiency={efficiencies[n]:.4f}, score={scores[n]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806bdf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:47.867830Z",
     "iopub.status.busy": "2026-01-20T04:40:47.867727Z",
     "iopub.status.idle": "2026-01-20T04:40:47.871661Z",
     "shell.execute_reply": "2026-01-20T04:40:47.871308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gap to close: 1.756948\n",
      "Average gap per N: 0.008785\n",
      "Required reduction: 2.49%\n",
      "\n",
      "Score from N=1-20: 8.057295 (11.4% of total)\n",
      "If we improve N=1-20 by 50%: saves 4.028647\n",
      "\n",
      "Score from N=21-100: 28.626026 (40.5% of total)\n",
      "Score from N=101-200: 33.992781 (48.1% of total)\n"
     ]
    }
   ],
   "source": [
    "# Analyze what improvement is needed per N to reach target\n",
    "target = 68.919154\n",
    "current = total_score\n",
    "gap = current - target\n",
    "\n",
    "print(f'Total gap to close: {gap:.6f}')\n",
    "print(f'Average gap per N: {gap/200:.6f}')\n",
    "\n",
    "# If we could improve each N by the same percentage\n",
    "required_reduction = gap / current\n",
    "print(f'Required reduction: {required_reduction*100:.2f}%')\n",
    "\n",
    "# What if we focus on small N values?\n",
    "small_n_score = sum(scores[n] for n in range(1, 21))\n",
    "print(f'\\nScore from N=1-20: {small_n_score:.6f} ({small_n_score/current*100:.1f}% of total)')\n",
    "print(f'If we improve N=1-20 by 50%: saves {small_n_score*0.5:.6f}')\n",
    "\n",
    "medium_n_score = sum(scores[n] for n in range(21, 101))\n",
    "print(f'\\nScore from N=21-100: {medium_n_score:.6f} ({medium_n_score/current*100:.1f}% of total)')\n",
    "\n",
    "large_n_score = sum(scores[n] for n in range(101, 201))\n",
    "print(f'Score from N=101-200: {large_n_score:.6f} ({large_n_score/current*100:.1f}% of total)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0b848e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:47.872905Z",
     "iopub.status.busy": "2026-01-20T04:40:47.872618Z",
     "iopub.status.idle": "2026-01-20T04:40:47.878843Z",
     "shell.execute_reply": "2026-01-20T04:40:47.878496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuild from corners function defined\n"
     ]
    }
   ],
   "source": [
    "# Try the \"rebuild from corners\" approach from chistyakov kernel\n",
    "# For each large N, extract smaller layouts by taking trees closest to each corner\n",
    "\n",
    "def get_trees_for_n(df, n):\n",
    "    \"\"\"Get tree data for group N\"\"\"\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    trees = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = float(parse_value(row['x']))\n",
    "        y = float(parse_value(row['y']))\n",
    "        deg = float(parse_value(row['deg']))\n",
    "        trees.append({'x': x, 'y': y, 'deg': deg, 'polygon': build_polygon(x, y, deg)})\n",
    "    return trees\n",
    "\n",
    "def get_side_length(trees):\n",
    "    \"\"\"Get bounding box side length for a list of trees\"\"\"\n",
    "    all_points = []\n",
    "    for t in trees:\n",
    "        all_points.extend(list(t['polygon'].exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def rebuild_from_corners(large_n_trees, target_n):\n",
    "    \"\"\"Extract target_n trees from large_n_trees by taking trees closest to each corner\"\"\"\n",
    "    # Get bounding box\n",
    "    all_points = []\n",
    "    for t in large_n_trees:\n",
    "        all_points.extend(list(t['polygon'].exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    bounds = (all_points.min(axis=0)[0], all_points.min(axis=0)[1],\n",
    "              all_points.max(axis=0)[0], all_points.max(axis=0)[1])\n",
    "    \n",
    "    corners = [\n",
    "        (bounds[0], bounds[1]),  # bottom-left\n",
    "        (bounds[0], bounds[3]),  # top-left\n",
    "        (bounds[2], bounds[1]),  # bottom-right\n",
    "        (bounds[2], bounds[3]),  # top-right\n",
    "    ]\n",
    "    \n",
    "    best_side = float('inf')\n",
    "    best_trees = None\n",
    "    \n",
    "    for corner_x, corner_y in corners:\n",
    "        # Calculate max distance to corner for each tree\n",
    "        distances = []\n",
    "        for i, t in enumerate(large_n_trees):\n",
    "            b = t['polygon'].bounds\n",
    "            dist = max(\n",
    "                abs(b[0] - corner_x), abs(b[2] - corner_x),\n",
    "                abs(b[1] - corner_y), abs(b[3] - corner_y)\n",
    "            )\n",
    "            distances.append((dist, i))\n",
    "        \n",
    "        # Sort by distance and take closest target_n trees\n",
    "        distances.sort()\n",
    "        selected_indices = [idx for _, idx in distances[:target_n]]\n",
    "        selected_trees = [large_n_trees[i] for i in selected_indices]\n",
    "        \n",
    "        side = get_side_length(selected_trees)\n",
    "        if side < best_side:\n",
    "            best_side = side\n",
    "            best_trees = selected_trees\n",
    "    \n",
    "    return best_trees, best_side\n",
    "\n",
    "print('Rebuild from corners function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6437696b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:47.879886Z",
     "iopub.status.busy": "2026-01-20T04:40:47.879791Z",
     "iopub.status.idle": "2026-01-20T04:40:49.139918Z",
     "shell.execute_reply": "2026-01-20T04:40:49.139500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing rebuild from corners approach...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvements found with rebuild from corners\n"
     ]
    }
   ],
   "source": [
    "# Test rebuild from corners on a few large N values\n",
    "print('Testing rebuild from corners approach...')\n",
    "print('='*60)\n",
    "\n",
    "improvements = []\n",
    "\n",
    "for large_n in [50, 100, 150, 200]:\n",
    "    large_trees = get_trees_for_n(baseline_df, large_n)\n",
    "    \n",
    "    for target_n in range(1, min(large_n, 50)):\n",
    "        current_score = scores[target_n]\n",
    "        \n",
    "        rebuilt_trees, rebuilt_side = rebuild_from_corners(large_trees, target_n)\n",
    "        rebuilt_score = (rebuilt_side ** 2) / target_n\n",
    "        \n",
    "        if rebuilt_score < current_score - 1e-9:\n",
    "            improvement = current_score - rebuilt_score\n",
    "            improvements.append((target_n, large_n, improvement, current_score, rebuilt_score))\n",
    "            print(f'N={target_n} from N={large_n}: {current_score:.6f} -> {rebuilt_score:.6f} (improvement: {improvement:.6f})')\n",
    "\n",
    "if not improvements:\n",
    "    print('No improvements found with rebuild from corners')\n",
    "else:\n",
    "    total_improvement = sum(imp[2] for imp in improvements)\n",
    "    print(f'\\nTotal potential improvement: {total_improvement:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485f2e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:49.141045Z",
     "iopub.status.busy": "2026-01-20T04:40:49.140937Z",
     "iopub.status.idle": "2026-01-20T04:40:49.150133Z",
     "shell.execute_reply": "2026-01-20T04:40:49.149782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing N=1 configuration:\n",
      "  Position: (-48.196086, 58.770985)\n",
      "  Angle: 45.000000 degrees\n",
      "  Score: 0.661250\n",
      "  Theoretical optimal score: 1.490000\n",
      "  Gap: -0.828750\n",
      "\n",
      "Analyzing N=2 configuration:\n",
      "  Tree 0: (0.154097, -0.038541), angle=203.629378\n",
      "  Tree 1: (-0.154097, -0.561459), angle=23.629378\n",
      "  Score: 0.450779\n"
     ]
    }
   ],
   "source": [
    "# Analyze the structure of optimal solutions for small N\n",
    "# N=1: Single tree - optimal is 45-degree rotation\n",
    "# N=2: Two trees - what's the optimal arrangement?\n",
    "\n",
    "print('Analyzing N=1 configuration:')\n",
    "trees_n1 = get_trees_for_n(baseline_df, 1)\n",
    "print(f'  Position: ({trees_n1[0][\"x\"]:.6f}, {trees_n1[0][\"y\"]:.6f})')\n",
    "print(f'  Angle: {trees_n1[0][\"deg\"]:.6f} degrees')\n",
    "print(f'  Score: {scores[1]:.6f}')\n",
    "\n",
    "# For N=1, optimal angle is 45 degrees\n",
    "# Tree at 45 degrees has bounding box of sqrt(0.7^2 + 1.0^2) = 1.22\n",
    "optimal_n1_side = np.sqrt(0.7**2 + 1.0**2)\n",
    "optimal_n1_score = optimal_n1_side**2 / 1\n",
    "print(f'  Theoretical optimal score: {optimal_n1_score:.6f}')\n",
    "print(f'  Gap: {scores[1] - optimal_n1_score:.6f}')\n",
    "\n",
    "print('\\nAnalyzing N=2 configuration:')\n",
    "trees_n2 = get_trees_for_n(baseline_df, 2)\n",
    "for i, t in enumerate(trees_n2):\n",
    "    print(f'  Tree {i}: ({t[\"x\"]:.6f}, {t[\"y\"]:.6f}), angle={t[\"deg\"]:.6f}')\n",
    "print(f'  Score: {scores[2]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b8c575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:49.151001Z",
     "iopub.status.busy": "2026-01-20T04:40:49.150888Z",
     "iopub.status.idle": "2026-01-20T04:40:54.500670Z",
     "shell.execute_reply": "2026-01-20T04:40:54.500275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 snapshot directories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Snapshot analysis complete\n"
     ]
    }
   ],
   "source": [
    "# Check what's in the snapshots - are there any solutions with different approaches?\n",
    "import glob\n",
    "import os\n",
    "\n",
    "snapshot_dirs = glob.glob('/home/nonroot/snapshots/santa-2025/*/')\n",
    "print(f'Found {len(snapshot_dirs)} snapshot directories')\n",
    "\n",
    "# Look for any solutions with significantly different scores\n",
    "best_per_n = {n: scores[n] for n in range(1, 201)}\n",
    "\n",
    "for snap_dir in snapshot_dirs[:10]:  # Check first 10\n",
    "    csv_files = glob.glob(os.path.join(snap_dir, 'code/**/*.csv'), recursive=True)\n",
    "    for csv_path in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if 'id' not in df.columns or len(df) != 20100:\n",
    "                continue\n",
    "            \n",
    "            # Check a few N values\n",
    "            for n in [1, 2, 3, 5, 10]:\n",
    "                score, _ = get_score_for_n(df, n)\n",
    "                if score < best_per_n[n] - 0.001:\n",
    "                    print(f'{csv_path}: N={n} score={score:.6f} (baseline={best_per_n[n]:.6f})')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print('\\nSnapshot analysis complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7db774b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T04:40:54.501767Z",
     "iopub.status.busy": "2026-01-20T04:40:54.501664Z",
     "iopub.status.idle": "2026-01-20T04:40:54.504897Z",
     "shell.execute_reply": "2026-01-20T04:40:54.504578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUMMARY OF ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Current score: 70.676102\n",
      "Target: 68.919154\n",
      "Gap: 1.756948 (2.49%)\n",
      "\n",
      "Key findings:\n",
      "1. Baseline is at extremely tight local optimum\n",
      "2. Standard optimizers (bbox3, SA, fractional translation) cannot improve it\n",
      "3. Rebuild from corners approach may find some improvements\n",
      "4. Small N values (1-20) contribute disproportionately to score\n",
      "5. Need fundamentally different approach to close 1.76 point gap\n",
      "\n",
      "Recommended next steps:\n",
      "1. Implement grid-based SA with deletion cascade (jiweiliu kernel)\n",
      "2. Try symmetric solution search for small N\n",
      "3. Explore analytical solutions for N=1,2,3\n",
      "4. Run very long optimization from random starting points\n"
     ]
    }
   ],
   "source": [
    "# Summary of findings\n",
    "print('='*60)\n",
    "print('SUMMARY OF ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'\\nCurrent score: {total_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap: {gap:.6f} ({gap/current*100:.2f}%)')\n",
    "\n",
    "print('\\nKey findings:')\n",
    "print('1. Baseline is at extremely tight local optimum')\n",
    "print('2. Standard optimizers (bbox3, SA, fractional translation) cannot improve it')\n",
    "print('3. Rebuild from corners approach may find some improvements')\n",
    "print('4. Small N values (1-20) contribute disproportionately to score')\n",
    "print('5. Need fundamentally different approach to close 1.76 point gap')\n",
    "\n",
    "print('\\nRecommended next steps:')\n",
    "print('1. Implement grid-based SA with deletion cascade (jiweiliu kernel)')\n",
    "print('2. Try symmetric solution search for small N')\n",
    "print('3. Explore analytical solutions for N=1,2,3')\n",
    "print('4. Run very long optimization from random starting points')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
