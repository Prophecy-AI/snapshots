{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da76bafe",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: Finding Novel Approaches to Beat 68.919\n",
    "\n",
    "## Current Situation\n",
    "- Best CV/LB: 70.676102 (validated, no overlaps)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.76 points (2.49%)\n",
    "\n",
    "## What's Been Tried (All Failed)\n",
    "1. bbox3 optimizer - 80 rounds, 0 improvement\n",
    "2. tree_packer_v21 - 0 improvement\n",
    "3. Fractional translation - 0.000000003 improvement on N=128 only\n",
    "4. sa_v1_parallel - 4 generations, 0 improvement\n",
    "5. Ensemble from 731 CSV files - best 51.42 but 168/200 overlapping groups\n",
    "\n",
    "## Key Insight\n",
    "The baseline is at an EXTREMELY tight local optimum. Standard optimization cannot escape it.\n",
    "\n",
    "## Novel Approaches to Explore\n",
    "1. **Rebuild from corners** (chistyakov kernel) - Extract smaller layouts from larger ones\n",
    "2. **Grid-based SA with deletion cascade** (jiweiliu kernel) - Different starting point\n",
    "3. **Symmetric solutions** - Discussed in forums as key to winning\n",
    "4. **Analytical solutions for small N** - N=1,2,3 may have closed-form optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9772b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return val[1:]\n",
    "    return str(val)\n",
    "\n",
    "def build_polygon(x, y, angle):\n",
    "    angle_rad = float(angle) * np.pi / 180.0\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "    vertices = [(TX[i] * cos_a - TY[i] * sin_a + float(x),\n",
    "                 TX[i] * sin_a + TY[i] * cos_a + float(y)) for i in range(15)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def get_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    if len(rows) != n:\n",
    "        return float('inf'), None\n",
    "    \n",
    "    all_points = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = float(parse_value(row['x']))\n",
    "        y = float(parse_value(row['y']))\n",
    "        deg = float(parse_value(row['deg']))\n",
    "        poly = build_polygon(x, y, deg)\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    \n",
    "    all_points = np.array(all_points)\n",
    "    side = max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "    return (side ** 2) / n, rows\n",
    "\n",
    "print('Functions loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407506ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline\n",
    "baseline_df = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "\n",
    "# Calculate per-N scores\n",
    "scores = {}\n",
    "for n in range(1, 201):\n",
    "    score, _ = get_score_for_n(baseline_df, n)\n",
    "    scores[n] = score\n",
    "\n",
    "total_score = sum(scores.values())\n",
    "print(f'Total baseline score: {total_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap: {total_score - 68.919154:.6f}')\n",
    "\n",
    "# Find N values with highest scores (most room for improvement)\n",
    "scores_sorted = sorted(scores.items(), key=lambda x: -x[1])\n",
    "print('\\nTop 20 N values by score contribution:')\n",
    "for n, s in scores_sorted[:20]:\n",
    "    print(f'  N={n:3d}: {s:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency for each N\n",
    "# Efficiency = (side_length^2 / n) / (theoretical_minimum)\n",
    "# For a single tree, theoretical minimum is when tree is rotated 45 degrees\n",
    "# Tree dimensions: width=0.7, height=1.0\n",
    "# At 45 degrees: diagonal = sqrt(0.7^2 + 1.0^2) = 1.22\n",
    "\n",
    "efficiencies = {}\n",
    "for n, score in scores.items():\n",
    "    # score = side^2 / n, so side = sqrt(score * n)\n",
    "    side = np.sqrt(score * n)\n",
    "    # Theoretical minimum for n trees packed perfectly\n",
    "    # For large n, approaches sqrt(n * tree_area) where tree_area ~ 0.5\n",
    "    tree_area = 0.5  # approximate\n",
    "    theoretical_side = np.sqrt(n * tree_area)\n",
    "    efficiency = theoretical_side / side if side > 0 else 0\n",
    "    efficiencies[n] = efficiency\n",
    "\n",
    "print('Efficiency by N (higher = better packed):')\n",
    "for n in [1, 2, 3, 4, 5, 10, 20, 50, 100, 150, 200]:\n",
    "    print(f'  N={n:3d}: efficiency={efficiencies[n]:.4f}, score={scores[n]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what improvement is needed per N to reach target\n",
    "target = 68.919154\n",
    "current = total_score\n",
    "gap = current - target\n",
    "\n",
    "print(f'Total gap to close: {gap:.6f}')\n",
    "print(f'Average gap per N: {gap/200:.6f}')\n",
    "\n",
    "# If we could improve each N by the same percentage\n",
    "required_reduction = gap / current\n",
    "print(f'Required reduction: {required_reduction*100:.2f}%')\n",
    "\n",
    "# What if we focus on small N values?\n",
    "small_n_score = sum(scores[n] for n in range(1, 21))\n",
    "print(f'\\nScore from N=1-20: {small_n_score:.6f} ({small_n_score/current*100:.1f}% of total)')\n",
    "print(f'If we improve N=1-20 by 50%: saves {small_n_score*0.5:.6f}')\n",
    "\n",
    "medium_n_score = sum(scores[n] for n in range(21, 101))\n",
    "print(f'\\nScore from N=21-100: {medium_n_score:.6f} ({medium_n_score/current*100:.1f}% of total)')\n",
    "\n",
    "large_n_score = sum(scores[n] for n in range(101, 201))\n",
    "print(f'Score from N=101-200: {large_n_score:.6f} ({large_n_score/current*100:.1f}% of total)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the \"rebuild from corners\" approach from chistyakov kernel\n",
    "# For each large N, extract smaller layouts by taking trees closest to each corner\n",
    "\n",
    "def get_trees_for_n(df, n):\n",
    "    \"\"\"Get tree data for group N\"\"\"\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    trees = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = float(parse_value(row['x']))\n",
    "        y = float(parse_value(row['y']))\n",
    "        deg = float(parse_value(row['deg']))\n",
    "        trees.append({'x': x, 'y': y, 'deg': deg, 'polygon': build_polygon(x, y, deg)})\n",
    "    return trees\n",
    "\n",
    "def get_side_length(trees):\n",
    "    \"\"\"Get bounding box side length for a list of trees\"\"\"\n",
    "    all_points = []\n",
    "    for t in trees:\n",
    "        all_points.extend(list(t['polygon'].exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def rebuild_from_corners(large_n_trees, target_n):\n",
    "    \"\"\"Extract target_n trees from large_n_trees by taking trees closest to each corner\"\"\"\n",
    "    # Get bounding box\n",
    "    all_points = []\n",
    "    for t in large_n_trees:\n",
    "        all_points.extend(list(t['polygon'].exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    bounds = (all_points.min(axis=0)[0], all_points.min(axis=0)[1],\n",
    "              all_points.max(axis=0)[0], all_points.max(axis=0)[1])\n",
    "    \n",
    "    corners = [\n",
    "        (bounds[0], bounds[1]),  # bottom-left\n",
    "        (bounds[0], bounds[3]),  # top-left\n",
    "        (bounds[2], bounds[1]),  # bottom-right\n",
    "        (bounds[2], bounds[3]),  # top-right\n",
    "    ]\n",
    "    \n",
    "    best_side = float('inf')\n",
    "    best_trees = None\n",
    "    \n",
    "    for corner_x, corner_y in corners:\n",
    "        # Calculate max distance to corner for each tree\n",
    "        distances = []\n",
    "        for i, t in enumerate(large_n_trees):\n",
    "            b = t['polygon'].bounds\n",
    "            dist = max(\n",
    "                abs(b[0] - corner_x), abs(b[2] - corner_x),\n",
    "                abs(b[1] - corner_y), abs(b[3] - corner_y)\n",
    "            )\n",
    "            distances.append((dist, i))\n",
    "        \n",
    "        # Sort by distance and take closest target_n trees\n",
    "        distances.sort()\n",
    "        selected_indices = [idx for _, idx in distances[:target_n]]\n",
    "        selected_trees = [large_n_trees[i] for i in selected_indices]\n",
    "        \n",
    "        side = get_side_length(selected_trees)\n",
    "        if side < best_side:\n",
    "            best_side = side\n",
    "            best_trees = selected_trees\n",
    "    \n",
    "    return best_trees, best_side\n",
    "\n",
    "print('Rebuild from corners function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rebuild from corners on a few large N values\n",
    "print('Testing rebuild from corners approach...')\n",
    "print('='*60)\n",
    "\n",
    "improvements = []\n",
    "\n",
    "for large_n in [50, 100, 150, 200]:\n",
    "    large_trees = get_trees_for_n(baseline_df, large_n)\n",
    "    \n",
    "    for target_n in range(1, min(large_n, 50)):\n",
    "        current_score = scores[target_n]\n",
    "        \n",
    "        rebuilt_trees, rebuilt_side = rebuild_from_corners(large_trees, target_n)\n",
    "        rebuilt_score = (rebuilt_side ** 2) / target_n\n",
    "        \n",
    "        if rebuilt_score < current_score - 1e-9:\n",
    "            improvement = current_score - rebuilt_score\n",
    "            improvements.append((target_n, large_n, improvement, current_score, rebuilt_score))\n",
    "            print(f'N={target_n} from N={large_n}: {current_score:.6f} -> {rebuilt_score:.6f} (improvement: {improvement:.6f})')\n",
    "\n",
    "if not improvements:\n",
    "    print('No improvements found with rebuild from corners')\n",
    "else:\n",
    "    total_improvement = sum(imp[2] for imp in improvements)\n",
    "    print(f'\\nTotal potential improvement: {total_improvement:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the structure of optimal solutions for small N\n",
    "# N=1: Single tree - optimal is 45-degree rotation\n",
    "# N=2: Two trees - what's the optimal arrangement?\n",
    "\n",
    "print('Analyzing N=1 configuration:')\n",
    "trees_n1 = get_trees_for_n(baseline_df, 1)\n",
    "print(f'  Position: ({trees_n1[0][\"x\"]:.6f}, {trees_n1[0][\"y\"]:.6f})')\n",
    "print(f'  Angle: {trees_n1[0][\"deg\"]:.6f} degrees')\n",
    "print(f'  Score: {scores[1]:.6f}')\n",
    "\n",
    "# For N=1, optimal angle is 45 degrees\n",
    "# Tree at 45 degrees has bounding box of sqrt(0.7^2 + 1.0^2) = 1.22\n",
    "optimal_n1_side = np.sqrt(0.7**2 + 1.0**2)\n",
    "optimal_n1_score = optimal_n1_side**2 / 1\n",
    "print(f'  Theoretical optimal score: {optimal_n1_score:.6f}')\n",
    "print(f'  Gap: {scores[1] - optimal_n1_score:.6f}')\n",
    "\n",
    "print('\\nAnalyzing N=2 configuration:')\n",
    "trees_n2 = get_trees_for_n(baseline_df, 2)\n",
    "for i, t in enumerate(trees_n2):\n",
    "    print(f'  Tree {i}: ({t[\"x\"]:.6f}, {t[\"y\"]:.6f}), angle={t[\"deg\"]:.6f}')\n",
    "print(f'  Score: {scores[2]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in the snapshots - are there any solutions with different approaches?\n",
    "import glob\n",
    "import os\n",
    "\n",
    "snapshot_dirs = glob.glob('/home/nonroot/snapshots/santa-2025/*/')\n",
    "print(f'Found {len(snapshot_dirs)} snapshot directories')\n",
    "\n",
    "# Look for any solutions with significantly different scores\n",
    "best_per_n = {n: scores[n] for n in range(1, 201)}\n",
    "\n",
    "for snap_dir in snapshot_dirs[:10]:  # Check first 10\n",
    "    csv_files = glob.glob(os.path.join(snap_dir, 'code/**/*.csv'), recursive=True)\n",
    "    for csv_path in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if 'id' not in df.columns or len(df) != 20100:\n",
    "                continue\n",
    "            \n",
    "            # Check a few N values\n",
    "            for n in [1, 2, 3, 5, 10]:\n",
    "                score, _ = get_score_for_n(df, n)\n",
    "                if score < best_per_n[n] - 0.001:\n",
    "                    print(f'{csv_path}: N={n} score={score:.6f} (baseline={best_per_n[n]:.6f})')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print('\\nSnapshot analysis complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print('='*60)\n",
    "print('SUMMARY OF ANALYSIS')\n",
    "print('='*60)\n",
    "print(f'\\nCurrent score: {total_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap: {gap:.6f} ({gap/current*100:.2f}%)')\n",
    "\n",
    "print('\\nKey findings:')\n",
    "print('1. Baseline is at extremely tight local optimum')\n",
    "print('2. Standard optimizers (bbox3, SA, fractional translation) cannot improve it')\n",
    "print('3. Rebuild from corners approach may find some improvements')\n",
    "print('4. Small N values (1-20) contribute disproportionately to score')\n",
    "print('5. Need fundamentally different approach to close 1.76 point gap')\n",
    "\n",
    "print('\\nRecommended next steps:')\n",
    "print('1. Implement grid-based SA with deletion cascade (jiweiliu kernel)')\n",
    "print('2. Try symmetric solution search for small N')\n",
    "print('3. Explore analytical solutions for N=1,2,3')\n",
    "print('4. Run very long optimization from random starting points')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
