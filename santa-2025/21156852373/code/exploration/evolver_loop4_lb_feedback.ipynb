{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f19f06",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 - LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **exp_000**: CV 70.6761 | LB 70.6761 (gap: 0.0000)\n",
    "- **exp_003**: CV 70.6761 | LB 70.6761 (gap: 0.0000)\n",
    "\n",
    "## Key Finding: Perfect CV-LB Alignment\n",
    "The CV and LB scores are IDENTICAL, which means:\n",
    "1. Our scoring function is correct\n",
    "2. Our overlap detection is correct\n",
    "3. The baseline is truly at 70.676102\n",
    "\n",
    "## The Challenge\n",
    "- Target: 68.919154\n",
    "- Current: 70.676102\n",
    "- Gap: 1.756948 (2.49% improvement needed)\n",
    "\n",
    "## What We've Tried (All Failed)\n",
    "1. Fractional translation - 0 improvement\n",
    "2. SA + local search + fractional translation - 0 improvement\n",
    "3. bbox3 optimizer (80 rounds) - 0 improvement\n",
    "4. tree_packer_v21 - 0 improvement\n",
    "5. Ensemble from 731 CSV files - all better scores have overlaps\n",
    "\n",
    "## Key Insight from Research\n",
    "To break below 70, we need **multi-tree lattice packings** with 3-, 4-, or 5-tree repeating units, not just optimization of existing solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e590d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return val[1:]\n",
    "    return str(val)\n",
    "\n",
    "def build_polygon(x, y, angle):\n",
    "    angle_rad = float(angle) * np.pi / 180.0\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "    vertices = [(TX[i] * cos_a - TY[i] * sin_a + float(x),\n",
    "                 TX[i] * sin_a + TY[i] * cos_a + float(y)) for i in range(15)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def get_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    if len(rows) != n:\n",
    "        return float('inf')\n",
    "    \n",
    "    all_points = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = float(parse_value(row['x']))\n",
    "        y = float(parse_value(row['y']))\n",
    "        deg = float(parse_value(row['deg']))\n",
    "        poly = build_polygon(x, y, deg)\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    \n",
    "    all_points = np.array(all_points)\n",
    "    side = max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline and analyze score breakdown\n",
    "baseline_df = pd.read_csv('/home/code/submission_candidates/candidate_000.csv')\n",
    "\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    score = get_score_for_n(baseline_df, n)\n",
    "    scores.append({'n': n, 'score': score, 'contribution': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(f\"Total score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {scores_df['score'].sum() - 68.919154:.6f}\")\n",
    "print()\n",
    "print(\"Score breakdown by N range:\")\n",
    "for start in [1, 11, 21, 51, 101, 151]:\n",
    "    end = min(start + 9, 200) if start < 101 else min(start + 49, 200)\n",
    "    range_score = scores_df[(scores_df['n'] >= start) & (scores_df['n'] <= end)]['score'].sum()\n",
    "    print(f\"  N={start:3d}-{end:3d}: {range_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ad811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which N values have the most room for improvement\n",
    "# Theoretical minimum for N trees is approximately sqrt(N) * tree_area\n",
    "# But for small N, the packing efficiency is much worse\n",
    "\n",
    "print(\"Top 20 N values by score contribution:\")\n",
    "top_n = scores_df.nlargest(20, 'score')\n",
    "for _, row in top_n.iterrows():\n",
    "    print(f\"  N={int(row['n']):3d}: score={row['score']:.6f}\")\n",
    "\n",
    "print(\"\\nSmall N values (1-20) contribute:\", scores_df[scores_df['n'] <= 20]['score'].sum())\n",
    "print(\"Medium N values (21-100) contribute:\", scores_df[(scores_df['n'] > 20) & (scores_df['n'] <= 100)]['score'].sum())\n",
    "print(\"Large N values (101-200) contribute:\", scores_df[scores_df['n'] > 100]['score'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ff5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency for each N\n",
    "# Efficiency = (N * tree_area) / (bounding_box_area)\n",
    "# Tree area is approximately 0.35 * 1.0 = 0.35 (rough estimate)\n",
    "\n",
    "tree_area = 0.35  # Approximate\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    score = scores_df[scores_df['n'] == n]['score'].values[0]\n",
    "    bbox_area = score * n  # score = side^2 / n, so side^2 = score * n\n",
    "    efficiency = (n * tree_area) / bbox_area\n",
    "    efficiencies.append({'n': n, 'efficiency': efficiency, 'score': score})\n",
    "\n",
    "eff_df = pd.DataFrame(efficiencies)\n",
    "\n",
    "print(\"Efficiency by N range (higher is better):\")\n",
    "for start in [1, 11, 21, 51, 101, 151]:\n",
    "    end = min(start + 9, 200) if start < 101 else min(start + 49, 200)\n",
    "    avg_eff = eff_df[(eff_df['n'] >= start) & (eff_df['n'] <= end)]['efficiency'].mean()\n",
    "    print(f\"  N={start:3d}-{end:3d}: avg efficiency={avg_eff:.4f}\")\n",
    "\n",
    "print(\"\\nLowest efficiency N values (most room for improvement):\")\n",
    "lowest_eff = eff_df.nsmallest(10, 'efficiency')\n",
    "for _, row in lowest_eff.iterrows():\n",
    "    print(f\"  N={int(row['n']):3d}: efficiency={row['efficiency']:.4f}, score={row['score']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: To close the 1.76 point gap, we need to improve across all N values\n",
    "# But small N values have the worst efficiency and contribute disproportionately\n",
    "\n",
    "# Calculate how much improvement we need per N value\n",
    "target = 68.919154\n",
    "current = scores_df['score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current total: {current:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f}\")\n",
    "print()\n",
    "print(f\"Average improvement needed per N: {gap / 200:.6f}\")\n",
    "print(f\"Percentage improvement needed: {100 * gap / current:.2f}%\")\n",
    "print()\n",
    "print(\"If we could improve each N by 2.49%:\")\n",
    "for n in [1, 2, 5, 10, 50, 100, 200]:\n",
    "    current_score = scores_df[scores_df['n'] == n]['score'].values[0]\n",
    "    improved_score = current_score * 0.9751\n",
    "    improvement = current_score - improved_score\n",
    "    print(f\"  N={n:3d}: {current_score:.6f} -> {improved_score:.6f} (save {improvement:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8890b",
   "metadata": {},
   "source": [
    "## Strategy Analysis\n",
    "\n",
    "### What We Know:\n",
    "1. The baseline is at a VERY tight local optimum - standard optimizers cannot improve it\n",
    "2. The gap to target is 1.76 points (2.49% improvement needed)\n",
    "3. Small N values (1-20) have the worst efficiency and contribute disproportionately\n",
    "4. All CSV files with better scores have overlapping trees\n",
    "\n",
    "### What Research Suggests:\n",
    "1. **Multi-tree lattice packings** with 3-, 4-, or 5-tree repeating units can break below 70\n",
    "2. **Symmetric solutions** dramatically shrink search space while covering optimal region\n",
    "3. **Grid-based approaches** with SA optimization on lattice parameters\n",
    "4. The \"super-fast-simulated-annealing-with-translations\" kernel uses grid configs\n",
    "\n",
    "### Key Approaches to Try:\n",
    "1. **Lattice-based packing for large N** - Generate grid configurations and optimize\n",
    "2. **Symmetric solutions for small N** - Exhaustive search with symmetry constraints\n",
    "3. **Novel repeating patterns** - 3-tree, 4-tree, 5-tree unit cells\n",
    "4. **Very long random restarts** - Start from scratch with different initial configs"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
