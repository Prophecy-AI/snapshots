# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.615745 from exp_002 (003_validated_ensemble)
- Best LB score: 70.647327 (exp_000 baseline - ONLY valid submission so far)
- Target: 68.894234 | Gap to target: 1.75 points (2.5%)

## CRITICAL BUG IDENTIFIED - MUST FIX FIRST

**The last two submissions (exp_001 and exp_002) failed due to PRECISION TRUNCATION!**

The issue:
- Baseline has full precision: `s0.1540970696213643` (16 decimal places)
- My submissions had truncated: `s0.154097` (6 decimal places)
- This truncation causes trees that were just touching to now OVERLAP

**THE FIX:**
When generating submissions, preserve the ORIGINAL STRING VALUES from source files.
Do NOT convert to float and back - this loses precision.

```python
# WRONG (loses precision):
df['x_val'] = df['x'].str.replace('s', '').astype(float)
# ... later ...
row['x'] = f's{xs[i]}'  # Truncated!

# CORRECT (preserves precision):
# Keep original string values from source files
# Only use float for scoring calculations, not for output
```

## Response to Evaluator

The evaluator correctly identified that:
1. The validated ensemble (candidate_002.csv) needed to be submitted to verify it passes Kaggle's validator - it FAILED
2. The strict overlap validation was not strict enough - CONFIRMED, but the root cause is precision truncation, not the validation logic
3. No actual optimization has been run - AGREED, but we must first fix the precision bug

**I agree with the evaluator's assessment.** The immediate priority is:
1. Fix the precision bug in submission generation
2. Submit a valid ensemble with full precision
3. THEN run actual optimization (bbox3, SA, etc.)

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY]** Fix Precision Bug and Resubmit Ensemble

Create a new ensemble that:
- Preserves original string values from source files (don't convert to float)
- Uses official overlap validation (intersects but not touches)
- Falls back to baseline for any failing N values

```python
def generate_submission_preserve_precision(configs_by_n, output_path):
    """Generate submission preserving original string precision"""
    rows = []
    for n in range(1, 201):
        source_df = configs_by_n[n]  # DataFrame with original 'x', 'y', 'deg' strings
        for idx, row in source_df.iterrows():
            rows.append({
                'id': f'{n:03d}_{row["tree_idx"]}',
                'x': row['x'],  # Keep original string!
                'y': row['y'],
                'deg': row['deg']
            })
    df = pd.DataFrame(rows)
    df.to_csv(output_path, index=False)
```

### 2. **[HIGH PRIORITY]** After Valid Submission, Run bbox3 Optimizer

The bbox3 optimizer is compiled and ready at /home/code/bbox3:
```bash
cd /home/code
cp submission_candidates/candidate_XXX.csv submission.csv  # Use valid submission
./bbox3 -n 5000 -r 100  # Run optimization
```

### 3. **[MEDIUM PRIORITY]** Implement Fundamentally Different Approaches

After establishing a valid optimized baseline, try:
- Lattice/grid-based approaches for large N (N≥58)
- Asymmetric layouts (38-vote discussion supports this)
- Per-N specialized optimization for small N values

## What NOT to Try
- ❌ Any submission generation that converts float to string (loses precision)
- ❌ Running optimization before fixing the precision bug
- ❌ Micro-optimization when 1.75 points from target

## Validation Notes
- Use official overlap detection: `intersects() and not touches()`
- Use Decimal precision with scale_factor = 1e15 (matching official kernel)
- Preserve original string values in submissions

## SUBMISSION STRATEGY
- Remaining submissions: 97
- Submit after this experiment? YES - need to verify precision fix works
- If precision fix works, we'll have a valid ensemble at ~70.615
- Then run actual optimization to close the 1.75 point gap