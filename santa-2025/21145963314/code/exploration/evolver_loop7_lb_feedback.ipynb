{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befba8bf",
   "metadata": {},
   "source": [
    "# Loop 7 LB Feedback Analysis\n",
    "\n",
    "**Submission**: exp_006 (011_long_optimization)\n",
    "**CV Score**: 70.6600\n",
    "**LB Score**: 70.6600\n",
    "**Gap**: 0.0000 (CV = LB, as expected for this optimization problem)\n",
    "\n",
    "## Key Observations\n",
    "1. CV = LB confirms this is a pure optimization problem with no train/test split\n",
    "2. 33 minutes of C++ optimization found ZERO improvement\n",
    "3. The baseline is at an extremely tight local optimum with no slack\n",
    "4. Gap to target: 70.66 - 68.92 = 1.74 points (2.46%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f167c1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:34.628595Z",
     "iopub.status.busy": "2026-01-19T20:45:34.628081Z",
     "iopub.status.idle": "2026-01-19T20:45:35.015247Z",
     "shell.execute_reply": "2026-01-19T20:45:35.014877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 20100\n",
      "      id                          x                         y  \\\n",
      "0  001_0  s-48.19608619421424577922  s58.77098461521422478882   \n",
      "1  002_0    s0.15409706962135588659  s-0.03854074269479464826   \n",
      "2  002_1   s-0.15409706962137284525  s-0.56145925730522405761   \n",
      "3  003_0    s1.12365581614030096702   s0.78110181599256300888   \n",
      "4  003_1    s1.23405569584216001644   s1.27599950066375900093   \n",
      "\n",
      "                         deg  \n",
      "0   s45.00000000000000000000  \n",
      "1  s203.62937773065684154972  \n",
      "2   s23.62937773065679181173  \n",
      "3  s111.12513229289299943048  \n",
      "4   s66.37062226934300213088  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import math\n",
    "\n",
    "# Load current best submission\n",
    "df = pd.read_csv('/home/code/external_data/saspav_latest/santa-2025.csv')\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17f2cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:35.016294Z",
     "iopub.status.busy": "2026-01-19T20:45:35.016188Z",
     "iopub.status.idle": "2026-01-19T20:45:35.466063Z",
     "shell.execute_reply": "2026-01-19T20:45:35.465685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scoring function\n",
    "@njit\n",
    "def make_polygon_template():\n",
    "    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n",
    "    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n",
    "    x=np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2],np.float64)\n",
    "    y=np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1],np.float64)\n",
    "    return x,y\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r); s = math.sin(r)\n",
    "        xi = xs[i]; yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xi\n",
    "            Y = s * tx[j] + c * ty[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s','')) for v in a], np.float64)\n",
    "\n",
    "tx, ty = make_polygon_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d0b7ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:35.467946Z",
     "iopub.status.busy": "2026-01-19T20:45:35.467578Z",
     "iopub.status.idle": "2026-01-19T20:45:35.620558Z",
     "shell.execute_reply": "2026-01-19T20:45:35.620014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 70.659958\n",
      "\n",
      "Top 10 worst-packed (highest score/N):\n",
      "     N     score      side\n",
      "0    1  0.661250  0.813173\n",
      "1    2  0.450779  0.949504\n",
      "2    3  0.434745  1.142031\n",
      "4    5  0.416850  1.443692\n",
      "3    4  0.416545  1.290806\n",
      "6    7  0.399897  1.673104\n",
      "5    6  0.399610  1.548438\n",
      "8    9  0.387415  1.867280\n",
      "7    8  0.385407  1.755921\n",
      "14  15  0.379203  2.384962\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-N scores\n",
    "df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "\n",
    "scores = []\n",
    "for n, g in df.groupby('N'):\n",
    "    xs = strip(g['x'].to_numpy())\n",
    "    ys = strip(g['y'].to_numpy())\n",
    "    ds = strip(g['deg'].to_numpy())\n",
    "    sc = score_group(xs, ys, ds, tx, ty)\n",
    "    scores.append({'N': n, 'score': sc, 'side': np.sqrt(sc * n)})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(f\"Total score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 worst-packed (highest score/N):\")\n",
    "print(scores_df.nlargest(10, 'score')[['N', 'score', 'side']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d3276c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:35.621605Z",
     "iopub.status.busy": "2026-01-19T20:45:35.621499Z",
     "iopub.status.idle": "2026-01-19T20:45:35.628459Z",
     "shell.execute_reply": "2026-01-19T20:45:35.628118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efficiency analysis (lower is better):\n",
      "Best efficiency (lowest score): N=181, score=0.329946\n",
      "Worst efficiency (highest score): N=1, score=0.661250\n",
      "\n",
      "Score contribution by N range:\n",
      "               sum      mean  count\n",
      "N_range                            \n",
      "1-10      4.329128  0.432913     10\n",
      "11-50    14.712640  0.367816     40\n",
      "51-100   17.632268  0.352645     50\n",
      "101-150  17.140770  0.342815     50\n",
      "151-200  16.845152  0.336903     50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66458/2644961680.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(scores_df.groupby('N_range')['score'].agg(['sum', 'mean', 'count']))\n"
     ]
    }
   ],
   "source": [
    "# Analyze which N values have the most room for improvement\n",
    "# Theoretical minimum for N trees in a square is when they're perfectly packed\n",
    "# For this tree shape, the theoretical packing efficiency is unknown\n",
    "\n",
    "# Let's look at the efficiency metric: score / N vs N\n",
    "scores_df['efficiency'] = scores_df['score']  # Already normalized by N\n",
    "scores_df['side_per_tree'] = scores_df['side'] / np.sqrt(scores_df['N'])\n",
    "\n",
    "print(\"\\nEfficiency analysis (lower is better):\")\n",
    "print(f\"Best efficiency (lowest score): N={scores_df.loc[scores_df['score'].idxmin(), 'N']}, score={scores_df['score'].min():.6f}\")\n",
    "print(f\"Worst efficiency (highest score): N={scores_df.loc[scores_df['score'].idxmax(), 'N']}, score={scores_df['score'].max():.6f}\")\n",
    "\n",
    "# Group by N ranges\n",
    "scores_df['N_range'] = pd.cut(scores_df['N'], bins=[0, 10, 50, 100, 150, 200], labels=['1-10', '11-50', '51-100', '101-150', '151-200'])\n",
    "print(\"\\nScore contribution by N range:\")\n",
    "print(scores_df.groupby('N_range')['score'].agg(['sum', 'mean', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25168e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:35.629268Z",
     "iopub.status.busy": "2026-01-19T20:45:35.629179Z",
     "iopub.status.idle": "2026-01-19T20:45:35.632242Z",
     "shell.execute_reply": "2026-01-19T20:45:35.631920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid configurations for large N (from egortrushin kernel):\n",
      "N=72: [4,9] -> 4*9*2 = 72\n",
      "N=100: [5,10] -> 5*10*2 = 100\n",
      "N=110: [5,11] -> 5*11*2 = 110\n",
      "N=144: [6,12] -> 6*12*2 = 144\n",
      "N=156: [6,13] -> 6*13*2 = 156\n",
      "N=196: [7,14] -> 7*14*2 = 196\n",
      "N=200: [7,15] -> 7*15*2 = 210, take first 200\n",
      "\n",
      "These are the N values where lattice approach is most effective.\n",
      "The super-fast SA kernel shows ~0.15 improvement in 2 minutes!\n"
     ]
    }
   ],
   "source": [
    "# The key insight from the super-fast SA kernel:\n",
    "# 1. Use 2-tree unit cells with translations\n",
    "# 2. Automatically explore all viable grid sizes\n",
    "# 3. Apply deletion cascade\n",
    "\n",
    "# Let's check what grid sizes could work for large N\n",
    "print(\"Grid configurations for large N (from egortrushin kernel):\")\n",
    "print(\"N=72: [4,9] -> 4*9*2 = 72\")\n",
    "print(\"N=100: [5,10] -> 5*10*2 = 100\")\n",
    "print(\"N=110: [5,11] -> 5*11*2 = 110\")\n",
    "print(\"N=144: [6,12] -> 6*12*2 = 144\")\n",
    "print(\"N=156: [6,13] -> 6*13*2 = 156\")\n",
    "print(\"N=196: [7,14] -> 7*14*2 = 196\")\n",
    "print(\"N=200: [7,15] -> 7*15*2 = 210, take first 200\")\n",
    "\n",
    "print(\"\\nThese are the N values where lattice approach is most effective.\")\n",
    "print(\"The super-fast SA kernel shows ~0.15 improvement in 2 minutes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00c3d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T20:45:35.633082Z",
     "iopub.status.busy": "2026-01-19T20:45:35.632983Z",
     "iopub.status.idle": "2026-01-19T20:45:35.636536Z",
     "shell.execute_reply": "2026-01-19T20:45:35.636174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 70.659958\n",
      "Target score: 68.919154\n",
      "Gap: 1.740804 (2.46%)\n",
      "\n",
      "Large N (>100) contribution: 33.985922 (48.1%)\n",
      "5% improvement on large N: 1.699296\n",
      "Would close 97.6% of the gap\n"
     ]
    }
   ],
   "source": [
    "# What's the gap breakdown?\n",
    "target = 68.919154\n",
    "current = scores_df['score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({100*gap/current:.2f}%)\")\n",
    "\n",
    "# If we could improve large N by 5%, how much would that help?\n",
    "large_n_score = scores_df[scores_df['N'] > 100]['score'].sum()\n",
    "print(f\"\\nLarge N (>100) contribution: {large_n_score:.6f} ({100*large_n_score/current:.1f}%)\")\n",
    "print(f\"5% improvement on large N: {0.05 * large_n_score:.6f}\")\n",
    "print(f\"Would close {100 * 0.05 * large_n_score / gap:.1f}% of the gap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24575d60",
   "metadata": {},
   "source": [
    "## Strategy for Next Experiment\n",
    "\n",
    "### Key Insight from Research\n",
    "\n",
    "The **super-fast SA with translations** kernel (jiweiliu) shows a complete workflow that:\n",
    "1. Uses 2-tree unit cells with grid translations\n",
    "2. Automatically explores ALL viable grid sizes (not just hand-picked ones)\n",
    "3. Applies deletion cascade (backward propagation)\n",
    "4. Gets ~0.15 improvement in under 2 minutes!\n",
    "\n",
    "### The Problem with Our Current Approach\n",
    "\n",
    "We've been trying to optimize an ALREADY OPTIMIZED solution. The baseline is at a tight local optimum.\n",
    "\n",
    "### The Solution: Generate NEW Configurations from Scratch\n",
    "\n",
    "The lattice approach generates DIFFERENT configurations that may be in DIFFERENT basins:\n",
    "1. Start with 2 trees at (0,0) and (0.5, 0.5) with angles 0 and 180\n",
    "2. Optimize the 2-tree unit cell with SA\n",
    "3. Translate the unit cell in a grid pattern\n",
    "4. Run SA on the full configuration\n",
    "5. Apply deletion cascade to propagate improvements to smaller N\n",
    "\n",
    "### Next Experiment: Implement Super-Fast SA with Translations\n",
    "\n",
    "We should implement the jiweiliu kernel approach which:\n",
    "- Automatically explores all viable grid sizes\n",
    "- Uses Numba for acceleration\n",
    "- Applies deletion cascade\n",
    "- Gets ~0.15 improvement quickly\n",
    "\n",
    "This is fundamentally different from optimizing the current baseline!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
