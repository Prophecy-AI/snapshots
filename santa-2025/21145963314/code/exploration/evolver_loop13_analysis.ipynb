{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20d2f47",
   "metadata": {},
   "source": [
    "# Loop 13 Analysis\n",
    "\n",
    "Analyzing the current state and identifying next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae07ac29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T01:22:38.513147Z",
     "iopub.status.busy": "2026-01-20T01:22:38.512625Z",
     "iopub.status.idle": "2026-01-20T01:22:38.812011Z",
     "shell.execute_reply": "2026-01-20T01:22:38.811664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Tree shape constants\n",
    "TRUNK_W = 0.15\n",
    "TRUNK_H = 0.2\n",
    "BASE_W = 0.7\n",
    "MID_W = 0.4\n",
    "TOP_W = 0.25\n",
    "TIP_Y = 0.8\n",
    "TIER_1_Y = 0.5\n",
    "TIER_2_Y = 0.25\n",
    "BASE_Y = 0.0\n",
    "TRUNK_BOTTOM_Y = -TRUNK_H\n",
    "\n",
    "def get_tree_poly(x, y, deg):\n",
    "    coords = [\n",
    "        (0.0, TIP_Y), (TOP_W / 2.0, TIER_1_Y), (TOP_W / 4.0, TIER_1_Y),\n",
    "        (MID_W / 2.0, TIER_2_Y), (MID_W / 4.0, TIER_2_Y), (BASE_W / 2.0, BASE_Y),\n",
    "        (TRUNK_W / 2.0, BASE_Y), (TRUNK_W / 2.0, TRUNK_BOTTOM_Y),\n",
    "        (-TRUNK_W / 2.0, TRUNK_BOTTOM_Y), (-TRUNK_W / 2.0, BASE_Y),\n",
    "        (-BASE_W / 2.0, BASE_Y), (-MID_W / 4.0, TIER_2_Y), (-MID_W / 2.0, TIER_2_Y),\n",
    "        (-TOP_W / 4.0, TIER_1_Y), (-TOP_W / 2.0, TIER_1_Y),\n",
    "    ]\n",
    "    poly = Polygon(coords)\n",
    "    return affinity.translate(affinity.rotate(poly, deg, origin=(0, 0)), x, y)\n",
    "\n",
    "def rotate_point(x, y, cos_a, sin_a):\n",
    "    return x * cos_a - y * sin_a, x * sin_a + y * cos_a\n",
    "\n",
    "def get_tree_vertices(cx, cy, angle_deg):\n",
    "    angle_rad = angle_deg * math.pi / 180.0\n",
    "    cos_a = math.cos(angle_rad)\n",
    "    sin_a = math.sin(angle_rad)\n",
    "    pts = [\n",
    "        [0.0, TIP_Y], [TOP_W / 2.0, TIER_1_Y], [TOP_W / 4.0, TIER_1_Y],\n",
    "        [MID_W / 2.0, TIER_2_Y], [MID_W / 4.0, TIER_2_Y], [BASE_W / 2.0, BASE_Y],\n",
    "        [TRUNK_W / 2.0, BASE_Y], [TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "        [-TRUNK_W / 2.0, TRUNK_BOTTOM_Y], [-TRUNK_W / 2.0, BASE_Y],\n",
    "        [-BASE_W / 2.0, BASE_Y], [-MID_W / 4.0, TIER_2_Y], [-MID_W / 2.0, TIER_2_Y],\n",
    "        [-TOP_W / 4.0, TIER_1_Y], [-TOP_W / 2.0, TIER_1_Y],\n",
    "    ]\n",
    "    vertices = []\n",
    "    for px, py in pts:\n",
    "        rx, ry = rotate_point(px, py, cos_a, sin_a)\n",
    "        vertices.append((rx + cx, ry + cy))\n",
    "    return vertices\n",
    "\n",
    "def calculate_score(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    for col in ['x', 'y', 'deg', 'angle']:\n",
    "        if col in df.columns and df[col].dtype == object:\n",
    "            df[col] = df[col].astype(str).str.replace('s', '').astype(float)\n",
    "    angle_col = 'deg' if 'deg' in df.columns else 'angle'\n",
    "    \n",
    "    total = 0.0\n",
    "    scores = {}\n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        group = df[df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "        if len(group) != n:\n",
    "            continue\n",
    "        xs = group['x'].values\n",
    "        ys = group['y'].values\n",
    "        degs = group[angle_col].values\n",
    "        \n",
    "        min_x = min_y = 1e10\n",
    "        max_x = max_y = -1e10\n",
    "        for i in range(n):\n",
    "            verts = get_tree_vertices(xs[i], ys[i], degs[i])\n",
    "            for vx, vy in verts:\n",
    "                if vx < min_x: min_x = vx\n",
    "                if vx > max_x: max_x = vx\n",
    "                if vy < min_y: min_y = vy\n",
    "                if vy > max_y: max_y = vy\n",
    "        \n",
    "        side = max(max_x - min_x, max_y - min_y)\n",
    "        score = side * side / n\n",
    "        scores[n] = score\n",
    "        total += score\n",
    "    \n",
    "    return total, scores\n",
    "\n",
    "print(\"Functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64345bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T01:22:38.813108Z",
     "iopub.status.busy": "2026-01-20T01:22:38.812978Z",
     "iopub.status.idle": "2026-01-20T01:22:40.581709Z",
     "shell.execute_reply": "2026-01-20T01:22:40.581314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CURRENT STATE ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current submission score: 70.659493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (saspav_latest) score: 70.659958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eazy output score: 70.659943\n",
      "\n",
      "Target: 68.919154\n",
      "Gap from current: 1.740339 (2.53%)\n",
      "Gap from baseline: 1.740804 (2.53%)\n"
     ]
    }
   ],
   "source": [
    "# Current state analysis\n",
    "print(\"=== CURRENT STATE ===\")\n",
    "print()\n",
    "\n",
    "# Check current submission\n",
    "current_score, current_scores = calculate_score('/home/submission/submission.csv')\n",
    "print(f\"Current submission score: {current_score:.6f}\")\n",
    "\n",
    "# Check baseline\n",
    "baseline_score, baseline_scores = calculate_score('/home/code/external_data/saspav_latest/santa-2025.csv')\n",
    "print(f\"Baseline (saspav_latest) score: {baseline_score:.6f}\")\n",
    "\n",
    "# Check eazy output\n",
    "eazy_score, eazy_scores = calculate_score('/home/code/experiments/017_just_luck_multiphase/eazy_output.csv')\n",
    "print(f\"Eazy output score: {eazy_score:.6f}\")\n",
    "\n",
    "# Target\n",
    "target = 68.919154\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Gap from current: {current_score - target:.6f} ({(current_score - target)/target*100:.2f}%)\")\n",
    "print(f\"Gap from baseline: {baseline_score - target:.6f} ({(baseline_score - target)/target*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6236a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T01:22:40.582808Z",
     "iopub.status.busy": "2026-01-20T01:22:40.582699Z",
     "iopub.status.idle": "2026-01-20T01:22:40.586604Z",
     "shell.execute_reply": "2026-01-20T01:22:40.586241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PER-N COMPARISON (current vs baseline) ===\n",
      "\n",
      "N values where current differs from baseline: 1\n",
      "\n",
      "Top 10 improvements (current better than baseline):\n",
      "  N=65: baseline=0.363793, current=0.363328, improvement=0.000466\n",
      "\n",
      "Top 10 regressions (current worse than baseline):\n",
      "  N=65: baseline=0.363793, current=0.363328, regression=-0.000466\n"
     ]
    }
   ],
   "source": [
    "# Compare current vs baseline per N\n",
    "print(\"\\n=== PER-N COMPARISON (current vs baseline) ===\")\n",
    "print()\n",
    "\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    if n in current_scores and n in baseline_scores:\n",
    "        diff = baseline_scores[n] - current_scores[n]\n",
    "        if abs(diff) > 1e-9:\n",
    "            improvements.append((n, baseline_scores[n], current_scores[n], diff))\n",
    "\n",
    "print(f\"N values where current differs from baseline: {len(improvements)}\")\n",
    "if improvements:\n",
    "    print(\"\\nTop 10 improvements (current better than baseline):\")\n",
    "    for n, base, curr, diff in sorted(improvements, key=lambda x: -x[3])[:10]:\n",
    "        print(f\"  N={n}: baseline={base:.6f}, current={curr:.6f}, improvement={diff:.6f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 regressions (current worse than baseline):\")\n",
    "    for n, base, curr, diff in sorted(improvements, key=lambda x: x[3])[:10]:\n",
    "        print(f\"  N={n}: baseline={base:.6f}, current={curr:.6f}, regression={-diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d8225f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T01:22:40.587502Z",
     "iopub.status.busy": "2026-01-20T01:22:40.587401Z",
     "iopub.status.idle": "2026-01-20T01:22:40.592004Z",
     "shell.execute_reply": "2026-01-20T01:22:40.591600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GAP ANALYSIS ===\n",
      "\n",
      "Top 20 N values by score contribution:\n",
      "  N=1: score=0.661250 (0.94% of total)\n",
      "  N=2: score=0.450779 (0.64% of total)\n",
      "  N=3: score=0.434745 (0.62% of total)\n",
      "  N=5: score=0.416850 (0.59% of total)\n",
      "  N=4: score=0.416545 (0.59% of total)\n",
      "  N=7: score=0.399897 (0.57% of total)\n",
      "  N=6: score=0.399610 (0.57% of total)\n",
      "  N=9: score=0.387415 (0.55% of total)\n",
      "  N=8: score=0.385407 (0.55% of total)\n",
      "  N=15: score=0.379203 (0.54% of total)\n",
      "  N=10: score=0.376630 (0.53% of total)\n",
      "  N=21: score=0.376451 (0.53% of total)\n",
      "  N=20: score=0.376057 (0.53% of total)\n",
      "  N=11: score=0.375736 (0.53% of total)\n",
      "  N=22: score=0.375258 (0.53% of total)\n",
      "  N=16: score=0.374128 (0.53% of total)\n",
      "  N=26: score=0.373997 (0.53% of total)\n",
      "  N=12: score=0.372724 (0.53% of total)\n",
      "  N=13: score=0.372294 (0.53% of total)\n",
      "  N=25: score=0.372144 (0.53% of total)\n",
      "\n",
      "=== SMALL N ANALYSIS ===\n",
      "  N=1: score=0.661250\n",
      "  N=2: score=0.450779\n",
      "  N=3: score=0.434745\n",
      "  N=4: score=0.416545\n",
      "  N=5: score=0.416850\n",
      "  N=6: score=0.399610\n",
      "  N=7: score=0.399897\n",
      "  N=8: score=0.385407\n",
      "  N=9: score=0.387415\n",
      "  N=10: score=0.376630\n"
     ]
    }
   ],
   "source": [
    "# Analyze which N values contribute most to the gap\n",
    "print(\"\\n=== GAP ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "# Calculate contribution to gap for each N\n",
    "gap_contributions = []\n",
    "for n in range(1, 201):\n",
    "    if n in current_scores:\n",
    "        contribution = current_scores[n]\n",
    "        gap_contributions.append((n, contribution, contribution / current_score * 100))\n",
    "\n",
    "# Sort by contribution\n",
    "gap_contributions.sort(key=lambda x: -x[1])\n",
    "\n",
    "print(\"Top 20 N values by score contribution:\")\n",
    "for n, score, pct in gap_contributions[:20]:\n",
    "    print(f\"  N={n}: score={score:.6f} ({pct:.2f}% of total)\")\n",
    "\n",
    "# Small N analysis\n",
    "print(\"\\n=== SMALL N ANALYSIS ===\")\n",
    "for n in range(1, 11):\n",
    "    if n in current_scores:\n",
    "        print(f\"  N={n}: score={current_scores[n]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b09de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the corner extraction approach could achieve\n",
    "print(\"\\n=== CORNER EXTRACTION POTENTIAL ===\")\n",
    "print()\n",
    "\n",
    "# Load baseline\n",
    "df = pd.read_csv('/home/code/external_data/saspav_latest/santa-2025.csv')\n",
    "for col in ['x', 'y', 'deg']:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].astype(str).str.replace('s', '').astype(float)\n",
    "\n",
    "# For a sample large N, check if corner subsets could beat smaller N\n",
    "def extract_corner_subsets(df, n_large):\n",
    "    prefix = f\"{n_large:03d}_\"\n",
    "    group = df[df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "    if len(group) != n_large:\n",
    "        return {}\n",
    "    \n",
    "    xs = group['x'].values\n",
    "    ys = group['y'].values\n",
    "    degs = group['deg'].values\n",
    "    \n",
    "    # Create tree list with polygons\n",
    "    trees = []\n",
    "    for i in range(n_large):\n",
    "        poly = get_tree_poly(xs[i], ys[i], degs[i])\n",
    "        trees.append({'x': xs[i], 'y': ys[i], 'deg': degs[i], 'poly': poly})\n",
    "    \n",
    "    # Get bounds\n",
    "    all_polys = [t['poly'] for t in trees]\n",
    "    bounds = unary_union(all_polys).bounds\n",
    "    \n",
    "    results = {}\n",
    "    corners = [\n",
    "        (bounds[0], bounds[1]),  # bottom-left\n",
    "        (bounds[0], bounds[3]),  # top-left\n",
    "        (bounds[2], bounds[1]),  # bottom-right\n",
    "        (bounds[2], bounds[3]),  # top-right\n",
    "    ]\n",
    "    \n",
    "    for corner_x, corner_y in corners:\n",
    "        # Calculate max distance to corner for each tree\n",
    "        tree_distances = []\n",
    "        for tree in trees:\n",
    "            poly_bounds = tree['poly'].bounds\n",
    "            max_dist = max(\n",
    "                abs(poly_bounds[0] - corner_x),\n",
    "                abs(poly_bounds[2] - corner_x),\n",
    "                abs(poly_bounds[1] - corner_y),\n",
    "                abs(poly_bounds[3] - corner_y),\n",
    "            )\n",
    "            tree_distances.append((max_dist, tree))\n",
    "        \n",
    "        tree_distances.sort(key=lambda x: x[0])\n",
    "        \n",
    "        subset = []\n",
    "        for dist, tree in tree_distances:\n",
    "            subset.append(tree)\n",
    "            small_n = len(subset)\n",
    "            if small_n >= n_large:\n",
    "                break\n",
    "            \n",
    "            # Calculate subset score\n",
    "            subset_polys = [t['poly'] for t in subset]\n",
    "            subset_bounds = unary_union(subset_polys).bounds\n",
    "            width = subset_bounds[2] - subset_bounds[0]\n",
    "            height = subset_bounds[3] - subset_bounds[1]\n",
    "            side = max(width, height)\n",
    "            subset_score = side * side / small_n\n",
    "            \n",
    "            if small_n not in results or subset_score < results[small_n][0]:\n",
    "                results[small_n] = (subset_score, subset)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test on multiple large N values\n",
    "print(\"Testing corner extraction on multiple large N values...\")\n",
    "all_improvements = []\n",
    "for n_large in [50, 100, 111, 150, 200]:\n",
    "    subsets = extract_corner_subsets(df, n_large)\n",
    "    for small_n, (subset_score, _) in subsets.items():\n",
    "        if small_n in baseline_scores and subset_score < baseline_scores[small_n]:\n",
    "            all_improvements.append((small_n, n_large, baseline_scores[small_n], subset_score, baseline_scores[small_n] - subset_score))\n",
    "\n",
    "print(f\"\\nFound {len(all_improvements)} potential improvements from corner extraction\")\n",
    "if all_improvements:\n",
    "    print(\"\\nTop 20 improvements:\")\n",
    "    for n, from_n, base, sub, imp in sorted(all_improvements, key=lambda x: -x[4])[:20]:\n",
    "        print(f\"  N={n} (from N={from_n}): baseline={base:.6f}, subset={sub:.6f}, improvement={imp:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
