{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd755245",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis\n",
    "\n",
    "## Situation Analysis\n",
    "\n",
    "Current best: 70.676102\n",
    "Target: 68.919154\n",
    "Gap: 1.756948 (2.49%)\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the per-N breakdown of the gap?\n",
    "2. Which N values have the most room for improvement?\n",
    "3. Are there better solutions in the pre-optimized CSVs that we haven't used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65188544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:15:48.340428Z",
     "iopub.status.busy": "2026-01-19T18:15:48.339973Z",
     "iopub.status.idle": "2026-01-19T18:15:48.681717Z",
     "shell.execute_reply": "2026-01-19T18:15:48.681316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "import glob\n",
    "import os\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda38bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:15:48.682807Z",
     "iopub.status.busy": "2026-01-19T18:15:48.682668Z",
     "iopub.status.idle": "2026-01-19T18:15:48.688778Z",
     "shell.execute_reply": "2026-01-19T18:15:48.688415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined\n"
     ]
    }
   ],
   "source": [
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "        \n",
    "        vertices = []\n",
    "        for tx, ty in zip(TX, TY):\n",
    "            vertices.append((float(Decimal(str(tx)) * scale_factor), \n",
    "                           float(Decimal(str(ty)) * scale_factor)))\n",
    "        initial_polygon = Polygon(vertices)\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor)\n",
    "        )\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return val[1:]\n",
    "    return str(val)\n",
    "\n",
    "def load_trees_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    rows = df[df['id'].str.startswith(prefix)]\n",
    "    trees = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def calculate_side(trees):\n",
    "    if not trees:\n",
    "        return Decimal('0')\n",
    "    all_polygons = [t.polygon for t in trees]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    minx = Decimal(bounds[0]) / scale_factor\n",
    "    miny = Decimal(bounds[1]) / scale_factor\n",
    "    maxx = Decimal(bounds[2]) / scale_factor\n",
    "    maxy = Decimal(bounds[3]) / scale_factor\n",
    "    return max(maxx - minx, maxy - miny)\n",
    "\n",
    "def calculate_score_for_n(trees, n):\n",
    "    side = calculate_side(trees)\n",
    "    return float(side * side / n)\n",
    "\n",
    "print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fdb775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:15:48.689721Z",
     "iopub.status.busy": "2026-01-19T18:15:48.689627Z",
     "iopub.status.idle": "2026-01-19T18:15:53.461875Z",
     "shell.execute_reply": "2026-01-19T18:15:53.461484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded baseline: 20100 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total baseline score: 70.676102\n",
      "Target: 68.919154\n",
      "Gap: 1.756948\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025-csv/santa-2025.csv'\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "print(f'Loaded baseline: {len(baseline_df)} rows')\n",
    "\n",
    "# Calculate per-N scores\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees_for_n(baseline_df, n)\n",
    "    baseline_scores[n] = calculate_score_for_n(trees, n)\n",
    "\n",
    "total_baseline = sum(baseline_scores.values())\n",
    "print(f'\\nTotal baseline score: {total_baseline:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap: {total_baseline - 68.919154:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all available pre-optimized CSVs and find best per-N\n",
    "csv_paths = glob.glob('/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/**/*.csv', recursive=True)\n",
    "print(f'Found {len(csv_paths)} CSV files')\n",
    "\n",
    "# Load each CSV and calculate scores\n",
    "all_scores = {}  # {path: {n: score}}\n",
    "\n",
    "for path in csv_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        scores = {}\n",
    "        for n in range(1, 201):\n",
    "            trees = load_trees_for_n(df, n)\n",
    "            if len(trees) == n:\n",
    "                scores[n] = calculate_score_for_n(trees, n)\n",
    "        if len(scores) == 200:\n",
    "            all_scores[path] = scores\n",
    "            total = sum(scores.values())\n",
    "            print(f'{os.path.basename(path)}: {total:.6f}')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f'\\nLoaded {len(all_scores)} valid CSV files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best score per N across all CSVs\n",
    "best_per_n = {}\n",
    "best_source_per_n = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    for path, scores in all_scores.items():\n",
    "        if n in scores and scores[n] < best_score:\n",
    "            best_score = scores[n]\n",
    "            best_source = path\n",
    "    best_per_n[n] = best_score\n",
    "    best_source_per_n[n] = best_source\n",
    "\n",
    "# Calculate best possible ensemble score\n",
    "best_ensemble_score = sum(best_per_n.values())\n",
    "print(f'Best possible ensemble score: {best_ensemble_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap to target: {best_ensemble_score - 68.919154:.6f}')\n",
    "print(f'\\nBaseline score: {total_baseline:.6f}')\n",
    "print(f'Improvement from ensemble: {total_baseline - best_ensemble_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd529ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find N values where baseline is NOT the best\n",
    "improvable_ns = []\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n] < baseline_scores[n] - 1e-9:\n",
    "        improvement = baseline_scores[n] - best_per_n[n]\n",
    "        improvable_ns.append((n, improvement, baseline_scores[n], best_per_n[n], best_source_per_n[n]))\n",
    "\n",
    "if improvable_ns:\n",
    "    print(f'Found {len(improvable_ns)} N values where better solutions exist:')\n",
    "    improvable_ns.sort(key=lambda x: -x[1])  # Sort by improvement\n",
    "    for n, imp, base, best, source in improvable_ns[:20]:\n",
    "        print(f'  N={n}: baseline={base:.6f}, best={best:.6f}, improvement={imp:.9f}, source={os.path.basename(source)}')\n",
    "else:\n",
    "    print('Baseline is already the best for all N values!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score contribution by N range\n",
    "ranges = [\n",
    "    (1, 10, 'Small (1-10)'),\n",
    "    (11, 50, 'Medium (11-50)'),\n",
    "    (51, 100, 'Large (51-100)'),\n",
    "    (101, 200, 'Very Large (101-200)')\n",
    "]\n",
    "\n",
    "print('Score contribution by N range:')\n",
    "print('='*60)\n",
    "for start, end, name in ranges:\n",
    "    baseline_sum = sum(baseline_scores[n] for n in range(start, end+1))\n",
    "    best_sum = sum(best_per_n[n] for n in range(start, end+1))\n",
    "    improvement = baseline_sum - best_sum\n",
    "    pct = baseline_sum / total_baseline * 100\n",
    "    print(f'{name}:')\n",
    "    print(f'  Baseline: {baseline_sum:.6f} ({pct:.1f}% of total)')\n",
    "    print(f'  Best available: {best_sum:.6f}')\n",
    "    print(f'  Potential improvement: {improvement:.6f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print('='*60)\n",
    "print('SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Current baseline: {total_baseline:.6f}')\n",
    "print(f'Best ensemble from available CSVs: {best_ensemble_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'\\nGap analysis:')\n",
    "print(f'  Baseline to target: {total_baseline - 68.919154:.6f}')\n",
    "print(f'  Best ensemble to target: {best_ensemble_score - 68.919154:.6f}')\n",
    "print(f'\\nConclusion:')\n",
    "if best_ensemble_score < total_baseline - 0.001:\n",
    "    print(f'  There are better solutions available! Ensemble could improve by {total_baseline - best_ensemble_score:.6f}')\n",
    "else:\n",
    "    print(f'  Baseline is already the best available from pre-optimized CSVs.')\n",
    "    print(f'  Need to run longer optimization or try fundamentally different approaches.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
