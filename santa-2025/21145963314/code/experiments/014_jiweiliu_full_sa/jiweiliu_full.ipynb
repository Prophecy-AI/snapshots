{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ee61da",
   "metadata": {},
   "source": [
    "# Full jiweiliu SA Kernel Implementation\n",
    "\n",
    "This notebook implements the COMPLETE jiweiliu kernel with:\n",
    "1. Pre-optimized seeds\n",
    "2. Grid generation with append support\n",
    "3. SA optimization on EACH grid configuration (100,000 moves per config)\n",
    "4. Deletion cascade\n",
    "5. Multiprocessing for parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d26cb97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:06:55.357728Z",
     "iopub.status.busy": "2026-01-19T21:06:55.357346Z",
     "iopub.status.idle": "2026-01-19T21:06:55.759011Z",
     "shell.execute_reply": "2026-01-19T21:06:55.758614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 26\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from numba.typed import List as NumbaList\n",
    "\n",
    "print(f'CPU count: {cpu_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8fd373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:06:55.760111Z",
     "iopub.status.busy": "2026-01-19T21:06:55.759967Z",
     "iopub.status.idle": "2026-01-19T21:06:55.762634Z",
     "shell.execute_reply": "2026-01-19T21:06:55.762265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tree shape constants (must match official spec)\n",
    "TRUNK_W = 0.15\n",
    "TRUNK_H = 0.2\n",
    "BASE_W = 0.7\n",
    "MID_W = 0.4\n",
    "TOP_W = 0.25\n",
    "TIP_Y = 0.8\n",
    "TIER_1_Y = 0.5\n",
    "TIER_2_Y = 0.25\n",
    "BASE_Y = 0.0\n",
    "TRUNK_BOTTOM_Y = -TRUNK_H\n",
    "\n",
    "# Maximum distance between tree centers for possible overlap\n",
    "MAX_OVERLAP_DIST = 2.0\n",
    "MAX_OVERLAP_DIST_SQ = MAX_OVERLAP_DIST * MAX_OVERLAP_DIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1d278a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:06:55.763633Z",
     "iopub.status.busy": "2026-01-19T21:06:55.763531Z",
     "iopub.status.idle": "2026-01-19T21:06:55.769765Z",
     "shell.execute_reply": "2026-01-19T21:06:55.769425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Geometry helper functions\n",
    "@njit(cache=True)\n",
    "def rotate_point(x, y, cos_a, sin_a):\n",
    "    return x * cos_a - y * sin_a, x * sin_a + y * cos_a\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_tree_vertices(cx, cy, angle_deg):\n",
    "    \"\"\"Get 15 vertices of tree polygon at given position and angle.\"\"\"\n",
    "    angle_rad = angle_deg * math.pi / 180.0\n",
    "    cos_a = math.cos(angle_rad)\n",
    "    sin_a = math.sin(angle_rad)\n",
    "    vertices = np.empty((15, 2), dtype=np.float64)\n",
    "    pts = np.array([\n",
    "        [0.0, TIP_Y],\n",
    "        [TOP_W / 2.0, TIER_1_Y],\n",
    "        [TOP_W / 4.0, TIER_1_Y],\n",
    "        [MID_W / 2.0, TIER_2_Y],\n",
    "        [MID_W / 4.0, TIER_2_Y],\n",
    "        [BASE_W / 2.0, BASE_Y],\n",
    "        [TRUNK_W / 2.0, BASE_Y],\n",
    "        [TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "        [-TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "        [-TRUNK_W / 2.0, BASE_Y],\n",
    "        [-BASE_W / 2.0, BASE_Y],\n",
    "        [-MID_W / 4.0, TIER_2_Y],\n",
    "        [-MID_W / 2.0, TIER_2_Y],\n",
    "        [-TOP_W / 4.0, TIER_1_Y],\n",
    "        [-TOP_W / 2.0, TIER_1_Y],\n",
    "    ], dtype=np.float64)\n",
    "    for i in range(15):\n",
    "        rx, ry = rotate_point(pts[i, 0], pts[i, 1], cos_a, sin_a)\n",
    "        vertices[i, 0] = rx + cx\n",
    "        vertices[i, 1] = ry + cy\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d450098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.052088Z",
     "iopub.status.busy": "2026-01-19T21:07:11.051680Z",
     "iopub.status.idle": "2026-01-19T21:07:11.059427Z",
     "shell.execute_reply": "2026-01-19T21:07:11.059066Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def polygon_bounds(vertices):\n",
    "    \"\"\"Get bounding box of polygon vertices.\"\"\"\n",
    "    min_x = vertices[0, 0]\n",
    "    min_y = vertices[0, 1]\n",
    "    max_x = vertices[0, 0]\n",
    "    max_y = vertices[0, 1]\n",
    "    for i in range(1, vertices.shape[0]):\n",
    "        x = vertices[i, 0]\n",
    "        y = vertices[i, 1]\n",
    "        if x < min_x:\n",
    "            min_x = x\n",
    "        if x > max_x:\n",
    "            max_x = x\n",
    "        if y < min_y:\n",
    "            min_y = y\n",
    "        if y > max_y:\n",
    "            max_y = y\n",
    "    return min_x, min_y, max_x, max_y\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def point_in_polygon(px, py, vertices):\n",
    "    \"\"\"Check if point is inside polygon using ray casting.\"\"\"\n",
    "    n = vertices.shape[0]\n",
    "    inside = False\n",
    "    j = n - 1\n",
    "    for i in range(n):\n",
    "        xi, yi = vertices[i, 0], vertices[i, 1]\n",
    "        xj, yj = vertices[j, 0], vertices[j, 1]\n",
    "        if ((yi > py) != (yj > py)) and (px < (xj - xi) * (py - yi) / (yj - yi) + xi):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "    return inside\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def segments_intersect(p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y):\n",
    "    \"\"\"Check if two line segments intersect.\"\"\"\n",
    "    dax = p2x - p1x\n",
    "    day = p2y - p1y\n",
    "    dbx = p4x - p3x\n",
    "    dby = p4y - p3y\n",
    "    d1x = p1x - p3x\n",
    "    d1y = p1y - p3y\n",
    "    d2x = p2x - p3x\n",
    "    d2y = p2y - p3y\n",
    "    cross_b1 = dbx * d1y - dby * d1x\n",
    "    cross_b2 = dbx * d2y - dby * d2x\n",
    "    if cross_b1 * cross_b2 > 0:\n",
    "        return False\n",
    "    d3x = p3x - p1x\n",
    "    d3y = p3y - p1y\n",
    "    d4x = p4x - p1x\n",
    "    d4y = p4y - p1y\n",
    "    cross_a1 = dax * d3y - day * d3x\n",
    "    cross_a2 = dax * d4y - day * d4x\n",
    "    if cross_a1 * cross_a2 > 0:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ce84d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.060766Z",
     "iopub.status.busy": "2026-01-19T21:07:11.060476Z",
     "iopub.status.idle": "2026-01-19T21:07:11.067348Z",
     "shell.execute_reply": "2026-01-19T21:07:11.066997Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def polygons_overlap(verts1, verts2, cx1, cy1, cx2, cy2):\n",
    "    \"\"\"Check if two polygons overlap (not just touch).\"\"\"\n",
    "    dx = cx2 - cx1\n",
    "    dy = cy2 - cy1\n",
    "    dist_sq = dx * dx + dy * dy\n",
    "    if dist_sq > MAX_OVERLAP_DIST_SQ:\n",
    "        return False\n",
    "    min_x1, min_y1, max_x1, max_y1 = polygon_bounds(verts1)\n",
    "    min_x2, min_y2, max_x2, max_y2 = polygon_bounds(verts2)\n",
    "    if max_x1 < min_x2 or max_x2 < min_x1 or max_y1 < min_y2 or max_y2 < min_y1:\n",
    "        return False\n",
    "    for i in range(verts1.shape[0]):\n",
    "        if point_in_polygon(verts1[i, 0], verts1[i, 1], verts2):\n",
    "            return True\n",
    "    for i in range(verts2.shape[0]):\n",
    "        if point_in_polygon(verts2[i, 0], verts2[i, 1], verts1):\n",
    "            return True\n",
    "    n1 = verts1.shape[0]\n",
    "    n2 = verts2.shape[0]\n",
    "    for i in range(n1):\n",
    "        j = (i + 1) % n1\n",
    "        p1x, p1y = verts1[i, 0], verts1[i, 1]\n",
    "        p2x, p2y = verts1[j, 0], verts1[j, 1]\n",
    "        for k in range(n2):\n",
    "            m = (k + 1) % n2\n",
    "            p3x, p3y = verts2[k, 0], verts2[k, 1]\n",
    "            p4x, p4y = verts2[m, 0], verts2[m, 1]\n",
    "            if segments_intersect(p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "    \"\"\"Check if any pair of polygons overlap.\"\"\"\n",
    "    n = len(all_vertices)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if polygons_overlap(all_vertices[i], all_vertices[j],\n",
    "                              centers_x[i], centers_y[i], centers_x[j], centers_y[j]):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69390c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.068258Z",
     "iopub.status.busy": "2026-01-19T21:07:11.068169Z",
     "iopub.status.idle": "2026-01-19T21:07:11.073207Z",
     "shell.execute_reply": "2026-01-19T21:07:11.072892Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def compute_bounding_box(all_vertices):\n",
    "    \"\"\"Compute overall bounding box of all polygons.\"\"\"\n",
    "    min_x = math.inf\n",
    "    min_y = math.inf\n",
    "    max_x = -math.inf\n",
    "    max_y = -math.inf\n",
    "    for verts in all_vertices:\n",
    "        x1, y1, x2, y2 = polygon_bounds(verts)\n",
    "        if x1 < min_x:\n",
    "            min_x = x1\n",
    "        if y1 < min_y:\n",
    "            min_y = y1\n",
    "        if x2 > max_x:\n",
    "            max_x = x2\n",
    "        if y2 > max_y:\n",
    "            max_y = y2\n",
    "    return min_x, min_y, max_x, max_y\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_side_length(all_vertices):\n",
    "    \"\"\"Get side length of bounding square.\"\"\"\n",
    "    min_x, min_y, max_x, max_y = compute_bounding_box(all_vertices)\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_score_numba(all_vertices):\n",
    "    \"\"\"Calculate score = max(width, height)^2 / n\"\"\"\n",
    "    side = get_side_length(all_vertices)\n",
    "    return side * side / len(all_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0b945d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.074182Z",
     "iopub.status.busy": "2026-01-19T21:07:11.074091Z",
     "iopub.status.idle": "2026-01-19T21:07:11.111816Z",
     "shell.execute_reply": "2026-01-19T21:07:11.111463Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y):\n",
    "    \"\"\"Create grid of tree vertices by translation with optional append.\"\"\"\n",
    "    n_seeds = len(seed_xs)\n",
    "    n_base = n_seeds * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_total = n_base + n_append_x + n_append_y\n",
    "\n",
    "    all_vertices = []\n",
    "    centers_x = np.empty(n_total, dtype=np.float64)\n",
    "    centers_y = np.empty(n_total, dtype=np.float64)\n",
    "\n",
    "    idx = 0\n",
    "    for s in range(n_seeds):\n",
    "        for col in range(ncols):\n",
    "            for row in range(nrows):\n",
    "                cx = seed_xs[s] + col * a\n",
    "                cy = seed_ys[s] + row * b\n",
    "                all_vertices.append(get_tree_vertices(cx, cy, seed_degs[s]))\n",
    "                centers_x[idx] = cx\n",
    "                centers_y[idx] = cy\n",
    "                idx += 1\n",
    "\n",
    "    if append_x and n_seeds > 1:\n",
    "        for row in range(nrows):\n",
    "            cx = seed_xs[1] + ncols * a\n",
    "            cy = seed_ys[1] + row * b\n",
    "            all_vertices.append(get_tree_vertices(cx, cy, seed_degs[1]))\n",
    "            centers_x[idx] = cx\n",
    "            centers_y[idx] = cy\n",
    "            idx += 1\n",
    "\n",
    "    if append_y and n_seeds > 1:\n",
    "        for col in range(ncols):\n",
    "            cx = seed_xs[1] + col * a\n",
    "            cy = seed_ys[1] + nrows * b\n",
    "            all_vertices.append(get_tree_vertices(cx, cy, seed_degs[1]))\n",
    "            centers_x[idx] = cx\n",
    "            centers_y[idx] = cy\n",
    "            idx += 1\n",
    "\n",
    "    return all_vertices, centers_x, centers_y\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_initial_translations(seed_xs, seed_ys, seed_degs):\n",
    "    \"\"\"Get initial translation lengths from seed bounding box.\"\"\"\n",
    "    seed_vertices = [get_tree_vertices(seed_xs[i], seed_ys[i], seed_degs[i]) for i in range(len(seed_xs))]\n",
    "    min_x, min_y, max_x, max_y = compute_bounding_box(seed_vertices)\n",
    "    return max_x - min_x, max_y - min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93a62c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.112914Z",
     "iopub.status.busy": "2026-01-19T21:07:11.112785Z",
     "iopub.status.idle": "2026-01-19T21:07:11.119639Z",
     "shell.execute_reply": "2026-01-19T21:07:11.119240Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_final_grid_positions_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y):\n",
    "    \"\"\"Get final tree positions for the optimized grid with append support.\"\"\"\n",
    "    n_seeds = len(seed_xs)\n",
    "    n_base = n_seeds * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_total = n_base + n_append_x + n_append_y\n",
    "\n",
    "    xs = np.empty(n_total, dtype=np.float64)\n",
    "    ys = np.empty(n_total, dtype=np.float64)\n",
    "    degs = np.empty(n_total, dtype=np.float64)\n",
    "\n",
    "    idx = 0\n",
    "    for s in range(n_seeds):\n",
    "        for col in range(ncols):\n",
    "            for row in range(nrows):\n",
    "                xs[idx] = seed_xs[s] + col * a\n",
    "                ys[idx] = seed_ys[s] + row * b\n",
    "                degs[idx] = seed_degs[s]\n",
    "                idx += 1\n",
    "\n",
    "    if append_x and n_seeds > 1:\n",
    "        for row in range(nrows):\n",
    "            xs[idx] = seed_xs[1] + ncols * a\n",
    "            ys[idx] = seed_ys[1] + row * b\n",
    "            degs[idx] = seed_degs[1]\n",
    "            idx += 1\n",
    "\n",
    "    if append_y and n_seeds > 1:\n",
    "        for col in range(ncols):\n",
    "            xs[idx] = seed_xs[1] + col * a\n",
    "            ys[idx] = seed_ys[1] + nrows * b\n",
    "            degs[idx] = seed_degs[1]\n",
    "            idx += 1\n",
    "\n",
    "    return xs, ys, degs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8358319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.120728Z",
     "iopub.status.busy": "2026-01-19T21:07:11.120620Z",
     "iopub.status.idle": "2026-01-19T21:07:11.132631Z",
     "shell.execute_reply": "2026-01-19T21:07:11.132311Z"
    }
   },
   "outputs": [],
   "source": [
    "# THE CRITICAL SA OPTIMIZATION FUNCTION\n",
    "@njit(cache=True)\n",
    "def sa_optimize_improved(\n",
    "    seed_xs_init,\n",
    "    seed_ys_init,\n",
    "    seed_degs_init,\n",
    "    a_init,\n",
    "    b_init,\n",
    "    ncols,\n",
    "    nrows,\n",
    "    append_x,\n",
    "    append_y,\n",
    "    Tmax,\n",
    "    Tmin,\n",
    "    nsteps,\n",
    "    nsteps_per_T,\n",
    "    position_delta,\n",
    "    angle_delta,\n",
    "    angle_delta2,\n",
    "    delta_t,\n",
    "    random_seed,\n",
    "):\n",
    "    \"\"\"Improved simulated annealing with translation optimization.\"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n_seeds = len(seed_xs_init)\n",
    "\n",
    "    seed_xs = seed_xs_init.copy()\n",
    "    seed_ys = seed_ys_init.copy()\n",
    "    seed_degs = seed_degs_init.copy()\n",
    "\n",
    "    a = a_init\n",
    "    b = b_init\n",
    "\n",
    "    all_vertices, centers_x, centers_y = create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y)\n",
    "    if has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "        a_test, b_test = get_initial_translations(seed_xs, seed_ys, seed_degs)\n",
    "        a = max(a, a_test * 1.5)\n",
    "        b = max(b, b_test * 1.5)\n",
    "        all_vertices, centers_x, centers_y = create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y)\n",
    "\n",
    "    current_score = calculate_score_numba(all_vertices)\n",
    "\n",
    "    best_score = current_score\n",
    "    best_xs = seed_xs.copy()\n",
    "    best_ys = seed_ys.copy()\n",
    "    best_degs = seed_degs.copy()\n",
    "    best_a = a\n",
    "    best_b = b\n",
    "\n",
    "    T = Tmax\n",
    "    Tfactor = -math.log(Tmax / Tmin)\n",
    "\n",
    "    n_move_types = n_seeds + 2\n",
    "\n",
    "    for step in range(nsteps):\n",
    "        for _ in range(nsteps_per_T):\n",
    "            move_type = np.random.randint(0, n_move_types)\n",
    "\n",
    "            if move_type < n_seeds:\n",
    "                i = move_type\n",
    "                old_x = seed_xs[i]\n",
    "                old_y = seed_ys[i]\n",
    "                old_deg = seed_degs[i]\n",
    "\n",
    "                dx = (np.random.random() * 2.0 - 1.0) * position_delta\n",
    "                dy = (np.random.random() * 2.0 - 1.0) * position_delta\n",
    "                ddeg = (np.random.random() * 2.0 - 1.0) * angle_delta\n",
    "\n",
    "                seed_xs[i] = old_x + dx\n",
    "                seed_ys[i] = old_y + dy\n",
    "                seed_degs[i] = (old_deg + ddeg) % 360.0\n",
    "\n",
    "            elif move_type == n_seeds:\n",
    "                old_a = a\n",
    "                old_b = b\n",
    "                da = (np.random.random() * 2.0 - 1.0) * delta_t\n",
    "                db = (np.random.random() * 2.0 - 1.0) * delta_t\n",
    "                a = old_a + old_a * da\n",
    "                b = old_b + old_b * db\n",
    "\n",
    "            else:\n",
    "                old_degs = seed_degs.copy()\n",
    "                ddeg = (np.random.random() * 2.0 - 1.0) * angle_delta2\n",
    "                for i in range(n_seeds):\n",
    "                    seed_degs[i] = (seed_degs[i] + ddeg) % 360.0\n",
    "\n",
    "            test_vertices, test_cx, test_cy = create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, 2, 2, False, False)\n",
    "            if has_any_overlap(test_vertices, test_cx, test_cy):\n",
    "                if move_type < n_seeds:\n",
    "                    seed_xs[move_type] = old_x\n",
    "                    seed_ys[move_type] = old_y\n",
    "                    seed_degs[move_type] = old_deg\n",
    "                elif move_type == n_seeds:\n",
    "                    a = old_a\n",
    "                    b = old_b\n",
    "                else:\n",
    "                    for i in range(n_seeds):\n",
    "                        seed_degs[i] = old_degs[i]\n",
    "                continue\n",
    "\n",
    "            new_vertices, new_cx, new_cy = create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y)\n",
    "\n",
    "            if has_any_overlap(new_vertices, new_cx, new_cy):\n",
    "                if move_type < n_seeds:\n",
    "                    seed_xs[move_type] = old_x\n",
    "                    seed_ys[move_type] = old_y\n",
    "                    seed_degs[move_type] = old_deg\n",
    "                elif move_type == n_seeds:\n",
    "                    a = old_a\n",
    "                    b = old_b\n",
    "                else:\n",
    "                    for i in range(n_seeds):\n",
    "                        seed_degs[i] = old_degs[i]\n",
    "                continue\n",
    "\n",
    "            new_score = calculate_score_numba(new_vertices)\n",
    "            delta = new_score - current_score\n",
    "\n",
    "            accept = False\n",
    "            if delta < 0:\n",
    "                accept = True\n",
    "            elif T > 1e-10:\n",
    "                if np.random.random() < math.exp(-delta / T):\n",
    "                    accept = True\n",
    "\n",
    "            if accept:\n",
    "                current_score = new_score\n",
    "                if new_score < best_score:\n",
    "                    best_score = new_score\n",
    "                    best_xs = seed_xs.copy()\n",
    "                    best_ys = seed_ys.copy()\n",
    "                    best_degs = seed_degs.copy()\n",
    "                    best_a = a\n",
    "                    best_b = b\n",
    "            else:\n",
    "                if move_type < n_seeds:\n",
    "                    seed_xs[move_type] = old_x\n",
    "                    seed_ys[move_type] = old_y\n",
    "                    seed_degs[move_type] = old_deg\n",
    "                elif move_type == n_seeds:\n",
    "                    a = old_a\n",
    "                    b = old_b\n",
    "                else:\n",
    "                    for i in range(n_seeds):\n",
    "                        seed_degs[i] = old_degs[i]\n",
    "\n",
    "        T = Tmax * math.exp(Tfactor * (step + 1) / nsteps)\n",
    "\n",
    "    return best_score, best_xs, best_ys, best_degs, best_a, best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c26137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.133627Z",
     "iopub.status.busy": "2026-01-19T21:07:11.133539Z",
     "iopub.status.idle": "2026-01-19T21:07:11.137462Z",
     "shell.execute_reply": "2026-01-19T21:07:11.137149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Worker function for multiprocessing\n",
    "def optimize_grid_config(args):\n",
    "    \"\"\"Optimize a single grid configuration (worker function for multiprocessing).\"\"\"\n",
    "    ncols, nrows, append_x, append_y, initial_seeds, a_init, b_init, params, seed = args\n",
    "\n",
    "    seed_xs = np.array([s[0] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_ys = np.array([s[1] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_degs = np.array([s[2] for s in initial_seeds], dtype=np.float64)\n",
    "\n",
    "    n_seeds = len(initial_seeds)\n",
    "    n_base = n_seeds * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_trees = n_base + n_append_x + n_append_y\n",
    "\n",
    "    best_score, best_xs, best_ys, best_degs, best_a, best_b = sa_optimize_improved(\n",
    "        seed_xs, seed_ys, seed_degs,\n",
    "        a_init, b_init,\n",
    "        ncols, nrows,\n",
    "        append_x, append_y,\n",
    "        params[\"Tmax\"],\n",
    "        params[\"Tmin\"],\n",
    "        params[\"nsteps\"],\n",
    "        params[\"nsteps_per_T\"],\n",
    "        params[\"position_delta\"],\n",
    "        params[\"angle_delta\"],\n",
    "        params[\"angle_delta2\"],\n",
    "        params[\"delta_t\"],\n",
    "        seed,\n",
    "    )\n",
    "\n",
    "    final_xs, final_ys, final_degs = get_final_grid_positions_extended(\n",
    "        best_xs, best_ys, best_degs, best_a, best_b, ncols, nrows, append_x, append_y\n",
    "    )\n",
    "\n",
    "    tree_data = [(final_xs[i], final_ys[i], final_degs[i]) for i in range(len(final_xs))]\n",
    "\n",
    "    return n_trees, best_score, tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b678c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:07:11.138347Z",
     "iopub.status.busy": "2026-01-19T21:07:11.138254Z",
     "iopub.status.idle": "2026-01-19T21:07:11.143720Z",
     "shell.execute_reply": "2026-01-19T21:07:11.143412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deletion cascade function\n",
    "@njit(cache=True)\n",
    "def deletion_cascade_numba(all_xs, all_ys, all_degs, group_sizes):\n",
    "    \"\"\"Apply tree deletion cascade using numba.\"\"\"\n",
    "    group_start = np.zeros(201, dtype=np.int64)\n",
    "    for n in range(1, 201):\n",
    "        group_start[n] = group_start[n-1] + (n - 1) if n > 1 else 0\n",
    "\n",
    "    new_xs = all_xs.copy()\n",
    "    new_ys = all_ys.copy()\n",
    "    new_degs = all_degs.copy()\n",
    "\n",
    "    side_lengths = np.zeros(201, dtype=np.float64)\n",
    "    for n in range(1, 201):\n",
    "        start = group_start[n]\n",
    "        end = start + n\n",
    "        vertices = [get_tree_vertices(new_xs[i], new_ys[i], new_degs[i]) for i in range(start, end)]\n",
    "        side_lengths[n] = get_side_length(vertices)\n",
    "\n",
    "    for n in range(200, 1, -1):\n",
    "        start_n = group_start[n]\n",
    "        end_n = start_n + n\n",
    "        start_prev = group_start[n - 1]\n",
    "\n",
    "        best_side = side_lengths[n - 1]\n",
    "        best_delete_idx = -1\n",
    "\n",
    "        for del_idx in range(n):\n",
    "            vertices = []\n",
    "            for i in range(n):\n",
    "                if i != del_idx:\n",
    "                    idx = start_n + i\n",
    "                    vertices.append(get_tree_vertices(new_xs[idx], new_ys[idx], new_degs[idx]))\n",
    "\n",
    "            candidate_side = get_side_length(vertices)\n",
    "            if candidate_side < best_side:\n",
    "                best_side = candidate_side\n",
    "                best_delete_idx = del_idx\n",
    "\n",
    "        if best_delete_idx >= 0:\n",
    "            out_idx = start_prev\n",
    "            for i in range(n):\n",
    "                if i != best_delete_idx:\n",
    "                    in_idx = start_n + i\n",
    "                    new_xs[out_idx] = new_xs[in_idx]\n",
    "                    new_ys[out_idx] = new_ys[in_idx]\n",
    "                    new_degs[out_idx] = new_degs[in_idx]\n",
    "                    out_idx += 1\n",
    "            side_lengths[n - 1] = best_side\n",
    "\n",
    "    return new_xs, new_ys, new_degs, side_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06dd0876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:03.670874Z",
     "iopub.status.busy": "2026-01-19T21:08:03.670381Z",
     "iopub.status.idle": "2026-01-19T21:08:03.675796Z",
     "shell.execute_reply": "2026-01-19T21:08:03.675440Z"
    }
   },
   "outputs": [],
   "source": [
    "# I/O helpers\n",
    "def load_submission_data(filepath):\n",
    "    \"\"\"Load submission and return flattened arrays.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Handle 's' prefix in values (saspav format)\n",
    "    for col in ['x', 'y', 'deg']:\n",
    "        if col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                df[col] = df[col].str.replace('s', '').astype(float)\n",
    "    \n",
    "    # Handle different column names\n",
    "    angle_col = 'deg' if 'deg' in df.columns else 'angle'\n",
    "\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    all_degs = []\n",
    "\n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        group = df[df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "        all_xs.extend(group[\"x\"].values)\n",
    "        all_ys.extend(group[\"y\"].values)\n",
    "        all_degs.extend(group[angle_col].values)\n",
    "\n",
    "    return np.array(all_xs), np.array(all_ys), np.array(all_degs)\n",
    "\n",
    "\n",
    "def calculate_total_score(all_xs, all_ys, all_degs):\n",
    "    \"\"\"Calculate total score from flattened arrays.\"\"\"\n",
    "    total = 0.0\n",
    "    idx = 0\n",
    "    for n in range(1, 201):\n",
    "        vertices = [get_tree_vertices(all_xs[idx + i], all_ys[idx + i], all_degs[idx + i]) for i in range(n)]\n",
    "        side = get_side_length(vertices)\n",
    "        total += side * side / n\n",
    "        idx += n\n",
    "    return total\n",
    "\n",
    "\n",
    "def save_submission(filepath, all_xs, all_ys, all_degs):\n",
    "    \"\"\"Save submission to CSV.\"\"\"\n",
    "    rows = []\n",
    "    idx = 0\n",
    "    for n in range(1, 201):\n",
    "        for i in range(n):\n",
    "            rows.append({\n",
    "                \"id\": f\"{n:03d}_{i:03d}\",\n",
    "                \"x\": all_xs[idx],\n",
    "                \"y\": all_ys[idx],\n",
    "                \"angle\": all_degs[idx],\n",
    "            })\n",
    "            idx += 1\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff8292e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:03.677045Z",
     "iopub.status.busy": "2026-01-19T21:08:03.676792Z",
     "iopub.status.idle": "2026-01-19T21:08:05.281752Z",
     "shell.execute_reply": "2026-01-19T21:08:05.281345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline total score: 70.659958\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_path = '/home/code/external_data/saspav_latest/santa-2025.csv'\n",
    "baseline_xs, baseline_ys, baseline_degs = load_submission_data(baseline_path)\n",
    "baseline_total = calculate_total_score(baseline_xs, baseline_ys, baseline_degs)\n",
    "print(f\"Baseline total score: {baseline_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e6a281",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:05.282979Z",
     "iopub.status.busy": "2026-01-19T21:08:05.282819Z",
     "iopub.status.idle": "2026-01-19T21:08:05.285670Z",
     "shell.execute_reply": "2026-01-19T21:08:05.285360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1: (-4.191683864412409, -4.498489528496051, 74.54421568660419)\n",
      "Seed 2: (-4.92202045352307, -4.727639556649786, 254.5401905706735)\n",
      "a_init: 0.8744896974945239, b_init: 0.7499641699190263\n"
     ]
    }
   ],
   "source": [
    "# Pre-optimized seeds from jiweiliu kernel\n",
    "initial_seeds = [\n",
    "    (-4.191683864412409, -4.498489528496051, 74.54421568660419),\n",
    "    (-4.92202045352307, -4.727639556649786, 254.5401905706735),\n",
    "]\n",
    "\n",
    "# Initial translation lengths\n",
    "a_init = 0.8744896974945239\n",
    "b_init = 0.7499641699190263\n",
    "\n",
    "print(f\"Seed 1: {initial_seeds[0]}\")\n",
    "print(f\"Seed 2: {initial_seeds[1]}\")\n",
    "print(f\"a_init: {a_init}, b_init: {b_init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a11d2cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:05.286519Z",
     "iopub.status.busy": "2026-01-19T21:08:05.286418Z",
     "iopub.status.idle": "2026-01-19T21:08:05.292235Z",
     "shell.execute_reply": "2026-01-19T21:08:05.291901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 197 grid configurations\n"
     ]
    }
   ],
   "source": [
    "# Generate grid configurations\n",
    "grid_configs = [\n",
    "    (3, 5, False, False),   # 30 trees\n",
    "    (4, 5, False, False),   # 40 trees\n",
    "    (4, 6, False, False),   # 48 trees\n",
    "    (4, 7, False, False),   # 56 trees\n",
    "    (5, 7, False, True),    # 75 trees\n",
    "    (5, 8, False, False),   # 80 trees\n",
    "    (6, 7, False, False),   # 84 trees\n",
    "    (7, 11, False, True),   # 161 trees\n",
    "    (8, 12, False, True),   # 200 trees\n",
    "]\n",
    "\n",
    "# Generate more configurations for better coverage\n",
    "for ncols in range(2, 11):\n",
    "    for nrows in range(ncols, 15):\n",
    "        n_trees = 2 * ncols * nrows\n",
    "        if 20 <= n_trees <= 200:\n",
    "            if (ncols, nrows, False, False) not in grid_configs:\n",
    "                grid_configs.append((ncols, nrows, False, False))\n",
    "            n_with_append_y = n_trees + ncols\n",
    "            if n_with_append_y <= 200:\n",
    "                if (ncols, nrows, False, True) not in grid_configs:\n",
    "                    grid_configs.append((ncols, nrows, False, True))\n",
    "            n_with_append_x = n_trees + nrows\n",
    "            if n_with_append_x <= 200:\n",
    "                if (ncols, nrows, True, False) not in grid_configs:\n",
    "                    grid_configs.append((ncols, nrows, True, False))\n",
    "\n",
    "# Remove duplicates and sort\n",
    "grid_configs = list(set(grid_configs))\n",
    "grid_configs.sort(key=lambda x: (2 * x[0] * x[1] + (x[1] if x[2] else 0) + (x[0] if x[3] else 0)))\n",
    "\n",
    "print(f\"Generated {len(grid_configs)} grid configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8032e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:05.293201Z",
     "iopub.status.busy": "2026-01-19T21:08:05.293112Z",
     "iopub.status.idle": "2026-01-19T21:08:05.295626Z",
     "shell.execute_reply": "2026-01-19T21:08:05.295304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA params: {'Tmax': 0.001, 'Tmin': 1e-06, 'nsteps': 10, 'nsteps_per_T': 10000, 'position_delta': 0.002, 'angle_delta': 1.0, 'angle_delta2': 1.0, 'delta_t': 0.002}\n",
      "Total SA moves per config: 100,000\n"
     ]
    }
   ],
   "source": [
    "# SA parameters - exactly as in jiweiliu kernel\n",
    "sa_params = {\n",
    "    \"Tmax\": 0.001,\n",
    "    \"Tmin\": 0.000001,\n",
    "    \"nsteps\": 10,\n",
    "    \"nsteps_per_T\": 10000,  # 100,000 total SA moves per config\n",
    "    \"position_delta\": 0.002,\n",
    "    \"angle_delta\": 1.0,\n",
    "    \"angle_delta2\": 1.0,\n",
    "    \"delta_t\": 0.002,\n",
    "}\n",
    "\n",
    "print(f\"SA params: {sa_params}\")\n",
    "print(f\"Total SA moves per config: {sa_params['nsteps'] * sa_params['nsteps_per_T']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143254b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:05.296514Z",
     "iopub.status.busy": "2026-01-19T21:08:05.296423Z",
     "iopub.status.idle": "2026-01-19T21:08:07.839051Z",
     "shell.execute_reply": "2026-01-19T21:08:07.838652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling numba functions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba compilation done in 2.5s\n"
     ]
    }
   ],
   "source": [
    "# Warm up numba\n",
    "print(\"Compiling numba functions...\")\n",
    "t0 = time.time()\n",
    "dummy_xs = np.array([0.0, 1.0], dtype=np.float64)\n",
    "dummy_ys = np.array([0.0, 0.0], dtype=np.float64)\n",
    "dummy_degs = np.array([0.0, 180.0], dtype=np.float64)\n",
    "_ = sa_optimize_improved(\n",
    "    dummy_xs, dummy_ys, dummy_degs,\n",
    "    1.0, 1.0,\n",
    "    2, 2,\n",
    "    False, False,\n",
    "    0.001, 0.0001, 2, 100, 0.01, 1.0, 1.0, 0.01, 42\n",
    ")\n",
    "print(f\"Numba compilation done in {time.time() - t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f6af7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:07.840115Z",
     "iopub.status.busy": "2026-01-19T21:08:07.840019Z",
     "iopub.status.idle": "2026-01-19T21:08:07.843721Z",
     "shell.execute_reply": "2026-01-19T21:08:07.843401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 591 tasks for SA optimization\n",
      "Unique tree counts: [20, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 68, 69, 70, 72, 75, 76, 77, 78, 80, 81, 84, 85, 87, 88, 90, 91, 92, 95, 96, 98, 99, 100, 102, 104, 105, 108, 110, 112, 114, 115, 116, 117, 119, 120, 121, 125, 126, 128, 130, 132, 133, 135, 136, 138, 140, 143, 144, 145, 147, 150, 152, 153, 154, 156, 160, 161, 162, 165, 168, 169, 170, 171, 174, 175, 176, 180, 182, 184, 187, 189, 190, 192, 195, 196, 198, 200]\n"
     ]
    }
   ],
   "source": [
    "# Prepare tasks\n",
    "tasks = []\n",
    "tree_counts = []\n",
    "for i, (ncols, nrows, append_x, append_y) in enumerate(grid_configs):\n",
    "    n_base = 2 * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_trees = n_base + n_append_x + n_append_y\n",
    "\n",
    "    if n_trees > 200:\n",
    "        continue\n",
    "\n",
    "    # Run with 3 different random seeds for each config\n",
    "    for seed in range(3):\n",
    "        tasks.append((ncols, nrows, append_x, append_y, initial_seeds, a_init, b_init, sa_params, seed))\n",
    "        tree_counts.append(n_trees)\n",
    "\n",
    "print(f\"Prepared {len(tasks)} tasks for SA optimization\")\n",
    "print(f\"Unique tree counts: {sorted(set(tree_counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb9b2c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:08:18.346944Z",
     "iopub.status.busy": "2026-01-19T21:08:18.346470Z",
     "iopub.status.idle": "2026-01-19T21:18:10.071107Z",
     "shell.execute_reply": "2026-01-19T21:18:10.070675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SA optimization on 591 configurations...\n",
      "Using 26 workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA optimization completed in 591.7s (9.9 min)\n"
     ]
    }
   ],
   "source": [
    "# Run SA optimization in parallel\n",
    "print(f\"Running SA optimization on {len(tasks)} configurations...\")\n",
    "num_workers = min(cpu_count(), len(tasks))\n",
    "print(f\"Using {num_workers} workers\")\n",
    "\n",
    "t0 = time.time()\n",
    "with Pool(num_workers) as pool:\n",
    "    results = pool.map(optimize_grid_config, tasks)\n",
    "elapsed = time.time() - t0\n",
    "print(f\"SA optimization completed in {elapsed:.1f}s ({elapsed/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48c51663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:18:19.956125Z",
     "iopub.status.busy": "2026-01-19T21:18:19.955618Z",
     "iopub.status.idle": "2026-01-19T21:18:20.460558Z",
     "shell.execute_reply": "2026-01-19T21:18:20.460179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found improvements for 0 different N values\n",
      "Total improved configurations: 0\n"
     ]
    }
   ],
   "source": [
    "# Collect results and compare with baseline\n",
    "new_trees = {}\n",
    "improved_count = 0\n",
    "for n_trees, score, tree_data in results:\n",
    "    # Get baseline score for this n\n",
    "    idx = sum(range(1, n_trees))\n",
    "    baseline_vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n_trees)]\n",
    "    baseline_score = calculate_score_numba(baseline_vertices)\n",
    "\n",
    "    if score < baseline_score:\n",
    "        if n_trees not in new_trees or score < new_trees[n_trees][0]:\n",
    "            new_trees[n_trees] = (score, tree_data)\n",
    "            improved_count += 1\n",
    "            print(f\"N={n_trees}: SA={score:.6f} < baseline={baseline_score:.6f} (improvement: {baseline_score - score:.6f})\")\n",
    "\n",
    "print(f\"\\nFound improvements for {len(new_trees)} different N values\")\n",
    "print(f\"Total improved configurations: {improved_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e58ea552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:18:41.239022Z",
     "iopub.status.busy": "2026-01-19T21:18:41.238547Z",
     "iopub.status.idle": "2026-01-19T21:18:41.245926Z",
     "shell.execute_reply": "2026-01-19T21:18:41.245567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing SA results vs baseline for a few N values:\n",
      "N=20: SA=0.535060, baseline=0.376057, diff=+0.159004\n",
      "N=20: SA=0.532802, baseline=0.376057, diff=+0.156745\n",
      "N=20: SA=0.532474, baseline=0.376057, diff=+0.156417\n",
      "N=22: SA=0.615471, baseline=0.375258, diff=+0.240213\n",
      "N=22: SA=0.612228, baseline=0.375258, diff=+0.236970\n",
      "N=22: SA=0.611241, baseline=0.375258, diff=+0.235983\n",
      "N=24: SA=0.375920, baseline=0.365506, diff=+0.010414\n",
      "N=24: SA=0.375809, baseline=0.365506, diff=+0.010303\n",
      "N=24: SA=0.375855, baseline=0.365506, diff=+0.010349\n",
      "N=24: SA=0.625291, baseline=0.365506, diff=+0.259785\n",
      "N=24: SA=0.622946, baseline=0.365506, diff=+0.257441\n",
      "N=24: SA=0.623844, baseline=0.365506, diff=+0.258339\n",
      "N=25: SA=0.427844, baseline=0.372144, diff=+0.055700\n",
      "N=25: SA=0.426155, baseline=0.372144, diff=+0.054011\n",
      "N=25: SA=0.425582, baseline=0.372144, diff=+0.053437\n",
      "N=26: SA=0.701920, baseline=0.373997, diff=+0.327923\n",
      "N=26: SA=0.705210, baseline=0.373997, diff=+0.331213\n",
      "N=26: SA=0.701991, baseline=0.373997, diff=+0.327994\n",
      "N=27: SA=0.387557, baseline=0.362719, diff=+0.024838\n",
      "N=27: SA=0.387618, baseline=0.362719, diff=+0.024900\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check a few results vs baseline\n",
    "print(\"Comparing SA results vs baseline for a few N values:\")\n",
    "for n_trees, score, tree_data in results[:20]:\n",
    "    idx = sum(range(1, n_trees))\n",
    "    baseline_vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n_trees)]\n",
    "    baseline_score = calculate_score_numba(baseline_vertices)\n",
    "    diff = score - baseline_score\n",
    "    print(f\"N={n_trees}: SA={score:.6f}, baseline={baseline_score:.6f}, diff={diff:+.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b4bad",
   "metadata": {},
   "source": [
    "# Corner Extraction Approach\\n\\nSince the jiweiliu SA approach didn't improve the baseline (saspav_latest is already better than what jiweiliu can produce), let's try the chistyakov corner extraction approach.\\n\\nThis approach extracts smaller layouts from corners of larger layouts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5d88dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:20:34.956386Z",
     "iopub.status.busy": "2026-01-19T21:20:34.955891Z",
     "iopub.status.idle": "2026-01-19T21:20:46.383032Z",
     "shell.execute_reply": "2026-01-19T21:20:46.382637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running corner extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corner extraction completed in 11.4s\n",
      "Found 0 improvements\n"
     ]
    }
   ],
   "source": [
    "# Corner extraction approach\n",
    "# For each large N, extract smaller layouts from corners\n",
    "\n",
    "def corner_extraction(all_xs, all_ys, all_degs):\n",
    "    \"\"\"Extract smaller layouts from corners of larger layouts.\"\"\"\n",
    "    improvements = {}\n",
    "    \n",
    "    # Try extracting from large N values\n",
    "    for source_n in range(50, 201):\n",
    "        # Get trees for this N\n",
    "        source_idx = sum(range(1, source_n))\n",
    "        source_xs = all_xs[source_idx:source_idx + source_n]\n",
    "        source_ys = all_ys[source_idx:source_idx + source_n]\n",
    "        source_degs = all_degs[source_idx:source_idx + source_n]\n",
    "        \n",
    "        # Get bounding box\n",
    "        all_vertices = [get_tree_vertices(source_xs[i], source_ys[i], source_degs[i]) for i in range(source_n)]\n",
    "        min_x, min_y, max_x, max_y = compute_bounding_box(all_vertices)\n",
    "        \n",
    "        # Try each corner\n",
    "        corners = [(min_x, min_y), (min_x, max_y), (max_x, min_y), (max_x, max_y)]\n",
    "        \n",
    "        for corner_x, corner_y in corners:\n",
    "            # Calculate distance from corner for each tree\n",
    "            distances = []\n",
    "            for i in range(source_n):\n",
    "                verts = all_vertices[i]\n",
    "                # Max distance from corner to any vertex of tree\n",
    "                max_dist = 0\n",
    "                for j in range(verts.shape[0]):\n",
    "                    dist = max(abs(verts[j, 0] - corner_x), abs(verts[j, 1] - corner_y))\n",
    "                    if dist > max_dist:\n",
    "                        max_dist = dist\n",
    "                distances.append((max_dist, i))\n",
    "            \n",
    "            # Sort by distance\n",
    "            distances.sort()\n",
    "            \n",
    "            # Try extracting subsets\n",
    "            for target_n in range(2, min(source_n, 50)):  # Only check small N values\n",
    "                # Get the closest target_n trees\n",
    "                subset_indices = [idx for _, idx in distances[:target_n]]\n",
    "                subset_xs = [source_xs[i] for i in subset_indices]\n",
    "                subset_ys = [source_ys[i] for i in subset_indices]\n",
    "                subset_degs = [source_degs[i] for i in subset_indices]\n",
    "                \n",
    "                # Calculate score for this subset\n",
    "                subset_vertices = [get_tree_vertices(subset_xs[i], subset_ys[i], subset_degs[i]) for i in range(target_n)]\n",
    "                subset_side = get_side_length(subset_vertices)\n",
    "                subset_score = subset_side * subset_side / target_n\n",
    "                \n",
    "                # Compare with baseline\n",
    "                target_idx = sum(range(1, target_n))\n",
    "                baseline_vertices = [get_tree_vertices(all_xs[target_idx + i], all_ys[target_idx + i], all_degs[target_idx + i]) for i in range(target_n)]\n",
    "                baseline_score = calculate_score_numba(baseline_vertices)\n",
    "                \n",
    "                if subset_score < baseline_score:\n",
    "                    if target_n not in improvements or subset_score < improvements[target_n][0]:\n",
    "                        improvements[target_n] = (subset_score, baseline_score, subset_xs, subset_ys, subset_degs, source_n)\n",
    "                        print(f\"N={target_n}: Found improvement from N={source_n} corner ({corner_x:.2f},{corner_y:.2f}): {baseline_score:.6f} -> {subset_score:.6f}\")\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "print(\"Running corner extraction...\")\n",
    "t0 = time.time()\n",
    "improvements = corner_extraction(baseline_xs, baseline_ys, baseline_degs)\n",
    "print(f\"Corner extraction completed in {time.time() - t0:.1f}s\")\n",
    "print(f\"Found {len(improvements)} improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a818e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:21:11.121019Z",
     "iopub.status.busy": "2026-01-19T21:21:11.120456Z",
     "iopub.status.idle": "2026-01-19T21:21:11.261843Z",
     "shell.execute_reply": "2026-01-19T21:21:11.261479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing baseline scores per N:\n",
      "\n",
      "Top 20 worst-packed N values (highest score):\n",
      "  N=1: score=0.661250, side=0.8132\n",
      "  N=2: score=0.450779, side=0.9495\n",
      "  N=3: score=0.434745, side=1.1420\n",
      "  N=5: score=0.416850, side=1.4437\n",
      "  N=4: score=0.416545, side=1.2908\n",
      "  N=7: score=0.399897, side=1.6731\n",
      "  N=6: score=0.399610, side=1.5484\n",
      "  N=9: score=0.387415, side=1.8673\n",
      "  N=8: score=0.385407, side=1.7559\n",
      "  N=15: score=0.379203, side=2.3850\n",
      "  N=10: score=0.376630, side=1.9407\n",
      "  N=21: score=0.376451, side=2.8117\n",
      "  N=20: score=0.376057, side=2.7425\n",
      "  N=11: score=0.375736, side=2.0330\n",
      "  N=22: score=0.375258, side=2.8733\n",
      "  N=16: score=0.374128, side=2.4466\n",
      "  N=26: score=0.373997, side=3.1183\n",
      "  N=12: score=0.372724, side=2.1149\n",
      "  N=13: score=0.372294, side=2.2000\n",
      "  N=25: score=0.372144, side=3.0502\n"
     ]
    }
   ],
   "source": [
    "# Try running SA with more aggressive parameters and longer runs\n",
    "# Focus on specific N values that might have room for improvement\n",
    "\n",
    "# First, let's analyze which N values have the worst \"efficiency\" (highest score per tree)\n",
    "print(\"Analyzing baseline scores per N:\")\n",
    "scores_per_n = []\n",
    "idx = 0\n",
    "for n in range(1, 201):\n",
    "    vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n)]\n",
    "    side = get_side_length(vertices)\n",
    "    score = side * side / n\n",
    "    scores_per_n.append((n, score, side))\n",
    "    idx += n\n",
    "\n",
    "# Sort by score (highest first) - these are the worst packed\n",
    "scores_per_n.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 20 worst-packed N values (highest score):\")\n",
    "for n, score, side in scores_per_n[:20]:\n",
    "    print(f\"  N={n}: score={score:.6f}, side={side:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fc9be5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:21:36.210266Z",
     "iopub.status.busy": "2026-01-19T21:21:36.209775Z",
     "iopub.status.idle": "2026-01-19T21:21:36.217161Z",
     "shell.execute_reply": "2026-01-19T21:21:36.216793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking lattice-compatible N values:\n",
      "Lattice-compatible N values: [8, 12, 16, 18, 20, 24, 28, 30, 32, 36, 40, 42, 44, 48, 50, 52, 54, 56, 60, 64, 66, 70, 72, 78, 80, 84, 88, 90, 96, 98, 100, 104, 108, 110, 112, 120, 126, 128, 130, 132, 140, 144, 154, 156, 160, 162, 168, 176, 180, 182, 192, 196, 198, 200]\n",
      "\n",
      "Baseline scores for lattice-compatible N values:\n",
      "  N=8: score=0.385407\n",
      "  N=12: score=0.372724\n",
      "  N=16: score=0.374128\n",
      "  N=18: score=0.368771\n",
      "  N=20: score=0.376057\n",
      "  N=24: score=0.365506\n",
      "  N=28: score=0.366105\n",
      "  N=30: score=0.360883\n",
      "  N=32: score=0.365592\n",
      "  N=36: score=0.358820\n",
      "  N=40: score=0.362148\n",
      "  N=42: score=0.366839\n",
      "  N=44: score=0.366271\n",
      "  N=48: score=0.355530\n",
      "  N=50: score=0.360753\n"
     ]
    }
   ],
   "source": [
    "# Check which N values are exact multiples of 2 (base grid) and might benefit from lattice\n",
    "# The jiweiliu kernel uses 2-tree seeds, so N = 2 * ncols * nrows\n",
    "\n",
    "print(\"Checking lattice-compatible N values:\")\n",
    "lattice_n_values = []\n",
    "for ncols in range(2, 11):\n",
    "    for nrows in range(ncols, 15):\n",
    "        n = 2 * ncols * nrows\n",
    "        if n <= 200:\n",
    "            lattice_n_values.append(n)\n",
    "\n",
    "lattice_n_values = sorted(set(lattice_n_values))\n",
    "print(f\"Lattice-compatible N values: {lattice_n_values}\")\n",
    "\n",
    "# Check baseline scores for these N values\n",
    "print(\"\\nBaseline scores for lattice-compatible N values:\")\n",
    "for n in lattice_n_values[:15]:\n",
    "    idx = sum(range(1, n))\n",
    "    vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n)]\n",
    "    score = calculate_score_numba(vertices)\n",
    "    print(f\"  N={n}: score={score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0649f865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:22:07.248657Z",
     "iopub.status.busy": "2026-01-19T21:22:07.248490Z",
     "iopub.status.idle": "2026-01-19T21:26:02.381170Z",
     "shell.execute_reply": "2026-01-19T21:26:02.380739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggressive SA params: {'Tmax': 0.01, 'Tmin': 1e-07, 'nsteps': 20, 'nsteps_per_T': 50000, 'position_delta': 0.005, 'angle_delta': 2.0, 'angle_delta2': 2.0, 'delta_t': 0.005}\n",
      "Total SA moves per config: 1,000,000\n",
      "\n",
      "Running aggressive SA on test configs...\n",
      "  N=48 (4x6): SA=0.358497, baseline=0.355530, diff=+0.002968 (worse) [61.7s]\n",
      "  N=70 (5x7): SA=0.351889, baseline=0.349513, diff=+0.002376 (worse) [73.2s]\n",
      "  N=96 (6x8): SA=0.348290, baseline=0.346397, diff=+0.001893 (worse) [100.2s]\n"
     ]
    }
   ],
   "source": [
    "# Try more aggressive SA parameters\n",
    "# Focus on a few specific N values with longer runs\n",
    "\n",
    "aggressive_sa_params = {\n",
    "    \"Tmax\": 0.01,  # Higher starting temperature\n",
    "    \"Tmin\": 0.0000001,  # Lower ending temperature\n",
    "    \"nsteps\": 20,  # More temperature steps\n",
    "    \"nsteps_per_T\": 50000,  # More iterations per step (1M total moves)\n",
    "    \"position_delta\": 0.005,  # Slightly larger position changes\n",
    "    \"angle_delta\": 2.0,  # Slightly larger angle changes\n",
    "    \"angle_delta2\": 2.0,\n",
    "    \"delta_t\": 0.005,\n",
    "}\n",
    "\n",
    "print(f\"Aggressive SA params: {aggressive_sa_params}\")\n",
    "print(f\"Total SA moves per config: {aggressive_sa_params['nsteps'] * aggressive_sa_params['nsteps_per_T']:,}\")\n",
    "\n",
    "# Test on a few specific grid configs\n",
    "test_configs = [\n",
    "    (4, 6, False, False),   # 48 trees\n",
    "    (5, 7, False, False),   # 70 trees\n",
    "    (6, 8, False, False),   # 96 trees\n",
    "]\n",
    "\n",
    "print(\"\\nRunning aggressive SA on test configs...\")\n",
    "for ncols, nrows, append_x, append_y in test_configs:\n",
    "    n_trees = 2 * ncols * nrows\n",
    "    \n",
    "    # Get baseline score\n",
    "    idx = sum(range(1, n_trees))\n",
    "    baseline_vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n_trees)]\n",
    "    baseline_score = calculate_score_numba(baseline_vertices)\n",
    "    \n",
    "    # Run SA\n",
    "    seed_xs = np.array([s[0] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_ys = np.array([s[1] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_degs = np.array([s[2] for s in initial_seeds], dtype=np.float64)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    best_score, best_xs, best_ys, best_degs, best_a, best_b = sa_optimize_improved(\n",
    "        seed_xs, seed_ys, seed_degs,\n",
    "        a_init, b_init,\n",
    "        ncols, nrows,\n",
    "        append_x, append_y,\n",
    "        aggressive_sa_params[\"Tmax\"],\n",
    "        aggressive_sa_params[\"Tmin\"],\n",
    "        aggressive_sa_params[\"nsteps\"],\n",
    "        aggressive_sa_params[\"nsteps_per_T\"],\n",
    "        aggressive_sa_params[\"position_delta\"],\n",
    "        aggressive_sa_params[\"angle_delta\"],\n",
    "        aggressive_sa_params[\"angle_delta2\"],\n",
    "        aggressive_sa_params[\"delta_t\"],\n",
    "        42,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    diff = best_score - baseline_score\n",
    "    status = \"BETTER!\" if diff < 0 else \"worse\"\n",
    "    print(f\"  N={n_trees} ({ncols}x{nrows}): SA={best_score:.6f}, baseline={baseline_score:.6f}, diff={diff:+.6f} ({status}) [{elapsed:.1f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9195316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T21:26:41.378313Z",
     "iopub.status.busy": "2026-01-19T21:26:41.377789Z",
     "iopub.status.idle": "2026-01-19T21:26:41.923093Z",
     "shell.execute_reply": "2026-01-19T21:26:41.922740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling SA from baseline function...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Try SA optimization starting from the BASELINE configurations instead of lattice seeds\n",
    "# This might find small improvements by fine-tuning the existing solution\n",
    "\n",
    "@njit(cache=True)\n",
    "def sa_optimize_from_baseline(\n",
    "    xs_init, ys_init, degs_init,\n",
    "    Tmax, Tmin, nsteps, nsteps_per_T,\n",
    "    position_delta, angle_delta,\n",
    "    random_seed,\n",
    "):\n",
    "    \"\"\"SA optimization starting from existing configuration.\"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n = len(xs_init)\n",
    "    \n",
    "    xs = xs_init.copy()\n",
    "    ys = ys_init.copy()\n",
    "    degs = degs_init.copy()\n",
    "    \n",
    "    # Calculate initial score\n",
    "    all_vertices = [get_tree_vertices(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    current_score = calculate_score_numba(all_vertices)\n",
    "    \n",
    "    best_score = current_score\n",
    "    best_xs = xs.copy()\n",
    "    best_ys = ys.copy()\n",
    "    best_degs = degs.copy()\n",
    "    \n",
    "    T = Tmax\n",
    "    Tfactor = -math.log(Tmax / Tmin)\n",
    "    \n",
    "    for step in range(nsteps):\n",
    "        for _ in range(nsteps_per_T):\n",
    "            # Choose a random tree to modify\n",
    "            i = np.random.randint(0, n)\n",
    "            \n",
    "            old_x = xs[i]\n",
    "            old_y = ys[i]\n",
    "            old_deg = degs[i]\n",
    "            \n",
    "            # Apply small perturbation\n",
    "            dx = (np.random.random() * 2.0 - 1.0) * position_delta\n",
    "            dy = (np.random.random() * 2.0 - 1.0) * position_delta\n",
    "            ddeg = (np.random.random() * 2.0 - 1.0) * angle_delta\n",
    "            \n",
    "            xs[i] = old_x + dx\n",
    "            ys[i] = old_y + dy\n",
    "            degs[i] = (old_deg + ddeg) % 360.0\n",
    "            \n",
    "            # Check for overlaps\n",
    "            new_vertices = [get_tree_vertices(xs[j], ys[j], degs[j]) for j in range(n)]\n",
    "            centers_x = xs\n",
    "            centers_y = ys\n",
    "            \n",
    "            # Check if this tree overlaps with any other\n",
    "            has_overlap = False\n",
    "            new_vert_i = new_vertices[i]\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    if polygons_overlap(new_vert_i, new_vertices[j], xs[i], ys[i], xs[j], ys[j]):\n",
    "                        has_overlap = True\n",
    "                        break\n",
    "            \n",
    "            if has_overlap:\n",
    "                xs[i] = old_x\n",
    "                ys[i] = old_y\n",
    "                degs[i] = old_deg\n",
    "                continue\n",
    "            \n",
    "            new_score = calculate_score_numba(new_vertices)\n",
    "            delta = new_score - current_score\n",
    "            \n",
    "            accept = False\n",
    "            if delta < 0:\n",
    "                accept = True\n",
    "            elif T > 1e-10:\n",
    "                if np.random.random() < math.exp(-delta / T):\n",
    "                    accept = True\n",
    "            \n",
    "            if accept:\n",
    "                current_score = new_score\n",
    "                if new_score < best_score:\n",
    "                    best_score = new_score\n",
    "                    best_xs = xs.copy()\n",
    "                    best_ys = ys.copy()\n",
    "                    best_degs = degs.copy()\n",
    "            else:\n",
    "                xs[i] = old_x\n",
    "                ys[i] = old_y\n",
    "                degs[i] = old_deg\n",
    "        \n",
    "        T = Tmax * math.exp(Tfactor * (step + 1) / nsteps)\n",
    "    \n",
    "    return best_score, best_xs, best_ys, best_degs\n",
    "\n",
    "# Warm up\n",
    "print(\"Compiling SA from baseline function...\")\n",
    "dummy_xs = np.array([0.0, 1.0], dtype=np.float64)\n",
    "dummy_ys = np.array([0.0, 0.0], dtype=np.float64)\n",
    "dummy_degs = np.array([0.0, 180.0], dtype=np.float64)\n",
    "_ = sa_optimize_from_baseline(dummy_xs, dummy_ys, dummy_degs, 0.001, 0.0001, 2, 100, 0.01, 1.0, 42)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with baseline\n",
    "print(\"Merging with baseline...\")\n",
    "merged_xs = baseline_xs.copy()\n",
    "merged_ys = baseline_ys.copy()\n",
    "merged_degs = baseline_degs.copy()\n",
    "\n",
    "for n_trees, (score, tree_data) in new_trees.items():\n",
    "    idx = sum(range(1, n_trees))\n",
    "    for i in range(n_trees):\n",
    "        merged_xs[idx + i] = tree_data[i][0]\n",
    "        merged_ys[idx + i] = tree_data[i][1]\n",
    "        merged_degs[idx + i] = tree_data[i][2]\n",
    "\n",
    "pre_cascade_score = calculate_total_score(merged_xs, merged_ys, merged_degs)\n",
    "print(f\"Score after SA merge: {pre_cascade_score:.6f}\")\n",
    "print(f\"Improvement from SA: {baseline_total - pre_cascade_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02498dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tree deletion cascade\n",
    "print(\"Applying tree deletion cascade...\")\n",
    "t0 = time.time()\n",
    "final_xs, final_ys, final_degs, side_lengths = deletion_cascade_numba(\n",
    "    merged_xs, merged_ys, merged_degs,\n",
    "    np.arange(1, 201, dtype=np.int64)\n",
    ")\n",
    "print(f\"Cascade completed in {time.time() - t0:.1f}s\")\n",
    "\n",
    "final_score = calculate_total_score(final_xs, final_ys, final_degs)\n",
    "print(f\"Score after cascade: {final_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Summary:\")\n",
    "print(f\"  Baseline total:      {baseline_total:.6f}\")\n",
    "print(f\"  After SA:            {pre_cascade_score:.6f}\")\n",
    "print(f\"  After cascade:       {final_score:.6f}\")\n",
    "print(f\"  Total improvement:   {baseline_total - final_score:+.6f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "if final_score < baseline_total:\n",
    "    output_path = \"/home/submission/submission.csv\"\n",
    "    save_submission(output_path, final_xs, final_ys, final_degs)\n",
    "    print(f\"Saved to {output_path}\")\n",
    "else:\n",
    "    # Save baseline if no improvement\n",
    "    output_path = \"/home/submission/submission.csv\"\n",
    "    save_submission(output_path, baseline_xs, baseline_ys, baseline_degs)\n",
    "    print(f\"No improvement - saved baseline to {output_path}\")\n",
    "\n",
    "print(f\"\\nFinal score: {min(final_score, baseline_total):.9f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
