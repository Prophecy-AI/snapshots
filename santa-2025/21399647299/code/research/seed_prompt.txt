## Current Status
- Best CV score: 70.316492 (exp_022)
- Best LB score: 70.3165 (exp_022)
- Target: 68.873342 | Gap to target: 1.44 points (2.1%)

## ⛔⛔⛔ CRITICAL: 30 EXPERIMENTS AT SAME SCORE ⛔⛔⛔

**THE LAST 10 EXPERIMENTS ALL PRODUCED THE SAME SCORE (70.316492).**

This is the PUBLIC KERNEL CEILING. Standard optimization approaches are EXHAUSTED:
- Simulated Annealing (SA) - EXHAUSTED
- Genetic Algorithm (GA) - EXHAUSTED  
- Branch-and-Bound - EXHAUSTED
- Lattice Packing - EXHAUSTED
- Constraint Programming (simple) - EXHAUSTED
- Jostle Algorithm - EXHAUSTED
- Bottom-Left Fill - EXHAUSTED
- Extended C++ optimization (8+ hours) - EXHAUSTED

**ALL THESE APPROACHES CONVERGE TO THE SAME LOCAL OPTIMUM.**

## Response to Evaluator

The evaluator correctly identified that:
1. 10+ fundamentally different algorithms have all converged to 70.316492
2. The CP approach failed because Manhattan distance constraints are too simple
3. The gap to target requires either:
   - Gradient-based optimization (density flow, boundary tension)
   - Proper NFP-based constraint programming
   - Fresh external data sources
   - Significantly more compute time

I AGREE with the evaluator's assessment. The next experiment MUST try a fundamentally different paradigm.

## ✅ MANDATORY NEXT EXPERIMENT: GRADIENT-BASED DENSITY FLOW

The bbox3.cpp kernel uses "Density Gradient Flow" and "Global Boundary Tension" which we haven't fully explored in Python.

**IMPLEMENT THIS ALGORITHM:**

```python
"""
Gradient-Based Density Flow Optimization

Key insight: Instead of random perturbations (SA), use DIRECTED movement
based on the gradient of the objective function.

Algorithm:
1. Compute the gradient of bounding box with respect to each tree position
2. Move trees in the direction that reduces the bounding box
3. Add "density flow" - trees are attracted toward the centroid
4. Add "boundary tension" - trees on the boundary are pushed inward
5. Use adaptive step sizes to escape local optima
"""

def compute_bbox_gradient(xs, ys, angles):
    """
    Compute the gradient of the bounding box with respect to tree positions.
    
    Returns: (dx, dy) for each tree - the direction to move to reduce bbox
    """
    n = len(xs)
    
    # Find which trees are on the boundary
    all_vertices = []
    for i in range(n):
        verts = get_tree_vertices(xs[i], ys[i], angles[i])
        all_vertices.append(verts)
    
    # Find min/max x/y
    min_x = min(v[0] for verts in all_vertices for v in verts)
    max_x = max(v[0] for verts in all_vertices for v in verts)
    min_y = min(v[1] for verts in all_vertices for v in verts)
    max_y = max(v[1] for verts in all_vertices for v in verts)
    
    # Gradient: trees on boundary should move inward
    gradients = []
    for i in range(n):
        dx, dy = 0, 0
        for vx, vy in all_vertices[i]:
            if abs(vx - min_x) < 1e-6:
                dx += 0.1  # Push right
            if abs(vx - max_x) < 1e-6:
                dx -= 0.1  # Push left
            if abs(vy - min_y) < 1e-6:
                dy += 0.1  # Push up
            if abs(vy - max_y) < 1e-6:
                dy -= 0.1  # Push down
        gradients.append((dx, dy))
    
    return gradients

def density_flow(xs, ys, angles):
    """
    Compute density flow - trees are attracted toward the centroid.
    """
    cx = sum(xs) / len(xs)
    cy = sum(ys) / len(ys)
    
    flows = []
    for x, y in zip(xs, ys):
        dx = (cx - x) * 0.01  # Weak attraction to center
        dy = (cy - y) * 0.01
        flows.append((dx, dy))
    
    return flows

def gradient_descent_step(xs, ys, angles, step_size=0.01):
    """
    Take one gradient descent step.
    """
    # Compute gradients
    bbox_grad = compute_bbox_gradient(xs, ys, angles)
    density = density_flow(xs, ys, angles)
    
    # Combine gradients
    new_xs = []
    new_ys = []
    for i in range(len(xs)):
        dx = bbox_grad[i][0] + density[i][0]
        dy = bbox_grad[i][1] + density[i][1]
        new_xs.append(xs[i] + dx * step_size)
        new_ys.append(ys[i] + dy * step_size)
    
    return new_xs, new_ys
```

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with SA - FORBIDDEN
- Any approach that has already been tried 10+ times - FORBIDDEN

## ✅ REQUIRED: TEST ON SMALL N FIRST

Before running on all 200 N values:
1. Test gradient descent on N=10, N=20, N=30
2. Visualize the optimization trajectory
3. If it doesn't beat baseline on small N, the approach won't scale

```python
# Test on small N
for n in [10, 20, 30]:
    xs, ys, angles = load_baseline(n)
    baseline_score = compute_score(xs, ys, angles)
    
    # Run gradient descent
    for iteration in range(1000):
        xs, ys = gradient_descent_step(xs, ys, angles)
        if has_overlap(xs, ys, angles):
            # Revert and try smaller step
            ...
    
    new_score = compute_score(xs, ys, angles)
    print(f"N={n}: {baseline_score:.6f} -> {new_score:.6f}")
```

## ✅ REQUIRED: PER-N TRACKING

Track best solution for EACH N separately:
- Load baseline per-N scores
- After each experiment, compare per-N
- Keep only N values where you improved
- Ensemble = best per-N from all sources

## Alternative Approaches (if gradient descent fails)

### Option B: Proper NFP-Based Constraint Programming
If gradient-based fails, implement proper CP with NFP constraints:
1. Precompute NFPs for discrete angle combinations (e.g., 12 angles = 144 NFPs per tree pair)
2. Use NFP constraints in the CP model
3. This is computationally expensive but may find solutions SA cannot

### Option C: Reinforcement Learning
Train an RL agent to place trees one at a time:
1. State: current configuration
2. Action: place next tree at (x, y, angle)
3. Reward: negative bounding box score
4. This could learn placement strategies that heuristics miss

## Submission Strategy
- SUBMIT the result even if it doesn't improve
- We have 87 submissions remaining
- LB feedback is valuable for validating approaches

## What We've Learned (from 30 experiments)
- SA converges to 70.316 regardless of parameters
- GA converges to 70.316 regardless of population size
- B&B is too slow for N > 10
- Lattice packing doesn't fit the tree shape well
- Simple CP constraints (Manhattan distance) don't model tree shape
- Extended C++ optimization (8+ hours) finds ZERO improvement
- The baseline is at an EXTREMELY strong local optimum

## The Path to 68.873

The target score (68.873) is 1.44 points below our current best (70.316).
This is a 2.1% improvement.

Top competitors achieved this through:
1. Novel algorithms not publicly shared
2. Significantly more compute time (days, not hours)
3. Private solutions shared via Discord/Telegram
4. Accumulating improvements over 900+ submissions

We need to try fundamentally different approaches to break through the ceiling.
