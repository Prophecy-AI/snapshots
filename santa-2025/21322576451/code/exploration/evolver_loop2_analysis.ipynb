{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da15b087",
   "metadata": {},
   "source": [
    "# Loop 2 Analysis: Understanding the Gap to Target\n",
    "\n",
    "## Key Questions:\n",
    "1. Where is the gap concentrated (which N values)?\n",
    "2. What would be needed per-N to reach the target?\n",
    "3. What approaches haven't been tried yet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4b0010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:20.945897Z",
     "iopub.status.busy": "2026-01-24T23:45:20.945458Z",
     "iopub.status.idle": "2026-01-24T23:45:21.346880Z",
     "shell.execute_reply": "2026-01-24T23:45:21.346451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (20100, 4)\n",
      "N values range: 1 to 200\n",
      "Unique N values: 200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load the current best valid submission\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "print(f\"Submission shape: {df.shape}\")\n",
    "\n",
    "# Parse the data\n",
    "def parse_value(v):\n",
    "    if isinstance(v, str) and v.startswith('s'):\n",
    "        return float(v[1:])\n",
    "    return float(v)\n",
    "\n",
    "df['xf'] = df['x'].apply(parse_value)\n",
    "df['yf'] = df['y'].apply(parse_value)\n",
    "df['degf'] = df['deg'].apply(parse_value)\n",
    "df['n_val'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "\n",
    "print(f\"N values range: {df['n_val'].min()} to {df['n_val'].max()}\")\n",
    "print(f\"Unique N values: {df['n_val'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefebd51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.348215Z",
     "iopub.status.busy": "2026-01-24T23:45:21.348101Z",
     "iopub.status.idle": "2026-01-24T23:45:21.410240Z",
     "shell.execute_reply": "2026-01-24T23:45:21.409843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (approx): 86.879164\n",
      "\n",
      "Top 10 N values by score contribution:\n",
      "     n      side     score\n",
      "1    2  1.522919  1.159640\n",
      "0    1  1.000000  1.000000\n",
      "3    4  1.864220  0.868829\n",
      "4    5  1.963054  0.770716\n",
      "2    3  1.494898  0.744906\n",
      "6    7  2.222297  0.705515\n",
      "5    6  2.014194  0.676163\n",
      "7    8  2.253674  0.634881\n",
      "8    9  2.329993  0.603207\n",
      "11  12  2.689319  0.602703\n"
     ]
    }
   ],
   "source": [
    "# Calculate score per N\n",
    "def calculate_score_per_n(df):\n",
    "    scores = []\n",
    "    for n in range(1, 201):\n",
    "        group = df[df['n_val'] == n]\n",
    "        if len(group) == 0:\n",
    "            continue\n",
    "        x_min, x_max = group['xf'].min(), group['xf'].max()\n",
    "        y_min, y_max = group['yf'].min(), group['yf'].max()\n",
    "        # Need to account for tree polygon extent\n",
    "        # Tree is roughly 0.7 wide and 1.0 tall\n",
    "        # But rotation changes this - use approximate bounding\n",
    "        side = max(x_max - x_min + 0.7, y_max - y_min + 1.0)\n",
    "        score_n = (side ** 2) / n\n",
    "        scores.append({'n': n, 'side': side, 'score': score_n, 'count': len(group)})\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "scores_df = calculate_score_per_n(df)\n",
    "print(f\"Total score (approx): {scores_df['score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 N values by score contribution:\")\n",
    "print(scores_df.nlargest(10, 'score')[['n', 'side', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d330da46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.411626Z",
     "iopub.status.busy": "2026-01-24T23:45:21.411285Z",
     "iopub.status.idle": "2026-01-24T23:45:21.414337Z",
     "shell.execute_reply": "2026-01-24T23:45:21.413967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 70.626088\n",
      "Target score: 68.897509\n",
      "Gap to close: 1.728579 (2.51%)\n",
      "\n",
      "Average improvement needed per N: 0.008643\n"
     ]
    }
   ],
   "source": [
    "# Target analysis\n",
    "TARGET = 68.897509\n",
    "CURRENT = 70.626088\n",
    "GAP = CURRENT - TARGET\n",
    "\n",
    "print(f\"Current score: {CURRENT:.6f}\")\n",
    "print(f\"Target score: {TARGET:.6f}\")\n",
    "print(f\"Gap to close: {GAP:.6f} ({GAP/TARGET*100:.2f}%)\")\n",
    "\n",
    "# If we need to close 1.73 points across 200 N values\n",
    "# Average improvement needed per N = 1.73/200 = 0.00865\n",
    "print(f\"\\nAverage improvement needed per N: {GAP/200:.6f}\")\n",
    "\n",
    "# But score = S^2/n, so improvement is weighted by 1/n\n",
    "# Small N values have much higher leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864662ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.415340Z",
     "iopub.status.busy": "2026-01-24T23:45:21.415220Z",
     "iopub.status.idle": "2026-01-24T23:45:21.418147Z",
     "shell.execute_reply": "2026-01-24T23:45:21.417734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all side lengths reduced uniformly:\n",
      "  Reduction factor k = 0.987687\n",
      "  Each side needs to be 1.23% smaller\n",
      "  For a side of 1.0, need to reduce by 0.0123 units\n"
     ]
    }
   ],
   "source": [
    "# Analyze what side length reduction is needed per N to reach target\n",
    "# Current: sum(S_n^2/n) = 70.626\n",
    "# Target: sum(S_n^2/n) = 68.897\n",
    "# Need to reduce by 1.729\n",
    "\n",
    "# If we reduce ALL side lengths by factor k:\n",
    "# New score = sum((k*S_n)^2/n) = k^2 * sum(S_n^2/n) = k^2 * 70.626\n",
    "# For k^2 * 70.626 = 68.897\n",
    "# k^2 = 68.897/70.626 = 0.9755\n",
    "# k = 0.9877\n",
    "\n",
    "k_needed = np.sqrt(TARGET / CURRENT)\n",
    "print(f\"If all side lengths reduced uniformly:\")\n",
    "print(f\"  Reduction factor k = {k_needed:.6f}\")\n",
    "print(f\"  Each side needs to be {(1-k_needed)*100:.2f}% smaller\")\n",
    "print(f\"  For a side of 1.0, need to reduce by {(1-k_needed):.4f} units\")\n",
    "\n",
    "# This is a 1.23% reduction in all side lengths\n",
    "# For N=1 with side ~0.813, need to reduce by 0.01 units\n",
    "# For N=200 with side ~5.5, need to reduce by 0.068 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213ce038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.419023Z",
     "iopub.status.busy": "2026-01-24T23:45:21.418920Z",
     "iopub.status.idle": "2026-01-24T23:45:21.424516Z",
     "shell.execute_reply": "2026-01-24T23:45:21.424119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot has 38 experiments\n",
      "Snapshot has 13 submissions\n",
      "\n",
      "Experiment history:\n",
      "  001_baseline: 70.647327\n",
      "  002_ensemble: 70.647306\n",
      "  003_validated_ensemble: 70.647327\n",
      "  004_bbox3_optimization: 70.647326\n",
      "  005_baseline_validated: 70.647327\n",
      "  006_zaburo_grid: 70.647327\n",
      "  007_sa_optimization: 70.647327\n",
      "  008_repair_ensemble: 70.647327\n",
      "  009_fractional_translation: 70.647327\n",
      "  010_tessellation_and_ensemble: 70.630478\n",
      "  011_random_restart_sa: 70.630478\n",
      "  012_scanline_packer: 70.630478\n",
      "  013_long_sa: 70.630478\n",
      "  014_basin_hopping: 70.630478\n",
      "  015_constraint_programming: 70.630478\n",
      "  016_rebuild_corners: 70.630465\n",
      "  017_cross_n_extraction: 70.630465\n",
      "  018_egortrushin_tessellation: 70.630478\n",
      "  019_cpp_sa: 70.630455\n",
      "  020_asymmetric_solutions: 70.630455\n",
      "  021_tessellation_search: 70.630429\n",
      "  022_exhaustive_small_n: 70.627582\n",
      "  023_invalid_snapshot_analysis: 70.627582\n",
      "  024_exhaustive_n1: 70.627582\n",
      "  025_iterative_refinement: 70.626088\n",
      "  026_thorough_cascade: 70.624381\n",
      "  027_iterative_sa_refinement: 70.624381\n",
      "  028_asymmetric_perturbations: 70.624381\n",
      "  029_greedy_beam_search: 70.624381\n",
      "  030_final_ensemble_verification: 70.624381\n",
      "  031_jiweiliu_deletion_cascade: 70.624381\n",
      "  032_corner_rebuild_large_n: 70.624381\n",
      "  033_comprehensive_ensemble: 70.624381\n",
      "  034_mip_small_n: 70.624381\n",
      "  035_genetic_algorithm_medium_n: 70.624381\n",
      "  036_very_long_optimization: 70.626088\n",
      "  037_truly_asymmetric_random: 70.626088\n",
      "  038_final_verification: 70.626088\n"
     ]
    }
   ],
   "source": [
    "# Load snapshot experiment history to understand what's been tried\n",
    "import os\n",
    "\n",
    "snapshot_path = '/home/nonroot/snapshots/santa-2025/21222392487/code/session_state.json'\n",
    "if os.path.exists(snapshot_path):\n",
    "    with open(snapshot_path) as f:\n",
    "        snapshot_state = json.load(f)\n",
    "    \n",
    "    print(f\"Snapshot has {len(snapshot_state.get('experiments', []))} experiments\")\n",
    "    print(f\"Snapshot has {len(snapshot_state.get('submissions', []))} submissions\")\n",
    "    \n",
    "    # List experiment names and scores\n",
    "    print(\"\\nExperiment history:\")\n",
    "    for exp in snapshot_state.get('experiments', []):\n",
    "        print(f\"  {exp['name']}: {exp.get('cv_score', 'N/A'):.6f}\")\n",
    "else:\n",
    "    print(\"Snapshot not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e23186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.425647Z",
     "iopub.status.busy": "2026-01-24T23:45:21.425536Z",
     "iopub.status.idle": "2026-01-24T23:45:21.429232Z",
     "shell.execute_reply": "2026-01-24T23:45:21.428838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission history from snapshot:\n",
      "  001_baseline: CV=70.647327, LB=70.647326897636, Error=None\n",
      "  002_ensemble: CV=70.647306, LB=, Error=Overlapping trees in group 042\n",
      "  003_validated_ensemble: CV=70.647327, LB=70.647326897636, Error=None\n",
      "  004_bbox3_optimization: CV=70.647326, LB=, Error=Overlapping trees in group 016\n",
      "  010_tessellation_and_ensemble: CV=70.630478, LB=70.630478453757, Error=None\n",
      "  011_random_restart_sa: CV=70.630478, LB=70.630478453757, Error=None\n",
      "  018_egortrushin_tessellation: CV=70.630478, LB=70.630465007968, Error=None\n",
      "  019_cpp_sa: CV=70.630455, LB=70.630454595919, Error=None\n",
      "  022_exhaustive_small_n: CV=70.627582, LB=70.627582179198, Error=None\n",
      "  025_iterative_refinement: CV=70.626088, LB=70.626088313081, Error=None\n",
      "  026_thorough_cascade: CV=70.624381, LB=, Error=Overlapping trees in group 040\n",
      "  035_genetic_algorithm_medium_n: CV=70.624381, LB=, Error=Overlapping trees in group 040\n",
      "  036_very_long_optimization: CV=70.626088, LB=70.626088313081, Error=None\n",
      "\n",
      "Valid submissions: 9\n",
      "Invalid submissions (overlaps): 4\n"
     ]
    }
   ],
   "source": [
    "# Analyze submissions from snapshot\n",
    "print(\"\\nSubmission history from snapshot:\")\n",
    "for sub in snapshot_state.get('submissions', []):\n",
    "    lb = sub.get('lb_score', 'N/A')\n",
    "    cv = sub.get('cv_score', 'N/A')\n",
    "    error = sub.get('error', '')\n",
    "    print(f\"  {sub.get('model_name', 'unknown')}: CV={cv}, LB={lb}, Error={error[:50] if error else 'None'}\")\n",
    "\n",
    "# Count valid vs invalid submissions\n",
    "valid_subs = [s for s in snapshot_state.get('submissions', []) if not s.get('error')]\n",
    "invalid_subs = [s for s in snapshot_state.get('submissions', []) if s.get('error')]\n",
    "print(f\"\\nValid submissions: {len(valid_subs)}\")\n",
    "print(f\"Invalid submissions (overlaps): {len(invalid_subs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a7efdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.430156Z",
     "iopub.status.busy": "2026-01-24T23:45:21.430055Z",
     "iopub.status.idle": "2026-01-24T23:45:21.433632Z",
     "shell.execute_reply": "2026-01-24T23:45:21.433254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaches tried in snapshot:\n",
      "  ✓ bbox3 C++ optimizer\n",
      "  ✓ Simulated Annealing (SA)\n",
      "  ✓ Tessellation patterns\n",
      "  ✓ Genetic Algorithm\n",
      "  ✓ MIP for small N\n",
      "  ✓ Ensemble from multiple sources\n",
      "  ✓ Asymmetric perturbations\n",
      "  ✓ Deletion cascade\n",
      "  ✓ Corner rebuild\n",
      "  ✓ Fractional translation\n",
      "  ✓ Basin hopping\n",
      "  ✓ Random restart SA\n",
      "  ✓ Greedy beam search\n",
      "\n",
      "Approaches NOT tried:\n",
      "  ✗ Reinforcement Learning\n",
      "  ✗ MIP for medium N (10-50)\n",
      "  ✗ Constraint Programming with global constraints\n",
      "  ✗ Lattice-based initialization with optimal spacing\n",
      "  ✗ No-fit polygon (NFP) based placement\n",
      "  ✗ Jostle algorithm\n",
      "  ✗ Density gradient flow\n",
      "  ✗ Global boundary tension optimization\n"
     ]
    }
   ],
   "source": [
    "# Key insight: What approaches HAVEN'T been tried?\n",
    "# From the snapshot experiments:\n",
    "# - bbox3 optimization ✓\n",
    "# - SA optimization ✓\n",
    "# - Tessellation ✓\n",
    "# - Genetic algorithm ✓\n",
    "# - MIP for small N ✓\n",
    "# - Ensemble from multiple sources ✓\n",
    "# - Asymmetric perturbations ✓\n",
    "# - Deletion cascade ✓\n",
    "# - Corner rebuild ✓\n",
    "\n",
    "# What's NOT in the list:\n",
    "# 1. Reinforcement Learning (mentioned in web research)\n",
    "# 2. Mixed-Integer Programming for medium N (only small N tried)\n",
    "# 3. Constraint Programming with global constraints\n",
    "# 4. Lattice-based initialization with optimal spacing\n",
    "# 5. Cross-pollination from top LB submissions (not public)\n",
    "\n",
    "print(\"Approaches tried in snapshot:\")\n",
    "approaches_tried = [\n",
    "    \"bbox3 C++ optimizer\",\n",
    "    \"Simulated Annealing (SA)\",\n",
    "    \"Tessellation patterns\",\n",
    "    \"Genetic Algorithm\",\n",
    "    \"MIP for small N\",\n",
    "    \"Ensemble from multiple sources\",\n",
    "    \"Asymmetric perturbations\",\n",
    "    \"Deletion cascade\",\n",
    "    \"Corner rebuild\",\n",
    "    \"Fractional translation\",\n",
    "    \"Basin hopping\",\n",
    "    \"Random restart SA\",\n",
    "    \"Greedy beam search\"\n",
    "]\n",
    "for a in approaches_tried:\n",
    "    print(f\"  ✓ {a}\")\n",
    "\n",
    "print(\"\\nApproaches NOT tried:\")\n",
    "approaches_not_tried = [\n",
    "    \"Reinforcement Learning\",\n",
    "    \"MIP for medium N (10-50)\",\n",
    "    \"Constraint Programming with global constraints\",\n",
    "    \"Lattice-based initialization with optimal spacing\",\n",
    "    \"No-fit polygon (NFP) based placement\",\n",
    "    \"Jostle algorithm\",\n",
    "    \"Density gradient flow\",\n",
    "    \"Global boundary tension optimization\"\n",
    "]\n",
    "for a in approaches_not_tried:\n",
    "    print(f\"  ✗ {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbf4407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.434538Z",
     "iopub.status.busy": "2026-01-24T23:45:21.434413Z",
     "iopub.status.idle": "2026-01-24T23:45:21.439603Z",
     "shell.execute_reply": "2026-01-24T23:45:21.439191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orientation analysis:\n",
      "  N=10: Up=8, Down=2, Ratio=0.80\n",
      "  N=50: Up=26, Down=24, Ratio=0.52\n",
      "  N=100: Up=50, Down=50, Ratio=0.50\n",
      "  N=150: Up=78, Down=72, Ratio=0.52\n",
      "  N=200: Up=101, Down=99, Ratio=0.51\n"
     ]
    }
   ],
   "source": [
    "# Analyze the crystallization pattern from the Why Not kernel\n",
    "# The kernel shows that trees form lattice patterns with alternating orientations\n",
    "\n",
    "# Let's analyze the current solution's orientation distribution\n",
    "print(\"Orientation analysis:\")\n",
    "for n in [10, 50, 100, 150, 200]:\n",
    "    group = df[df['n_val'] == n]\n",
    "    angles = group['degf'].values % 360\n",
    "    \n",
    "    # Count trees pointing up (0-90 or 270-360) vs down (90-270)\n",
    "    up = np.sum((angles <= 90) | (angles >= 270))\n",
    "    down = np.sum((angles > 90) & (angles < 270))\n",
    "    \n",
    "    print(f\"  N={n}: Up={up}, Down={down}, Ratio={up/(up+down):.2f}\")\n",
    "\n",
    "# If the ratio is close to 0.5, trees are alternating orientations\n",
    "# This is the \"crystallization\" pattern mentioned in the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5931c05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T23:45:21.440505Z",
     "iopub.status.busy": "2026-01-24T23:45:21.440390Z",
     "iopub.status.idle": "2026-01-24T23:45:24.559775Z",
     "shell.execute_reply": "2026-01-24T23:45:24.559332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 candidate files in snapshot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current submission score: 70.626088\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any candidate files in the snapshot that might be better\n",
    "import os\n",
    "\n",
    "candidate_dir = '/home/nonroot/snapshots/santa-2025/21222392487/code/submission_candidates'\n",
    "if os.path.exists(candidate_dir):\n",
    "    candidates = os.listdir(candidate_dir)\n",
    "    print(f\"Found {len(candidates)} candidate files in snapshot\")\n",
    "    \n",
    "    # Score a few candidates to see if any are better\n",
    "    from shapely.geometry import Polygon\n",
    "    from shapely import affinity\n",
    "    from shapely.strtree import STRtree\n",
    "    \n",
    "    def get_tree_polygon(x, y, deg):\n",
    "        TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "        TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "        p = Polygon(zip(TX, TY))\n",
    "        p = affinity.rotate(p, deg, origin=(0, 0))\n",
    "        p = affinity.translate(p, x, y)\n",
    "        return p\n",
    "    \n",
    "    def score_submission(filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['xf'] = df['x'].apply(lambda v: float(str(v).lstrip('s')))\n",
    "        df['yf'] = df['y'].apply(lambda v: float(str(v).lstrip('s')))\n",
    "        df['degf'] = df['deg'].apply(lambda v: float(str(v).lstrip('s')))\n",
    "        df['n_val'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "        \n",
    "        total_score = 0\n",
    "        for n in range(1, 201):\n",
    "            group = df[df['n_val'] == n]\n",
    "            if len(group) != n:\n",
    "                return None  # Invalid\n",
    "            \n",
    "            # Get bounding box of all tree polygons\n",
    "            all_coords = []\n",
    "            for _, row in group.iterrows():\n",
    "                poly = get_tree_polygon(row['xf'], row['yf'], row['degf'])\n",
    "                coords = np.array(poly.exterior.coords)\n",
    "                all_coords.append(coords)\n",
    "            all_coords = np.vstack(all_coords)\n",
    "            \n",
    "            x_range = all_coords[:, 0].max() - all_coords[:, 0].min()\n",
    "            y_range = all_coords[:, 1].max() - all_coords[:, 1].min()\n",
    "            side = max(x_range, y_range)\n",
    "            total_score += (side ** 2) / n\n",
    "        \n",
    "        return total_score\n",
    "    \n",
    "    # Score the current submission\n",
    "    current_score = score_submission('/home/submission/submission.csv')\n",
    "    print(f\"\\nCurrent submission score: {current_score:.6f}\")\n",
    "else:\n",
    "    print(\"Candidate directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print(\"=\"*60)\n",
    "print(\"LOOP 2 ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCurrent best valid LB score: 70.626088\")\n",
    "print(f\"Target score: 68.897509\")\n",
    "print(f\"Gap: 1.728579 (2.51%)\")\n",
    "print(f\"\\nKey findings:\")\n",
    "print(\"1. 38 experiments in snapshot all converged to ~70.624\")\n",
    "print(\"2. All standard approaches (SA, GA, bbox3, MIP, ensemble) exhausted\")\n",
    "print(\"3. Need ~1.23% reduction in ALL side lengths to reach target\")\n",
    "print(\"4. Local overlap validation is LESS strict than Kaggle's\")\n",
    "print(\"5. Trees show crystallization pattern (alternating orientations)\")\n",
    "print(f\"\\nRecommended next steps:\")\n",
    "print(\"1. Try fundamentally different initialization (lattice-based)\")\n",
    "print(\"2. Use more conservative overlap detection (add buffer)\")\n",
    "print(\"3. Focus on N=2-50 where improvements have highest leverage\")\n",
    "print(\"4. Try NFP-based placement for guaranteed non-overlap\")\n",
    "print(\"5. Research what top LB teams are doing differently\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
