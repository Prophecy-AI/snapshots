{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6bf0c7",
   "metadata": {},
   "source": [
    "# Loop 16 Strategic Analysis\n",
    "\n",
    "## Current Situation\n",
    "- Best CV/LB: 70.630478 (from ensemble of 25+ sources)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.711 points (2.42%)\n",
    "- Submissions used: 6/100 (84 remaining)\n",
    "\n",
    "## Key Findings from 17 Experiments\n",
    "1. All public solutions converge to ~70.63 (same local optimum)\n",
    "2. SA optimizers (bbox3, sa_v1_parallel) produce overlapping trees\n",
    "3. Grid-based approaches (zaburo, tessellation) are fundamentally worse\n",
    "4. Tree removal found only 1 tiny improvement (0.00001345)\n",
    "5. Basin hopping, GA, constraint programming - no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0267169d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T21:38:30.182166Z",
     "iopub.status.busy": "2026-01-20T21:38:30.181642Z",
     "iopub.status.idle": "2026-01-20T21:38:35.594191Z",
     "shell.execute_reply": "2026-01-20T21:38:35.593737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ensemble_best.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 70.63047845\n",
      "Target: 68.919154\n",
      "Gap: 1.711324 (2.48%)\n",
      "\n",
      "Top 20 N values by score contribution:\n",
      "  N=  1: score=0.661250 (0.94%)\n",
      "  N=  2: score=0.450779 (0.64%)\n",
      "  N=  3: score=0.434745 (0.62%)\n",
      "  N=  5: score=0.416850 (0.59%)\n",
      "  N=  4: score=0.416545 (0.59%)\n",
      "  N=  7: score=0.399897 (0.57%)\n",
      "  N=  6: score=0.399610 (0.57%)\n",
      "  N=  9: score=0.387415 (0.55%)\n",
      "  N=  8: score=0.385407 (0.55%)\n",
      "  N= 15: score=0.376978 (0.53%)\n",
      "  N= 10: score=0.376630 (0.53%)\n",
      "  N= 21: score=0.376451 (0.53%)\n",
      "  N= 20: score=0.376057 (0.53%)\n",
      "  N= 22: score=0.375258 (0.53%)\n",
      "  N= 11: score=0.374924 (0.53%)\n",
      "  N= 16: score=0.374128 (0.53%)\n",
      "  N= 26: score=0.373997 (0.53%)\n",
      "  N= 12: score=0.372724 (0.53%)\n",
      "  N= 13: score=0.372294 (0.53%)\n",
      "  N= 25: score=0.372144 (0.53%)\n"
     ]
    }
   ],
   "source": [
    "# Load current best and analyze per-N scores\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def get_tree_list_side_length(tree_list):\n",
    "    all_polygons = [t.polygon for t in tree_list]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    return Decimal(max(bounds[2] - bounds[0], bounds[3] - bounds[1])) / scale_factor\n",
    "\n",
    "def parse_csv(csv_path):\n",
    "    result = pd.read_csv(csv_path)\n",
    "    result['x'] = result['x'].str.strip('s')\n",
    "    result['y'] = result['y'].str.strip('s')\n",
    "    result['deg'] = result['deg'].str.strip('s')\n",
    "    result[['group_id', 'item_id']] = result['id'].str.split('_', n=2, expand=True)\n",
    "    dict_of_tree_list = {}\n",
    "    dict_of_side_length = {}\n",
    "    for group_id, group_data in result.groupby('group_id'):\n",
    "        tree_list = [ChristmasTree(center_x=row['x'], center_y=row['y'], angle=row['deg']) for _, row in group_data.iterrows()]\n",
    "        dict_of_tree_list[group_id] = tree_list\n",
    "        dict_of_side_length[group_id] = get_tree_list_side_length(tree_list)\n",
    "    return dict_of_tree_list, dict_of_side_length\n",
    "\n",
    "print(\"Loading ensemble_best.csv...\")\n",
    "dict_of_tree_list, dict_of_side_length = parse_csv('/home/code/exploration/datasets/ensemble_best.csv')\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    key = f'{n:03d}'\n",
    "    side = dict_of_side_length[key]\n",
    "    score = float(side ** 2 / Decimal(n))\n",
    "    per_n_scores[n] = {'side': float(side), 'score': score}\n",
    "\n",
    "total_score = sum(v['score'] for v in per_n_scores.values())\n",
    "print(f\"Total score: {total_score:.8f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {total_score - 68.919154:.6f} ({(total_score - 68.919154)/68.919154*100:.2f}%)\")\n",
    "\n",
    "# Find N values with highest contribution to score\n",
    "contributions = [(n, v['score'], v['score']/total_score*100) for n, v in per_n_scores.items()]\n",
    "contributions.sort(key=lambda x: -x[1])\n",
    "print(\"\\nTop 20 N values by score contribution:\")\n",
    "for n, score, pct in contributions[:20]:\n",
    "    print(f\"  N={n:3d}: score={score:.6f} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cded209a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T21:38:35.595412Z",
     "iopub.status.busy": "2026-01-20T21:38:35.595278Z",
     "iopub.status.idle": "2026-01-20T21:38:35.599548Z",
     "shell.execute_reply": "2026-01-20T21:38:35.599111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 70.630478\n",
      "Target: 68.919154\n",
      "Gap: 1.711324\n",
      "\n",
      "If we improve each N by the same percentage:\n",
      "  Required reduction: 2.42%\n",
      "\n",
      "Required side length reduction per N (to close gap proportionally):\n",
      "  N=  1: side 0.8132 -> 0.8033 (reduction: 1.22%)\n",
      "  N= 10: side 1.9407 -> 1.9170 (reduction: 1.22%)\n",
      "  N= 50: side 4.2471 -> 4.1953 (reduction: 1.22%)\n",
      "  N=100: side 5.8603 -> 5.7888 (reduction: 1.22%)\n",
      "  N=150: side 7.1105 -> 7.0239 (reduction: 1.22%)\n",
      "  N=200: side 8.2164 -> 8.1163 (reduction: 1.22%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate what improvement is needed per N to reach target\n",
    "import math\n",
    "\n",
    "target = 68.919154\n",
    "current = total_score\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current: {current:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f}\")\n",
    "\n",
    "# If we improve each N proportionally\n",
    "print(f\"\\nIf we improve each N by the same percentage:\")\n",
    "required_reduction = gap / current * 100\n",
    "print(f\"  Required reduction: {required_reduction:.2f}%\")\n",
    "\n",
    "# Calculate required side length reduction for each N\n",
    "print(f\"\\nRequired side length reduction per N (to close gap proportionally):\")\n",
    "for n in [1, 10, 50, 100, 150, 200]:\n",
    "    current_side = per_n_scores[n]['side']\n",
    "    current_score = per_n_scores[n]['score']\n",
    "    # If we reduce score by required_reduction%, what's the new side?\n",
    "    new_score = current_score * (1 - required_reduction/100)\n",
    "    new_side = math.sqrt(new_score * n)\n",
    "    side_reduction = (current_side - new_side) / current_side * 100\n",
    "    print(f\"  N={n:3d}: side {current_side:.4f} -> {new_side:.4f} (reduction: {side_reduction:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691cc6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T21:38:35.600751Z",
     "iopub.status.busy": "2026-01-20T21:38:35.600603Z",
     "iopub.status.idle": "2026-01-20T21:38:35.604658Z",
     "shell.execute_reply": "2026-01-20T21:38:35.604238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency analysis (comparing to theoretical minimum):\n",
      "============================================================\n",
      "N=  1: side=0.8132, theoretical_min=0.8367, efficiency=102.9%\n",
      "N=  2: side=0.9495, theoretical_min=1.1832, efficiency=124.6%\n",
      "N=  3: side=1.1420, theoretical_min=1.4491, efficiency=126.9%\n",
      "N=  4: side=1.2908, theoretical_min=1.6733, efficiency=129.6%\n",
      "N=  5: side=1.4437, theoretical_min=1.8708, efficiency=129.6%\n",
      "N=  6: side=1.5484, theoretical_min=2.0494, efficiency=132.4%\n",
      "N=  7: side=1.6731, theoretical_min=2.2136, efficiency=132.3%\n",
      "N=  8: side=1.7559, theoretical_min=2.3664, efficiency=134.8%\n",
      "N=  9: side=1.8673, theoretical_min=2.5100, efficiency=134.4%\n",
      "N= 10: side=1.9407, theoretical_min=2.6458, efficiency=136.3%\n",
      "N= 50: side=4.2471, theoretical_min=5.9161, efficiency=139.3%\n",
      "N=100: side=5.8603, theoretical_min=8.3666, efficiency=142.8%\n",
      "N=150: side=7.1105, theoretical_min=10.2470, efficiency=144.1%\n",
      "N=200: side=8.2164, theoretical_min=11.8322, efficiency=144.0%\n"
     ]
    }
   ],
   "source": [
    "# Analyze which N values have the most \"room for improvement\"\n",
    "# by comparing to theoretical lower bounds\n",
    "\n",
    "# For N trees arranged in a grid, the minimum side is approximately:\n",
    "# side = sqrt(N) * tree_spacing\n",
    "# where tree_spacing depends on tree dimensions and rotation\n",
    "\n",
    "# Tree dimensions at 0 degrees: width=0.7, height=1.0\n",
    "# At 45 degrees: diagonal ~1.22\n",
    "\n",
    "print(\"Efficiency analysis (comparing to theoretical minimum):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for n in range(1, 201):\n",
    "    current_side = per_n_scores[n]['side']\n",
    "    current_score = per_n_scores[n]['score']\n",
    "    \n",
    "    # Theoretical minimum: if trees could be packed perfectly\n",
    "    # Assume tree footprint ~0.7 x 1.0 = 0.7 sq units\n",
    "    # Minimum area = N * 0.7 (if 100% efficient)\n",
    "    # Minimum side = sqrt(N * 0.7)\n",
    "    theoretical_min_side = math.sqrt(n * 0.7)\n",
    "    theoretical_min_score = theoretical_min_side ** 2 / n\n",
    "    \n",
    "    # Efficiency = theoretical_min / actual\n",
    "    efficiency = theoretical_min_side / current_side * 100\n",
    "    \n",
    "    # Only show N values with low efficiency (room for improvement)\n",
    "    if efficiency < 50 or n <= 10 or n % 50 == 0:\n",
    "        print(f\"N={n:3d}: side={current_side:.4f}, theoretical_min={theoretical_min_side:.4f}, efficiency={efficiency:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d270ab1",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **The gap is 2.42%** - This is significant but not impossible\n",
    "2. **Top N values contribute disproportionately** - Focus on high-contribution N values\n",
    "3. **Packing efficiency varies** - Some N values may have more room for improvement\n",
    "4. **All public solutions converge to same optimum** - Need fundamentally different approach\n",
    "\n",
    "## What Hasn't Been Tried\n",
    "\n",
    "1. **Egortrushin tessellation SA** - Creates grid patterns with specific dimensions\n",
    "   - N=72: [4,9] grid\n",
    "   - N=100: [5,10] grid\n",
    "   - N=200: [7,15] grid (210 trees, delete 10 worst)\n",
    "   \n",
    "2. **Asymmetric layouts** - Discussion mentions top teams use asymmetric solutions\n",
    "\n",
    "3. **Very high temperature SA from random starts** - Escape current basin entirely\n",
    "\n",
    "4. **Hybrid: tessellation + tree deletion** - Generate tessellation, then extract for smaller N"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
