{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4149085c",
   "metadata": {},
   "source": [
    "# Experiment 004: sa_fast_v2 Optimization\n",
    "\n",
    "Try the sa_fast_v2 optimizer (Simulated Annealing with fractional translation) on the VALIDATED baseline.\n",
    "\n",
    "**Starting point**: candidate_024.csv (LB: 70.626088) - Kaggle validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5045269c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:51:18.065866Z",
     "iopub.status.busy": "2026-01-25T08:51:18.065473Z",
     "iopub.status.idle": "2026-01-25T08:51:18.470174Z",
     "shell.execute_reply": "2026-01-25T08:51:18.469738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring functions defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import njit\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = mny = 1e300\n",
    "    mxx = mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xs[i]\n",
    "            Y = s * tx[j] + c * ty[j] + ys[i]\n",
    "            mnx, mxx = min(mnx, X), max(mxx, X)\n",
    "            mny, mxy = min(mny, Y), max(mxy, Y)\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def calculate_total_score(df):\n",
    "    total_score = 0.0\n",
    "    scores_by_n = {}\n",
    "    for n in range(1, 201):\n",
    "        mask = df['id'].str.startswith(f'{n:03d}_')\n",
    "        group = df[mask]\n",
    "        if len(group) != n:\n",
    "            continue\n",
    "        xs = group['x'].str[1:].astype(float).values\n",
    "        ys = group['y'].str[1:].astype(float).values\n",
    "        degs = group['deg'].str[1:].astype(float).values\n",
    "        score = score_group(xs, ys, degs, TX, TY)\n",
    "        scores_by_n[n] = score\n",
    "        total_score += score\n",
    "    return total_score, scores_by_n\n",
    "\n",
    "print(\"Scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28e37d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:51:18.471613Z",
     "iopub.status.busy": "2026-01-25T08:51:18.471446Z",
     "iopub.status.idle": "2026-01-25T08:51:19.378997Z",
     "shell.execute_reply": "2026-01-25T08:51:19.378595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: 70.626088\n",
      "Expected LB: 70.626088\n",
      "Rows: 20100\n",
      "\n",
      "This is the VALIDATED submission (candidate_024.csv)\n"
     ]
    }
   ],
   "source": [
    "# Calculate initial score of VALIDATED submission\n",
    "os.chdir('/home/code/experiments/004_sa_fast_v2_optimization')\n",
    "df_initial = pd.read_csv('submission.csv')\n",
    "initial_score, initial_scores_by_n = calculate_total_score(df_initial)\n",
    "print(f\"Initial Score: {initial_score:.6f}\")\n",
    "print(f\"Expected LB: 70.626088\")\n",
    "print(f\"Rows: {len(df_initial)}\")\n",
    "print(f\"\\nThis is the VALIDATED submission (candidate_024.csv)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2a1f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:51:19.380263Z",
     "iopub.status.busy": "2026-01-25T08:51:19.380121Z",
     "iopub.status.idle": "2026-01-25T08:51:19.384865Z",
     "shell.execute_reply": "2026-01-25T08:51:19.384520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout: Loading csv: submission1.csv\n",
      "\n",
      "stderr: Error: Could not open input CSV: submission1.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check sa_fast_v2 help to understand parameters\n",
    "result = subprocess.run(['./sa_fast_v2', '--help'], capture_output=True, text=True, timeout=10)\n",
    "print(\"stdout:\", result.stdout)\n",
    "print(\"stderr:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85f72e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:52:09.008442Z",
     "iopub.status.busy": "2026-01-25T08:52:09.007869Z",
     "iopub.status.idle": "2026-01-25T08:52:09.013038Z",
     "shell.execute_reply": "2026-01-25T08:52:09.012664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa_fast_v2 runner defined\n"
     ]
    }
   ],
   "source": [
    "# Run sa_fast_v2 optimizer\n",
    "# NOTE: sa_fast_v2 expects input as \"submission1.csv\" and outputs to \"submission2.csv\"\n",
    "\n",
    "def run_sa_fast_v2(n_iter, rounds, timeout=600):\n",
    "    \"\"\"Run sa_fast_v2 optimizer and return the improvement\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Copy current submission to submission1.csv (input)\n",
    "    import shutil\n",
    "    shutil.copy('submission.csv', 'submission1.csv')\n",
    "    \n",
    "    # Read initial score\n",
    "    df_before = pd.read_csv('submission1.csv')\n",
    "    score_before, _ = calculate_total_score(df_before)\n",
    "    \n",
    "    # Run sa_fast_v2\n",
    "    cmd = f'./sa_fast_v2 -n {n_iter} -r {rounds}'\n",
    "    print(f\"Running: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            cmd.split(),\n",
    "            cwd='/home/code/experiments/004_sa_fast_v2_optimization',\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        print(f\"stdout: {result.stdout[:500]}...\")\n",
    "        if result.stderr:\n",
    "            print(f\"stderr: {result.stderr[:200]}\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Timeout after {timeout}s\")\n",
    "    \n",
    "    # Read output from submission2.csv\n",
    "    if os.path.exists('submission2.csv'):\n",
    "        df_after = pd.read_csv('submission2.csv')\n",
    "        score_after, _ = calculate_total_score(df_after)\n",
    "        # Copy improved result back to submission.csv\n",
    "        shutil.copy('submission2.csv', 'submission.csv')\n",
    "        shutil.copy('submission2.csv', 'submission1.csv')  # For next iteration\n",
    "    else:\n",
    "        df_after = df_before\n",
    "        score_after = score_before\n",
    "        print(\"No output file generated!\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    improvement = score_before - score_after\n",
    "    \n",
    "    print(f\"Score: {score_before:.6f} -> {score_after:.6f} (improvement: {improvement:.6f})\")\n",
    "    print(f\"Time: {elapsed:.1f}s\")\n",
    "    \n",
    "    return score_after, improvement\n",
    "\n",
    "print(\"sa_fast_v2 runner defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb24ee18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:52:09.013964Z",
     "iopub.status.busy": "2026-01-25T08:52:09.013871Z",
     "iopub.status.idle": "2026-01-25T09:12:13.713222Z",
     "shell.execute_reply": "2026-01-25T09:12:13.712840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running sa_fast_v2 optimization\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: ./sa_fast_v2 -n 5000 -r 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout after 300s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 70.626088 -> 70.623148 (improvement: 0.002940)\n",
      "Time: 301.1s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: ./sa_fast_v2 -n 5000 -r 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout after 300s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 70.623148 -> 70.622889 (improvement: 0.000260)\n",
      "Time: 301.2s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: ./sa_fast_v2 -n 10000 -r 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout after 300s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 70.622889 -> 70.622844 (improvement: 0.000044)\n",
      "Time: 301.2s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: ./sa_fast_v2 -n 10000 -r 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout after 300s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 70.622844 -> 70.622842 (improvement: 0.000002)\n",
      "Time: 301.2s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run sa_fast_v2 with aggressive parameters\n",
    "print(\"=\" * 60)\n",
    "print(\"Running sa_fast_v2 optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_score = initial_score\n",
    "results = []\n",
    "\n",
    "# Try different parameter combinations\n",
    "for n_iter in [5000, 10000]:\n",
    "    for rounds in [50, 80]:\n",
    "        score, improvement = run_sa_fast_v2(n_iter, rounds, timeout=300)\n",
    "        results.append({'n': n_iter, 'r': rounds, 'score': score, 'improvement': improvement})\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844553a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue optimization - sa_fast_v2 is working!\n",
    "print(\"=\" * 60)\n",
    "print(\"CONTINUING sa_fast_v2 optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run more iterations to squeeze out more improvement\n",
    "for n_iter in [15000]:\n",
    "    for rounds in [80, 100]:\n",
    "        score, improvement = run_sa_fast_v2(n_iter, rounds, timeout=400)\n",
    "        results.append({'n': n_iter, 'r': rounds, 'score': score, 'improvement': improvement})\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b356104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Initial score (validated): {initial_score:.6f}\")\n",
    "print(f\"Final score: {best_score:.6f}\")\n",
    "print(f\"Total improvement: {initial_score - best_score:.6f}\")\n",
    "print(f\"\\nAll runs:\")\n",
    "for r in results:\n",
    "    print(f\"  n={r['n']:5d}, r={r['r']:3d}: score={r['score']:.6f}, improvement={r['improvement']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final score and copy to submission folder\n",
    "df_final = pd.read_csv('submission.csv')\n",
    "final_score, final_scores_by_n = calculate_total_score(df_final)\n",
    "print(f\"\\nFinal verified score: {final_score:.6f}\")\n",
    "\n",
    "import shutil\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy('submission.csv', '/home/submission/submission.csv')\n",
    "print(\"Copied to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': final_score,\n",
    "    'initial_score': initial_score,\n",
    "    'improvement': initial_score - final_score,\n",
    "    'optimization_runs': results,\n",
    "    'source': 'candidate_024.csv (LB validated: 70.626088)'\n",
    "}\n",
    "\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics saved. Final CV Score: {final_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
