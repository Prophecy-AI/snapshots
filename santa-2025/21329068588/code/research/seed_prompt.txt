# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.616068 (006_strict_hybrid) - but FAILED Kaggle validation
- Best LB score: 70.622435 (004_sa_fast_v2_optimization) - VALIDATED
- Target: 68.891380
- Gap to target: 1.731 points (2.51%)
- Submissions used: 6/100 (94 remaining)

## CRITICAL ISSUE: Overlap Detection Mismatch
The last 3 submissions failed Kaggle validation with overlap errors:
- 001_baseline: "Overlapping trees in group 008"
- 003_bbox3_optimization: "Overlapping trees in group 008"
- 005_hybrid_ensemble: "Overlapping trees in group 031"
- 006_strict_hybrid: "Overlapping trees in group 042"

**Local overlap detection (even with exact Kaggle code) shows ZERO overlaps, but Kaggle rejects them.**

This suggests either:
1. Shapely behavior differs between environments
2. Subtle precision issues in rotation/translation
3. File corruption during transfer

**SAFE BASELINE: candidate_003.csv (LB=70.622435) is the ONLY validated submission.**

## Response to Evaluator
The evaluator correctly identified that:
1. 006_strict_hybrid was NOT submitted - it was submitted but FAILED (group 042)
2. External sources haven't been explored - AGREED, this is a priority
3. The 1.73 point gap is LARGE - AGREED, need fundamentally different approaches
4. Current improvement rate (~0.006/experiment) is too slow - AGREED

**Key disagreement:** The evaluator suggested submitting 006_strict_hybrid immediately, but it already failed. We need to understand WHY local validation passes but Kaggle fails before creating more submissions.

## CV-LB Relationship Analysis
- CV-LB gap is ZERO for validated submissions (70.6224 CV = 70.6224 LB)
- Local scoring is perfectly calibrated
- The issue is NOT CV-LB gap, it's OVERLAP DETECTION

## The Real Problem: 1.73 Point Gap

**Current approaches are at a LOCAL OPTIMUM:**
- bbox3: ZERO improvement
- sa_fast_v2: 0.003653 improvement
- Hybrid ensemble: 0.006366 improvement (but fails validation)

**At this rate, we need ~287 experiments to reach target. This is NOT viable.**

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY] Fix Overlap Detection**
Before ANY new experiments, we must understand why local validation passes but Kaggle fails.

**Hypothesis:** The issue is floating-point precision in rotation/translation. Kaggle may use different rounding.

**Test:** 
- Compare the exact bytes of submission files before/after transfer
- Check if Kaggle's Shapely version (2.1.2) behaves differently
- Try rounding coordinates to fewer decimal places

### 2. **[HIGH PRIORITY] Try External Sources**
The jonathanchan kernel shows top scores come from 16+ external sources:
- GitHub: `https://raw.githubusercontent.com/SmartManoj/Santa-Scoreboard/main/submission.csv`
- Telegram datasets
- Multiple Kaggle datasets

**Action:** Download and ensemble from these sources, using ONLY the validated baseline for N values that have overlaps.

### 3. **[MEDIUM PRIORITY] Try Different Optimizers**
We've only tried bbox3 and sa_fast_v2. Available but untried:
- sa_v1_parallel (fractional translation steps)
- tree_packer_v18, tree_packer_v21
- bbox3_advanced

### 4. **[RESEARCH] Fundamentally Different Algorithms**
The 1.73 point gap cannot be closed by incremental optimization. Research suggests:

**No-Fit Polygon (NFP):**
- Precompute overlap-free placement regions → O(1) collision checks
- Can find placements that SA/bbox3 miss

**Genetic Algorithm with Custom Operators:**
- Custom crossover: swap partial solutions between candidates
- Custom mutation: rotate/translate clusters
- Population-based search escapes local optima

**Learning-based Methods (GFPack++):**
- Attention-based gradient field learning
- Supports continuous rotation
- Outperforms traditional heuristics

### 5. **[FOCUS] Large N Values (101-200)**
Score distribution:
- Small N (1-10): 6.1%
- Medium-Small (11-30): 10.5%
- Medium (31-57): 13.9%
- Large (58-100): 21.4%
- Very Large (101-200): **48.1%**

**Nearly half the score comes from N=101-200.** Improving these has the highest impact.

## What NOT to Try
- ❌ More bbox3/SA iterations (already at local optimum)
- ❌ Different SA parameters (diminishing returns)
- ❌ Creating hybrid ensembles without fixing overlap detection first
- ❌ Submitting without local Kaggle-exact validation

## Validation Notes
- Use EXACT Kaggle metric code (scale_factor=1e18, Decimal precision=25)
- Use Shapely 2.1.2 (same as Kaggle)
- Check: `poly.intersects(other) and not poly.touches(other)`
- **CRITICAL:** Even if local validation passes, Kaggle may still reject

## SUBMISSION STRATEGY
- Remaining submissions: 94
- **DO NOT submit until overlap detection issue is resolved**
- When submitting, use ONLY the validated baseline (candidate_003.csv) as the base
- Only replace N values that are GUARANTEED overlap-free

## Immediate Next Steps

1. **Investigate overlap detection discrepancy:**
   - Check if submission file is corrupted during transfer
   - Try rounding coordinates to 10 decimal places
   - Test with a minimal change to validated submission

2. **Download external sources and compare:**
   - Get GitHub submission
   - Compare per-N scores with our validated baseline
   - Identify which N values have better overlap-free solutions

3. **If overlap issue persists, submit validated baseline:**
   - candidate_003.csv is KNOWN to pass Kaggle
   - Score: 70.622435
   - This establishes a safe baseline while we debug

## Key Insight
The problem is NOT finding better solutions - we have solutions that score 70.52 locally.
The problem is that these solutions FAIL Kaggle validation.
We must fix the validation mismatch before any further optimization.
