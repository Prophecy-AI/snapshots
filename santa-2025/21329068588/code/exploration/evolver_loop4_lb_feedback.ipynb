{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81728101",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "**Submission Result**: CV 70.6224 | LB 70.6224 (gap: +0.0000)\n",
    "\n",
    "**Key Insight**: CV-LB gap is ZERO! This means our local scoring is perfectly calibrated.\n",
    "\n",
    "## Current Status\n",
    "- Best LB: 70.6224\n",
    "- Target: 68.8914\n",
    "- Gap: 1.73 points (2.5%)\n",
    "\n",
    "## Key Findings from Research\n",
    "\n",
    "1. **jonathanchan kernel** shows top scores come from **ensembling 16+ external sources**:\n",
    "   - GitHub: SmartManoj/Santa-Scoreboard\n",
    "   - Telegram shared solutions\n",
    "   - Multiple Kaggle datasets and notebooks\n",
    "   \n",
    "2. **The kernel uses a C++ optimizer (sa_v1_parallel)** with:\n",
    "   - Fractional translation steps: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n",
    "   - SA with perturb + local search\n",
    "   - Population-based optimization (keeps top 3)\n",
    "\n",
    "3. **Key strategy**: For each N, take the BEST solution from ALL sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5897d984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T09:41:06.499017Z",
     "iopub.status.busy": "2026-01-25T09:41:06.498459Z",
     "iopub.status.idle": "2026-01-25T09:41:06.877927Z",
     "shell.execute_reply": "2026-01-25T09:41:06.877503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring functions ready\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from numba import njit\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = mny = 1e300\n",
    "    mxx = mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xs[i]\n",
    "            Y = s * tx[j] + c * ty[j] + ys[i]\n",
    "            mnx, mxx = min(mnx, X), max(mxx, X)\n",
    "            mny, mxy = min(mny, Y), max(mxy, Y)\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "def calculate_scores_by_n(df):\n",
    "    scores = {}\n",
    "    for n in range(1, 201):\n",
    "        mask = df['id'].str.startswith(f'{n:03d}_')\n",
    "        group = df[mask]\n",
    "        if len(group) != n:\n",
    "            continue\n",
    "        xs = strip(group['x'].values)\n",
    "        ys = strip(group['y'].values)\n",
    "        degs = strip(group['deg'].values)\n",
    "        scores[n] = score_group(xs, ys, degs, TX, TY)\n",
    "    return scores\n",
    "\n",
    "print('Scoring functions ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef4bc4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T09:41:06.879155Z",
     "iopub.status.busy": "2026-01-25T09:41:06.878994Z",
     "iopub.status.idle": "2026-01-25T09:41:07.690406Z",
     "shell.execute_reply": "2026-01-25T09:41:07.689982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best score: 70.622435\n",
      "Target: 68.891380\n",
      "Gap: 1.731055 (2.51%)\n"
     ]
    }
   ],
   "source": [
    "# Load our current best submission\n",
    "df_current = pd.read_csv('/home/submission/submission.csv')\n",
    "current_scores = calculate_scores_by_n(df_current)\n",
    "current_total = sum(current_scores.values())\n",
    "print(f'Current best score: {current_total:.6f}')\n",
    "print(f'Target: 68.891380')\n",
    "print(f'Gap: {current_total - 68.891380:.6f} ({(current_total - 68.891380) / 68.891380 * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e2c6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T09:41:07.691533Z",
     "iopub.status.busy": "2026-01-25T09:41:07.691358Z",
     "iopub.status.idle": "2026-01-25T09:41:07.739695Z",
     "shell.execute_reply": "2026-01-25T09:41:07.739367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2104 potential submission files\n",
      "\n",
      "Sample files:\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/004_sa_v1_parallel/submission_best.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/004_sa_v1_parallel/submission_v18.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/005_backward_propagation/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/005_backward_propagation/submission_v21.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/002_preoptimized/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_000.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_004.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_002.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_003.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_001.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT4.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT3.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT2.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_70_936673758122.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_70_926149550346.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT1.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_opt1.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Find all CSV files in snapshots that could be ensemble sources\n",
    "import subprocess\n",
    "\n",
    "# Search for all submission files in snapshots\n",
    "result = subprocess.run(\n",
    "    ['find', '/home/nonroot/snapshots', '-name', '*.csv', '-type', 'f'],\n",
    "    capture_output=True, text=True, timeout=60\n",
    ")\n",
    "\n",
    "csv_files = [f for f in result.stdout.strip().split('\\n') if f and 'submission' in f.lower()]\n",
    "print(f'Found {len(csv_files)} potential submission files')\n",
    "print('\\nSample files:')\n",
    "for f in csv_files[:20]:\n",
    "    print(f'  {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ca27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all potential ensemble sources\n",
    "from tqdm import tqdm\n",
    "\n",
    "ensemble_sources = []\n",
    "\n",
    "for fp in tqdm(csv_files[:100], desc='Scoring files'):  # Limit to first 100 for speed\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            continue\n",
    "        if len(df) < 20000:  # Should have ~20100 rows\n",
    "            continue\n",
    "        \n",
    "        scores = calculate_scores_by_n(df)\n",
    "        if len(scores) == 200:\n",
    "            total = sum(scores.values())\n",
    "            ensemble_sources.append({\n",
    "                'file': fp,\n",
    "                'total_score': total,\n",
    "                'scores_by_n': scores\n",
    "            })\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f'\\nFound {len(ensemble_sources)} valid ensemble sources')\n",
    "ensemble_sources.sort(key=lambda x: x['total_score'])\n",
    "\n",
    "print('\\nTop 10 sources by total score:')\n",
    "for i, src in enumerate(ensemble_sources[:10]):\n",
    "    print(f'{i+1}. {src[\"total_score\"]:.6f} - {src[\"file\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble: for each N, take the best solution from all sources\n",
    "if len(ensemble_sources) > 0:\n",
    "    best_per_n = {}\n",
    "    best_source_per_n = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        best_score = float('inf')\n",
    "        best_src = None\n",
    "        \n",
    "        for src in ensemble_sources:\n",
    "            if n in src['scores_by_n']:\n",
    "                if src['scores_by_n'][n] < best_score:\n",
    "                    best_score = src['scores_by_n'][n]\n",
    "                    best_src = src['file']\n",
    "        \n",
    "        best_per_n[n] = best_score\n",
    "        best_source_per_n[n] = best_src\n",
    "    \n",
    "    ensemble_total = sum(best_per_n.values())\n",
    "    print(f'Ensemble total score: {ensemble_total:.6f}')\n",
    "    print(f'Current best: {current_total:.6f}')\n",
    "    print(f'Improvement: {current_total - ensemble_total:.6f}')\n",
    "    \n",
    "    # Show which N values improved\n",
    "    improved_n = []\n",
    "    for n in range(1, 201):\n",
    "        if n in current_scores and n in best_per_n:\n",
    "            if best_per_n[n] < current_scores[n] - 1e-9:\n",
    "                improved_n.append((n, current_scores[n] - best_per_n[n], best_source_per_n[n]))\n",
    "    \n",
    "    print(f'\\nN values with improvement ({len(improved_n)} total):')\n",
    "    improved_n.sort(key=lambda x: -x[1])  # Sort by improvement\n",
    "    for n, imp, src in improved_n[:20]:\n",
    "        print(f'  N={n:3d}: improvement={imp:.6f} from {src.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a35776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ensemble submission\n",
    "if len(ensemble_sources) > 0 and ensemble_total < current_total:\n",
    "    print('Building ensemble submission...')\n",
    "    \n",
    "    rows = []\n",
    "    for n in range(1, 201):\n",
    "        best_src = best_source_per_n[n]\n",
    "        if best_src:\n",
    "            df_src = pd.read_csv(best_src)\n",
    "            mask = df_src['id'].str.startswith(f'{n:03d}_')\n",
    "            rows.append(df_src[mask][['id', 'x', 'y', 'deg']])\n",
    "    \n",
    "    df_ensemble = pd.concat(rows, ignore_index=True)\n",
    "    \n",
    "    # Sort properly\n",
    "    df_ensemble['sn'] = df_ensemble['id'].str.split('_').str[0].astype(int)\n",
    "    df_ensemble['si'] = df_ensemble['id'].str.split('_').str[1].astype(int)\n",
    "    df_ensemble = df_ensemble.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "    \n",
    "    # Verify score\n",
    "    ensemble_scores = calculate_scores_by_n(df_ensemble)\n",
    "    verified_total = sum(ensemble_scores.values())\n",
    "    print(f'Verified ensemble score: {verified_total:.6f}')\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs('/home/code/experiments/005_ensemble', exist_ok=True)\n",
    "    df_ensemble.to_csv('/home/code/experiments/005_ensemble/submission.csv', index=False)\n",
    "    print('Saved to /home/code/experiments/005_ensemble/submission.csv')\n",
    "else:\n",
    "    print('No improvement from ensemble - all sources are worse or equal')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
