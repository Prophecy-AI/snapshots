Tree Packer v21 - ENHANCED (26 threads)
NEW: Swap moves, multi-angle restarts, higher SA temperature
Iterations: 25000, Restarts: 256
Processing all n=1..200 concurrently
Loading submission.csv...
Loaded 200 configs
Initial: 116.975167

Phase 1: Parallel optimization...

n=  2: 0.450864 -> 0.450823 (0.0089%)
n=  3: 0.434786 -> 0.434784 (0.0004%)
n=  4: 0.427211 -> 0.423155 (0.9496%)
n= 11: 0.464562 -> 0.458395 (1.3275%)
n=  5: 0.450554 -> 0.436195 (3.1869%)
n= 12: 0.481438 -> 0.468454 (2.6968%)
n= 13: 0.483065 -> 0.468844 (2.9439%)
n= 15: 0.503274 -> 0.496087 (1.4280%)
n=  6: 0.442914 -> 0.437027 (1.3291%)
n= 14: 0.500405 -> 0.476800 (4.7171%)
n= 19: 0.502808 -> 0.495183 (1.5163%)
n= 16: 0.523828 -> 0.500352 (4.4816%)
n=  7: 0.437389 -> 0.428150 (2.1123%)
n= 18: 0.488939 -> 0.485570 (0.6892%)
n= 17: 0.495884 -> 0.472689 (4.6774%)
n= 21: 0.528868 -> 0.519407 (1.7889%)
n= 20: 0.513856 -> 0.504153 (1.8883%)
n=  8: 0.431754 -> 0.427123 (1.0725%)
n=  9: 0.470433 -> 0.438079 (6.8774%)
n= 23: 0.529372 -> 0.510749 (3.5178%)
n= 10: 0.463989 -> 0.453521 (2.2559%)
n= 22: 0.512159 -> 0.496979 (2.9640%)
n= 26: 0.529460 -> 0.511364 (3.4180%)
n= 24: 0.544640 -> 0.534688 (1.8272%)
n= 25: 0.532620 -> 0.501879 (5.7716%)
n= 27: 0.562809 -> 0.519992 (7.6078%)
n= 31: 0.586089 -> 0.569443 (2.8402%)
n= 32: 0.585579 -> 0.569049 (2.8228%)
n= 34: 0.572456 -> 0.551571 (3.6484%)
n= 35: 0.566904 -> 0.547444 (3.4326%)
n= 33: 0.571232 -> 0.551557 (3.4444%)
n= 37: 0.566008 -> 0.556689 (1.6465%)
n= 28: 0.568528 -> 0.530235 (6.7356%)
n= 36: 0.553497 -> 0.523141 (5.4843%)
n= 40: 0.569782 -> 0.553792 (2.8065%)
n= 43: 0.566917 -> 0.563873 (0.5370%)
n= 38: 0.556496 -> 0.541017 (2.7814%)
n= 39: 0.560334 -> 0.539302 (3.7535%)
n= 41: 0.578786 -> 0.572852 (1.0252%)
n= 42: 0.571705 -> 0.554039 (3.0900%)
n= 29: 0.576758 -> 0.550680 (4.5216%)
n= 44: 0.564454 -> 0.552735 (2.0761%)
n= 45: 0.563371 -> 0.558311 (0.8981%)
n= 30: 0.566525 -> 0.538391 (4.9661%)
n= 47: 0.566002 -> 0.553868 (2.1438%)
n= 49: 0.590261 -> 0.580410 (1.6690%)
n= 48: 0.577404 -> 0.568727 (1.5028%)
n= 46: 0.570393 -> 0.554128 (2.8515%)
n= 52: 0.587703 -> 0.585506 (0.3739%)
n= 50: 0.582481 -> 0.569792 (2.1786%)
n= 51: 0.578260 -> 0.574741 (0.6086%)
n= 53: 0.579509 -> 0.576159 (0.5782%)
n= 56: 0.585203 -> 0.572616 (2.1509%)
n= 54: 0.573029 -> 0.564377 (1.5098%)
n= 57: 0.582261 -> 0.575216 (1.2098%)
n= 63: 0.573384 -> 0.562005 (1.9846%)
n= 62: 0.576426 -> 0.572760 (0.6362%)
n= 58: 0.585923 -> 0.579454 (1.1042%)
n= 55: 0.564371 -> 0.560893 (0.6164%)
n= 59: 0.578519 -> 0.571104 (1.2818%)
n= 61: 0.584777 -> 0.574514 (1.7550%)
n= 66: 0.572310 -> 0.563907 (1.4683%)
n= 64: 0.578848 -> 0.563692 (2.6183%)
n= 68: 0.572209 -> 0.566471 (1.0028%)
n= 60: 0.590801 -> 0.576577 (2.4075%)
n= 65: 0.580509 -> 0.569481 (1.8997%)
n= 69: 0.572619 -> 0.562645 (1.7420%)
n= 70: 0.591480 -> 0.584087 (1.2499%)
n= 71: 0.593654 -> 0.587826 (0.9817%)
n= 73: 0.586622 -> 0.580171 (1.0996%)
n= 67: 0.575021 -> 0.558173 (2.9300%)
n= 74: 0.579842 -> 0.576882 (0.5105%)
n= 72: 0.590944 -> 0.573075 (3.0238%)
n= 75: 0.581562 -> 0.572549 (1.5498%)
n= 77: 0.586072 -> 0.575875 (1.7398%)
n= 79: 0.598396 -> 0.594595 (0.6351%)
n= 76: 0.591708 -> 0.576342 (2.5970%)
n= 78: 0.595894 -> 0.591582 (0.7236%)
n= 84: 0.579771 -> 0.573968 (1.0008%)
n= 83: 0.584675 -> 0.580321 (0.7446%)
n= 81: 0.594131 -> 0.589579 (0.7662%)
n= 80: 0.592544 -> 0.590503 (0.3444%)
n= 85: 0.581938 -> 0.573344 (1.4767%)
n= 88: 0.581754 -> 0.571749 (1.7199%)
n= 82: 0.590470 -> 0.583520 (1.1771%)
n= 86: 0.583322 -> 0.572476 (1.8593%)
n= 87: 0.581262 -> 0.574076 (1.2362%)
n= 91: 0.581463 -> 0.576349 (0.8795%)
n= 92: 0.589389 -> 0.586552 (0.4814%)
n= 93: 0.592040 -> 0.588152 (0.6566%)
n= 94: 0.590230 -> 0.588034 (0.3721%)
n= 89: 0.576521 -> 0.565839 (1.8530%)
n= 90: 0.572723 -> 0.561655 (1.9325%)
n= 95: 0.585572 -> 0.581780 (0.6476%)
n= 96: 0.588166 -> 0.582580 (0.9497%)
n= 97: 0.590386 -> 0.578745 (1.9717%)
n=101: 0.594777 -> 0.593570 (0.2030%)
n=102: 0.588953 -> 0.587371 (0.2687%)
n= 98: 0.590920 -> 0.580051 (1.8393%)
n=103: 0.585512 -> 0.582100 (0.5826%)
n= 99: 0.590051 -> 0.580426 (1.6313%)
n=104: 0.583448 -> 0.579377 (0.6977%)
n=110: 0.576455 -> 0.574260 (0.3807%)
n=107: 0.580166 -> 0.577071 (0.5335%)
n=108: 0.579761 -> 0.577893 (0.3223%)
n=111: 0.573072 -> 0.570962 (0.3682%)
n=105: 0.584127 -> 0.579026 (0.8733%)
n=100: 0.600692 -> 0.597866 (0.4705%)
n=112: 0.577996 -> 0.572819 (0.8957%)
n=113: 0.592291 -> 0.586575 (0.9651%)
n=109: 0.579493 -> 0.573506 (1.0332%)
n=106: 0.581047 -> 0.577648 (0.5850%)
n=115: 0.594652 -> 0.593339 (0.2209%)
n=114: 0.589619 -> 0.583935 (0.9641%)
n=118: 0.590369 -> 0.582875 (1.2693%)
n=117: 0.589604 -> 0.585495 (0.6970%)
n=119: 0.600276 -> 0.589131 (1.8566%)
n=122: 0.596517 -> 0.595179 (0.2243%)
n=123: 0.598633 -> 0.595233 (0.5680%)
n=124: 0.597138 -> 0.594308 (0.4739%)
n=121: 0.595660 -> 0.592669 (0.5021%)
n=125: 0.592900 -> 0.590642 (0.3809%)
n=126: 0.589951 -> 0.588035 (0.3248%)
n=120: 0.596732 -> 0.591220 (0.9237%)
n=127: 0.592408 -> 0.589728 (0.4524%)
n=128: 0.592573 -> 0.590897 (0.2830%)
n=131: 0.591836 -> 0.589804 (0.3432%)
n=129: 0.597835 -> 0.594795 (0.5085%)
n=130: 0.596267 -> 0.592772 (0.5863%)
n=132: 0.590192 -> 0.586490 (0.6273%)
n=136: 0.581902 -> 0.579423 (0.4259%)
n=137: 0.581159 -> 0.578014 (0.5412%)
n=141: 0.593165 -> 0.591076 (0.3522%)
n=140: 0.595763 -> 0.589444 (1.0607%)
n=139: 0.586977 -> 0.575179 (2.0099%)
n=143: 0.606667 -> 0.599002 (1.2634%)
n=144: 0.602570 -> 0.600609 (0.3255%)
n=151: 0.596032 -> 0.594248 (0.2993%)
n=134: 0.589496 -> 0.580785 (1.4778%)
n=145: 0.599045 -> 0.597529 (0.2531%)
n=152: 0.600463 -> 0.593796 (1.1104%)
n=138: 0.585110 -> 0.572321 (2.1858%)
n=135: 0.585644 -> 0.577815 (1.3368%)
