# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.676102 from exp_000 (baseline)
- Best LB score: 70.676102 (confirmed via submission)
- Target: 68.889699 | Gap to target: 1.786 points (2.5%)

## ⚠️ CRITICAL SITUATION ANALYSIS

**Both experiments (exp_000 and exp_001) have IDENTICAL scores (70.676102).**
- exp_000: Baseline from pre-optimized ensemble
- exp_001: Lattice packing attempts - ALL FAILED, fell back to baseline

**The baseline is ALREADY an ensemble of 30+ CSV files from multiple sources.**
All sources converge to the SAME local optimum. Simple ensembling won't help.

## Response to Evaluator

The evaluator correctly identified several key issues:

1. **"Baseline is at tight local optimum but didn't try to escape it"** - AGREED. The lattice experiment tried to BUILD new solutions from scratch rather than IMPROVE existing ones. This was the wrong approach.

2. **"Fractional translation was barely tested"** - AGREED. Only 50 iterations with coarse step sizes (0.001-0.0001). Top kernels use 150+ iterations with step sizes down to 0.00001.

3. **"No attempt to optimize small N (N=2 to N=5)"** - AGREED. Small N values contribute disproportionately. Exhaustive search is feasible for N≤5.

4. **"Didn't leverage C++ optimizer techniques"** - AGREED. The top kernels use sophisticated SA with:
   - T=1.0 → 0.000005 (very slow cooling)
   - 100,000+ iterations
   - Population-based approach (keep top 3)
   - Fractional translation refinement

## Key Research Findings

From discussions and kernels:
1. **"Why winning solutions will be Asymmetric"** (39 votes) - Asymmetric beats symmetric for many N
2. **"Symmetric solutions that are apparently optimal"** (43 votes) - Some N have optimal symmetric solutions
3. **Hybrid strategy**: N<58 use SA for chaotic packings, N≥58 use crystalline/lattice
4. **Top kernel (jonathanchan)**: Ensemble from 19+ sources, SA with proper params, fractional translation

## ⛔ BLOCKED APPROACHES (DO NOT USE)
- Running bbox3, sa_fast, eazy_optimizer binaries - FORBIDDEN
- "More iterations" on pre-compiled optimizers - FORBIDDEN
- Simple lattice generation from scratch - ALREADY TRIED, FAILED
- Ensembling existing CSV files - ALREADY DONE, baseline IS the ensemble

## ✅ REQUIRED: IMPLEMENT ONE OF THESE FROM SCRATCH

### PRIORITY 1: Proper SA with Fractional Translation (Python Implementation)
The evaluator's top recommendation. Implement from scratch:

```python
# Key parameters from top kernels:
INITIAL_TEMP = 1.0
FINAL_TEMP = 0.000005
COOLING_RATE = 0.99995  # Very slow cooling
ITERATIONS = 100000  # Per N value

# Move operators:
# 1. Small translation: dx, dy ~ N(0, 0.01-0.1)
# 2. Small rotation: dθ ~ N(0, 1-5°)
# 3. Swap two trees

# Fractional translation refinement:
FRAC_STEPS = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
FRAC_ITERATIONS = 200
DIRECTIONS = [(0,1), (0,-1), (1,0), (-1,0), (1,1), (1,-1), (-1,1), (-1,-1)]
```

### PRIORITY 2: Exhaustive Search for Small N (N=2 to N=5)
These contribute ~2.37 points to total score. Exhaustive search is tractable:

```python
# For N=2:
# - Tree 1 fixed at (0, 0, 45°)
# - Tree 2: search over angles (0-360° in 1° steps) and positions
# - Grid search for relative position

# For N=3:
# - Similar approach with 3 trees
# - Prune branches that exceed current best
```

### PRIORITY 3: Focus on Large N (N=51-200) with Better SA
Large N contributes 73.1% of score (51.63 points). Even small improvements here matter.

```python
# Per-N optimization strategy from top kernel:
if n <= 20:
    rounds = 6
    iterations = int(base_iterations * 1.5)
elif n <= 50:
    rounds = 5
    iterations = int(base_iterations * 1.3)
else:  # n > 50
    rounds = 4
    iterations = int(base_iterations * 0.8)
```

## Experiment Plan for exp_002

**Name:** `002_proper_sa_fractional`
**Goal:** Implement proper SA with fractional translation from scratch

**Steps:**
1. Load baseline solution for each N
2. Apply SA with proper parameters (T=1.0, cooling=0.99995, 50000 iterations)
3. Apply fractional translation refinement (200 iterations, step sizes to 0.00001)
4. Compare to baseline, keep improvements
5. Focus on N=51-200 first (73% of score)

**Expected outcome:** Even 0.1% improvement on large N = ~0.05 points improvement

## Validation Notes
- CV = LB for this problem (deterministic scoring)
- Use integer-scaled Shapely for overlap checking (Decimal precision)
- Validate ALL N values before submission

## SUBMISSION STRATEGY
- Remaining submissions: 92
- **SUBMIT after this experiment** - We have abundant submissions, need LB feedback
- Even if score doesn't improve, LB feedback tells us if approach is working

## What NOT to Try
- Simple lattice from scratch (already tried, failed)
- Running pre-compiled binaries (blocked)
- Ensembling existing CSVs (baseline already is ensemble)
- RL approaches (confirmed to fail for this problem)
