{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02ca880",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Key Insights from Research:\n",
    "\n",
    "1. **Two experiments with IDENTICAL scores (70.676102)** - We're stuck at a local optimum\n",
    "2. **bbox3 with extended parameters found ZERO improvement** - The baseline is extremely tight\n",
    "3. **zaburo kernel**: Constructive approach with aligned rows (score 88.33 initial)\n",
    "4. **saspav kernel**: Uses shake_public optimizer (different from bbox3)\n",
    "5. **Discussion mentions**: Asymmetric solutions may beat symmetric for large N\n",
    "\n",
    "## Strategy:\n",
    "1. Understand WHY the baseline is so tight\n",
    "2. Test fundamentally different approaches on small N\n",
    "3. Look for per-N improvements rather than global optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d931ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.strtree import STRtree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tree geometry (15 vertices)\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "TREE_COORDS = list(zip(TX, TY))\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    \"\"\"Create a tree polygon at position (x, y) with rotation deg.\"\"\"\n",
    "    poly = Polygon(TREE_COORDS)\n",
    "    poly = rotate(poly, deg, origin=(0, 0))\n",
    "    poly = translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def has_overlap(polygons):\n",
    "    \"\"\"Check if any polygons overlap.\"\"\"\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        indices = tree_index.query(poly)\n",
    "        for idx in indices:\n",
    "            if idx != i and poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                intersection = poly.intersection(polygons[idx])\n",
    "                if intersection.area > 1e-10:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def calculate_score(trees_data):\n",
    "    \"\"\"Calculate score for a configuration.\"\"\"\n",
    "    polygons = [create_tree_polygon(x, y, deg) for x, y, deg in trees_data]\n",
    "    all_coords = np.vstack([np.array(p.exterior.coords) for p in polygons])\n",
    "    min_xy = all_coords.min(axis=0)\n",
    "    max_xy = all_coords.max(axis=0)\n",
    "    side = max(max_xy - min_xy)\n",
    "    return side**2 / len(trees_data), side\n",
    "\n",
    "print(\"Functions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592503d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline submission\n",
    "baseline_df = pd.read_csv('/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv')\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "baseline_df['x_val'] = baseline_df['x'].apply(parse_value)\n",
    "baseline_df['y_val'] = baseline_df['y'].apply(parse_value)\n",
    "baseline_df['deg_val'] = baseline_df['deg'].apply(parse_value)\n",
    "baseline_df['n'] = baseline_df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Get baseline scores for each N\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    group = baseline_df[baseline_df['n'] == n]\n",
    "    trees_data = [(row['x_val'], row['y_val'], row['deg_val']) for _, row in group.iterrows()]\n",
    "    score, side = calculate_score(trees_data)\n",
    "    baseline_scores[n] = {'score': score, 'side': side}\n",
    "\n",
    "print(f\"Baseline total score: {sum(s['score'] for s in baseline_scores.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values contribute most to the score\n",
    "# and which have the most room for improvement\n",
    "\n",
    "scores_df = pd.DataFrame([\n",
    "    {'n': n, 'score': baseline_scores[n]['score'], 'side': baseline_scores[n]['side']}\n",
    "    for n in range(1, 201)\n",
    "])\n",
    "\n",
    "# Sort by score contribution (highest first)\n",
    "print(\"Top 20 N values by score contribution:\")\n",
    "print(scores_df.nlargest(20, 'score')[['n', 'score', 'side']].to_string())\n",
    "\n",
    "print(f\"\\nTotal score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"Top 20 contribute: {scores_df.nlargest(20, 'score')['score'].sum():.6f}\")\n",
    "print(f\"That's {100*scores_df.nlargest(20, 'score')['score'].sum()/scores_df['score'].sum():.1f}% of total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4adb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: Small N values (especially N=1) contribute disproportionately\n",
    "# N=1 alone contributes 0.661 which is almost 1% of the total score!\n",
    "\n",
    "# Let's check if N=1 is at the theoretical minimum\n",
    "# For N=1, the optimal angle is 45 degrees (minimizes bounding box)\n",
    "\n",
    "# Tree at 45 degrees:\n",
    "tree_45 = create_tree_polygon(0, 0, 45)\n",
    "bounds_45 = tree_45.bounds\n",
    "side_45 = max(bounds_45[2] - bounds_45[0], bounds_45[3] - bounds_45[1])\n",
    "score_45 = side_45**2\n",
    "\n",
    "print(f\"N=1 at 45 degrees: side={side_45:.6f}, score={score_45:.6f}\")\n",
    "print(f\"Baseline N=1: side={baseline_scores[1]['side']:.6f}, score={baseline_scores[1]['score']:.6f}\")\n",
    "\n",
    "# Check other angles\n",
    "print(\"\\nN=1 scores at different angles:\")\n",
    "for angle in [0, 15, 30, 45, 60, 75, 90]:\n",
    "    tree = create_tree_polygon(0, 0, angle)\n",
    "    bounds = tree.bounds\n",
    "    side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "    score = side**2\n",
    "    print(f\"  {angle:3d} degrees: side={side:.6f}, score={score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N=1 is already at the theoretical minimum (45 degrees)\n",
    "# Let's look at N=2 - can we improve it?\n",
    "\n",
    "# Get baseline N=2 configuration\n",
    "group_2 = baseline_df[baseline_df['n'] == 2]\n",
    "print(\"Baseline N=2 configuration:\")\n",
    "for _, row in group_2.iterrows():\n",
    "    print(f\"  x={row['x_val']:.6f}, y={row['y_val']:.6f}, deg={row['deg_val']:.2f}\")\n",
    "print(f\"Baseline N=2 score: {baseline_scores[2]['score']:.6f}\")\n",
    "\n",
    "# Try different configurations for N=2\n",
    "print(\"\\nTrying different N=2 configurations:\")\n",
    "\n",
    "best_n2_score = baseline_scores[2]['score']\n",
    "best_n2_config = None\n",
    "\n",
    "# Try placing two trees side by side at various angles\n",
    "for angle1 in range(0, 180, 15):\n",
    "    for angle2 in [angle1, angle1 + 90, angle1 + 180]:\n",
    "        for dx in np.arange(0.3, 1.0, 0.05):\n",
    "            for dy in np.arange(-0.5, 0.6, 0.1):\n",
    "                trees = [(0, 0, angle1), (dx, dy, angle2)]\n",
    "                polygons = [create_tree_polygon(x, y, deg) for x, y, deg in trees]\n",
    "                if has_overlap(polygons):\n",
    "                    continue\n",
    "                score, side = calculate_score(trees)\n",
    "                if score < best_n2_score - 0.0001:\n",
    "                    best_n2_score = score\n",
    "                    best_n2_config = trees\n",
    "                    print(f\"  New best N=2: score={score:.6f}, config={trees}\")\n",
    "\n",
    "print(f\"\\nBest N=2 score found: {best_n2_score:.6f}\")\n",
    "print(f\"Baseline N=2 score: {baseline_scores[2]['score']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a more systematic search for N=2\n",
    "# The key is to find configurations where trees interlock\n",
    "\n",
    "import itertools\n",
    "\n",
    "def exhaustive_search_n2():\n",
    "    \"\"\"Exhaustive search for best N=2 configuration.\"\"\"\n",
    "    best_score = float('inf')\n",
    "    best_config = None\n",
    "    \n",
    "    # First tree at origin with angle 0 (we can rotate the whole config later)\n",
    "    # Second tree at various positions and angles\n",
    "    \n",
    "    for angle2 in range(0, 360, 5):\n",
    "        for dx in np.arange(-1.5, 1.5, 0.02):\n",
    "            for dy in np.arange(-1.5, 1.5, 0.02):\n",
    "                trees = [(0, 0, 0), (dx, dy, angle2)]\n",
    "                polygons = [create_tree_polygon(x, y, deg) for x, y, deg in trees]\n",
    "                if has_overlap(polygons):\n",
    "                    continue\n",
    "                score, side = calculate_score(trees)\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_config = trees\n",
    "    \n",
    "    return best_score, best_config\n",
    "\n",
    "print(\"Running exhaustive search for N=2 (this may take a minute)...\")\n",
    "best_score_n2, best_config_n2 = exhaustive_search_n2()\n",
    "print(f\"Best N=2 score: {best_score_n2:.6f}\")\n",
    "print(f\"Best N=2 config: {best_config_n2}\")\n",
    "print(f\"Baseline N=2 score: {baseline_scores[2]['score']:.6f}\")\n",
    "print(f\"Improvement: {baseline_scores[2]['score'] - best_score_n2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also check N=3, N=4, N=5 to see if there's room for improvement\n",
    "\n",
    "def get_baseline_config(n):\n",
    "    \"\"\"Get baseline configuration for N.\"\"\"\n",
    "    group = baseline_df[baseline_df['n'] == n]\n",
    "    return [(row['x_val'], row['y_val'], row['deg_val']) for _, row in group.iterrows()]\n",
    "\n",
    "print(\"Baseline configurations for small N:\")\n",
    "for n in [3, 4, 5]:\n",
    "    config = get_baseline_config(n)\n",
    "    score = baseline_scores[n]['score']\n",
    "    print(f\"\\nN={n}: score={score:.6f}\")\n",
    "    for i, (x, y, deg) in enumerate(config):\n",
    "        print(f\"  Tree {i}: x={x:.4f}, y={y:.4f}, deg={deg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816640c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the zaburo constructive approach and see how it compares\n",
    "# This creates aligned rows with alternating angles\n",
    "\n",
    "def zaburo_constructive(n):\n",
    "    \"\"\"Create configuration using zaburo's aligned row approach.\"\"\"\n",
    "    best_score = float('inf')\n",
    "    best_trees = None\n",
    "    \n",
    "    for n_even in range(1, n + 1):\n",
    "        for n_odd in [n_even, n_even - 1]:\n",
    "            if n_odd < 0:\n",
    "                continue\n",
    "            all_trees = []\n",
    "            rest = n\n",
    "            r = 0\n",
    "            while rest > 0:\n",
    "                m = min(rest, n_even if r % 2 == 0 else n_odd)\n",
    "                if m <= 0:\n",
    "                    break\n",
    "                rest -= m\n",
    "                \n",
    "                angle = 0 if r % 2 == 0 else 180\n",
    "                x_offset = 0 if r % 2 == 0 else 0.35  # Half of 0.7\n",
    "                y = r // 2 * 1.0 if r % 2 == 0 else (0.8 + (r - 1) // 2 * 1.0)\n",
    "                \n",
    "                for i in range(m):\n",
    "                    x = 0.7 * i + x_offset\n",
    "                    all_trees.append((x, y, angle))\n",
    "                \n",
    "                r += 1\n",
    "            \n",
    "            if len(all_trees) != n:\n",
    "                continue\n",
    "                \n",
    "            score, side = calculate_score(all_trees)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_trees = all_trees\n",
    "    \n",
    "    return best_score, best_trees\n",
    "\n",
    "print(\"Comparing zaburo constructive vs baseline:\")\n",
    "print(\"=\"*60)\n",
    "for n in [5, 10, 20, 50, 100, 150, 200]:\n",
    "    zaburo_score, _ = zaburo_constructive(n)\n",
    "    baseline_score = baseline_scores[n]['score']\n",
    "    diff = zaburo_score - baseline_score\n",
    "    print(f\"N={n:3d}: zaburo={zaburo_score:.6f}, baseline={baseline_score:.6f}, diff={diff:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The zaburo constructive approach is MUCH WORSE than the baseline\n",
    "# This confirms the baseline is highly optimized\n",
    "\n",
    "# Let's analyze the baseline configuration structure for large N\n",
    "# to understand what makes it so good\n",
    "\n",
    "n = 100\n",
    "group = baseline_df[baseline_df['n'] == n]\n",
    "\n",
    "print(f\"Baseline N={n} configuration analysis:\")\n",
    "print(f\"  Number of trees: {len(group)}\")\n",
    "print(f\"  X range: [{group['x_val'].min():.4f}, {group['x_val'].max():.4f}]\")\n",
    "print(f\"  Y range: [{group['y_val'].min():.4f}, {group['y_val'].max():.4f}]\")\n",
    "print(f\"  Angle range: [{group['deg_val'].min():.2f}, {group['deg_val'].max():.2f}]\")\n",
    "\n",
    "# Angle distribution\n",
    "angles_mod = group['deg_val'] % 360\n",
    "print(f\"\\n  Angle distribution (mod 360):\")\n",
    "print(f\"    Mean: {angles_mod.mean():.2f}\")\n",
    "print(f\"    Std: {angles_mod.std():.2f}\")\n",
    "print(f\"    Unique angles (rounded to 1 degree): {len(angles_mod.round(0).unique())}\")\n",
    "\n",
    "# Check if there's a pattern\n",
    "print(f\"\\n  Most common angles (rounded to 5 degrees):\")\n",
    "angle_counts = (angles_mod / 5).round() * 5\n",
    "print(angle_counts.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The baseline has many unique angles - it's NOT a simple grid pattern\n",
    "# This suggests it was optimized with continuous angle optimization\n",
    "\n",
    "# Let's check if there are any N values where the baseline might be suboptimal\n",
    "# by looking at the efficiency (trees per unit area)\n",
    "\n",
    "print(\"Efficiency analysis (trees per unit area):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    side = baseline_scores[n]['side']\n",
    "    area = side ** 2\n",
    "    efficiency = n / area\n",
    "    efficiencies.append({'n': n, 'side': side, 'area': area, 'efficiency': efficiency, 'score': baseline_scores[n]['score']})\n",
    "\n",
    "eff_df = pd.DataFrame(efficiencies)\n",
    "\n",
    "# Find N values with unusually low efficiency (potential for improvement)\n",
    "print(\"\\nN values with lowest efficiency (worst packing):\")\n",
    "print(eff_df.nsmallest(15, 'efficiency')[['n', 'side', 'efficiency', 'score']].to_string())\n",
    "\n",
    "print(\"\\nN values with highest efficiency (best packing):\")\n",
    "print(eff_df.nlargest(15, 'efficiency')[['n', 'side', 'efficiency', 'score']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: Small N values (1-15) have the lowest efficiency\n",
    "# These are the hardest to pack efficiently because there's more \"wasted space\"\n",
    "\n",
    "# The target score is 68.894234, current is 70.676102\n",
    "# Gap = 1.78 points (2.6%)\n",
    "\n",
    "# To close this gap, we need to find improvements somewhere\n",
    "# Let's calculate how much improvement we'd need per N\n",
    "\n",
    "target_score = 68.894234\n",
    "current_score = 70.676102\n",
    "gap = current_score - target_score\n",
    "\n",
    "print(f\"Target: {target_score:.6f}\")\n",
    "print(f\"Current: {current_score:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({100*gap/current_score:.2f}%)\")\n",
    "\n",
    "# If we could improve each N by the same percentage:\n",
    "required_improvement_pct = gap / current_score\n",
    "print(f\"\\nRequired improvement per N: {100*required_improvement_pct:.2f}%\")\n",
    "\n",
    "# But some N values contribute more to the score\n",
    "# Let's see which N values would give the most bang for the buck\n",
    "print(\"\\nIf we could improve each N by 1%, contribution to total improvement:\")\n",
    "for n in [1, 2, 3, 4, 5, 10, 50, 100, 200]:\n",
    "    contribution = baseline_scores[n]['score'] * 0.01\n",
    "    print(f\"  N={n:3d}: {contribution:.6f} (score={baseline_scores[n]['score']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf614c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings:\n",
    "# 1. N=1 is at theoretical minimum (45 degrees) - no improvement possible\n",
    "# 2. Small N values (1-15) have lowest efficiency but contribute most to score\n",
    "# 3. The baseline is highly optimized with continuous angle optimization\n",
    "# 4. Simple constructive approaches (zaburo) are MUCH worse than baseline\n",
    "# 5. The gap of 1.78 points requires ~2.5% improvement across all N\n",
    "\n",
    "# The only way to beat this is:\n",
    "# 1. Run optimization for MUCH longer (hours, not minutes)\n",
    "# 2. Try fundamentally different algorithms (not just bbox3)\n",
    "# 3. Focus on specific N values that might have room for improvement\n",
    "\n",
    "# Let's check if there are any other optimizers available\n",
    "import os\n",
    "print(\"Available optimizers:\")\n",
    "for root, dirs, files in os.walk('/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/'):\n",
    "    for f in files:\n",
    "        if os.access(os.path.join(root, f), os.X_OK) or f.endswith('.cpp'):\n",
    "            print(f\"  {os.path.join(root, f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8da97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the bucket-of-chump and other pre-optimized solutions\n",
    "# to see if any of them beat the baseline for specific N values\n",
    "\n",
    "import glob\n",
    "\n",
    "preopt_dir = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/'\n",
    "csv_files = glob.glob(preopt_dir + '**/*.csv', recursive=True)\n",
    "\n",
    "print(f\"Found {len(csv_files)} pre-optimized CSV files\")\n",
    "for f in csv_files[:10]:\n",
    "    print(f\"  {f}\")\n",
    "if len(csv_files) > 10:\n",
    "    print(f\"  ... and {len(csv_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d00e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare all pre-optimized CSVs to find if any beat the baseline for specific N\n",
    "\n",
    "def load_and_score_csv(filepath):\n",
    "    \"\"\"Load a CSV and calculate scores for each N.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['x_val'] = df['x'].apply(parse_value)\n",
    "        df['y_val'] = df['y'].apply(parse_value)\n",
    "        df['deg_val'] = df['deg'].apply(parse_value)\n",
    "        df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "        \n",
    "        scores = {}\n",
    "        for n in range(1, 201):\n",
    "            group = df[df['n'] == n]\n",
    "            if len(group) != n:\n",
    "                return None  # Invalid file\n",
    "            trees_data = [(row['x_val'], row['y_val'], row['deg_val']) for _, row in group.iterrows()]\n",
    "            score, side = calculate_score(trees_data)\n",
    "            scores[n] = score\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Load all CSVs and compare\n",
    "print(\"Comparing all pre-optimized CSVs...\")\n",
    "best_per_n = {n: {'score': baseline_scores[n]['score'], 'source': 'baseline'} for n in range(1, 201)}\n",
    "\n",
    "for filepath in csv_files:\n",
    "    scores = load_and_score_csv(filepath)\n",
    "    if scores is None:\n",
    "        continue\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        if scores[n] < best_per_n[n]['score'] - 1e-8:\n",
    "            best_per_n[n] = {'score': scores[n], 'source': filepath}\n",
    "\n",
    "# Check if any N values have better solutions than baseline\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n]['source'] != 'baseline':\n",
    "        improvement = baseline_scores[n]['score'] - best_per_n[n]['score']\n",
    "        improvements.append({'n': n, 'improvement': improvement, 'source': best_per_n[n]['source']})\n",
    "\n",
    "if improvements:\n",
    "    print(f\"\\nFound {len(improvements)} N values with better solutions:\")\n",
    "    for imp in sorted(improvements, key=lambda x: -x['improvement'])[:20]:\n",
    "        print(f\"  N={imp['n']}: improvement={imp['improvement']:.6f}, source={imp['source']}\")\n",
    "else:\n",
    "    print(\"\\nNo improvements found - baseline dominates all N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score if we use best per N\n",
    "total_best = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nTotal score using best per N: {total_best:.6f}\")\n",
    "print(f\"Baseline total: {sum(baseline_scores[n]['score'] for n in range(1, 201)):.6f}\")\n",
    "print(f\"Improvement: {sum(baseline_scores[n]['score'] for n in range(1, 201)) - total_best:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee5e98",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. **The baseline (santa-2025.csv) dominates ALL 200 N values** - no pre-optimized CSV beats it for any N\n",
    "2. **N=1 is at theoretical minimum** (45 degrees) - no improvement possible\n",
    "3. **Small N values contribute most to score** but are already well-optimized\n",
    "4. **Simple constructive approaches are MUCH worse** than the baseline\n",
    "5. **The baseline uses continuous angle optimization** - not a simple grid pattern\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Run bbox3 for MUCH longer** (hours, not minutes) - the evaluator suggested this\n",
    "2. **Try shake_public optimizer** (from saspav kernel) - different algorithm\n",
    "3. **Try perturbation + optimization** - escape local optima by perturbing first\n",
    "4. **Focus on asymmetric solutions** - discussion suggests these may beat symmetric for large N"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
