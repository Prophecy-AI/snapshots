{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a40ded1",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "## Strategic Assessment\n",
    "\n",
    "Analyzing the current state and identifying the best path forward to beat target 68.901319."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae35964a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.384398Z",
     "iopub.status.busy": "2026-01-24T22:47:50.383835Z",
     "iopub.status.idle": "2026-01-24T22:47:50.735450Z",
     "shell.execute_reply": "2026-01-24T22:47:50.735003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments: 1\n",
      "Submissions: 0\n",
      "Target: 68.901319\n",
      "Current best: 70.627582\n",
      "Gap: 1.726263\n",
      "Gap %: 2.51%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.strtree import STRtree\n",
    "import os\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "print(f\"Experiments: {len(state['experiments'])}\")\n",
    "print(f\"Submissions: {len(state['submissions'])}\")\n",
    "print(f\"Target: 68.901319\")\n",
    "print(f\"Current best: {state['experiments'][0]['score']}\")\n",
    "print(f\"Gap: {state['experiments'][0]['score'] - 68.901319:.6f}\")\n",
    "print(f\"Gap %: {(state['experiments'][0]['score'] - 68.901319) / 68.901319 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaa83f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.736649Z",
     "iopub.status.busy": "2026-01-24T22:47:50.736495Z",
     "iopub.status.idle": "2026-01-24T22:47:50.741177Z",
     "shell.execute_reply": "2026-01-24T22:47:50.740777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Past LB Submissions Analysis ===\n",
      "\n",
      "LB Score | CV Score | Gap\n",
      "----------------------------------------\n",
      "70.630478 | 70.630478 | 0.000000\n",
      "70.647327 | 70.647327 | 0.000000\n",
      "70.647306 | 70.647306 | 0.000000\n",
      "70.658891 | 70.658891 | 0.000000\n",
      "70.659437 | 70.659437 | 0.000000\n",
      "70.659493 | 70.659493 | 0.000000\n",
      "70.659958 | 70.659958 | 0.000000\n",
      "70.675457 | 70.675457 | 0.000000\n",
      "70.676102 | 70.676102 | 0.000000\n",
      "70.734327 | 70.734327 | 0.000000\n",
      "\n",
      "Key insight: CV and LB are nearly identical!\n",
      "This means there's NO distribution shift - CV is reliable.\n",
      "The challenge is pure optimization, not generalization.\n"
     ]
    }
   ],
   "source": [
    "# Analyze past LB submissions from snapshots\n",
    "print(\"\\n=== Past LB Submissions Analysis ===\")\n",
    "\n",
    "lb_submissions = [\n",
    "    # From snapshot analysis\n",
    "    (70.630478, 70.630478),  # Best achieved\n",
    "    (70.647327, 70.647327),\n",
    "    (70.647306, 70.647306),\n",
    "    (70.658891, 70.658891),\n",
    "    (70.659437, 70.659437),\n",
    "    (70.659493, 70.659493),\n",
    "    (70.659958, 70.659958),\n",
    "    (70.675457, 70.675457),\n",
    "    (70.676102, 70.676102),\n",
    "    (70.734327, 70.734327),\n",
    "]\n",
    "\n",
    "print(\"\\nLB Score | CV Score | Gap\")\n",
    "print(\"-\" * 40)\n",
    "for lb, cv in lb_submissions:\n",
    "    gap = lb - cv\n",
    "    print(f\"{lb:.6f} | {cv:.6f} | {gap:.6f}\")\n",
    "\n",
    "print(f\"\\nKey insight: CV and LB are nearly identical!\")\n",
    "print(f\"This means there's NO distribution shift - CV is reliable.\")\n",
    "print(f\"The challenge is pure optimization, not generalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76405fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.742194Z",
     "iopub.status.busy": "2026-01-24T22:47:50.742087Z",
     "iopub.status.idle": "2026-01-24T22:47:50.746047Z",
     "shell.execute_reply": "2026-01-24T22:47:50.745666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Techniques Tried in Past Runs ===\n",
      "\n",
      "Technique | Result | Notes\n",
      "----------------------------------------------------------------------\n",
      "Ensemble from public sources        | 70.627-70.647   | Works but limited by source quality\n",
      "bbox3 optimizer                     | No improvement  | Produces overlapping trees\n",
      "sa_fast_v2 optimizer                | No improvement  | Also produces overlaps\n",
      "Zaburo grid initialization          | 88.33           | Much worse than baseline\n",
      "Rotation tightening (fix_direction) | No improvement  | Baseline already optimized\n",
      "Backward propagation (deletion cascade) | No improvement  | Baseline already optimal\n",
      "Tessellation SA                     | Worse           | Grid patterns don't compete\n",
      "Exhaustive search N=1,2             | Optimal         | Baseline is already optimal\n",
      "Random restart SA                   | Worse           | Random configs worse than baseline\n",
      "\n",
      "=== Key Insight ===\n",
      "The baseline (saspav_best ensemble) is at an EXTREMELY strong local optimum.\n",
      "All standard optimization techniques fail to improve it.\n",
      "The gap to target (1.73 points) requires a FUNDAMENTALLY different approach.\n"
     ]
    }
   ],
   "source": [
    "# Analyze what techniques have been tried\n",
    "print(\"\\n=== Techniques Tried in Past Runs ===\")\n",
    "\n",
    "techniques = [\n",
    "    (\"Ensemble from public sources\", \"70.627-70.647\", \"Works but limited by source quality\"),\n",
    "    (\"bbox3 optimizer\", \"No improvement\", \"Produces overlapping trees\"),\n",
    "    (\"sa_fast_v2 optimizer\", \"No improvement\", \"Also produces overlaps\"),\n",
    "    (\"Zaburo grid initialization\", \"88.33\", \"Much worse than baseline\"),\n",
    "    (\"Rotation tightening (fix_direction)\", \"No improvement\", \"Baseline already optimized\"),\n",
    "    (\"Backward propagation (deletion cascade)\", \"No improvement\", \"Baseline already optimal\"),\n",
    "    (\"Tessellation SA\", \"Worse\", \"Grid patterns don't compete\"),\n",
    "    (\"Exhaustive search N=1,2\", \"Optimal\", \"Baseline is already optimal\"),\n",
    "    (\"Random restart SA\", \"Worse\", \"Random configs worse than baseline\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTechnique | Result | Notes\")\n",
    "print(\"-\" * 70)\n",
    "for tech, result, notes in techniques:\n",
    "    print(f\"{tech:35s} | {result:15s} | {notes}\")\n",
    "\n",
    "print(\"\\n=== Key Insight ===\")\n",
    "print(\"The baseline (saspav_best ensemble) is at an EXTREMELY strong local optimum.\")\n",
    "print(\"All standard optimization techniques fail to improve it.\")\n",
    "print(\"The gap to target (1.73 points) requires a FUNDAMENTALLY different approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a0918b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.747130Z",
     "iopub.status.busy": "2026-01-24T22:47:50.747023Z",
     "iopub.status.idle": "2026-01-24T22:47:50.750984Z",
     "shell.execute_reply": "2026-01-24T22:47:50.750604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Score Breakdown Analysis ===\n",
      "Total score: 70.62\n",
      "Target: 68.901319\n",
      "Need to reduce by: 1.72\n",
      "\n",
      "Breakdown:\n",
      "  N=1-10: 4.33 (6.1%)\n",
      "  N=11-20: 3.72 (5.3%)\n",
      "  N=21-50: 10.98 (15.5%)\n",
      "  N=51-100: 17.61 (24.9%)\n",
      "  N=101-150: 17.14 (24.3%)\n",
      "  N=151-200: 16.84 (23.8%)\n",
      "\n",
      "=== Where to Focus ===\n",
      "Small N (1-20) contributes 8.05 points (11.4%)\n",
      "Large N (101-200) contributes 33.98 points (48.2%)\n",
      "The bulk of the score comes from large N values.\n",
      "But small N has higher per-tree contribution (easier to improve).\n"
     ]
    }
   ],
   "source": [
    "# What's the theoretical minimum?\n",
    "print(\"\\n=== Score Breakdown Analysis ===\")\n",
    "\n",
    "# From the baseline experiment notes\n",
    "breakdown = {\n",
    "    'N=1-10': 4.33,\n",
    "    'N=11-20': 3.72,\n",
    "    'N=21-50': 10.98,\n",
    "    'N=51-100': 17.61,\n",
    "    'N=101-150': 17.14,\n",
    "    'N=151-200': 16.84,\n",
    "}\n",
    "\n",
    "total = sum(breakdown.values())\n",
    "print(f\"Total score: {total:.2f}\")\n",
    "print(f\"Target: 68.901319\")\n",
    "print(f\"Need to reduce by: {total - 68.901319:.2f}\")\n",
    "\n",
    "print(\"\\nBreakdown:\")\n",
    "for range_name, score in breakdown.items():\n",
    "    pct = score / total * 100\n",
    "    print(f\"  {range_name}: {score:.2f} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Where to Focus ===\")\n",
    "print(\"Small N (1-20) contributes 8.05 points (11.4%)\")\n",
    "print(\"Large N (101-200) contributes 33.98 points (48.2%)\")\n",
    "print(\"The bulk of the score comes from large N values.\")\n",
    "print(\"But small N has higher per-tree contribution (easier to improve).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e52ae7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.752167Z",
     "iopub.status.busy": "2026-01-24T22:47:50.752058Z",
     "iopub.status.idle": "2026-01-24T22:47:50.755994Z",
     "shell.execute_reply": "2026-01-24T22:47:50.755602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target Analysis ===\n",
      "Current: 70.627582\n",
      "Target: 68.901319\n",
      "Gap: 1.726263 (2.44%)\n",
      "\n",
      "Average reduction needed per N: 0.008631\n",
      "\n",
      "Impact of 0.1 side length reduction:\n",
      "  N=  1: side ~0.59 -> 0.49, score reduction: 0.1083\n",
      "  N= 10: side ~1.87 -> 1.77, score reduction: 0.0364\n",
      "  N= 50: side ~4.18 -> 4.08, score reduction: 0.0165\n",
      "  N=100: side ~5.92 -> 5.82, score reduction: 0.0117\n",
      "  N=200: side ~8.37 -> 8.27, score reduction: 0.0083\n",
      "\n",
      "Key insight: Small N improvements have MUCH higher leverage!\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the target implies\n",
    "print(\"\\n=== Target Analysis ===\")\n",
    "\n",
    "current = 70.627582\n",
    "target = 68.901319\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current: {current:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({gap/current*100:.2f}%)\")\n",
    "\n",
    "# If we need to reduce by 1.73 points across 200 N values\n",
    "avg_reduction_per_n = gap / 200\n",
    "print(f\"\\nAverage reduction needed per N: {avg_reduction_per_n:.6f}\")\n",
    "\n",
    "# The score formula is sum(side^2/n)\n",
    "# For N=100, if side reduces by 0.1, score reduces by ~0.02\n",
    "# For N=1, if side reduces by 0.1, score reduces by ~0.2\n",
    "print(\"\\nImpact of 0.1 side length reduction:\")\n",
    "for n in [1, 10, 50, 100, 200]:\n",
    "    # Assume current side ~= sqrt(n * 0.35) (rough approximation)\n",
    "    current_side = np.sqrt(n * 0.35)\n",
    "    new_side = current_side - 0.1\n",
    "    current_contrib = current_side**2 / n\n",
    "    new_contrib = new_side**2 / n\n",
    "    reduction = current_contrib - new_contrib\n",
    "    print(f\"  N={n:3d}: side ~{current_side:.2f} -> {new_side:.2f}, score reduction: {reduction:.4f}\")\n",
    "\n",
    "print(\"\\nKey insight: Small N improvements have MUCH higher leverage!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea832761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T22:47:50.757042Z",
     "iopub.status.busy": "2026-01-24T22:47:50.756936Z",
     "iopub.status.idle": "2026-01-24T22:47:50.760090Z",
     "shell.execute_reply": "2026-01-24T22:47:50.759724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Unexplored Approaches ===\n",
      "1. Run bbox3/sa_fast_v2 with REPAIR strategy (replace overlapping N with baseline)\n",
      "2. Longer optimization runs (hours instead of minutes)\n",
      "3. Different initial configurations (not grid-based)\n",
      "4. Genetic algorithm with population of diverse solutions\n",
      "5. Constraint programming / exact solvers for small N\n",
      "6. Manual optimization of worst N values\n",
      "7. Hybrid approaches: optimize subset of trees while keeping others fixed\n",
      "8. Temperature-based annealing with very slow cooling\n",
      "9. Multi-objective optimization (minimize side + maximize margin)\n",
      "10. Learn from asymmetric solutions (discussion mentions these win)\n",
      "\n",
      "=== Most Promising ===\n",
      "1. REPAIR strategy with bbox3 - even if only 10% of N values improve, that's progress\n",
      "2. Focus on small N (1-20) where improvements have highest leverage\n",
      "3. Asymmetric solutions - discussion says these win\n",
      "4. Longer optimization runs with proper validation\n"
     ]
    }
   ],
   "source": [
    "# What approaches haven't been tried?\n",
    "print(\"\\n=== Unexplored Approaches ===\")\n",
    "\n",
    "unexplored = [\n",
    "    \"1. Run bbox3/sa_fast_v2 with REPAIR strategy (replace overlapping N with baseline)\",\n",
    "    \"2. Longer optimization runs (hours instead of minutes)\",\n",
    "    \"3. Different initial configurations (not grid-based)\",\n",
    "    \"4. Genetic algorithm with population of diverse solutions\",\n",
    "    \"5. Constraint programming / exact solvers for small N\",\n",
    "    \"6. Manual optimization of worst N values\",\n",
    "    \"7. Hybrid approaches: optimize subset of trees while keeping others fixed\",\n",
    "    \"8. Temperature-based annealing with very slow cooling\",\n",
    "    \"9. Multi-objective optimization (minimize side + maximize margin)\",\n",
    "    \"10. Learn from asymmetric solutions (discussion mentions these win)\",\n",
    "]\n",
    "\n",
    "for approach in unexplored:\n",
    "    print(approach)\n",
    "\n",
    "print(\"\\n=== Most Promising ===\")\n",
    "print(\"1. REPAIR strategy with bbox3 - even if only 10% of N values improve, that's progress\")\n",
    "print(\"2. Focus on small N (1-20) where improvements have highest leverage\")\n",
    "print(\"3. Asymmetric solutions - discussion says these win\")\n",
    "print(\"4. Longer optimization runs with proper validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b11948",
   "metadata": {},
   "source": [
    "## Strategic Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "1. **CV = LB**: No distribution shift, CV is reliable\n",
    "2. **Baseline is strong**: All standard techniques fail to improve\n",
    "3. **Gap is 2.5%**: Need 1.73 points reduction\n",
    "4. **Small N has high leverage**: N=1-20 contributes 11.4% but improvements there have 10x impact\n",
    "\n",
    "### Recommended Strategy:\n",
    "1. **Run bbox3 with REPAIR**: Even if it produces overlaps, replace invalid N with baseline\n",
    "2. **Focus on small N**: Manually optimize N=1-10 if possible\n",
    "3. **Asymmetric solutions**: The discussion says winning solutions are asymmetric\n",
    "4. **Longer runs**: Previous runs were too short (minutes, not hours)\n",
    "5. **Submit early**: Get LB feedback to calibrate CV-LB relationship"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
