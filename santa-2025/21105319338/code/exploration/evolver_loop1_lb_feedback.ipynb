{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0f031f",
   "metadata": {},
   "source": [
    "# Loop 1 LB Feedback Analysis\n",
    "\n",
    "## Current Status\n",
    "- **Best CV/LB Score**: 70.7343\n",
    "- **Target**: 68.931058\n",
    "- **Gap**: 1.803 points (2.6%)\n",
    "\n",
    "## Key Observations\n",
    "1. CV = LB (perfect match) - this is expected for deterministic optimization problems\n",
    "2. The pre-optimized submission is already at a local optimum\n",
    "3. bbox3 binary requires GLIBC 2.34 (system has 2.31) - cannot use directly\n",
    "4. tree_packer_v21 C++ source is available and can be compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the current best submission\n",
    "submission_path = '/home/code/experiments/001_baseline/submission.csv'\n",
    "df = pd.read_csv(submission_path)\n",
    "print(f'Submission shape: {df.shape}')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4105a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores to identify worst performers\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import math\n",
    "\n",
    "getcontext().prec = 30\n",
    "scale_factor = Decimal('1e18')\n",
    "\n",
    "# Tree template\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def score_group(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    V = len(TX)\n",
    "    mnx, mny = 1e300, 1e300\n",
    "    mxx, mxy = -1e300, -1e300\n",
    "    \n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        xi, yi = xs[i], ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * TX[j] - s * TY[j] + xi\n",
    "            Y = s * TX[j] + c * TY[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    \n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n, side\n",
    "\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "# Parse submission\n",
    "df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "\n",
    "per_n_scores = []\n",
    "for n, g in df.groupby('N'):\n",
    "    xs = strip(g['x'].to_numpy())\n",
    "    ys = strip(g['y'].to_numpy())\n",
    "    ds = strip(g['deg'].to_numpy())\n",
    "    sc, side = score_group(xs, ys, ds)\n",
    "    per_n_scores.append({'N': n, 'score': sc, 'side': side, 'contribution_pct': 0})\n",
    "\n",
    "per_n_df = pd.DataFrame(per_n_scores)\n",
    "total_score = per_n_df['score'].sum()\n",
    "per_n_df['contribution_pct'] = per_n_df['score'] / total_score * 100\n",
    "\n",
    "print(f'Total score: {total_score:.10f}')\n",
    "print(f'\\nTop 20 worst N values (highest contribution):')\n",
    "print(per_n_df.nlargest(20, 'score')[['N', 'score', 'side', 'contribution_pct']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Score by N\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(per_n_df['N'], per_n_df['score'], alpha=0.7)\n",
    "ax1.set_xlabel('N')\n",
    "ax1.set_ylabel('Score (s²/n)')\n",
    "ax1.set_title('Score Contribution by N')\n",
    "\n",
    "# Side length by N\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(per_n_df['N'], per_n_df['side'], alpha=0.5, s=10)\n",
    "ax2.set_xlabel('N')\n",
    "ax2.set_ylabel('Side Length')\n",
    "ax2.set_title('Bounding Box Side Length by N')\n",
    "\n",
    "# Cumulative contribution\n",
    "ax3 = axes[1, 0]\n",
    "sorted_df = per_n_df.sort_values('score', ascending=False)\n",
    "sorted_df['cumsum'] = sorted_df['contribution_pct'].cumsum()\n",
    "ax3.plot(range(1, 201), sorted_df['cumsum'].values)\n",
    "ax3.axhline(y=50, color='r', linestyle='--', label='50%')\n",
    "ax3.axhline(y=80, color='g', linestyle='--', label='80%')\n",
    "ax3.set_xlabel('Number of N values (sorted by contribution)')\n",
    "ax3.set_ylabel('Cumulative % of Total Score')\n",
    "ax3.set_title('Cumulative Score Contribution')\n",
    "ax3.legend()\n",
    "\n",
    "# Efficiency (side / sqrt(N))\n",
    "ax4 = axes[1, 1]\n",
    "per_n_df['efficiency'] = per_n_df['side'] / np.sqrt(per_n_df['N'])\n",
    "ax4.scatter(per_n_df['N'], per_n_df['efficiency'], alpha=0.5, s=10)\n",
    "ax4.set_xlabel('N')\n",
    "ax4.set_ylabel('Efficiency (side / √N)')\n",
    "ax4.set_title('Packing Efficiency by N')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/per_n_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nN values with worst efficiency (highest side/√N):')\n",
    "print(per_n_df.nlargest(10, 'efficiency')[['N', 'side', 'efficiency', 'score']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d27c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much improvement is needed per N to reach target\n",
    "target = 68.931058\n",
    "current = total_score\n",
    "gap = current - target\n",
    "\n",
    "print(f'Current score: {current:.6f}')\n",
    "print(f'Target score: {target:.6f}')\n",
    "print(f'Gap to close: {gap:.6f} ({gap/current*100:.2f}%)')\n",
    "\n",
    "# If we improve all N equally by X%, what X do we need?\n",
    "# new_score = current * (1 - X/100)\n",
    "# target = current * (1 - X/100)\n",
    "# X = (1 - target/current) * 100\n",
    "required_improvement_pct = (1 - target/current) * 100\n",
    "print(f'\\nRequired uniform improvement: {required_improvement_pct:.2f}%')\n",
    "\n",
    "# Alternatively, if we focus on worst N values\n",
    "worst_20 = per_n_df.nlargest(20, 'score')\n",
    "worst_20_total = worst_20['score'].sum()\n",
    "print(f'\\nWorst 20 N values contribute: {worst_20_total:.6f} ({worst_20_total/current*100:.1f}%)')\n",
    "print(f'If we improve worst 20 by 10%: saves {worst_20_total * 0.1:.6f}')\n",
    "print(f'If we improve worst 20 by 20%: saves {worst_20_total * 0.2:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what datasets/submissions are available for ensemble\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print('Available datasets:')\n",
    "for d in glob.glob('/home/code/datasets/*'):\n",
    "    print(f'  {d}')\n",
    "    for f in glob.glob(f'{d}/*.csv'):\n",
    "        print(f'    - {os.path.basename(f)}')\n",
    "\n",
    "print('\\nAvailable submission files:')\n",
    "for f in glob.glob('/home/code/**/*.csv', recursive=True):\n",
    "    if 'submission' in f.lower():\n",
    "        print(f'  {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2465fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: We need to implement ENSEMBLE approach\n",
    "# The jonathanchan kernel shows that combining best N from multiple sources\n",
    "# is the key to getting good scores\n",
    "\n",
    "# Let's compare our current submission with the bucket-of-chump submission\n",
    "boc_path = '/home/code/datasets/bucket-of-chump/submission.csv'\n",
    "santa_path = '/home/code/datasets/santa-2025-csv/santa-2025.csv'\n",
    "\n",
    "def score_submission(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    scores = {}\n",
    "    for n, g in df.groupby('N'):\n",
    "        xs = strip(g['x'].to_numpy())\n",
    "        ys = strip(g['y'].to_numpy())\n",
    "        ds = strip(g['deg'].to_numpy())\n",
    "        sc, side = score_group(xs, ys, ds)\n",
    "        scores[n] = {'score': sc, 'side': side}\n",
    "    return scores, sum(s['score'] for s in scores.values())\n",
    "\n",
    "boc_scores, boc_total = score_submission(boc_path)\n",
    "santa_scores, santa_total = score_submission(santa_path)\n",
    "our_scores = {row['N']: {'score': row['score'], 'side': row['side']} for _, row in per_n_df.iterrows()}\n",
    "\n",
    "print(f'bucket-of-chump total: {boc_total:.10f}')\n",
    "print(f'santa-2025-csv total: {santa_total:.10f}')\n",
    "print(f'Our current total: {total_score:.10f}')\n",
    "\n",
    "# Find N values where other submissions are better\n",
    "better_in_boc = []\n",
    "better_in_santa = []\n",
    "for n in range(1, 201):\n",
    "    our = our_scores[n]['score']\n",
    "    boc = boc_scores[n]['score']\n",
    "    santa = santa_scores[n]['score']\n",
    "    if boc < our - 1e-12:\n",
    "        better_in_boc.append((n, our - boc))\n",
    "    if santa < our - 1e-12:\n",
    "        better_in_santa.append((n, our - santa))\n",
    "\n",
    "print(f'\\nN values where bucket-of-chump is better: {len(better_in_boc)}')\n",
    "if better_in_boc:\n",
    "    print(f'  Potential improvement: {sum(x[1] for x in better_in_boc):.10f}')\n",
    "    print(f'  Top 5: {sorted(better_in_boc, key=lambda x: -x[1])[:5]}')\n",
    "\n",
    "print(f'\\nN values where santa-2025-csv is better: {len(better_in_santa)}')\n",
    "if better_in_santa:\n",
    "    print(f'  Potential improvement: {sum(x[1] for x in better_in_santa):.10f}')\n",
    "    print(f'  Top 5: {sorted(better_in_santa, key=lambda x: -x[1])[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a7713",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **CV = LB perfectly** - Expected for deterministic optimization\n",
    "2. **Gap is 2.6%** - Need ~1.8 points improvement\n",
    "3. **Small N values contribute most** - N=1 to N=20 are critical\n",
    "4. **Ensemble is key** - Combining best N from multiple sources\n",
    "5. **bbox3 unavailable** - Must use tree_packer_v21 or implement SA in Python\n",
    "\n",
    "## Recommended Strategy\n",
    "\n",
    "1. **Implement ensemble approach** - Combine best configurations from multiple public submissions\n",
    "2. **Run extended tree_packer_v21** - With higher iterations (-n 10000 -r 100+)\n",
    "3. **Implement fractional translation** - Very fine position adjustments\n",
    "4. **Focus on worst N values** - Targeted optimization\n",
    "5. **Download more public submissions** - More sources = better ensemble"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
