{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b91c66",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "Goal: Understand the current state and develop strategy to beat target 68.931058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Current state\n",
    "current_score = 70.734327\n",
    "target_score = 68.931058\n",
    "gap = current_score - target_score\n",
    "\n",
    "print(f\"Current best score: {current_score:.6f}\")\n",
    "print(f\"Target score: {target_score:.6f}\")\n",
    "print(f\"Gap to target: {gap:.6f}\")\n",
    "print(f\"Gap percentage: {gap/target_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dea2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the current best solution\n",
    "df = pd.read_csv('/home/code/santa_data/santa-2025.csv')\n",
    "print(f\"Solution shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and calculate scores per n\n",
    "def strip_s(val):\n",
    "    return float(str(val).replace('s', ''))\n",
    "\n",
    "def calculate_score_per_n(df):\n",
    "    scores = {}\n",
    "    for n in range(1, 201):\n",
    "        group = df[df['id'].str.startswith(f'{n:03d}_')]\n",
    "        if len(group) > 0:\n",
    "            xs = group['x'].apply(strip_s).values\n",
    "            ys = group['y'].apply(strip_s).values\n",
    "            degs = group['deg'].apply(strip_s).values\n",
    "            \n",
    "            # Calculate bounding box\n",
    "            all_x, all_y = [], []\n",
    "            for x, y, deg in zip(xs, ys, degs):\n",
    "                # Tree vertices\n",
    "                TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "                TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "                rad = np.radians(deg)\n",
    "                c, s = np.cos(rad), np.sin(rad)\n",
    "                rotated_x = TX * c - TY * s + x\n",
    "                rotated_y = TX * s + TY * c + y\n",
    "                all_x.extend(rotated_x)\n",
    "                all_y.extend(rotated_y)\n",
    "            \n",
    "            side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "            scores[n] = side**2 / n\n",
    "    return scores\n",
    "\n",
    "scores = calculate_score_per_n(df)\n",
    "total = sum(scores.values())\n",
    "print(f\"Calculated total score: {total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution\n",
    "ns = list(range(1, 201))\n",
    "score_list = [scores.get(n, 0) for n in ns]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Score per n\n",
    "axes[0,0].bar(ns, score_list, alpha=0.7)\n",
    "axes[0,0].set_xlabel('n (number of trees)')\n",
    "axes[0,0].set_ylabel('Score contribution (s²/n)')\n",
    "axes[0,0].set_title('Score Contribution by Configuration Size')\n",
    "\n",
    "# Plot 2: Cumulative score\n",
    "cum_score = np.cumsum(score_list)\n",
    "axes[0,1].plot(ns, cum_score)\n",
    "axes[0,1].axhline(y=target_score, color='r', linestyle='--', label=f'Target: {target_score}')\n",
    "axes[0,1].set_xlabel('n (number of trees)')\n",
    "axes[0,1].set_ylabel('Cumulative Score')\n",
    "axes[0,1].set_title('Cumulative Score')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Plot 3: Score per n (zoomed to high-n)\n",
    "axes[1,0].bar(ns[100:], score_list[100:], alpha=0.7)\n",
    "axes[1,0].set_xlabel('n (number of trees)')\n",
    "axes[1,0].set_ylabel('Score contribution (s²/n)')\n",
    "axes[1,0].set_title('Score Contribution (n > 100)')\n",
    "\n",
    "# Plot 4: Identify worst configurations\n",
    "sorted_scores = sorted([(n, s) for n, s in scores.items()], key=lambda x: -x[1])\n",
    "worst_10 = sorted_scores[:10]\n",
    "print(\"Top 10 worst configurations (highest score contribution):\")\n",
    "for n, s in worst_10:\n",
    "    print(f\"  n={n}: {s:.6f}\")\n",
    "\n",
    "axes[1,1].barh([f'n={n}' for n, s in worst_10], [s for n, s in worst_10])\n",
    "axes[1,1].set_xlabel('Score contribution')\n",
    "axes[1,1].set_title('Top 10 Worst Configurations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/score_analysis.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much improvement is needed per configuration\n",
    "print(\"\\nTo beat target, we need to reduce total score by:\", gap)\n",
    "print(f\"Average reduction needed per configuration: {gap/200:.6f}\")\n",
    "\n",
    "# If we could improve each configuration by X%, what would the new score be?\n",
    "for pct in [1, 2, 3, 5, 10]:\n",
    "    new_score = total * (1 - pct/100)\n",
    "    print(f\"  {pct}% improvement: {new_score:.6f} (gap: {new_score - target_score:.6f})\")\n",
    "\n",
    "print(f\"\\nRequired improvement percentage: {gap/total*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available pre-computed solutions\n",
    "import os\n",
    "\n",
    "print(\"Available pre-computed solutions:\")\n",
    "print(\"1. santa_data/santa-2025.csv (Kaggle dataset)\")\n",
    "print(\"2. bucket_data/submission.csv (bucket-of-chump)\")\n",
    "print(\"3. precomputed_submission.csv (GitHub)\")\n",
    "\n",
    "# Load and compare all three\n",
    "kaggle_df = pd.read_csv('/home/code/santa_data/santa-2025.csv')\n",
    "bucket_df = pd.read_csv('/home/code/bucket_data/submission.csv')\n",
    "github_df = pd.read_csv('/home/code/precomputed_submission.csv')\n",
    "\n",
    "kaggle_scores = calculate_score_per_n(kaggle_df)\n",
    "bucket_scores = calculate_score_per_n(bucket_df)\n",
    "github_scores = calculate_score_per_n(github_df)\n",
    "\n",
    "print(f\"\\nKaggle dataset total: {sum(kaggle_scores.values()):.6f}\")\n",
    "print(f\"Bucket-of-chump total: {sum(bucket_scores.values()):.6f}\")\n",
    "print(f\"GitHub total: {sum(github_scores.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merged best solution\n",
    "merged_scores = {}\n",
    "merged_source = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_src = None\n",
    "    \n",
    "    for name, scores_dict in [('kaggle', kaggle_scores), ('bucket', bucket_scores), ('github', github_scores)]:\n",
    "        if n in scores_dict and scores_dict[n] < best_score:\n",
    "            best_score = scores_dict[n]\n",
    "            best_src = name\n",
    "    \n",
    "    merged_scores[n] = best_score\n",
    "    merged_source[n] = best_src\n",
    "\n",
    "merged_total = sum(merged_scores.values())\n",
    "print(f\"Merged best total: {merged_total:.6f}\")\n",
    "print(f\"Gap to target: {merged_total - target_score:.6f}\")\n",
    "\n",
    "# Count sources\n",
    "from collections import Counter\n",
    "source_counts = Counter(merged_source.values())\n",
    "print(f\"\\nSource distribution: {dict(source_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfdcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify configurations where different sources are better\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    kaggle_s = kaggle_scores.get(n, float('inf'))\n",
    "    bucket_s = bucket_scores.get(n, float('inf'))\n",
    "    github_s = github_scores.get(n, float('inf'))\n",
    "    \n",
    "    best = min(kaggle_s, bucket_s, github_s)\n",
    "    worst = max(kaggle_s, bucket_s, github_s)\n",
    "    \n",
    "    if worst - best > 0.001:  # Significant difference\n",
    "        improvements.append((n, best, worst, worst - best))\n",
    "\n",
    "print(f\"\\nConfigurations with significant differences between sources: {len(improvements)}\")\n",
    "for n, best, worst, diff in sorted(improvements, key=lambda x: -x[3])[:10]:\n",
    "    print(f\"  n={n}: best={best:.6f}, worst={worst:.6f}, diff={diff:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
