{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72f7f45",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline from Pre-computed Solution\n",
    "\n",
    "Goal: Evaluate the pre-computed solution from SmartManoj's GitHub and compare with sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a037552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "from shapely import affinity\n",
    "from decimal import Decimal, getcontext\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "getcontext().prec = 30\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d452e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChristmasTree:\n",
    "    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "        \n",
    "        # Tree dimensions\n",
    "        trunk_w, trunk_h = Decimal(\"0.15\"), Decimal(\"0.2\")\n",
    "        base_w, mid_w, top_w = Decimal(\"0.7\"), Decimal(\"0.4\"), Decimal(\"0.25\")\n",
    "        tip_y, tier_1_y, tier_2_y = Decimal(\"0.8\"), Decimal(\"0.5\"), Decimal(\"0.25\")\n",
    "        base_y, trunk_bottom_y = Decimal(\"0.0\"), -trunk_h\n",
    "        \n",
    "        # 15 vertices\n",
    "        initial_polygon = Polygon([\n",
    "            (0, float(tip_y)),\n",
    "            (float(top_w/2), float(tier_1_y)),\n",
    "            (float(top_w/4), float(tier_1_y)),\n",
    "            (float(mid_w/2), float(tier_2_y)),\n",
    "            (float(mid_w/4), float(tier_2_y)),\n",
    "            (float(base_w/2), float(base_y)),\n",
    "            (float(trunk_w/2), float(base_y)),\n",
    "            (float(trunk_w/2), float(trunk_bottom_y)),\n",
    "            (float(-trunk_w/2), float(trunk_bottom_y)),\n",
    "            (float(-trunk_w/2), float(base_y)),\n",
    "            (float(-base_w/2), float(base_y)),\n",
    "            (float(-mid_w/4), float(tier_2_y)),\n",
    "            (float(-mid_w/2), float(tier_2_y)),\n",
    "            (float(-top_w/4), float(tier_1_y)),\n",
    "            (float(-top_w/2), float(tier_1_y)),\n",
    "        ])\n",
    "        \n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated, xoff=float(self.center_x), yoff=float(self.center_y))\n",
    "\n",
    "def has_overlap(trees):\n",
    "    \"\"\"Check if any trees overlap (touching is OK)\"\"\"\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    polygons = [t.polygon for t in trees]\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        indices = tree_index.query(poly)\n",
    "        for idx in indices:\n",
    "            if idx != i and poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_score(trees, n):\n",
    "    \"\"\"Calculate score for a single n-tree configuration\"\"\"\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T for t in trees])\n",
    "    side = max(xys.max(axis=0) - xys.min(axis=0))\n",
    "    return side**2 / n\n",
    "\n",
    "print(\"ChristmasTree class and helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_submission(df):\n",
    "    \"\"\"Parse submission dataframe and return trees grouped by n\"\"\"\n",
    "    groups = {}\n",
    "    for n in range(1, 201):\n",
    "        group = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "        if len(group) > 0:\n",
    "            trees = []\n",
    "            for _, row in group.iterrows():\n",
    "                x = str(row[\"x\"])[1:]  # Remove 's' prefix\n",
    "                y = str(row[\"y\"])[1:]\n",
    "                deg = str(row[\"deg\"])[1:]\n",
    "                trees.append(ChristmasTree(x, y, deg))\n",
    "            groups[n] = trees\n",
    "    return groups\n",
    "\n",
    "def calculate_total_score(groups, verbose=False):\n",
    "    \"\"\"Calculate total score and check for overlaps\"\"\"\n",
    "    total_score = 0.0\n",
    "    overlaps = []\n",
    "    scores_by_n = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        if n in groups:\n",
    "            trees = groups[n]\n",
    "            score = get_score(trees, n)\n",
    "            scores_by_n[n] = score\n",
    "            total_score += score\n",
    "            \n",
    "            if has_overlap(trees):\n",
    "                overlaps.append(n)\n",
    "                if verbose:\n",
    "                    print(f\"  n={n}: OVERLAP DETECTED!\")\n",
    "            elif verbose and n <= 10:\n",
    "                print(f\"  n={n}: score={score:.6f}\")\n",
    "    \n",
    "    return total_score, overlaps, scores_by_n\n",
    "\n",
    "print(\"Scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed solution from GitHub\n",
    "print(\"Loading pre-computed solution from GitHub...\")\n",
    "precomputed_df = pd.read_csv('/home/code/precomputed_submission.csv')\n",
    "print(f\"Shape: {precomputed_df.shape}\")\n",
    "print(precomputed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and score pre-computed solution\n",
    "print(\"\\nParsing pre-computed solution...\")\n",
    "precomputed_groups = parse_submission(precomputed_df)\n",
    "print(f\"Parsed {len(precomputed_groups)} groups\")\n",
    "\n",
    "print(\"\\nCalculating score for pre-computed solution...\")\n",
    "precomputed_score, precomputed_overlaps, precomputed_scores = calculate_total_score(precomputed_groups, verbose=True)\n",
    "print(f\"\\nPre-computed solution total score: {precomputed_score:.6f}\")\n",
    "print(f\"Overlapping configurations: {len(precomputed_overlaps)}\")\n",
    "if precomputed_overlaps:\n",
    "    print(f\"Overlap n values: {precomputed_overlaps[:20]}...\" if len(precomputed_overlaps) > 20 else f\"Overlap n values: {precomputed_overlaps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission\n",
    "print(\"Loading sample submission...\")\n",
    "sample_df = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "\n",
    "print(\"\\nParsing sample submission...\")\n",
    "sample_groups = parse_submission(sample_df)\n",
    "print(f\"Parsed {len(sample_groups)} groups\")\n",
    "\n",
    "print(\"\\nCalculating score for sample submission...\")\n",
    "sample_score, sample_overlaps, sample_scores = calculate_total_score(sample_groups, verbose=True)\n",
    "print(f\"\\nSample submission total score: {sample_score:.6f}\")\n",
    "print(f\"Overlapping configurations: {len(sample_overlaps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCORE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Pre-computed solution (GitHub): {precomputed_score:.6f}\")\n",
    "print(f\"Sample submission:               {sample_score:.6f}\")\n",
    "print(f\"Target to beat:                  68.931058\")\n",
    "print(f\"\\nImprovement over sample: {sample_score - precomputed_score:.6f}\")\n",
    "print(f\"Gap to target: {precomputed_score - 68.931058:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution by n\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Score by n\n",
    "ns = list(range(1, 201))\n",
    "precomputed_scores_list = [precomputed_scores.get(n, 0) for n in ns]\n",
    "sample_scores_list = [sample_scores.get(n, 0) for n in ns]\n",
    "\n",
    "axes[0].plot(ns, precomputed_scores_list, label='Pre-computed', alpha=0.7)\n",
    "axes[0].plot(ns, sample_scores_list, label='Sample', alpha=0.7)\n",
    "axes[0].set_xlabel('n (number of trees)')\n",
    "axes[0].set_ylabel('Score contribution (sÂ²/n)')\n",
    "axes[0].set_title('Score by Configuration Size')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative score\n",
    "cum_precomputed = np.cumsum(precomputed_scores_list)\n",
    "cum_sample = np.cumsum(sample_scores_list)\n",
    "\n",
    "axes[1].plot(ns, cum_precomputed, label='Pre-computed', alpha=0.7)\n",
    "axes[1].plot(ns, cum_sample, label='Sample', alpha=0.7)\n",
    "axes[1].axhline(y=68.931058, color='r', linestyle='--', label='Target')\n",
    "axes[1].set_xlabel('n (number of trees)')\n",
    "axes[1].set_ylabel('Cumulative Score')\n",
    "axes[1].set_title('Cumulative Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/experiments/001_baseline/score_comparison.png', dpi=100)\n",
    "plt.show()\n",
    "print(\"Score comparison plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If pre-computed solution is valid (no overlaps), use it as submission\n",
    "if len(precomputed_overlaps) == 0:\n",
    "    print(\"Pre-computed solution has no overlaps - using as submission\")\n",
    "    precomputed_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "    print(\"Saved to /home/submission/submission.csv\")\n",
    "else:\n",
    "    print(f\"Pre-computed solution has {len(precomputed_overlaps)} overlapping configurations\")\n",
    "    print(\"Need to repair overlaps before submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90997a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission file\n",
    "print(\"\\nVerifying submission file...\")\n",
    "submission = pd.read_csv('/home/submission/submission.csv')\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"Columns: {submission.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfd718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 001 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Pre-computed solution score: {precomputed_score:.6f}\")\n",
    "print(f\"Target score: 68.931058\")\n",
    "print(f\"Gap to target: {precomputed_score - 68.931058:.6f}\")\n",
    "print(f\"Overlaps: {len(precomputed_overlaps)}\")\n",
    "print(f\"Submission saved: /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
