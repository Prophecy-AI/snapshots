{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e577816",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Goal: Understand the gap to target and plan next experiment\n",
    "\n",
    "**Target Score:** 68.922808\n",
    "**Current Best:** 70.676099 (gap: 1.75 points)\n",
    "\n",
    "## Key Insights from Evaluator:\n",
    "1. The bbox3 optimizer uses perturbations too coarse (0.01-0.1 units)\n",
    "2. Need **fractional translation** with micro-adjustments (0.001-0.00001 units)\n",
    "3. Need **ensemble approach** - best config for each N from multiple sources\n",
    "4. Need **per-N analysis** to identify worst-performing configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# List all available submissions\n",
    "print(\"=== Available Submissions ===\")\n",
    "submission_files = [\n",
    "    '/home/code/preoptimized/santa-2025.csv',\n",
    "    '/home/code/preoptimized/ensemble.csv',\n",
    "    '/home/code/preoptimized/bucket-of-chump/submission.csv',\n",
    "    '/home/code/preoptimized/telegram/71.97.csv',\n",
    "    '/home/code/preoptimized/telegram/72.49.csv',\n",
    "]\n",
    "\n",
    "for f in submission_files:\n",
    "    if os.path.exists(f):\n",
    "        df = pd.read_csv(f)\n",
    "        print(f\"{f}: {len(df)} rows\")\n",
    "    else:\n",
    "        print(f\"{f}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functions\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "import math\n",
    "\n",
    "getcontext().prec = 30\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (float(0), float(tip_y)),\n",
    "            (float(top_w / 2), float(tier_1_y)),\n",
    "            (float(top_w / 4), float(tier_1_y)),\n",
    "            (float(mid_w / 2), float(tier_2_y)),\n",
    "            (float(mid_w / 4), float(tier_2_y)),\n",
    "            (float(base_w / 2), float(base_y)),\n",
    "            (float(trunk_w / 2), float(base_y)),\n",
    "            (float(trunk_w / 2), float(trunk_bottom_y)),\n",
    "            (float(-trunk_w / 2), float(trunk_bottom_y)),\n",
    "            (float(-trunk_w / 2), float(base_y)),\n",
    "            (float(-base_w / 2), float(base_y)),\n",
    "            (float(-mid_w / 4), float(tier_2_y)),\n",
    "            (float(-mid_w / 2), float(tier_2_y)),\n",
    "            (float(-top_w / 4), float(tier_1_y)),\n",
    "            (float(-top_w / 2), float(tier_1_y)),\n",
    "        ])\n",
    "\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated, xoff=float(self.center_x), yoff=float(self.center_y))\n",
    "\n",
    "def load_trees_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    subset = df[df['id'].str.startswith(prefix)]\n",
    "    trees = []\n",
    "    for _, row in subset.iterrows():\n",
    "        x = str(row['x']).lstrip('s')\n",
    "        y = str(row['y']).lstrip('s')\n",
    "        deg = str(row['deg']).lstrip('s')\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_bounding_box_side(trees):\n",
    "    if not trees:\n",
    "        return 0\n",
    "    all_coords = []\n",
    "    for tree in trees:\n",
    "        coords = np.array(tree.polygon.exterior.coords)\n",
    "        all_coords.append(coords)\n",
    "    all_coords = np.vstack(all_coords)\n",
    "    x_range = all_coords[:, 0].max() - all_coords[:, 0].min()\n",
    "    y_range = all_coords[:, 1].max() - all_coords[:, 1].min()\n",
    "    return max(x_range, y_range)\n",
    "\n",
    "def score_n(df, n):\n",
    "    trees = load_trees_for_n(df, n)\n",
    "    if len(trees) != n:\n",
    "        return None\n",
    "    side = get_bounding_box_side(trees)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(\"Scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cba653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all submissions and compare per-N\n",
    "print(\"Scoring all submissions (this takes a few minutes)...\")\n",
    "\n",
    "submissions = {}\n",
    "for f in submission_files:\n",
    "    if os.path.exists(f):\n",
    "        name = os.path.basename(f).replace('.csv', '')\n",
    "        submissions[name] = pd.read_csv(f)\n",
    "        print(f\"Loaded {name}\")\n",
    "\n",
    "# Calculate scores for each N\n",
    "scores_per_n = {name: {} for name in submissions}\n",
    "\n",
    "for name, df in submissions.items():\n",
    "    print(f\"\\nScoring {name}...\")\n",
    "    total = 0\n",
    "    for n in range(1, 201):\n",
    "        sc = score_n(df, n)\n",
    "        if sc is not None:\n",
    "            scores_per_n[name][n] = sc\n",
    "            total += sc\n",
    "    print(f\"  Total: {total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble - best config for each N\n",
    "print(\"\\n=== Creating Ensemble ===\")\n",
    "\n",
    "best_per_n = {}\n",
    "best_source_per_n = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    for name in scores_per_n:\n",
    "        if n in scores_per_n[name] and scores_per_n[name][n] < best_score:\n",
    "            best_score = scores_per_n[name][n]\n",
    "            best_source = name\n",
    "    best_per_n[n] = best_score\n",
    "    best_source_per_n[n] = best_source\n",
    "\n",
    "ensemble_total = sum(best_per_n.values())\n",
    "print(f\"\\nEnsemble total score: {ensemble_total:.6f}\")\n",
    "print(f\"Gap to target (68.922808): {ensemble_total - 68.922808:.6f}\")\n",
    "\n",
    "# Count sources\n",
    "from collections import Counter\n",
    "source_counts = Counter(best_source_per_n.values())\n",
    "print(f\"\\nSource distribution:\")\n",
    "for source, count in source_counts.most_common():\n",
    "    print(f\"  {source}: {count} configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify worst-performing N values (highest score contribution)\n",
    "print(\"\\n=== Worst-Performing N Values (Highest Score Contribution) ===\")\n",
    "\n",
    "# Sort by score contribution\n",
    "sorted_n = sorted(best_per_n.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 20 worst N values:\")\n",
    "print(f\"{'N':>5} {'Score':>12} {'Side':>10} {'Source':>20}\")\n",
    "print(\"-\" * 50)\n",
    "for n, score in sorted_n[:20]:\n",
    "    side = np.sqrt(score * n)\n",
    "    print(f\"{n:>5} {score:>12.6f} {side:>10.4f} {best_source_per_n[n]:>20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac743e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate potential improvement from fractional translation\n",
    "print(\"\\n=== Potential Improvement Analysis ===\")\n",
    "\n",
    "# If we could reduce each side by 0.001 (micro-adjustment), how much would score improve?\n",
    "test_reduction = 0.001\n",
    "\n",
    "total_potential = 0\n",
    "for n in range(1, 201):\n",
    "    current_score = best_per_n[n]\n",
    "    current_side = np.sqrt(current_score * n)\n",
    "    new_side = current_side - test_reduction\n",
    "    if new_side > 0:\n",
    "        new_score = (new_side ** 2) / n\n",
    "        improvement = current_score - new_score\n",
    "        total_potential += improvement\n",
    "\n",
    "print(f\"If we reduce each side by {test_reduction}:\")\n",
    "print(f\"  Total potential improvement: {total_potential:.6f}\")\n",
    "print(f\"  New ensemble score: {ensemble_total - total_potential:.6f}\")\n",
    "\n",
    "# More aggressive reduction\n",
    "test_reduction = 0.01\n",
    "total_potential = 0\n",
    "for n in range(1, 201):\n",
    "    current_score = best_per_n[n]\n",
    "    current_side = np.sqrt(current_score * n)\n",
    "    new_side = current_side - test_reduction\n",
    "    if new_side > 0:\n",
    "        new_score = (new_side ** 2) / n\n",
    "        improvement = current_score - new_score\n",
    "        total_potential += improvement\n",
    "\n",
    "print(f\"\\nIf we reduce each side by {test_reduction}:\")\n",
    "print(f\"  Total potential improvement: {total_potential:.6f}\")\n",
    "print(f\"  New ensemble score: {ensemble_total - total_potential:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ensemble submission\n",
    "print(\"\\n=== Building Ensemble Submission ===\")\n",
    "\n",
    "ensemble_rows = []\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_source = best_source_per_n[n]\n",
    "    df = submissions[best_source]\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    subset = df[df['id'].str.startswith(prefix)].copy()\n",
    "    ensemble_rows.append(subset)\n",
    "\n",
    "ensemble_df = pd.concat(ensemble_rows, ignore_index=True)\n",
    "print(f\"Ensemble shape: {ensemble_df.shape}\")\n",
    "\n",
    "# Save ensemble\n",
    "ensemble_df.to_csv('/home/code/preoptimized/best_ensemble.csv', index=False)\n",
    "print(\"Saved to /home/code/preoptimized/best_ensemble.csv\")\n",
    "\n",
    "# Verify score\n",
    "verify_total = 0\n",
    "for n in range(1, 201):\n",
    "    sc = score_n(ensemble_df, n)\n",
    "    if sc is not None:\n",
    "        verify_total += sc\n",
    "print(f\"Verified ensemble score: {verify_total:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
