{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37603f2c",
   "metadata": {},
   "source": [
    "# Loop 32 Strategic Analysis\n",
    "\n",
    "## Critical Situation\n",
    "- **Current best LB**: 70.315537 (exp_029)\n",
    "- **Target**: 68.870973 (Jingle bins)\n",
    "- **Gap**: 1.44 points (2.05%)\n",
    "- **Last 12 experiments**: 0.001 points total improvement\n",
    "\n",
    "## The Problem\n",
    "The last 12 experiments (exp_021-032) found essentially ZERO improvement:\n",
    "- bbox3 extended runs: 0.0000003 improvement\n",
    "- External data mining: diminishing returns\n",
    "- All algorithmic approaches converge to same score\n",
    "\n",
    "## Key Insight from Leaderboard\n",
    "Top teams have scores in the 68.8-69.3 range. Our 70.3 is 1.4+ points away.\n",
    "This is NOT a micro-optimization problem - we need a FUNDAMENTALLY different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the score breakdown by N range\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load our best submission\n",
    "df = pd.read_csv('/home/code/experiments/029_final_ensemble_v2/submission.csv')\n",
    "\n",
    "def parse_coord(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "def parse_id(id_str):\n",
    "    parts = str(id_str).split('_')\n",
    "    return int(parts[0]), int(parts[1])\n",
    "\n",
    "df['n'] = df['id'].apply(lambda x: parse_id(x)[0])\n",
    "df['i'] = df['id'].apply(lambda x: parse_id(x)[1])\n",
    "for col in ['x', 'y', 'deg']:\n",
    "    df[col] = df[col].apply(parse_coord)\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def get_tree_vertices(x, y, deg):\n",
    "    rad = np.radians(deg)\n",
    "    cos_a, sin_a = np.cos(rad), np.sin(rad)\n",
    "    vertices = []\n",
    "    for tx, ty in zip(TX, TY):\n",
    "        rx = tx * cos_a - ty * sin_a + x\n",
    "        ry = tx * sin_a + ty * cos_a + y\n",
    "        vertices.append((rx, ry))\n",
    "    return vertices\n",
    "\n",
    "def calculate_score(trees, n):\n",
    "    all_x, all_y = [], []\n",
    "    for tree in trees:\n",
    "        vertices = get_tree_vertices(tree['x'], tree['y'], tree['deg'])\n",
    "        for vx, vy in vertices:\n",
    "            all_x.append(vx)\n",
    "            all_y.append(vy)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side**2 / n\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    n_df = df[df['n'] == n].sort_values('i')\n",
    "    trees = n_df[['x', 'y', 'deg']].to_dict('records')\n",
    "    per_n_scores[n] = calculate_score(trees, n)\n",
    "\n",
    "total = sum(per_n_scores.values())\n",
    "print(f\"Total score: {total:.6f}\")\n",
    "print(f\"Target: 68.870973\")\n",
    "print(f\"Gap: {total - 68.870973:.6f}\")\n",
    "print()\n",
    "\n",
    "# Score by N range\n",
    "ranges = [(1, 10), (11, 30), (31, 50), (51, 100), (101, 150), (151, 200)]\n",
    "for start, end in ranges:\n",
    "    range_score = sum(per_n_scores[n] for n in range(start, end+1))\n",
    "    pct = range_score / total * 100\n",
    "    print(f\"N={start:3d}-{end:3d}: {range_score:.4f} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal: {total:.6f}\")\n",
    "print(f\"Target: 68.870973\")\n",
    "print(f\"Gap: {total - 68.870973:.6f} ({(total - 68.870973)/68.870973*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9210946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which N values have the most room for improvement\n",
    "# Compare to theoretical lower bound (area of N trees / N)\n",
    "\n",
    "# Single tree area (approximate)\n",
    "tree_area = 0.5 * 0.7 * 0.8  # rough approximation\n",
    "print(f\"Approximate single tree area: {tree_area:.4f}\")\n",
    "\n",
    "# For each N, the theoretical minimum score would be if we could pack\n",
    "# N trees with zero wasted space. This is impossible, but gives a lower bound.\n",
    "\n",
    "print(\"\\nN values with highest potential for improvement:\")\n",
    "print(\"(comparing current score to theoretical minimum)\")\n",
    "print()\n",
    "\n",
    "potential_improvements = []\n",
    "for n in range(1, 201):\n",
    "    current = per_n_scores[n]\n",
    "    # Theoretical minimum: if trees packed perfectly, side = sqrt(n * tree_area)\n",
    "    # Score = side^2 / n = n * tree_area / n = tree_area\n",
    "    # But this ignores the tree shape, so it's a very loose bound\n",
    "    \n",
    "    # Better estimate: for small N, we can compute tighter bounds\n",
    "    # For N=1, optimal is known: 0.6612\n",
    "    # For N=2, optimal is known: 0.4508\n",
    "    \n",
    "    # Let's just look at where we're furthest from the \"expected\" score\n",
    "    # based on the pattern of scores\n",
    "    potential_improvements.append((n, current))\n",
    "\n",
    "# Sort by score (highest first - these contribute most to total)\n",
    "potential_improvements.sort(key=lambda x: -x[1])\n",
    "print(\"Top 20 N values by score contribution:\")\n",
    "for n, score in potential_improvements[:20]:\n",
    "    print(f\"  N={n:3d}: {score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what external data sources we have and their scores\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"External data sources:\")\n",
    "for path in glob.glob('/home/code/research/**/*.csv', recursive=True):\n",
    "    try:\n",
    "        ext_df = pd.read_csv(path)\n",
    "        if 'id' in ext_df.columns and len(ext_df) > 0:\n",
    "            # Try to calculate total score\n",
    "            ext_df['n'] = ext_df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "            for col in ['x', 'y', 'deg']:\n",
    "                if col in ext_df.columns:\n",
    "                    ext_df[col] = ext_df[col].apply(parse_coord)\n",
    "            \n",
    "            ext_total = 0\n",
    "            valid = True\n",
    "            for n in range(1, 201):\n",
    "                n_df = ext_df[ext_df['n'] == n]\n",
    "                if len(n_df) != n:\n",
    "                    valid = False\n",
    "                    break\n",
    "                trees = n_df[['x', 'y', 'deg']].to_dict('records')\n",
    "                ext_total += calculate_score(trees, n)\n",
    "            \n",
    "            if valid:\n",
    "                print(f\"  {os.path.basename(path)}: {ext_total:.6f}\")\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7af64",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "1. **The gap is 1.44 points (2.05%)** - This is NOT achievable through micro-optimization\n",
    "\n",
    "2. **Top teams (68.8-69.3) are 1+ points better** - They have fundamentally different solutions\n",
    "\n",
    "3. **bbox3 extended runs found 0.0000003 improvement** - The optimizer is at its limit\n",
    "\n",
    "4. **External data mining is exhausted** - All public sources are worse than our current best\n",
    "\n",
    "## What Top Teams Are Doing Differently\n",
    "\n",
    "From the discussions and kernels:\n",
    "1. **Running for 24-72 HOURS** with 24+ CPUs (we ran 53 minutes)\n",
    "2. **Using shake_public** - A different optimizer we haven't tried\n",
    "3. **Asymmetric solutions** - Breaking symmetry for better packing\n",
    "4. **Per-N specialization** - Different strategies for different N ranges\n",
    "\n",
    "## The Path Forward\n",
    "\n",
    "### Option 1: MUCH LONGER COMPUTE TIME\n",
    "- Run bbox3 for 8-24 hours (not 53 minutes)\n",
    "- This is 16-27x longer than our current runs\n",
    "- May find improvements that shorter runs miss\n",
    "\n",
    "### Option 2: TRY SHAKE_PUBLIC\n",
    "- We have shake_public binary but haven't used it\n",
    "- It may find different local optima than bbox3\n",
    "- Library compatibility issues need to be resolved\n",
    "\n",
    "### Option 3: FUNDAMENTALLY DIFFERENT ALGORITHM\n",
    "- Implement constructive heuristics from scratch\n",
    "- Focus on high-impact N values (N=1-50 contribute 27% of score)\n",
    "- Try asymmetric placements\n",
    "\n",
    "### Option 4: FIND BETTER EXTERNAL DATA\n",
    "- Check for new Kaggle kernels with better scores\n",
    "- Look for private/unpublished solutions\n",
    "- Analyze what makes top solutions different"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
