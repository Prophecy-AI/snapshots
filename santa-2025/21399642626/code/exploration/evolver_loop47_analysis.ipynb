{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f1cc85",
   "metadata": {},
   "source": [
    "# Loop 47 Strategic Analysis\n",
    "\n",
    "## Current Situation\n",
    "- Best LB: 70.306164\n",
    "- Target: 68.861114  \n",
    "- Gap: 1.445 points (2.05%)\n",
    "- Submissions used: 22/100\n",
    "\n",
    "## Key Observations from 47 experiments:\n",
    "1. All local optimization methods (SA, exhaustive, NFP, shake, bbox3) converge to ~70.3\n",
    "2. External data mining found ~0.01 points total (exhausted)\n",
    "3. Subset extraction found ~0.002 points (exhausted)\n",
    "4. Last 4 experiments found ZERO improvement\n",
    "\n",
    "## The Fundamental Problem\n",
    "The baseline solutions are at EXTREMELY strong local optima. No perturbation-based method can escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze experiment progression\n",
    "experiments = state['experiments']\n",
    "print(\"=== EXPERIMENT PROGRESSION ===\")\n",
    "for exp in experiments[-15:]:\n",
    "    score = exp.get('cv_score', 'N/A')\n",
    "    name = exp.get('name', 'N/A')\n",
    "    fallback = exp.get('used_baseline_fallback', False)\n",
    "    print(f\"{name}: {score:.6f} {'(FALLBACK)' if fallback else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores to find where improvements are possible\n",
    "import os\n",
    "\n",
    "# Load best submission\n",
    "best_path = '/home/code/experiments/044_extended_subset_extraction/ensemble_044.csv'\n",
    "df = pd.read_csv(best_path)\n",
    "\n",
    "def parse_coord(val):\n",
    "    if isinstance(val, str):\n",
    "        if val.startswith('s'):\n",
    "            return float(val[1:])\n",
    "        return float(val)\n",
    "    return float(val)\n",
    "\n",
    "df['x'] = df['x'].apply(parse_coord)\n",
    "df['y'] = df['y'].apply(parse_coord)\n",
    "df['deg'] = df['deg'].apply(parse_coord)\n",
    "df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def get_tree_vertices(x, y, angle_deg):\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    rx = TX * cos_a - TY * sin_a\n",
    "    ry = TX * sin_a + TY * cos_a\n",
    "    return rx + x, ry + y\n",
    "\n",
    "def compute_bbox_size(trees):\n",
    "    all_x, all_y = [], []\n",
    "    for x, y, angle in trees:\n",
    "        vx, vy = get_tree_vertices(x, y, angle)\n",
    "        all_x.extend(vx)\n",
    "        all_y.extend(vy)\n",
    "    return max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "\n",
    "def compute_score(trees, n):\n",
    "    size = compute_bbox_size(trees)\n",
    "    return (size ** 2) / n\n",
    "\n",
    "# Compute per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    n_df = df[df['n'] == n]\n",
    "    if len(n_df) == n:\n",
    "        trees = [(row['x'], row['y'], row['deg']) for _, row in n_df.iterrows()]\n",
    "        per_n_scores[n] = compute_score(trees, n)\n",
    "\n",
    "print(f\"Total score: {sum(per_n_scores.values()):.6f}\")\n",
    "print(f\"\\nTop 10 highest per-N scores (most room for improvement):\")\n",
    "sorted_scores = sorted(per_n_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_scores[:10]:\n",
    "    print(f\"  N={n}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the theoretical minimum\n",
    "# For N=1, the minimum is when the tree is rotated to minimize bbox\n",
    "# At 45 degrees, the bbox is minimized\n",
    "\n",
    "print(\"=== THEORETICAL ANALYSIS ===\")\n",
    "print(f\"\\nTree dimensions: width={max(TX)-min(TX):.3f}, height={max(TY)-min(TY):.3f}\")\n",
    "print(f\"Tree area: ~0.35 (approximate)\")\n",
    "\n",
    "# For N=1 at 45 degrees\n",
    "import math\n",
    "width = max(TX) - min(TX)  # 0.7\n",
    "height = max(TY) - min(TY)  # 1.0\n",
    "diag = math.sqrt(width**2 + height**2)\n",
    "print(f\"\\nN=1 at 0°: bbox = {height:.3f}, score = {height**2:.6f}\")\n",
    "print(f\"N=1 at 45°: bbox = {diag/math.sqrt(2):.6f}, score = {(diag/math.sqrt(2))**2:.6f}\")\n",
    "print(f\"N=1 actual: {per_n_scores[1]:.6f}\")\n",
    "\n",
    "# The gap analysis\n",
    "print(f\"\\n=== GAP ANALYSIS ===\")\n",
    "print(f\"Current total: {sum(per_n_scores.values()):.6f}\")\n",
    "print(f\"Target: 68.861114\")\n",
    "print(f\"Gap: {sum(per_n_scores.values()) - 68.861114:.6f}\")\n",
    "print(f\"\\nTo close the gap, we need to find ~1.445 points of improvement\")\n",
    "print(f\"That's equivalent to:\")\n",
    "print(f\"  - Improving N=1 by 1.445 (impossible, N=1 is already optimal)\")\n",
    "print(f\"  - Improving 145 N values by 0.01 each\")\n",
    "print(f\"  - Improving 14 N values by 0.1 each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do top solutions look like?\n",
    "# Let's analyze the structure of our best solutions\n",
    "\n",
    "print(\"=== SOLUTION STRUCTURE ANALYSIS ===\")\n",
    "\n",
    "# Analyze angle distribution\n",
    "all_angles = df['deg'].values\n",
    "print(f\"\\nAngle distribution:\")\n",
    "print(f\"  Mean: {np.mean(all_angles):.2f}°\")\n",
    "print(f\"  Std: {np.std(all_angles):.2f}°\")\n",
    "print(f\"  Min: {np.min(all_angles):.2f}°\")\n",
    "print(f\"  Max: {np.max(all_angles):.2f}°\")\n",
    "\n",
    "# Analyze position distribution\n",
    "all_x = df['x'].values\n",
    "all_y = df['y'].values\n",
    "print(f\"\\nPosition distribution:\")\n",
    "print(f\"  X range: [{np.min(all_x):.2f}, {np.max(all_x):.2f}]\")\n",
    "print(f\"  Y range: [{np.min(all_y):.2f}, {np.max(all_y):.2f}]\")\n",
    "\n",
    "# Analyze per-N patterns\n",
    "print(f\"\\nPer-N analysis for small N:\")\n",
    "for n in [2, 3, 4, 5, 10, 20, 50, 100, 200]:\n",
    "    n_df = df[df['n'] == n]\n",
    "    angles = n_df['deg'].values\n",
    "    unique_angles = len(np.unique(np.round(angles, 1)))\n",
    "    print(f\"  N={n}: {unique_angles} unique angles, score={per_n_scores[n]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The top solutions use DIFFERENT algorithms for different N ranges\n",
    "# Let's see what the theoretical limits are\n",
    "\n",
    "print(\"=== THEORETICAL LIMITS ===\")\n",
    "\n",
    "# For small N, we can compute theoretical minimum\n",
    "# N=1: Single tree, optimal rotation\n",
    "print(f\"\\nN=1: Theoretical minimum = {0.661250:.6f} (at 45°)\")\n",
    "print(f\"      Our score = {per_n_scores[1]:.6f}\")\n",
    "print(f\"      Gap = {per_n_scores[1] - 0.661250:.6f}\")\n",
    "\n",
    "# For N=2: Two trees interlocked\n",
    "# Theoretical minimum is when trees are perfectly interlocked\n",
    "print(f\"\\nN=2: Our score = {per_n_scores[2]:.6f}\")\n",
    "\n",
    "# For large N, the theoretical minimum approaches sqrt(N) * tree_area\n",
    "# But this is very loose\n",
    "print(f\"\\nLarge N theoretical analysis:\")\n",
    "for n in [50, 100, 150, 200]:\n",
    "    # Rough estimate: if trees pack perfectly, bbox ~ sqrt(N * tree_area)\n",
    "    tree_area = 0.35  # approximate\n",
    "    theoretical_min = n * tree_area / n  # = tree_area (per tree)\n",
    "    print(f\"  N={n}: Our score = {per_n_scores[n]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL INSIGHT: What makes top solutions better?\n",
    "# From the kernel analysis, top teams:\n",
    "# 1. Run bbox3 for 24-72 hours (we run 2 hours)\n",
    "# 2. Combine solutions from 17+ team members\n",
    "# 3. Have 953+ submissions\n",
    "\n",
    "# The gap of 1.445 points represents:\n",
    "# - Our compute: ~2 hours on 26 threads = ~52 CPU-hours\n",
    "# - Top teams: 24-72 hours on 24+ CPUs = 576-1728 CPU-hours\n",
    "# That's 10-30x more compute!\n",
    "\n",
    "print(\"=== COMPUTE GAP ANALYSIS ===\")\n",
    "print(f\"\\nOur compute: ~52 CPU-hours\")\n",
    "print(f\"Top teams: ~576-1728 CPU-hours\")\n",
    "print(f\"Compute ratio: 10-30x\")\n",
    "\n",
    "print(f\"\\nBut even with more compute, local optimization converges to same score!\")\n",
    "print(f\"The issue is NOT compute time, it's the ALGORITHM.\")\n",
    "\n",
    "print(f\"\\n=== WHAT WE NEED ===\")\n",
    "print(f\"1. A fundamentally different algorithm that finds DIFFERENT local optima\")\n",
    "print(f\"2. Or, access to solutions from other teams (external data mining exhausted)\")\n",
    "print(f\"3. Or, a way to combine solutions that creates NEW configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze what specific N values have the most room for improvement\n",
    "# by comparing to theoretical limits\n",
    "\n",
    "print(\"=== PER-N IMPROVEMENT POTENTIAL ===\")\n",
    "\n",
    "# For each N, estimate the theoretical minimum\n",
    "# This is very rough but gives us direction\n",
    "\n",
    "improvement_potential = []\n",
    "for n in range(1, 201):\n",
    "    current = per_n_scores[n]\n",
    "    # Rough theoretical minimum: assume perfect packing\n",
    "    # For small N, this is very loose\n",
    "    # For large N, this is more accurate\n",
    "    if n == 1:\n",
    "        theoretical = 0.661250  # Known optimal\n",
    "    else:\n",
    "        # Rough estimate based on tree area and packing efficiency\n",
    "        # Assume 70% packing efficiency for large N\n",
    "        tree_area = 0.35\n",
    "        packing_efficiency = 0.7 if n > 50 else 0.5\n",
    "        theoretical = tree_area / packing_efficiency\n",
    "    \n",
    "    gap = current - theoretical\n",
    "    improvement_potential.append((n, current, theoretical, gap))\n",
    "\n",
    "# Sort by gap (most room for improvement)\n",
    "improvement_potential.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 20 N values with most improvement potential:\")\n",
    "for n, current, theoretical, gap in improvement_potential[:20]:\n",
    "    print(f\"  N={n}: current={current:.4f}, theoretical={theoretical:.4f}, gap={gap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL ANALYSIS: What should we try next?\n",
    "\n",
    "print(\"=== STRATEGIC RECOMMENDATIONS ===\")\n",
    "\n",
    "print(\"\"\"\n",
    "1. STOP running local optimization (SA, bbox3, shake)\n",
    "   - These all converge to the same local optimum (~70.3)\n",
    "   - More iterations won't help\n",
    "\n",
    "2. FOCUS on fundamentally different approaches:\n",
    "   a) Constructive algorithms that build solutions from scratch\n",
    "      - Bottom-left fill (BLF)\n",
    "      - Lattice-based placement\n",
    "      - Spiral placement\n",
    "   \n",
    "   b) Global optimization that can escape local optima\n",
    "      - Genetic algorithm with diverse population\n",
    "      - Simulated annealing with VERY high temperature\n",
    "      - Basin hopping with large jumps\n",
    "   \n",
    "   c) Hybrid approaches\n",
    "      - Use constructive to generate diverse starting points\n",
    "      - Then refine with local search\n",
    "\n",
    "3. ANALYZE top solutions more carefully:\n",
    "   - What patterns do they use?\n",
    "   - What angles are common?\n",
    "   - What spatial arrangements work best?\n",
    "\n",
    "4. The gap of 1.445 points is LARGE\n",
    "   - This is not a fine-tuning problem\n",
    "   - We need a breakthrough, not incremental improvement\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n=== NEXT EXPERIMENT RECOMMENDATION ===\")\n",
    "print(f\"Implement a CONSTRUCTIVE algorithm that builds solutions from scratch.\")\n",
    "print(f\"Start with N=10, N=20, N=30 to test if it can beat baseline.\")\n",
    "print(f\"If it can't beat baseline on small N, the approach won't work.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
