{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8bddda",
   "metadata": {},
   "source": [
    "# Loop 43 LB Feedback Analysis\n",
    "\n",
    "**exp_043 (subset_extraction)**: CV 70.3070 | LB 70.3070 (gap: +0.0000)\n",
    "\n",
    "## Key Findings\n",
    "1. **CV-LB gap is ZERO** - Our local validation is perfectly calibrated\n",
    "2. **Subset extraction found 2 improvements** - N=121 and N=122\n",
    "3. **Total improvement**: 0.001612 points\n",
    "4. **Gap to target**: 1.446 points (2.05%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46f692a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T16:17:55.020004Z",
     "iopub.status.busy": "2026-01-28T16:17:55.019487Z",
     "iopub.status.idle": "2026-01-28T16:17:55.028972Z",
     "shell.execute_reply": "2026-01-28T16:17:55.028557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments: 44\n",
      "Submissions used: 21/100\n",
      "Remaining: 79 submissions\n",
      "\n",
      "Best CV: 70.265730\n",
      "Target: 68.861114\n",
      "Gap: 1.404616 (2.04%)\n",
      "\n",
      "Recent experiments:\n",
      "  039_per_n_gap_analysis                   CV: 70.308629 \n",
      "  040_extended_mining                      CV: 70.308619 \n",
      "  041_constructive_small_n                 CV: 70.308629 FALLBACK\n",
      "  042_row_based_constructive               CV: 70.308629 FALLBACK\n",
      "  043_subset_extraction                    CV: 70.307017 \n"
     ]
    }
   ],
   "source": [
    "# Current state analysis\n",
    "import json\n",
    "\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Count experiment types\n",
    "experiments = state['experiments']\n",
    "print(f\"Total experiments: {len(experiments)}\")\n",
    "print(f\"Submissions used: {21}/100\")\n",
    "print(f\"Remaining: 79 submissions\")\n",
    "\n",
    "# Best scores\n",
    "best_cv = min(exp.get('cv_score', exp.get('score', 999)) for exp in experiments)\n",
    "print(f\"\\nBest CV: {best_cv:.6f}\")\n",
    "print(f\"Target: 68.861114\")\n",
    "print(f\"Gap: {best_cv - 68.861114:.6f} ({(best_cv - 68.861114) / 68.861114 * 100:.2f}%)\")\n",
    "\n",
    "# Recent progress\n",
    "print(\"\\nRecent experiments:\")\n",
    "for exp in experiments[-5:]:\n",
    "    cv = exp.get('cv_score', exp.get('score', 'N/A'))\n",
    "    fallback = exp.get('used_baseline_fallback', False)\n",
    "    print(f\"  {exp['name'][:40]:40s} CV: {cv:.6f} {'FALLBACK' if fallback else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59abe32",
   "metadata": {},
   "source": [
    "## Critical Analysis\n",
    "\n",
    "### What's Working\n",
    "1. **Subset extraction** - First algorithmic improvement in 10+ experiments\n",
    "2. **CV-LB calibration** - Perfect match, no validation issues\n",
    "3. **External data mining** - Found improvements from multiple sources\n",
    "\n",
    "### What's NOT Working\n",
    "1. **Local search methods** (SA, bbox3, shake) - ZERO improvement\n",
    "2. **Constructive approaches** - WORSE than baseline (fallback)\n",
    "3. **Genetic algorithm** - ZERO improvement\n",
    "\n",
    "### The Gap Problem\n",
    "- Current: 70.307\n",
    "- Target: 68.861\n",
    "- Gap: 1.446 points (2.05%)\n",
    "\n",
    "**This gap is TOO LARGE for incremental improvements!**\n",
    "\n",
    "Subset extraction found 0.001612 improvement. At this rate:\n",
    "- Need ~900 similar improvements to reach target\n",
    "- But subset extraction only found 2 improvements total\n",
    "\n",
    "### What Top Teams Did Differently\n",
    "1. **953 submissions** - Accumulated improvements over time\n",
    "2. **Novel algorithms** - Not just running bbox3/SA\n",
    "3. **Per-N specialization** - Different approaches for different N ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbb2b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T16:17:55.030048Z",
     "iopub.status.busy": "2026-01-28T16:17:55.029943Z",
     "iopub.status.idle": "2026-01-28T16:17:55.834886Z",
     "shell.execute_reply": "2026-01-28T16:17:55.834504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-N score analysis:\n",
      "Total: 70.307017\n",
      "\n",
      "Top 10 contributors:\n",
      "  N=  1: 0.661250 (0.94%)\n",
      "  N=  2: 0.450779 (0.64%)\n",
      "  N=  3: 0.434745 (0.62%)\n",
      "  N=  5: 0.416850 (0.59%)\n",
      "  N=  4: 0.416545 (0.59%)\n",
      "  N=  7: 0.399842 (0.57%)\n",
      "  N=  6: 0.399610 (0.57%)\n",
      "  N=  8: 0.385407 (0.55%)\n",
      "  N=  9: 0.383042 (0.54%)\n",
      "  N= 10: 0.376630 (0.54%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze what N values have the most room for improvement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "def parse_coord(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "df['x'] = df['x'].apply(parse_coord)\n",
    "df['y'] = df['y'].apply(parse_coord)\n",
    "df['deg'] = df['deg'].apply(parse_coord)\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def get_tree_vertices(x, y, angle_deg):\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    rx = TX * cos_a - TY * sin_a\n",
    "    ry = TX * sin_a + TY * cos_a\n",
    "    return rx + x, ry + y\n",
    "\n",
    "def compute_bbox_size(trees):\n",
    "    all_x, all_y = [], []\n",
    "    for x, y, angle in trees:\n",
    "        vx, vy = get_tree_vertices(x, y, angle)\n",
    "        all_x.extend(vx)\n",
    "        all_y.extend(vy)\n",
    "    return max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "\n",
    "def compute_score(trees, n):\n",
    "    size = compute_bbox_size(trees)\n",
    "    return (size ** 2) / n\n",
    "\n",
    "# Compute per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    n_df = df[df['n'] == n]\n",
    "    trees = [(row['x'], row['y'], row['deg']) for _, row in n_df.iterrows()]\n",
    "    per_n_scores[n] = compute_score(trees, n)\n",
    "\n",
    "print(\"Per-N score analysis:\")\n",
    "print(f\"Total: {sum(per_n_scores.values()):.6f}\")\n",
    "print(f\"\\nTop 10 contributors:\")\n",
    "for n, score in sorted(per_n_scores.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"  N={n:3d}: {score:.6f} ({score/sum(per_n_scores.values())*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1bf0e",
   "metadata": {},
   "source": [
    "## Strategy for Next Experiment\n",
    "\n",
    "### EXPAND SUBSET EXTRACTION (Evaluator's Recommendation)\n",
    "\n",
    "The subset extraction approach is the **ONLY** method that found improvements in 10+ experiments.\n",
    "\n",
    "**What to try:**\n",
    "1. **N+2 → N extraction**: Remove 2 trees from N+2 to create N\n",
    "2. **N+3 → N extraction**: Remove 3 trees from N+3 to create N\n",
    "3. **Cross-N extraction**: Use trees from multiple different N values\n",
    "4. **Recursive extraction**: Apply extraction to the improved solutions\n",
    "\n",
    "### Alternative: External Data Mining\n",
    "\n",
    "Check for new kernels/datasets that might have better solutions:\n",
    "- New kernels published in last 24 hours?\n",
    "- New datasets shared?\n",
    "- Solutions from other teams?\n",
    "\n",
    "### The Math\n",
    "\n",
    "To reach target (68.861), we need 1.446 points improvement:\n",
    "- If we find 0.01 improvement per N value: need 145 N values\n",
    "- If we find 0.001 improvement per N value: need 1446 N values (impossible)\n",
    "\n",
    "**Conclusion**: Need LARGER improvements per N, not more tiny improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record key finding\n",
    "print(\"KEY FINDING:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Subset extraction is the ONLY approach that found improvements\")\n",
    "print(\"in the last 10+ experiments.\")\n",
    "print(\"\")\n",
    "print(\"exp_043 found 2 improvements totaling 0.001612 points:\")\n",
    "print(\"  - N=121: +0.000766 (from N=122)\")\n",
    "print(\"  - N=122: +0.000846 (from N=123)\")\n",
    "print(\"\")\n",
    "print(\"This proves the baseline is NOT globally optimal for all N.\")\n",
    "print(\"The key is to find MORE improvements through expanded extraction.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
