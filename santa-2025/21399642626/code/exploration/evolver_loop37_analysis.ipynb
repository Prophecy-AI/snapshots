{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a404ea",
   "metadata": {},
   "source": [
    "# Loop 37 Analysis: Critical Assessment\n",
    "\n",
    "## Key Questions:\n",
    "1. What is the actual gap to target?\n",
    "2. What approaches have been tried vs what's left?\n",
    "3. What do top solutions do differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c5e579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.535633Z",
     "iopub.status.busy": "2026-01-28T10:03:32.535225Z",
     "iopub.status.idle": "2026-01-28T10:03:32.689823Z",
     "shell.execute_reply": "2026-01-28T10:03:32.689442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiments: 38\n",
      "\n",
      "Score progression:\n",
      "  023_branch_and_bound_small_n: CV=70.316492, LB=None\n",
      "  024_lattice_packing: CV=70.316492, LB=None\n",
      "  025_interlock_pattern: CV=70.316492, LB=None\n",
      "  026_jostle_algorithm: CV=70.316492, LB=None\n",
      "  027_blf_constructive: CV=70.316492, LB=None\n",
      "  028_final_ensemble: CV=70.315653, LB=None\n",
      "  029_final_ensemble_v2: CV=70.315537, LB=None\n",
      "  030_extended_cpp_ensemble: CV=70.315393, LB=None\n",
      "  031_safe_ensemble: CV=70.315389, LB=None\n",
      "  032_extended_bbox3: CV=70.315389, LB=None\n",
      "  033_extended_bbox3_revert: CV=70.315537, LB=None\n",
      "  034_extended_bbox3_final: CV=70.315537, LB=None\n",
      "  035_lattice_constructive: CV=70.315537, LB=None\n",
      "  036_shake_algorithm: CV=70.315537, LB=None\n",
      "  037_genetic_algorithm: CV=70.315537, LB=None\n",
      "\n",
      "Best CV: 70.265730\n",
      "Target: 68.866853\n",
      "Gap: 1.398877 (2.03%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze experiments\n",
    "experiments = state['experiments']\n",
    "print(f\"Total experiments: {len(experiments)}\")\n",
    "print(f\"\\nScore progression:\")\n",
    "for exp in experiments[-15:]:\n",
    "    print(f\"  {exp['name']}: CV={exp['cv_score']:.6f}, LB={exp.get('lb_score', 'N/A')}\")\n",
    "\n",
    "# Best scores\n",
    "cv_scores = [e['cv_score'] for e in experiments]\n",
    "best_cv = min(cv_scores)\n",
    "print(f\"\\nBest CV: {best_cv:.6f}\")\n",
    "print(f\"Target: 68.866853\")\n",
    "print(f\"Gap: {best_cv - 68.866853:.6f} ({(best_cv - 68.866853)/68.866853*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a823eecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.690893Z",
     "iopub.status.busy": "2026-01-28T10:03:32.690738Z",
     "iopub.status.idle": "2026-01-28T10:03:32.695595Z",
     "shell.execute_reply": "2026-01-28T10:03:32.695265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments by approach type:\n",
      "  baseline: 2 experiments, best=70.523320\n",
      "  local_search: 11 experiments, best=70.315389\n",
      "  ensemble: 13 experiments, best=70.265730\n",
      "  constructive: 5 experiments, best=70.315537\n",
      "  population: 3 experiments, best=70.315537\n",
      "  extended_opt: 4 experiments, best=70.315389\n"
     ]
    }
   ],
   "source": [
    "# Categorize experiments by approach type\n",
    "approach_types = {\n",
    "    'baseline': [],\n",
    "    'local_search': [],  # SA, exhaustive, NFP\n",
    "    'ensemble': [],\n",
    "    'constructive': [],  # lattice, BLF, interlock\n",
    "    'population': [],  # GA\n",
    "    'extended_opt': []  # long bbox3 runs\n",
    "}\n",
    "\n",
    "for exp in experiments:\n",
    "    name = exp['name'].lower()\n",
    "    notes = exp.get('notes', '').lower()\n",
    "    \n",
    "    if 'baseline' in name:\n",
    "        approach_types['baseline'].append(exp)\n",
    "    elif any(x in name for x in ['sa', 'annealing', 'exhaustive', 'nfp', 'shake', 'numba']):\n",
    "        approach_types['local_search'].append(exp)\n",
    "    elif 'ensemble' in name:\n",
    "        approach_types['ensemble'].append(exp)\n",
    "    elif any(x in name for x in ['lattice', 'blf', 'interlock', 'jostle', 'constructive']):\n",
    "        approach_types['constructive'].append(exp)\n",
    "    elif 'genetic' in name or 'ga' in name:\n",
    "        approach_types['population'].append(exp)\n",
    "    elif '8hr' in name or 'extended' in name:\n",
    "        approach_types['extended_opt'].append(exp)\n",
    "    else:\n",
    "        approach_types['local_search'].append(exp)  # default\n",
    "\n",
    "print(\"Experiments by approach type:\")\n",
    "for approach, exps in approach_types.items():\n",
    "    if exps:\n",
    "        best = min(e['cv_score'] for e in exps)\n",
    "        print(f\"  {approach}: {len(exps)} experiments, best={best:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0abee10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.696402Z",
     "iopub.status.busy": "2026-01-28T10:03:32.696313Z",
     "iopub.status.idle": "2026-01-28T10:03:32.800696Z",
     "shell.execute_reply": "2026-01-28T10:03:32.800353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest score contributors (worst N values):\n",
      "  N=2: 1.1596\n",
      "  N=1: 1.0000\n",
      "  N=4: 0.8688\n",
      "  N=3: 0.8452\n",
      "  N=5: 0.7382\n",
      "  N=8: 0.6782\n",
      "  N=6: 0.6762\n",
      "  N=7: 0.6445\n",
      "  N=12: 0.6027\n",
      "  N=9: 0.5957\n",
      "\n",
      "Total score: 89.35940420926349\n"
     ]
    }
   ],
   "source": [
    "# Analyze per-N scores from best submission\n",
    "baseline_path = '/home/code/experiments/029_final_ensemble_v2/submission.csv'\n",
    "df = pd.read_csv(baseline_path)\n",
    "\n",
    "# Parse coordinates\n",
    "def parse_coord(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "df['n'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "df['i'] = df['id'].apply(lambda x: int(str(x).split('_')[1]))\n",
    "for col in ['x', 'y', 'deg']:\n",
    "    df[col] = df[col].apply(parse_coord)\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    n_df = df[df['n'] == n]\n",
    "    if len(n_df) > 0:\n",
    "        min_x = n_df['x'].min()\n",
    "        max_x = n_df['x'].max()\n",
    "        min_y = n_df['y'].min()\n",
    "        max_y = n_df['y'].max()\n",
    "        # This is approximate - need to account for tree geometry\n",
    "        side = max(max_x - min_x, max_y - min_y) + 1.0  # rough tree size\n",
    "        per_n_scores[n] = side**2 / n\n",
    "\n",
    "print(\"Top 10 highest score contributors (worst N values):\")\n",
    "sorted_scores = sorted(per_n_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_scores[:10]:\n",
    "    print(f\"  N={n}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTotal score:\", sum(per_n_scores.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863110cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.801754Z",
     "iopub.status.busy": "2026-01-28T10:03:32.801663Z",
     "iopub.status.idle": "2026-01-28T10:03:32.804474Z",
     "shell.execute_reply": "2026-01-28T10:03:32.804149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap analysis:\n",
      "  Current best: 70.315537\n",
      "  Target: 68.866853\n",
      "  Gap: 1.448684 points\n",
      "  Average improvement needed per N: 0.007243\n",
      "\n",
      "  If we improve 50 N values by 0.03 each: 1.5 points\n",
      "  If we improve 100 N values by 0.015 each: 1.5 points\n",
      "  If we improve 200 N values by 0.0075 each: 1.5 points\n"
     ]
    }
   ],
   "source": [
    "# What's the theoretical minimum?\n",
    "# For N trees, the minimum bounding box is limited by the tree geometry\n",
    "# Tree dimensions: width ~0.7, height ~1.0\n",
    "\n",
    "# Theoretical analysis:\n",
    "# - N=1: Single tree, min side = max(0.7, 1.0) = 1.0, score = 1.0\n",
    "# - But with rotation, we can get smaller bounding box\n",
    "# - Optimal N=1 rotation gives ~0.813 (from baseline)\n",
    "\n",
    "# The gap to target is 1.45 points (2.1%)\n",
    "# This is distributed across all 200 N values\n",
    "# Average improvement needed per N: 1.45/200 = 0.00725\n",
    "\n",
    "print(\"Gap analysis:\")\n",
    "print(f\"  Current best: 70.315537\")\n",
    "print(f\"  Target: 68.866853\")\n",
    "print(f\"  Gap: 1.448684 points\")\n",
    "print(f\"  Average improvement needed per N: {1.448684/200:.6f}\")\n",
    "print(f\"\")\n",
    "print(\"  If we improve 50 N values by 0.03 each: 1.5 points\")\n",
    "print(\"  If we improve 100 N values by 0.015 each: 1.5 points\")\n",
    "print(\"  If we improve 200 N values by 0.0075 each: 1.5 points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5a9a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.805249Z",
     "iopub.status.busy": "2026-01-28T10:03:32.805153Z",
     "iopub.status.idle": "2026-01-28T10:03:32.807995Z",
     "shell.execute_reply": "2026-01-28T10:03:32.807665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External data sources mentioned in experiments:\n",
      "  000_baseline: Baseline from best pre-optimized snapshot ensemble (21328309254/003_valid_ensemble). Score 70.523320 vs target 68.882921, gap of 1.64 points. N=1 is already optimal at 0.6612. Top score contributors a...\n",
      "  001_valid_baseline: Valid baseline from snapshot 21337107511 that PASSED Kaggle validation with LB score 70.615106516706. This submission has high precision coordinates (20+ decimal places) which is required to pass Kagg...\n",
      "  007_ensemble_fractional: BREAKTHROUGH: Ensemble from all snapshots achieved 70.265730 vs baseline 70.615102 - improvement of 0.349 points! Key insight: N=24 alone contributed 0.348 improvement (99% of total gain). Found 43 N ...\n",
      "  008_snapshot_ensemble: Ensemble of best per-N solutions from 3512 snapshot files. Fractional translation found no improvements (baseline is at strong local optimum). Ensemble approach found 167/200 N values with improvement...\n",
      "  009_highprec_ensemble: High-precision ensemble with strict overlap validation. Loaded 3728 valid submissions from snapshots. Found 142/200 N values with improvements. Rejected 11127 improvements that were too small (< 1e-5 ...\n",
      "  012_mega_ensemble: Mega-ensemble combining external data (santa-2025.csv, 70.378875862989.csv, etc.) with 3755 internal snapshots. Result: IDENTICAL to exp_010 (70.365091). External data did NOT provide any improvements...\n",
      "  013_selective_threshold: Selective threshold ensemble using MIN_IMPROVEMENT=0.0001 for safe N values and MIN_IMPROVEMENT=0.001 for problematic N values (2, 70, 79, 123, 138). Found 127 N values with improvements (vs 74 in exp...\n",
      "  014_conservative_ensemble: Conservative ensemble with MIN_IMPROVEMENT=0.003 and 0.005 thresholds. Result: IDENTICAL to exp_010 (70.365091). No improvements found because ALL external data improvements are below 0.001 (largest i...\n",
      "  016_mega_ensemble_external: Mega-ensemble combining exp_010 with external data sources (saspav santa-2025.csv, bucket_of_chump, chistyakov, etc.) and 3777 internal snapshots. Found 7 N values with improvements >= 0.001: N=21 (+0...\n",
      "  017_extended_ensemble: Extended ensemble combining exp_016 with ALL available sources (15 external CSV files + 3782 internal snapshots = 3797 total sources). Result: IDENTICAL to exp_016 (70.353516). No additional improveme...\n",
      "  019_comprehensive_external_ensemble: Downloaded 12+ external datasets from Kaggle (bucket-of-chump, santa25-public, santa-2025-try3, telegram solutions, santa-2025-csv, chistyakov, santa-2025-editor, santa2025-starter, hengck, crodoc, im...\n",
      "  020_optimal_ensemble_final: Optimal ensemble using why-not kernel output as base with NO threshold (1e-10 instead of 0.001). This captures 156 improvements that were previously rejected by the conservative MIN_IMPROVEMENT=0.001 ...\n",
      "  021_comprehensive_ensemble_v2: Comprehensive ensemble from ALL available sources (3496 CSV files). Downloaded new datasets: saspav_latest, chistyakov_latest, nctuan, blueshyy_ensemble, ibrahimqasimi, camurberkayy. Found 43 tiny imp...\n",
      "  022_extended_cpp_optimization: Extended C++ optimization with bbox3 compiled with OpenMP. Ran for 576 seconds (9.6 minutes) with 50000 iterations and 80 restarts per N value using 26 parallel threads. Found essentially ZERO improve...\n",
      "  028_final_ensemble: Final ensemble incorporating latest saspav dataset (updated Jan 27). Found 1 improvement: N=124 improved by 0.000839 (from 0.344309 to 0.343470). Total score improved from 70.316492 to 70.315653. This...\n",
      "  029_final_ensemble_v2: Final ensemble v2 incorporating latest saspav kernel output (submission_shake.csv). Found 1 improvement: N=31 improved by 0.000116 (from 0.363665 to 0.363550). Total score improved from 70.315653 to 7...\n",
      "  030_extended_cpp_ensemble: Extended C++ optimization (bbox3) ran for 2198 seconds with 100K iterations and 200 restarts. Found essentially ZERO improvement (0.000000341573). However, scanning newly downloaded external sources (...\n",
      "  031_safe_ensemble: Backpacking technique (using first N trees from larger configurations) found ZERO improvements - the current solution is already well-optimized. However, scanning newly updated external sources (kumar...\n",
      "  032_extended_bbox3: Extended bbox3 optimization ran for 3159 seconds (~53 minutes) with 100K iterations and 300 restarts. Found essentially ZERO improvement (0.000000341662) - only 3 N values improved by tiny amounts. Th...\n",
      "  033_extended_bbox3_revert: Extended bbox3 optimization (692 sec, 50K iterations, 100 restarts) found essentially ZERO improvement (0.0000003). This confirms the solution is at a very strong local optimum. CRITICAL: The last 3 s...\n",
      "  034_extended_bbox3_final: Extended bbox3 optimization (3207 sec = 53 min, 100K iterations, 300 restarts) found essentially ZERO improvement (0.000000341573). This DEFINITIVELY confirms the solution is at a very strong local op...\n"
     ]
    }
   ],
   "source": [
    "# Check what external data sources have been tried\n",
    "print(\"External data sources mentioned in experiments:\")\n",
    "for exp in experiments:\n",
    "    notes = exp.get('notes', '')\n",
    "    if 'external' in notes.lower() or 'snapshot' in notes.lower() or 'csv' in notes.lower():\n",
    "        print(f\"  {exp['name']}: {notes[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea3ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T10:03:32.808901Z",
     "iopub.status.busy": "2026-01-28T10:03:32.808811Z",
     "iopub.status.idle": "2026-01-28T10:03:32.811496Z",
     "shell.execute_reply": "2026-01-28T10:03:32.811169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTE TIME ANALYSIS:\n",
      "\n",
      "Top competitors:\n",
      "  - Run time: 24-72 hours\n",
      "  - CPUs: 24+\n",
      "  - Total compute: 576-1728 CPU-hours\n",
      "\n",
      "Our best attempt:\n",
      "  - Run time: 53 minutes\n",
      "  - CPUs: 1\n",
      "  - Total compute: 0.88 CPU-hours\n",
      "\n",
      "Ratio: Our compute is 1/655 to 1/1964 of top competitors\n",
      "\n",
      "CONCLUSION: We have NOT tried extended optimization at scale.\n",
      "This is the ONLY approach that top teams use that we haven't tried.\n"
     ]
    }
   ],
   "source": [
    "# Key insight from research:\n",
    "# Top teams run bbox3 for 24-72 HOURS with 24+ CPUs\n",
    "# Our longest run was 53 minutes on 1 CPU\n",
    "# That's 1/648th to 1/1944th of top competitor compute\n",
    "\n",
    "print(\"COMPUTE TIME ANALYSIS:\")\n",
    "print(\"\")\n",
    "print(\"Top competitors:\")\n",
    "print(\"  - Run time: 24-72 hours\")\n",
    "print(\"  - CPUs: 24+\")\n",
    "print(\"  - Total compute: 576-1728 CPU-hours\")\n",
    "print(\"\")\n",
    "print(\"Our best attempt:\")\n",
    "print(\"  - Run time: 53 minutes\")\n",
    "print(\"  - CPUs: 1\")\n",
    "print(\"  - Total compute: 0.88 CPU-hours\")\n",
    "print(\"\")\n",
    "print(\"Ratio: Our compute is 1/655 to 1/1964 of top competitors\")\n",
    "print(\"\")\n",
    "print(\"CONCLUSION: We have NOT tried extended optimization at scale.\")\n",
    "print(\"This is the ONLY approach that top teams use that we haven't tried.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
