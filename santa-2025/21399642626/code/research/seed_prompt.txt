## Current Status
- Best CV score: 70.307017 from exp_043 (subset_extraction)
- Best LB score: 70.307017 (CONFIRMED - CV-LB gap is ZERO)
- Target: 68.861114 | Gap to target: 1.446 points (2.05%)

## CRITICAL BREAKTHROUGH: SUBSET EXTRACTION WORKS!

exp_043 found the **FIRST algorithmic improvements in 10+ experiments**:
- N=121: improved by 0.000766 (from N=122 with tree 8 removed)
- N=122: improved by 0.000846 (from N=123 with tree 23 removed)
- Total: 0.001612 points improvement

**This proves the baseline is NOT globally optimal for all N values!**

## Response to Evaluator

The evaluator correctly identified that subset extraction is a breakthrough:
> "This is the first algorithmic improvement in 10+ experiments!"

I agree with expanding this approach. The evaluator recommends:
1. N+2 → N extraction (remove 2 trees)
2. N+3 → N extraction (remove 3 trees)
3. Cross-N extraction
4. Recursive extraction

**I will implement N+k extraction for k=2,3,4,5 as the next experiment.**

## Submission Log
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 039 | per_n_analysis | 70.3086 | 70.3086 | External data mining |
| 040 | extended_mining | 70.3086 | ERROR | Overlapping trees |
| 041 | constructive | 70.3086 | - | FALLBACK - approach failed |
| 042 | row_based | 70.3086 | - | FALLBACK - approach failed |
| 043 | subset_extraction | 70.3070 | 70.3070 | ✅ IMPROVEMENT! |

## What We've Learned
1. **Local search methods (SA, bbox3, shake) find ZERO improvement** - baseline is at strong local optimum
2. **Constructive approaches produce WORSE results** - fall back to baseline
3. **Subset extraction WORKS** - found 2 improvements where everything else failed
4. **CV-LB gap is ZERO** - our validation is perfectly calibrated

## Next Experiment: EXPANDED SUBSET EXTRACTION

### MANDATORY: Implement N+k → N extraction for k=2,3,4,5

```python
# For each target N from 1 to 198:
#   For k from 2 to min(5, 200-N):
#     Get source solution from N+k
#     Try all combinations of removing k trees
#     For k=2: C(N+2, 2) combinations
#     For k=3: C(N+3, 3) combinations (may be expensive for large N)
#     Keep best valid improvement

from itertools import combinations

def extract_n_from_n_plus_k(source_trees, target_n, k):
    """Extract target_n trees from source_trees by removing k trees."""
    best_score = float('inf')
    best_subset = None
    
    for remove_indices in combinations(range(len(source_trees)), k):
        subset = [t for i, t in enumerate(source_trees) if i not in remove_indices]
        if len(subset) != target_n:
            continue
        
        score = compute_score(subset, target_n)
        if score < best_score:
            if not check_overlap(subset):
                best_score = score
                best_subset = subset
    
    return best_subset, best_score
```

### Expected Improvements
- k=1 found 2 improvements (N=121, N=122)
- k=2 might find more improvements (different tree removal patterns)
- k=3,4,5 explore even more diverse configurations

### Computational Considerations
- k=2: C(N+2, 2) ≈ N²/2 combinations per N
- k=3: C(N+3, 3) ≈ N³/6 combinations per N (expensive for large N)
- Start with k=2 for all N, then k=3 for N≤50

## ⛔ FORBIDDEN (DO NOT DO)
- bbox3, sa_fast, eazy_optimizer - ZERO improvement, waste of time
- subprocess.run() or os.system() - NO BINARIES
- "More iterations" on same optimizer - DOESN'T WORK
- Constructive approaches - WORSE than baseline

## ✅ REQUIRED
1. Implement N+k extraction for k=2,3,4,5
2. Track improvements per N value
3. Validate no overlaps before accepting
4. Create ensemble with all improvements
5. SUBMIT to get LB feedback

## What NOT to Try
- SA/bbox3/shake - 10+ experiments showed ZERO improvement
- Random initialization - Cannot even generate valid configs for N≥20
- Constructive heuristics - Produce WORSE results than baseline
- "Optimizing" existing solutions - Baseline is at strong local optimum

## The Math
To reach target (68.861), we need 1.446 points improvement:
- If subset extraction finds 0.01 improvement per N: need 145 N values
- If subset extraction finds 0.001 improvement per N: need 1446 N values

**We need LARGER improvements per N, not just more tiny improvements.**

The k=2,3,4,5 extraction explores fundamentally different configurations that k=1 cannot reach.
