{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004592b5",
   "metadata": {},
   "source": [
    "# Loop 3 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- exp_003 (eazy_optimizer): CV 70.6761 | LB 70.6761 (gap: 0.0000)\n",
    "\n",
    "## Key Observations\n",
    "1. CV = LB exactly (as expected for optimization problem)\n",
    "2. Improvement from baseline: 0.000043 (tiny!)\n",
    "3. Gap to target: 1.78 points (2.59%)\n",
    "\n",
    "## Evaluator's Key Insights\n",
    "1. Local optimization is STUCK - 3 experiments with essentially no improvement\n",
    "2. Need to extract lattice parameters from baseline\n",
    "3. Need to implement proper tessellation for large N\n",
    "4. Need to ensemble from external sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "import json\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "# Tree shape\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x).replace('s', ''))\n",
    "        self.center_y = Decimal(str(center_y).replace('s', ''))\n",
    "        self.angle = Decimal(str(angle).replace('s', ''))\n",
    "        \n",
    "        initial_polygon = Polygon(list(zip(TX, TY)))\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated, \n",
    "            xoff=float(self.center_x), yoff=float(self.center_y))\n",
    "\n",
    "def load_submission(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    configs = {}\n",
    "    for _, row in df.iterrows():\n",
    "        id_parts = row['id'].split('_')\n",
    "        n = int(id_parts[0])\n",
    "        x = str(row['x']).replace('s', '')\n",
    "        y = str(row['y']).replace('s', '')\n",
    "        deg = str(row['deg']).replace('s', '')\n",
    "        if n not in configs:\n",
    "            configs[n] = []\n",
    "        configs[n].append({'x': float(x), 'y': float(y), 'deg': float(deg)})\n",
    "    return configs\n",
    "\n",
    "print('Loading baseline...')\n",
    "baseline = load_submission('/home/code/preoptimized/santa-2025.csv')\n",
    "print(f'Loaded {len(baseline)} N values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze lattice patterns in large N configurations\n",
    "# The jazivxt kernel mentions 'blue' (upward) and 'pink' (downward) trees\n",
    "# with specific (dx, dy) offsets\n",
    "\n",
    "def analyze_lattice_pattern(configs, n):\n",
    "    \"\"\"Analyze the lattice pattern for a given N configuration.\"\"\"\n",
    "    trees = configs[n]\n",
    "    \n",
    "    # Group trees by angle (roughly)\n",
    "    angles = [t['deg'] % 360 for t in trees]\n",
    "    \n",
    "    # Find the two main angle groups (blue and pink)\n",
    "    angle_hist = {}\n",
    "    for a in angles:\n",
    "        rounded = round(a / 10) * 10  # Round to nearest 10 degrees\n",
    "        angle_hist[rounded] = angle_hist.get(rounded, 0) + 1\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_angles = sorted(angle_hist.items(), key=lambda x: -x[1])\n",
    "    \n",
    "    print(f'\\nN={n}: {len(trees)} trees')\n",
    "    print(f'Top angle groups: {sorted_angles[:5]}')\n",
    "    \n",
    "    # Find dx, dy offsets between adjacent trees\n",
    "    positions = [(t['x'], t['y']) for t in trees]\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    diffs = []\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(i+1, len(positions)):\n",
    "            dx = positions[j][0] - positions[i][0]\n",
    "            dy = positions[j][1] - positions[i][1]\n",
    "            dist = (dx**2 + dy**2)**0.5\n",
    "            if dist < 1.0:  # Only nearby trees\n",
    "                diffs.append((dx, dy, dist))\n",
    "    \n",
    "    if diffs:\n",
    "        # Find most common dx, dy\n",
    "        dx_values = [d[0] for d in diffs]\n",
    "        dy_values = [d[1] for d in diffs]\n",
    "        print(f'Typical dx range: [{min(dx_values):.4f}, {max(dx_values):.4f}]')\n",
    "        print(f'Typical dy range: [{min(dy_values):.4f}, {max(dy_values):.4f}]')\n",
    "    \n",
    "    return sorted_angles, diffs\n",
    "\n",
    "# Analyze several large N values\n",
    "for n in [100, 144, 169, 196, 200]:\n",
    "    if n in baseline:\n",
    "        analyze_lattice_pattern(baseline, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-N scores and identify worst performers\n",
    "def get_side_length(configs, n):\n",
    "    trees = [ChristmasTree(t['x'], t['y'], t['deg']) for t in configs[n]]\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "def get_score(side, n):\n",
    "    return side**2 / n\n",
    "\n",
    "# Calculate theoretical minimum (perfect packing)\n",
    "tree_area = 0.245625  # Area of one tree\n",
    "\n",
    "print('Per-N Analysis:')\n",
    "print('='*60)\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    side = get_side_length(baseline, n)\n",
    "    score = get_score(side, n)\n",
    "    actual_area = side**2\n",
    "    theoretical_min_area = n * tree_area\n",
    "    efficiency = theoretical_min_area / actual_area * 100\n",
    "    scores.append({'n': n, 'side': side, 'score': score, 'efficiency': efficiency})\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "print(f'Total score: {df_scores[\"score\"].sum():.6f}')\n",
    "print(f'Target: 68.892266')\n",
    "print(f'Gap: {df_scores[\"score\"].sum() - 68.892266:.6f}')\n",
    "\n",
    "# Find worst efficiency N values\n",
    "worst = df_scores.nsmallest(20, 'efficiency')\n",
    "print('\\nWorst efficiency N values:')\n",
    "print(worst[['n', 'side', 'score', 'efficiency']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2490811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Score by N\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(df_scores['n'], df_scores['score'], alpha=0.7)\n",
    "ax1.set_xlabel('N')\n",
    "ax1.set_ylabel('Score (sideÂ²/N)')\n",
    "ax1.set_title('Score Contribution by N')\n",
    "\n",
    "# Efficiency by N\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(df_scores['n'], df_scores['efficiency'], alpha=0.7, s=10)\n",
    "ax2.set_xlabel('N')\n",
    "ax2.set_ylabel('Packing Efficiency (%)')\n",
    "ax2.set_title('Packing Efficiency by N')\n",
    "ax2.axhline(y=70, color='r', linestyle='--', label='70% efficiency')\n",
    "ax2.legend()\n",
    "\n",
    "# Cumulative score\n",
    "ax3 = axes[1, 0]\n",
    "df_scores['cumsum'] = df_scores['score'].cumsum()\n",
    "ax3.plot(df_scores['n'], df_scores['cumsum'])\n",
    "ax3.set_xlabel('N')\n",
    "ax3.set_ylabel('Cumulative Score')\n",
    "ax3.set_title('Cumulative Score')\n",
    "ax3.axhline(y=68.892266, color='r', linestyle='--', label='Target')\n",
    "ax3.legend()\n",
    "\n",
    "# Score vs theoretical minimum\n",
    "ax4 = axes[1, 1]\n",
    "theoretical_min = [tree_area * n / n for n in range(1, 201)]  # = tree_area always\n",
    "ax4.scatter(df_scores['n'], df_scores['score'], alpha=0.7, s=10, label='Actual')\n",
    "ax4.axhline(y=tree_area, color='r', linestyle='--', label='Theoretical min (tree_area)')\n",
    "ax4.set_xlabel('N')\n",
    "ax4.set_ylabel('Score')\n",
    "ax4.set_title('Score vs Theoretical Minimum')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/score_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print('\\nScore breakdown by N range:')\n",
    "for start, end in [(1, 10), (11, 50), (51, 100), (101, 150), (151, 200)]:\n",
    "    subset = df_scores[(df_scores['n'] >= start) & (df_scores['n'] <= end)]\n",
    "    print(f'N={start}-{end}: {subset[\"score\"].sum():.4f} ({subset[\"score\"].sum()/df_scores[\"score\"].sum()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what external CSVs are available and their scores\n",
    "import os\n",
    "\n",
    "external_dirs = [\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump/',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/telegram/',\n",
    "]\n",
    "\n",
    "print('External CSV files available:')\n",
    "for dir_path in external_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        print(f'\\n{dir_path}:')\n",
    "        for f in os.listdir(dir_path):\n",
    "            if f.endswith('.csv'):\n",
    "                full_path = os.path.join(dir_path, f)\n",
    "                try:\n",
    "                    configs = load_submission(full_path)\n",
    "                    total_score = sum(get_score(get_side_length(configs, n), n) for n in configs.keys())\n",
    "                    print(f'  {f}: {total_score:.6f}')\n",
    "                except Exception as e:\n",
    "                    print(f'  {f}: ERROR - {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faba5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: We need to find which N values have the most room for improvement\n",
    "# Compare our baseline to theoretical minimum\n",
    "\n",
    "print('\\nN values with most room for improvement (score - theoretical_min):')\n",
    "df_scores['theoretical_min'] = tree_area  # Perfect packing would give tree_area for all N\n",
    "df_scores['improvement_potential'] = df_scores['score'] - df_scores['theoretical_min']\n",
    "df_scores['improvement_pct'] = (df_scores['score'] - df_scores['theoretical_min']) / df_scores['score'] * 100\n",
    "\n",
    "# Sort by improvement potential\n",
    "top_potential = df_scores.nlargest(20, 'improvement_potential')\n",
    "print(top_potential[['n', 'score', 'theoretical_min', 'improvement_potential', 'improvement_pct']].to_string())\n",
    "\n",
    "print(f'\\nTotal improvement potential: {df_scores[\"improvement_potential\"].sum():.4f}')\n",
    "print(f'We need to capture: {(df_scores[\"score\"].sum() - 68.892266) / df_scores[\"improvement_potential\"].sum() * 100:.1f}% of this potential')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985807a",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **Local optimization is stuck**: 3 experiments with essentially no improvement (0.000043 total)\n",
    "2. **Gap to target**: 1.78 points (2.59%)\n",
    "3. **Worst efficiency N values**: N=1 (37.1%), N=2 (54.5%), N=3 (56.5%)\n",
    "4. **Large N contributes most**: N=51-200 contributes 73% of total score\n",
    "\n",
    "## Next Steps (from Evaluator)\n",
    "\n",
    "1. **Extract lattice parameters** from baseline using `generate_geometry_report()`\n",
    "2. **Implement proper tessellation** for large N (N >= 50)\n",
    "3. **Ensemble from external sources** for small N\n",
    "4. **Focus on high-leverage N values**: N=51-200 where small improvements have big impact\n",
    "\n",
    "## Strategy Change Required\n",
    "\n",
    "STOP running local optimizers. They cannot close a 2.59% gap.\n",
    "\n",
    "Need FUNDAMENTALLY different approach:\n",
    "- Different algorithm family (not SA variations)\n",
    "- Different representation (tessellation patterns)\n",
    "- Constructive approach (build from scratch)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
