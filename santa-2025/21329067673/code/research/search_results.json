{
  "query": "How do top Kaggle competitors solve 2D polygon packing optimization problems when stuck at local optimum?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Top Kaggle competitors addressing 2D polygon packing optimization problems when stuck at a local optimum typically employ heuristic and metaheuristic approaches, such as local search, evolutionary algorithms, simulated annealing, and hybrid methods. According to recent research, these strategies involve obtaining initial solutions through greedy algorithms or integer programming and then improving them via local search techniques to escape local optima ([Luo et al., 2024](https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.86/LIPIcs.SoCG.2024.86.pdf); [Guilherme da Fonseca et al., 2024](https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.84/LIPIcs.SoCG.2024.84.pdf)). \n\nSpecifically, they often incorporate iterative improvement methods such as local search, which moves vertices or polygons to reduce overlaps and increase packing efficiency, or employ evolutionary algorithms that adaptively explore the solution space with mutation and crossover operations ([Hopper, 2007](https://www.sciencedirect.com/science/article/abs/pii/S0377221706003018); [Jakobs, 2003](http://www.cs.nott.ac.uk/~pszgxk/aim/2008/reading/ga_representation_2.pdf)). When progress stalls at a local optimum, these competitors may use techniques like simulated annealing, which probabilistically accepts worse solutions to escape local minima, or hybridize methods combining deterministic and stochastic strategies to enhance exploration ([Martins & Tsuzuki, 2005](https://abcm.org.br/symposium-series/SSM_Vol2/Section_XII_Emerging_Technologies_and_AI_Applications/SSM2_XII_02.pdf)). \n\nOverall, the common approach involves a combination of initial heuristics, local search improvements, and metaheuristic techniques to effectively navigate and escape local optima in complex polygon packing problems.",
      "url": ""
    },
    {
      "title": "A General Heuristic Approach for Maximum Polygon Packing",
      "text": "A General Heuristic Approach for Maximum\nPolygon Packing\nCanhui Luo #\nHuazhong University of Science and Technology, Wuhan, China\nZhouxing Su1 #\nHuazhong University of Science and Technology, Wuhan, China\nZhipeng L\u00fc #\nHuazhong University of Science and Technology, Wuhan, China\nAbstract\nThis work proposes a general heuristic packing approach to address the Maximum Polygon Packing\nProblem introduced by the CG:SHOP 2024 Challenge. Our solver primarily consists of two steps:\n(1) Partitioning the container and polygons to form a series of small-scale subproblems; (2) For each\nsubproblem, sequentially placing polygons into the container and attempting to eliminate overlaps.\n2012 ACM Subject Classification Theory of computation \u2192 Computational geometry; Computing\nmethodologies \u2192 Search methodologies\nKeywords and phrases packing, polygon, heuristic, differential evolution, local search, tabu search\nDigital Object Identifier 10.4230/LIPIcs.SoCG.2024.86\nCategory CG Challenge\nFunding This work was supported in part by the National Natural Science Foundation of China\n(NSFC) under Grant 72101094 and the Special Project for Knowledge Innovation of Hubei Province\nunder Grant 2022013301015175.\nAcknowledgements We want to thank the organizers of CG:SHOP 2024 and all other participants\nfor creating such an engaging challenge. We also want to thank Dominik Krupke for providing a\nhelpful official validator for solutions.\n1 Introduction\nThe recent CG:SHOP 2024 Challenge introduced a variant of irregular packing problems\nknown as the Maximum Polygon Packing (MPP) problem. The MPP problem involves a\nconvex polygonal container C and a polygon set P = {p1, p2, ..., pN }, where polygon piis\nassociated with a value vi. It seeks for a non-overlapping packing with the maximum total\nvalue. The challenge presents a total of 180 instances whose number of polygons ranges from\n28 to 50,000. The official document [4] gives a detailed description of the challenge.\nOur proposed algorithm employs a general process to solve these instances indiscriminately,\nand the overall framework is presented in Figure 1. We first partition a large-scale problem\ninto multiple small-scale subproblems (Section 2) and then solve each subproblem using\nupper-level polygon ordering (Section 3.1) and lower-level packing optimization techniques\n(Section 3.2). Section 4 presents our experimental results, followed by conclusions.\n1 Corresponding author: Zhouxing Su\n\u00a9 Canhui Luo, Zhouxing Su, and Zhipeng L\u00fc;\nlicensed under Creative Commons License CC-BY 4.0\n40th International Symposium on Computational Geometry (SoCG 2024).\nEditors: Wolfgang Mulzer and Jeff M. Phillips; Article No. 86; pp. 86:1\u201386:9\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\n86:2 A General Heuristic Approach for Maximum Polygon Packing\nInput polygon set P and container C\nUpper-level polygon ordering\nLower-level packing optimization\nFinished?\n \nPacking\nAssemble and return the complete solution\nMPP1 MPP2 MPPm\n( ) 0? Overlap Scurr== ( ) Update Sbest best\nReturn S\nPartitioning\nYes\nNo\nYes\nNo\nSelect next one\nFigure 1 The framework of our proposed algorithm.\n2 Partitioning\nIn this section, we present the decomposition of the original large-scale problem into a series\nof smaller MPP subproblems. It involves two components: partitioning the container C into\nmultiple regions and assigning polygons to each region.\n2.1 Container Partitioning\nThe container partitioning process consists of two steps, as shown in Figure 2. Initially, we\narrange two-dimensional square grids starting from the bottom-left corner of the bounding\nbox until the entire container is covered. The subregions formed by the intersection of the\ncontainer with all the grids constitute its partition C = C1 \u222a C2 \u222a ... \u222a Cm. Subsequently,\nwe merge the small subregions with adjacent grids, which are difficult to be used effectively.\nThe grid is dimensioned to keep the scale of each subproblem at approximately 300 polygons,\nmaking a trade-off between effectiveness and efficiency of lower-level packing optimization.\n2.2 Polygon Assignment\nWe adopt a simple approach of randomly assigning polygons to each subregion. Specifically, for\neach subregion Ci, we randomly select a polygon pj from P until\nP\nj\narea(pj )\narea(Ci) \u2265\nPN\ni=0\narea(pi)\narea(C)\n.\nThe advantage of random assignment lies in ensuring that the overall characteristics of each\nsubproblem align with the original problem.\nC. Luo, Z. Su, and Z. L\u00fc 86:3\nFigure 2 The partitioning process for the instance jigsaw_cf1_4fd4c46e. Step 1 (left): Cover the\ncontainer with squares; Step 2: Intersect and merge small regions (from the middle to the right).\nminimum translation\nminimum translation\nIFP\nContainer\nFigure 3 Examples of NFP between two polygons and IFP between container and polygon.\n3 Packing\n3.1 Upper-Level Polygon Ordering\nWe define a priority for each polygon. We repeatedly select one remaining polygon with the\nhighest priority (ties are broken by value) and try to insert it into the current solution. If the\ninsertion with lower-level packing optimization fails, we skip the current polygon and turn to\nthe next one. For the majority of instances, the priority is defined as the value-to-area ratio\nof a polygon (we also call it unit value). Polygons with higher unit values are prioritized\nfor putting in the container, which is called the Unit Value First (UVF) strategy. For\nsmall-scale instances (N < 100), we employ the \u03b1\u03b2-random strategy. It randomly selects\n\u03b1% and \u03b2% of the polygons and reassigns their UVF-based priority to the highest and the\nlowest, respectively. These instances are run for multiple times to ensure comprehensive\noptimization, with \u03b1 and \u03b2 set to 10 in our implementation.\n3.2 Lower-Level Packing Optimization\nThe position of a polygon can be represented by the coordinates l = (x, y) of a reference point,\nsuch as the bottom-left corner of the boundary. Then, the translation of a polygon can be\nrepresented by a vector pointing from its original position to its new position. Given a feasible\npacking S and a polygon p to be placed, it is impossible to find a non-overlapping position\nfor p without moving other polygons in most cases. This section introduces the algorithm for\neliminating overlaps for an invalid packing, which involves solving an unconstrained nonlinear\nproblem and heuristic polygon movement.\nS o C G 2 0 2 4\n86:4 A General Heuristic Approach for Maximum Polygon Packing\n3.2.1 Overlap Minimization\nTo determine the appropriate translation for the polygons, we utilized the no-fit polygon\n(NFP) and inner-fit polygon (IFP), which are fundamental in algorithmic approaches to\ngeometric design and optimization challenges. For a fixed polygon pi and a movable polygon\npj , NFP(pi, pj ) describes their non-overlapping positions with boundaries in contact precisely,\nwhich can be utilized to determine the minimum translation for pj to avoid overlap. Similarly,\nIFP(pi, pj ) is employed to determine the minimum translation to place pj inside pi. Figure 3\nillustrates the polygon translations determined using NFP (left) and IFP (right). The readers\nmay refer to Burke et al. [2] for a more detailed description.\nFor a packing S, based on NFP and IFP, we define the overlap between polygons pi\nand pj as fij (S), representing the minimum translation to separate them, and f0i(S) as the\nminimum translation for moving pi to fit into the container. Subsequently, we employ the\nseparation algorithm proposed by Imamichi et al. [7] to minimize the overlap, which involves\nsolving an unconstrained nonlinear programming problem as follows:\nmin\nS\nF(S) = X\n0\u2264i<j\u2264N\nf\n2\nij (S) (1)\nThe model relaxes the non-overlapping constraint but introduces repulsion forces between\nany two overlapped polygons. We use the classic L-BFGS (limited memory BFGS) method\nto solve this problem. It makes the packing S converge to a local optimum but strongly\ndepends on the initial layout. ...",
      "url": "https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.86/LIPIcs.SoCG.2024.86.pdf"
    },
    {
      "title": "",
      "text": "Shadoks Approach to Knapsack Polygonal Packing\nGuilherme D. da Fonseca #\nLIS, Aix-Marseille Universit\u00e9, France\nYan Gerard #\nLIMOS, University Clermont Auvergne, Aubi\u00e8re, France\nAbstract\nWe describe the heuristics used by the Shadoks team in the CG:SHOP 2024 Challenge. Each instance\nconsists of a convex polygon called container and a multiset of items, where each item is a simple\npolygon and has an associated value. The goal is to pack some of the items inside the container\nusing translations, in order to maximize the sum of their values. Our strategy consists of obtaining\ngood initial solutions and improving them with local search. To obtain the initial solutions we used\ninteger programming and a carefully designed greedy approach.\n2012 ACM Subject Classification Theory of computation \u2192 Computational geometry\nKeywords and phrases Packing, polygons, heuristics, integer programming, computational geometry\nDigital Object Identifier 10.4230/LIPIcs.SoCG.2024.84\nCategory CG Challenge\nRelated Version Full Version: https://arxiv.org/abs/2403.20123\nSupplementary Material\nSoftware (Source Code): https://github.com/gfonsecabr/shadoks-CGSHOP2024\narchived at swh:1:dir:96fb9ad50c0c1307c7aef78560655cfcfabb24a6\nFunding Work supported by the French ANR PRC grant ADDS (ANR-19-CE48-0005).\nAcknowledgements We would like to thank the Challenge organizers and other competitors for their\ntime, feedback, and making this whole event possible. We would like to thank H\u00e9l\u00e8ne Toussaint,\nRapha\u00ebl Amato, Boris Lonjon, and William Guyot-L\u00e9nat from LIMOS, as well as the Qarma and\nTALEP teams and Manuel Bertrand from LIS, who continue to make the computational resources of\nthe LIMOS and LIS clusters available to our research. We would also like to thank Aldo Gonzalez\u0002Lorenzo and the undergraduate students Aymeric Beck, Houssam Boufarachan, Marine Izoulet, and\nCarla Scardigli for coding viewers for the solutions.\nFigure 1 Our best solutions to jigsaw_cf2_5db5d75a_34, random_rcf4_6e323d40_100,\natris1240, and satris1786 instances.\n\u00a9 Guilherme D. da Fonseca and Yan Gerard;\nlicensed under Creative Commons License CC-BY 4.0\n40th International Symposium on Computational Geometry (SoCG 2024).\nEditors: Wolfgang Mulzer and Jeff M. Phillips; Article No. 84; pp. 84:1\u201384:9\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\n84:2 Shadoks Approach to Knapsack Polygonal Packing\n1 Introduction\nCG:SHOP Challenge is an annual geometric optimization challenge. The sixth edition in\n2024 considers a 2-dimensional knapsack packing problem. The team Shadoks won first place\nwith the best solution (among the 14 participating teams) to 75 instances out of 180. In this\npaper, we describe the heuristics we used. We start by briefly describing the problem.\nAn input instance consists of a convex polygon called container and a multiset of items.\nEach item is a simple polygon with an associated integer value. The goal is to pack some of\nthe instance items inside the container using integer translations in order to maximize the\nsum of their values. In total, 180 instances have been given, ranging from 28 to 50,000 items.\nThe instances are of several different types according to the shape and values of the items.\nSome instances have mostly convex items, while other instances have many non-convex items\nsuch as polyominoes. In terms of item values, some items have only unit value, some have\nvalues proportional to the area, and other have random values, for example. Some solutions\nare presented in Figure 1 and more details about the challenge are available in the organizers\u2019\nsurvey paper [3].\nOur general strategy consists of finding a good initial solution (using integer programming\nor a greedy heuristic) and subsequently optimizing them with local search. Our strategy\nshares many common elements with the second place [5], but they did not use integer\nprogramming to obtain initial solutions and their optimization phase is more sophisticated\nthan ours. The third place [4] uses an hierarchical grid approach. The fourth place [1] used\na completely different integer programming model and a genetic algorithm.\nWe describe the algorithms in Section 2 and experimentally analyze their performance\nusing different parameters in Section 3. Our solvers were coded in Python and C++ and\nexecuted on several desktop laptop computers, as well as the LIMOS and LIS clusters.\n2 Algorithms\nWe used two different algorithms to compute initial solutions, a preprocessing phase that\ncan be executed beforehand, and a local search phase to improve the solutions.\n2.1 Integer Programming Approach\nA simple idea to solve the challenge problem is to produce a set V of random translations of\neach item inside the container and then reduce the problem to a kind of maximum weight\nindependent set problem in a graph G = (V, E). Each translated item is a vertex and there\nare two types of edges: (1) an edge between two translations that overlap and (2) translations\nof the same item i form a clique Ci. If all item have quantity one, then this is a traditional\nmaximum weight independent set problem. However, if items have non-unit quantities, then\neach clique Ciis associated with the quantity qi of item i and at most qi vertices of the\nclique are allowed in the solution.\nThis combinatorial problem can easily be modeled as integer programming with one\nbinary variable per vertex. A type-1 edge uv is modeled as u + v \u2264 1 and each clique Ci\nis modeled as P\nv\u2208Ci\nv \u2264 qi. The CPLEX solver [2] can optimally solve graphs with a few\nthousand vertices obtained from the challenge instances, which is not enough to obtain good\nsolutions using uniformly random placements.\nTo obtain better solutions, we start from a solutions S obtained with the aforementioned\nmethod and build a new graph G = (V, E) as follows. Let \u03c3 > 0 be a parameter and N be a\nset of the zero vector and random vectors where each random vector has x and y coordinates\nG. D. da Fonseca and Y. Gerard 84:3\nas Gaussian random variables of average 0 and standard deviation \u03c3. We create a translation\nin V for each item that is placed in S and for each translation vector in N if the translation\nis inside the container. We also create vertices in V using uniform random translations for\nall items. Edges and cliques are created as before, and the new combinatorial problem is\nsolved with CPLEX. We repeat this procedure multiple times using the previous solution S\nand reducing the value of \u03c3 at each step.\nThis method works well for instances with up to 200 items. To handle larger instances,\nwe partition the container using a square grid and partition the items equally among the\ncells. The partition is such that items are grouped by the slope of the longest edge, breaking\nties by the slope of the diameter. Each cell is then solved independently. The intuition to\ngroup items of similar slope together is that they can often be placed in a way that minimizes\nthe wasted space. Since the values of the items do not seem to be related to the slopes, this\napproach works well for the challenge instances.\n2.2 Greedy Heuristic\nThe greedy heuristic starts by creating an initial list L of n grid points inside the container\n(typically n = 1000). The list L is shuffled and we compute its centroid c rounded to integer\ncoordinates. The point c is inserted in the beginning of L. The input items are placed into a\nlist I ordered by decreasing utility, where the utility function is described next. Different\nutility functions may be used (more details in Section 3). The goal is that items of small\narea and high value have high utility while large items with small value have low utility.\nWe then build the packing by considering the items of the list I one by one in order. At\neach step, we have a current packing and a new item i to pack. We first try to pack i at\nthe first grid position g \u2208 L and at a number of random positions around g. If one of these\npositions is availa...",
      "url": "https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.84/LIPIcs.SoCG.2024.84.pdf"
    },
    {
      "title": "Applying self-adaptive evolutionary algorithms to two-dimensional packing problems using a four corners\u2019 heuristic",
      "text": "[Skip to main content](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-title)\n\n- [Access through\u00a0**your organization**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0377221706003018)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S0377221706003018/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-abstract)\n- [Introduction](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-introduction)\n- [Section snippets](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-snippets)\n- [References (16)](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-references)\n- [Cited by (13)](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-cited-by)\n\n## [European Journal of Operational Research](https://www.sciencedirect.com/journal/european-journal-of-operational-research)\n\n[Volume 183, Issue 3](https://www.sciencedirect.com/journal/european-journal-of-operational-research/vol/183/issue/3), 16 December 2007, Pages 1230-1248\n\n# Applying self-adaptive evolutionary algorithms to two-dimensional packing problems using a four corners\u2019 heuristic\n\nAuthor links open overlay panelKevin J.Binkley, [MasafumiHagiwara](https://www.sciencedirect.com/author/7201487333/masafurni-hagiwara)\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.ejor.2004.12.029](https://doi.org/10.1016/j.ejor.2004.12.029) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S0377221706003018&orderBeanReset=true)\n\n## Abstract\n\nThis paper proposes a four corners\u2019 heuristic for application in evolutionary algorithms (EAs) applied to two-dimensional packing problems. The four corners\u2019 (FC) heuristic is specifically designed to increase the search efficiency of EAs. Experiments with the FC heuristic are conducted on 31 problems from the literature both with rotations permitted and without rotations permitted, using two different EA algorithms: a self-adaptive parallel recombinative simulated annealing (PRSA) algorithm, and a self-adaptive genetic algorithm (GA). Results on bin packing problems yield the smallest trim losses we have seen in the published literature; with the FC heuristic, zero trim loss was achieved on problems of up to 97 rectangles. A comparison of the self-adaptive GA to fixed-parameter GAs is presented and the benefits of self-adaption are highlighted.\n\n## Introduction\n\nTwo-dimensional (2D) packing problems occur in a wide range of industries. The goal is simply the optimal utilization of space or material available. In the garment and paper industries the problem is often to cut smaller pieces from a large roll of cloth or paper while reducing the scrap. In the wood, glass, and metal industries the task is not to cut from a roll, but to cut from a fixed size sheet or plate. In the semiconductor industry the task is VLSI floor planning with the goal being to optimize the use of space on the chip.\n\nThere are two major variants of the 2D packing problem: bin packing and strip packing. In the 2D bin packing variant, rectangles are to be packed in bins of given width and height, the goal being to minimize the number of bins used. In the 2D strip packing variant, rectangles must be packed in a fixed width, infinite height strip, the goal being to minimize the height. The bin packing variant is most suitable for the wood, glass, metal, and semiconductor industries, while the strip packing variant will generally apply to the paper and garment industries.\n\nAn important consideration is whether or not the rectangles can be rotated as they are placed. In the wood and garment industries one may care about the grain of the material and rotations may not be permitted. While in the paper, glass, and semiconductor industries there may be no particular restrictions. Allowing rotations adds flexibility and can result in a better packing, while at the same time apparently complicating the task.\n\nGiven the many permutations of 2D packing problems, most research focuses on a particular type of the packing problem: either bin packing or strip packing, with or without rotations. A recent survey of 2D packing problems is given by Lodi et al. (2002). A typology of cutting and packing problems is defined in W\u00e4scher et al. (2006).\n\nBeing NP-hard, the 2D packing problems are an attractive challenge for evolutionary algorithms (EA). For application to strip packing problems, Jakobs (1996) developed a genetic algorithm (GA) using the bottom-left (BL) packing method with support for rotation of rectangles. Hopper and Turton (2001) provide a comprehensive comparison of GA, simulated annealing (SA), na\u00efve evolution, and simple hill-climbing for the strip packing problem with rotations and for various BL methods. A recent paper by Lesh et al. (2004) gives a method to find strip packing solutions using an exact branch and bounds exhaustive search. They successfully find perfect packings (zero trim loss) for problem sizes up to 30 rectangles. In regards to bin packing problems, Babu and Babu (1999) use a GA and a BL packing heuristic. Recently, Leung et al. (2003) developed a mixed simulated annealing-genetic algorithm.\n\nIn this paper, we design the four corners\u2019 (FC) packing heuristic with the aim to increase the search efficiency of EAs when applied to bin packing problems. By the nature of the FC heuristic, the packings produced are non-guillotineable and bottom-left stability is not preserved. In this research we study only orthogonal packing problems, consisting of one bin with the goal to seek minimum trim loss. In the typology of cutting and packing problems as defined by W\u00e4scher et al. (2006), we deal with a two-dimensional, output maximization problem: we have one large rectangle of fixed dimensions, into which the value of the placed smaller rectangles (assumed proportional to area of the rectangle) must be maximized. The smaller rectangles are strongly heterogeneous and must be laid out orthogonally. Specifically, we study the two-dimensional single orthogonal knapsack problem.\n\nThe FC heuristic is tested with two different self-adapting EAs: a self-adapting parallel recombinative simulated annealing (PRSA) algorithm and a self-adapting GA. The results are presented both with and without support for rotations. The FC heuristic combined with the self-adapting PRSA algorithm is found to produce tighter packings than any of the methods we have seen published in the literature.\n\nThis paper is outlined as follows. In Section 2, an analysis on how EAs work on packing problems is performed and the EA-friendly four corners\u2019 packing heuristic is introduced. In Section 3, a detailed description of the EA components developed in this study is given. Section 4 describes details of the PRSA implementation. Section 5 describes the GA implementation. The remaining sections cover the experimental settings, results, and conclusions.\n\n## Section snippets\n\n## Designing the four corners\u2019 heuristic\n\nIn this section, we analyze how EAs commonly function on packing problems and propose a four corners\u2019 heuristic designed specifically for EAs. GAs are chosen as the representative EA for this discussion, however most of the principles apply in general to the many types of EAs. For example, SA can be implemented using the genome encoding and the mutation operators of a GA. An implementation of PRSA (see Section 4) could use both the mutation and crossover operators of a GA as is done in this\n\n## Common components of a self-adapting evolutionary algorithm\n\nThe PRSA and GA algorithms implemented in this paper share the genome structure, the crossover operators, mutation operators, and the fitness function.\n\n## Self-adaptive parallel recombinative simulate...",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S0377221706003018"
    },
    {
      "title": "PII: 0377-2217(94)00166-9",
      "text": "ELSEVIER European Journal of Operational Research 88 (1996) 165-181 \nEUROPEAN \nJOURNAL \nOFOPERATIONAL \nRESEARCH \nTheory and Methodology \nOn genetic algorithms for the packing of polygons \nStefan Jakobs \nRWTH Aachen, Lehrstuhl C J~r Mathematik, Templergraben 55, 17-52062 Aachen, Germany \nReceived June 1993 \nAbstract \nA genetic algorithm for placing polygons on a rectangular board is proposed. The algorithm is improved by \ncombination with deterministic methods. \nKeywords: Optimization; Genetic algorithms; Mathematical programming; Adaptive processes; Packing problems \n1. Introduction and motivation \nIn the steel industry problems frequently occur \nwhen the need to stamp polygonal figures from a \nrectangular board arises. The aim is to maximize \nthe use of the contiguous remainder of the board. \nSimilar problems exist in the textile industry, \nwhen clothes are cut out of a rectangular piece of \nmaterial. \nIn order to solve these problems let us con\u0002sider the following simpler approach. Given a \nfinite number of rectangles ri, i = 1,..., n, and a \nrectangular board, an orthogonal packing pattern \nrequires by definition a disjunctive placement of \nthe rectangles on the board in such a way that the \nedges of r i are parallel to the x- and y-axes, \nrespectively. The computation of the orthogonal \npacking pattern with minimal height is called \northogonal packing problem (OPP). \nBaker, Coffman and Rivest propose an heuris\u0002tic for the orthogonal packing problem; in addi\u0002tion they present an upper bound for the height \nof the packing pattern [2]. A recent survey on \npacking problems and their respective heuristics \nis given in [16]. The extension from rectangles to \npolygons can be realized in several ways. The first \nmethod places the polygons directly on the board \nand then the algorithm optimizes locally by means \nof shifts and rotations [23]. A second approach \nplaces two or three polygons in a cluster. The \nclusters are then placed on the board [1]. \nIn this article we use another approach, namely \nan evolutionary algorithm. There are three main \nclasses in this approach, each of which is inde\u0002pendently developed. The first class is called evo\u0002lutionary programming (EP). L.J. Fogel, Owens, \nand Walsh were the first to develop the EP-al\u0002gorithms [5]. D.B. Fogel has recently improved \nthis approach [6]. The second class was developed \nby Rechenberg and Schwefel. They called their \napproach evolutionary strategies (ES) [17-20]. Fi\u0002nally, Holland developed the so called genetic \nalgorithm (GA) [12]. The genetic algorithm has \nbeen perfected by De Jong [13] and Goldberg [9]. \nThe paper is organized as follows. It begins by \nexplaining the problem and its complexity. In the \nnext section the data structure and its transfor\u0002mation into a packing pattern are described. Sec\u00020377-2217/96/$9.50 \u00a9 1996 Elsevier Science B.V. All rights reserved \nSSDI 0377-2217(94)00166-A \n166 S. Jakobs / European Journal of Operational Research 88 (1996) 165-181 \ntion 4 provides the genetic algorithm in combina\u0002tion with a deterministic algorithm, and numeri\u0002cal examples are presented. In Section 5 two \napproaches for the extension to polygons are \nproposed. The straightforward extension applies \nthe genetic algorithm directly to the polygons. \nThis method results, however, in a rather long \ncomputing time. An alternative to this method is \nthe application of the genetic algorithm to rectan\u0002gles in which the polygons are embedded; subse\u0002quently, the use of a deterministic shrinking step \nmoves the polygons closer to each other. \n2. The problem \nThe size of the search space of the orthogonal \npacking problem is infinite, because every move\u0002ment of a rectangle into a packing pattern in a \nfeasible direction creates a new packing pattern. \nIn order to effectively reduce the number of \npossible orthogonal packing patterns the so called \nbattom-left-condition (BL-condition) is intro\u0002duced. The orthogonal packing pattern fulfills the \nBL-condition if no rectangle can be shifted fur\u0002ther to the bottom or to the left. \nIn addition, the complexity of the problem \nmust be considered. The QPP is a natural gener\u0002alization of the one-dimensional bin-packing \nproblem. Indeed, ff all rectangles are required to \nhave the same height, then the two problems \ncoincide. On the other hand, the case in which all \nrectangles have the same width corresponds to \nthe well-known makespan minimization problem \nof combinatorial scheduling theory. Both these \nrestricted problems are known to be NP-com\u0002plete [8]. \nOther authors as Sleator, who did not use the \nBL-condition, mentioned that the packing prob\u0002lem can be reduced to the partition problem \n[22,7]. \n3. Data structure \nThe data structure is important for the genetic \nalgorithm. The first genetic algorithms (shortly \nGAs) worked with bit-strings. Over the last few \nyears, GAs have been developed which are based \non other data structures. In this way the differ\u0002ence between GAs and the evolutionary strate\u0002gies has diminished [15]. The theory about ge\u0002netic algorithms calls the data structure a geno\u0002type and its decoding (here: packing pattern) is \ncalled phenotype. These technical terms are based \non biological terminology [9]. \nThe natural representation of a packing pat\u0002tern is based on the placement-coordinates of \neach rectangle on the board. If the left lower and \nthe right upper corner of all rectangles are known, \nthen the packing pattern can be reconstructed \neasily. For example see Fig. 1. \nThe advantage of the natural representation \nlies in its easy reconstruction. But if small changes \nin the coordinates are made it is probable that a \npacking pattern with overlaps will be created. \nr4 \n\u2022 x \nrectangle \nrl \nr2 \nr3 \nr4 \nr5 \nXo, Yo) \n(18,0) \n(lO,O) \n(10,5) \n(o,o) \n(0,7) \nFig. 1. Natural representation of a packing pattern. \nXl, Yl) \n(22,1o) \n(18,5) \n(15,11) \n(lO,7) \n(4,12) \ns. Jakobs / European Journal of Operational Research 88 (1996) 165-181 167 \nThis property of natural representation is, how\u0002ever, not suited for GA. Consequently, a more \nvariable data structure is needed. \nAlternatively, a packing pattern can be repre\u0002sented by a permutation ~-. \ni~- Index of the rectangle (ri). \na . J \n~- = (i 1 ..... i,) - Permutation. \nThe permutation represents the sequence in \nwhich the rectangles are packed. The advantage \nof this data structure is the facile creation of new \npermutations by changing the sequence. A conse\u0002quence of the variable data structure is the fact \nthat every permutation has to be assigned to a \nunique packing pattern. This decoding of the \ngenotype needs more effort than the conversion \nof the natural representation into the packing \npattern. Hence, the aim is to create a fast decod\u0002ing algorithm. \n3.1. BL-algorithm \nStep 1. Place r~(1) into the left lower corner of \nthe board. \nStep i. Shift r~(i) alternately, beginning from \nthe upper right corner of the board, as far as \npossible to the bottom and then as far as possible \nto the left. \nFig. 2 illustrates the packing process of the BL-al\u0002gorithm. \nIt is easy to show, that the packing pattern, \nwhich is created by the BL-algorithm, fulfills the \nBL-condition, because otherwise at least one of \nthe rectangles could be shifted further to the \nheight \nr2 \n.X \nPermutation: \n= 3 \n= 2 \n= 4 \n= 1 \nor \n= (3,2,4,1) \nFig. 2. Illustration of the BL-algorithm. \nbottom or to the left. This is in contradiction to \nStep i of the BL-algorithm. \nSome properties of the BL-algorithm are pre\u0002sented below. The first one is an upper bound to \nthe possible packing patterns. Given n rectangles, \nthe number 2\"-n[ is an upper bound to the \npacking patterns which can be calculated by the \nBL-algorithm. This is a consequence of the fact \nthat the orthogonal packing problem is a permu\u0002tation problem. So there are n! sequences of \nrectangles. Furthermore each rectangle can be \nplaced in two ways such that the edges are paral\u0002lel to the x- and y-axes. In practice, less packing \npatterns than 2\". n! can be creat...",
      "url": "http://www.cs.nott.ac.uk/~pszgxk/aim/2008/reading/ga_representation_2.pdf"
    },
    {
      "title": "",
      "text": "Procedings of COBEM 2005\nCopyright \u00b0c 2005 by ABCM\n18th International Congress of Mechanical Engineering\nNovember 6-11, 2005, Ouro Preto, MG\nApplying the Simulated Annealing to the Problem of Positioning Rotational\nNon Convex Polygons\nMartins, T. C\nDepartment of Mechatronics and Mechanical Systems Engineering, EPUSP\nthiago.martins@poli.usp.br\nTsuzuki, M. S. G.\nDepartment of Mechatronics and Mechanical Systems Engineering, EPUSP\nmtsuzuki@usp.br\nThis work deals with the problem of minimize the waste of space that occurs on a placement of a set of bi-dimensional\npolygons inside a bi-dimensional container. This problem is approached with an heuristic based on Simulated Annealing,\nwhich is inspired on the physico-chemical process that take place during the recrystalisation of a metal. Traditional \u201cex\u0002ternal penalisation\u201d techniques are avoided through the application of the Minkowski sum algorithm, that determinates\ncollision-free areas for the set of polygons. That gives to the proposed process a more universal character, as external\npenalisations are based on empiric parameters of great influence on the optimisation performance. The proposed process\nis suited for non-convex polygons and containers, and can be easily adapted for related problems, such as container size\nminimisation.\n1. Introduction to placement problems\nThe polygonal placement problems arises in the industry whenever one must place multiple objects inside a container\nso that there is no collision between the objects, while either minimizing the size of the container either maximizing the\nvolume occupied by the objects. For instance, on the shoe industry, a maximum number of shoe parts must be placed\nover a leather piece. Another instance of the problem occurs in the textile industry, where cloth parts must be placed over\nthe smallest possible sheet of tissue. Those problems are also closely related to robot motion planning, where a trajectory\nfor an object (the robot) that leads it from one point to another must be found while avoiding collisions with pre-placed\nobstacles. Those placement problems are also known by the names of nesting, containment, layout, packing and cutting\nstock (Downsland et al., 1995). Surveys of placement problems can be found at (Lodi et al., 2002; Downsland et al., 1992;\nDownsland et al., 1995). Computational approaches often focus on purely translational versions of the problem, and the\nmajor part of them approach problems whose polygons are constrained to rectangular shapes.\n2. This work\nAs seen on the section 1, due to their complexity, irregular placement problems are the least computationally ap\u0002proached, despite their great relevancy for the industry. This is the motivation for this work, which deals with the bidi\u0002mentional placement on its most unconstrained form, the translational and rotational placement of heterogeneous irregular\nforms (both nonvex and non convex) on irregular containers (also both convex and non convex).\n2.1 Problem statement\nThe problem can be defined as the problem of, given a container (a polygon, convex or non-convex) and a polygon\nset, to determinate a subset of polygons and the transformations (translations and rotations) that, when applied to their\nrespective polygons, place them without collisions inside the container while minimising the wasted space (see Figure 1).\nDefinition 1 There is a collision between two polygons when their intersection is a non-empty set.\nAs mentioned, it can be show that even restricted versions of this problem (for instance, limiting the polygon shape to\nrectangles only) are NP-Complete, which means it is believed they cannot be algorithmically solved for practical instances\n(Fowler et al. 1981). This motivates an heuristic approach, that while is not guaranteed to find the optimal solution, can,\nin a reasonable amount of time, find a good solution. Probabilistic optimisation heuristics follow this pattern: while a\nstipulated stop criteria is not satisfied, at each step the function to be optimised is evaluated at a set of points and a set of\nrules is applied to determinate the set of points to be evaluated at the next step. The process converges to a solution of the\nproblem.\nFor our problem, the space of valid solutions is the set of transformations (\u2206x, \u2206y, \u2206\u03b8) to be applied to the polygons\nrestricted to the condition of no-collisions between them. The space delimited by those restrictions is very complex (and\nmutable). Usually, when confronted to such complex spaces, probabilistic heuristics \u201crelax\u201d the original constrains of\nProcedings of COBEM 2005\nCopyright \u00b0c 2005 by ABCM\n18th International Congress of Mechanical Engineering\nNovember 6-11, 2005, Ouro Preto, MG\nPolygon set Container\nSolution\nFigure 1. A placement problem and its optimal solution.\nthe problem, allowing the search to go through points outside the space of valid solutions and applying penalisations to\ntheir cost. This technique is known as external penalisation. While at first this technique greatly simplifies the problem,\nit also introduces and additional problem: How to determinate the exact amount of penalisation to be applied to external\npoints? Another drawback of external penalisation is that it can lead the optimisation process to non-valid solutions. This\ncan be seen on the work of Heckman (1995), where problems very similar to those studied here are approached with\nsimulated annealing. On his work. Heckman points that his optimisation process can produce invalid solutions (solutions\nwith collisions between polygons), requiring a post-processing step of the obtained data.\nThe approach adopted here avoids the pitfalls of external penalisation by the continuous mapping (meaning it is\nupdated at each step of the process) of the complex space of valid solution into a simplified space. Although this additional\nmapping step increases the complexity of the process, it confers to the process a more universal character, as there is one\nless empiric parameter to be defined. Actually, the proposed process does not explores the whole space of possible\nsolutions, focusing instead on a reduced space, that contains at least one optimal solution. This reduces the search through\nirrelevant points and enhances the performance of the process.\n2.2 Simulated annealing\nSimulated Annealing (Kirkpatrick et al., 1983) is the probabilistic meta-heuristic adopted on this work. It was chose\ndue to its capacity of \u201cescape\u201d from local minima (which are very frequent on this problem). It is also worth of mention\nthat the process of recrystalisation, the inspiration for simulated annealing, is a natural instance of a placement problem.\n2.2.1 Description\nSimulated annealing comes from the Metropolis algorithm, a simulation of the recrystalisation of atoms on a metal\nduring its annealing (gradual and controlled cooling). During annealing, atoms migrate naturally to configurations that\nminimize the system total energy, even if during this migration the system must pass through high-energy configurations.\nThe observation of this behavior suggests the application of the simulation of such process to combinatorial optimisation\nproblems.\nSimulated annealing is a hill-climbing local exploration1 optimisation heuristic, which means it can skip local minima\nby allowing the exploration of the space in directions that lead to an increase on the cost function. It sequentially applies\nrandom modifications on the evaluation point of the cost function. If a modification yields a point of smaller cost,\nit is automatically kept. Otherwise, the modification also can be kept with a probability obtained form the Boltzman\ndistribution (1).\nP(\u2206E) = e\n\u2212 \u2206E\nkt (1)\nwhere P(\u2206E) is the probability of the optimisation process to keep a modification that incurred on an increase \u2206E of\nthe cost function, k is a parameter of the process (analogous to the Stefan-Boltzman constant) and t is the instantaneous\n\u201ctemperature\u201d of the process. This temperature is defined by a cooling schedul...",
      "url": "https://abcm.org.br/symposium-series/SSM_Vol2/Section_XII_Emerging_Technologies_and_AI_Applications/SSM2_XII_02.pdf"
    },
    {
      "title": "Extended local search algorithm based on nonlinear programming for two-dimensional irregular strip packing problem",
      "text": "Extended local search algorithm based on nonlinear programming for two-dimensional irregular strip packing problem - ScienceDirect\n[Skip to main content](#screen-reader-main-content)[Skip to article](#screen-reader-main-title)\n[![Elsevier logo](https://www.sciencedirect.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg)ScienceDirect](https://www.sciencedirect.com/)\n[My account](https://www.sciencedirect.com/user/login?targetURL=/science/article/pii/S0305054811001596&amp;from=globalheader)\n[Sign in](https://www.sciencedirect.com/user/institution/login?targetURL=/science/article/pii/S0305054811001596)\n* [Access through**your organization**](https://www.sciencedirect.com/user/institution/login?targetUrl=/science/article/pii/S0305054811001596)\n* [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S0305054811001596/purchase)\nSearch ScienceDirect\n## Article preview\n* [Abstract](#preview-section-abstract)\n* [Introduction](#preview-section-introduction)\n* [Section snippets](#preview-section-snippets)\n* [References (20)](#preview-section-references)\n* [Cited by (70)](#preview-section-cited-by)\n[![Elsevier](https://www.sciencedirect.com/us-east-1/prod/bd96d51d266808527bf1018bd38b59c0b4bc6286/image/elsevier-non-solus.svg)](https://www.sciencedirect.com/journal/computers-and-operations-research)\n## [Computers &amp; Operations Research](https://www.sciencedirect.com/journal/computers-and-operations-research)\n[Volume 39, Issue 3](https://www.sciencedirect.com/journal/computers-and-operations-research/vol/39/issue/3),March 2012, Pages 678-686\n[![Computers &amp; Operations Research](https://ars.els-cdn.com/content/image/1-s2.0-S0305054811X00084-cov150h.gif)](https://www.sciencedirect.com/journal/computers-and-operations-research/vol/39/issue/3)\n# Extended local search algorithm based on nonlinear programming for two-dimensional irregular strip packing problem\nAuthor links open overlay panelStephen C.H.Leunga,YangbinLinb,DefuZhangb\nShow more\nAdd to Mendeley\nShare\nCite\n[https://doi.org/10.1016/j.cor.2011.05.025](https://doi.org/10.1016/j.cor.2011.05.025)[Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0305054811001596&amp;orderBeanReset=true)\n## Abstract\nThis paper presents an extended local search algorithm (ELS) for the irregular strip[packing problem](https://www.sciencedirect.com/topics/social-sciences/packing-problem). It adopts two neighborhoods, swapping two given polygons in a placement and placing one polygon into a new position. The local search algorithm is used to minimize the overlap on the basis of the neighborhoods mentioned above and the unconstrained[nonlinear programming](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/nonlinear-programming)model is adopted to further minimize the overlap during the search process. Moreover, the[tabu](https://www.sciencedirect.com/topics/social-sciences/tabu)search algorithm is used to avoid[local minima](https://www.sciencedirect.com/topics/engineering/local-minimum), and a compact algorithm is presented to improve the result. The results of standard test instances indicate that when compared with other existing algorithms, the presented algorithm does not only show some signs of competitive power but also updates several best known results.\n## Introduction\nThe irregular strip packing problem, also known as the nesting problem, has a wide area of applications. Given a set of irregular shapes and a rectangular strip with a fixed width and an arbitrary length, the target of the two-dimensional irregular strip packing problem is to place all shapes within the strip such that the length of the strip is minimized and the irregular shapes do not overlap. A classic example application is clothing industry. Several pieces of clothes will be cut from a roll of fabric and the objective is to minimize the waste of fabric. The fabric has a fixed width and its length can be generally assumed infinite; so the problem is to minimize the length required for producing the specified number of irregular shapes.\nThe irregular strip packing problem is a NP-hard combinatorial optimization problem [1]. Numerous papers on nesting problem have been published since the first paper by Art [2]. Meta-heuristics are often used to solve this problem. Hopper and Turton [3] reviewed these methods, and a summary of geometric methods was published by Bennell and Oliveira [4]. As research progressed, further breakthroughs in algorithms for this problem have achieved in recent years. When compared with the previous years, these solutions have markedly improved the effect and speed of nesting results. The typical methods include Burke et al. [5], Gomes and Oliveira [6], Egeblad et al. [7], Imamichi et al. [8], etc.\nAlbano and Sapuppo [9] proposed an algorithm that places each shape at the bottom-left position, and the sequence of places is obtained by tree search. Jakobs [10] proposed a two-stage solution which first generates the rectangular enclosure of each irregular shape, and then finds the placement for these enclosures through a genetic algorithm. Secondly, a shrinking algorithm moves the shapes to another one as close as possible using the idea of the bottom-left heuristic. Gomes and Oliveira [11] based on bottom-left heuristic and find a good placement by exchanging two shapes in the layout. Dowsland et al. [12] developed a compact algorithm to improve the bottom-left heuristic algorithm. The algorithm first gets the initial placement by the bottom-left heuristic, and then uses a shaking process to compact the placement. Burke et al. [5] presented a new bottom-left heuristic algorithm based on discretization, and combination with hill climbing or tabu search to get a high quality solution. This algorithm can also pack the shapes with circular arcs and holes. Egeblad et al. [7] proposed an efficient fast local search method whose neighborhood is any horizontal or vertical translation of a given shape. They also formulated a polynomial time algorithm to find a translation with minimum overlap area between the given polygon and the other polygons in the current placement. Gomes and Oliveira [6] presented a separation algorithm to locally optimize the placement based on linear programming models, and used simulated annealing to guide the search. A new separation algorithm based on unconstrained nonlinear programming is proposed by Imamichi et al. [8]. They also designed an algorithm that swaps two polygons in a placement, and then the algorithms are combined as a component into an iterated local search algorithm for the overlap minimization problem. This method yielded several best known results on the standard test instances. Our algorithm is based on a separation algorithm presented by Imamichi et al. [8], and local search is adopted to guide the search. Moreover, a tabu search algorithm is used to avoid local minima and a compacted algorithm is used to improve the packing results.\n## Section snippets\n## Formulation\nIn this section, some fundamental elements of geometry are first defined, before formulation of the irregular strip packing problem algorithm is given.\n**Definition 1 (point)**\nA point*p*in two-dimensional space is represented by a pair:p=(px,py)\u2208R2.\n**Definition 2 (line segment)**\nA line segment*s*is a point set defined by two endpoints*p**a*and*p**b*:s={p\u2208R2,t\u2208[0,1]|p=pa+t(pb\u2212pa)}.\n**Definition 3 (polygon)**\nA polygon is a plane figure bounded by a closed path composes of a finite sequence of line segments denoted by*S*. No cross occurs in any pair of line segments in*S*. Here we\n## Geometric approaches\nCompared with the regular polygon, e.g., triangle and rectangle, the irregular polygon is much more complex and more time is taken in dealing with some basic geometric problems, i.e., determining if two polygons are overlapping each other, and determining the minimum translation vector that can separate two overlap polygons. The increase in ge...",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S0305054811001596"
    },
    {
      "title": "Simulated Annealing with Adaptive Neighborhood Applied to the Placement over Containers with Fixed Dimensions",
      "text": "[Skip to main content](https://www.sciencedirect.com/science/article/pii/S147466701535549X#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/pii/S147466701535549X#screen-reader-main-title)\n\n- [View\u00a0**PDF**](https://www.sciencedirect.com/science/article/pii/S147466701535549X/pdf?md5=7bca88c33d2daef044751913b4156e2b&pid=1-s2.0-S147466701535549X-main.pdf)\n- Download full issue\n\nSearch ScienceDirect\n\n## Outline\n\n1. [Abstract](https://www.sciencedirect.com/science/article/pii/S147466701535549X#ceab10)\n2. [Keywords](https://www.sciencedirect.com/science/article/pii/S147466701535549X#cekeyws10)\n3. [References](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bibl10)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/558f6b3505d331efa27a89a25731aa712b0662a4/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/ifac-proceedings-volumes)\n\n## [IFAC Proceedings Volumes](https://www.sciencedirect.com/journal/ifac-proceedings-volumes)\n\n[Volume 41, Issue 3](https://www.sciencedirect.com/journal/ifac-proceedings-volumes/vol/41/issue/3), 2008, Pages 106-111\n\n[![IFAC Proceedings Volumes](https://ars.els-cdn.com/content/image/1-s2.0-S1474667015X60770-cov150h.gif)](https://www.sciencedirect.com/journal/ifac-proceedings-volumes/vol/41/issue/3)\n\n# Simulated Annealing with Adaptive Neighborhood Applied to the Placement over Containers with Fixed Dimensions\n\nAuthor links open overlay panelThiagode Castro Martins\\*, Marcosde Sales Guerra Tsuzuki\\*\n\nShow more\n\nOutline\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.3182/20081205-2-CL-4009.00020](https://doi.org/10.3182/20081205-2-CL-4009.00020) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S147466701535549X&orderBeanReset=true)\n\n## Abstract\n\nThis work deals with the problem of minimizing the waste of space that occurs on a rotational placement of a set of irregular bi-dimensional items inside a bi-dimensional container. This problem is approached with an heuristic based on Simulated Annealing (SA) with adaptive neighborhood. Traditional \u201cexternal penalization\u201d techniques are avoided through the application of the no\u2013fit polygon, that determinates the collision-free area for each polygon before its placement. The SA controls continuous and discrete parameters. The rotation applied and the translation of the polygon are continuous parameters, and the sequence of placement is represented as a set of discrete parameters. For each non\u2013placed item, a limited depth binary search is performed to find a scale factor that when applied to the item, would allow it to be fitted in the container.\n\n- [Previous article in issue](https://www.sciencedirect.com/science/article/pii/S1474667015355488)\n- [Next article in issue](https://www.sciencedirect.com/science/article/pii/S1474667015355506)\n\n## Keywords\n\nSimulated Annealing\n\nPlacement Problems\n\nOptimization\n\nProbabilistic Heuristics\n\n[View PDF](https://www.sciencedirect.com/science/article/pii/S147466701535549X/pdf?md5=7bca88c33d2daef044751913b4156e2b&pid=1-s2.0-S147466701535549X-main.pdf)\n\nSpecial issue articlesRecommended articles\n\n## References\n\n01. [Art, 1966](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib1)\n    Art, R.C. (1966). An approach to the two-dimensional irregular cutting stock problem. Technical report, IBM Cambridge Scientific Centre.\n\n    [Google Scholar](https://scholar.google.com/scholar?q=Art%2C%20R.C.%20(1966).%20An%20approach%20to%20the%20two-dimensional%20irregular%20cutting%20stock%20problem.%20Technical%20report%2C%20IBM%20Cambridge%20Scientific%20Centre.)\n\n02. [Bohachevsky et al., 1986](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib2)\n\n\n    I.O. Bohachevsky, M.E. Johnson, M.L. Stein\n\n\n\n    Generalized simulated annealing for function optimization\n\n\n\n    Technometrics, 28 (1986), pp. 209-217\n\n\n\n\n\n    [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0022758683&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Generalized%20simulated%20annealing%20for%20function%20optimization&publication_year=1986&author=I.O.%20Bohachevsky&author=M.E.%20Johnson&author=M.L.%20Stein)\n\n03. [Burke et al., 2007](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib3)\n\n\n    E.K. Burke, R.S.R. Hellier, G. Kendall, G. Whitwell\n\n\n\n    Complete and robust no-fit polygon generation for the irregular stock cutting problem\n\n\n\n    European Journal of Operational Research, 179 (2007), pp. 27-49\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221706001639/pdfft?md5=262c7a09c1162709123beee32f0b72e8&pid=1-s2.0-S0377221706001639-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0377221706001639) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-33751335925&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Complete%20and%20robust%20no-fit%20polygon%20generation%20for%20the%20irregular%20stock%20cutting%20problem&publication_year=2007&author=E.K.%20Burke&author=R.S.R.%20Hellier&author=G.%20Kendall&author=G.%20Whitwell)\n\n04. [Corana et al., 1987](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib4)\n\n\n    A. Corana, M. Marchesi, C. Martini, S. Ridella\n\n\n\n    Minimizing multimodal functions of continuous variables with the simulated annealing algorithm\n\n\n\n    ACM Transactions on Mathematical Software, 13 (1987), pp. 262-280\n\n\n\n\n\n    [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0023416976&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Minimizing%20multimodal%20functions%20of%20continuous%20variables%20with%20the%20simulated%20annealing%20algorithm&publication_year=1987&author=A.%20Corana&author=M.%20Marchesi&author=C.%20Martini&author=S.%20Ridella)\n\n05. [Dowsland et al., 2002](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib5)\n\n\n    K.A. Dowsland, S. Vaid, B.W. Dowsland\n\n\n\n    An algorithm for polygon placement using a bottom-left strategy\n\n\n\n    European Journal of Operational Research, 141 (2002), pp. 371-381\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221702001315/pdfft?md5=68f3c9993c2c281df7f1bd84d209f68b&pid=1-s2.0-S0377221702001315-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0377221702001315) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0036722394&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=An%20algorithm%20for%20polygon%20placement%20using%20a%20bottom-left%20strategy&publication_year=2002&author=K.A.%20Dowsland&author=S.%20Vaid&author=B.W.%20Dowsland)\n\n06. [Dyckhoff, 1990](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib6)\n\n\n    H. Dyckhoff\n\n\n\n    A typology of cutting and packing problems\n\n\n\n    European Journal of Operational Research, 44 (1990), pp. 145-159\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/037722179090350K/pdf?md5=24cb0198949a826fc64bf7a98f4974f3&pid=1-s2.0-037722179090350K-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/037722179090350K) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0025210672&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20typology%20of%20cutting%20and%20packing%20problems&publication_year=1990&author=H.%20Dyckhoff)\n\n07. [Gomes and Oliveira, 2006](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib7)\n\n\n    A.M. Gomes, J.F. Oliveira\n\n\n\n    Solving irregular strip packing problems by hybridising simulated annealing and linear programming\n\n\n\n    European Journal of Operational Research, 171 (2006), pp. 811-829\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221...",
      "url": "https://www.sciencedirect.com/science/article/pii/S147466701535549X"
    },
    {
      "title": "",
      "text": "Lo\u00efc Crombez \nGuilherme D Da Fonseca \nYan Gerard \nGreedy and Local Search Heuristics to Build Area-Optimal Polygons\n\nIn this paper, we present our heuristic solutions to the problems of finding the maximum and minimum area polygons with a given set of vertices. Our solutions are based mostly on two simple algorithmic paradigms: greedy method and local search. The greedy heuristic starts with a simple polygon and adds vertices one by one, according to a weight function. A crucial ingredient to obtain good solutions is the choice of an appropriate weight function that avoids long edges. The local search part consists of moving consecutive vertices to another location in the polygonal chain. We also discuss the different implementation techniques that are necessary to reduce the running time.\n\nIntroduction\n\nIn this paper, we consider the optimal area polygonalization problem, i.e. the problem of finding large and small area simple polygons with a given vertex set. Optimal area polygonalization resembles to the well-known travelling salesman problem, the difference being that the objective function of the former is the area of the computed polygon instead of its perimeter. This problem has been the subject of the 2019 Geometric Optimization Challenge and is known to be NP-hard for both minimization and maximization [2]. Exact algorithms are discussed in [3] and a recent state of the art is given in [1].\n\nIn this paper, we describe the algorithm that we developed during the 2019 Geometric Optimization Challenge. Our results gave us the second place, both for the minimization and maximization contests. Throughout, we refer to the score of a solution as the area of the polygon divided by the area of the convex hull. The score is a real number between 0 and 1, and a lower score is better for the minimization version while a higher score is better for the maximization version. The scores obtained on the instances of the challenge are in the range [0.025, 0.352] for the minimization problem and in the range [0.835, 0.976] for the maximization problem. These two intervals become [0.110, 0.135] and [0.871, 0.924] if we only consider the uniform instances of at least 100 points where the inputs sets have been randomly generated in a square with a uniform density function. More results are presented in Section 4.\n\nOur results have been obtained with a relatively simple and fast heuristic coded in Python and executed with pypy3. The heuristic consists of two phases: a greedy heuristic and a subsequent local search optimization. It is surprising that our results are very competitive when compared to the more complex approaches used by the other teams [1]. The whole source code is available at github.com/gfonsecabr/poLYG and is less than 500 lines long, requiring no external library. While during the challenge we used several different machines, all the running times presented herein have been obtained on a Dell XPS 13-9380 laptop with an Intel i7-10510U CPU and 16GB of RAM running Fedora 32 Linux. The implementation only uses one CPU thread and the other CPU threads were kept mostly idle during the benchmarks.\n\nThe paper is organized as follows. Section 2 describes the algorithmic approach we used. In Section 3, we present different techniques implemented to make the code run faster and find better solutions. Section 4 presents our results. In Section 5, we discuss some possible improvements.\n\n\nMethods\n\nIn the next two sections, we describe the two phases of our solution. For simplicity, we focus only on the maximum area polygon. The few changes necessary to solve the minimization version are described in Section 2.3.\n\n2.1. Greedy Heuristic. Let S be the input set with n points. Throughout the execution of the algorithm, we work with a simple polygon P whose set of vertices is a subset of S. The set of points in S which are not yet vertices of P is denotedP . The current polygon P is initialized with the convex hull of S.\n\nEach greedy step consists of choosing a point q \u2208 P and inserting q in the current polygon P . We insert q as the intermediary point of an edge p 1 , p 2 \u2208 P so that our current polygon P has two new edges p 1 , q and q, p 2 replacing p 1 , p 2 . We preserve at each step the simplicity of P by verifying that the new edges p 1 , q and q, p 2 do not cross the existing edges of P .\n\nWe repeat our greedy steps until either the set P becomes empty or until no point of P can possibly be inserted anywhere in P (see Figure 2). In the former case the algorithm successfully finds a solution, and in the latter case it fails. Our experiments showed that if the triple q, p 1 , p 2 is chosen carefully at each step, as we explain in the next paragraphs, then the heuristic hardly ever fails. Hence, we simply ignored the extremely rare failures and when it happened we used a different value of the parameter \u03b1 described later on to guide the heuristic.\n\nThe choice of the triple q, p 1 , p 2 at each step is essential to the quality of the solution. A strategy investigated in [5] is to randomly choose the point q in P and then choose the best edge p 1 , p 2 where to insert q. We employ a more exhaustive search. At each step we choose the triple minimizing weight(p 1 , p 2 , q), for a weight function to be described next. Perhaps, the most natural greedy choice is to minimize the area of the triangle p 1 p 2 q (denoted area(p 1 p 2 q)), since the area of P will decrease by exactly area(p 1 p 2 q) when q is inserted between p 1 and p 2 . In this case, we say that the weight function is weight(p 1 , p 2 , q) = area(p 1 p 2 q). This weight function has the property that all points of P lie in the interior of P . However, this function leads to very long edges as shown in    Table 1. Scores before and after local search for different values of \u03b1 and instances with 500 points. The scores above use the formula weight(p 1 , p 2 , q) = area(p 1 p 2 q) + \u03b1( qp 1 + qp 2 \u2212 p 1 p 2 ) while the ones below use weight(p 1 , p 2 , q) = area(p 1 p 2 q) + \u03b1( qp 1 + qp 2 + p 1 p 2 ). Figure 1(a). While long edges may seem like a good choice at short term, they dramatically reduce the search space of potential new triangles, which will hence deteriorate the solution at long term and often make the algorithm fail. We experimented with several different weight functions in order to obtain better solutions. The best function that we found by penalizing long edges is\nweight(p 1 , p 2 , q) = area(p 1 p 2 q) + \u03b1( qp 1 + qp 2 \u2212 p 1 p 2 ),\nwhere \u00b7 denotes the Euclidean distance and \u03b1 is a small parameter. The term qp 1 + qp 2 penalizes the creation of long edges, while the term \u2212 p 1 p 2 favors breaking existing long edges. Another weight function that gives good results is obtained by replacing the minus sign by a plus sign, and numerous other variations exist. Notice that these functions do not guarantee that all points of P lie in the interior of P .\n\nThe value of area(p 1 p 2 q) is a positive number if q is inside P and a negative number otherwise. Using signed areas (negative for clockwise triangles) is important, since some input points in P may possibly lie outside P . We determined that the best values of \u03b1 are generally in the range 1/150 \u2264 \u03b1 \u2264 1/50. Unless otherwise specified, the examples in this paper use \u03b1 = 1/90. Figure 1(b) shows the improvement obtained by penalizing long edges, while Table 1 shows some scores achieved through different weight functions (the local search algorithm is discussed in the next section).\n\n\nLocal Search.\n\nAfter obtaining the greedy solution, we perform a second phase to improve the score of the solution, by making local changes to the polygon. The simplest optimization we perform consists of moving one vertex v to another position in the polygonal chain, between the endpoints of an edge u 1 u 2 (Figure 3(a)), adding the edges u 1 v and vu 2 , while removing the edge u 1 u 2 . A more general version of this procedure consists of moving a path V = v 1 ,...",
      "url": "https://export.arxiv.org/pdf/2106.14728v1.pdf"
    }
  ]
}