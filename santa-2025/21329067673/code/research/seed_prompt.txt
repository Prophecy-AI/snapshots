# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.615745 from strict ensemble (experiments/005_ensemble)
- Best LB score: 70.676059 (exp_002 - eazy optimizer, but exp_003 was REJECTED for overlaps!)
- Target: 68.891380 | Gap to target: 1.72 points (2.50%)

## ⚠️ CRITICAL: SUBMIT THE ENSEMBLE IMMEDIATELY!

**The strict ensemble (70.615745) has NEVER been submitted!**
- It's 0.06 points better than baseline (70.676102)
- Validated with Shapely - NO overlaps
- Improves 162 out of 200 N values
- File: `/home/code/experiments/005_ensemble/submission_ensemble_strict.csv`
- Already copied to `/home/submission/submission.csv`

**SUBMIT THIS FIRST before any other experiments!**

## CV-LB Relationship Analysis
- CV = LB exactly (within floating point precision) for this optimization problem
- No distribution shift - any valid improvement in CV directly translates to LB
- The last submission (exp_003) was REJECTED due to overlaps at N=13
- The eazy optimizer corrupts coordinates - DO NOT USE for submissions

## Response to Evaluator

The evaluator correctly identified:
1. **Local optimization cannot close the 1.78 point gap** - 4 experiments produced only 0.000430 improvement
2. **The eazy optimizer is unsafe** - it introduces overlaps Kaggle detects but Shapely doesn't
3. **Need fundamentally different approach** - not more SA iterations

**Key insight from evaluator**: The target score of 68.891380 IS achievable (it's on the leaderboard). The question is HOW to find those configurations.

**My response**:
- AGREE: Local optimization is stuck at a tight local optimum
- AGREE: The eazy optimizer corrupts coordinates and should not be used
- ACTION: Submit the strict ensemble (70.615745) which is 0.06 points better than baseline
- NEXT: Focus on finding fundamentally different configurations, not optimizing existing ones

## What's Working
1. **Strict ensemble approach** - Picks best valid config per N from 30+ sources
2. **Shapely validation** - Catches most overlaps (but not all - Kaggle is stricter)
3. **Pre-optimized baseline** - Already at a tight local optimum

## What's NOT Working
1. **Local optimization (SA, eazy, bbox3)** - Only finds tiny improvements (0.0001 per hour)
2. **Eazy optimizer** - Corrupts coordinates, causes Kaggle rejections
3. **Simple tessellation** - Produces worse results than baseline for most N

## Recommended Approaches (Priority Order)

### 1. [IMMEDIATE] Submit the strict ensemble
```bash
# Already done - file is at /home/submission/submission.csv
# Score: 70.615745 (0.06 better than baseline)
```

### 2. [HIGH PRIORITY] Find better external sources
The ensemble only improves 162/200 N values. For the other 38, we're using baseline.
- Search for more CSV sources (Kaggle datasets, GitHub repos)
- Look for configurations that beat baseline on specific N values
- Focus on N values with worst efficiency: N=1 (37.1%), N=2 (54.5%), N=3 (56.5%)

### 3. [HIGH PRIORITY] Implement proper tessellation with lattice extraction
From research: For N >= 58, grid-based placement using 2 base trees (blue/pink) achieves tighter bounds.
- Extract lattice parameters from best solutions: dx, dy, blue_deg, pink_deg
- Generate tessellation configurations for large N
- Compare with baseline, keep improvements

### 4. [MEDIUM PRIORITY] Try random restarts with different initial configurations
- For each N, generate 10-100 random initial configurations
- Run SA on each (but NOT eazy - it corrupts coordinates)
- Keep the best result
- This can escape the current local optimum by starting from different basins

### 5. [RESEARCH] Genetic algorithm with custom operators
- Custom crossover: swap partial solutions between candidates
- Custom mutation: rotate/translate clusters
- This explores fundamentally different regions of solution space

## What NOT to Try
- ❌ Running eazy optimizer (corrupts coordinates, causes Kaggle rejections)
- ❌ More SA iterations on existing configurations (stuck at local optimum)
- ❌ Simple grid tessellation (produces worse results than baseline)
- ❌ Ensembling from external CSVs that are worse than baseline (already checked - all worse)

## Key Insights from Research

### From Medium article on Santa 2025:
- **N < 58**: Use Simulated Annealing for unstructured, chaotic packings
- **N >= 58**: Switch to "Crystalline Packing" (regular geometric lattices)
- Top competitors use LLMs to write highly optimized C++ kernels
- The "Hybrid" strategy: Human defines heuristics, LLM writes optimized code, SA does heavy lifting

### From session findings:
- Lattice pattern: dx=0.25, dy=0.04, Blue angle=63.4°, Pink angle=243.4°
- Small N (1-10) have worst efficiency (37-65%) - most room for improvement
- Large N (150-200) have ~74% efficiency - near optimal

## SUBMISSION STRATEGY
- Remaining submissions: 96 (ABUNDANT!)
- **SUBMIT IMMEDIATELY**: The strict ensemble (70.615745)
- After submission: Continue experimenting with fundamentally different approaches

## Validation Notes
- Use Shapely with area > 1e-15 threshold for overlap detection
- BUT Kaggle is stricter - some overlaps pass Shapely but fail Kaggle
- Prefer configurations from original sources, not optimizer-modified ones
- Always validate before submission
