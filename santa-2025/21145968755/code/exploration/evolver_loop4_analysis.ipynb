{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e40d03f",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 Analysis: Comprehensive Source Exploration\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The evaluator correctly identified that we've only used 4 sources, but there are 15+ available pre-optimized CSVs. The Jonathan Chan kernel achieves better scores by ensembling from many more sources.\n",
    "\n",
    "## Goal\n",
    "1. Scan ALL available pre-optimized CSVs\n",
    "2. Score each one\n",
    "3. Build comprehensive ensemble picking best per-N\n",
    "4. Identify which sources win for which N values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    angle_rad = np.radians(deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    vertices = [(tx * cos_a - ty * sin_a + x, tx * sin_a + ty * cos_a + y) for tx, ty in zip(TX, TY)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def compute_bounding_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_points = []\n",
    "    for poly in polygons:\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) != n:\n",
    "        return float('inf')\n",
    "    polygons = [create_tree_polygon(parse_value(row['x']), parse_value(row['y']), parse_value(row['deg'])) for _, row in trees.iterrows()]\n",
    "    side = compute_bounding_side(polygons)\n",
    "    return side**2 / n\n",
    "\n",
    "def compute_total_score(df):\n",
    "    return sum(compute_score_for_n(df, n) for n in range(1, 201))\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18985a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find ALL CSV files in preoptimized directories\n",
    "\n",
    "base_paths = [\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/',\n",
    "    '/home/code/external_data/',\n",
    "]\n",
    "\n",
    "all_csvs = []\n",
    "for base in base_paths:\n",
    "    csvs = glob.glob(os.path.join(base, '**/*.csv'), recursive=True)\n",
    "    all_csvs.extend(csvs)\n",
    "\n",
    "print(f\"Found {len(all_csvs)} CSV files:\")\n",
    "for csv in sorted(all_csvs):\n",
    "    print(f\"  {csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Score each CSV file\n",
    "\n",
    "print(\"\\nScoring all CSV files...\")\n",
    "scores = {}\n",
    "valid_dfs = {}\n",
    "\n",
    "for csv_path in tqdm(all_csvs):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Check if it has the right columns\n",
    "        if 'id' not in df.columns or 'x' not in df.columns or 'y' not in df.columns or 'deg' not in df.columns:\n",
    "            print(f\"  Skipping {csv_path} - missing columns\")\n",
    "            continue\n",
    "        # Check if it has 200 configurations (N=1 to 200)\n",
    "        n_configs = len(df['id'].str[:3].unique())\n",
    "        if n_configs < 200:\n",
    "            print(f\"  Skipping {csv_path} - only {n_configs} configurations\")\n",
    "            continue\n",
    "        \n",
    "        score = compute_total_score(df)\n",
    "        scores[csv_path] = score\n",
    "        valid_dfs[csv_path] = df\n",
    "        print(f\"  {os.path.basename(csv_path)}: {score:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error with {csv_path}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully scored {len(scores)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Rank all sources by total score\n",
    "\n",
    "print(\"\\nRanking all sources by total score:\")\n",
    "print(\"=\"*80)\n",
    "ranked = sorted(scores.items(), key=lambda x: x[1])\n",
    "for i, (path, score) in enumerate(ranked[:20], 1):\n",
    "    print(f\"{i:2d}. {score:.6f} - {os.path.basename(path)}\")\n",
    "\n",
    "print(f\"\\nBest source: {os.path.basename(ranked[0][0])} with score {ranked[0][1]:.6f}\")\n",
    "print(f\"Current baseline: 70.659959\")\n",
    "print(f\"Target: 68.919154\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build comprehensive ensemble - pick best per-N from ALL sources\n",
    "\n",
    "print(\"\\nBuilding comprehensive ensemble (best per-N from all sources)...\")\n",
    "\n",
    "# For each N, find the best source\n",
    "best_per_n = {}  # n -> (score, source_path)\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    for path, df in valid_dfs.items():\n",
    "        score_n = compute_score_for_n(df, n)\n",
    "        if score_n < best_score:\n",
    "            best_score = score_n\n",
    "            best_source = path\n",
    "    best_per_n[n] = (best_score, best_source)\n",
    "\n",
    "# Count wins per source\n",
    "wins_per_source = {}\n",
    "for n, (score, source) in best_per_n.items():\n",
    "    source_name = os.path.basename(source)\n",
    "    wins_per_source[source_name] = wins_per_source.get(source_name, 0) + 1\n",
    "\n",
    "print(\"\\nWins per source:\")\n",
    "for source, wins in sorted(wins_per_source.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {wins} N values\")\n",
    "\n",
    "# Calculate ensemble score\n",
    "ensemble_score = sum(score for score, _ in best_per_n.values())\n",
    "print(f\"\\nEnsemble score (best per-N from all sources): {ensemble_score:.6f}\")\n",
    "print(f\"Best single source score: {ranked[0][1]:.6f}\")\n",
    "print(f\"Improvement from ensemble: {ranked[0][1] - ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the ensemble submission\n",
    "\n",
    "print(\"\\nCreating ensemble submission...\")\n",
    "ensemble_rows = []\n",
    "\n",
    "for n in range(1, 201):\n",
    "    score_n, source_path = best_per_n[n]\n",
    "    df = valid_dfs[source_path]\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    for _, row in trees.iterrows():\n",
    "        ensemble_rows.append(row.to_dict())\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "print(f\"Ensemble has {len(ensemble_df)} rows\")\n",
    "\n",
    "# Verify score\n",
    "verify_score = compute_total_score(ensemble_df)\n",
    "print(f\"Verified ensemble score: {verify_score:.6f}\")\n",
    "\n",
    "# Save\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"Saved to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Analyze per-N improvements\n",
    "\n",
    "print(\"\\nPer-N analysis: Where did ensemble improve over best single source?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_single_df = valid_dfs[ranked[0][0]]\n",
    "improvements = []\n",
    "\n",
    "for n in range(1, 201):\n",
    "    single_score = compute_score_for_n(best_single_df, n)\n",
    "    ensemble_score_n = best_per_n[n][0]\n",
    "    diff = single_score - ensemble_score_n\n",
    "    if diff > 1e-9:\n",
    "        improvements.append((n, diff, single_score, ensemble_score_n, os.path.basename(best_per_n[n][1])))\n",
    "\n",
    "print(f\"\\nEnsemble improved {len(improvements)} N values over best single source:\")\n",
    "for n, diff, single, ens, source in sorted(improvements, key=lambda x: -x[1])[:20]:\n",
    "    print(f\"  N={n:3d}: {single:.6f} -> {ens:.6f} (improved by {diff:.6f}) from {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Summary\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ENSEMBLE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal sources scanned: {len(all_csvs)}\")\n",
    "print(f\"Valid sources: {len(valid_dfs)}\")\n",
    "print(f\"\\nBest single source: {os.path.basename(ranked[0][0])}\")\n",
    "print(f\"Best single source score: {ranked[0][1]:.6f}\")\n",
    "print(f\"\\nEnsemble score: {verify_score:.6f}\")\n",
    "print(f\"Improvement: {ranked[0][1] - verify_score:.6f}\")\n",
    "print(f\"\\nTarget: 68.919154\")\n",
    "print(f\"Gap to target: {verify_score - 68.919154:.6f}\")\n",
    "print(f\"\\nSources contributing to ensemble:\")\n",
    "for source, wins in sorted(wins_per_source.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {wins} N values\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
