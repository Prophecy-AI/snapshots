{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4e4c5e",
   "metadata": {},
   "source": [
    "# Evolver Loop 6 Analysis\n",
    "\n",
    "## Situation Summary\n",
    "\n",
    "**Current Status:**\n",
    "- Best CV/LB score: 70.659959 (saspav baseline)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.74 points (2.5%)\n",
    "- Submissions used: 2/100 (93 remaining)\n",
    "\n",
    "**Key Findings from 6 experiments:**\n",
    "1. Saspav baseline (70.659959) is the best VALID source\n",
    "2. C++ SA optimizer shows 0 improvement on pre-optimized solutions\n",
    "3. Lattice construction produces WORSE scores (88.33 → 85.93 after SA)\n",
    "4. Comprehensive ensemble provides 0 improvement - saspav wins for all 200 N values\n",
    "5. Many CSV files have overlapping trees (invalid)\n",
    "\n",
    "**Critical Insight:**\n",
    "We've been searching for pre-optimized solutions but NOT actively optimizing them.\n",
    "The Eazy optimizer and other sophisticated techniques have NOT been applied to our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be06af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what C++ optimizers are available\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# List available optimizers\n",
    "print(\"=== Available C++ Optimizers ===\")\n",
    "for root, dirs, files in os.walk('/home/code/experiments'):\n",
    "    for f in files:\n",
    "        if f.endswith('.cpp') or (not '.' in f and os.access(os.path.join(root, f), os.X_OK)):\n",
    "            full_path = os.path.join(root, f)\n",
    "            size = os.path.getsize(full_path)\n",
    "            print(f\"{full_path}: {size/1024:.1f}KB\")\n",
    "\n",
    "print(\"\\n=== Research Kernels ===\")\n",
    "for d in os.listdir('/home/code/research/kernels'):\n",
    "    if os.path.isdir(f'/home/code/research/kernels/{d}'):\n",
    "        print(f\"  {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3973171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Eazy optimizer C++ code\n",
    "with open('/home/code/research/kernels/jazivxt_eazy-optimizer/eazy-optimizer.ipynb', 'r') as f:\n",
    "    import json\n",
    "    nb = json.load(f)\n",
    "    \n",
    "# Find the C++ code cell\n",
    "for cell in nb['cells']:\n",
    "    if cell['cell_type'] == 'code':\n",
    "        source = ''.join(cell['source'])\n",
    "        if 'writefile eazy.cpp' in source:\n",
    "            # Extract key techniques\n",
    "            print(\"=== Eazy Optimizer Key Techniques ===\")\n",
    "            if 'apply_square_pressure' in source:\n",
    "                print(\"✓ Square Potential Gradient (pushes toward center)\")\n",
    "            if 'Elastic Pulse' in source:\n",
    "                print(\"✓ Elastic Pulse (periodic squeeze/relax)\")\n",
    "            if 'Complex Orbital Move' in source:\n",
    "                print(\"✓ Complex Orbital Moves (rotation in complex plane)\")\n",
    "            if 'scales' in source and '1e-3' in source:\n",
    "                print(\"✓ Multi-scale optimization (1e-3 → 1e-9)\")\n",
    "            if '250000' in source:\n",
    "                print(\"✓ 250,000 iterations per N\")\n",
    "            if 'omp parallel' in source:\n",
    "                print(\"✓ OpenMP parallelization\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc37035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can compile the Eazy optimizer\n",
    "import subprocess\n",
    "\n",
    "# Create a working directory for the optimizer\n",
    "os.makedirs('/home/code/experiments/007_eazy_optimizer', exist_ok=True)\n",
    "\n",
    "# Check if g++ with OpenMP is available\n",
    "result = subprocess.run(['g++', '--version'], capture_output=True, text=True)\n",
    "print(\"G++ version:\")\n",
    "print(result.stdout[:200])\n",
    "\n",
    "# Check OpenMP support\n",
    "result = subprocess.run(['g++', '-fopenmp', '-v'], capture_output=True, text=True)\n",
    "if 'openmp' in result.stderr.lower():\n",
    "    print(\"\\n✓ OpenMP support available\")\n",
    "else:\n",
    "    print(\"\\n⚠ OpenMP may not be available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N efficiency to identify where improvements are most needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load baseline\n",
    "df = pd.read_csv('/home/code/external_data/saspav/santa-2025.csv')\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def compute_side_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) != n:\n",
    "        return float('inf')\n",
    "    \n",
    "    all_points = []\n",
    "    for _, row in trees.iterrows():\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        angle_rad = np.radians(deg)\n",
    "        cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "        for tx, ty in zip(TX, TY):\n",
    "            px = tx * cos_a - ty * sin_a + x\n",
    "            py = tx * sin_a + ty * cos_a + y\n",
    "            all_points.append((px, py))\n",
    "    \n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "# Compute per-N scores\n",
    "per_n_data = []\n",
    "for n in range(1, 201):\n",
    "    side = compute_side_for_n(df, n)\n",
    "    score = side**2 / n\n",
    "    efficiency = score / 0.355  # Theoretical minimum is ~0.355\n",
    "    per_n_data.append({'n': n, 'side': side, 'score': score, 'efficiency': efficiency})\n",
    "\n",
    "per_n_df = pd.DataFrame(per_n_data)\n",
    "print(\"Per-N Analysis:\")\n",
    "print(f\"Total score: {per_n_df['score'].sum():.6f}\")\n",
    "print(f\"\\nWorst efficiency (most room for improvement):\")\n",
    "print(per_n_df.nsmallest(10, 'efficiency')[['n', 'side', 'score', 'efficiency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate potential improvement if we could match best efficiency\n",
    "best_efficiency = per_n_df['efficiency'].min()\n",
    "print(f\"\\nBest efficiency: {best_efficiency:.4f} at N={per_n_df.loc[per_n_df['efficiency'].idxmin(), 'n']}\")\n",
    "\n",
    "# If all N matched best efficiency\n",
    "theoretical_best = 0.355 * best_efficiency * 200\n",
    "print(f\"If all N matched best efficiency: {theoretical_best:.2f}\")\n",
    "\n",
    "# Improvement needed per N to reach target\n",
    "target = 68.919154\n",
    "current = per_n_df['score'].sum()\n",
    "gap = current - target\n",
    "print(f\"\\nCurrent: {current:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f}\")\n",
    "print(f\"Average improvement needed per N: {gap/200:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify N values with most potential for improvement\n",
    "per_n_df['improvement_potential'] = per_n_df['score'] - 0.355  # vs theoretical minimum\n",
    "per_n_df['contribution_pct'] = per_n_df['score'] / per_n_df['score'].sum() * 100\n",
    "\n",
    "print(\"\\nN values with highest improvement potential:\")\n",
    "print(per_n_df.nlargest(20, 'improvement_potential')[['n', 'score', 'improvement_potential', 'contribution_pct']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e8a7c",
   "metadata": {},
   "source": [
    "## Strategy Analysis\n",
    "\n",
    "### What We've Tried (All Failed to Improve):\n",
    "1. ❌ Ensemble from existing CSVs - saspav wins for all N\n",
    "2. ❌ C++ SA optimizer on pre-optimized - 0 improvement\n",
    "3. ❌ Lattice construction - much worse (88.33)\n",
    "4. ❌ Lattice + SA - still worse (85.93)\n",
    "\n",
    "### What We HAVEN'T Tried:\n",
    "1. **Eazy Optimizer** - Uses sophisticated techniques:\n",
    "   - Square potential gradient (pushes toward center)\n",
    "   - Elastic pulse (periodic squeeze/relax)\n",
    "   - Complex orbital moves\n",
    "   - Multi-scale optimization (1e-3 → 1e-9)\n",
    "   - 250,000 iterations per N with 20-second timeout\n",
    "\n",
    "2. **Different SA parameters** - The sa_v1_parallel may need different settings\n",
    "\n",
    "3. **Focus on specific N values** - Small N (1-20) have worst efficiency\n",
    "\n",
    "### Recommended Next Experiment:\n",
    "**Compile and run the Eazy optimizer on the saspav baseline**\n",
    "\n",
    "This is the highest-leverage action because:\n",
    "1. It uses fundamentally different optimization techniques\n",
    "2. It's designed specifically for this problem\n",
    "3. It runs 250,000 iterations per N (much more than our previous attempts)\n",
    "4. It uses multi-scale approach (1e-3 → 1e-9) for fine-tuning"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
