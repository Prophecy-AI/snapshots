{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bde0e73",
   "metadata": {},
   "source": [
    "# Loop 8 Analysis: Strategic Assessment\n",
    "\n",
    "## Key Observations:\n",
    "1. All local optimization approaches (SA, Eazy, bbox3, rotation) show 0 or marginal improvement\n",
    "2. The saspav baseline (70.659959) is at a very strong local optimum\n",
    "3. The gap to target (68.919154) is 1.74 points (2.5%)\n",
    "4. Eazy optimizer submission failed on Kaggle with overlap detection mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load baseline\n",
    "df = pd.read_csv('/home/code/external_data/saspav/santa-2025.csv')\n",
    "print(f\"Loaded {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe80e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores and identify improvement potential\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def compute_bounding_side(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) == 0:\n",
    "        return 0\n",
    "    \n",
    "    all_points = []\n",
    "    for _, row in trees.iterrows():\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        angle_rad = np.radians(deg)\n",
    "        cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "        for tx, ty in zip(TX, TY):\n",
    "            px = tx * cos_a - ty * sin_a + x\n",
    "            py = tx * sin_a + ty * cos_a + y\n",
    "            all_points.append([px, py])\n",
    "    \n",
    "    points = np.array(all_points)\n",
    "    return max(points.max(axis=0) - points.min(axis=0))\n",
    "\n",
    "# Compute per-N scores\n",
    "per_n_data = []\n",
    "for n in range(1, 201):\n",
    "    side = compute_bounding_side(df, n)\n",
    "    score = side**2 / n\n",
    "    # Theoretical minimum: sqrt(n) * tree_area / n = tree_area / sqrt(n)\n",
    "    # But for packing, we need to account for tree shape\n",
    "    per_n_data.append({'n': n, 'side': side, 'score': score})\n",
    "\n",
    "df_scores = pd.DataFrame(per_n_data)\n",
    "print(f\"Total score: {df_scores['score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 N values with highest score contribution:\")\n",
    "print(df_scores.nlargest(10, 'score')[['n', 'side', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency: score / theoretical_minimum\n",
    "# Theoretical minimum for N trees: if perfectly packed, side = sqrt(N * tree_area)\n",
    "# Tree area is approximately 0.35 (from bounding box of single tree)\n",
    "tree_area = 0.7 * 1.0  # width * height of single tree\n",
    "\n",
    "df_scores['theoretical_side'] = np.sqrt(df_scores['n'] * tree_area)\n",
    "df_scores['efficiency'] = df_scores['side'] / df_scores['theoretical_side']\n",
    "\n",
    "print(\"Efficiency analysis (lower is better):\")\n",
    "print(f\"Mean efficiency: {df_scores['efficiency'].mean():.4f}\")\n",
    "print(f\"\\nWorst efficiency (most room for improvement):\")\n",
    "print(df_scores.nlargest(10, 'efficiency')[['n', 'side', 'theoretical_side', 'efficiency', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot efficiency vs N\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(df_scores['n'], df_scores['efficiency'], alpha=0.5)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Efficiency (side / theoretical)')\n",
    "plt.title('Packing Efficiency by N')\n",
    "plt.axhline(y=1.0, color='r', linestyle='--', label='Perfect packing')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(df_scores['n'], df_scores['score'], alpha=0.5)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Score contribution')\n",
    "plt.title('Score Contribution by N')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/efficiency_analysis.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much improvement is needed per N to reach target\n",
    "target = 68.919154\n",
    "current = df_scores['score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f}\")\n",
    "print(f\"Average improvement needed per N: {gap/200:.6f}\")\n",
    "\n",
    "# If we could improve the worst N values proportionally\n",
    "df_scores_sorted = df_scores.sort_values('efficiency', ascending=False)\n",
    "print(f\"\\nIf we focus on worst 20 N values:\")\n",
    "worst_20 = df_scores_sorted.head(20)\n",
    "print(f\"Their total score: {worst_20['score'].sum():.6f}\")\n",
    "print(f\"If we could reduce their efficiency by 10%:\")\n",
    "potential_improvement = worst_20['score'].sum() * 0.1\n",
    "print(f\"Potential improvement: {potential_improvement:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0970e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what top kernels achieve\n",
    "# From the bbox3-runner kernel, they use multi-phase optimization:\n",
    "# Phase A: 2min runs with n=1000-2000, r=30-90\n",
    "# Phase B: 10min runs on top candidates\n",
    "# Phase C: 20min runs on best few\n",
    "\n",
    "# The key insight is that they use:\n",
    "# 1. bbox3 optimizer with specific parameters\n",
    "# 2. fix_direction rotation optimization\n",
    "# 3. overlap repair with donor solutions\n",
    "\n",
    "print(\"Key techniques from top kernels:\")\n",
    "print(\"1. bbox3 optimizer: Uses complex number vector coordination, fluid dynamics, hinge pivot\")\n",
    "print(\"2. fix_direction: Rotation optimization to minimize bounding box\")\n",
    "print(\"3. overlap repair: Uses donor solutions to fix invalid configurations\")\n",
    "print(\"4. Multi-phase approach: Short runs to find promising settings, then longer runs\")\n",
    "print(\"\")\n",
    "print(\"Our experiments show:\")\n",
    "print(\"- bbox3 with n=1000, r=60: 0.0000006 improvement\")\n",
    "print(\"- Rotation optimization: 0 improvement (baseline already optimal)\")\n",
    "print(\"- Eazy optimizer: 0.000015 improvement but FAILED on Kaggle (overlaps)\")\n",
    "print(\"\")\n",
    "print(\"CONCLUSION: The saspav baseline is at a very strong local optimum.\")\n",
    "print(\"Local optimization cannot close the 1.74 point gap to target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e52c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the target score implies\n",
    "# Target: 68.919154\n",
    "# Current: 70.659959\n",
    "# Gap: 1.740805\n",
    "\n",
    "# This means we need to reduce the average score per N by:\n",
    "avg_reduction = gap / 200\n",
    "print(f\"Average reduction needed per N: {avg_reduction:.6f}\")\n",
    "\n",
    "# For N=1 (score 0.661), this would be a 1.3% reduction\n",
    "# For N=200 (score 0.333), this would be a 2.6% reduction\n",
    "\n",
    "print(f\"\\nFor N=1 (score {df_scores[df_scores['n']==1]['score'].values[0]:.6f}):\")\n",
    "print(f\"  Reduction needed: {avg_reduction / df_scores[df_scores['n']==1]['score'].values[0] * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFor N=200 (score {df_scores[df_scores['n']==200]['score'].values[0]:.6f}):\")\n",
    "print(f\"  Reduction needed: {avg_reduction / df_scores[df_scores['n']==200]['score'].values[0] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key question: How do top teams achieve scores below 69?\n",
    "# From discussions:\n",
    "# 1. They use asymmetric solutions (not just symmetric lattices)\n",
    "# 2. They use different construction methods for different N ranges\n",
    "# 3. They run optimization for much longer (hours, not minutes)\n",
    "\n",
    "# Our options:\n",
    "# 1. Run bbox3 for much longer (hours)\n",
    "# 2. Try different construction methods (not just lattice)\n",
    "# 3. Use the \"rebuild from corners\" approach from chistyakov kernel\n",
    "# 4. Try ensemble from multiple independent optimization runs\n",
    "\n",
    "print(\"STRATEGIC OPTIONS:\")\n",
    "print(\"\")\n",
    "print(\"1. LONGER OPTIMIZATION:\")\n",
    "print(\"   - Run bbox3 for 30+ minutes per N\")\n",
    "print(\"   - Use multi-phase approach from bbox3-runner\")\n",
    "print(\"   - Expected improvement: 0.001-0.01 (not enough)\")\n",
    "print(\"\")\n",
    "print(\"2. DIFFERENT CONSTRUCTION:\")\n",
    "print(\"   - Rebuild from corners (chistyakov kernel)\")\n",
    "print(\"   - Use asymmetric solutions\")\n",
    "print(\"   - Expected improvement: Unknown\")\n",
    "print(\"\")\n",
    "print(\"3. ENSEMBLE FROM MULTIPLE RUNS:\")\n",
    "print(\"   - Run bbox3 with different seeds\")\n",
    "print(\"   - Pick best per-N from multiple runs\")\n",
    "print(\"   - Expected improvement: 0.01-0.1 (possible)\")\n",
    "print(\"\")\n",
    "print(\"4. FUNDAMENTALLY DIFFERENT APPROACH:\")\n",
    "print(\"   - Constraint programming (CP-SAT)\")\n",
    "print(\"   - Genetic algorithms with crossover\")\n",
    "print(\"   - Expected improvement: Unknown but potentially large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"LOOP 8 ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Current best: 70.659959 (saspav baseline)\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: 1.740805 (2.5%)\")\n",
    "print(\"\")\n",
    "print(\"EXPERIMENTS COMPLETED:\")\n",
    "print(\"- exp_000: Baseline = 70.659959\")\n",
    "print(\"- exp_001: C++ SA optimizer = 0 improvement\")\n",
    "print(\"- exp_002: Lattice construction = 88.33 (worse)\")\n",
    "print(\"- exp_003: Lattice + SA = 85.93 (worse)\")\n",
    "print(\"- exp_004: Invalid ensemble (overlaps)\")\n",
    "print(\"- exp_005: Valid ensemble = 0 improvement\")\n",
    "print(\"- exp_006: Eazy optimizer = 0.000015 improvement (FAILED on Kaggle)\")\n",
    "print(\"- exp_007: Rotation optimization = 0 improvement\")\n",
    "print(\"\")\n",
    "print(\"KEY INSIGHT: The saspav baseline is at a very strong local optimum.\")\n",
    "print(\"Local optimization cannot close the 1.74 point gap.\")\n",
    "print(\"\")\n",
    "print(\"RECOMMENDED NEXT STEPS:\")\n",
    "print(\"1. Try the 'rebuild from corners' approach (chistyakov kernel)\")\n",
    "print(\"2. Run bbox3 with multiple seeds and ensemble\")\n",
    "print(\"3. Investigate asymmetric solutions\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
