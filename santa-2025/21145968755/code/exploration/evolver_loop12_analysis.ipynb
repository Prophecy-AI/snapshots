{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd142a6",
   "metadata": {},
   "source": [
    "# Loop 12 Analysis: Strategic Pivot Required\n",
    "\n",
    "## Key Observations:\n",
    "1. 12 experiments all converge to ~70.66 (local optimum)\n",
    "2. Target is 68.92 - 1.74 points below current best\n",
    "3. Local optimization (SA, bbox3) provides negligible improvement (0.000001)\n",
    "4. Need fundamentally different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load session state to understand experiment history\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "print(f\"Total experiments: {len(state['experiments'])}\")\n",
    "print(f\"\\nExperiment scores:\")\n",
    "for exp in state['experiments']:\n",
    "    print(f\"  {exp['id']}: {exp['name'][:50]:50s} | Score: {exp['score']:.6f}\")\n",
    "\n",
    "print(f\"\\nBest score: {min(e['score'] for e in state['experiments']):.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {min(e['score'] for e in state['experiments']) - 68.919154:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bcdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have been tried\n",
    "approaches_tried = [\n",
    "    ('Pre-optimized baseline', 70.659959, 'No improvement possible'),\n",
    "    ('C++ SA optimizer', 70.659959, '0 improvement'),\n",
    "    ('Lattice construction', 88.33, 'Much worse'),\n",
    "    ('Lattice + SA', 85.93, 'Still much worse'),\n",
    "    ('Eazy optimizer', 70.659944, '0.000015 improvement'),\n",
    "    ('Rotation optimization', 70.659959, 'Negative improvement'),\n",
    "    ('bbox3 short runs', 70.659958666, '0.000001 improvement'),\n",
    "    ('Tree removal', 70.659959, '0 improvement'),\n",
    "    ('bbox3 with repair', 70.659958437, '0.000001 improvement'),\n",
    "    ('bbox3 multi-phase', 70.659958593, '0.000001 improvement'),\n",
    "]\n",
    "\n",
    "print(\"Approaches tried and results:\")\n",
    "print(\"=\"*80)\n",
    "for name, score, result in approaches_tried:\n",
    "    print(f\"{name:30s} | Score: {score:.6f} | {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION: All local optimization approaches converge to ~70.66\")\n",
    "print(\"The baseline is at an EXTREMELY strong local optimum\")\n",
    "print(\"Need GLOBAL search or fundamentally different representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have NOT been tried?\n",
    "approaches_not_tried = [\n",
    "    'Genetic Algorithm with crossover',\n",
    "    'Basin hopping (random perturbation + local opt)',\n",
    "    'Constraint Programming (CP-SAT)',\n",
    "    'Different starting points (not saspav)',\n",
    "    'Asymmetric solutions (mentioned in discussions)',\n",
    "    'Focus on small N values (N=1-20 have worst efficiency)',\n",
    "    'Hexagonal/triangular lattice with different parameters',\n",
    "    'Greedy constructive with different orderings',\n",
    "    'Backward iteration (from N=200 down)',\n",
    "]\n",
    "\n",
    "print(\"Approaches NOT yet tried:\")\n",
    "print(\"=\"*80)\n",
    "for i, approach in enumerate(approaches_not_tried, 1):\n",
    "    print(f\"{i}. {approach}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRIORITY: Try approaches that can ESCAPE the local optimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4505ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in the snapshots - maybe there are better solutions\n",
    "import glob\n",
    "\n",
    "snapshot_dirs = glob.glob('/home/nonroot/snapshots/santa-2025/*/')\n",
    "print(f\"Found {len(snapshot_dirs)} snapshot directories\")\n",
    "\n",
    "# Check the most recent ones for submission files\n",
    "for snap_dir in sorted(snapshot_dirs)[-5:]:\n",
    "    sub_path = os.path.join(snap_dir, 'submission', 'submission.csv')\n",
    "    if os.path.exists(sub_path):\n",
    "        print(f\"\\n{snap_dir}:\")\n",
    "        df = pd.read_csv(sub_path)\n",
    "        print(f\"  Rows: {len(df)}\")\n",
    "        # Check first few rows\n",
    "        print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763da918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the current best submission and understand its structure\n",
    "baseline_path = '/home/code/external_data/saspav/santa-2025.csv'\n",
    "df = pd.read_csv(baseline_path)\n",
    "\n",
    "print(f\"Baseline submission shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Extract N values\n",
    "df['N'] = df['id'].str.split('_').str[0].astype(int)\n",
    "print(f\"\\nN values range: {df['N'].min()} to {df['N'].max()}\")\n",
    "print(f\"Total configurations: {df['N'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores to find where improvements are most needed\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor),\n",
    "        )\n",
    "\n",
    "def get_score_for_n(df, n):\n",
    "    group = df[df['N'] == n]\n",
    "    trees = []\n",
    "    for _, row in group.iterrows():\n",
    "        x = str(row['x']).lstrip('s')\n",
    "        y = str(row['y']).lstrip('s')\n",
    "        deg = str(row['deg']).lstrip('s')\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    \n",
    "    if not trees:\n",
    "        return float('inf')\n",
    "    \n",
    "    all_polygons = [t.polygon for t in trees]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    \n",
    "    minx = Decimal(bounds[0]) / scale_factor\n",
    "    miny = Decimal(bounds[1]) / scale_factor\n",
    "    maxx = Decimal(bounds[2]) / scale_factor\n",
    "    maxy = Decimal(bounds[3]) / scale_factor\n",
    "    \n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "    side_length = max(width, height)\n",
    "    \n",
    "    return float(side_length * side_length / n)\n",
    "\n",
    "print(\"Calculating per-N scores (this may take a minute)...\")\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    per_n_scores[n] = get_score_for_n(df, n)\n",
    "    if n % 20 == 0:\n",
    "        print(f\"  N={n}: {per_n_scores[n]:.6f}\")\n",
    "\n",
    "print(f\"\\nTotal score: {sum(per_n_scores.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9dd45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find N values with worst efficiency (highest score contribution)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores_df = pd.DataFrame([\n",
    "    {'N': n, 'score': s, 'efficiency': s * n / (n * 1.0)}  # s^2/n, so efficiency = s^2\n",
    "    for n, s in per_n_scores.items()\n",
    "])\n",
    "\n",
    "# Sort by score (highest first = worst efficiency)\n",
    "worst_n = scores_df.nlargest(20, 'score')\n",
    "print(\"Top 20 N values with WORST efficiency (highest score contribution):\")\n",
    "print(worst_n.to_string(index=False))\n",
    "\n",
    "# Calculate cumulative contribution\n",
    "scores_df = scores_df.sort_values('score', ascending=False)\n",
    "scores_df['cumulative_pct'] = scores_df['score'].cumsum() / scores_df['score'].sum() * 100\n",
    "print(f\"\\nTop 10 N values contribute {scores_df.head(10)['score'].sum() / scores_df['score'].sum() * 100:.1f}% of total score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What would it take to reach the target?\n",
    "target = 68.919154\n",
    "current = sum(per_n_scores.values())\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap to close: {gap:.6f}\")\n",
    "print(f\"Gap percentage: {gap/current*100:.2f}%\")\n",
    "\n",
    "# If we improved each N proportionally, how much improvement per N?\n",
    "avg_improvement_per_n = gap / 200\n",
    "print(f\"\\nAverage improvement needed per N: {avg_improvement_per_n:.6f}\")\n",
    "\n",
    "# Focus on worst N values - if we improved just the top 20 worst\n",
    "top20_contribution = scores_df.head(20)['score'].sum()\n",
    "print(f\"\\nTop 20 worst N values contribute: {top20_contribution:.6f} ({top20_contribution/current*100:.1f}%)\")\n",
    "print(f\"If we improved these by 10%: {top20_contribution * 0.1:.6f} improvement\")\n",
    "print(f\"If we improved these by 20%: {top20_contribution * 0.2:.6f} improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"=\"*80)\n",
    "print(\"STRATEGIC ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. CURRENT STATE:\n",
    "   - Best score: 70.659959\n",
    "   - Target: 68.919154\n",
    "   - Gap: 1.74 points (2.5%)\n",
    "   - All local optimization approaches converge to ~70.66\n",
    "\n",
    "2. WHY LOCAL OPTIMIZATION FAILS:\n",
    "   - The saspav baseline is at an EXTREMELY strong local optimum\n",
    "   - SA, bbox3, rotation optimization all show ~0 improvement\n",
    "   - The solution space has many local optima, but we're stuck in one\n",
    "\n",
    "3. APPROACHES TO TRY:\n",
    "   a) GENETIC ALGORITHM:\n",
    "      - Crossover between different configurations\n",
    "      - Can escape local optima by combining good parts\n",
    "   \n",
    "   b) BASIN HOPPING:\n",
    "      - Random large perturbation + local optimization\n",
    "      - Explores different basins of attraction\n",
    "   \n",
    "   c) FOCUS ON SMALL N:\n",
    "      - N=1-20 have worst efficiency\n",
    "      - Manual optimization or exhaustive search may be feasible\n",
    "   \n",
    "   d) DIFFERENT STARTING POINTS:\n",
    "      - Don't start from saspav baseline\n",
    "      - Try lattice-based or random initial solutions\n",
    "   \n",
    "   e) ASYMMETRIC SOLUTIONS:\n",
    "      - Discussions mention asymmetric solutions outperform symmetric\n",
    "      - Break symmetry in current solutions\n",
    "\n",
    "4. PRIORITY:\n",
    "   - Try Genetic Algorithm first (can escape local optima)\n",
    "   - Focus on small N values (highest improvement potential)\n",
    "   - Explore different starting configurations\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
