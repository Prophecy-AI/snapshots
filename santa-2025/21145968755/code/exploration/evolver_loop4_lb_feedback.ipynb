{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10722417",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 - LB Feedback Analysis\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The evaluator correctly identified that we've only used 4 pre-optimized sources, but there are 15+ available in the snapshots directory. The Jonathan Chan kernel achieves better scores by ensembling from many more sources.\n",
    "\n",
    "## Plan\n",
    "1. Comprehensively scan ALL pre-optimized CSVs\n",
    "2. Score each one and identify best per-N\n",
    "3. Build ensemble picking best per-N from ALL sources\n",
    "4. Analyze which N values have room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2abbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    angle_rad = np.radians(deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    vertices = [(tx * cos_a - ty * sin_a + x, tx * sin_a + ty * cos_a + y) for tx, ty in zip(TX, TY)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def compute_bounding_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_points = []\n",
    "    for poly in polygons:\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) != n:\n",
    "        return float('inf')\n",
    "    polygons = [create_tree_polygon(parse_value(row['x']), parse_value(row['y']), parse_value(row['deg'])) for _, row in trees.iterrows()]\n",
    "    side = compute_bounding_side(polygons)\n",
    "    return side**2 / n\n",
    "\n",
    "def compute_total_score(df):\n",
    "    return sum(compute_score_for_n(df, n) for n in range(1, 201))\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan ALL pre-optimized CSVs\n",
    "base_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "\n",
    "# Find all CSV files recursively\n",
    "all_csvs = glob.glob(f'{base_path}/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(all_csvs)} CSV files\")\n",
    "\n",
    "# Also check external data\n",
    "external_csvs = glob.glob('/home/code/external_data/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(external_csvs)} external CSV files\")\n",
    "\n",
    "all_csvs.extend(external_csvs)\n",
    "print(f\"Total: {len(all_csvs)} CSV files to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c164b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and score each CSV\n",
    "scores = {}\n",
    "per_n_scores = {}  # {source: {n: score}}\n",
    "\n",
    "for csv_path in tqdm(all_csvs):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Check if it has all N values\n",
    "        total_score = compute_total_score(df)\n",
    "        if total_score < float('inf'):\n",
    "            source_name = csv_path.replace(base_path, '').replace('/home/code/external_data/', 'ext:')\n",
    "            scores[source_name] = total_score\n",
    "            \n",
    "            # Compute per-N scores\n",
    "            per_n_scores[source_name] = {}\n",
    "            for n in range(1, 201):\n",
    "                per_n_scores[source_name][n] = compute_score_for_n(df, n)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_path}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully scored {len(scores)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by score\n",
    "sorted_scores = sorted(scores.items(), key=lambda x: x[1])\n",
    "print(\"Top 20 pre-optimized solutions:\")\n",
    "print(\"=\"*60)\n",
    "for i, (source, score) in enumerate(sorted_scores[:20]):\n",
    "    print(f\"{i+1:2d}. {score:.6f} - {source}\")\n",
    "\n",
    "print(f\"\\nBest score: {sorted_scores[0][1]:.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {sorted_scores[0][1] - 68.919154:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble picking best per-N from ALL sources\n",
    "print(\"\\nBuilding comprehensive ensemble...\")\n",
    "\n",
    "best_per_n = {}  # {n: (best_score, best_source)}\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    for source, n_scores in per_n_scores.items():\n",
    "        if n in n_scores and n_scores[n] < best_score:\n",
    "            best_score = n_scores[n]\n",
    "            best_source = source\n",
    "    best_per_n[n] = (best_score, best_source)\n",
    "\n",
    "# Count wins per source\n",
    "wins_per_source = {}\n",
    "for n, (score, source) in best_per_n.items():\n",
    "    wins_per_source[source] = wins_per_source.get(source, 0) + 1\n",
    "\n",
    "print(\"\\nWins per source:\")\n",
    "for source, wins in sorted(wins_per_source.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {wins:3d} wins: {source}\")\n",
    "\n",
    "# Calculate ensemble score\n",
    "ensemble_score = sum(score for score, _ in best_per_n.values())\n",
    "print(f\"\\nEnsemble score (best per-N from all sources): {ensemble_score:.6f}\")\n",
    "print(f\"Best single source: {sorted_scores[0][1]:.6f}\")\n",
    "print(f\"Improvement from ensemble: {sorted_scores[0][1] - ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0675df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values have room for improvement\n",
    "print(\"\\nPer-N analysis - looking for improvement opportunities:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get best source's per-N scores\n",
    "best_source = sorted_scores[0][0]\n",
    "best_source_scores = per_n_scores[best_source]\n",
    "\n",
    "# Compare to ensemble\n",
    "print(\"N values where ensemble beats best single source:\")\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    best_single = best_source_scores[n]\n",
    "    ensemble_n = best_per_n[n][0]\n",
    "    if ensemble_n < best_single - 1e-9:\n",
    "        improvements.append((n, best_single - ensemble_n, best_per_n[n][1]))\n",
    "        print(f\"  N={n}: {best_single:.6f} -> {ensemble_n:.6f} (improvement: {best_single - ensemble_n:.6f}) from {best_per_n[n][1]}\")\n",
    "\n",
    "if not improvements:\n",
    "    print(\"  None - best single source wins for all N values\")\n",
    "else:\n",
    "    print(f\"\\nTotal improvements: {len(improvements)} N values\")\n",
    "    print(f\"Total score improvement: {sum(imp[1] for imp in improvements):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1998a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at theoretical optimal efficiency\n",
    "print(\"\\nEfficiency analysis (score_n / n):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    score_n = best_per_n[n][0]\n",
    "    efficiency = score_n  # Already normalized by n\n",
    "    efficiencies.append((n, efficiency))\n",
    "\n",
    "# Sort by efficiency (worst first)\n",
    "efficiencies.sort(key=lambda x: -x[1])\n",
    "\n",
    "print(\"Worst 20 N values (most room for improvement):\")\n",
    "for n, eff in efficiencies[:20]:\n",
    "    print(f\"  N={n:3d}: efficiency={eff:.6f}\")\n",
    "\n",
    "print(\"\\nBest 20 N values:\")\n",
    "for n, eff in efficiencies[-20:]:\n",
    "    print(f\"  N={n:3d}: efficiency={eff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f19c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ensemble submission\n",
    "print(\"\\nCreating ensemble submission...\")\n",
    "\n",
    "# Load all source dataframes\n",
    "source_dfs = {}\n",
    "for source in wins_per_source.keys():\n",
    "    if source.startswith('ext:'):\n",
    "        path = '/home/code/external_data/' + source[4:]\n",
    "    else:\n",
    "        path = base_path + source\n",
    "    source_dfs[source] = pd.read_csv(path)\n",
    "\n",
    "# Build ensemble\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    best_score, best_source = best_per_n[n]\n",
    "    df = source_dfs[best_source]\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    for _, row in trees.iterrows():\n",
    "        ensemble_rows.append(row.to_dict())\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved ensemble with {len(ensemble_df)} rows\")\n",
    "\n",
    "# Verify\n",
    "df_verify = pd.read_csv('/home/submission/submission.csv')\n",
    "verify_score = compute_total_score(df_verify)\n",
    "print(f\"Verified ensemble score: {verify_score:.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {verify_score - 68.919154:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
