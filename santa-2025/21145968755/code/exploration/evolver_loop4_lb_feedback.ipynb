{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10722417",
   "metadata": {},
   "source": [
    "# Evolver Loop 4 - LB Feedback Analysis\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The evaluator correctly identified that we've only used 4 pre-optimized sources, but there are 15+ available in the snapshots directory. The Jonathan Chan kernel achieves better scores by ensembling from many more sources.\n",
    "\n",
    "## Plan\n",
    "1. Comprehensively scan ALL pre-optimized CSVs\n",
    "2. Score each one and identify best per-N\n",
    "3. Build ensemble picking best per-N from ALL sources\n",
    "4. Analyze which N values have room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2abbbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:45:19.714580Z",
     "iopub.status.busy": "2026-01-19T18:45:19.714164Z",
     "iopub.status.idle": "2026-01-19T18:45:20.034716Z",
     "shell.execute_reply": "2026-01-19T18:45:20.034299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    angle_rad = np.radians(deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    vertices = [(tx * cos_a - ty * sin_a + x, tx * sin_a + ty * cos_a + y) for tx, ty in zip(TX, TY)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def compute_bounding_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_points = []\n",
    "    for poly in polygons:\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) != n:\n",
    "        return float('inf')\n",
    "    polygons = [create_tree_polygon(parse_value(row['x']), parse_value(row['y']), parse_value(row['deg'])) for _, row in trees.iterrows()]\n",
    "    side = compute_bounding_side(polygons)\n",
    "    return side**2 / n\n",
    "\n",
    "def compute_total_score(df):\n",
    "    return sum(compute_score_for_n(df, n) for n in range(1, 201))\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ec0676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:45:20.035982Z",
     "iopub.status.busy": "2026-01-19T18:45:20.035835Z",
     "iopub.status.idle": "2026-01-19T18:45:20.039490Z",
     "shell.execute_reply": "2026-01-19T18:45:20.039139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 CSV files\n",
      "Found 7 external CSV files\n",
      "Total: 37 CSV files to evaluate\n"
     ]
    }
   ],
   "source": [
    "# Scan ALL pre-optimized CSVs\n",
    "base_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "\n",
    "# Find all CSV files recursively\n",
    "all_csvs = glob.glob(f'{base_path}/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(all_csvs)} CSV files\")\n",
    "\n",
    "# Also check external data\n",
    "external_csvs = glob.glob('/home/code/external_data/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(external_csvs)} external CSV files\")\n",
    "\n",
    "all_csvs.extend(external_csvs)\n",
    "print(f\"Total: {len(all_csvs)} CSV files to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c164b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T18:45:20.040337Z",
     "iopub.status.busy": "2026-01-19T18:45:20.040243Z",
     "iopub.status.idle": "2026-01-19T18:47:44.422477Z",
     "shell.execute_reply": "2026-01-19T18:47:44.422054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/37 [00:03<02:19,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/37 [00:07<02:16,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/37 [00:11<02:13,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 4/37 [00:15<02:09,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 5/37 [00:19<02:04,  3.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 6/37 [00:23<02:00,  3.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 7/37 [00:27<01:56,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 8/37 [00:31<01:52,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 9/37 [00:35<01:48,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 10/37 [00:38<01:44,  3.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 11/37 [00:42<01:40,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 12/37 [00:46<01:36,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 13/37 [00:50<01:32,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 14/37 [00:54<01:28,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 15/37 [00:58<01:25,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 16/37 [01:02<01:21,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 17/37 [01:05<01:17,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 18/37 [01:09<01:13,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 19/37 [01:13<01:09,  3.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 20/37 [01:17<01:06,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 21/37 [01:21<01:02,  3.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 22/37 [01:25<00:58,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 23/37 [01:29<00:54,  3.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 24/37 [01:33<00:50,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 25/37 [01:37<00:46,  3.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 26/37 [01:41<00:43,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 27/37 [01:45<00:39,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 28/37 [01:49<00:35,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 29/37 [01:52<00:31,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 30/37 [01:56<00:27,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 31/37 [02:00<00:23,  3.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 32/37 [02:04<00:19,  3.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 33/37 [02:08<00:15,  3.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 34/37 [02:12<00:11,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 35/37 [02:16<00:07,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 36/37 [02:20<00:03,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 37/37 [02:24<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 37/37 [02:24<00:00,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully scored 37 CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and score each CSV\n",
    "scores = {}\n",
    "per_n_scores = {}  # {source: {n: score}}\n",
    "\n",
    "for csv_path in tqdm(all_csvs):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Check if it has all N values\n",
    "        total_score = compute_total_score(df)\n",
    "        if total_score < float('inf'):\n",
    "            source_name = csv_path.replace(base_path, '').replace('/home/code/external_data/', 'ext:')\n",
    "            scores[source_name] = total_score\n",
    "            \n",
    "            # Compute per-N scores\n",
    "            per_n_scores[source_name] = {}\n",
    "            for n in range(1, 201):\n",
    "                per_n_scores[source_name][n] = compute_score_for_n(df, n)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_path}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully scored {len(scores)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by score\n",
    "sorted_scores = sorted(scores.items(), key=lambda x: x[1])\n",
    "print(\"Top 20 pre-optimized solutions:\")\n",
    "print(\"=\"*60)\n",
    "for i, (source, score) in enumerate(sorted_scores[:20]):\n",
    "    print(f\"{i+1:2d}. {score:.6f} - {source}\")\n",
    "\n",
    "print(f\"\\nBest score: {sorted_scores[0][1]:.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {sorted_scores[0][1] - 68.919154:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble picking best per-N from ALL sources\n",
    "print(\"\\nBuilding comprehensive ensemble...\")\n",
    "\n",
    "best_per_n = {}  # {n: (best_score, best_source)}\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    for source, n_scores in per_n_scores.items():\n",
    "        if n in n_scores and n_scores[n] < best_score:\n",
    "            best_score = n_scores[n]\n",
    "            best_source = source\n",
    "    best_per_n[n] = (best_score, best_source)\n",
    "\n",
    "# Count wins per source\n",
    "wins_per_source = {}\n",
    "for n, (score, source) in best_per_n.items():\n",
    "    wins_per_source[source] = wins_per_source.get(source, 0) + 1\n",
    "\n",
    "print(\"\\nWins per source:\")\n",
    "for source, wins in sorted(wins_per_source.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {wins:3d} wins: {source}\")\n",
    "\n",
    "# Calculate ensemble score\n",
    "ensemble_score = sum(score for score, _ in best_per_n.values())\n",
    "print(f\"\\nEnsemble score (best per-N from all sources): {ensemble_score:.6f}\")\n",
    "print(f\"Best single source: {sorted_scores[0][1]:.6f}\")\n",
    "print(f\"Improvement from ensemble: {sorted_scores[0][1] - ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0675df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values have room for improvement\n",
    "print(\"\\nPer-N analysis - looking for improvement opportunities:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get best source's per-N scores\n",
    "best_source = sorted_scores[0][0]\n",
    "best_source_scores = per_n_scores[best_source]\n",
    "\n",
    "# Compare to ensemble\n",
    "print(\"N values where ensemble beats best single source:\")\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    best_single = best_source_scores[n]\n",
    "    ensemble_n = best_per_n[n][0]\n",
    "    if ensemble_n < best_single - 1e-9:\n",
    "        improvements.append((n, best_single - ensemble_n, best_per_n[n][1]))\n",
    "        print(f\"  N={n}: {best_single:.6f} -> {ensemble_n:.6f} (improvement: {best_single - ensemble_n:.6f}) from {best_per_n[n][1]}\")\n",
    "\n",
    "if not improvements:\n",
    "    print(\"  None - best single source wins for all N values\")\n",
    "else:\n",
    "    print(f\"\\nTotal improvements: {len(improvements)} N values\")\n",
    "    print(f\"Total score improvement: {sum(imp[1] for imp in improvements):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1998a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at theoretical optimal efficiency\n",
    "print(\"\\nEfficiency analysis (score_n / n):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    score_n = best_per_n[n][0]\n",
    "    efficiency = score_n  # Already normalized by n\n",
    "    efficiencies.append((n, efficiency))\n",
    "\n",
    "# Sort by efficiency (worst first)\n",
    "efficiencies.sort(key=lambda x: -x[1])\n",
    "\n",
    "print(\"Worst 20 N values (most room for improvement):\")\n",
    "for n, eff in efficiencies[:20]:\n",
    "    print(f\"  N={n:3d}: efficiency={eff:.6f}\")\n",
    "\n",
    "print(\"\\nBest 20 N values:\")\n",
    "for n, eff in efficiencies[-20:]:\n",
    "    print(f\"  N={n:3d}: efficiency={eff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f19c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ensemble submission\n",
    "print(\"\\nCreating ensemble submission...\")\n",
    "\n",
    "# Load all source dataframes\n",
    "source_dfs = {}\n",
    "for source in wins_per_source.keys():\n",
    "    if source.startswith('ext:'):\n",
    "        path = '/home/code/external_data/' + source[4:]\n",
    "    else:\n",
    "        path = base_path + source\n",
    "    source_dfs[source] = pd.read_csv(path)\n",
    "\n",
    "# Build ensemble\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    best_score, best_source = best_per_n[n]\n",
    "    df = source_dfs[best_source]\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    for _, row in trees.iterrows():\n",
    "        ensemble_rows.append(row.to_dict())\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved ensemble with {len(ensemble_df)} rows\")\n",
    "\n",
    "# Verify\n",
    "df_verify = pd.read_csv('/home/submission/submission.csv')\n",
    "verify_score = compute_total_score(df_verify)\n",
    "print(f\"Verified ensemble score: {verify_score:.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {verify_score - 68.919154:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
