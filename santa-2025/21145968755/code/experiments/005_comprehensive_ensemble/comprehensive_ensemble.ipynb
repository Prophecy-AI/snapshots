{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b316bd63",
   "metadata": {},
   "source": [
    "# Experiment 005: Comprehensive Ensemble from ALL Sources\n",
    "\n",
    "The evaluator identified that we haven't explored all pre-optimized sources.\n",
    "There are 692 CSV files in the snapshots directory!\n",
    "\n",
    "This experiment will:\n",
    "1. Scan ALL CSV files\n",
    "2. Score each per-N\n",
    "3. Build ensemble picking best per-N from ALL sources\n",
    "4. Compare to current best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Tree geometry\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    angle_rad = np.radians(deg)\n",
    "    cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    vertices = [(tx * cos_a - ty * sin_a + x, tx * sin_a + ty * cos_a + y) for tx, ty in zip(TX, TY)]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def compute_bounding_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_points = []\n",
    "    for poly in polygons:\n",
    "        all_points.extend(list(poly.exterior.coords))\n",
    "    all_points = np.array(all_points)\n",
    "    return max(all_points.max(axis=0) - all_points.min(axis=0))\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    trees = df[df['id'].str.startswith(prefix)]\n",
    "    if len(trees) != n:\n",
    "        return float('inf'), None\n",
    "    polygons = [create_tree_polygon(parse_value(row['x']), parse_value(row['y']), parse_value(row['deg'])) for _, row in trees.iterrows()]\n",
    "    side = compute_bounding_side(polygons)\n",
    "    return side**2 / n, trees\n",
    "\n",
    "def compute_total_score(df):\n",
    "    return sum(compute_score_for_n(df, n)[0] for n in range(1, 201))\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb844187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ALL CSV files in snapshots\n",
    "all_csvs = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(all_csvs)} CSV files\")\n",
    "\n",
    "# Also add external data CSVs\n",
    "external_csvs = glob.glob('/home/code/external_data/**/*.csv', recursive=True)\n",
    "all_csvs.extend(external_csvs)\n",
    "print(f\"Total with external data: {len(all_csvs)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate each CSV, keeping only valid submission files\n",
    "valid_sources = []\n",
    "\n",
    "for csv_path in tqdm(all_csvs, desc=\"Scanning CSVs\"):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Check if it's a valid submission file\n",
    "        if 'id' in df.columns and 'x' in df.columns and 'y' in df.columns and 'deg' in df.columns:\n",
    "            # Check if it has the right number of rows (20100 for complete submission)\n",
    "            if len(df) >= 20000:  # Allow some flexibility\n",
    "                valid_sources.append(csv_path)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nFound {len(valid_sources)} valid submission files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8002865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score each valid source and find total score\n",
    "print(\"Scoring each source...\")\n",
    "source_scores = []\n",
    "\n",
    "for csv_path in tqdm(valid_sources, desc=\"Scoring sources\"):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        total_score = compute_total_score(df)\n",
    "        if total_score < 200:  # Sanity check - valid scores should be < 200\n",
    "            source_scores.append((csv_path, total_score))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "# Sort by score\n",
    "source_scores.sort(key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nTop 20 sources by total score:\")\n",
    "for path, score in source_scores[:20]:\n",
    "    print(f\"  {score:.6f}: {path.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45908eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive ensemble: for each N, find the best source\n",
    "print(\"\\nBuilding comprehensive ensemble...\")\n",
    "\n",
    "# Load all valid dataframes\n",
    "all_dfs = {}\n",
    "for path, score in tqdm(source_scores, desc=\"Loading dataframes\"):\n",
    "    try:\n",
    "        all_dfs[path] = pd.read_csv(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"Loaded {len(all_dfs)} dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N, find the best source\n",
    "best_per_n = {}  # n -> (score, source_path, trees_df)\n",
    "\n",
    "for n in tqdm(range(1, 201), desc=\"Finding best per N\"):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    best_trees = None\n",
    "    \n",
    "    for path, df in all_dfs.items():\n",
    "        score, trees = compute_score_for_n(df, n)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_source = path\n",
    "            best_trees = trees\n",
    "    \n",
    "    best_per_n[n] = (best_score, best_source, best_trees)\n",
    "\n",
    "# Compute ensemble total\n",
    "ensemble_total = sum(best_per_n[n][0] for n in range(1, 201))\n",
    "print(f\"\\nEnsemble total score: {ensemble_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which sources win for which N values\n",
    "source_wins = {}\n",
    "for n in range(1, 201):\n",
    "    source = best_per_n[n][1]\n",
    "    source_name = source.split('/')[-1] if source else 'None'\n",
    "    source_wins[source_name] = source_wins.get(source_name, 0) + 1\n",
    "\n",
    "print(\"Source wins distribution:\")\n",
    "for source, wins in sorted(source_wins.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {wins} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to current best\n",
    "df_baseline = pd.read_csv('/home/code/external_data/saspav/santa-2025.csv')\n",
    "baseline_total = compute_total_score(df_baseline)\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"Baseline (saspav): {baseline_total:.6f}\")\n",
    "print(f\"Comprehensive ensemble: {ensemble_total:.6f}\")\n",
    "print(f\"Improvement: {baseline_total - ensemble_total:.9f}\")\n",
    "\n",
    "# Show N values where ensemble is different from baseline\n",
    "print(\"\\nN values where ensemble differs from baseline:\")\n",
    "for n in range(1, 201):\n",
    "    baseline_score, _ = compute_score_for_n(df_baseline, n)\n",
    "    ensemble_score = best_per_n[n][0]\n",
    "    if abs(ensemble_score - baseline_score) > 1e-9:\n",
    "        source_name = best_per_n[n][1].split('/')[-1] if best_per_n[n][1] else 'None'\n",
    "        print(f\"  N={n}: baseline={baseline_score:.6f}, ensemble={ensemble_score:.6f}, diff={ensemble_score-baseline_score:.9f}, source={source_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ensemble submission\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    trees = best_per_n[n][2]\n",
    "    if trees is not None:\n",
    "        for _, row in trees.iterrows():\n",
    "            ensemble_rows.append(row.to_dict())\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved ensemble with {len(ensemble_df)} rows\")\n",
    "\n",
    "# Verify\n",
    "df_verify = pd.read_csv('/home/submission/submission.csv')\n",
    "verify_score = compute_total_score(df_verify)\n",
    "print(f\"Verified ensemble score: {verify_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 005 SUMMARY: Comprehensive Ensemble\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total CSV files scanned: {len(all_csvs)}\")\n",
    "print(f\"Valid submission files: {len(valid_sources)}\")\n",
    "print(f\"Sources with valid scores: {len(source_scores)}\")\n",
    "print(f\"\\nBest single source: {source_scores[0][1]:.6f} ({source_scores[0][0].split('/')[-1]})\")\n",
    "print(f\"Comprehensive ensemble: {verify_score:.6f}\")\n",
    "print(f\"Improvement over best single: {source_scores[0][1] - verify_score:.9f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8544280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wrapper for submission\n",
    "class ComprehensiveEnsemble:\n",
    "    def __init__(self, data='single'):\n",
    "        self.data = data\n",
    "        \n",
    "    def load_best(self):\n",
    "        return pd.read_csv('/home/submission/submission.csv')\n",
    "    \n",
    "    def save_submission(self, path):\n",
    "        df = self.load_best()\n",
    "        df.to_csv(path, index=False)\n",
    "        return df\n",
    "\n",
    "model = ComprehensiveEnsemble(data='single')\n",
    "print(\"Model wrapper defined\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
