{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0c39dc",
   "metadata": {},
   "source": [
    "# Experiment 033: Comprehensive Ensemble from ALL Sources\n",
    "\n",
    "The ONLY approach that has yielded improvements is ensemble methods combining solutions from different sources.\n",
    "\n",
    "This experiment will:\n",
    "1. Collect ALL CSV files from all directories\n",
    "2. For each N=1-200, load solutions from ALL sources\n",
    "3. Validate each solution (no overlaps)\n",
    "4. Pick the best valid solution for each N\n",
    "5. Create ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d577508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:52:27.152454Z",
     "iopub.status.busy": "2026-01-22T00:52:27.151958Z",
     "iopub.status.idle": "2026-01-22T00:52:27.483909Z",
     "shell.execute_reply": "2026-01-22T00:52:27.483482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Tree shape\n",
    "TREE_VERTICES = np.array([\n",
    "    [0.0, 0.8], [0.125, 0.5], [0.0625, 0.5], [0.2, 0.25], [0.1, 0.25],\n",
    "    [0.35, 0.0], [0.075, 0.0], [0.075, -0.2], [-0.075, -0.2], [-0.075, 0.0],\n",
    "    [-0.35, 0.0], [-0.1, 0.25], [-0.2, 0.25], [-0.0625, 0.5], [-0.125, 0.5],\n",
    "], dtype=np.float64)\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    tree = Polygon(TREE_VERTICES)\n",
    "    tree = rotate(tree, deg, origin=(0, 0))\n",
    "    tree = translate(tree, x, y)\n",
    "    return tree\n",
    "\n",
    "def check_overlap(trees):\n",
    "    n = len(trees)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if trees[i].overlaps(trees[j]) or trees[i].contains(trees[j]) or trees[j].contains(trees[i]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def calculate_score(trees):\n",
    "    all_bounds = [t.bounds for t in trees]\n",
    "    min_x = min(b[0] for b in all_bounds)\n",
    "    min_y = min(b[1] for b in all_bounds)\n",
    "    max_x = max(b[2] for b in all_bounds)\n",
    "    max_y = max(b[3] for b in all_bounds)\n",
    "    side = max(max_x - min_x, max_y - min_y)\n",
    "    return side * side / len(trees)\n",
    "\n",
    "def parse_value(v):\n",
    "    if isinstance(v, str) and v.startswith('s'):\n",
    "        return float(v[1:])\n",
    "    return float(v)\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a210d767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:52:27.485148Z",
     "iopub.status.busy": "2026-01-22T00:52:27.484986Z",
     "iopub.status.idle": "2026-01-22T00:52:27.490130Z",
     "shell.execute_reply": "2026-01-22T00:52:27.489724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 CSV files\n",
      "  /home/nonroot/snapshots/santa-2025/21165872902/submission/submission.csv\n",
      "  /home/code/exploration/datasets/ensemble_best_v2.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21129620891/submission/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21165878844/submission/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21156853393/submission/submission.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v66.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21222375510/submission/submission.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_JKoT4.csv\n",
      "  /home/code/exploration/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21122904233/submission/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Find ALL CSV files\n",
    "csv_files = []\n",
    "\n",
    "# Main exploration datasets\n",
    "csv_files.extend(glob.glob('/home/code/exploration/datasets/**/*.csv', recursive=True))\n",
    "csv_files.extend(glob.glob('/home/code/exploration/*.csv'))\n",
    "\n",
    "# Snapshot submissions\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/submission/submission.csv'))\n",
    "\n",
    "# Remove duplicates\n",
    "csv_files = list(set(csv_files))\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Show some examples\n",
    "for f in csv_files[:10]:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69a32bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T00:52:27.491431Z",
     "iopub.status.busy": "2026-01-22T00:52:27.491317Z",
     "iopub.status.idle": "2026-01-22T00:52:29.357126Z",
     "shell.execute_reply": "2026-01-22T00:52:29.356743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline total score: 70.624381\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "baseline_configs = {}\n",
    "baseline_scores = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    group = baseline_df[baseline_df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "    configs = []\n",
    "    for _, row in group.iterrows():\n",
    "        x = parse_value(row[\"x\"])\n",
    "        y = parse_value(row[\"y\"])\n",
    "        deg = parse_value(row[\"deg\"])\n",
    "        configs.append((x, y, deg))\n",
    "    baseline_configs[n] = configs\n",
    "    trees = [create_tree_polygon(x, y, deg) for x, y, deg in configs]\n",
    "    baseline_scores[n] = calculate_score(trees)\n",
    "\n",
    "print(f\"Baseline total score: {sum(baseline_scores.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01235bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sources and find best per N\n",
    "best_configs = dict(baseline_configs)\n",
    "best_scores = dict(baseline_scores)\n",
    "best_sources = {n: 'baseline' for n in range(1, 201)}\n",
    "\n",
    "improvements_found = 0\n",
    "total_improvement = 0.0\n",
    "\n",
    "for filepath in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        for n in range(1, 201):\n",
    "            prefix = f\"{n:03d}_\"\n",
    "            group = df[df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "            if len(group) != n:\n",
    "                continue\n",
    "            \n",
    "            configs = []\n",
    "            for _, row in group.iterrows():\n",
    "                x = parse_value(row[\"x\"])\n",
    "                y = parse_value(row[\"y\"])\n",
    "                deg = parse_value(row[\"deg\"])\n",
    "                configs.append((x, y, deg))\n",
    "            \n",
    "            trees = [create_tree_polygon(x, y, deg) for x, y, deg in configs]\n",
    "            \n",
    "            # Check for overlaps\n",
    "            if check_overlap(trees):\n",
    "                continue\n",
    "            \n",
    "            score = calculate_score(trees)\n",
    "            if score < best_scores[n]:\n",
    "                improvement = best_scores[n] - score\n",
    "                if improvement > 1e-6:\n",
    "                    print(f\"N={n}: {best_scores[n]:.6f} -> {score:.6f} (improvement: {improvement:.6f}) from {os.path.basename(filepath)}\")\n",
    "                    improvements_found += 1\n",
    "                    total_improvement += improvement\n",
    "                best_scores[n] = score\n",
    "                best_configs[n] = configs\n",
    "                best_sources[n] = filepath\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal improvements found: {improvements_found}\")\n",
    "print(f\"Total improvement: {total_improvement:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7350e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "old_total = sum(baseline_scores.values())\n",
    "new_total = sum(best_scores.values())\n",
    "\n",
    "print(f\"\\nBaseline total: {old_total:.6f}\")\n",
    "print(f\"Ensemble total: {new_total:.6f}\")\n",
    "print(f\"Improvement: {old_total - new_total:.6f}\")\n",
    "\n",
    "# Count sources\n",
    "source_counts = {}\n",
    "for n, source in best_sources.items():\n",
    "    source_name = os.path.basename(source) if source != 'baseline' else 'baseline'\n",
    "    source_counts[source_name] = source_counts.get(source_name, 0) + 1\n",
    "\n",
    "print(f\"\\nSources used:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {count} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate all groups\n",
    "print(\"\\nValidating all groups...\")\n",
    "overlap_count = 0\n",
    "\n",
    "for n in range(1, 201):\n",
    "    configs = best_configs[n]\n",
    "    trees = [create_tree_polygon(x, y, deg) for x, y, deg in configs]\n",
    "    if check_overlap(trees):\n",
    "        overlap_count += 1\n",
    "        print(f\"  Group {n:03d} has overlaps!\")\n",
    "\n",
    "if overlap_count == 0:\n",
    "    print(\"All groups valid - no overlaps!\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: {overlap_count} groups have overlaps!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a354210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission if improved and valid\n",
    "final_score = sum(best_scores.values())\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "\n",
    "if final_score < baseline_total and overlap_count == 0:\n",
    "    print(f\"\\nSaving improved submission...\")\n",
    "    \n",
    "    rows = []\n",
    "    for n in range(1, 201):\n",
    "        for i, (x, y, deg) in enumerate(best_configs[n]):\n",
    "            rows.append({\n",
    "                \"id\": f\"{n:03d}_{i}\",\n",
    "                \"x\": f\"s{x}\",\n",
    "                \"y\": f\"s{y}\",\n",
    "                \"deg\": f\"s{deg}\",\n",
    "            })\n",
    "    \n",
    "    new_df = pd.DataFrame(rows)\n",
    "    new_df.to_csv(\"/home/submission/submission.csv\", index=False)\n",
    "    print(f\"Saved to /home/submission/submission.csv\")\n",
    "    print(f\"New total score: {final_score:.9f}\")\n",
    "else:\n",
    "    print(f\"\\nNo improvement or invalid - keeping baseline\")\n",
    "    print(f\"Baseline score: {baseline_total:.9f}\")\n",
    "    final_score = baseline_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': final_score,\n",
    "    'baseline_score': baseline_total,\n",
    "    'improvement': baseline_total - final_score,\n",
    "    'improvements_found': improvements_found,\n",
    "    'total_sources_checked': len(csv_files),\n",
    "    'overlap_count': overlap_count,\n",
    "    'approach': 'Comprehensive ensemble from ALL CSV sources'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/033_comprehensive_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\nMetrics saved:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
