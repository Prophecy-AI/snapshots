{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d03d5b",
   "metadata": {},
   "source": [
    "# Experiment 031: jiweiliu Fast SA with Deletion Cascade\n",
    "\n",
    "Implementing the jiweiliu kernel's approach:\n",
    "1. Generate grid configurations with varying ncols, nrows, append_x, append_y\n",
    "2. Run SA optimization on each configuration\n",
    "3. Apply deletion cascade - propagate good large configs to smaller N\n",
    "4. This generates FUNDAMENTALLY DIFFERENT solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03940e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from numba.typed import List as NumbaList\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "\n",
    "print(f\"CPU count: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree shape constants (must match official spec)\n",
    "TRUNK_W = 0.15\n",
    "TRUNK_H = 0.2\n",
    "BASE_W = 0.7\n",
    "MID_W = 0.4\n",
    "TOP_W = 0.25\n",
    "TIP_Y = 0.8\n",
    "TIER_1_Y = 0.5\n",
    "TIER_2_Y = 0.25\n",
    "BASE_Y = 0.0\n",
    "TRUNK_BOTTOM_Y = -TRUNK_H\n",
    "\n",
    "# Maximum distance between tree centers for possible overlap\n",
    "MAX_OVERLAP_DIST = 1.8\n",
    "MAX_OVERLAP_DIST_SQ = MAX_OVERLAP_DIST * MAX_OVERLAP_DIST\n",
    "\n",
    "# Tree vertices in canonical position\n",
    "TREE_VERTICES = np.array([\n",
    "    [0.0, TIP_Y],\n",
    "    [TOP_W / 2.0, TIER_1_Y],\n",
    "    [TOP_W / 4.0, TIER_1_Y],\n",
    "    [MID_W / 2.0, TIER_2_Y],\n",
    "    [MID_W / 4.0, TIER_2_Y],\n",
    "    [BASE_W / 2.0, BASE_Y],\n",
    "    [TRUNK_W / 2.0, BASE_Y],\n",
    "    [TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "    [-TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "    [-TRUNK_W / 2.0, BASE_Y],\n",
    "    [-BASE_W / 2.0, BASE_Y],\n",
    "    [-MID_W / 4.0, TIER_2_Y],\n",
    "    [-MID_W / 2.0, TIER_2_Y],\n",
    "    [-TOP_W / 4.0, TIER_1_Y],\n",
    "    [-TOP_W / 2.0, TIER_1_Y],\n",
    "], dtype=np.float64)\n",
    "\n",
    "print(f\"Tree vertices: {len(TREE_VERTICES)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def rotate_point(x, y, cos_a, sin_a):\n",
    "    return x * cos_a - y * sin_a, x * sin_a + y * cos_a\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_tree_vertices(cx, cy, angle_deg):\n",
    "    \"\"\"Get 15 vertices of tree polygon at given position and angle.\"\"\"\n",
    "    angle_rad = angle_deg * math.pi / 180.0\n",
    "    cos_a = math.cos(angle_rad)\n",
    "    sin_a = math.sin(angle_rad)\n",
    "    vertices = np.empty((15, 2), dtype=np.float64)\n",
    "    pts = np.array([\n",
    "        [0.0, 0.8],\n",
    "        [0.125, 0.5],\n",
    "        [0.0625, 0.5],\n",
    "        [0.2, 0.25],\n",
    "        [0.1, 0.25],\n",
    "        [0.35, 0.0],\n",
    "        [0.075, 0.0],\n",
    "        [0.075, -0.2],\n",
    "        [-0.075, -0.2],\n",
    "        [-0.075, 0.0],\n",
    "        [-0.35, 0.0],\n",
    "        [-0.1, 0.25],\n",
    "        [-0.2, 0.25],\n",
    "        [-0.0625, 0.5],\n",
    "        [-0.125, 0.5],\n",
    "    ], dtype=np.float64)\n",
    "    for i in range(15):\n",
    "        rx, ry = rotate_point(pts[i, 0], pts[i, 1], cos_a, sin_a)\n",
    "        vertices[i, 0] = rx + cx\n",
    "        vertices[i, 1] = ry + cy\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def polygon_bounds(vertices):\n",
    "    \"\"\"Get bounding box of polygon vertices.\"\"\"\n",
    "    min_x = vertices[0, 0]\n",
    "    min_y = vertices[0, 1]\n",
    "    max_x = vertices[0, 0]\n",
    "    max_y = vertices[0, 1]\n",
    "    for i in range(1, vertices.shape[0]):\n",
    "        x = vertices[i, 0]\n",
    "        y = vertices[i, 1]\n",
    "        if x < min_x:\n",
    "            min_x = x\n",
    "        if x > max_x:\n",
    "            max_x = x\n",
    "        if y < min_y:\n",
    "            min_y = y\n",
    "        if y > max_y:\n",
    "            max_y = y\n",
    "    return min_x, min_y, max_x, max_y\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def point_in_polygon(px, py, vertices):\n",
    "    \"\"\"Check if point is inside polygon using ray casting.\"\"\"\n",
    "    n = vertices.shape[0]\n",
    "    inside = False\n",
    "    j = n - 1\n",
    "    for i in range(n):\n",
    "        xi, yi = vertices[i, 0], vertices[i, 1]\n",
    "        xj, yj = vertices[j, 0], vertices[j, 1]\n",
    "        if ((yi > py) != (yj > py)) and (px < (xj - xi) * (py - yi) / (yj - yi) + xi):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "    return inside\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def segments_intersect(p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y):\n",
    "    \"\"\"Check if two line segments intersect.\"\"\"\n",
    "    dax = p2x - p1x\n",
    "    day = p2y - p1y\n",
    "    dbx = p4x - p3x\n",
    "    dby = p4y - p3y\n",
    "\n",
    "    d1x = p1x - p3x\n",
    "    d1y = p1y - p3y\n",
    "    d2x = p2x - p3x\n",
    "    d2y = p2y - p3y\n",
    "\n",
    "    cross_b1 = dbx * d1y - dby * d1x\n",
    "    cross_b2 = dbx * d2y - dby * d2x\n",
    "\n",
    "    if cross_b1 * cross_b2 > 0:\n",
    "        return False\n",
    "\n",
    "    d3x = p3x - p1x\n",
    "    d3y = p3y - p1y\n",
    "    d4x = p4x - p1x\n",
    "    d4y = p4y - p1y\n",
    "\n",
    "    cross_a1 = dax * d3y - day * d3x\n",
    "    cross_a2 = dax * d4y - day * d4x\n",
    "\n",
    "    if cross_a1 * cross_a2 > 0:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def polygons_overlap(verts1, verts2, cx1, cy1, cx2, cy2):\n",
    "    \"\"\"Check if two polygons overlap (not just touch).\"\"\"\n",
    "    # Quick center distance check\n",
    "    dx = cx2 - cx1\n",
    "    dy = cy2 - cy1\n",
    "    dist_sq = dx * dx + dy * dy\n",
    "    if dist_sq > MAX_OVERLAP_DIST_SQ:\n",
    "        return False\n",
    "\n",
    "    # Bounding box check\n",
    "    min_x1, min_y1, max_x1, max_y1 = polygon_bounds(verts1)\n",
    "    min_x2, min_y2, max_x2, max_y2 = polygon_bounds(verts2)\n",
    "    if max_x1 < min_x2 or max_x2 < min_x1 or max_y1 < min_y2 or max_y2 < min_y1:\n",
    "        return False\n",
    "\n",
    "    # Check if any vertex of poly1 is inside poly2\n",
    "    for i in range(verts1.shape[0]):\n",
    "        if point_in_polygon(verts1[i, 0], verts1[i, 1], verts2):\n",
    "            return True\n",
    "\n",
    "    # Check if any vertex of poly2 is inside poly1\n",
    "    for i in range(verts2.shape[0]):\n",
    "        if point_in_polygon(verts2[i, 0], verts2[i, 1], verts1):\n",
    "            return True\n",
    "\n",
    "    # Check edge intersections\n",
    "    n1 = verts1.shape[0]\n",
    "    n2 = verts2.shape[0]\n",
    "    for i in range(n1):\n",
    "        j = (i + 1) % n1\n",
    "        p1x, p1y = verts1[i, 0], verts1[i, 1]\n",
    "        p2x, p2y = verts1[j, 0], verts1[j, 1]\n",
    "        for k in range(n2):\n",
    "            m = (k + 1) % n2\n",
    "            p3x, p3y = verts2[k, 0], verts2[k, 1]\n",
    "            p4x, p4y = verts2[m, 0], verts2[m, 1]\n",
    "            if segments_intersect(p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "    \"\"\"Check if any pair of polygons overlap.\"\"\"\n",
    "    n = len(all_vertices)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if polygons_overlap(all_vertices[i], all_vertices[j],\n",
    "                              centers_x[i], centers_y[i], centers_x[j], centers_y[j]):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def compute_bounding_box(all_vertices):\n",
    "    \"\"\"Compute overall bounding box of all polygons.\"\"\"\n",
    "    min_x = math.inf\n",
    "    min_y = math.inf\n",
    "    max_x = -math.inf\n",
    "    max_y = -math.inf\n",
    "    for verts in all_vertices:\n",
    "        x1, y1, x2, y2 = polygon_bounds(verts)\n",
    "        if x1 < min_x:\n",
    "            min_x = x1\n",
    "        if y1 < min_y:\n",
    "            min_y = y1\n",
    "        if x2 > max_x:\n",
    "            max_x = x2\n",
    "        if y2 > max_y:\n",
    "            max_y = y2\n",
    "    return min_x, min_y, max_x, max_y\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_side_length(all_vertices):\n",
    "    \"\"\"Get side length of bounding square.\"\"\"\n",
    "    min_x, min_y, max_x, max_y = compute_bounding_box(all_vertices)\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_score_numba(all_vertices):\n",
    "    \"\"\"Calculate score = max(width, height)^2 / n\"\"\"\n",
    "    side = get_side_length(all_vertices)\n",
    "    return side * side / len(all_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def create_grid_vertices_extended(seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y):\n",
    "    \"\"\"\n",
    "    Create grid of tree vertices by translation with optional append.\n",
    "    Returns both vertices and center coordinates.\n",
    "    \"\"\"\n",
    "    n_seeds = len(seed_xs)\n",
    "\n",
    "    # Calculate total number of trees\n",
    "    n_base = n_seeds * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_total = n_base + n_append_x + n_append_y\n",
    "\n",
    "    all_vertices = []\n",
    "    centers_x = np.empty(n_total, dtype=np.float64)\n",
    "    centers_y = np.empty(n_total, dtype=np.float64)\n",
    "\n",
    "    idx = 0\n",
    "    # Base grid\n",
    "    for s in range(n_seeds):\n",
    "        for col in range(ncols):\n",
    "            for row in range(nrows):\n",
    "                cx = seed_xs[s] + col * a\n",
    "                cy = seed_ys[s] + row * b\n",
    "                all_vertices.append(get_tree_vertices(cx, cy, seed_degs[s]))\n",
    "                centers_x[idx] = cx\n",
    "                centers_y[idx] = cy\n",
    "                idx += 1\n",
    "\n",
    "    # Append in x direction\n",
    "    if append_x and n_seeds > 1:\n",
    "        for row in range(nrows):\n",
    "            cx = seed_xs[1] + ncols * a\n",
    "            cy = seed_ys[1] + row * b\n",
    "            all_vertices.append(get_tree_vertices(cx, cy, seed_degs[1]))\n",
    "            centers_x[idx] = cx\n",
    "            centers_y[idx] = cy\n",
    "            idx += 1\n",
    "\n",
    "    # Append in y direction\n",
    "    if append_y and n_seeds > 1:\n",
    "        for col in range(ncols):\n",
    "            cx = seed_xs[1] + col * a\n",
    "            cy = seed_ys[1] + nrows * b\n",
    "            all_vertices.append(get_tree_vertices(cx, cy, seed_degs[1]))\n",
    "            centers_x[idx] = cx\n",
    "            centers_y[idx] = cy\n",
    "            idx += 1\n",
    "\n",
    "    return all_vertices, centers_x, centers_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def get_initial_translations(seed_xs, seed_ys, seed_degs):\n",
    "    \"\"\"Get initial translation lengths from seed configuration.\"\"\"\n",
    "    n_seeds = len(seed_xs)\n",
    "    if n_seeds < 2:\n",
    "        return 1.0, 1.0\n",
    "    \n",
    "    # Calculate distances between seeds\n",
    "    dx = seed_xs[1] - seed_xs[0]\n",
    "    dy = seed_ys[1] - seed_ys[0]\n",
    "    \n",
    "    # Use the distance as initial translation\n",
    "    a = abs(dx) if abs(dx) > 0.1 else 0.9\n",
    "    b = abs(dy) if abs(dy) > 0.1 else 0.75\n",
    "    \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d79603",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def sa_optimize_improved(\n",
    "    seed_xs_init,\n",
    "    seed_ys_init,\n",
    "    seed_degs_init,\n",
    "    a_init,\n",
    "    b_init,\n",
    "    ncols,\n",
    "    nrows,\n",
    "    append_x,\n",
    "    append_y,\n",
    "    Tmax,\n",
    "    Tmin,\n",
    "    nsteps,\n",
    "    nsteps_per_T,\n",
    "    position_delta,\n",
    "    angle_delta,\n",
    "    angle_delta2,\n",
    "    delta_t,\n",
    "    random_seed,\n",
    "):\n",
    "    \"\"\"\n",
    "    Improved simulated annealing with:\n",
    "    1. Translation lengths optimized via SA\n",
    "    2. rotate_all move type\n",
    "    3. append_x/append_y support\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n_seeds = len(seed_xs_init)\n",
    "\n",
    "    # Copy initial seeds\n",
    "    seed_xs = seed_xs_init.copy()\n",
    "    seed_ys = seed_ys_init.copy()\n",
    "    seed_degs = seed_degs_init.copy()\n",
    "\n",
    "    # Initial translations\n",
    "    a = a_init\n",
    "    b = b_init\n",
    "\n",
    "    # Create initial grid and check validity\n",
    "    all_vertices, centers_x, centers_y = create_grid_vertices_extended(\n",
    "        seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y\n",
    "    )\n",
    "    \n",
    "    if has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "        # Try to find valid initial translations\n",
    "        a_test, b_test = get_initial_translations(seed_xs, seed_ys, seed_degs)\n",
    "        a = max(a, a_test * 1.5)\n",
    "        b = max(b, b_test * 1.5)\n",
    "        all_vertices, centers_x, centers_y = create_grid_vertices_extended(\n",
    "            seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y\n",
    "        )\n",
    "        \n",
    "        if has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "            # Still overlapping, return large score\n",
    "            return 1e10, seed_xs, seed_ys, seed_degs, a, b\n",
    "\n",
    "    current_score = calculate_score_numba(all_vertices)\n",
    "    best_score = current_score\n",
    "    best_seed_xs = seed_xs.copy()\n",
    "    best_seed_ys = seed_ys.copy()\n",
    "    best_seed_degs = seed_degs.copy()\n",
    "    best_a = a\n",
    "    best_b = b\n",
    "\n",
    "    # Temperature schedule\n",
    "    T = Tmax\n",
    "    alpha = (Tmin / Tmax) ** (1.0 / nsteps)\n",
    "\n",
    "    for step in range(nsteps):\n",
    "        for _ in range(nsteps_per_T):\n",
    "            # Choose move type\n",
    "            move_type = np.random.randint(0, 6)\n",
    "            \n",
    "            # Save current state\n",
    "            old_seed_xs = seed_xs.copy()\n",
    "            old_seed_ys = seed_ys.copy()\n",
    "            old_seed_degs = seed_degs.copy()\n",
    "            old_a = a\n",
    "            old_b = b\n",
    "\n",
    "            if move_type == 0:  # Move single seed position\n",
    "                idx = np.random.randint(0, n_seeds)\n",
    "                seed_xs[idx] += (np.random.random() - 0.5) * 2 * position_delta\n",
    "                seed_ys[idx] += (np.random.random() - 0.5) * 2 * position_delta\n",
    "            elif move_type == 1:  # Rotate single seed\n",
    "                idx = np.random.randint(0, n_seeds)\n",
    "                seed_degs[idx] += (np.random.random() - 0.5) * 2 * angle_delta\n",
    "            elif move_type == 2:  # Rotate all seeds\n",
    "                delta = (np.random.random() - 0.5) * 2 * angle_delta2\n",
    "                for i in range(n_seeds):\n",
    "                    seed_degs[i] += delta\n",
    "            elif move_type == 3:  # Change translation a\n",
    "                a += (np.random.random() - 0.5) * 2 * delta_t\n",
    "                a = max(0.5, a)\n",
    "            elif move_type == 4:  # Change translation b\n",
    "                b += (np.random.random() - 0.5) * 2 * delta_t\n",
    "                b = max(0.5, b)\n",
    "            else:  # Move all seeds\n",
    "                dx = (np.random.random() - 0.5) * 2 * position_delta\n",
    "                dy = (np.random.random() - 0.5) * 2 * position_delta\n",
    "                for i in range(n_seeds):\n",
    "                    seed_xs[i] += dx\n",
    "                    seed_ys[i] += dy\n",
    "\n",
    "            # Create new grid\n",
    "            all_vertices, centers_x, centers_y = create_grid_vertices_extended(\n",
    "                seed_xs, seed_ys, seed_degs, a, b, ncols, nrows, append_x, append_y\n",
    "            )\n",
    "\n",
    "            # Check validity\n",
    "            if has_any_overlap(all_vertices, centers_x, centers_y):\n",
    "                # Reject move\n",
    "                seed_xs = old_seed_xs\n",
    "                seed_ys = old_seed_ys\n",
    "                seed_degs = old_seed_degs\n",
    "                a = old_a\n",
    "                b = old_b\n",
    "                continue\n",
    "\n",
    "            new_score = calculate_score_numba(all_vertices)\n",
    "            delta_score = new_score - current_score\n",
    "\n",
    "            # Accept or reject\n",
    "            if delta_score < 0 or np.random.random() < math.exp(-delta_score / T):\n",
    "                current_score = new_score\n",
    "                if new_score < best_score:\n",
    "                    best_score = new_score\n",
    "                    best_seed_xs = seed_xs.copy()\n",
    "                    best_seed_ys = seed_ys.copy()\n",
    "                    best_seed_degs = seed_degs.copy()\n",
    "                    best_a = a\n",
    "                    best_b = b\n",
    "            else:\n",
    "                # Reject move\n",
    "                seed_xs = old_seed_xs\n",
    "                seed_ys = old_seed_ys\n",
    "                seed_degs = old_seed_degs\n",
    "                a = old_a\n",
    "                b = old_b\n",
    "\n",
    "        T *= alpha\n",
    "\n",
    "    return best_score, best_seed_xs, best_seed_ys, best_seed_degs, best_a, best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_grid_config(args):\n",
    "    \"\"\"Wrapper for parallel execution.\"\"\"\n",
    "    ncols, nrows, append_x, append_y, initial_seeds, a_init, b_init, sa_params, seed = args\n",
    "    \n",
    "    seed_xs = np.array([s[0] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_ys = np.array([s[1] for s in initial_seeds], dtype=np.float64)\n",
    "    seed_degs = np.array([s[2] for s in initial_seeds], dtype=np.float64)\n",
    "    \n",
    "    score, opt_xs, opt_ys, opt_degs, opt_a, opt_b = sa_optimize_improved(\n",
    "        seed_xs, seed_ys, seed_degs,\n",
    "        a_init, b_init,\n",
    "        ncols, nrows, append_x, append_y,\n",
    "        sa_params[\"Tmax\"],\n",
    "        sa_params[\"Tmin\"],\n",
    "        sa_params[\"nsteps\"],\n",
    "        sa_params[\"nsteps_per_T\"],\n",
    "        sa_params[\"position_delta\"],\n",
    "        sa_params[\"angle_delta\"],\n",
    "        sa_params[\"angle_delta2\"],\n",
    "        sa_params[\"delta_t\"],\n",
    "        seed,\n",
    "    )\n",
    "    \n",
    "    # Calculate number of trees\n",
    "    n_seeds = len(initial_seeds)\n",
    "    n_base = n_seeds * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_trees = n_base + n_append_x + n_append_y\n",
    "    \n",
    "    # Generate tree data\n",
    "    tree_data = []\n",
    "    for s in range(n_seeds):\n",
    "        for col in range(ncols):\n",
    "            for row in range(nrows):\n",
    "                cx = opt_xs[s] + col * opt_a\n",
    "                cy = opt_ys[s] + row * opt_b\n",
    "                tree_data.append((cx, cy, opt_degs[s]))\n",
    "    \n",
    "    if append_x and n_seeds > 1:\n",
    "        for row in range(nrows):\n",
    "            cx = opt_xs[1] + ncols * opt_a\n",
    "            cy = opt_ys[1] + row * opt_b\n",
    "            tree_data.append((cx, cy, opt_degs[1]))\n",
    "    \n",
    "    if append_y and n_seeds > 1:\n",
    "        for col in range(ncols):\n",
    "            cx = opt_xs[1] + col * opt_a\n",
    "            cy = opt_ys[1] + nrows * opt_b\n",
    "            tree_data.append((cx, cy, opt_degs[1]))\n",
    "    \n",
    "    return n_trees, score, tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ddaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission_data(filepath):\n",
    "    \"\"\"Load submission and return flattened arrays.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    all_degs = []\n",
    "\n",
    "    for n in range(1, 201):\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        group = df[df[\"id\"].str.startswith(prefix)].sort_values(\"id\")\n",
    "        for _, row in group.iterrows():\n",
    "            x = float(str(row[\"x\"])[1:]) if str(row[\"x\"]).startswith('s') else float(row[\"x\"])\n",
    "            y = float(str(row[\"y\"])[1:]) if str(row[\"y\"]).startswith('s') else float(row[\"y\"])\n",
    "            deg = float(str(row[\"deg\"])[1:]) if str(row[\"deg\"]).startswith('s') else float(row[\"deg\"])\n",
    "            all_xs.append(x)\n",
    "            all_ys.append(y)\n",
    "            all_degs.append(deg)\n",
    "\n",
    "    return np.array(all_xs), np.array(all_ys), np.array(all_degs)\n",
    "\n",
    "\n",
    "def save_submission(filepath, all_xs, all_ys, all_degs):\n",
    "    \"\"\"Save submission from flattened arrays.\"\"\"\n",
    "    rows = []\n",
    "    idx = 0\n",
    "    for n in range(1, 201):\n",
    "        for t in range(n):\n",
    "            rows.append({\n",
    "                \"id\": f\"{n:03d}_{t}\",\n",
    "                \"x\": f\"s{all_xs[idx]}\",\n",
    "                \"y\": f\"s{all_ys[idx]}\",\n",
    "                \"deg\": f\"s{all_degs[idx]}\",\n",
    "            })\n",
    "            idx += 1\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "\n",
    "def calculate_total_score(all_xs, all_ys, all_degs):\n",
    "    \"\"\"Calculate total score across all groups.\"\"\"\n",
    "    total = 0.0\n",
    "    idx = 0\n",
    "    for n in range(1, 201):\n",
    "        vertices = [get_tree_vertices(all_xs[idx + i], all_ys[idx + i], all_degs[idx + i]) for i in range(n)]\n",
    "        score = calculate_score_numba(vertices)\n",
    "        total += score\n",
    "        idx += n\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dcfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline\n",
    "baseline_path = '/home/submission/submission.csv'\n",
    "print(f\"Loading baseline: {baseline_path}\")\n",
    "baseline_xs, baseline_ys, baseline_degs = load_submission_data(baseline_path)\n",
    "baseline_total = calculate_total_score(baseline_xs, baseline_ys, baseline_degs)\n",
    "print(f\"Baseline total score: {baseline_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2368f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial 2-tree seed configuration (from jiweiliu kernel)\n",
    "initial_seeds = [\n",
    "    (-4.191683864412409, -4.498489528496051, 74.54421568660419),\n",
    "    (-4.92202045352307, -4.727639556649786, 254.5401905706735),\n",
    "]\n",
    "\n",
    "# Initial translation lengths\n",
    "a_init = 0.8744896974945239\n",
    "b_init = 0.7499641699190263\n",
    "\n",
    "print(f\"Initial seeds: {len(initial_seeds)}\")\n",
    "print(f\"Initial translations: a={a_init:.4f}, b={b_init:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a23f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid configurations: (ncols, nrows, append_x, append_y)\n",
    "grid_configs = []\n",
    "\n",
    "# Generate configurations for better coverage\n",
    "for ncols in range(2, 11):\n",
    "    for nrows in range(ncols, 15):\n",
    "        n_trees = 2 * ncols * nrows\n",
    "        if 20 <= n_trees <= 200:\n",
    "            grid_configs.append((ncols, nrows, False, False))\n",
    "            n_with_append_y = n_trees + ncols\n",
    "            if n_with_append_y <= 200:\n",
    "                grid_configs.append((ncols, nrows, False, True))\n",
    "            n_with_append_x = n_trees + nrows\n",
    "            if n_with_append_x <= 200:\n",
    "                grid_configs.append((ncols, nrows, True, False))\n",
    "\n",
    "# Remove duplicates and sort\n",
    "grid_configs = list(set(grid_configs))\n",
    "grid_configs.sort(key=lambda x: (2 * x[0] * x[1] + (x[1] if x[2] else 0) + (x[0] if x[3] else 0)))\n",
    "\n",
    "print(f\"Generated {len(grid_configs)} grid configurations\")\n",
    "print(f\"Tree counts range: {min(2*c[0]*c[1] for c in grid_configs)} to {max(2*c[0]*c[1] + (c[1] if c[2] else 0) + (c[0] if c[3] else 0) for c in grid_configs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA parameters\n",
    "sa_params = {\n",
    "    \"Tmax\": 0.001,\n",
    "    \"Tmin\": 0.000001,\n",
    "    \"nsteps\": 10,\n",
    "    \"nsteps_per_T\": 10000,\n",
    "    \"position_delta\": 0.002,\n",
    "    \"angle_delta\": 1.0,\n",
    "    \"angle_delta2\": 1.0,\n",
    "    \"delta_t\": 0.002,\n",
    "}\n",
    "\n",
    "print(\"SA parameters:\")\n",
    "for k, v in sa_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61205fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm up numba\n",
    "print(\"Compiling numba functions...\")\n",
    "t0 = time.time()\n",
    "dummy_xs = np.array([0.0, 1.0], dtype=np.float64)\n",
    "dummy_ys = np.array([0.0, 0.0], dtype=np.float64)\n",
    "dummy_degs = np.array([0.0, 180.0], dtype=np.float64)\n",
    "_ = sa_optimize_improved(\n",
    "    dummy_xs, dummy_ys, dummy_degs,\n",
    "    1.0, 1.0, 2, 2, False, False,\n",
    "    0.001, 0.0001, 2, 10,\n",
    "    0.01, 10.0, 10.0, 0.01, 42\n",
    ")\n",
    "print(f\"Compilation done in {time.time() - t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb93e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tasks\n",
    "tasks = []\n",
    "tree_counts = []\n",
    "for i, (ncols, nrows, append_x, append_y) in enumerate(grid_configs):\n",
    "    n_base = 2 * ncols * nrows\n",
    "    n_append_x = nrows if append_x else 0\n",
    "    n_append_y = ncols if append_y else 0\n",
    "    n_trees = n_base + n_append_x + n_append_y\n",
    "\n",
    "    if n_trees > 200:\n",
    "        continue\n",
    "\n",
    "    seed = 42 + i * 1000\n",
    "    tasks.append((ncols, nrows, append_x, append_y, initial_seeds, a_init, b_init, sa_params, seed))\n",
    "    tree_counts.append(n_trees)\n",
    "\n",
    "print(f\"Tasks: {len(tasks)}, tree counts: {min(tree_counts)} to {max(tree_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SA optimization in parallel\n",
    "print(f\"Running SA optimization on {len(tasks)} configurations...\")\n",
    "num_workers = min(cpu_count(), len(tasks))\n",
    "print(f\"Using {num_workers} workers\")\n",
    "\n",
    "t0 = time.time()\n",
    "with Pool(num_workers) as pool:\n",
    "    results = pool.map(optimize_grid_config, tasks)\n",
    "elapsed = time.time() - t0\n",
    "print(f\"SA optimization completed in {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84add433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results and compare with baseline\n",
    "new_trees = {}\n",
    "improved_count = 0\n",
    "for n_trees, score, tree_data in results:\n",
    "    if score > 1e9:  # Invalid configuration\n",
    "        continue\n",
    "        \n",
    "    # Get baseline score for this n\n",
    "    idx = sum(range(1, n_trees))\n",
    "    baseline_vertices = [get_tree_vertices(baseline_xs[idx + i], baseline_ys[idx + i], baseline_degs[idx + i]) for i in range(n_trees)]\n",
    "    baseline_score = calculate_score_numba(baseline_vertices)\n",
    "\n",
    "    if score < baseline_score:\n",
    "        new_trees[n_trees] = tree_data\n",
    "        improvement = baseline_score - score\n",
    "        if improvement > 1e-6:\n",
    "            improved_count += 1\n",
    "            print(f\"  n={n_trees}: {score:.6f} (baseline: {baseline_score:.6f}, improved by {improvement:.6f})\")\n",
    "\n",
    "print(f\"\\nSA improved {improved_count} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9212512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with baseline\n",
    "print(\"Merging with baseline...\")\n",
    "merged_xs = baseline_xs.copy()\n",
    "merged_ys = baseline_ys.copy()\n",
    "merged_degs = baseline_degs.copy()\n",
    "\n",
    "for n_trees, tree_data in new_trees.items():\n",
    "    idx = sum(range(1, n_trees))\n",
    "    for i in range(n_trees):\n",
    "        merged_xs[idx + i] = tree_data[i][0]\n",
    "        merged_ys[idx + i] = tree_data[i][1]\n",
    "        merged_degs[idx + i] = tree_data[i][2]\n",
    "\n",
    "pre_cascade_score = calculate_total_score(merged_xs, merged_ys, merged_degs)\n",
    "print(f\"Score after SA merge: {pre_cascade_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af397540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletion cascade implementation\n",
    "@njit(cache=True)\n",
    "def deletion_cascade_numba(all_xs, all_ys, all_degs):\n",
    "    \"\"\"\n",
    "    Apply tree deletion cascade using numba.\n",
    "    For each N from 200 down to 2, check if removing any tree from N\n",
    "    gives a better score for N-1 than the current N-1 solution.\n",
    "    \"\"\"\n",
    "    # Build index mapping\n",
    "    group_start = np.zeros(201, dtype=np.int64)\n",
    "    for n in range(1, 201):\n",
    "        group_start[n] = group_start[n-1] + (n - 1) if n > 1 else 0\n",
    "\n",
    "    # Copy arrays\n",
    "    new_xs = all_xs.copy()\n",
    "    new_ys = all_ys.copy()\n",
    "    new_degs = all_degs.copy()\n",
    "\n",
    "    # Calculate initial side lengths\n",
    "    side_lengths = np.zeros(201, dtype=np.float64)\n",
    "    for n in range(1, 201):\n",
    "        start = group_start[n]\n",
    "        end = start + n\n",
    "        vertices = [get_tree_vertices(new_xs[i], new_ys[i], new_degs[i]) for i in range(start, end)]\n",
    "        side_lengths[n] = get_side_length(vertices)\n",
    "\n",
    "    # Cascade from n=200 down to n=2\n",
    "    for n in range(200, 1, -1):\n",
    "        start_n = group_start[n]\n",
    "        end_n = start_n + n\n",
    "        start_prev = group_start[n - 1]\n",
    "\n",
    "        best_side = side_lengths[n - 1]\n",
    "        best_delete_idx = -1\n",
    "\n",
    "        for del_idx in range(n):\n",
    "            vertices = []\n",
    "            for i in range(n):\n",
    "                if i != del_idx:\n",
    "                    idx = start_n + i\n",
    "                    vertices.append(get_tree_vertices(new_xs[idx], new_ys[idx], new_degs[idx]))\n",
    "\n",
    "            candidate_side = get_side_length(vertices)\n",
    "            if candidate_side < best_side:\n",
    "                best_side = candidate_side\n",
    "                best_delete_idx = del_idx\n",
    "\n",
    "        if best_delete_idx >= 0:\n",
    "            out_idx = start_prev\n",
    "            for i in range(n):\n",
    "                if i != best_delete_idx:\n",
    "                    in_idx = start_n + i\n",
    "                    new_xs[out_idx] = new_xs[in_idx]\n",
    "                    new_ys[out_idx] = new_ys[in_idx]\n",
    "                    new_degs[out_idx] = new_degs[in_idx]\n",
    "                    out_idx += 1\n",
    "            side_lengths[n - 1] = best_side\n",
    "\n",
    "    return new_xs, new_ys, new_degs, side_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tree deletion cascade\n",
    "print(\"Applying tree deletion cascade...\")\n",
    "t0 = time.time()\n",
    "final_xs, final_ys, final_degs, side_lengths = deletion_cascade_numba(\n",
    "    merged_xs, merged_ys, merged_degs\n",
    ")\n",
    "print(f\"Cascade completed in {time.time() - t0:.1f}s\")\n",
    "\n",
    "final_score = calculate_total_score(final_xs, final_ys, final_degs)\n",
    "print(f\"Final score after cascade: {final_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Summary:\")\n",
    "print(f\"  Baseline total:      {baseline_total:.6f}\")\n",
    "print(f\"  After SA:            {pre_cascade_score:.6f}\")\n",
    "print(f\"  After cascade:       {final_score:.6f}\")\n",
    "print(f\"  Total improvement:   {baseline_total - final_score:+.6f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate with Shapely\n",
    "print(\"\\nValidating with Shapely...\")\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    \"\"\"Create a Shapely polygon for a tree.\"\"\"\n",
    "    tree = Polygon(TREE_VERTICES)\n",
    "    tree = rotate(tree, deg, origin=(0, 0))\n",
    "    tree = translate(tree, x, y)\n",
    "    return tree\n",
    "\n",
    "def validate_group(xs, ys, degs):\n",
    "    \"\"\"Check if any trees in a group overlap.\"\"\"\n",
    "    n = len(xs)\n",
    "    trees = [create_tree_polygon(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if trees[i].overlaps(trees[j]) or trees[i].contains(trees[j]) or trees[j].contains(trees[i]):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Validate all groups\n",
    "overlap_count = 0\n",
    "idx = 0\n",
    "for n in range(1, 201):\n",
    "    xs = final_xs[idx:idx+n]\n",
    "    ys = final_ys[idx:idx+n]\n",
    "    degs = final_degs[idx:idx+n]\n",
    "    if not validate_group(xs, ys, degs):\n",
    "        overlap_count += 1\n",
    "        print(f\"  Group {n:03d} has overlaps!\")\n",
    "    idx += n\n",
    "\n",
    "if overlap_count == 0:\n",
    "    print(\"All groups valid - no overlaps!\")\n",
    "else:\n",
    "    print(f\"\\nWARNING: {overlap_count} groups have overlaps!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission if improved and valid\n",
    "if final_score < baseline_total and overlap_count == 0:\n",
    "    output_path = \"/home/submission/submission.csv\"\n",
    "    save_submission(output_path, final_xs, final_ys, final_degs)\n",
    "    print(f\"\\nSaved improved submission to {output_path}\")\n",
    "    print(f\"New total score: {final_score:.9f}\")\n",
    "else:\n",
    "    print(f\"\\nNo improvement or invalid - keeping baseline\")\n",
    "    print(f\"Baseline score: {baseline_total:.9f}\")\n",
    "    final_score = baseline_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff60a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': final_score,\n",
    "    'baseline_score': baseline_total,\n",
    "    'improvement': baseline_total - final_score,\n",
    "    'sa_improved_configs': improved_count,\n",
    "    'overlap_count': overlap_count,\n",
    "    'approach': 'jiweiliu Fast SA with Deletion Cascade'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/031_jiweiliu_deletion_cascade/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"\\nMetrics saved:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
