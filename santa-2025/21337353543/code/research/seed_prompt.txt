# Santa 2025 - EVOLVED SEED PROMPT (Loop 5)

## Current Status
- Best CV score: 70.622435 from exp_001 (fix_overlaps)
- Best LB score: 70.622435 (confirmed on Kaggle)
- Target: 68.887744 | Gap to target: 1.734 points (2.45%)
- Submissions used: 3/100 (92 remaining - ABUNDANT!)

## ⚠️ CRITICAL DIAGNOSIS: WE'RE STUCK AT LOCAL OPTIMUM

The last 4 experiments all produced the SAME score (70.622435):
- exp_001: Baseline from snapshot
- exp_002: Python optimization (0 improvements found)
- exp_003: Simulated annealing (0 improvements found)
- exp_004: Constructive + ensemble (constructive scored 110.18, baseline won all N)

**ROOT CAUSE:** We only have ONE source. The ensemble approach requires MANY diverse sources.

## Response to Evaluator

The evaluator correctly identified that:
1. The constructive implementation underperforms (110.18 vs zaburo's 88.33)
2. No local search was applied to constructive solutions
3. Only 2 sources were used (baseline + constructive)

**I AGREE with all points.** The key insight is that the jonathanchan kernel uses **15+ different sources** for ensemble. We need MORE sources, not better optimization of a single source.

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with the same approach - FORBIDDEN
- Running more SA iterations (already proven ineffective) - FORBIDDEN

## ✅ MANDATORY NEXT EXPERIMENT: MULTI-SOURCE ENSEMBLE

The jonathanchan kernel shows the winning approach:
1. Collect CSVs from 15+ different sources
2. For each N, take the BEST solution across all sources
3. Apply fractional translation to further optimize

**STEP 1: Collect ALL available sources from snapshots**

There are 100+ snapshot directories in `/home/nonroot/snapshots/santa-2025/` - each contains a submission.csv that may have different solutions for different N values.

```python
import os
import glob

# Find all unique submissions in snapshots
snapshot_dir = '/home/nonroot/snapshots/santa-2025/'
sources = []
for subdir in os.listdir(snapshot_dir):
    csv_path = os.path.join(snapshot_dir, subdir, 'submission', 'submission.csv')
    if os.path.exists(csv_path):
        sources.append(csv_path)

print(f"Found {len(sources)} source files")
```

**STEP 2: Ensemble - take best per-N from ALL sources**

Use numba for fast scoring:

```python
from numba import njit
import pandas as pd
import numpy as np

@njit
def make_polygon_template():
    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25
    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th
    x=np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2],np.float64)
    y=np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1],np.float64)
    return x,y

@njit
def score_group(xs, ys, degs, tx, ty):
    """Fast scoring using numba."""
    n = xs.size
    V = tx.size
    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300
    for i in range(n):
        r = degs[i] * np.pi / 180.0
        c = np.cos(r); s = np.sin(r)
        xi = xs[i]; yi = ys[i]
        for j in range(V):
            X = c * tx[j] - s * ty[j] + xi
            Y = s * tx[j] + c * ty[j] + yi
            if X < mnx: mnx = X
            if X > mxx: mxx = X
            if Y < mny: mny = Y
            if Y > mxy: mxy = Y
    side = max(mxx - mnx, mxy - mny)
    return side * side / n

def strip(a):
    return np.array([float(str(v).replace("s","")) for v in a], np.float64)

tx, ty = make_polygon_template()

# For each N, track best solution across ALL sources
best = {n: {"score": 1e300, "data": None, "src": None} for n in range(1, 201)}

for source_path in sources:
    try:
        df = pd.read_csv(source_path)
        if not {"id","x","y","deg"}.issubset(df.columns):
            continue
        df["N"] = df["id"].astype(str).str.split("_").str[0].astype(int)
        
        for n, g in df.groupby("N"):
            if n < 1 or n > 200:
                continue
            xs = strip(g["x"].to_numpy())
            ys = strip(g["y"].to_numpy())
            ds = strip(g["deg"].to_numpy())
            sc = score_group(xs, ys, ds, tx, ty)
            
            if sc < best[n]["score"]:
                best[n]["score"] = float(sc)
                best[n]["data"] = g.drop(columns=["N"]).copy()
                best[n]["src"] = source_path
    except Exception as e:
        continue
```

**STEP 3: Apply backward propagation (chistyakov approach)**

```python
def get_bbox_touching_tree_indices(tree_list):
    """Find indices of trees touching the bounding box boundary."""
    from shapely.geometry import box
    from shapely.ops import unary_union
    
    polys = [create_tree_polygon(t['x'], t['y'], t['deg']) for t in tree_list]
    
    minx = min(p.bounds[0] for p in polys)
    miny = min(p.bounds[1] for p in polys)
    maxx = max(p.bounds[2] for p in polys)
    maxy = max(p.bounds[3] for p in polys)
    
    bbox = box(minx, miny, maxx, maxy)
    
    touching_indices = [
        i for i, poly in enumerate(polys)
        if poly.boundary.intersects(bbox.boundary)
    ]
    
    return touching_indices

def backward_propagation(trees_by_n, scores_by_n):
    """Try removing trees from N to improve N-1."""
    improvements = []
    
    for n in range(200, 2, -1):
        trees = trees_by_n[n]
        target_n = n - 1
        current_best = scores_by_n[target_n]
        
        # Find trees touching the bounding box
        touching_indices = get_bbox_touching_tree_indices(trees)
        
        for idx in touching_indices:
            # Try removing this tree
            candidate = [t for i, t in enumerate(trees) if i != idx]
            score = get_score(candidate, target_n)
            
            if score < current_best - 1e-9:
                print(f"N={target_n}: IMPROVED by {current_best - score:.6f}")
                trees_by_n[target_n] = candidate
                scores_by_n[target_n] = score
                improvements.append((target_n, current_best - score))
                break  # Found improvement, move to next N
    
    return improvements
```

**STEP 4: Apply fractional translation (pure Python)**

```python
def fractional_translation(trees, n, max_iter=100):
    """Move trees in tiny steps to reduce bounding box."""
    frac_steps = [0.001, 0.0005, 0.0002, 0.0001]
    directions = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]
    
    best_score = get_score(trees, n)
    best_trees = [dict(t) for t in trees]
    
    for iteration in range(max_iter):
        improved = False
        for i in range(len(trees)):
            for step in frac_steps:
                for dx, dy in directions:
                    # Try moving tree i
                    new_trees = [dict(t) for t in best_trees]
                    new_trees[i]['x'] = str(float(new_trees[i]['x']) + dx * step)
                    new_trees[i]['y'] = str(float(new_trees[i]['y']) + dy * step)
                    
                    if not has_overlap(new_trees):
                        new_score = get_score(new_trees, n)
                        if new_score < best_score - 1e-12:
                            best_score = new_score
                            best_trees = new_trees
                            improved = True
        
        if not improved:
            break
    
    return best_trees, best_score
```

## Expected Outcome

With 100+ snapshot sources + backward propagation + fractional translation:
- We should find improvements for SOME N values
- Even small improvements (0.001 per N) can add up
- The ensemble approach IS how top teams achieve good scores

## Validation Requirements

Before submission, validate:
1. No overlaps (use 1e15 scaling for strict precision)
2. All N values have exactly N trees
3. Score matches expected value

## SUBMISSION STRATEGY

**SUBMIT AFTER THIS EXPERIMENT!**
- We have 92 submissions remaining
- LB feedback is valuable
- Even if score doesn't improve, we learn what works

## What NOT to Try
- More SA iterations (proven ineffective)
- More local search on single source (proven ineffective)
- Simple constructive without optimization (proven ineffective)

## Key Insight from Top Kernels

The jonathanchan kernel shows:
1. **15+ sources** are used for ensemble
2. **Best per-N** is taken from all sources
3. **Fractional translation** is applied after ensemble
4. **N=1 is fixed at 45°** (confirmed optimal)

The chistyakov kernel shows:
1. **Backward propagation** - remove boundary-touching trees from N to improve N-1
2. **Pure Python** implementation is possible
3. **Decimal precision** (1e18 scaling) for strict validation

## CRITICAL: Track Per-N Improvements

After this experiment:
1. Compare per-N scores to baseline
2. For any N where you improved, save that solution
3. Track which source contributed to each N
4. Even if total score is worse, individual N improvements are valuable

## Experiment Name: 005_multi_source_ensemble

Create folder: experiments/005_multi_source_ensemble/
Notebook: experiments/005_multi_source_ensemble/ensemble.ipynb