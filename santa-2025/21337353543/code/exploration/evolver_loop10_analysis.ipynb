{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723c2efa",
   "metadata": {},
   "source": [
    "# Evolver Loop 10 Analysis\n",
    "\n",
    "## Goal: Find more diverse sources and ensemble to beat 70.364\n",
    "\n",
    "Current best: 70.364392 (exp_010_full_ensemble)\n",
    "Target: 68.879467\n",
    "Gap: 1.485 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d3c3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T12:17:00.712144Z",
     "iopub.status.busy": "2026-01-26T12:17:00.711601Z",
     "iopub.status.idle": "2026-01-26T12:17:01.269633Z",
     "shell.execute_reply": "2026-01-26T12:17:01.269193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from numba import njit\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "\n",
    "getcontext().prec = 30\n",
    "SCALE = 10**18\n",
    "\n",
    "@njit\n",
    "def make_polygon_template():\n",
    "    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n",
    "    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n",
    "    x=np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2],np.float64)\n",
    "    y=np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1],np.float64)\n",
    "    return x,y\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    \"\"\"Compute score for a group of trees.\"\"\"\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r); s = math.sin(r)\n",
    "        xi = xs[i]; yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xi\n",
    "            Y = s * tx[j] + c * ty[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace(\"s\", \"\")) for v in a], np.float64)\n",
    "\n",
    "tx, ty = make_polygon_template()\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    \"\"\"Compute score for a specific N.\"\"\"\n",
    "    n_df = df[df['N'] == n]\n",
    "    if len(n_df) == 0:\n",
    "        return float('inf')\n",
    "    xs = strip(n_df['x'].to_numpy())\n",
    "    ys = strip(n_df['y'].to_numpy())\n",
    "    ds = strip(n_df['deg'].to_numpy())\n",
    "    return score_group(xs, ys, ds, tx, ty)\n",
    "\n",
    "def compute_total_score(df):\n",
    "    \"\"\"Compute total score for all N.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    total = 0\n",
    "    for n in range(1, 201):\n",
    "        score = compute_score_for_n(df, n)\n",
    "        total += score\n",
    "    return total\n",
    "\n",
    "def load_and_prepare(filepath):\n",
    "    \"\"\"Load CSV and add N column.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    return df\n",
    "\n",
    "print(\"Functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb866e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T12:17:01.271014Z",
     "iopub.status.busy": "2026-01-26T12:17:01.270849Z",
     "iopub.status.idle": "2026-01-26T12:17:01.274506Z",
     "shell.execute_reply": "2026-01-26T12:17:01.274134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 CSV files:\n",
      "  /home/code/kaggle_datasets/submission.csv\n",
      "  /home/code/kaggle_datasets/santa-2025.csv\n",
      "  /home/code/kaggle_datasets/72.49.csv\n",
      "  /home/code/kaggle_datasets/71.97.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_JKoT4.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/New_Tree_144_196.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_JKoT3.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v61.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_JKoT2.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v67.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v76.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_70_936673758122.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v65.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_70_926149550346.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v66.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v63.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v69.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_JKoT1.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/submission_opt1.csv\n",
      "  /home/code/kaggle_datasets/santa25-public/santa2025_ver2_v68.csv\n",
      "  /home/code/kaggle_datasets/bucket-of-chump/submission.csv\n",
      "  /home/code/kaggle_datasets/chistyakov_best_public/submission_best.csv\n",
      "  /home/code/kaggle_datasets/chistyakov_best_public/70.378875862989_20260126_045659.csv\n",
      "  /home/code/kaggle_datasets/saspav/santa-2025.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_JKoT4.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/New_Tree_144_196.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_JKoT3.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v61.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_JKoT2.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v67.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v76.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_70_936673758122.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v65.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_70_926149550346.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v66.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v63.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v69.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_JKoT1.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/submission_opt1.csv\n",
      "  /home/code/kaggle_datasets/santa25-public-new/santa2025_ver2_v68.csv\n",
      "  /home/code/kaggle_datasets/chistyakov/submission_best.csv\n",
      "  /home/code/kaggle_datasets/chistyakov/70.378875862989_20260126_045659.csv\n"
     ]
    }
   ],
   "source": [
    "# Check all available CSV files in kaggle_datasets\n",
    "import glob\n",
    "\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk('/home/code/kaggle_datasets'):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            csv_files.append(os.path.join(root, f))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for f in csv_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24e0765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T12:17:35.070416Z",
     "iopub.status.busy": "2026-01-26T12:17:35.069946Z",
     "iopub.status.idle": "2026-01-26T12:17:37.414100Z",
     "shell.execute_reply": "2026-01-26T12:17:37.413727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 unique CSV files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv: 70.647327\n",
      "santa-2025.csv: 70.376051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.49.csv: 72.495739\n",
      "71.97.csv: 71.972027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_JKoT4.csv: 72.489504\n",
      "New_Tree_144_196.csv: 72.927920\n",
      "submission_JKoT3.csv: 72.489488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa2025_ver2_v61.csv: 72.951925\n",
      "submission_JKoT2.csv: 72.489348\n",
      "santa2025_ver2_v67.csv: 72.938567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa2025_ver2_v76.csv: 72.826444\n",
      "submission_70_936673758122.csv: 70.936674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa2025_ver2_v65.csv: 72.935294\n",
      "submission_70_926149550346.csv: 70.926150\n",
      "santa2025_ver2_v66.csv: 72.938599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa2025_ver2_v63.csv: 72.947427\n",
      "santa2025_ver2_v69.csv: 72.850110\n",
      "submission_JKoT1.csv: 72.489483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_opt1.csv: 70.990692\n",
      "santa2025_ver2_v68.csv: 72.939233\n",
      "submission_best.csv: 70.926150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.378875862989_20260126_045659.csv: 70.378876\n",
      "\n",
      "Scored 22 files\n"
     ]
    }
   ],
   "source": [
    "# Score each unique CSV file (remove duplicates from different directories)\n",
    "unique_files = {}\n",
    "for f in csv_files:\n",
    "    basename = os.path.basename(f)\n",
    "    if basename not in unique_files:\n",
    "        unique_files[basename] = f\n",
    "\n",
    "print(f\"Found {len(unique_files)} unique CSV files\")\n",
    "\n",
    "scores = {}\n",
    "for basename, csv_file in unique_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if 'id' in df.columns and 'x' in df.columns:\n",
    "            df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "            score = compute_total_score(df)\n",
    "            scores[basename] = score\n",
    "            print(f\"{basename}: {score:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{basename}: ERROR - {e}\")\n",
    "\n",
    "print(f\"\\nScored {len(scores)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fa2b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T12:17:57.533377Z",
     "iopub.status.busy": "2026-01-26T12:17:57.532974Z",
     "iopub.status.idle": "2026-01-26T12:17:57.760156Z",
     "shell.execute_reply": "2026-01-26T12:17:57.759798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best (exp_010): 70.364392\n",
      "exp_009: 70.373334\n",
      "\n",
      "Target: 68.879467\n",
      "Gap: 1.484925\n"
     ]
    }
   ],
   "source": [
    "# Load current best (exp_010)\n",
    "exp010_df = load_and_prepare('/home/code/experiments/010_full_ensemble/submission.csv')\n",
    "exp010_score = compute_total_score(exp010_df)\n",
    "print(f\"Current best (exp_010): {exp010_score:.6f}\")\n",
    "\n",
    "# Load exp_009 for comparison\n",
    "exp009_df = load_and_prepare('/home/code/experiments/009_santa_ensemble/submission.csv')\n",
    "exp009_score = compute_total_score(exp009_df)\n",
    "print(f\"exp_009: {exp009_score:.6f}\")\n",
    "\n",
    "# Target\n",
    "target = 68.879467\n",
    "print(f\"\\nTarget: {target:.6f}\")\n",
    "print(f\"Gap: {exp010_score - target:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588d071d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T12:18:25.445279Z",
     "iopub.status.busy": "2026-01-26T12:18:25.444772Z",
     "iopub.status.idle": "2026-01-26T12:18:25.604743Z",
     "shell.execute_reply": "2026-01-26T12:18:25.604377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing overlap detection on exp_010...\n",
      "  N=1: ✓\n",
      "  N=2: ✓\n",
      "  N=5: ✓\n",
      "  N=10: ✓\n",
      "  N=50: ✓\n",
      "  N=100: ✓\n",
      "  N=200: ✓\n"
     ]
    }
   ],
   "source": [
    "# Strict overlap checking using 1e18 scaling\n",
    "@njit\n",
    "def check_overlap_numba(xs1, ys1, degs1, xs2, ys2, degs2, tx, ty):\n",
    "    \"\"\"Check if two tree placements overlap using integer scaling.\"\"\"\n",
    "    SCALE = 10**15  # Use 1e15 for numba compatibility\n",
    "    \n",
    "    # Get vertices for tree 1\n",
    "    r1 = degs1 * math.pi / 180.0\n",
    "    c1, s1 = math.cos(r1), math.sin(r1)\n",
    "    verts1 = []\n",
    "    for j in range(len(tx)):\n",
    "        X = int((c1 * tx[j] - s1 * ty[j] + xs1) * SCALE)\n",
    "        Y = int((s1 * tx[j] + c1 * ty[j] + ys1) * SCALE)\n",
    "        verts1.append((X, Y))\n",
    "    \n",
    "    # Get vertices for tree 2\n",
    "    r2 = degs2 * math.pi / 180.0\n",
    "    c2, s2 = math.cos(r2), math.sin(r2)\n",
    "    verts2 = []\n",
    "    for j in range(len(tx)):\n",
    "        X = int((c2 * tx[j] - s2 * ty[j] + xs2) * SCALE)\n",
    "        Y = int((s2 * tx[j] + c2 * ty[j] + ys2) * SCALE)\n",
    "        verts2.append((X, Y))\n",
    "    \n",
    "    return verts1, verts2\n",
    "\n",
    "def check_overlaps_for_n(df, n):\n",
    "    \"\"\"Check for overlaps in a specific N group using Shapely with high precision.\"\"\"\n",
    "    n_df = df[df['N'] == n]\n",
    "    if len(n_df) <= 1:\n",
    "        return True, []\n",
    "    \n",
    "    xs = strip(n_df['x'].to_numpy())\n",
    "    ys = strip(n_df['y'].to_numpy())\n",
    "    ds = strip(n_df['deg'].to_numpy())\n",
    "    \n",
    "    # Create polygons with high precision\n",
    "    polygons = []\n",
    "    for i in range(len(xs)):\n",
    "        r = ds[i] * math.pi / 180.0\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        coords = []\n",
    "        for j in range(len(tx)):\n",
    "            X = c * tx[j] - s * ty[j] + xs[i]\n",
    "            Y = s * tx[j] + c * ty[j] + ys[i]\n",
    "            # Scale to integers for strict comparison\n",
    "            coords.append((int(Decimal(str(X)) * SCALE), int(Decimal(str(Y)) * SCALE)))\n",
    "        polygons.append(Polygon(coords))\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):\n",
    "                overlaps.append((i, j))\n",
    "    \n",
    "    return len(overlaps) == 0, overlaps\n",
    "\n",
    "# Test on a few N values\n",
    "print(\"Testing overlap detection on exp_010...\")\n",
    "for n in [1, 2, 5, 10, 50, 100, 200]:\n",
    "    ok, overlaps = check_overlaps_for_n(exp010_df, n)\n",
    "    status = \"✓\" if ok else f\"✗ ({len(overlaps)} overlaps)\"\n",
    "    print(f\"  N={n}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sources and find best per-N\n",
    "print(\"Loading all sources...\")\n",
    "\n",
    "sources = {}\n",
    "\n",
    "# Current best\n",
    "sources['exp_010'] = exp010_df\n",
    "\n",
    "# All kaggle_datasets CSVs\n",
    "for basename, csv_file in unique_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if 'id' in df.columns and 'x' in df.columns:\n",
    "            df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "            sources[basename] = df\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Also load from snapshots\n",
    "snapshot_dir = '/home/nonroot/snapshots/santa-2025'\n",
    "if os.path.exists(snapshot_dir):\n",
    "    for snap in os.listdir(snapshot_dir)[:20]:  # Limit to 20 snapshots\n",
    "        snap_path = os.path.join(snapshot_dir, snap, 'submission', 'submission.csv')\n",
    "        if os.path.exists(snap_path):\n",
    "            try:\n",
    "                df = pd.read_csv(snap_path)\n",
    "                if 'id' in df.columns and 'x' in df.columns:\n",
    "                    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "                    sources[f'snap_{snap}'] = df\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(f\"Loaded {len(sources)} sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23918115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current best (exp_010)\n",
    "best_df = pd.read_csv('/home/code/experiments/010_full_ensemble/submission.csv')\n",
    "best_score = compute_total_score(best_df)\n",
    "print(f\"Current best (exp_010): {best_score:.6f}\")\n",
    "\n",
    "# Also load exp_009 for comparison\n",
    "exp009_df = pd.read_csv('/home/code/experiments/009_santa_ensemble/submission.csv')\n",
    "exp009_score = compute_total_score(exp009_df)\n",
    "print(f\"exp_009: {exp009_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9895d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check chistyakov submission_best.csv specifically\n",
    "chistyakov_best = pd.read_csv('/home/code/kaggle_datasets/chistyakov_best_public/submission_best.csv')\n",
    "chistyakov_score = compute_total_score(chistyakov_best)\n",
    "print(f\"chistyakov submission_best.csv: {chistyakov_score:.6f}\")\n",
    "\n",
    "# Check if it has overlaps\n",
    "def check_overlaps_strict(df, n):\n",
    "    \"\"\"Check for overlaps using strict 1e18 scaling.\"\"\"\n",
    "    n_str = str(n).zfill(3)\n",
    "    n_df = df[df['id'].str.startswith(n_str + '_')]\n",
    "    if len(n_df) == 0:\n",
    "        return True, []\n",
    "    \n",
    "    polygons = []\n",
    "    for _, row in n_df.iterrows():\n",
    "        tree_idx = int(row['id'].split('_')[1])\n",
    "        tree_id = tree_idx + 1\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        \n",
    "        poly = get_tree_polygon(tree_id, x, y, deg)\n",
    "        # Scale to integers for strict comparison\n",
    "        coords = [(int(Decimal(str(c[0])) * SCALE), int(Decimal(str(c[1])) * SCALE)) \n",
    "                  for c in poly.exterior.coords]\n",
    "        polygons.append(Polygon(coords))\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):\n",
    "                overlaps.append((i, j))\n",
    "    \n",
    "    return len(overlaps) == 0, overlaps\n",
    "\n",
    "# Check overlaps for chistyakov\n",
    "overlap_ns = []\n",
    "for n in range(1, 201):\n",
    "    ok, overlaps = check_overlaps_strict(chistyakov_best, n)\n",
    "    if not ok:\n",
    "        overlap_ns.append(n)\n",
    "\n",
    "print(f\"\\nchistyakov submission_best.csv has overlaps in {len(overlap_ns)} N values: {overlap_ns[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aa5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best source for each N\n",
    "print(\"\\nFinding best source for each N...\")\n",
    "\n",
    "# Load all valid sources\n",
    "sources = {}\n",
    "\n",
    "# exp_010 (current best)\n",
    "sources['exp_010'] = pd.read_csv('/home/code/experiments/010_full_ensemble/submission.csv')\n",
    "\n",
    "# All kaggle_datasets CSVs\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if 'id' in df.columns and 'x' in df.columns:\n",
    "            name = os.path.basename(csv_file)\n",
    "            sources[name] = df\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"Loaded {len(sources)} sources\")\n",
    "\n",
    "# For each N, find best valid source\n",
    "best_per_n = {}\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    \n",
    "    for name, df in sources.items():\n",
    "        score = compute_score_for_n(df, n)\n",
    "        if score < best_score:\n",
    "            # Check for overlaps\n",
    "            ok, _ = check_overlaps_strict(df, n)\n",
    "            if ok:\n",
    "                best_score = score\n",
    "                best_source = name\n",
    "    \n",
    "    best_per_n[n] = (best_source, best_score)\n",
    "    if n <= 10 or n % 20 == 0:\n",
    "        print(f\"N={n}: best={best_source} score={best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0620a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many N values each source contributes\n",
    "source_counts = {}\n",
    "for n, (source, score) in best_per_n.items():\n",
    "    if source not in source_counts:\n",
    "        source_counts[source] = 0\n",
    "    source_counts[source] += 1\n",
    "\n",
    "print(\"\\nSource contributions:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {count} N values\")\n",
    "\n",
    "# Calculate total score from best per N\n",
    "total_best = sum(score for _, score in best_per_n.values())\n",
    "print(f\"\\nTotal score from best per N: {total_best:.6f}\")\n",
    "print(f\"Current best (exp_010): {best_score:.6f}\")\n",
    "print(f\"Improvement: {best_score - total_best:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
