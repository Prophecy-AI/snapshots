# Santa 2025 - Evolved Seed Prompt (Loop 3)

## Current Status
- Best CV score: 70.659437 from mega ensemble (public sources + snapshots)
- Best LB score: N/A (both previous submissions failed - format issues and overlaps)
- Target: 68.919154 | Gap to target: 1.74 points (2.5% improvement needed)
- Submissions remaining: 98

## Public Kernel Status
- Downloaded public datasets: bucket-of-chump, telegram-shared, saspav, chistyakov
- Public sources have similar scores (70.66-72.5) to our snapshots
- Top kernel (jonathanchan) uses 15+ sources + fractional translation + SA
- **Key insight**: Public sources alone won't beat target - need optimization

## CV-LB Relationship Analysis
- No valid LB scores yet (both submissions failed)
- Need to submit clean ensemble to establish baseline

## Response to Evaluator
The evaluator correctly identified:
1. **Limited data sources = limited score** - Confirmed. Downloaded 4 public datasets but they have similar/worse scores than our snapshots.
2. **Beam search not competitive** - Confirmed. Grid-based search is too coarse and slow.
3. **Fractional translation not tried** - Still true. This is the key technique from top kernels.
4. **C++ optimizers can't improve pre-optimized solutions** - Confirmed. They're at local optima.

**Key disagreement**: The evaluator suggests downloading more public sources, but my analysis shows the public sources have similar scores to our snapshots. The real gap is in OPTIMIZATION TECHNIQUES, not data sources.

## Key Analysis Findings

### Score Distribution:
- N=1-10: 4.33 points (6.1%), avg efficiency 58%
- N=11-50: 14.71 points (20.8%), avg efficiency 67%
- N=51-100: 17.63 points (25.0%), avg efficiency 70%
- N=101-150: 17.14 points (24.3%), avg efficiency 72%
- N=151-200: 16.85 points (23.8%), avg efficiency 73%

### To reach target:
- Need ~2.5% improvement overall
- A 3% improvement would beat target (68.54 < 68.92)
- Focus on small N (1-10) where efficiency is worst

### Theoretical limits:
- Tree area: 0.245625
- Theoretical minimum score: 49.125 (100% packing efficiency)
- Current efficiency: ~70% average
- Target efficiency: ~72% average

## Recommended Approaches (Priority Order)

### 1. IMMEDIATE: Submit Current Ensemble
- Mega ensemble saved to /home/submission/submission.csv
- Verified: 0 overlapping groups, all 's' prefixes
- Score: 70.659437
- This establishes a valid baseline on LB

### 2. HIGH PRIORITY: Implement Fractional Translation
This is the key technique from top kernels that we haven't tried:
```python
def fractional_translation(config, steps=[0.001, 0.0005, 0.0001, 0.00005]):
    """Apply tiny translations to reduce bounding box."""
    improved = True
    while improved:
        improved = False
        for step in steps:
            for tree_idx in range(len(config)):
                for dx, dy in [(0,1), (0,-1), (1,0), (-1,0), (1,1), (1,-1), (-1,1), (-1,-1)]:
                    new_config = config.move_tree(tree_idx, dx*step, dy*step)
                    if not new_config.has_overlap() and new_config.score() < config.score():
                        config = new_config
                        improved = True
    return config
```

### 3. Focus on Small N Optimization
N=1-10 has worst efficiency (37-65%). Specific targets:
- N=1: 0.661250 (already optimal at 45Â°)
- N=2: 0.450779 (55% efficiency) - can we do better?
- N=3: 0.434745 (56% efficiency)
- N=4-10: 0.38-0.42 each

Try:
- Different angle combinations for small N
- Exhaustive search for N=2,3,4 (small enough to brute force)
- Lattice patterns for N=5-10

### 4. Try Different Optimization Algorithms
Since SA and local search are stuck at local optima:
- **Genetic Algorithm**: Crossover between different solutions
- **Basin Hopping**: Random perturbation + local optimization
- **Constraint Programming**: Model as optimization problem

### 5. Ensemble with Optimization
Instead of just taking best-per-N:
1. Take best-per-N from all sources
2. Apply fractional translation to each N
3. Re-ensemble the optimized configurations

## What NOT to Try
- More SA on pre-optimized solutions (confirmed stuck at local optima)
- Coarse grid-based beam search (too slow, produces worse results)
- Downloading more public datasets (similar scores to what we have)

## Validation Notes
- MUST check for overlaps before submission
- All values MUST have 's' prefix
- Use score_submission.py for local scoring
- Use check_overlaps.py to verify no overlaps

## Files and Paths
- Current submission: /home/submission/submission.csv (verified valid)
- Public sources: /home/code/public_sources/
- C++ optimizers: /home/code/sa_v1_parallel, /home/code/tree_packer_v18
- Scoring script: /home/code/score_submission.py
- Overlap checker: /home/code/check_overlaps.py

## SUBMISSION STRATEGY
- We have 98 submissions remaining - ABUNDANT!
- Submit current ensemble IMMEDIATELY to get LB feedback
- Then implement fractional translation and submit again
- Target: Get 3+ LB scores to understand CV-LB relationship
