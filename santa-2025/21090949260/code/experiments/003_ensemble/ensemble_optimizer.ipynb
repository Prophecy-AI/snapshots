{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fed3b99",
   "metadata": {},
   "source": [
    "# Experiment 003: Ensemble Approach with Snapshot Solutions\n",
    "\n",
    "This experiment implements the ENSEMBLE approach - the PRIMARY technique used by top kernels:\n",
    "1. Collect all available snapshot solutions\n",
    "2. For each N (1-200), pick the BEST configuration across all sources\n",
    "3. Apply optimization pipeline to this ensemble baseline\n",
    "\n",
    "**Critical Discovery:** Snapshot solutions exist with scores as low as 87.36!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1691d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import minimize_scalar\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e18\")\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast scoring using numpy (no Shapely for speed)\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def score_group_fast(xs, ys, degs):\n",
    "    \"\"\"Fast scoring for a single N configuration.\"\"\"\n",
    "    n = len(xs)\n",
    "    if n == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        px = TX * c - TY * s + xs[i]\n",
    "        py = TX * s + TY * c + ys[i]\n",
    "        all_x.extend(px)\n",
    "        all_y.extend(py)\n",
    "    \n",
    "    all_x = np.array(all_x)\n",
    "    all_y = np.array(all_y)\n",
    "    \n",
    "    side = max(all_x.max() - all_x.min(), all_y.max() - all_y.min())\n",
    "    return side * side / n\n",
    "\n",
    "def strip_s(val):\n",
    "    \"\"\"Remove 's' prefix from value.\"\"\"\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "def score_csv_fast(filepath):\n",
    "    \"\"\"Score a CSV file quickly.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return float('inf'), {}\n",
    "        \n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        df['x_val'] = df['x'].apply(strip_s)\n",
    "        df['y_val'] = df['y'].apply(strip_s)\n",
    "        df['deg_val'] = df['deg'].apply(strip_s)\n",
    "        \n",
    "        total_score = 0.0\n",
    "        scores_per_n = {}\n",
    "        \n",
    "        for n in range(1, 201):\n",
    "            group = df[df['N'] == n]\n",
    "            if len(group) == n:\n",
    "                xs = group['x_val'].values\n",
    "                ys = group['y_val'].values\n",
    "                degs = group['deg_val'].values\n",
    "                score = score_group_fast(xs, ys, degs)\n",
    "                scores_per_n[n] = score\n",
    "                total_score += score\n",
    "            else:\n",
    "                scores_per_n[n] = float('inf')\n",
    "                total_score = float('inf')\n",
    "                break\n",
    "        \n",
    "        return total_score, scores_per_n\n",
    "    except Exception as e:\n",
    "        return float('inf'), {}\n",
    "\n",
    "print(\"Fast scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files in snapshots\n",
    "snapshot_csvs = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(snapshot_csvs)} CSV files in snapshots\")\n",
    "\n",
    "# Also include our own candidates\n",
    "our_csvs = glob.glob('/home/code/submission_candidates/*.csv')\n",
    "our_csvs += glob.glob('/home/code/experiments/*/submission*.csv')\n",
    "our_csvs += glob.glob('/home/code/experiments/*/*.csv')\n",
    "print(f\"Found {len(our_csvs)} CSV files from our experiments\")\n",
    "\n",
    "all_csvs = list(set(snapshot_csvs + our_csvs))\n",
    "print(f\"Total unique CSV files: {len(all_csvs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ce894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all CSV files and find the best ones\n",
    "print(\"Scoring all CSV files...\")\n",
    "\n",
    "csv_scores = []\n",
    "for i, csv_path in enumerate(all_csvs):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"  Processing {i+1}/{len(all_csvs)}...\")\n",
    "    \n",
    "    total_score, scores_per_n = score_csv_fast(csv_path)\n",
    "    if total_score < float('inf'):\n",
    "        csv_scores.append({\n",
    "            'path': csv_path,\n",
    "            'total_score': total_score,\n",
    "            'scores_per_n': scores_per_n\n",
    "        })\n",
    "\n",
    "print(f\"\\nSuccessfully scored {len(csv_scores)} valid CSV files\")\n",
    "\n",
    "# Sort by total score\n",
    "csv_scores.sort(key=lambda x: x['total_score'])\n",
    "\n",
    "# Show top 10\n",
    "print(\"\\nTop 10 CSV files by total score:\")\n",
    "for i, entry in enumerate(csv_scores[:10]):\n",
    "    print(f\"  {i+1}. Score: {entry['total_score']:.6f} - {entry['path'].split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble: for each N, pick the best configuration across all sources\n",
    "print(\"\\nBuilding ensemble baseline...\")\n",
    "\n",
    "ensemble_configs = {}  # n -> (best_score, best_source, config_data)\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    best_data = None\n",
    "    \n",
    "    for entry in csv_scores:\n",
    "        if n in entry['scores_per_n'] and entry['scores_per_n'][n] < best_score:\n",
    "            best_score = entry['scores_per_n'][n]\n",
    "            best_source = entry['path']\n",
    "    \n",
    "    ensemble_configs[n] = {\n",
    "        'score': best_score,\n",
    "        'source': best_source\n",
    "    }\n",
    "\n",
    "# Calculate ensemble total score\n",
    "ensemble_total = sum(ensemble_configs[n]['score'] for n in range(1, 201))\n",
    "print(f\"Ensemble baseline total score: {ensemble_total:.6f}\")\n",
    "\n",
    "# Show improvement breakdown\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Best single CSV: {csv_scores[0]['total_score']:.6f}\")\n",
    "print(f\"  Ensemble baseline: {ensemble_total:.6f}\")\n",
    "print(f\"  Improvement: {csv_scores[0]['total_score'] - ensemble_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39763e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ensemble CSV by extracting best configs from each source\n",
    "print(\"\\nCreating ensemble CSV...\")\n",
    "\n",
    "ensemble_rows = []\n",
    "source_counts = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    source_path = ensemble_configs[n]['source']\n",
    "    if source_path is None:\n",
    "        print(f\"  WARNING: No valid source for N={n}\")\n",
    "        continue\n",
    "    \n",
    "    # Track source usage\n",
    "    source_name = source_path.split('/')[-1]\n",
    "    source_counts[source_name] = source_counts.get(source_name, 0) + 1\n",
    "    \n",
    "    # Load the configuration for this N\n",
    "    df = pd.read_csv(source_path)\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    group = df[df['N'] == n]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        ensemble_rows.append({\n",
    "            'id': row['id'],\n",
    "            'x': row['x'],\n",
    "            'y': row['y'],\n",
    "            'deg': row['deg']\n",
    "        })\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "ensemble_df.to_csv('/home/code/experiments/003_ensemble/ensemble_baseline.csv', index=False)\n",
    "\n",
    "print(f\"Ensemble CSV created with {len(ensemble_rows)} rows\")\n",
    "print(f\"\\nSource distribution (top 10):\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  {source}: {count} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb39ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify ensemble score\n",
    "verify_score, _ = score_csv_fast('/home/code/experiments/003_ensemble/ensemble_baseline.csv')\n",
    "print(f\"Verified ensemble score: {verify_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322da12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply our optimization pipeline to the ensemble baseline\n",
    "# First, copy the C++ optimizer from experiment 002\n",
    "shutil.copy('/home/code/experiments/002_multiphase/tree_packer_v2.cpp',\n",
    "            '/home/code/experiments/003_ensemble/tree_packer_v2.cpp')\n",
    "\n",
    "# Compile\n",
    "os.chdir('/home/code/experiments/003_ensemble')\n",
    "result = subprocess.run(\n",
    "    ['g++', '-O3', '-march=native', '-std=c++17', '-fopenmp', '-o', 'tree_packer_v2', 'tree_packer_v2.cpp'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if result.returncode == 0:\n",
    "    print(\"C++ optimizer compiled successfully\")\n",
    "else:\n",
    "    print(f\"Compilation failed: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf53d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy ensemble baseline to working file\n",
    "shutil.copy('/home/code/experiments/003_ensemble/ensemble_baseline.csv',\n",
    "            '/home/code/experiments/003_ensemble/submission.csv')\n",
    "\n",
    "print(f\"Starting optimization from ensemble baseline (score: {verify_score:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f72af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization with higher iterations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 1: C++ Optimizer on Ensemble Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_score = verify_score\n",
    "best_file = '/home/code/experiments/003_ensemble/submission.csv'\n",
    "\n",
    "for seed in range(3):\n",
    "    print(f\"\\n--- Seed {seed} ---\")\n",
    "    \n",
    "    if seed > 0:\n",
    "        shutil.copy(best_file, '/home/code/experiments/003_ensemble/submission.csv')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = subprocess.run(\n",
    "        ['./tree_packer_v2', '-n', '10000', '-r', '96', '-s', str(seed)],\n",
    "        capture_output=True, text=True,\n",
    "        cwd='/home/code/experiments/003_ensemble'\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Completed in {elapsed:.1f}s\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if os.path.exists('/home/code/experiments/003_ensemble/submission_optimized.csv'):\n",
    "        new_score, _ = score_csv_fast('/home/code/experiments/003_ensemble/submission_optimized.csv')\n",
    "        print(f\"Score: {new_score:.6f}\")\n",
    "        \n",
    "        if new_score < best_score:\n",
    "            best_score = new_score\n",
    "            shutil.copy('/home/code/experiments/003_ensemble/submission_optimized.csv',\n",
    "                       f'/home/code/experiments/003_ensemble/best_seed{seed}.csv')\n",
    "            best_file = f'/home/code/experiments/003_ensemble/best_seed{seed}.csv'\n",
    "            shutil.copy(best_file, '/home/code/experiments/003_ensemble/submission.csv')\n",
    "            print(f\"NEW BEST: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nPhase 1 best score: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeffeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Backward Propagation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2: Backward Propagation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ChristmasTree class for validation\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def load_trees(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_side(trees):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n",
    "    return max(xys.max(axis=0) - xys.min(axis=0))\n",
    "\n",
    "def has_overlap(trees):\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    polygons = [t.polygon for t in trees]\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        for idx in tree_index.query(poly):\n",
    "            if idx != i and poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def backward_propagation(input_file, output_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    configs = {}\n",
    "    sides = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        trees = load_trees(n, df)\n",
    "        if trees:\n",
    "            configs[n] = trees\n",
    "            sides[n] = get_side(trees)\n",
    "    \n",
    "    print(f\"Initial score: {sum(s**2/n for n, s in sides.items()):.6f}\")\n",
    "    \n",
    "    improvements = 0\n",
    "    for n in range(200, 1, -1):\n",
    "        if n not in configs or (n-1) not in configs:\n",
    "            continue\n",
    "        \n",
    "        current_side = sides[n-1]\n",
    "        best_side = current_side\n",
    "        best_idx = None\n",
    "        \n",
    "        for tree_idx in range(n):\n",
    "            candidate = [t for i, t in enumerate(configs[n]) if i != tree_idx]\n",
    "            if len(candidate) != n - 1:\n",
    "                continue\n",
    "            cand_side = get_side(candidate)\n",
    "            if cand_side < best_side and not has_overlap(candidate):\n",
    "                best_side = cand_side\n",
    "                best_idx = tree_idx\n",
    "        \n",
    "        if best_idx is not None:\n",
    "            configs[n-1] = [t for i, t in enumerate(configs[n]) if i != best_idx]\n",
    "            sides[n-1] = best_side\n",
    "            improvements += 1\n",
    "    \n",
    "    print(f\"Improvements: {improvements}\")\n",
    "    \n",
    "    rows = []\n",
    "    for n in range(1, 201):\n",
    "        if n in configs:\n",
    "            for i, tree in enumerate(configs[n]):\n",
    "                rows.append({\n",
    "                    'id': f\"{n:03d}_{i}\",\n",
    "                    'x': f\"s{float(tree.center_x)}\",\n",
    "                    'y': f\"s{float(tree.center_y)}\",\n",
    "                    'deg': f\"s{float(tree.angle)}\"\n",
    "                })\n",
    "    \n",
    "    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
    "    final_score = sum(s**2/n for n, s in sides.items())\n",
    "    print(f\"Final score: {final_score:.6f}\")\n",
    "    return final_score\n",
    "\n",
    "bp_score = backward_propagation(best_file, '/home/code/experiments/003_ensemble/submission_bp.csv')\n",
    "if bp_score < best_score:\n",
    "    best_score = bp_score\n",
    "    best_file = '/home/code/experiments/003_ensemble/submission_bp.csv'\n",
    "    print(f\"Backward propagation improved to: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25929c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Fix Direction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 3: Fix Direction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def calculate_bbox_at_angle(angle_deg, points):\n",
    "    rad = np.radians(angle_deg)\n",
    "    c, s = np.cos(rad), np.sin(rad)\n",
    "    rot = points.dot(np.array([[c, s], [-s, c]]))\n",
    "    return max(rot.max(axis=0) - rot.min(axis=0))\n",
    "\n",
    "def optimize_rotation(trees):\n",
    "    pts = []\n",
    "    for t in trees:\n",
    "        pts.extend(list(t.polygon.exterior.coords))\n",
    "    pts = np.array(pts) / float(scale_factor)\n",
    "    try:\n",
    "        hull = pts[ConvexHull(pts).vertices]\n",
    "    except:\n",
    "        return get_side(trees), 0.0\n",
    "    \n",
    "    init = calculate_bbox_at_angle(0, hull)\n",
    "    res = minimize_scalar(lambda a: calculate_bbox_at_angle(a, hull), bounds=(0.001, 89.999), method='bounded')\n",
    "    if res.fun < init - 1e-8:\n",
    "        return res.fun, res.x\n",
    "    return init, 0.0\n",
    "\n",
    "def apply_rotation(trees, angle):\n",
    "    if not trees or abs(angle) < 1e-9:\n",
    "        return trees\n",
    "    \n",
    "    bounds = [t.polygon.bounds for t in trees]\n",
    "    center = np.array([(min(b[0] for b in bounds) + max(b[2] for b in bounds)) / 2,\n",
    "                       (min(b[1] for b in bounds) + max(b[3] for b in bounds)) / 2]) / float(scale_factor)\n",
    "    \n",
    "    rad = np.radians(angle)\n",
    "    c, s = np.cos(rad), np.sin(rad)\n",
    "    rot = np.array([[c, -s], [s, c]])\n",
    "    \n",
    "    pts = np.array([[float(t.center_x), float(t.center_y)] for t in trees])\n",
    "    rotated = (pts - center).dot(rot.T) + center\n",
    "    \n",
    "    return [ChristmasTree(str(rotated[i, 0]), str(rotated[i, 1]), str(float(trees[i].angle) + angle)) \n",
    "            for i in range(len(trees))]\n",
    "\n",
    "def fix_direction(input_path, output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "    configs = {}\n",
    "    sides = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        trees = load_trees(n, df)\n",
    "        if trees:\n",
    "            configs[n] = trees\n",
    "            sides[n] = get_side(trees)\n",
    "    \n",
    "    print(f\"Initial: {sum(s**2/n for n, s in sides.items()):.6f}\")\n",
    "    \n",
    "    improved = 0\n",
    "    for n in range(1, 201):\n",
    "        if n not in configs or len(configs[n]) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            best_side, best_angle = optimize_rotation(configs[n])\n",
    "            if abs(best_angle) > 0.001 and best_side < sides[n] - 1e-8:\n",
    "                rotated = apply_rotation(configs[n], best_angle)\n",
    "                if not has_overlap(rotated):\n",
    "                    configs[n] = rotated\n",
    "                    sides[n] = best_side\n",
    "                    improved += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"Improved {improved} groups\")\n",
    "    \n",
    "    rows = []\n",
    "    for n in range(1, 201):\n",
    "        if n in configs:\n",
    "            for i, tree in enumerate(configs[n]):\n",
    "                rows.append({\n",
    "                    'id': f\"{n:03d}_{i}\",\n",
    "                    'x': f\"s{float(tree.center_x)}\",\n",
    "                    'y': f\"s{float(tree.center_y)}\",\n",
    "                    'deg': f\"s{float(tree.angle)}\"\n",
    "                })\n",
    "    \n",
    "    pd.DataFrame(rows).to_csv(output_path, index=False)\n",
    "    final = sum(s**2/n for n, s in sides.items())\n",
    "    print(f\"Final: {final:.6f}\")\n",
    "    return final\n",
    "\n",
    "fd_score = fix_direction(best_file, '/home/code/experiments/003_ensemble/submission_fd.csv')\n",
    "if fd_score < best_score:\n",
    "    best_score = fd_score\n",
    "    best_file = '/home/code/experiments/003_ensemble/submission_fd.csv'\n",
    "    print(f\"Fix direction improved to: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation and copy to submission\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_score, _ = score_csv_fast(best_file)\n",
    "print(f\"Final score: {final_score:.6f}\")\n",
    "\n",
    "# Copy to submission folder\n",
    "shutil.copy(best_file, '/home/submission/submission.csv')\n",
    "print(f\"Copied to /home/submission/submission.csv\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Ensemble baseline: {verify_score:.6f}\")\n",
    "print(f\"Final optimized: {final_score:.6f}\")\n",
    "print(f\"Improvement: {verify_score - final_score:.6f}\")\n",
    "print(f\"Target: 68.931058\")\n",
    "print(f\"Gap to target: {final_score - 68.931058:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
