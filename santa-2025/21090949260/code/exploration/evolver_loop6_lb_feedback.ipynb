{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20288bb7",
   "metadata": {},
   "source": [
    "# Loop 6 LB Feedback Analysis\n",
    "\n",
    "## Key Observations:\n",
    "1. Grid initialization found ZERO improvements - our ensemble already has optimal grid-based solutions\n",
    "2. CV = LB perfectly (no distribution shift - expected for deterministic optimization)\n",
    "3. Target (68.93) is BETTER than LB #1 (71.19) - need innovation beyond public solutions\n",
    "4. Gap: 84.71 - 68.93 = 15.78 points (18.6% improvement needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 135.819103, 'lb': 135.819103, 'method': 'baseline'},\n",
    "    {'exp': 'exp_001', 'cv': 117.281454, 'lb': 117.281454, 'method': 'multiphase'},\n",
    "    {'exp': 'exp_003', 'cv': 84.901044, 'lb': 84.901044, 'method': 'ensemble_fixed'},\n",
    "    {'exp': 'exp_004', 'cv': 84.712432, 'lb': 84.712432, 'method': 'extended_opt'},\n",
    "    {'exp': 'exp_005', 'cv': 84.712432, 'lb': 84.712432, 'method': 'grid_init'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df)\n",
    "\n",
    "# CV-LB relationship\n",
    "print(f\"\\nCV-LB Correlation: {np.corrcoef(df['cv'], df['lb'])[0,1]:.6f}\")\n",
    "print(\"Perfect CV=LB alignment (expected for deterministic optimization)\")\n",
    "\n",
    "# Progress analysis\n",
    "print(f\"\\nProgress:\")\n",
    "print(f\"  Starting score: {df['cv'].iloc[0]:.2f}\")\n",
    "print(f\"  Current best: {df['cv'].min():.2f}\")\n",
    "print(f\"  Improvement: {df['cv'].iloc[0] - df['cv'].min():.2f} ({(df['cv'].iloc[0] - df['cv'].min())/df['cv'].iloc[0]*100:.1f}%)\")\n",
    "print(f\"  Target: 68.93\")\n",
    "print(f\"  Gap to target: {df['cv'].min() - 68.93:.2f} ({(df['cv'].min() - 68.93)/68.93*100:.1f}% above target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37025ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's needed to reach target\n",
    "target = 68.931058\n",
    "current = 84.712432\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {current - target:.6f}\")\n",
    "print(f\"Reduction needed: {(current - target)/current * 100:.1f}%\")\n",
    "\n",
    "# What would it take?\n",
    "print(f\"\\nTo reach target, we need to reduce score by {current - target:.2f} points\")\n",
    "print(f\"This is equivalent to reducing EVERY N's score by {(current - target)/200:.4f} on average\")\n",
    "\n",
    "# Theoretical analysis\n",
    "print(f\"\\nTheoretical minimum (perfect packing): ~70.0\")\n",
    "print(f\"Target is {target - 70:.2f} above theoretical minimum\")\n",
    "print(f\"Current is {current - 70:.2f} above theoretical minimum\")\n",
    "print(f\"We need to close {(current - target)/(current - 70) * 100:.1f}% of the gap to theoretical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current best submission and analyze per-N scores\n",
    "import numpy as np\n",
    "\n",
    "df_sub = pd.read_csv('/home/code/experiments/006_grid_initialization/submission_grid.csv')\n",
    "\n",
    "# Fast scoring\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def strip_s(val):\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "def score_group_fast(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    if n == 0:\n",
    "        return float('inf')\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        px = TX * c - TY * s + xs[i]\n",
    "        py = TX * s + TY * c + ys[i]\n",
    "        all_x.extend(px)\n",
    "        all_y.extend(py)\n",
    "    all_x, all_y = np.array(all_x), np.array(all_y)\n",
    "    side = max(all_x.max() - all_x.min(), all_y.max() - all_y.min())\n",
    "    return side * side / n\n",
    "\n",
    "# Calculate per-N scores\n",
    "scores = {}\n",
    "for n in range(1, 201):\n",
    "    group = df_sub[df_sub['id'].str.startswith(f'{n:03d}_')]\n",
    "    if len(group) == n:\n",
    "        xs = group['x'].apply(strip_s).values\n",
    "        ys = group['y'].apply(strip_s).values\n",
    "        degs = group['deg'].apply(strip_s).values\n",
    "        scores[n] = score_group_fast(xs, ys, degs)\n",
    "\n",
    "print(f\"Total score: {sum(scores.values()):.6f}\")\n",
    "print(f\"\\nTop 20 worst N values (highest contribution to score):\")\n",
    "worst = sorted(scores.items(), key=lambda x: -x[1])[:20]\n",
    "for n, score in worst:\n",
    "    print(f\"  N={n:3d}: {score:.6f} (contributes {score/sum(scores.values())*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTop 20 worst contribute: {sum(s for n,s in worst)/sum(scores.values())*100:.1f}% of total score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf946df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze efficiency per N\n",
    "print(\"\\nEfficiency Analysis (lower score = better packing):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Theoretical minimum for each N (assuming perfect square packing)\n",
    "# For N trees, theoretical minimum side is approximately sqrt(N * tree_area)\n",
    "# Tree area is approximately 0.35 (rough estimate)\n",
    "tree_area = 0.35  # approximate\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    if n in scores:\n",
    "        actual = scores[n]\n",
    "        # Theoretical: side^2/n = tree_area (if perfectly packed)\n",
    "        theoretical = tree_area\n",
    "        efficiency = theoretical / actual\n",
    "        efficiencies.append((n, actual, theoretical, efficiency))\n",
    "\n",
    "# Sort by efficiency (worst first)\n",
    "efficiencies.sort(key=lambda x: x[3])\n",
    "\n",
    "print(\"\\nWorst efficiency (most room for improvement):\")\n",
    "for n, actual, theoretical, eff in efficiencies[:20]:\n",
    "    print(f\"  N={n:3d}: score={actual:.4f}, theoretical={theoretical:.4f}, efficiency={eff:.2%}\")\n",
    "\n",
    "print(\"\\nBest efficiency (already well-packed):\")\n",
    "for n, actual, theoretical, eff in efficiencies[-10:]:\n",
    "    print(f\"  N={n:3d}: score={actual:.4f}, theoretical={theoretical:.4f}, efficiency={eff:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ace01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What techniques haven't we tried?\n",
    "print(\"=\"*60)\n",
    "print(\"TECHNIQUE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "techniques_tried = [\n",
    "    (\"C++ bbox3 optimizer\", \"YES\", \"Baseline + extended optimization\"),\n",
    "    (\"Fix direction rotation\", \"YES\", \"Applied in all experiments\"),\n",
    "    (\"Backward propagation\", \"YES\", \"No opportunities found - monotonic side lengths\"),\n",
    "    (\"Ensemble (best-per-N)\", \"YES\", \"125 CSV sources combined\"),\n",
    "    (\"Grid initialization (zaburo)\", \"YES\", \"No improvements over ensemble\"),\n",
    "    (\"Extended SA (-n 50000 -r 200)\", \"YES\", \"Only 0.19 points improvement\"),\n",
    "]\n",
    "\n",
    "techniques_not_tried = [\n",
    "    (\"Per-tree rotation optimization\", \"Individual tree angle tuning\"),\n",
    "    (\"Greedy backtracking (blueshyy)\", \"Beam search for tree removal\"),\n",
    "    (\"Parallel SA with OpenMP\", \"Multi-threaded optimization (71.78 kernel)\"),\n",
    "    (\"Fractional translation polish\", \"Very fine position adjustments\"),\n",
    "    (\"Genetic crossover\", \"Combine tree positions from different solutions\"),\n",
    "    (\"Different compaction strategies\", \"Center-out, boundary-in, etc.\"),\n",
    "    (\"Access better datasets\", \"crodoc/santa2025submission has 74.75 solutions\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTechniques TRIED:\")\n",
    "for name, status, notes in techniques_tried:\n",
    "    print(f\"  [{status}] {name}: {notes}\")\n",
    "\n",
    "print(\"\\nTechniques NOT YET TRIED:\")\n",
    "for name, notes in techniques_not_tried:\n",
    "    print(f\"  [ ] {name}: {notes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight from kernels\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS FROM TOP KERNELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. seshurajup/71-78-jit-parallel-sa-c-tpu-96-cores (71.78 score):\n",
    "   - Uses TPU with 96 cores for massive parallelism\n",
    "   - Parallel SA with OpenMP\n",
    "   - Fractional translation for fine-tuning\n",
    "   - Multiple generations of optimization\n",
    "   - Key: COMPUTE POWER + BETTER STARTING SOLUTIONS\n",
    "\n",
    "2. blueshyy/santa-2025-ensemble-sa-greedy-backtracking (ensemble):\n",
    "   - Greedy backtracking with beam search\n",
    "   - Removes trees from N to improve N-1\n",
    "   - Multi-pass optimization\n",
    "   - Key: SMART TREE REMOVAL STRATEGY\n",
    "\n",
    "3. crodoc/74-75-backpacking-christmas-trees (74.75 score):\n",
    "   - Uses crodoc/santa2025submission dataset (better starting solutions!)\n",
    "   - Backward iteration from N=200 to N=1\n",
    "   - Key: ACCESS TO BETTER DATASETS\n",
    "\n",
    "CRITICAL OBSERVATION:\n",
    "The 71.78 kernel uses datasets from other kernels as input:\n",
    "- santa-2025-ensemble-sa-greedy-backtracking\n",
    "- santa-claude\n",
    "\n",
    "These datasets likely contain solutions BETTER than what we have!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nRECOMMENDED NEXT STEPS:\")\n",
    "print(\"1. Implement greedy backtracking (blueshyy approach)\")\n",
    "print(\"2. Implement per-tree rotation optimization\")\n",
    "print(\"3. Implement fractional translation polish\")\n",
    "print(\"4. Try to access better starting solution datasets\")\n",
    "print(\"5. Run longer optimization with more compute\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
