{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20288bb7",
   "metadata": {},
   "source": [
    "# Loop 6 LB Feedback Analysis\n",
    "\n",
    "## Key Observations:\n",
    "1. Grid initialization found ZERO improvements - our ensemble already has optimal grid-based solutions\n",
    "2. CV = LB perfectly (no distribution shift - expected for deterministic optimization)\n",
    "3. Target (68.93) is BETTER than LB #1 (71.19) - need innovation beyond public solutions\n",
    "4. Gap: 84.71 - 68.93 = 15.78 points (18.6% improvement needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1425d550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:26.866459Z",
     "iopub.status.busy": "2026-01-17T10:54:26.866027Z",
     "iopub.status.idle": "2026-01-17T10:54:27.460552Z",
     "shell.execute_reply": "2026-01-17T10:54:27.460112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission History:\n",
      "       exp          cv          lb          method\n",
      "0  exp_000  135.819103  135.819103        baseline\n",
      "1  exp_001  117.281454  117.281454      multiphase\n",
      "2  exp_003   84.901044   84.901044  ensemble_fixed\n",
      "3  exp_004   84.712432   84.712432    extended_opt\n",
      "4  exp_005   84.712432   84.712432       grid_init\n",
      "\n",
      "CV-LB Correlation: 1.000000\n",
      "Perfect CV=LB alignment (expected for deterministic optimization)\n",
      "\n",
      "Progress:\n",
      "  Starting score: 135.82\n",
      "  Current best: 84.71\n",
      "  Improvement: 51.11 (37.6%)\n",
      "  Target: 68.93\n",
      "  Gap to target: 15.78 (22.9% above target)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load submission history\n",
    "submissions = [\n",
    "    {'exp': 'exp_000', 'cv': 135.819103, 'lb': 135.819103, 'method': 'baseline'},\n",
    "    {'exp': 'exp_001', 'cv': 117.281454, 'lb': 117.281454, 'method': 'multiphase'},\n",
    "    {'exp': 'exp_003', 'cv': 84.901044, 'lb': 84.901044, 'method': 'ensemble_fixed'},\n",
    "    {'exp': 'exp_004', 'cv': 84.712432, 'lb': 84.712432, 'method': 'extended_opt'},\n",
    "    {'exp': 'exp_005', 'cv': 84.712432, 'lb': 84.712432, 'method': 'grid_init'},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(submissions)\n",
    "print(\"Submission History:\")\n",
    "print(df)\n",
    "\n",
    "# CV-LB relationship\n",
    "print(f\"\\nCV-LB Correlation: {np.corrcoef(df['cv'], df['lb'])[0,1]:.6f}\")\n",
    "print(\"Perfect CV=LB alignment (expected for deterministic optimization)\")\n",
    "\n",
    "# Progress analysis\n",
    "print(f\"\\nProgress:\")\n",
    "print(f\"  Starting score: {df['cv'].iloc[0]:.2f}\")\n",
    "print(f\"  Current best: {df['cv'].min():.2f}\")\n",
    "print(f\"  Improvement: {df['cv'].iloc[0] - df['cv'].min():.2f} ({(df['cv'].iloc[0] - df['cv'].min())/df['cv'].iloc[0]*100:.1f}%)\")\n",
    "print(f\"  Target: 68.93\")\n",
    "print(f\"  Gap to target: {df['cv'].min() - 68.93:.2f} ({(df['cv'].min() - 68.93)/68.93*100:.1f}% above target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37025ab5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:27.461752Z",
     "iopub.status.busy": "2026-01-17T10:54:27.461598Z",
     "iopub.status.idle": "2026-01-17T10:54:27.465416Z",
     "shell.execute_reply": "2026-01-17T10:54:27.465021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GAP ANALYSIS\n",
      "============================================================\n",
      "Current score: 84.712432\n",
      "Target score: 68.931058\n",
      "Gap: 15.781374\n",
      "Reduction needed: 18.6%\n",
      "\n",
      "To reach target, we need to reduce score by 15.78 points\n",
      "This is equivalent to reducing EVERY N's score by 0.0789 on average\n",
      "\n",
      "Theoretical minimum (perfect packing): ~70.0\n",
      "Target is -1.07 above theoretical minimum\n",
      "Current is 14.71 above theoretical minimum\n",
      "We need to close 107.3% of the gap to theoretical\n"
     ]
    }
   ],
   "source": [
    "# Analyze what's needed to reach target\n",
    "target = 68.931058\n",
    "current = 84.712432\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {current - target:.6f}\")\n",
    "print(f\"Reduction needed: {(current - target)/current * 100:.1f}%\")\n",
    "\n",
    "# What would it take?\n",
    "print(f\"\\nTo reach target, we need to reduce score by {current - target:.2f} points\")\n",
    "print(f\"This is equivalent to reducing EVERY N's score by {(current - target)/200:.4f} on average\")\n",
    "\n",
    "# Theoretical analysis\n",
    "print(f\"\\nTheoretical minimum (perfect packing): ~70.0\")\n",
    "print(f\"Target is {target - 70:.2f} above theoretical minimum\")\n",
    "print(f\"Current is {current - 70:.2f} above theoretical minimum\")\n",
    "print(f\"We need to close {(current - target)/(current - 70) * 100:.1f}% of the gap to theoretical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d1dd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:27.466408Z",
     "iopub.status.busy": "2026-01-17T10:54:27.466290Z",
     "iopub.status.idle": "2026-01-17T10:54:28.239469Z",
     "shell.execute_reply": "2026-01-17T10:54:28.239046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 84.712432\n",
      "\n",
      "Top 20 worst N values (highest contribution to score):\n",
      "  N=  1: 0.661250 (contributes 0.78%)\n",
      "  N= 49: 0.490000 (contributes 0.58%)\n",
      "  N= 21: 0.487619 (contributes 0.58%)\n",
      "  N= 50: 0.480200 (contributes 0.57%)\n",
      "  N= 20: 0.478371 (contributes 0.56%)\n",
      "  N= 37: 0.476757 (contributes 0.56%)\n",
      "  N= 53: 0.471698 (contributes 0.56%)\n",
      "  N= 51: 0.470784 (contributes 0.56%)\n",
      "  N= 34: 0.470588 (contributes 0.56%)\n",
      "  N= 19: 0.468739 (contributes 0.55%)\n",
      "  N= 32: 0.468214 (contributes 0.55%)\n",
      "  N= 76: 0.465822 (contributes 0.55%)\n",
      "  N= 22: 0.465455 (contributes 0.55%)\n",
      "  N= 38: 0.464211 (contributes 0.55%)\n",
      "  N= 54: 0.462963 (contributes 0.55%)\n",
      "  N= 52: 0.461731 (contributes 0.55%)\n",
      "  N= 45: 0.460056 (contributes 0.54%)\n",
      "  N= 18: 0.460021 (contributes 0.54%)\n",
      "  N= 77: 0.459773 (contributes 0.54%)\n",
      "  N= 35: 0.457143 (contributes 0.54%)\n",
      "\n",
      "Top 20 worst contribute: 11.3% of total score\n"
     ]
    }
   ],
   "source": [
    "# Load current best submission and analyze per-N scores\n",
    "import numpy as np\n",
    "\n",
    "df_sub = pd.read_csv('/home/code/experiments/006_grid_initialization/submission_grid.csv')\n",
    "\n",
    "# Fast scoring\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def strip_s(val):\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "def score_group_fast(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    if n == 0:\n",
    "        return float('inf')\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        px = TX * c - TY * s + xs[i]\n",
    "        py = TX * s + TY * c + ys[i]\n",
    "        all_x.extend(px)\n",
    "        all_y.extend(py)\n",
    "    all_x, all_y = np.array(all_x), np.array(all_y)\n",
    "    side = max(all_x.max() - all_x.min(), all_y.max() - all_y.min())\n",
    "    return side * side / n\n",
    "\n",
    "# Calculate per-N scores\n",
    "scores = {}\n",
    "for n in range(1, 201):\n",
    "    group = df_sub[df_sub['id'].str.startswith(f'{n:03d}_')]\n",
    "    if len(group) == n:\n",
    "        xs = group['x'].apply(strip_s).values\n",
    "        ys = group['y'].apply(strip_s).values\n",
    "        degs = group['deg'].apply(strip_s).values\n",
    "        scores[n] = score_group_fast(xs, ys, degs)\n",
    "\n",
    "print(f\"Total score: {sum(scores.values()):.6f}\")\n",
    "print(f\"\\nTop 20 worst N values (highest contribution to score):\")\n",
    "worst = sorted(scores.items(), key=lambda x: -x[1])[:20]\n",
    "for n, score in worst:\n",
    "    print(f\"  N={n:3d}: {score:.6f} (contributes {score/sum(scores.values())*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTop 20 worst contribute: {sum(s for n,s in worst)/sum(scores.values())*100:.1f}% of total score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf946df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:28.240483Z",
     "iopub.status.busy": "2026-01-17T10:54:28.240374Z",
     "iopub.status.idle": "2026-01-17T10:54:28.244741Z",
     "shell.execute_reply": "2026-01-17T10:54:28.244366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efficiency Analysis (lower score = better packing):\n",
      "============================================================\n",
      "\n",
      "Worst efficiency (most room for improvement):\n",
      "  N=  1: score=0.6612, theoretical=0.3500, efficiency=52.93%\n",
      "  N= 49: score=0.4900, theoretical=0.3500, efficiency=71.43%\n",
      "  N= 21: score=0.4876, theoretical=0.3500, efficiency=71.78%\n",
      "  N= 50: score=0.4802, theoretical=0.3500, efficiency=72.89%\n",
      "  N= 20: score=0.4784, theoretical=0.3500, efficiency=73.16%\n",
      "  N= 37: score=0.4768, theoretical=0.3500, efficiency=73.41%\n",
      "  N= 53: score=0.4717, theoretical=0.3500, efficiency=74.20%\n",
      "  N= 51: score=0.4708, theoretical=0.3500, efficiency=74.34%\n",
      "  N= 34: score=0.4706, theoretical=0.3500, efficiency=74.37%\n",
      "  N= 19: score=0.4687, theoretical=0.3500, efficiency=74.67%\n",
      "  N= 32: score=0.4682, theoretical=0.3500, efficiency=74.75%\n",
      "  N= 76: score=0.4658, theoretical=0.3500, efficiency=75.14%\n",
      "  N= 22: score=0.4655, theoretical=0.3500, efficiency=75.20%\n",
      "  N= 38: score=0.4642, theoretical=0.3500, efficiency=75.40%\n",
      "  N= 54: score=0.4630, theoretical=0.3500, efficiency=75.60%\n",
      "  N= 52: score=0.4617, theoretical=0.3500, efficiency=75.80%\n",
      "  N= 45: score=0.4601, theoretical=0.3500, efficiency=76.08%\n",
      "  N= 18: score=0.4600, theoretical=0.3500, efficiency=76.08%\n",
      "  N= 77: score=0.4598, theoretical=0.3500, efficiency=76.12%\n",
      "  N= 35: score=0.4571, theoretical=0.3500, efficiency=76.56%\n",
      "\n",
      "Best efficiency (already well-packed):\n",
      "  N=102: score=0.3891, theoretical=0.3500, efficiency=89.95%\n",
      "  N=173: score=0.3887, theoretical=0.3500, efficiency=90.05%\n",
      "  N=139: score=0.3887, theoretical=0.3500, efficiency=90.06%\n",
      "  N=182: score=0.3877, theoretical=0.3500, efficiency=90.28%\n",
      "  N=174: score=0.3864, theoretical=0.3500, efficiency=90.57%\n",
      "  N=140: score=0.3859, theoretical=0.3500, efficiency=90.70%\n",
      "  N=183: score=0.3856, theoretical=0.3500, efficiency=90.77%\n",
      "  N=175: score=0.3842, theoretical=0.3500, efficiency=91.09%\n",
      "  N=184: score=0.3835, theoretical=0.3500, efficiency=91.27%\n",
      "  N=176: score=0.3820, theoretical=0.3500, efficiency=91.61%\n"
     ]
    }
   ],
   "source": [
    "# Analyze efficiency per N\n",
    "print(\"\\nEfficiency Analysis (lower score = better packing):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Theoretical minimum for each N (assuming perfect square packing)\n",
    "# For N trees, theoretical minimum side is approximately sqrt(N * tree_area)\n",
    "# Tree area is approximately 0.35 (rough estimate)\n",
    "tree_area = 0.35  # approximate\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    if n in scores:\n",
    "        actual = scores[n]\n",
    "        # Theoretical: side^2/n = tree_area (if perfectly packed)\n",
    "        theoretical = tree_area\n",
    "        efficiency = theoretical / actual\n",
    "        efficiencies.append((n, actual, theoretical, efficiency))\n",
    "\n",
    "# Sort by efficiency (worst first)\n",
    "efficiencies.sort(key=lambda x: x[3])\n",
    "\n",
    "print(\"\\nWorst efficiency (most room for improvement):\")\n",
    "for n, actual, theoretical, eff in efficiencies[:20]:\n",
    "    print(f\"  N={n:3d}: score={actual:.4f}, theoretical={theoretical:.4f}, efficiency={eff:.2%}\")\n",
    "\n",
    "print(\"\\nBest efficiency (already well-packed):\")\n",
    "for n, actual, theoretical, eff in efficiencies[-10:]:\n",
    "    print(f\"  N={n:3d}: score={actual:.4f}, theoretical={theoretical:.4f}, efficiency={eff:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225ace01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:28.245823Z",
     "iopub.status.busy": "2026-01-17T10:54:28.245719Z",
     "iopub.status.idle": "2026-01-17T10:54:28.249664Z",
     "shell.execute_reply": "2026-01-17T10:54:28.249287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TECHNIQUE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Techniques TRIED:\n",
      "  [YES] C++ bbox3 optimizer: Baseline + extended optimization\n",
      "  [YES] Fix direction rotation: Applied in all experiments\n",
      "  [YES] Backward propagation: No opportunities found - monotonic side lengths\n",
      "  [YES] Ensemble (best-per-N): 125 CSV sources combined\n",
      "  [YES] Grid initialization (zaburo): No improvements over ensemble\n",
      "  [YES] Extended SA (-n 50000 -r 200): Only 0.19 points improvement\n",
      "\n",
      "Techniques NOT YET TRIED:\n",
      "  [ ] Per-tree rotation optimization: Individual tree angle tuning\n",
      "  [ ] Greedy backtracking (blueshyy): Beam search for tree removal\n",
      "  [ ] Parallel SA with OpenMP: Multi-threaded optimization (71.78 kernel)\n",
      "  [ ] Fractional translation polish: Very fine position adjustments\n",
      "  [ ] Genetic crossover: Combine tree positions from different solutions\n",
      "  [ ] Different compaction strategies: Center-out, boundary-in, etc.\n",
      "  [ ] Access better datasets: crodoc/santa2025submission has 74.75 solutions\n"
     ]
    }
   ],
   "source": [
    "# What techniques haven't we tried?\n",
    "print(\"=\"*60)\n",
    "print(\"TECHNIQUE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "techniques_tried = [\n",
    "    (\"C++ bbox3 optimizer\", \"YES\", \"Baseline + extended optimization\"),\n",
    "    (\"Fix direction rotation\", \"YES\", \"Applied in all experiments\"),\n",
    "    (\"Backward propagation\", \"YES\", \"No opportunities found - monotonic side lengths\"),\n",
    "    (\"Ensemble (best-per-N)\", \"YES\", \"125 CSV sources combined\"),\n",
    "    (\"Grid initialization (zaburo)\", \"YES\", \"No improvements over ensemble\"),\n",
    "    (\"Extended SA (-n 50000 -r 200)\", \"YES\", \"Only 0.19 points improvement\"),\n",
    "]\n",
    "\n",
    "techniques_not_tried = [\n",
    "    (\"Per-tree rotation optimization\", \"Individual tree angle tuning\"),\n",
    "    (\"Greedy backtracking (blueshyy)\", \"Beam search for tree removal\"),\n",
    "    (\"Parallel SA with OpenMP\", \"Multi-threaded optimization (71.78 kernel)\"),\n",
    "    (\"Fractional translation polish\", \"Very fine position adjustments\"),\n",
    "    (\"Genetic crossover\", \"Combine tree positions from different solutions\"),\n",
    "    (\"Different compaction strategies\", \"Center-out, boundary-in, etc.\"),\n",
    "    (\"Access better datasets\", \"crodoc/santa2025submission has 74.75 solutions\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTechniques TRIED:\")\n",
    "for name, status, notes in techniques_tried:\n",
    "    print(f\"  [{status}] {name}: {notes}\")\n",
    "\n",
    "print(\"\\nTechniques NOT YET TRIED:\")\n",
    "for name, notes in techniques_not_tried:\n",
    "    print(f\"  [ ] {name}: {notes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5120e047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T10:54:28.250716Z",
     "iopub.status.busy": "2026-01-17T10:54:28.250605Z",
     "iopub.status.idle": "2026-01-17T10:54:28.253907Z",
     "shell.execute_reply": "2026-01-17T10:54:28.253535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KEY INSIGHTS FROM TOP KERNELS\n",
      "============================================================\n",
      "\n",
      "1. seshurajup/71-78-jit-parallel-sa-c-tpu-96-cores (71.78 score):\n",
      "   - Uses TPU with 96 cores for massive parallelism\n",
      "   - Parallel SA with OpenMP\n",
      "   - Fractional translation for fine-tuning\n",
      "   - Multiple generations of optimization\n",
      "   - Key: COMPUTE POWER + BETTER STARTING SOLUTIONS\n",
      "\n",
      "2. blueshyy/santa-2025-ensemble-sa-greedy-backtracking (ensemble):\n",
      "   - Greedy backtracking with beam search\n",
      "   - Removes trees from N to improve N-1\n",
      "   - Multi-pass optimization\n",
      "   - Key: SMART TREE REMOVAL STRATEGY\n",
      "\n",
      "3. crodoc/74-75-backpacking-christmas-trees (74.75 score):\n",
      "   - Uses crodoc/santa2025submission dataset (better starting solutions!)\n",
      "   - Backward iteration from N=200 to N=1\n",
      "   - Key: ACCESS TO BETTER DATASETS\n",
      "\n",
      "CRITICAL OBSERVATION:\n",
      "The 71.78 kernel uses datasets from other kernels as input:\n",
      "- santa-2025-ensemble-sa-greedy-backtracking\n",
      "- santa-claude\n",
      "\n",
      "These datasets likely contain solutions BETTER than what we have!\n",
      "\n",
      "\n",
      "RECOMMENDED NEXT STEPS:\n",
      "1. Implement greedy backtracking (blueshyy approach)\n",
      "2. Implement per-tree rotation optimization\n",
      "3. Implement fractional translation polish\n",
      "4. Try to access better starting solution datasets\n",
      "5. Run longer optimization with more compute\n"
     ]
    }
   ],
   "source": [
    "# Key insight from kernels\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS FROM TOP KERNELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. seshurajup/71-78-jit-parallel-sa-c-tpu-96-cores (71.78 score):\n",
    "   - Uses TPU with 96 cores for massive parallelism\n",
    "   - Parallel SA with OpenMP\n",
    "   - Fractional translation for fine-tuning\n",
    "   - Multiple generations of optimization\n",
    "   - Key: COMPUTE POWER + BETTER STARTING SOLUTIONS\n",
    "\n",
    "2. blueshyy/santa-2025-ensemble-sa-greedy-backtracking (ensemble):\n",
    "   - Greedy backtracking with beam search\n",
    "   - Removes trees from N to improve N-1\n",
    "   - Multi-pass optimization\n",
    "   - Key: SMART TREE REMOVAL STRATEGY\n",
    "\n",
    "3. crodoc/74-75-backpacking-christmas-trees (74.75 score):\n",
    "   - Uses crodoc/santa2025submission dataset (better starting solutions!)\n",
    "   - Backward iteration from N=200 to N=1\n",
    "   - Key: ACCESS TO BETTER DATASETS\n",
    "\n",
    "CRITICAL OBSERVATION:\n",
    "The 71.78 kernel uses datasets from other kernels as input:\n",
    "- santa-2025-ensemble-sa-greedy-backtracking\n",
    "- santa-claude\n",
    "\n",
    "These datasets likely contain solutions BETTER than what we have!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nRECOMMENDED NEXT STEPS:\")\n",
    "print(\"1. Implement greedy backtracking (blueshyy approach)\")\n",
    "print(\"2. Implement per-tree rotation optimization\")\n",
    "print(\"3. Implement fractional translation polish\")\n",
    "print(\"4. Try to access better starting solution datasets\")\n",
    "print(\"5. Run longer optimization with more compute\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
