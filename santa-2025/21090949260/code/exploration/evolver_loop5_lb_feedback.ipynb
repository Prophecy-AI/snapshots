{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446011c6",
   "metadata": {},
   "source": [
    "# Loop 5 LB Feedback Analysis\n",
    "\n",
    "**Latest submission:** exp_004 (005_extended_optimization)\n",
    "- CV: 84.712432\n",
    "- LB: 84.712432 (gap: 0.0000)\n",
    "\n",
    "**Key observations:**\n",
    "1. Perfect CV-LB alignment (expected for deterministic optimization)\n",
    "2. Extended optimization (57 min) yielded only 0.19 points improvement\n",
    "3. Diminishing returns signal we're hitting local optimum\n",
    "4. Gap to target: 15.78 points (22.9%)\n",
    "\n",
    "**Analysis goals:**\n",
    "1. Understand worst-performing N values\n",
    "2. Identify opportunities for aggressive backward propagation\n",
    "3. Analyze grid-based initialization potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load current best submission\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "\n",
    "# Parse values\n",
    "def strip_s(val):\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "df['x_val'] = df['x'].apply(strip_s)\n",
    "df['y_val'] = df['y'].apply(strip_s)\n",
    "df['deg_val'] = df['deg'].apply(strip_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast scoring\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def score_group_fast(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    if n == 0:\n",
    "        return float('inf'), 0\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        px = TX * c - TY * s + xs[i]\n",
    "        py = TX * s + TY * c + ys[i]\n",
    "        all_x.extend(px)\n",
    "        all_y.extend(py)\n",
    "    all_x, all_y = np.array(all_x), np.array(all_y)\n",
    "    side = max(all_x.max() - all_x.min(), all_y.max() - all_y.min())\n",
    "    return side * side / n, side\n",
    "\n",
    "# Calculate scores for each N\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    g = df[df['N'] == n]\n",
    "    if len(g) == n:\n",
    "        score, side = score_group_fast(g['x_val'].values, g['y_val'].values, g['deg_val'].values)\n",
    "        scores.append({'N': n, 'score': score, 'side': side, 'contribution': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "total_score = scores_df['score'].sum()\n",
    "print(f\"Total score: {total_score:.6f}\")\n",
    "print(f\"Target: 68.931058\")\n",
    "print(f\"Gap: {total_score - 68.931058:.6f} ({(total_score - 68.931058)/68.931058*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze worst performing N values\n",
    "scores_df['pct_contribution'] = scores_df['score'] / total_score * 100\n",
    "scores_df = scores_df.sort_values('score', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 20 WORST N VALUES ===\")\n",
    "print(scores_df.head(20).to_string())\n",
    "\n",
    "print(f\"\\nTop 20 worst contribute: {scores_df.head(20)['pct_contribution'].sum():.2f}% of total\")\n",
    "print(f\"Top 10 worst contribute: {scores_df.head(10)['pct_contribution'].sum():.2f}% of total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76757726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution by N\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(scores_df['N'], scores_df['score'], alpha=0.6, s=20)\n",
    "plt.xlabel('N (number of trees)')\n",
    "plt.ylabel('Score (side²/N)')\n",
    "plt.title('Score by N')\n",
    "plt.axhline(y=68.931058/200, color='r', linestyle='--', label='Target avg')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(scores_df['N'], scores_df['side'], alpha=0.6, s=20)\n",
    "plt.xlabel('N (number of trees)')\n",
    "plt.ylabel('Side length')\n",
    "plt.title('Side length by N')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/loop5_score_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved to loop5_score_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a19162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze potential for backward propagation\n",
    "# For each N, compare side length to N+1, N+2, etc.\n",
    "scores_sorted = scores_df.sort_values('N').reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== BACKWARD PROPAGATION POTENTIAL ===\")\n",
    "print(\"Looking for N values where larger N has SMALLER side length (propagation opportunity)\")\n",
    "\n",
    "propagation_opportunities = []\n",
    "for i, row in scores_sorted.iterrows():\n",
    "    n = row['N']\n",
    "    current_side = row['side']\n",
    "    \n",
    "    # Check if any larger N has smaller side\n",
    "    larger = scores_sorted[scores_sorted['N'] > n]\n",
    "    if len(larger) > 0:\n",
    "        min_larger_side = larger['side'].min()\n",
    "        min_larger_n = larger.loc[larger['side'].idxmin(), 'N']\n",
    "        if min_larger_side < current_side:\n",
    "            improvement = (current_side - min_larger_side) / current_side * 100\n",
    "            propagation_opportunities.append({\n",
    "                'N': n,\n",
    "                'current_side': current_side,\n",
    "                'best_larger_N': min_larger_n,\n",
    "                'best_larger_side': min_larger_side,\n",
    "                'potential_improvement_pct': improvement\n",
    "            })\n",
    "\n",
    "if propagation_opportunities:\n",
    "    prop_df = pd.DataFrame(propagation_opportunities)\n",
    "    prop_df = prop_df.sort_values('potential_improvement_pct', ascending=False)\n",
    "    print(f\"\\nFound {len(prop_df)} N values with propagation potential:\")\n",
    "    print(prop_df.head(20).to_string())\n",
    "else:\n",
    "    print(\"No propagation opportunities found (all N have optimal or near-optimal side lengths)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445827bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze theoretical minimum vs current\n",
    "# Theoretical: trees packed perfectly with no wasted space\n",
    "# Tree area ≈ 0.35 * 0.7 + 0.15 * 0.2 = 0.245 + 0.03 = 0.275 (rough estimate)\n",
    "# Actually tree bounding box is about 0.7 x 1.0 = 0.7\n",
    "\n",
    "print(\"\\n=== EFFICIENCY ANALYSIS ===\")\n",
    "for n in [1, 10, 50, 100, 150, 200]:\n",
    "    row = scores_sorted[scores_sorted['N'] == n].iloc[0]\n",
    "    side = row['side']\n",
    "    area = side * side\n",
    "    tree_area = 0.275 * n  # rough estimate\n",
    "    efficiency = tree_area / area * 100\n",
    "    print(f\"N={n:3d}: side={side:.4f}, area={area:.4f}, efficiency≈{efficiency:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check submission history\n",
    "print(\"\\n=== SUBMISSION HISTORY ===\")\n",
    "print(\"#1: exp_000 | CV: 135.8191 | LB: 135.8191\")\n",
    "print(\"#2: exp_001 | CV: 117.2815 | LB: 117.2815\")\n",
    "print(\"#3: exp_002 | CV: 84.8940 | LB: FAILED (overlap)\")\n",
    "print(\"#4: exp_003 | CV: 84.9010 | LB: 84.9010\")\n",
    "print(\"#5: exp_004 | CV: 84.7124 | LB: 84.7124\")\n",
    "\n",
    "print(\"\\n=== CV-LB RELATIONSHIP ===\")\n",
    "print(\"Perfect alignment (gap = 0) for all valid submissions\")\n",
    "print(\"This is expected for deterministic optimization problem\")\n",
    "print(\"No distribution shift concerns\")\n",
    "\n",
    "print(\"\\n=== PROGRESS TRAJECTORY ===\")\n",
    "print(\"exp_000 → exp_001: 18.5 point improvement (13.6%)\")\n",
    "print(\"exp_001 → exp_002: 32.4 point improvement (27.6%)\")\n",
    "print(\"exp_002 → exp_004: 0.19 point improvement (0.22%)\")\n",
    "print(\"\\nDIMINISHING RETURNS DETECTED - need new approach!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Current Status:\n",
    "- Best score: 84.712432\n",
    "- Target: 68.931058\n",
    "- Gap: 15.78 points (22.9%)\n",
    "- LB #1: 71.19 (crodoc achieved 74.75 with BackPacking)\n",
    "\n",
    "Key Findings:\n",
    "1. Extended optimization (57 min) yielded only 0.19 points\n",
    "2. Diminishing returns from current SA approach\n",
    "3. Top 20 worst N values contribute ~11% of total score\n",
    "4. Perfect CV-LB alignment (no distribution shift)\n",
    "\n",
    "Recommended Next Steps (Priority Order):\n",
    "\n",
    "1. AGGRESSIVE BACKWARD PROPAGATION (crodoc style)\n",
    "   - Current backward prop only found 2 improvements\n",
    "   - crodoc achieved 74.75 with this technique\n",
    "   - Key: When N performs poorly, COPY best config from larger N and drop trees\n",
    "   - This propagates successful patterns across all N values\n",
    "\n",
    "2. GRID-BASED INITIALIZATION (zaburo style)\n",
    "   - For worst-performing N values (N=1, 19, 49, 21, 31...)\n",
    "   - Place trees in alternating rows (0° and 180° rotation)\n",
    "   - Optimize number of trees per row\n",
    "   - Creates well-aligned starting point\n",
    "\n",
    "3. TARGET WORST N VALUES\n",
    "   - Focus optimization budget on top 20 worst N values\n",
    "   - These contribute 11% of score but have most room for improvement\n",
    "   - Run dedicated optimization with 10x iterations\n",
    "\n",
    "4. ENSEMBLE MORE SOURCES\n",
    "   - Look for additional pre-computed solutions\n",
    "   - crodoc/santa2025submission dataset may have better configs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09820fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what datasets we have access to\n",
    "import os\n",
    "\n",
    "print(\"\\n=== AVAILABLE DATA SOURCES ===\")\n",
    "for path in ['/home/code/data', '/home/code/research/snapshots']:\n",
    "    if os.path.exists(path):\n",
    "        files = os.listdir(path)\n",
    "        print(f\"\\n{path}:\")\n",
    "        for f in files[:20]:\n",
    "            print(f\"  {f}\")\n",
    "        if len(files) > 20:\n",
    "            print(f\"  ... and {len(files) - 20} more\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
