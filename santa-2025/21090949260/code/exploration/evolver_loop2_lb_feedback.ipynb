{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12f90c8",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 - LB Feedback Analysis\n",
    "\n",
    "**LB Score: 117.2815** (CV: 117.2815, gap: 0.0000)\n",
    "\n",
    "The CV-LB gap is essentially zero, which is expected for this optimization problem (no train/test split).\n",
    "\n",
    "## Key Evaluator Feedback:\n",
    "1. **ENSEMBLE APPROACH NOT IMPLEMENTED** - This is the #1 technique in top kernels\n",
    "2. **No external solution datasets used** - Pre-computed solutions may already be better\n",
    "3. **bbox3 binary not used** - Primary optimizer in winning solutions\n",
    "4. **Limited optimization time** - Top kernels use 3-hour budgets\n",
    "\n",
    "## Analysis Goals:\n",
    "1. Scan all available snapshot CSVs and score them\n",
    "2. Build an ensemble baseline from best configurations\n",
    "3. Identify the gap between ensemble baseline and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e18\")\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChristmasTree class\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "print(\"ChristmasTree class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9beebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast scoring using numpy (no Shapely for speed)\n",
    "def fast_score_group(xs, ys, degs, n):\n",
    "    \"\"\"Fast scoring using numpy - no polygon construction needed for bounding box.\"\"\"\n",
    "    # Tree template vertices\n",
    "    tx = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "    ty = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    \n",
    "    for i in range(len(xs)):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        # Rotate and translate\n",
    "        rx = c * tx - s * ty + xs[i]\n",
    "        ry = s * tx + c * ty + ys[i]\n",
    "        all_x.extend(rx)\n",
    "        all_y.extend(ry)\n",
    "    \n",
    "    all_x = np.array(all_x)\n",
    "    all_y = np.array(all_y)\n",
    "    \n",
    "    side = max(all_x.max() - all_x.min(), all_y.max() - all_y.min())\n",
    "    return side**2 / n\n",
    "\n",
    "def strip_s(val):\n",
    "    \"\"\"Remove 's' prefix from string values.\"\"\"\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "def score_csv(filepath):\n",
    "    \"\"\"Score a submission CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None, None\n",
    "        \n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        \n",
    "        total_score = 0.0\n",
    "        scores_per_n = {}\n",
    "        \n",
    "        for n, group in df.groupby('N'):\n",
    "            if n < 1 or n > 200:\n",
    "                continue\n",
    "            xs = np.array([strip_s(v) for v in group['x']])\n",
    "            ys = np.array([strip_s(v) for v in group['y']])\n",
    "            degs = np.array([strip_s(v) for v in group['deg']])\n",
    "            \n",
    "            if len(xs) != n:\n",
    "                continue\n",
    "                \n",
    "            score = fast_score_group(xs, ys, degs, n)\n",
    "            scores_per_n[n] = score\n",
    "            total_score += score\n",
    "        \n",
    "        return total_score, scores_per_n\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "print(\"Scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b68a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all available CSV files\n",
    "csv_files = []\n",
    "\n",
    "# Our current candidates\n",
    "csv_files.extend(glob.glob('/home/code/submission_candidates/*.csv'))\n",
    "\n",
    "# Snapshot files\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission_candidates/*.csv'))\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/code/*.csv'))\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/submission/*.csv'))\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/code/experiments/*/*.csv'))\n",
    "\n",
    "# Remove duplicates\n",
    "csv_files = list(set(csv_files))\n",
    "print(f\"Found {len(csv_files)} CSV files to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe37d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all CSV files\n",
    "results = []\n",
    "\n",
    "for filepath in tqdm(csv_files, desc=\"Scoring CSVs\"):\n",
    "    total_score, scores_per_n = score_csv(filepath)\n",
    "    if total_score is not None:\n",
    "        results.append({\n",
    "            'filepath': filepath,\n",
    "            'total_score': total_score,\n",
    "            'scores_per_n': scores_per_n\n",
    "        })\n",
    "\n",
    "# Sort by score\n",
    "results.sort(key=lambda x: x['total_score'])\n",
    "\n",
    "print(f\"\\nSuccessfully scored {len(results)} files\")\n",
    "print(\"\\nTop 10 best scores:\")\n",
    "for i, r in enumerate(results[:10]):\n",
    "    print(f\"{i+1}. {r['total_score']:.6f} - {r['filepath'].split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble: for each N, pick the best configuration across all sources\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BUILDING ENSEMBLE BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_per_n = {n: {'score': float('inf'), 'source': None, 'data': None} for n in range(1, 201)}\n",
    "\n",
    "for r in results:\n",
    "    for n, score in r['scores_per_n'].items():\n",
    "        if score < best_per_n[n]['score']:\n",
    "            best_per_n[n]['score'] = score\n",
    "            best_per_n[n]['source'] = r['filepath']\n",
    "\n",
    "# Calculate ensemble score\n",
    "ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nEnsemble baseline score: {ensemble_score:.6f}\")\n",
    "print(f\"Target score: 68.931058\")\n",
    "print(f\"Gap to target: {ensemble_score - 68.931058:.6f}\")\n",
    "\n",
    "# Show source distribution\n",
    "from collections import Counter\n",
    "sources = Counter([best_per_n[n]['source'].split('/')[-1] for n in range(1, 201)])\n",
    "print(f\"\\nSources used in ensemble:\")\n",
    "for src, count in sources.most_common(10):\n",
    "    print(f\"  {src}: {count} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare our best vs ensemble\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "our_best = 117.281454\n",
    "print(f\"Our best score: {our_best:.6f}\")\n",
    "print(f\"Ensemble score: {ensemble_score:.6f}\")\n",
    "print(f\"Improvement from ensemble: {our_best - ensemble_score:.6f}\")\n",
    "print(f\"\\nTarget: 68.931058\")\n",
    "print(f\"Gap from ensemble to target: {ensemble_score - 68.931058:.6f} ({(ensemble_score - 68.931058)/68.931058*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79066cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values have the most room for improvement\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"N VALUES WITH LARGEST GAPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Theoretical minimum for N=1 is a single tree at 45 degrees\n",
    "# side = sqrt(2) * 0.8 (approximately)\n",
    "theoretical_n1 = (np.sqrt(2) * 0.8)**2 / 1  # ~1.28\n",
    "\n",
    "print(f\"\\nTheoretical minimum for N=1: ~{theoretical_n1:.4f}\")\n",
    "print(f\"Current best for N=1: {best_per_n[1]['score']:.6f}\")\n",
    "\n",
    "# Show worst N values\n",
    "worst_n = sorted([(n, best_per_n[n]['score']) for n in range(1, 201)], key=lambda x: -x[1])[:20]\n",
    "print(f\"\\nTop 20 worst N values (highest score contribution):\")\n",
    "for n, score in worst_n:\n",
    "    print(f\"  N={n}: {score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
