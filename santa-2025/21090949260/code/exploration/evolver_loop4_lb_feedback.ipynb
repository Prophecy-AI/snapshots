{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7457179c",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "**LB Score**: 84.9010 (confirmed)\n",
    "**CV Score**: 84.9010\n",
    "**Gap**: 0.0000 (perfect alignment as expected for deterministic optimization)\n",
    "\n",
    "## Key Observations\n",
    "1. CV-LB alignment is perfect - this is a deterministic optimization problem\n",
    "2. Current best: 84.90, Target: 68.93, Gap: 15.97 points (23.2%)\n",
    "3. Current LB #1: 71.19 (terry_u16) - our target is BETTER than #1!\n",
    "4. The crodoc kernel claims 74.75 but uses external datasets we don't have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1754ed12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T09:30:46.936784Z",
     "iopub.status.busy": "2026-01-17T09:30:46.936369Z",
     "iopub.status.idle": "2026-01-17T09:30:47.274518Z",
     "shell.execute_reply": "2026-01-17T09:30:47.274095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e18\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def load_trees(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_side(trees):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n",
    "    return max(xys.max(axis=0) - xys.min(axis=0))\n",
    "\n",
    "print(\"Functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a630c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T09:30:47.275705Z",
     "iopub.status.busy": "2026-01-17T09:30:47.275543Z",
     "iopub.status.idle": "2026-01-17T09:30:51.255120Z",
     "shell.execute_reply": "2026-01-17T09:30:51.254684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 84.901044\n",
      "\n",
      "Worst 20 N values by score contribution:\n",
      "     n      side     score\n",
      "0    1  0.813173  0.661250\n",
      "18  19  3.057855  0.492130\n",
      "48  49  4.900000  0.490000\n",
      "20  21  3.200000  0.487619\n",
      "30  31  3.869559  0.483016\n",
      "19  20  3.101126  0.480849\n",
      "49  50  4.900000  0.480200\n",
      "36  37  4.200000  0.476757\n",
      "24  25  3.436040  0.472255\n",
      "52  53  5.000000  0.471698\n",
      "25  26  3.500000  0.471154\n",
      "50  51  4.900000  0.470784\n",
      "33  34  4.000000  0.470588\n",
      "31  32  3.878606  0.470112\n",
      "75  76  5.950000  0.465822\n",
      "21  22  3.200000  0.465455\n",
      "37  38  4.200000  0.464211\n",
      "53  54  5.000000  0.462963\n",
      "51  52  4.900000  0.461731\n",
      "27  28  3.590841  0.460505\n"
     ]
    }
   ],
   "source": [
    "# Analyze our current best solution\n",
    "df = pd.read_csv('/home/code/experiments/004_ensemble_fixed/submission.csv')\n",
    "\n",
    "# Calculate score per N\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    if trees:\n",
    "        side = get_side(trees)\n",
    "        score = side**2 / n\n",
    "        scores.append({'n': n, 'side': side, 'score': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(f\"Total score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"\\nWorst 20 N values by score contribution:\")\n",
    "print(scores_df.nlargest(20, 'score')[['n', 'side', 'score']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d79439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T09:30:51.256329Z",
     "iopub.status.busy": "2026-01-17T09:30:51.256209Z",
     "iopub.status.idle": "2026-01-17T09:30:51.260732Z",
     "shell.execute_reply": "2026-01-17T09:30:51.260281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical minimum total score: 70.00\n",
      "\n",
      "Our score: 84.90\n",
      "Efficiency: 82.4%\n"
     ]
    }
   ],
   "source": [
    "# Calculate theoretical minimum (perfect packing)\n",
    "# Tree area is approximately 0.35 * 1.0 = 0.35 (rough estimate)\n",
    "# For N trees, minimum square side would be sqrt(N * tree_area)\n",
    "\n",
    "tree_area = 0.35  # approximate\n",
    "theoretical = []\n",
    "for n in range(1, 201):\n",
    "    min_side = np.sqrt(n * tree_area)\n",
    "    min_score = min_side**2 / n\n",
    "    theoretical.append({'n': n, 'theoretical_score': min_score})\n",
    "\n",
    "theoretical_df = pd.DataFrame(theoretical)\n",
    "print(f\"Theoretical minimum total score: {theoretical_df['theoretical_score'].sum():.2f}\")\n",
    "print(f\"\\nOur score: {scores_df['score'].sum():.2f}\")\n",
    "print(f\"Efficiency: {theoretical_df['theoretical_score'].sum() / scores_df['score'].sum() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46dacbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T09:30:51.262096Z",
     "iopub.status.busy": "2026-01-17T09:30:51.261973Z",
     "iopub.status.idle": "2026-01-17T09:30:51.265358Z",
     "shell.execute_reply": "2026-01-17T09:30:51.264949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard Analysis:\n",
      "==================================================\n",
      "#1 terry_u16: 71.19\n",
      "#2 c-number: 71.19\n",
      "#3 Rafbill: 71.26\n",
      "Our score: 84.90\n",
      "Target: 68.93\n",
      "\n",
      "Gap to #1: 13.71 points (19.3%)\n",
      "Gap to target: 15.97 points (23.2%)\n",
      "\n",
      "CRITICAL: Target 68.93 is BETTER than current #1 (71.19)!\n",
      "This requires techniques beyond what's publicly available.\n"
     ]
    }
   ],
   "source": [
    "# Compare with leaderboard\n",
    "print(\"Leaderboard Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"#1 terry_u16: 71.19\")\n",
    "print(f\"#2 c-number: 71.19\")\n",
    "print(f\"#3 Rafbill: 71.26\")\n",
    "print(f\"Our score: 84.90\")\n",
    "print(f\"Target: 68.93\")\n",
    "print()\n",
    "print(f\"Gap to #1: {84.90 - 71.19:.2f} points ({(84.90 - 71.19)/71.19*100:.1f}%)\")\n",
    "print(f\"Gap to target: {84.90 - 68.93:.2f} points ({(84.90 - 68.93)/68.93*100:.1f}%)\")\n",
    "print()\n",
    "print(\"CRITICAL: Target 68.93 is BETTER than current #1 (71.19)!\")\n",
    "print(\"This requires techniques beyond what's publicly available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2aabd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T09:30:51.266305Z",
     "iopub.status.busy": "2026-01-17T09:30:51.266199Z",
     "iopub.status.idle": "2026-01-17T09:30:51.273041Z",
     "shell.execute_reply": "2026-01-17T09:30:51.272665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to reduce total score by 18.8%\n",
      "\n",
      "If we improve uniformly, each N needs to improve by 18.8%\n",
      "\n",
      "Alternatively, focus on worst performers:\n",
      "\n",
      "Top 20 worst N values contribute:\n",
      "  11.4% of total score\n",
      "  If we halve these, we save 4.83 points\n"
     ]
    }
   ],
   "source": [
    "# Analyze where improvements are needed most\n",
    "# Compare our scores to what would be needed to reach target\n",
    "\n",
    "target = 68.93\n",
    "current = 84.90\n",
    "reduction_needed = (current - target) / current * 100\n",
    "\n",
    "print(f\"Need to reduce total score by {reduction_needed:.1f}%\")\n",
    "print(f\"\\nIf we improve uniformly, each N needs to improve by {reduction_needed:.1f}%\")\n",
    "print(f\"\\nAlternatively, focus on worst performers:\")\n",
    "\n",
    "# Calculate how much each N contributes to total\n",
    "scores_df['pct_of_total'] = scores_df['score'] / scores_df['score'].sum() * 100\n",
    "scores_df['cumulative_pct'] = scores_df.sort_values('score', ascending=False)['pct_of_total'].cumsum()\n",
    "\n",
    "print(\"\\nTop 20 worst N values contribute:\")\n",
    "worst_20 = scores_df.nlargest(20, 'score')\n",
    "print(f\"  {worst_20['pct_of_total'].sum():.1f}% of total score\")\n",
    "print(f\"  If we halve these, we save {worst_20['score'].sum() * 0.5:.2f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339c247",
   "metadata": {},
   "source": [
    "## Strategy Analysis\n",
    "\n",
    "### Key Insights:\n",
    "1. **Target is BETTER than LB #1** - This is extremely ambitious\n",
    "2. **CV-LB alignment is perfect** - No distribution shift issues\n",
    "3. **Gap is 15.97 points (23.2%)** - Need significant improvement\n",
    "\n",
    "### What Top Competitors Likely Have:\n",
    "1. **Better starting solutions** - Access to datasets with pre-computed solutions\n",
    "2. **Longer optimization time** - 3+ hour runs vs our ~10 min\n",
    "3. **bbox3 binary optimizer** - We're using C++ SA which may be less effective\n",
    "4. **More sophisticated techniques** - Not shared publicly\n",
    "\n",
    "### Recommended Strategy:\n",
    "1. **Extended optimization** - Run C++ optimizer for 60+ minutes with higher params\n",
    "2. **Target worst N values** - Focus on N=1, 19, 49, 21, 31 etc.\n",
    "3. **Better backward propagation** - More aggressive tree dropping\n",
    "4. **Fractional translation polish** - Very fine-grained adjustments\n",
    "5. **Multiple optimization passes** - Iterate until no improvement"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
