{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7457179c",
   "metadata": {},
   "source": [
    "# Loop 4 LB Feedback Analysis\n",
    "\n",
    "**LB Score**: 84.9010 (confirmed)\n",
    "**CV Score**: 84.9010\n",
    "**Gap**: 0.0000 (perfect alignment as expected for deterministic optimization)\n",
    "\n",
    "## Key Observations\n",
    "1. CV-LB alignment is perfect - this is a deterministic optimization problem\n",
    "2. Current best: 84.90, Target: 68.93, Gap: 15.97 points (23.2%)\n",
    "3. Current LB #1: 71.19 (terry_u16) - our target is BETTER than #1!\n",
    "4. The crodoc kernel claims 74.75 but uses external datasets we don't have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e18\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def load_trees(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_side(trees):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n",
    "    return max(xys.max(axis=0) - xys.min(axis=0))\n",
    "\n",
    "print(\"Functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze our current best solution\n",
    "df = pd.read_csv('/home/code/experiments/004_ensemble_fixed/submission.csv')\n",
    "\n",
    "# Calculate score per N\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    if trees:\n",
    "        side = get_side(trees)\n",
    "        score = side**2 / n\n",
    "        scores.append({'n': n, 'side': side, 'score': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(f\"Total score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"\\nWorst 20 N values by score contribution:\")\n",
    "print(scores_df.nlargest(20, 'score')[['n', 'side', 'score']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d79439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum (perfect packing)\n",
    "# Tree area is approximately 0.35 * 1.0 = 0.35 (rough estimate)\n",
    "# For N trees, minimum square side would be sqrt(N * tree_area)\n",
    "\n",
    "tree_area = 0.35  # approximate\n",
    "theoretical = []\n",
    "for n in range(1, 201):\n",
    "    min_side = np.sqrt(n * tree_area)\n",
    "    min_score = min_side**2 / n\n",
    "    theoretical.append({'n': n, 'theoretical_score': min_score})\n",
    "\n",
    "theoretical_df = pd.DataFrame(theoretical)\n",
    "print(f\"Theoretical minimum total score: {theoretical_df['theoretical_score'].sum():.2f}\")\n",
    "print(f\"\\nOur score: {scores_df['score'].sum():.2f}\")\n",
    "print(f\"Efficiency: {theoretical_df['theoretical_score'].sum() / scores_df['score'].sum() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with leaderboard\n",
    "print(\"Leaderboard Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"#1 terry_u16: 71.19\")\n",
    "print(f\"#2 c-number: 71.19\")\n",
    "print(f\"#3 Rafbill: 71.26\")\n",
    "print(f\"Our score: 84.90\")\n",
    "print(f\"Target: 68.93\")\n",
    "print()\n",
    "print(f\"Gap to #1: {84.90 - 71.19:.2f} points ({(84.90 - 71.19)/71.19*100:.1f}%)\")\n",
    "print(f\"Gap to target: {84.90 - 68.93:.2f} points ({(84.90 - 68.93)/68.93*100:.1f}%)\")\n",
    "print()\n",
    "print(\"CRITICAL: Target 68.93 is BETTER than current #1 (71.19)!\")\n",
    "print(\"This requires techniques beyond what's publicly available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aabd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze where improvements are needed most\n",
    "# Compare our scores to what would be needed to reach target\n",
    "\n",
    "target = 68.93\n",
    "current = 84.90\n",
    "reduction_needed = (current - target) / current * 100\n",
    "\n",
    "print(f\"Need to reduce total score by {reduction_needed:.1f}%\")\n",
    "print(f\"\\nIf we improve uniformly, each N needs to improve by {reduction_needed:.1f}%\")\n",
    "print(f\"\\nAlternatively, focus on worst performers:\")\n",
    "\n",
    "# Calculate how much each N contributes to total\n",
    "scores_df['pct_of_total'] = scores_df['score'] / scores_df['score'].sum() * 100\n",
    "scores_df['cumulative_pct'] = scores_df.sort_values('score', ascending=False)['pct_of_total'].cumsum()\n",
    "\n",
    "print(\"\\nTop 20 worst N values contribute:\")\n",
    "worst_20 = scores_df.nlargest(20, 'score')\n",
    "print(f\"  {worst_20['pct_of_total'].sum():.1f}% of total score\")\n",
    "print(f\"  If we halve these, we save {worst_20['score'].sum() * 0.5:.2f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339c247",
   "metadata": {},
   "source": [
    "## Strategy Analysis\n",
    "\n",
    "### Key Insights:\n",
    "1. **Target is BETTER than LB #1** - This is extremely ambitious\n",
    "2. **CV-LB alignment is perfect** - No distribution shift issues\n",
    "3. **Gap is 15.97 points (23.2%)** - Need significant improvement\n",
    "\n",
    "### What Top Competitors Likely Have:\n",
    "1. **Better starting solutions** - Access to datasets with pre-computed solutions\n",
    "2. **Longer optimization time** - 3+ hour runs vs our ~10 min\n",
    "3. **bbox3 binary optimizer** - We're using C++ SA which may be less effective\n",
    "4. **More sophisticated techniques** - Not shared publicly\n",
    "\n",
    "### Recommended Strategy:\n",
    "1. **Extended optimization** - Run C++ optimizer for 60+ minutes with higher params\n",
    "2. **Target worst N values** - Focus on N=1, 19, 49, 21, 31 etc.\n",
    "3. **Better backward propagation** - More aggressive tree dropping\n",
    "4. **Fractional translation polish** - Very fine-grained adjustments\n",
    "5. **Multiple optimization passes** - Iterate until no improvement"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
