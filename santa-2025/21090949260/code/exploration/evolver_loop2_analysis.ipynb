{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199ef108",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Objectives:\n",
    "1. Analyze current experiment results (exp_001: 117.28)\n",
    "2. Check available snapshot solutions for ensemble potential\n",
    "3. Understand the gap to target (68.93)\n",
    "4. Identify the best path forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5074b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "import os\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e18\")\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChristmasTree class\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "print(\"ChristmasTree class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functions\n",
    "def load_configuration_from_df(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_side_length(trees):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "def get_score(trees, n):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    side = get_side_length(trees)\n",
    "    return side**2 / n\n",
    "\n",
    "def score_submission(file_path, max_n=200):\n",
    "    df = pd.read_csv(file_path)\n",
    "    total_score = 0.0\n",
    "    scores_by_n = {}\n",
    "    for n in range(1, max_n + 1):\n",
    "        trees = load_configuration_from_df(n, df)\n",
    "        if trees:\n",
    "            score = get_score(trees, n)\n",
    "            total_score += score\n",
    "            scores_by_n[n] = score\n",
    "    return total_score, scores_by_n\n",
    "\n",
    "print(\"Scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15040c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all available CSV files\n",
    "csv_files = []\n",
    "\n",
    "# Current experiment candidates\n",
    "csv_files.extend(glob.glob('/home/code/submission_candidates/*.csv'))\n",
    "csv_files.extend(glob.glob('/home/code/experiments/*/submission*.csv'))\n",
    "csv_files.extend(glob.glob('/home/code/experiments/*/*.csv'))\n",
    "\n",
    "# Snapshot files\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission*.csv'))\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission_candidates/*.csv'))\n",
    "csv_files.extend(glob.glob('/home/nonroot/snapshots/santa-2025/*/submission/*.csv'))\n",
    "\n",
    "# Sample submission\n",
    "csv_files.append('/home/data/sample_submission.csv')\n",
    "\n",
    "# Deduplicate\n",
    "csv_files = list(set(csv_files))\n",
    "print(f\"Found {len(csv_files)} CSV files to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all available submissions\n",
    "results = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        if os.path.exists(csv_file) and os.path.getsize(csv_file) > 10000:  # At least 10KB\n",
    "            score, scores_by_n = score_submission(csv_file)\n",
    "            results.append({\n",
    "                'file': csv_file,\n",
    "                'score': score,\n",
    "                'scores_by_n': scores_by_n\n",
    "            })\n",
    "            print(f\"{score:.4f} - {csv_file.split('/')[-1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {csv_file}: {e}\")\n",
    "\n",
    "results.sort(key=lambda x: x['score'])\n",
    "print(f\"\\nBest score: {results[0]['score']:.6f} from {results[0]['file']}\")\n",
    "print(f\"Worst score: {results[-1]['score']:.6f} from {results[-1]['file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca445f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best submissions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 5 SUBMISSIONS\")\n",
    "print(\"=\"*60)\n",
    "for i, r in enumerate(results[:5]):\n",
    "    print(f\"{i+1}. Score: {r['score']:.6f} - {r['file'].split('/')[-1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCORE BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target: 68.931058\")\n",
    "print(f\"Best available: {results[0]['score']:.6f}\")\n",
    "print(f\"Gap to target: {results[0]['score'] - 68.931058:.6f}\")\n",
    "print(f\"Percentage worse: {(results[0]['score'] - 68.931058) / 68.931058 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an ensemble from all available solutions\n",
    "# For each N, pick the best configuration across all sources\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load all dataframes\n",
    "dfs = {}\n",
    "for r in results:\n",
    "    try:\n",
    "        dfs[r['file']] = pd.read_csv(r['file'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# For each N, find the best source\n",
    "ensemble_scores = {}\n",
    "ensemble_sources = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    \n",
    "    for file_path, df in dfs.items():\n",
    "        trees = load_configuration_from_df(n, df)\n",
    "        if trees and len(trees) == n:\n",
    "            score = get_score(trees, n)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_source = file_path\n",
    "    \n",
    "    if best_source:\n",
    "        ensemble_scores[n] = best_score\n",
    "        ensemble_sources[n] = best_source\n",
    "\n",
    "ensemble_total = sum(ensemble_scores.values())\n",
    "print(f\"Ensemble score (best per N): {ensemble_total:.6f}\")\n",
    "print(f\"Improvement over best single: {results[0]['score'] - ensemble_total:.6f}\")\n",
    "print(f\"Gap to target: {ensemble_total - 68.931058:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3529e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which sources contribute most to the ensemble\n",
    "from collections import Counter\n",
    "\n",
    "source_counts = Counter(ensemble_sources.values())\n",
    "print(\"\\nSource contributions to ensemble:\")\n",
    "for source, count in source_counts.most_common():\n",
    "    print(f\"  {count:3d} configs from {source.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap by N - which N values are hardest?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HARDEST N VALUES (highest score contribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_scores_by_n = results[0]['scores_by_n']\n",
    "sorted_by_score = sorted(best_scores_by_n.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 20 worst N values:\")\n",
    "for n, score in sorted_by_score[:20]:\n",
    "    print(f\"  N={n:3d}: score={score:.6f} (side={np.sqrt(score*n):.4f})\")\n",
    "\n",
    "print(f\"\\nSum of top 20 worst: {sum(s for _, s in sorted_by_score[:20]):.6f}\")\n",
    "print(f\"Percentage of total: {sum(s for _, s in sorted_by_score[:20]) / results[0]['score'] * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ac1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "1. CURRENT STATUS:\n",
    "   - Best experiment score: 117.28 (exp_001)\n",
    "   - Best available score: {results[0]['score']:.4f}\n",
    "   - Ensemble potential: {ensemble_total:.4f}\n",
    "   - Target: 68.93\n",
    "   - Gap: {ensemble_total - 68.931058:.2f} ({(ensemble_total - 68.931058) / 68.931058 * 100:.1f}% worse)\n",
    "\n",
    "2. KEY OBSERVATIONS:\n",
    "   - Ensemble approach shows {results[0]['score'] - ensemble_total:.4f} improvement potential\n",
    "   - Top 20 worst N values contribute {sum(s for _, s in sorted_by_score[:20]) / results[0]['score'] * 100:.1f}% of score\n",
    "   - Need to reduce score by ~{results[0]['score'] - 68.931058:.1f} points to reach target\n",
    "\n",
    "3. CRITICAL GAPS:\n",
    "   - No bbox3 binary available (top kernels use this)\n",
    "   - No external solution datasets (bucket-of-chump, etc.)\n",
    "   - Limited optimization time compared to top kernels (3+ hours)\n",
    "\n",
    "4. RECOMMENDED NEXT STEPS:\n",
    "   a) Implement ensemble approach - combine best configs per N\n",
    "   b) Run longer optimization (more iterations, more seeds)\n",
    "   c) Focus on worst N values (high-impact optimization)\n",
    "   d) Try to obtain/compile bbox3 or equivalent optimizer\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
