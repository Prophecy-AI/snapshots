{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f84b373",
   "metadata": {},
   "source": [
    "# Loop 17 LB Feedback Analysis\n",
    "\n",
    "**exp_016 submitted: CV=70.3535, LB=70.3535 (perfect match)**\n",
    "\n",
    "This confirms:\n",
    "1. Our validation is working correctly\n",
    "2. The MIN_IMPROVEMENT=0.001 threshold is safe\n",
    "3. We have 1.48 points gap to target (68.878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b60dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze submission history\n",
    "print(\"=\" * 70)\n",
    "print(\"SUBMISSION HISTORY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "submissions = state.get('submissions', [])\n",
    "for sub in submissions:\n",
    "    exp_id = sub.get('experiment_id', 'unknown')\n",
    "    cv = sub.get('cv_score', 0)\n",
    "    lb = sub.get('lb_score', 'pending')\n",
    "    print(f\"{exp_id}: CV={cv:.4f}, LB={lb}\")\n",
    "\n",
    "print(f\"\\nTotal submissions: {len(submissions)}/100\")\n",
    "print(f\"Remaining: {state.get('remaining_submissions', 100)}\")\n",
    "\n",
    "# Calculate CV-LB relationship\n",
    "valid_subs = [(s['cv_score'], s['lb_score']) for s in submissions \n",
    "              if s.get('lb_score') and s['lb_score'] != 'pending']\n",
    "if valid_subs:\n",
    "    print(f\"\\nValid submissions with LB scores: {len(valid_subs)}\")\n",
    "    for cv, lb in valid_subs:\n",
    "        gap = lb - cv\n",
    "        print(f\"  CV={cv:.4f}, LB={lb:.4f}, gap={gap:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiments\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "experiments = state.get('experiments', [])\n",
    "scores = []\n",
    "for exp in experiments:\n",
    "    name = exp.get('name', 'unknown')\n",
    "    cv = exp.get('cv_score', exp.get('score', 0))\n",
    "    lb = exp.get('lb_score')\n",
    "    scores.append({'name': name, 'cv': cv, 'lb': lb})\n",
    "    print(f\"{name}: CV={cv:.4f}, LB={lb if lb else 'N/A'}\")\n",
    "\n",
    "# Find best scores\n",
    "best_cv = min(scores, key=lambda x: x['cv'])\n",
    "print(f\"\\nBest CV: {best_cv['name']} with {best_cv['cv']:.4f}\")\n",
    "\n",
    "# Target analysis\n",
    "target = 68.877877\n",
    "best_score = best_cv['cv']\n",
    "gap = best_score - target\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Best score: {best_score:.4f}\")\n",
    "print(f\"Gap: {gap:.4f} ({100*gap/target:.2f}%)\")\n",
    "print(f\"\\nAt current improvement rate (0.01/exp), need {gap/0.01:.0f} more experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what's working vs not working\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APPROACH ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Group experiments by type\n",
    "optimization_exps = [e for e in experiments if 'optimization' in e.get('model_type', '') or 'sa' in e.get('name', '').lower()]\n",
    "ensemble_exps = [e for e in experiments if 'ensemble' in e.get('model_type', '')]\n",
    "baseline_exps = [e for e in experiments if 'baseline' in e.get('name', '').lower()]\n",
    "\n",
    "print(f\"\\nOptimization experiments: {len(optimization_exps)}\")\n",
    "for e in optimization_exps:\n",
    "    print(f\"  {e['name']}: {e.get('cv_score', e.get('score', 0)):.4f}\")\n",
    "\n",
    "print(f\"\\nEnsemble experiments: {len(ensemble_exps)}\")\n",
    "for e in ensemble_exps:\n",
    "    print(f\"  {e['name']}: {e.get('cv_score', e.get('score', 0)):.4f}\")\n",
    "\n",
    "print(f\"\\nBaseline experiments: {len(baseline_exps)}\")\n",
    "for e in baseline_exps:\n",
    "    print(f\"  {e['name']}: {e.get('cv_score', e.get('score', 0)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761073d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What's the theoretical minimum?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"THEORETICAL ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Tree area calculation\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "tree_poly = Polygon(zip(TX, TY))\n",
    "tree_area = tree_poly.area\n",
    "print(f\"Single tree area: {tree_area:.6f}\")\n",
    "\n",
    "# For N trees, minimum bounding box area >= N * tree_area\n",
    "# Score = S^2/N where S is side length\n",
    "# If perfect packing: S^2 = N * tree_area, so Score = tree_area\n",
    "print(f\"\\nTheoretical minimum score (perfect packing): {tree_area:.6f}\")\n",
    "print(f\"Our best score: {best_score:.4f}\")\n",
    "print(f\"Packing efficiency: {100*tree_area/best_score:.1f}%\")\n",
    "\n",
    "# Per-N analysis\n",
    "print(f\"\\nPer-N theoretical minimum:\")\n",
    "for n in [1, 10, 50, 100, 200]:\n",
    "    min_side = np.sqrt(n * tree_area)\n",
    "    min_score = min_side**2 / n\n",
    "    print(f\"  N={n}: min_side={min_side:.4f}, min_score={min_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches haven't been tried?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"UNTRIED APPROACHES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. LATTICE-BASED CONSTRUCTION (from why-not kernel analysis):\n",
    "   - Trees have 'blue' (upward) and 'pink' (downward) orientations\n",
    "   - They form crystallization patterns with specific offsets\n",
    "   - Could construct solutions from scratch using lattice patterns\n",
    "\n",
    "2. ASYMMETRIC SOLUTIONS (from discussion 666880):\n",
    "   - Top discussion says winning solutions will be asymmetric\n",
    "   - Our current solutions may be too symmetric\n",
    "   - Need to explore asymmetric configurations\n",
    "\n",
    "3. AGGRESSIVE BBOX3 PARAMETERS:\n",
    "   - Top kernels use -n 1000-2000 -r 96 (we may be using less)\n",
    "   - Run for hours, not minutes\n",
    "   - Need to verify our bbox3 parameters\n",
    "\n",
    "4. MORE EXTERNAL DATA SOURCES:\n",
    "   - Top kernels use 15-20 sources\n",
    "   - We only have ~10 sources\n",
    "   - Download more from Kaggle datasets\n",
    "\n",
    "5. SMART THRESHOLD BY N:\n",
    "   - 16,780 improvements rejected as too small (<0.001)\n",
    "   - Some N values are 'safe' (never failed Kaggle)\n",
    "   - Could use lower threshold for safe N values\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nKEY INSIGHT: The gap is 1.48 points (2.1%)\")\n",
    "print(\"At 0.01 improvement per experiment, need 148 more experiments\")\n",
    "print(\"MUST find approaches that give 0.1+ improvement per experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what external data sources we have vs what top kernels use\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXTERNAL DATA SOURCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import glob\n",
    "\n",
    "external_files = glob.glob('/home/code/external_data/**/*.csv', recursive=True)\n",
    "print(f\"External CSV files: {len(external_files)}\")\n",
    "for f in external_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "print(\"\\nTop kernels use these sources (from jonathanchan analysis):\")\n",
    "top_sources = [\n",
    "    'bucket-of-chump',\n",
    "    'why-not', \n",
    "    'santa25-improved-sa-with-translations',\n",
    "    'santa-2025-try3',\n",
    "    'santa25-public',\n",
    "    'santa2025-ver2',\n",
    "    'santa-submission (saspav)',\n",
    "    'santa25-simulated-annealing-with-translations',\n",
    "    'santa-2025-simple-optimization-new-slow-version',\n",
    "    'santa-2025-fix-direction',\n",
    "    '72-71-santa-2025-jit-parallel-sa-c',\n",
    "    'santa-claude',\n",
    "    'blending-multiple-oplimisation',\n",
    "    'telegram-public-shared-solution-for-santa-2025',\n",
    "    'santa2025-just-keep-on-trying',\n",
    "    'decent-starting-solution'\n",
    "]\n",
    "for src in top_sources:\n",
    "    print(f\"  - {src}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a95fe0",
   "metadata": {},
   "source": [
    "## STRATEGIC CONCLUSIONS\n",
    "\n",
    "### Current Status:\n",
    "- Best LB: 70.3535 (exp_016)\n",
    "- Target: 68.878\n",
    "- Gap: 1.48 points (2.1%)\n",
    "\n",
    "### What's Working:\n",
    "1. Ensemble approach with MIN_IMPROVEMENT=0.001 threshold\n",
    "2. External data sources (saspav santa-2025.csv is best)\n",
    "3. Strict overlap validation with integer arithmetic\n",
    "\n",
    "### What's NOT Working:\n",
    "1. Local optimization (SA, exhaustive search) - baseline is at strong local optimum\n",
    "2. Small improvements (<0.001) - fail Kaggle validation\n",
    "3. Running same optimizer repeatedly - no improvement\n",
    "\n",
    "### Path Forward:\n",
    "1. **Download more external data sources** - top kernels use 15-20, we have ~10\n",
    "2. **Run bbox3 with aggressive parameters** - -n 2000 -r 96 for hours\n",
    "3. **Explore lattice-based construction** - build solutions from scratch using crystallization patterns\n",
    "4. **Try asymmetric configurations** - per discussion, winning solutions are asymmetric\n",
    "5. **Smart threshold by N** - use lower threshold for 'safe' N values"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
