{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152cdad5",
   "metadata": {},
   "source": [
    "# Ensemble + Fractional Translation (v2)\n",
    "\n",
    "Key fix: Validate that solutions don't have overlaps before accepting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c94e391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:37:39.043548Z",
     "iopub.status.busy": "2026-01-26T05:37:39.043065Z",
     "iopub.status.idle": "2026-01-26T05:37:39.218177Z",
     "shell.execute_reply": "2026-01-26T05:37:39.217776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('/home/code/experiments/007_ensemble_fractional')\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "from numba import njit\n",
    "\n",
    "from code.tree_geometry import TX, TY, calculate_score, calculate_bbox\n",
    "from code.overlap_check import has_overlap\n",
    "from code.utils import parse_submission, save_submission\n",
    "\n",
    "print(\"Imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020af9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:37:39.219388Z",
     "iopub.status.busy": "2026-01-26T05:37:39.219185Z",
     "iopub.status.idle": "2026-01-26T05:37:39.222965Z",
     "shell.execute_reply": "2026-01-26T05:37:39.222616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def strip(a):\n",
    "    \"\"\"Remove 's' prefix from values.\"\"\"\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "def load_and_validate_csv(fp):\n",
    "    \"\"\"Load a submission CSV and validate each N group.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        return df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f324223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:37:39.223845Z",
     "iopub.status.busy": "2026-01-26T05:37:39.223744Z",
     "iopub.status.idle": "2026-01-26T05:37:39.283176Z",
     "shell.execute_reply": "2026-01-26T05:37:39.282742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3530 CSV files to ensemble\n"
     ]
    }
   ],
   "source": [
    "# Collect all CSV files from snapshots\n",
    "snapshot_dir = '/home/nonroot/snapshots/santa-2025'\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk(snapshot_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            csv_files.append(os.path.join(root, f))\n",
    "\n",
    "# Also add our baseline (which we know is valid)\n",
    "csv_files.append('/home/code/experiments/001_valid_baseline/submission.csv')\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files to ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b43963e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:37:39.284405Z",
     "iopub.status.busy": "2026-01-26T05:37:39.284274Z",
     "iopub.status.idle": "2026-01-26T05:49:52.466578Z",
     "shell.execute_reply": "2026-01-26T05:49:52.466134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CSV files with overlap validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500 files, found 83999 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1000 files, found 170171 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1500 files, found 255997 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2000 files, found 340166 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2500 files, found 428669 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3000 files, found 513842 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3500 files, found 592189 valid configs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3519 files total\n",
      "Found 595791 valid configurations\n",
      "\n",
      "Ensemble score: 70.265730\n"
     ]
    }
   ],
   "source": [
    "# Build ensemble - best per-N from all sources WITH VALIDATION\n",
    "best_per_n = {n: {'score': 1e300, 'config': None, 'src': None} for n in range(1, 201)}\n",
    "\n",
    "print(\"Processing CSV files with overlap validation...\")\n",
    "processed = 0\n",
    "valid_found = 0\n",
    "\n",
    "for fp in csv_files:\n",
    "    df = load_and_validate_csv(fp)\n",
    "    if df is None:\n",
    "        continue\n",
    "    \n",
    "    for n, g in df.groupby('N'):\n",
    "        if n < 1 or n > 200:\n",
    "            continue\n",
    "        \n",
    "        xs = strip(g['x'].to_numpy())\n",
    "        ys = strip(g['y'].to_numpy())\n",
    "        ds = strip(g['deg'].to_numpy())\n",
    "        \n",
    "        # Create config as list of tuples\n",
    "        config = [(xs[i], ys[i], ds[i]) for i in range(len(xs))]\n",
    "        \n",
    "        # Validate - no overlaps\n",
    "        if has_overlap(config):\n",
    "            continue\n",
    "        \n",
    "        # Calculate score\n",
    "        sc = calculate_score(config)\n",
    "        valid_found += 1\n",
    "        \n",
    "        if sc < best_per_n[n]['score']:\n",
    "            best_per_n[n]['score'] = sc\n",
    "            best_per_n[n]['config'] = config\n",
    "            best_per_n[n]['src'] = fp.split('/')[-2]\n",
    "    \n",
    "    processed += 1\n",
    "    if processed % 500 == 0:\n",
    "        print(f\"  Processed {processed} files, found {valid_found} valid configs...\")\n",
    "\n",
    "print(f\"\\nProcessed {processed} files total\")\n",
    "print(f\"Found {valid_found} valid configurations\")\n",
    "\n",
    "# Calculate ensemble score\n",
    "ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nEnsemble score: {ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc449ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:49:52.467989Z",
     "iopub.status.busy": "2026-01-26T05:49:52.467882Z",
     "iopub.status.idle": "2026-01-26T05:49:52.470757Z",
     "shell.execute_reply": "2026-01-26T05:49:52.470436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample per-N scores:\n",
      "  N=1: 0.661250 (from code)\n",
      "  N=2: 0.450779 (from preoptimized)\n",
      "  N=5: 0.416850 (from code)\n",
      "  N=10: 0.376630 (from 013_long_sa)\n",
      "  N=20: 0.376057 (from 013_long_sa)\n",
      "  N=50: 0.360753 (from code)\n",
      "  N=100: 0.343394 (from code)\n",
      "  N=150: 0.337064 (from code)\n",
      "  N=200: 0.337549 (from code)\n"
     ]
    }
   ],
   "source": [
    "# Check sample scores\n",
    "print(\"\\nSample per-N scores:\")\n",
    "for n in [1, 2, 5, 10, 20, 50, 100, 150, 200]:\n",
    "    entry = best_per_n[n]\n",
    "    print(f\"  N={n}: {entry['score']:.6f} (from {entry['src']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48eac4bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:49:52.471759Z",
     "iopub.status.busy": "2026-01-26T05:49:52.471667Z",
     "iopub.status.idle": "2026-01-26T05:49:52.956179Z",
     "shell.execute_reply": "2026-01-26T05:49:52.955747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline total: 70.615102\n",
      "Ensemble total: 70.265730\n",
      "Improvement: 0.349372300\n"
     ]
    }
   ],
   "source": [
    "# Load baseline for comparison\n",
    "baseline_df = pd.read_csv('/home/code/experiments/001_valid_baseline/submission.csv')\n",
    "baseline_configs = parse_submission(baseline_df)\n",
    "\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    baseline_scores[n] = calculate_score(baseline_configs[n])\n",
    "\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "print(f\"Baseline total: {baseline_total:.6f}\")\n",
    "print(f\"Ensemble total: {ensemble_score:.6f}\")\n",
    "print(f\"Improvement: {baseline_total - ensemble_score:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e977db2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:49:52.957445Z",
     "iopub.status.busy": "2026-01-26T05:49:52.957329Z",
     "iopub.status.idle": "2026-01-26T05:49:52.960924Z",
     "shell.execute_reply": "2026-01-26T05:49:52.960577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 43 improvements over baseline:\n",
      "  N=15: improved by 0.000007550 (from 016_multi_seed_sa)\n",
      "  N=24: improved by 0.348368973 (from experiments)\n",
      "  N=35: improved by 0.000015456 (from 016_multi_seed_sa)\n",
      "  N=36: improved by 0.000333559 (from 016_multi_seed_sa)\n",
      "  N=57: improved by 0.000027633 (from 016_multi_seed_sa)\n",
      "  N=58: improved by 0.000001355 (from code)\n",
      "  N=59: improved by 0.000000974 (from 016_multi_seed_sa)\n",
      "  N=61: improved by 0.000000330 (from code)\n",
      "  N=63: improved by 0.000000942 (from code)\n",
      "  N=64: improved by 0.000001317 (from code)\n",
      "  N=65: improved by 0.000326870 (from 016_multi_seed_sa)\n",
      "  N=66: improved by 0.000002632 (from 016_multi_seed_sa)\n",
      "  N=73: improved by 0.000000750 (from solutions)\n",
      "  N=76: improved by 0.000000313 (from 016_multi_seed_sa)\n",
      "  N=78: improved by 0.000002320 (from code)\n",
      "  N=81: improved by 0.000001643 (from code)\n",
      "  N=87: improved by 0.000002791 (from code)\n",
      "  N=88: improved by 0.000007482 (from code)\n",
      "  N=91: improved by 0.000000705 (from solutions)\n",
      "  N=92: improved by 0.000000187 (from code)\n"
     ]
    }
   ],
   "source": [
    "# Find improvements over baseline\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    ens_score = best_per_n[n]['score']\n",
    "    base_score = baseline_scores[n]\n",
    "    if ens_score < base_score - 1e-9:\n",
    "        diff = base_score - ens_score\n",
    "        improvements.append((n, diff, best_per_n[n]['src']))\n",
    "\n",
    "print(f\"\\nFound {len(improvements)} improvements over baseline:\")\n",
    "for n, diff, src in improvements[:20]:\n",
    "    print(f\"  N={n}: improved by {diff:.9f} (from {src})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629112e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:49:52.961796Z",
     "iopub.status.busy": "2026-01-26T05:49:52.961694Z",
     "iopub.status.idle": "2026-01-26T05:49:52.971953Z",
     "shell.execute_reply": "2026-01-26T05:49:52.971565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final score: 70.265730\n",
      "Baseline: 70.615102\n",
      "Improvement: 0.349372288\n"
     ]
    }
   ],
   "source": [
    "# Create final configs - use ensemble where better, baseline otherwise\n",
    "final_configs = {}\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n]['score'] < baseline_scores[n] - 1e-9:\n",
    "        final_configs[n] = best_per_n[n]['config']\n",
    "    else:\n",
    "        final_configs[n] = list(baseline_configs[n])\n",
    "\n",
    "# Calculate final score\n",
    "final_score = sum(calculate_score(final_configs[n]) for n in range(1, 201))\n",
    "print(f\"\\nFinal score: {final_score:.6f}\")\n",
    "print(f\"Baseline: {baseline_total:.6f}\")\n",
    "print(f\"Improvement: {baseline_total - final_score:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f12746a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:49:52.972818Z",
     "iopub.status.busy": "2026-01-26T05:49:52.972723Z",
     "iopub.status.idle": "2026-01-26T05:49:53.047577Z",
     "shell.execute_reply": "2026-01-26T05:49:53.047151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n",
      "Copied to /home/submission/\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "save_submission(final_configs, 'submission.csv')\n",
    "print(\"Saved submission.csv\")\n",
    "\n",
    "# Copy to submission folder\n",
    "import shutil\n",
    "shutil.copy('submission.csv', '/home/submission/submission.csv')\n",
    "print(\"Copied to /home/submission/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb16c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:50:05.200889Z",
     "iopub.status.busy": "2026-01-26T05:50:05.200348Z",
     "iopub.status.idle": "2026-01-26T05:50:05.204522Z",
     "shell.execute_reply": "2026-01-26T05:50:05.204079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final CV Score: 70.265730\n"
     ]
    }
   ],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': final_score,\n",
    "    'baseline_score': baseline_total,\n",
    "    'ensemble_score': ensemble_score,\n",
    "    'improvement': baseline_total - final_score,\n",
    "    'n_improvements': len(improvements),\n",
    "    'improvements': [(n, float(d), src) for n, d, src in improvements[:20]],\n",
    "    'notes': 'Ensemble from all snapshots with overlap validation'\n",
    "}\n",
    "\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nFinal CV Score: {final_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
