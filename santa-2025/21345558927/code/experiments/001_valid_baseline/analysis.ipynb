{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7cd197",
   "metadata": {},
   "source": [
    "# Valid Baseline Analysis\n",
    "\n",
    "Load and verify the submission that passed Kaggle validation with LB score 70.615106516706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdf3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.chdir('/home/code/experiments/001_valid_baseline')\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def get_tree_vertices(x, y, angle_deg):\n",
    "    \"\"\"Get tree polygon vertices at position (x,y) with rotation angle_deg.\"\"\"\n",
    "    rad = np.radians(angle_deg)\n",
    "    cos_a, sin_a = np.cos(rad), np.sin(rad)\n",
    "    rx = TX * cos_a - TY * sin_a + x\n",
    "    ry = TX * sin_a + TY * cos_a + y\n",
    "    return rx, ry\n",
    "\n",
    "def calculate_score_for_n(trees):\n",
    "    \"\"\"Calculate score for a single N value.\"\"\"\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    for x, y, angle in trees:\n",
    "        rx, ry = get_tree_vertices(x, y, angle)\n",
    "        all_xs.extend(rx)\n",
    "        all_ys.extend(ry)\n",
    "    width = max(all_xs) - min(all_xs)\n",
    "    height = max(all_ys) - min(all_ys)\n",
    "    side = max(width, height)\n",
    "    n = len(trees)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the submission\n",
    "df = pd.read_csv('submission.csv')\n",
    "print(f\"Submission shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f07eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the submission\n",
    "def parse_submission(df):\n",
    "    \"\"\"Parse submission CSV into dict of n -> list of (x, y, angle) tuples.\"\"\"\n",
    "    configs = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        parts = row['id'].split('_')\n",
    "        n = int(parts[0])\n",
    "        x = float(str(row['x']).replace('s', ''))\n",
    "        y = float(str(row['y']).replace('s', ''))\n",
    "        deg = float(str(row['deg']).replace('s', ''))\n",
    "        configs[n].append((x, y, deg))\n",
    "    return dict(configs)\n",
    "\n",
    "configs = parse_submission(df)\n",
    "print(f\"Parsed {len(configs)} N values\")\n",
    "print(f\"N=1 has {len(configs[1])} trees\")\n",
    "print(f\"N=200 has {len(configs[200])} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ecf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score\n",
    "def calculate_total_score(configs):\n",
    "    total = 0\n",
    "    scores_by_n = {}\n",
    "    for n in range(1, 201):\n",
    "        if n not in configs:\n",
    "            print(f\"WARNING: Missing N={n}\")\n",
    "            continue\n",
    "        trees = configs[n]\n",
    "        if len(trees) != n:\n",
    "            print(f\"WARNING: N={n} has {len(trees)} trees instead of {n}\")\n",
    "        score_n = calculate_score_for_n(trees)\n",
    "        scores_by_n[n] = score_n\n",
    "        total += score_n\n",
    "    return total, scores_by_n\n",
    "\n",
    "total_score, scores_by_n = calculate_total_score(configs)\n",
    "print(f\"\\nTotal CV Score: {total_score:.6f}\")\n",
    "print(f\"Expected LB Score: 70.615106516706\")\n",
    "print(f\"Target: 68.882921\")\n",
    "print(f\"Gap: {total_score - 68.882921:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score contributions\n",
    "print(\"\\nTop 10 highest score contributions (worst N values):\")\n",
    "sorted_scores = sorted(scores_by_n.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_scores[:10]:\n",
    "    print(f\"  N={n}: {score:.6f}\")\n",
    "\n",
    "print(f\"\\nN=1 score: {scores_by_n[1]:.6f} (theoretical optimal: 0.6612)\")\n",
    "print(f\"N=2 score: {scores_by_n[2]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252114e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': total_score,\n",
    "    'expected_lb_score': 70.615106516706,\n",
    "    'target': 68.882921,\n",
    "    'gap': total_score - 68.882921,\n",
    "    'notes': 'Valid baseline from snapshot 21337107511 that passed Kaggle validation'\n",
    "}\n",
    "\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics saved\")\n",
    "print(f\"\\nCV Score: {total_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to submission folder\n",
    "import shutil\n",
    "shutil.copy('submission.csv', '/home/submission/submission.csv')\n",
    "print(\"Copied to /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
