# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- **Best Valid LB Score: 70.365091** (exp_010 - PASSED Kaggle validation)
- **Target: 68.879467** (lower is better)
- **Gap to target: 1.49 points (2.1% improvement needed)**
- **Submissions: 7/100 used, 93 remaining**

## üö® CRITICAL DISCOVERY: EXTERNAL DATA IS BETTER!

**External santa-2025.csv scores 70.348933 - BETTER than our exp_010 (70.365091)!**

Analysis shows:
- External is better for **52 N values**
- exp_010 is better for only **6 N values**
- **Potential combined score: 70.341433** (improvement of 0.024 over exp_010)

## Submission Log
| Exp | Approach | CV | LB | Status |
|-----|----------|----|----|--------|
| 000 | baseline ensemble | 70.523 | - | ‚ùå FAILED |
| 001 | valid baseline | 70.615 | 70.615 | ‚úÖ PASSED |
| 002 | backward propagation | 70.615 | 70.615 | ‚úÖ PASSED |
| 007 | ensemble fractional | 70.266 | - | ‚ùå FAILED |
| 008 | snapshot ensemble | 70.373 | - | ‚ùå FAILED |
| 009 | highprec ensemble | 70.341 | - | ‚ùå FAILED |
| 010 | safe ensemble | 70.365 | 70.365 | ‚úÖ PASSED |

## Response to Evaluator

**AGREE with all evaluator concerns:**
1. ‚úÖ External data sources not fully leveraged - NOW DOWNLOADED AND ANALYZED
2. ‚úÖ Diminishing returns on current approach - External data provides new solutions
3. ‚úÖ Need step change, not incremental improvements - External data is the step change

## ‚õî FORBIDDEN
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() with binaries - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN

## ‚úÖ MANDATORY NEXT EXPERIMENT: MEGA-ENSEMBLE WITH EXTERNAL DATA

### STEP 1: Create Mega-Ensemble
Combine ALL sources with strict validation:

```python
import pandas as pd
import sys
sys.path.insert(0, '/home/code')
from code.tree_geometry import calculate_score
from code.utils import parse_submission, save_submission
from decimal import Decimal, getcontext
from shapely.geometry import Polygon

getcontext().prec = 30
SCALE = 10**18
MIN_IMPROVEMENT = 0.001  # Safe threshold

# Load all sources
sources = {
    'exp_010': '/home/code/experiments/010_safe_ensemble/submission.csv',
    'external_santa2025': '/home/code/external_data/santa-2025.csv',
    'external_70.378': '/home/code/external_data/70.378875862989_20260126_045659.csv',
    'external_submission': '/home/code/external_data/submission.csv',
}

# Also load all internal snapshots
import glob
snapshot_files = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)

# Load baseline for fallback
baseline_df = pd.read_csv('/home/code/experiments/001_valid_baseline/submission.csv')
baseline_configs = parse_submission(baseline_df)
baseline_scores = {n: calculate_score(baseline_configs[n]) for n in range(1, 201)}

# High-precision overlap validation
def validate_no_overlap_strict(trees):
    # ... (use SCALE=10^18 integer arithmetic)
    pass

# Build mega-ensemble
best_per_n = {}
for n in range(1, 201):
    best_score = baseline_scores[n]
    best_config = baseline_configs[n]
    
    for source_name, source_path in sources.items():
        df = pd.read_csv(source_path)
        configs = parse_submission(df)
        
        if n in configs:
            config = configs[n]
            score = calculate_score(config)
            improvement = best_score - score
            
            # Only accept if significant improvement AND valid
            if improvement > MIN_IMPROVEMENT:
                if validate_no_overlap_strict(config):
                    best_score = score
                    best_config = config
    
    best_per_n[n] = best_config

# Save and validate
save_submission(best_per_n, 'submission.csv')
```

### STEP 2: Validate Before Submission
```python
# Final validation with strict overlap checking
for n in range(1, 201):
    if not validate_no_overlap_strict(best_per_n[n]):
        print(f"N={n}: OVERLAP - falling back to baseline")
        best_per_n[n] = baseline_configs[n]
```

### STEP 3: Submit and Get LB Feedback
With 93 submissions remaining, submit the mega-ensemble to validate.

## Expected Outcome
- Mega-ensemble should score around **70.34** (improvement of ~0.025 over exp_010)
- If it passes validation, this is our new best
- Still need ~1.46 points more to reach target

## External Data Sources Downloaded
1. `/home/code/external_data/santa-2025.csv` - Score: 70.348933 ‚úÖ BETTER
2. `/home/code/external_data/70.378875862989_20260126_045659.csv` - Score: 70.378876
3. `/home/code/external_data/submission.csv` - Score: 70.647327
4. `/home/code/external_data/submission_best.csv` - Score: 70.926150

## Per-N Analysis (External vs exp_010)
Top N values where external is better:
- N=87: +0.000969
- N=69: +0.000946
- N=47: +0.000877
- N=116: +0.000875
- N=139: +0.000829

Top N values where exp_010 is better:
- N=21: +0.002616
- N=88: +0.002445
- N=41: +0.001517

## What NOT to Try
- ‚ùå Fractional translation (found NO improvements)
- ‚ùå Rotation optimization (found NO improvements)
- ‚ùå Running C++ binaries (FORBIDDEN)
- ‚ùå Small improvements below MIN_IMPROVEMENT=0.001 (causes overlap failures)

## Gap Analysis
| Score | Status | Gap to Target |
|-------|--------|---------------|
| 70.615 | Valid baseline | 1.74 points |
| 70.365 | exp_010 (current best) | 1.49 points |
| 70.341 | Potential mega-ensemble | 1.46 points |
| 68.879 | TARGET | 0 points |

The remaining gap is still significant (1.46 points). After mega-ensemble, need to explore:
1. More external data sources (Kaggle datasets)
2. Different optimization strategies from top kernels
3. Lattice/tessellation patterns for large N
