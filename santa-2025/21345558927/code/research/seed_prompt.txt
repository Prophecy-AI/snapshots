## Current Status
- Best CV score: 70.316648 from exp_020 (comprehensive ensemble)
- Best LB score: 70.3535 from exp_016
- Target: 68.877877 | Gap to target: 1.44 points (2.09%)

## Submission Log
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 001 | valid_baseline | 70.6151 | 70.6151 | First valid submission |
| 002 | backward_propagation | 70.6151 | 70.6151 | No improvement |
| 010 | safe_ensemble | 70.3651 | 70.3651 | MIN_IMPROVEMENT=0.001 |
| 016 | mega_ensemble | 70.3535 | 70.3535 | Best LB so far |
| 019 | comprehensive_external | 70.3434 | pending | 2 improvements |
| 020 | whynot_ensemble | 70.3166 | pending | Best CV so far |

## What We've Learned
1. **External data is the key lever**: Best sources are bbox3-ensemble-update (70.3197), fork-of-the-fork (70.3312), team-blend (70.3316), why-not (70.3322)
2. **Ensemble works**: Combining best per-N from multiple sources improves score
3. **Overlap validation is critical**: 2517 potential improvements rejected due to overlaps
4. **Local optimization fails**: SA, GA, exhaustive search, NFP, backward propagation all failed to improve the baseline
5. **The baseline is at a strong local optimum**: Any perturbation creates overlaps or worse scores

## Response to Evaluator
The evaluator correctly identified that:
1. The MIN_IMPROVEMENT=0.001 threshold was too conservative - we lowered it to 1e-8
2. The why-not submission (70.332) is better than our previous baseline
3. Building a proper ensemble with NO threshold captures more improvements

We implemented their recommendations and achieved 70.316648, an improvement of 0.037 over the best submitted LB (70.3535).

## Critical Gap Analysis
- **Current CV**: 70.316648
- **Target**: 68.877877
- **Gap**: 1.44 points (2.09%)

This gap is STILL TOO LARGE for ensemble optimization alone. The best external sources score around 70.32, and our ensemble achieves 70.3166. Even if we found perfect per-N solutions from external sources, we'd still be ~1.4 points away from target.

## What's NOT Working
1. ❌ Local optimization (SA, GA, gradient descent) - baseline is at strong local optimum
2. ❌ Exhaustive search for small N - baseline is already optimal
3. ❌ Ensemble of existing sources - ceiling around 70.31-70.32
4. ❌ Running bbox3 with different parameters - same results

## What MIGHT Work (Unexplored)
1. **Asymmetric solutions**: Discussion "Why the winning solutions will be Asymmetric" (40 votes) suggests asymmetric layouts beat symmetric ones
2. **Per-N specialization**: Different algorithms for different N ranges
3. **Novel placement algorithms**: NFP-based constructive heuristics
4. **More external data**: Top teams have 17+ sources vs our 4-5

## Next Experiment: SUBMIT exp_020 for LB Feedback

**CRITICAL**: We have 91 submissions remaining. Submit exp_020 NOW to get LB feedback!

The current CV of 70.316648 is 0.037 better than our best LB (70.3535). We need to verify this improvement on the leaderboard.

After submission, continue with:

### Option A: Download More External Data
```python
# Search for more datasets
kaggle datasets list -s "santa 2025" --sort-by votes
# Download any we haven't tried yet
```

### Option B: Implement Asymmetric Optimization
Based on the discussion "Why the winning solutions will be Asymmetric":
- Current solutions may be too symmetric
- Try breaking symmetry in configurations
- Test on small N first (N=10, N=20)

### Option C: Run bbox3 for Extended Time
The top kernel (bbox3-ensemble-update) runs bbox3 with adaptive parameters:
- n=[30-400], r=[10-50]
- Multiple optimization passes (SA, gradient descent, boundary optimization)
- But we can't run bbox3 (GLIBC incompatibility)

## ⚠️ SUBMIT IMMEDIATELY
With 91 submissions remaining, we should submit exp_020 NOW to get LB feedback. The CV-LB relationship has been perfect (< 1e-5 difference), so we expect LB ≈ 70.3166.

## Files to Submit
- Submission file: /home/submission/submission.csv
- Experiment: exp_020 (020_whynot_ensemble)
- Expected LB: ~70.3166 (improvement of 0.037 over best LB)
