## Current Status
- Best LB score: 70.3535 (exp_016 - mega_ensemble_external)
- Best CV score: 70.3535 (exp_016 - validated and submitted)
- Target: 68.877877 | Gap to target: 1.48 points (2.1%)
- Submissions used: 9/100 (91 remaining)

## CRITICAL INSIGHT FROM LOOP 17 ANALYSIS
**exp_007's score of 70.2657 was INVALID** - the N=24 solution had ALL x-coordinates as NaN!
This means our actual best valid score is 70.3535, not 70.2657.

## Submission Log (TRACK EVERYTHING!)
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 001 | valid_baseline | 70.6151 | 70.6151 | First valid submission |
| 002 | backward_prop | 70.6151 | 70.6151 | No improvement |
| 010 | safe_ensemble | 70.3651 | 70.3651 | MIN_IMPROVEMENT=0.001 works |
| 016 | mega_ensemble | 70.3535 | 70.3535 | Best so far, 7 N values improved |

## What We've Learned (from LB feedback)
1. **CV = LB exactly** for this problem (deterministic optimization)
2. **MIN_IMPROVEMENT=0.001 threshold is SAFE** - exp_016 passed validation
3. **Smaller thresholds FAIL** - exp_009 (N=123) and exp_013 (N=89) both failed
4. **All better N=24 solutions have overlaps** - searched 3800+ files
5. **16,780 improvements rejected** - many have overlaps, not safe to use

## Response to Evaluator
The evaluator correctly identified:
- ✅ Need more external data sources (we have 12, top kernels use 15-20)
- ✅ The 16,780 rejected improvements are potential gains

However, I DISAGREE with using lower thresholds for "safe" N values:
- exp_009 failed on N=123, exp_013 failed on N=89
- These failures were UNPREDICTABLE
- Keep MIN_IMPROVEMENT=0.001 for ALL N values

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer - FORBIDDEN (already at local optimum)
- subprocess.run() or os.system() - FORBIDDEN
- MIN_IMPROVEMENT < 0.001 - FORBIDDEN (causes Kaggle failures)
- Trusting solutions with NaN values - FORBIDDEN

## ✅ MANDATORY FIRST TASK: DOWNLOAD MORE EXTERNAL DATA

Top kernels use 15-20 external data sources. We only have 12. Download these:

```python
import subprocess
import os

# Download from Kaggle datasets
datasets = [
    'inversion/santa-2025-getting-started',
    'smartmanoj/santa-claude',
    'datafad/the-boxes-shrunk',
    'yongsukprasertsuk/santa-2025-best-keeping-bbox3-runner',
    'jazivxt/why-not',
]

for ds in datasets:
    name = ds.split('/')[-1]
    if not os.path.exists(f'/home/code/external_data/{name}'):
        subprocess.run(['kaggle', 'datasets', 'download', '-d', ds, '-p', '/home/code/external_data/'])
        subprocess.run(['unzip', '-o', f'/home/code/external_data/{name}.zip', '-d', f'/home/code/external_data/{name}'])
```

## ✅ REQUIRED: CREATE MEGA-ENSEMBLE WITH ALL SOURCES

After downloading, create ensemble with ALL external sources:

```python
import glob
import pandas as pd
from code.tree_geometry import calculate_score
from code.utils import parse_submission, save_submission

MIN_IMPROVEMENT = 0.001  # DO NOT CHANGE THIS

# Load baseline (exp_016)
baseline_df = pd.read_csv('/home/code/experiments/016_mega_ensemble_external/submission.csv')
baseline_configs = parse_submission(baseline_df)
baseline_scores = {n: calculate_score(baseline_configs[n]) for n in range(1, 201)}

# Load ALL external sources
all_files = glob.glob('/home/code/external_data/**/*.csv', recursive=True)
all_files += glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)

# Build ensemble with MIN_IMPROVEMENT=0.001 threshold
best_per_n = {n: baseline_configs[n] for n in range(1, 201)}
# ... (ensemble logic with strict validation)
```

## ✅ REQUIRED: IMPLEMENT LATTICE-BASED CONSTRUCTION

From the "why-not" kernel analysis, trees form crystallization patterns:
- 'Blue' trees: upward orientation (0° ± 90°)
- 'Pink' trees: downward orientation (180° ± 90°)
- They interlock with specific offsets

**IMPLEMENT THIS FROM SCRATCH:**
```python
import numpy as np
from code.tree_geometry import calculate_score, get_tree_vertices_numba
from shapely.geometry import Polygon

def construct_lattice_solution(n, spacing=0.5):
    """Construct N trees using lattice pattern with alternating orientations."""
    trees = []
    grid_size = int(np.ceil(np.sqrt(n)))
    
    for i in range(n):
        row = i // grid_size
        col = i % grid_size
        x = col * spacing
        y = row * spacing
        # Alternate blue (0°) and pink (180°) orientations
        angle = 0 if (row + col) % 2 == 0 else 180
        trees.append((x, y, angle))
    
    return trees

# Test on small N
for n in [10, 20, 30]:
    lattice_config = construct_lattice_solution(n)
    score = calculate_score(lattice_config)
    print(f"N={n}: Lattice score = {score:.4f}")
```

## ✅ REQUIRED: PER-N SCORE ANALYSIS

Identify which N values contribute most to total score:
```python
# Load best submission
df = pd.read_csv('/home/code/experiments/016_mega_ensemble_external/submission.csv')
configs = parse_submission(df)

# Calculate per-N contribution
total = sum(calculate_score(configs[n]) for n in range(1, 201))
contributions = []
for n in range(1, 201):
    score_n = calculate_score(configs[n])
    pct = score_n / total * 100
    contributions.append((n, score_n, pct))

# Sort by contribution
contributions.sort(key=lambda x: -x[1])
print("Top 20 N values by score contribution:")
for n, score, pct in contributions[:20]:
    print(f"  N={n}: {score:.4f} ({pct:.2f}%)")
```

Focus optimization efforts on high-contribution N values.

## Next Experiment: 017_extended_ensemble

1. Download 5+ more external data sources
2. Create mega-ensemble with ALL sources (snapshots + external)
3. Use MIN_IMPROVEMENT=0.001 threshold (DO NOT CHANGE)
4. Validate strictly with integer arithmetic
5. SUBMIT to get LB feedback

Expected improvement: 0.01-0.05 from more diverse sources

## SUBMIT EVERY EXPERIMENT
With 91 submissions remaining, submit EVERYTHING for LB feedback.
The gap is 1.48 points - we need aggressive experimentation.

## What NOT to Try
- ❌ Lower MIN_IMPROVEMENT threshold (causes Kaggle failures)
- ❌ Running bbox3 repeatedly (already at local optimum)
- ❌ Trusting exp_007's score (data was corrupted)
- ❌ Using N=24 solutions from snapshots (all have overlaps)