## Current Status
- Best CV score: 70.3535 from exp_016
- Best LB score: 70.3535 (exp_016 - VERIFIED)
- Target: 68.877877 | Gap to target: 1.48 points (2.1%)
- Submissions: 9/100 used, 91 remaining

## CRITICAL SITUATION ANALYSIS

**exp_017 confirmed we've EXHAUSTED the ensemble approach:**
- Scanned 3797 sources (15 external + 3782 snapshots)
- Found 0 improvements >= 0.001 threshold
- 17,543 improvements exist but are < 0.001 (unsafe to use)
- 2,410 configurations rejected for overlaps

**External constraints:**
- bbox3/shake_public binaries: GLIBC incompatible (cannot run)
- Kaggle API: Returns 403 Forbidden (cannot download more data)
- Our C++ SA optimizer: Finds only 0.00003 improvement (at local optimum)

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - CANNOT RUN (GLIBC incompatible)
- subprocess.run() or os.system() on binaries - WILL FAIL
- More ensemble combinations - ALREADY EXHAUSTED (0 improvements found)
- MIN_IMPROVEMENT < 0.001 - CAUSES KAGGLE FAILURES (proven by exp_009, exp_013)

## ✅ MANDATORY: IMPLEMENT NOVEL ALGORITHM FROM SCRATCH

Since all optimization approaches are exhausted, you MUST implement a NEW algorithm.

### EXPERIMENT 018: GENETIC ALGORITHM WITH CUSTOM CROSSOVER

**Why genetic algorithm?**
1. Can escape local optima through crossover (combines good parts of different solutions)
2. Population-based search explores more of the solution space
3. Different from SA which is stuck at local optimum

**Implementation requirements:**

```python
import numpy as np
import random
from code.tree_geometry import calculate_score, get_tree_vertices_numba
from code.utils import parse_submission, save_submission

# Load baseline as initial population
baseline_df = pd.read_csv('/home/code/experiments/016_mega_ensemble_external/submission.csv')
baseline_configs = parse_submission(baseline_df)

def crossover(parent1, parent2, n):
    """Swap a subset of trees between two configurations"""
    child = list(parent1)
    # Select random subset of trees to swap
    swap_count = max(1, n // 4)
    swap_indices = random.sample(range(n), swap_count)
    for i in swap_indices:
        child[i] = parent2[i]
    return child

def mutate(config, n, sigma=0.02):
    """Small perturbation to one tree"""
    config = list(config)
    i = random.randint(0, n-1)
    x, y, angle = config[i]
    config[i] = (x + random.gauss(0, sigma),
                 y + random.gauss(0, sigma),
                 angle + random.gauss(0, 2))
    return config

def repair_overlaps(config, n, max_attempts=100):
    """Try to fix overlaps by small perturbations"""
    for attempt in range(max_attempts):
        if not has_any_overlap(config):
            return config, True
        # Find overlapping pair and perturb one
        for i in range(n):
            for j in range(i+1, n):
                if check_overlap(config[i], config[j]):
                    # Perturb tree j
                    x, y, angle = config[j]
                    config[j] = (x + random.gauss(0, 0.05),
                                 y + random.gauss(0, 0.05),
                                 angle)
                    break
    return config, False

# Run genetic algorithm for each N
for n in [10, 20, 30]:  # TEST ON SMALL N FIRST
    print(f"\n=== N={n} ===")
    
    # Initialize population from baseline + random perturbations
    population = [baseline_configs[n]]
    for _ in range(19):
        mutated = mutate(baseline_configs[n], n, sigma=0.1)
        repaired, ok = repair_overlaps(mutated, n)
        if ok:
            population.append(repaired)
    
    best_score = calculate_score(baseline_configs[n])
    best_config = baseline_configs[n]
    
    for gen in range(100):
        # Evaluate fitness
        scores = [calculate_score(p) for p in population]
        
        # Selection (tournament)
        new_pop = []
        for _ in range(len(population)):
            i, j = random.sample(range(len(population)), 2)
            winner = population[i] if scores[i] < scores[j] else population[j]
            new_pop.append(winner)
        
        # Crossover
        for i in range(0, len(new_pop)-1, 2):
            if random.random() < 0.7:
                child1 = crossover(new_pop[i], new_pop[i+1], n)
                child2 = crossover(new_pop[i+1], new_pop[i], n)
                child1, ok1 = repair_overlaps(child1, n)
                child2, ok2 = repair_overlaps(child2, n)
                if ok1: new_pop[i] = child1
                if ok2: new_pop[i+1] = child2
        
        # Mutation
        for i in range(len(new_pop)):
            if random.random() < 0.3:
                mutated = mutate(new_pop[i], n)
                repaired, ok = repair_overlaps(mutated, n)
                if ok:
                    new_pop[i] = repaired
        
        population = new_pop
        
        # Track best
        for p in population:
            score = calculate_score(p)
            if score < best_score:
                best_score = score
                best_config = p
                print(f"  Gen {gen}: NEW BEST {best_score:.6f}")
    
    baseline_score = calculate_score(baseline_configs[n])
    print(f"N={n}: baseline={baseline_score:.6f}, best={best_score:.6f}")
    if best_score < baseline_score - 0.001:
        print(f"  ✅ IMPROVEMENT: {baseline_score - best_score:.6f}")
```

## ✅ REQUIRED: TEST ON SMALL N FIRST (MANDATORY)

Before running on all 200 N values, test on N=10, N=20, N=30:
- If you beat baseline on small N → Scale up to all N
- If you DON'T beat baseline on small N → Try different approach

## ✅ REQUIRED: PER-N TRACKING

Track best solution for EACH N separately:
```python
best_per_n = {}
for n in range(1, 201):
    my_score = calculate_score(my_config[n])
    baseline_score = baseline_scores[n]
    if my_score < baseline_score - 0.001:  # MIN_IMPROVEMENT threshold
        best_per_n[n] = my_config[n]
        print(f"✅ N={n}: IMPROVED by {baseline_score - my_score:.6f}")
    else:
        best_per_n[n] = baseline_configs[n]
```

## SUBMIT AFTER EXPERIMENT

Even if the genetic algorithm doesn't find improvements, SUBMIT the result:
- We have 91 submissions remaining
- LB feedback is valuable learning signal
- Only skip if result is INVALID (overlaps, format error)

## What NOT to Try
- ❌ More ensemble combinations (exhausted - 0 improvements found)
- ❌ Running bbox3/sa_fast (GLIBC incompatible)
- ❌ Smaller improvement thresholds (causes Kaggle failures)
- ❌ More SA iterations (already at local optimum - only 0.00003 improvement)
- ❌ fix_direction rotation (already tested - no improvement)

## Alternative Approaches (if GA doesn't work)

1. **Constructive heuristic (bottom-left placement)**
2. **Pattern-based placement (lattice with alternating orientations)**
3. **Branch-and-bound for small N (N=2-10)**
4. **Constraint programming formulation**

The key is to try FUNDAMENTALLY DIFFERENT approaches, not variations of the same optimization.