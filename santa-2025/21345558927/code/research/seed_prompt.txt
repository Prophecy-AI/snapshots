# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- **Best CV score**: 70.265730 from 007_ensemble_fractional (NOT YET SUBMITTED!)
- **Best LB score**: 70.615101 (from exp_001 baseline)
- **Target**: 68.881647 (lower is better)
- **Gap to target**: 1.38 points (2.0% improvement needed)

## ðŸš¨ CRITICAL: SUBMIT 007_ensemble_fractional IMMEDIATELY! ðŸš¨

The experiment 007_ensemble_fractional achieved **70.266** (0.35 point improvement over baseline).
This submission is ready in `/home/submission/submission.csv` but WAS NOT SUBMITTED!

**FIRST ACTION**: Submit this to get LB feedback!

## What We've Learned

### Breakthrough: Ensemble from Snapshots
- Ensembling best per-N solutions from 3530 CSV files in snapshots
- Found 43 N values with better solutions than baseline
- **N=24 alone contributed 0.348 improvement** (99% of total gain!)
- Most other improvements are tiny (1e-6 to 1e-4)

### Key Insight: N=24 Has a Much Better Solution
The snapshots contain a dramatically better solution for N=24.
This suggests:
1. Other N values may also have hidden better solutions
2. The baseline is NOT globally optimal for all N
3. More aggressive search on specific N values could yield big gains

### What Doesn't Work (Proven by 7 experiments)
- SA from baseline â†’ NO improvement (baseline is local optimum)
- Exhaustive search for N=2 â†’ Baseline already optimal
- NFP-based placement â†’ Cannot beat baseline
- Multi-start random â†’ Random configs are 73% worse
- Backward propagation â†’ Cannot improve by removing trees

## Submission Log
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 000 | baseline ensemble | 70.523 | ERROR | Overlapping trees |
| 001 | valid baseline | 70.615 | 70.615 | âœ… Valid baseline |
| 002 | backward prop | 70.615 | 70.615 | No improvement |
| 007 | ensemble snapshots | 70.266 | PENDING | **SUBMIT THIS!** |

## Response to Evaluator

The evaluator correctly identified:
1. âœ… Local search from baseline is exhausted (7 experiments, 0 improvements)
2. âœ… Ensemble approach is the key (we found 0.35 improvement!)
3. âœ… Public resources (snapshots) contain better solutions

**Action taken**: The executor implemented the ensemble approach and found a 0.35 point improvement.
**Missing**: The submission was not submitted to LB. This must be done first.

## Next Experiment Strategy

### Phase 1: Submit and Validate (IMMEDIATE)
1. Submit 007_ensemble_fractional to get LB score
2. If LB matches CV (~70.266), we've made real progress

### Phase 2: Find More N=24-like Wins
The N=24 improvement (0.348 points) shows that some N values have dramatically better solutions.
Search for other N values with similar potential:

```python
# For each N, compare best snapshot solution to baseline
# Look for N values where gap is > 0.01 (potential big wins)
for n in range(1, 201):
    snapshot_best = min(scores_from_all_snapshots[n])
    baseline_score = baseline_scores[n]
    gap = baseline_score - snapshot_best
    if gap > 0.01:
        print(f"N={n}: potential improvement of {gap:.4f}")
```

### Phase 3: Implement Fractional Translation
The top kernel uses fractional translation - tiny position adjustments:
```python
frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
directions = [(0,1), (0,-1), (1,0), (-1,0), (1,1), (1,-1), (-1,1), (-1,-1)]

for tree_idx in range(n):
    for step in frac_steps:
        for dx, dy in directions:
            # Try moving tree by (dx*step, dy*step)
            new_config = move_tree(config, tree_idx, dx*step, dy*step)
            if not has_overlap(new_config):
                new_score = calculate_score(new_config)
                if new_score < best_score:
                    best_score = new_score
                    best_config = new_config
```

This can find improvements that SA misses because it uses much smaller steps.

### Phase 4: Focus on Large N (73% of score)
N=51-200 contributes 73% of total score. Even small improvements matter:
- 0.001 improvement on each of 150 N values = 0.15 total improvement
- Focus optimization effort here

## â›” FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() with binaries - FORBIDDEN
- Running ANY pre-compiled binary - FORBIDDEN
- "Optimizing" existing CSV files with C++ tools - FORBIDDEN

## âœ… REQUIRED: Per-N Tracking

Track best solution for EACH N separately:
```python
best_per_n = {}
for n in range(1, 201):
    best_per_n[n] = {
        'score': baseline_scores[n],
        'config': baseline_configs[n],
        'source': 'baseline'
    }

# After each experiment, update best_per_n
# Final submission = ensemble of best per-N from all sources
```

## Score Breakdown (for prioritization)
- N=1-10: 4.33 points (6.1%)
- N=11-50: 14.11 points (20.0%)
- N=51-100: 17.61 points (24.9%)
- N=101-150: 17.13 points (24.3%)
- N=151-200: 16.84 points (23.9%)

**Large N (51-200) = 73% of score** - focus here!

## Immediate Actions

1. **SUBMIT 007_ensemble_fractional** - Get LB feedback on 70.266 score
2. **Analyze N=24** - Why is this solution so much better? Can we find similar wins?
3. **Implement fractional translation** - Fine-tune the ensemble solution
4. **Search for more big wins** - Look for N values with large gaps in snapshots

## Technical Notes

- Use high precision (20+ decimal places) for coordinates
- Prefix coordinates with 's' for Kaggle format
- Validate overlaps before submission using integer-scaled Shapely
- The baseline uses angles 180Â° apart for N=2 (symmetric placement)