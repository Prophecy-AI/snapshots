# Santa 2025 - Christmas Tree Packing Optimization

## ⚠️ CRITICAL: SUBMISSION FAILED - FIX OVERLAP VALIDATION FIRST!

**The baseline submission FAILED with "Overlapping trees in group 002".**

The ensemble submission from snapshots has precision issues that cause overlaps when Kaggle validates. This MUST be fixed before any other work.

## Current Status
- **Best CV score**: 70.523320 (from ensemble - BUT FAILED KAGGLE VALIDATION)
- **Best VALID LB score** (from snapshots): 70.627582
- **Target**: 68.882921
- **Gap to target**: 1.74 points (2.5% improvement needed)
- **Submissions remaining**: 99/100

## ⛔ ABSOLUTELY FORBIDDEN (EXPERIMENT WILL BE REJECTED)

The following are PERMANENTLY FORBIDDEN after baseline:
- bbox3 - FORBIDDEN
- sa_fast_v2 - FORBIDDEN  
- eazy_optimizer - FORBIDDEN
- tree_packer - FORBIDDEN (all versions)
- shake_public - FORBIDDEN
- subprocess.run() with any binary - FORBIDDEN
- os.system() with any binary - FORBIDDEN
- ANY pre-compiled binary or executable - FORBIDDEN

## ✅ MANDATORY FIRST TASK: FIX OVERLAP VALIDATION

**Before ANY other work, you MUST implement proper overlap validation:**

```python
from decimal import Decimal, getcontext
from shapely.geometry import Polygon
from shapely.strtree import STRtree

getcontext().prec = 30
SCALE = Decimal("1e18")  # CRITICAL: Use integer scaling for precision!

def get_tree_polygon_scaled(x, y, angle_deg):
    """Get tree polygon with integer-scaled coordinates for precise validation."""
    # Tree vertices (15 points)
    TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
    TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
    
    import math
    rad = math.radians(float(angle_deg))
    cos_a, sin_a = math.cos(rad), math.sin(rad)
    
    vertices = []
    for tx, ty in zip(TX, TY):
        # Rotate then translate, then scale to integer
        rx = Decimal(str(tx)) * Decimal(str(cos_a)) - Decimal(str(ty)) * Decimal(str(sin_a)) + Decimal(str(x))
        ry = Decimal(str(tx)) * Decimal(str(sin_a)) + Decimal(str(ty)) * Decimal(str(cos_a)) + Decimal(str(y))
        vertices.append((int(rx * SCALE), int(ry * SCALE)))
    
    return Polygon(vertices)

def validate_no_overlap(trees):
    """Validate that no trees overlap using integer-scaled coordinates."""
    if len(trees) <= 1:
        return True, []
    
    polygons = [get_tree_polygon_scaled(t[0], t[1], t[2]) for t in trees]
    tree_index = STRtree(polygons)
    
    overlaps = []
    for i, poly in enumerate(polygons):
        indices = tree_index.query(poly)
        for idx in indices:
            if idx <= i:
                continue
            if poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):
                overlaps.append((i, idx))
    
    return len(overlaps) == 0, overlaps

# MANDATORY: Validate ALL N values before submission
def validate_submission(configs):
    """Validate entire submission for overlaps."""
    invalid_n = []
    for n in range(1, 201):
        if n not in configs:
            continue
        trees = configs[n]  # List of (x, y, angle) tuples
        valid, overlaps = validate_no_overlap(trees)
        if not valid:
            invalid_n.append((n, overlaps))
            print(f"❌ N={n}: {len(overlaps)} overlapping pairs")
    
    if invalid_n:
        print(f"\n⚠️ INVALID SUBMISSION: {len(invalid_n)} N values have overlaps")
        return False
    else:
        print("✅ All N values validated - no overlaps")
        return True
```

## ✅ EXPERIMENT 001: ESTABLISH VALID BASELINE

**GOAL**: Get a submission that PASSES Kaggle validation.

**Steps:**
1. Load the ORIGINAL baseline submission (not the ensemble) that is known to pass Kaggle
2. The validated baseline score is 70.647327 (confirmed to pass Kaggle)
3. Validate locally using the integer-scaled overlap detection above
4. Submit to verify it passes

**Where to find valid baseline:**
```
/home/nonroot/snapshots/santa-2025/21198893057/code/experiments/001_baseline/
```
Or use the original sample submission and verify it passes.

**Key insight from snapshots:**
- Best VALID LB score achieved: 70.627582 (from exhaustive_small_n experiment)
- Ensemble submissions with lower CV scores often FAIL due to precision issues
- Only submissions with full precision (16+ decimal places) pass Kaggle

## ✅ AFTER VALID BASELINE: IMPLEMENT NOVEL ALGORITHMS

Once you have a valid baseline that passes Kaggle, implement algorithms from scratch:

### Priority 1: SMALL N EXHAUSTIVE SEARCH (N=2-10)
Small N values contribute MOST to score:
- N=1: 0.661 (already optimal at 45°)
- N=2: 0.437 (high contribution, room for improvement)
- N=3-10: High score contribution per tree

```python
import itertools
import numpy as np

def exhaustive_search_n2():
    """Exhaustive search for N=2 optimal configuration."""
    best_score = float('inf')
    best_config = None
    
    # Coarse grid search
    for angle1 in np.arange(0, 360, 1.0):  # 1° increments
        for angle2 in np.arange(0, 360, 1.0):
            for dx in np.arange(-1.0, 1.0, 0.05):
                for dy in np.arange(-1.0, 1.0, 0.05):
                    config = [(0, 0, angle1), (dx, dy, angle2)]
                    if not has_overlap(config):
                        score = calculate_bbox_score(config)
                        if score < best_score:
                            best_score = score
                            best_config = config
    
    return best_config, best_score
```

### Priority 2: TESSELLATION FOR LARGE N (N >= 50)
```python
def tessellation_packing(n, base_angle1=68, base_angle2=248):
    """Generate tessellation-based packing for large N."""
    # Start with 2 base trees in a specific configuration
    # Create grid by translating the 2-tree unit cell
    # Optimize: Use SA to find best (θ1, θ2, tx, ty, offset_x)
    pass
```

### Priority 3: BACKWARD PROPAGATION
After optimizing large N, propagate improvements to smaller N by removing trees.

## ✅ MANDATORY: PER-N SOLUTION TRACKING

Track best solution for EACH N value separately:

```python
# Load baseline per-N scores
baseline_scores = {}
for n in range(1, 201):
    baseline_scores[n] = calculate_score_for_n(baseline_config, n)

# After your algorithm runs, compare per-N scores
improved_n = []
for n in range(1, 201):
    new_score = calculate_score_for_n(new_config, n)
    if new_score < baseline_scores[n]:
        improved_n.append(n)
        print(f"N={n}: {baseline_scores[n]:.6f} -> {new_score:.6f}")

# SAVE any N where you improved (even if total is worse)
```

## Tree Geometry (15 vertices)
```python
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```

## What We've Learned from Snapshots

1. **Precision is CRITICAL**: Kaggle uses stricter precision than default Shapely
2. **Ensemble submissions often fail**: Due to truncated precision causing overlaps
3. **Best valid score**: 70.627582 (from exhaustive_small_n experiment)
4. **Baseline is at strong local optimum**: 26+ experiments in snapshots all converge to ~70.627
5. **Small N is already optimal**: N=2 baseline is optimal within search resolution

## Response to Evaluator

The evaluator correctly identified:
1. **No algorithm implementation yet** - We need to implement algorithms from scratch
2. **Small N values are biggest opportunity** - N=1-10 contribute ~3.3% of total score
3. **Tessellation not yet attempted** - This is fundamentally different from local search

**HOWEVER**, the immediate priority is fixing the overlap validation issue. The baseline submission FAILED Kaggle validation. We MUST:
1. First establish a VALID baseline that passes Kaggle
2. Then implement novel algorithms

## Next Experiment: 001_valid_baseline

1. **Load the original validated baseline** (score 70.647327)
2. **Implement proper overlap validation** using integer scaling
3. **Verify locally** that all N values pass validation
4. **Submit to Kaggle** to confirm it passes
5. **Then** proceed with novel algorithm implementation

**Expected outcome**: LB score of 70.647327 (matching the validated baseline from snapshots)