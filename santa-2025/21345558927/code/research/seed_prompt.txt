# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.615102 from exp_001 (valid baseline)
- Best LB score: 70.615101885765 (from exp_001)
- Target: 68.881647 (lower is better) | Gap to target: 1.73 points (2.5%)

## ⛔⛔⛔ CRITICAL: 6 EXPERIMENTS, SAME SCORE ⛔⛔⛔

**ALL 6 experiments produced score 70.615102:**
- exp_000: baseline (70.52 - failed validation)
- exp_001: valid baseline (70.615102) ✓
- exp_002: backward propagation (70.615101) - NO improvement
- exp_003: simulated annealing (70.615102) - NO improvement
- exp_004: exhaustive N=2 search (70.615102) - NO improvement
- exp_005: NFP placement (70.615102) - NO improvement

**CONCLUSION: The baseline is at an EXTREMELY strong local optimum.**
- Local search (SA) cannot escape it
- Exhaustive search on small N confirms baseline is optimal
- NFP-based placement finds no better positions
- Backward propagation finds no better tree removals

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast_v2, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- More SA iterations - ALREADY TRIED, DOESN'T WORK
- More exhaustive search on N=2 - ALREADY TRIED, DOESN'T WORK
- NFP-based optimization - ALREADY TRIED, DOESN'T WORK

## Response to Evaluator

The evaluator correctly identified that:
1. **Small-N optimization has been exhausted** - 6 experiments confirm baseline is optimal for small N
2. **Large N values contribute 73% of total score** - yet all experiments focused on small N
3. **Tessellation approach not tried** - constructive approach that creates different configurations
4. **Asymmetric configurations not explored** - discussion 666880 suggests asymmetric may be better
5. **Need to find a DIFFERENT basin of attraction** - local search cannot escape current optimum

I AGREE with the evaluator's assessment. The next experiment MUST be fundamentally different.

## ✅ MANDATORY NEXT EXPERIMENT: MULTI-START RANDOM INITIALIZATION

**The key insight:** The baseline is at a local optimum. We need to find a DIFFERENT starting point.

**Strategy:**
1. Generate RANDOM initial configurations for each N
2. Run SA optimization from each random start
3. Keep the best result across multiple random starts
4. Compare to baseline - if better for ANY N, we've found a new basin!

```python
# experiments/006_multistart_random/

import numpy as np
from code.tree_geometry import calculate_score, TX, TY
from code.overlap_check import has_overlap
from code.sa_optimizer import simulated_annealing

def generate_random_config(n, max_attempts=1000):
    """Generate a random valid configuration for N trees."""
    for _ in range(max_attempts):
        # Random positions in a reasonable range
        positions = np.random.uniform(-2, 2, (n, 2))
        # Random angles
        angles = np.random.uniform(0, 360, n)
        
        config = [(positions[i, 0], positions[i, 1], angles[i]) for i in range(n)]
        
        if not has_overlap(config):
            return config
    
    return None  # Failed to find valid config

def multistart_optimization(n, n_starts=10, sa_iterations=5000):
    """Run SA from multiple random starting points."""
    best_score = float('inf')
    best_config = None
    
    for start in range(n_starts):
        # Generate random initial config
        config = generate_random_config(n)
        if config is None:
            continue
        
        # Run SA from this starting point
        optimized_config = simulated_annealing(config, n_iterations=sa_iterations)
        score = calculate_score(optimized_config)
        
        if score < best_score:
            best_score = score
            best_config = optimized_config
            print(f"  Start {start}: New best score {score:.6f}")
    
    return best_config, best_score

# Test on N=10, 20, 30 first
for n in [10, 20, 30, 50, 100]:
    config, score = multistart_optimization(n, n_starts=20, sa_iterations=10000)
    baseline_score = get_baseline_score(n)
    diff = baseline_score - score
    print(f"N={n}: Multistart={score:.6f}, Baseline={baseline_score:.6f}, Diff={diff:.6f}")
    if diff > 0:
        print(f"  ✅ IMPROVEMENT FOUND!")
```

## Alternative Approach: GENETIC ALGORITHM

If multi-start doesn't work, try genetic algorithm:

```python
def genetic_algorithm(n, pop_size=50, generations=100, mutation_rate=0.1):
    """Evolve population of configurations."""
    
    # Initialize population with random valid configs
    population = [generate_random_config(n) for _ in range(pop_size)]
    population = [p for p in population if p is not None]
    
    for gen in range(generations):
        # Evaluate fitness (lower score = better)
        fitness = [(calculate_score(config), config) for config in population]
        fitness.sort(key=lambda x: x[0])
        
        # Keep top 50%
        survivors = [config for _, config in fitness[:pop_size//2]]
        
        # Crossover: combine parts of two parents
        children = []
        while len(children) < pop_size//2:
            p1, p2 = random.sample(survivors, 2)
            child = crossover(p1, p2, n)
            if child and not has_overlap(child):
                children.append(child)
        
        # Mutation: small random changes
        for config in survivors + children:
            if random.random() < mutation_rate:
                mutate(config)
        
        population = survivors + children
        
        if gen % 10 == 0:
            print(f"Gen {gen}: Best score = {fitness[0][0]:.6f}")
    
    return fitness[0][1], fitness[0][0]

def crossover(p1, p2, n):
    """Combine two parent configurations."""
    # Take first half from p1, second half from p2
    split = n // 2
    child = list(p1[:split]) + list(p2[split:])
    return child

def mutate(config):
    """Apply small random changes to a configuration."""
    idx = random.randint(0, len(config)-1)
    x, y, angle = config[idx]
    # Small perturbation
    x += random.gauss(0, 0.1)
    y += random.gauss(0, 0.1)
    angle += random.gauss(0, 5)
    config[idx] = (x, y, angle % 360)
```

## Per-N Score Tracking (MANDATORY)

```python
# Track improvements per-N
improvements = {}
for n in range(1, 201):
    my_score = calculate_score(my_configs[n])
    baseline_score = calculate_score(baseline_configs[n])
    diff = baseline_score - my_score
    if diff > 1e-6:
        improvements[n] = diff
        print(f"✅ N={n}: IMPROVED by {diff:.6f}")

# Create ensemble: best per-N from all sources
final_configs = {}
for n in range(1, 201):
    if n in improvements:
        final_configs[n] = my_configs[n]
    else:
        final_configs[n] = baseline_configs[n]
```

## Expected Outcomes

1. **Multi-start may find different basins** - even if total score is worse, individual N improvements are valuable
2. **Genetic algorithm explores more diverse configurations** - crossover creates novel combinations
3. **Large N values (N>50) are the key** - they contribute 73% of score

## What NOT to Try
- ❌ More SA from baseline - ALREADY TRIED, DOESN'T WORK
- ❌ More exhaustive search on small N - ALREADY TRIED, DOESN'T WORK
- ❌ NFP-based optimization - ALREADY TRIED, DOESN'T WORK
- ❌ Backward propagation - ALREADY TRIED, DOESN'T WORK
- ❌ Any binary optimizer - FORBIDDEN

## SUBMIT EVERY EXPERIMENT

With 97 submissions remaining, submit EVERY experiment to get LB feedback.
Even if CV score is worse, LB might reveal something different.

## Success Criteria

- Find improvement for ANY N value → partial success
- Find improvement for multiple N values → significant progress
- Beat baseline total score → major breakthrough
