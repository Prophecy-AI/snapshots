## Current Status
- Best CV score: 70.341099 from exp_009 (high-precision ensemble)
- Best LB score: 70.615101 (from exp_001/002 - baseline)
- Target: 68.879467 | Gap to target: 1.46 points (2.1% improvement needed)
- **SUBMISSION FAILED**: exp_009 failed with "Overlapping trees in group 123"

## CRITICAL: FIX THE OVERLAP ISSUE FIRST

The exp_009 submission (CV 70.341) failed Kaggle validation due to overlapping trees in N=123.

**Root Cause Analysis:**
- Our local validation (using Shapely with integer scaling) passed for N=123
- Kaggle's validation is stricter and detected an overlap we missed
- The N=123 configuration came from a snapshot with different precision than baseline

**IMMEDIATE FIX (DO THIS FIRST):**
1. Create a "safe" submission that only keeps improvements > 0.001
2. Fall back to baseline for all small improvements (which might be precision artifacts)
3. This gives score 70.365 (worse than 70.341 but should pass validation)

**Safe submission already created at:**
`/home/code/experiments/009_highprec_ensemble/submission_safe.csv`

**SUBMIT THIS FIRST** to validate the approach works.

## Response to Evaluator

The evaluator correctly identified:
1. ✅ N=70 has a tiny overlap (1.19e-29 area) - we fell back to baseline for this
2. ✅ The ensemble approach is sound but has precision bugs
3. ✅ External public datasets should be explored

**However**, the actual Kaggle failure was N=123, not N=70. This suggests:
- Our validation is not strict enough
- We need to be more conservative about which improvements to keep

**Action taken:**
- Created safe submission with MIN_IMPROVEMENT = 0.001 threshold
- Falls back to baseline for 68 N values with small improvements
- Keeps 74 N values with significant improvements (> 0.001)
- Score: 70.365 (0.25 improvement over baseline)

## Submission Log (TRACK EVERYTHING!)
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 000 | baseline | 70.523 | pending | Pre-optimized snapshot ensemble |
| 001 | valid_baseline | 70.615 | 70.615 | Passed Kaggle validation |
| 002 | backward_prop | 70.615 | 70.615 | No improvement |
| 007 | ensemble | 70.266 | pending | First real improvement |
| 008 | snapshot_ensemble | 70.373 | pending | 167 N improvements |
| 009 | highprec_ensemble | 70.341 | FAILED | Overlap in N=123 |

## What We've Learned

1. **Baseline is at strong local optimum**: SA, exhaustive search, NFP, backward propagation all failed to improve
2. **Snapshots contain better solutions**: Ensemble from 3728 snapshots found 142 N values with improvements
3. **Precision matters**: Kaggle uses stricter validation than our local Shapely-based checks
4. **Small improvements are risky**: Improvements < 0.001 might be precision artifacts that cause overlaps

## Next Experiment: SUBMIT SAFE ENSEMBLE

**IMMEDIATE ACTION:**
1. Submit the safe submission (70.365) to validate it passes Kaggle
2. If it passes, we have a new baseline to build on
3. If it fails, we need even stricter validation

**After validation:**
1. Download more external data sources (jazivxt/bucket-of-chump, etc.)
2. Ensemble with external sources for more per-N improvements
3. Consider implementing C++ optimizer for intensive local search

## Strategy for Reaching Target (68.88)

Current gap: 1.49 points (from 70.365 to 68.88)

**Path forward:**
1. **More data sources**: Top kernels use 15+ external sources
2. **C++ optimizer**: Python is too slow for intensive optimization
3. **Fractional translation**: Fine-tune positions with 0.00001 step sizes
4. **Per-N specialization**: Different strategies for different N ranges

**What NOT to try:**
- Running SA/exhaustive search on baseline (already tried, no improvement)
- Small parameter tweaks (won't bridge 1.49 point gap)
- Precision artifacts (cause validation failures)

## ⛔ FORBIDDEN
- bbox3, sa_fast, eazy_optimizer - FORBIDDEN (binaries)
- subprocess.run() or os.system() for binaries - FORBIDDEN
- Improvements < 0.001 without strict validation - RISKY

## ✅ REQUIRED
1. Submit safe ensemble FIRST to validate approach
2. Track per-N scores for all experiments
3. Use strict overlap validation (integer arithmetic with SCALE=10^18)
4. Fall back to baseline for any N that fails validation
