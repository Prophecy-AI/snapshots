## What I Understood

The junior researcher ran exp_018 (Genetic Algorithm optimizer) attempting to escape the local optimum that has trapped all previous optimization attempts. The GA used population size 20, 50 generations, crossover rate 0.7, and mutation rate 0.3, testing on N=5,10,15,20,25,30. Result: **0 improvements found** - the GA could not escape the local optimum either. The experiment correctly fell back to the baseline (exp_016) with CV=70.353516.

This is the 19th experiment, and the team has been stuck at essentially the same score since exp_010 (70.365091) with only marginal improvements from external data sources.

## Technical Execution Assessment

**Validation**: 
- ✅ MIN_IMPROVEMENT=0.001 threshold correctly applied
- ✅ Overlap validation using Shapely geometry
- ✅ Repair function attempts to fix overlaps before rejection
- ✅ Seeds set for reproducibility (random.seed(42), np.random.seed(42))

**Leakage Risk**: None. This is a pure geometric optimization problem.

**Score Integrity**: 
- ✅ CV score of 70.353516 verified - identical to exp_016 baseline (expected since 0 improvements)
- ✅ Metrics correctly report 0 improvements

**Code Quality**: 
- ✅ Clean implementation of GA with crossover, mutation, and repair
- ✅ Proper tournament selection
- ⚠️ Small concern: GA only tested on 6 N values before giving up - could have tested more

**CRITICAL FINDING - exp_007 Data Corruption**:
I investigated why exp_007 (CV=70.266) wasn't submitted despite being the "best" CV score. **The N=24 configuration in exp_007 contains NaN values for all x-coordinates!** This is corrupted data, not a real improvement. The calculate_score function incorrectly computed a low score (0.017) for this corrupted config. This explains the 0.348 "improvement" that was never real.

Verdict: **TRUSTWORTHY** - The GA experiment executed correctly. The exp_007 "best score" was a data corruption bug, not a missed opportunity.

## Strategic Assessment

**Approach Fit**: 
- ✅ GA is a reasonable approach to try for escaping local optima
- ⚠️ However, the problem structure (tight geometric packing with strict overlap constraints) makes crossover operations very likely to create invalid solutions
- ⚠️ The repair function is too simple - just random perturbations

**Effort Allocation**: 
- ⚠️ CONCERN: We've now tried SA, exhaustive search, NFP, multi-start random, backward propagation, and GA - ALL found 0 improvements
- ⚠️ The baseline configurations are at an EXTREMELY strong local optimum
- ⚠️ Further local search methods are unlikely to help
- ✅ The team correctly identified that external data sources are the key lever

**Assumptions Being Made**:
1. ⚠️ "We have all the good external data" - FALSE! Top kernels use 17-19 sources, we have ~8
2. ⚠️ "bbox3 is incompatible" - This may be solvable with static linking or different binary
3. ⚠️ "MIN_IMPROVEMENT=0.001 is necessary" - This is conservative; some N values may be safe with lower thresholds

**Blind Spots - CRITICAL**:

### 1. MISSING EXTERNAL DATA SOURCES (HIGHEST PRIORITY)
From jonathanchan kernel, top competitors use 17-19 data sources:
```
✅ bucket-of-chump (have)
✅ santa-submission/saspav (have)
✅ santa-2025-simple-optimization-new-slow-version/chistyakov (have)
✅ telegram-public-shared-solution-for-santa-2025 (have)
❌ why-not (MISSING)
❌ santa25-improved-sa-with-translations (MISSING)
❌ santa-2025-try3 (MISSING)
❌ santa25-public (MISSING)
❌ santa2025-ver2 (MISSING)
❌ santa25-simulated-annealing-with-translations (MISSING)
❌ santa-2025-fix-direction (MISSING)
❌ 72-71-santa-2025-jit-parallel-sa-c (MISSING)
❌ blending-multiple-oplimisation (MISSING)
❌ santa2025-just-keep-on-trying (MISSING)
❌ decent-starting-solution (MISSING)
```
**We're missing at least 10 external data sources that top kernels use!**

### 2. BBOX3 BINARY COMPATIBILITY
The team noted bbox3 has GLIBC issues. Options:
- Try downloading a statically-linked version
- Compile from source (bbox3.cpp exists in experiments folder)
- Use a Docker container with older GLIBC

### 3. THE 16,780 REJECTED IMPROVEMENTS
These improvements exist but are rejected as too small. Potential approaches:
- **Per-N safety analysis**: Which N values have NEVER caused Kaggle failures? Use lower threshold for those.
- **Ensemble multiple small improvements**: If 10 small improvements each add 0.0005, that's 0.005 total
- **Precision enhancement**: Increase coordinate precision to make small improvements safe

### 4. C++ OPTIMIZER FROM KERNELS
The jonathanchan kernel includes tree_packer_v18.cpp with:
- Population-based search with basin hopping
- Edge-based slide compaction
- OpenMP parallelization
This is more sophisticated than our SA optimizer and should be tried.

## CV-LB Relationship Analysis

Based on submission history:
- exp_001: CV=70.615102, LB=70.615101885765 ✅
- exp_010: CV=70.365091, LB=70.365091304619 ✅
- exp_016: CV=70.353516, LB=70.353515934637 ✅

**Perfect CV-LB match** (< 1e-5 difference). This is a deterministic optimization problem - CV equals LB exactly when validation passes. No distribution shift concerns.

**Submission Success Rate**: 4 passed out of 9 submitted (44%). Failures are due to tiny overlaps that pass local validation but fail Kaggle's stricter checks. The MIN_IMPROVEMENT=0.001 threshold has been working since exp_010.

## What's Working

1. **Conservative threshold approach** - exp_010, exp_016 both passed Kaggle with MIN_IMPROVEMENT=0.001
2. **External data integration** - Found 7 improvements from saspav, bucket_of_chump, etc.
3. **Code infrastructure** - Clean, reusable modules for ensemble building
4. **Understanding of the problem** - Correctly identified that local search is exhausted
5. **Systematic experimentation** - Tried many approaches before concluding local search is stuck

## Key Concerns

### Concern 1: CRITICAL - Missing External Data Sources
- **Observation**: We have ~8 external sources; top kernels use 17-19
- **Why it matters**: Each new source could contain better solutions for some N values. The gap of 1.476 points likely requires 10-20 N values with significant improvements.
- **Suggestion**: Download these datasets immediately:
  ```bash
  kaggle datasets download jazivxt/why-not
  kaggle datasets download santa25-improved-sa-with-translations
  kaggle datasets download santa-2025-try3
  kaggle datasets download santa25-public
  kaggle datasets download santa2025-ver2
  kaggle datasets download santa-2025-fix-direction
  kaggle datasets download blending-multiple-oplimisation
  ```

### Concern 2: HIGH - bbox3 Not Being Used
- **Observation**: bbox3.cpp exists but binary has GLIBC issues
- **Why it matters**: Top kernels run bbox3 for hours with 150,000+ iterations
- **Suggestion**: Compile bbox3 from source:
  ```bash
  g++ -O3 -march=native -std=c++17 -o bbox3_local bbox3.cpp
  ./bbox3_local -i submission.csv -o optimized.csv -n 150000 -r 32
  ```

### Concern 3: MEDIUM - 16,780 Rejected Improvements
- **Observation**: These improvements exist but are rejected as too small
- **Why it matters**: Potential score gains we're leaving on the table
- **Suggestion**: Analyze which N values have NEVER caused Kaggle failures across all submissions. For those "safe" N values, consider using a lower threshold (0.0001).

### Concern 4: LOW - GA Implementation Could Be Stronger
- **Observation**: GA only tested 6 N values before giving up
- **Why it matters**: Some larger N values might be more amenable to GA
- **Suggestion**: Not worth pursuing further - external data is the higher-leverage path

## Gap Analysis

- **Current best LB**: 70.353516 (exp_016)
- **Target**: 68.877877
- **Gap**: 1.476 points (2.1%)

The gap requires finding ~15-20 N values with improvements averaging 0.07-0.10 each, OR finding a few N values with dramatic improvements (like the corrupted N=24 that showed 0.348 improvement potential).

**The path forward requires NEW DATA, not more optimization algorithms.**

## Top Priority for Next Experiment

**DOWNLOAD ALL MISSING EXTERNAL DATA SOURCES AND BUILD A COMPREHENSIVE ENSEMBLE**

### Immediate Actions:

1. **Download ALL missing external data sources** (highest priority):
   ```bash
   # These are the sources used by top kernels that we're missing
   kaggle datasets download jazivxt/why-not
   kaggle datasets download santa25-improved-sa-with-translations
   kaggle datasets download santa-2025-try3
   kaggle datasets download santa25-public
   kaggle datasets download santa2025-ver2
   kaggle datasets download santa-2025-fix-direction
   kaggle datasets download blending-multiple-oplimisation
   kaggle datasets download santa2025-just-keep-on-trying
   kaggle datasets download decent-starting-solution
   ```

2. **Compile bbox3 from source** (if downloads don't yield enough improvement):
   ```bash
   g++ -O3 -march=native -std=c++17 -o bbox3_local /home/code/experiments/bbox3.cpp
   ```

3. **Build new ensemble with expanded data**:
   - Combine ALL new external sources with existing best
   - Use MIN_IMPROVEMENT=0.001 threshold
   - Submit to verify

### Expected Outcome:
- With 10+ new external sources: Could find improvements for 10-20 N values
- Each improvement averaging 0.05-0.10 could close the gap significantly
- Target of 68.878 IS reachable with comprehensive external data

**CRITICAL REMINDER**: The team has exhausted local search methods (SA, GA, exhaustive, NFP, backward propagation). The ONLY path forward is:
1. More external data sources (primary lever)
2. Running bbox3 for extended periods (secondary lever)
3. Trying the C++ optimizer from jonathanchan kernel (tertiary lever)

Stop trying new optimization algorithms. Get more data.
