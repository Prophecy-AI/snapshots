{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcc4055",
   "metadata": {},
   "source": [
    "# Evolver Loop 7 Analysis\n",
    "\n",
    "Analyzing the situation after 7 experiments with no improvement. Need to find a fundamentally different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62723411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "\n",
    "os.chdir('/home/code')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree shape constants\n",
    "TRUNK_W = 0.15\n",
    "TRUNK_H = 0.2\n",
    "BASE_W = 0.7\n",
    "MID_W = 0.4\n",
    "TOP_W = 0.25\n",
    "TIP_Y = 0.8\n",
    "TIER_1_Y = 0.5\n",
    "TIER_2_Y = 0.25\n",
    "BASE_Y = 0.0\n",
    "TRUNK_BOTTOM_Y = -TRUNK_H\n",
    "\n",
    "MAX_OVERLAP_DIST = 1.8\n",
    "MAX_OVERLAP_DIST_SQ = MAX_OVERLAP_DIST * MAX_OVERLAP_DIST\n",
    "\n",
    "@njit(cache=True)\n",
    "def rotate_point(x, y, cos_a, sin_a):\n",
    "    return x * cos_a - y * sin_a, x * sin_a + y * cos_a\n",
    "\n",
    "@njit(cache=True)\n",
    "def get_tree_vertices(cx, cy, angle_deg):\n",
    "    angle_rad = angle_deg * math.pi / 180.0\n",
    "    cos_a = math.cos(angle_rad)\n",
    "    sin_a = math.sin(angle_rad)\n",
    "    vertices = np.empty((15, 2), dtype=np.float64)\n",
    "    pts = np.array([\n",
    "        [0.0, TIP_Y], [TOP_W / 2.0, TIER_1_Y], [TOP_W / 4.0, TIER_1_Y],\n",
    "        [MID_W / 2.0, TIER_2_Y], [MID_W / 4.0, TIER_2_Y], [BASE_W / 2.0, BASE_Y],\n",
    "        [TRUNK_W / 2.0, BASE_Y], [TRUNK_W / 2.0, TRUNK_BOTTOM_Y],\n",
    "        [-TRUNK_W / 2.0, TRUNK_BOTTOM_Y], [-TRUNK_W / 2.0, BASE_Y],\n",
    "        [-BASE_W / 2.0, BASE_Y], [-MID_W / 4.0, TIER_2_Y], [-MID_W / 2.0, TIER_2_Y],\n",
    "        [-TOP_W / 4.0, TIER_1_Y], [-TOP_W / 2.0, TIER_1_Y],\n",
    "    ], dtype=np.float64)\n",
    "    for i in range(15):\n",
    "        rx, ry = rotate_point(pts[i, 0], pts[i, 1], cos_a, sin_a)\n",
    "        vertices[i, 0] = rx + cx\n",
    "        vertices[i, 1] = ry + cy\n",
    "    return vertices\n",
    "\n",
    "@njit(cache=True)\n",
    "def point_in_polygon(px, py, vertices):\n",
    "    n = vertices.shape[0]\n",
    "    inside = False\n",
    "    j = n - 1\n",
    "    for i in range(n):\n",
    "        xi, yi = vertices[i, 0], vertices[i, 1]\n",
    "        xj, yj = vertices[j, 0], vertices[j, 1]\n",
    "        if ((yi > py) != (yj > py)) and (px < (xj - xi) * (py - yi) / (yj - yi) + xi):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "    return inside\n",
    "\n",
    "@njit(cache=True)\n",
    "def segments_intersect(p1x, p1y, p2x, p2y, p3x, p3y, p4x, p4y):\n",
    "    dax = p2x - p1x; day = p2y - p1y\n",
    "    dbx = p4x - p3x; dby = p4y - p3y\n",
    "    d1x = p1x - p3x; d1y = p1y - p3y\n",
    "    d2x = p2x - p3x; d2y = p2y - p3y\n",
    "    cross_b1 = dbx * d1y - dby * d1x\n",
    "    cross_b2 = dbx * d2y - dby * d2x\n",
    "    if cross_b1 * cross_b2 > 0: return False\n",
    "    d3x = p3x - p1x; d3y = p3y - p1y\n",
    "    d4x = p4x - p1x; d4y = p4y - p1y\n",
    "    cross_a1 = dax * d3y - day * d3x\n",
    "    cross_a2 = dax * d4y - day * d4x\n",
    "    if cross_a1 * cross_a2 > 0: return False\n",
    "    return True\n",
    "\n",
    "@njit(cache=True)\n",
    "def polygons_overlap(v1, v2):\n",
    "    n1 = v1.shape[0]; n2 = v2.shape[0]\n",
    "    for i in range(n1):\n",
    "        if point_in_polygon(v1[i, 0], v1[i, 1], v2): return True\n",
    "    for i in range(n2):\n",
    "        if point_in_polygon(v2[i, 0], v2[i, 1], v1): return True\n",
    "    for i in range(n1):\n",
    "        i2 = (i + 1) % n1\n",
    "        for j in range(n2):\n",
    "            j2 = (j + 1) % n2\n",
    "            if segments_intersect(v1[i, 0], v1[i, 1], v1[i2, 0], v1[i2, 1],\n",
    "                                  v2[j, 0], v2[j, 1], v2[j2, 0], v2[j2, 1]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@njit(cache=True)\n",
    "def check_any_overlap(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dx = xs[i] - xs[j]; dy = ys[i] - ys[j]\n",
    "            if dx * dx + dy * dy < MAX_OVERLAP_DIST_SQ:\n",
    "                v1 = get_tree_vertices(xs[i], ys[i], degs[i])\n",
    "                v2 = get_tree_vertices(xs[j], ys[j], degs[j])\n",
    "                if polygons_overlap(v1, v2): return True\n",
    "    return False\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_bounding_box(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    min_x = 1e9; min_y = 1e9; max_x = -1e9; max_y = -1e9\n",
    "    for i in range(n):\n",
    "        v = get_tree_vertices(xs[i], ys[i], degs[i])\n",
    "        for j in range(15):\n",
    "            if v[j, 0] < min_x: min_x = v[j, 0]\n",
    "            if v[j, 0] > max_x: max_x = v[j, 0]\n",
    "            if v[j, 1] < min_y: min_y = v[j, 1]\n",
    "            if v[j, 1] > max_y: max_y = v[j, 1]\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "@njit(cache=True)\n",
    "def calculate_score(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    side = calculate_bounding_box(xs, ys, degs)\n",
    "    return side * side / n\n",
    "\n",
    "print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b482bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "def load_submission(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        configs = {}\n",
    "        for n, g in df.groupby('N'):\n",
    "            xs = strip(g['x'].to_numpy())\n",
    "            ys = strip(g['y'].to_numpy())\n",
    "            ds = strip(g['deg'].to_numpy())\n",
    "            configs[n] = {'x': xs, 'y': ys, 'deg': ds}\n",
    "        return configs\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def score_submission(configs):\n",
    "    total = 0.0\n",
    "    for n in range(1, 201):\n",
    "        if n in configs:\n",
    "            c = configs[n]\n",
    "            total += calculate_score(c['x'], c['y'], c['deg'])\n",
    "    return total\n",
    "\n",
    "def check_overlaps(configs):\n",
    "    overlaps = []\n",
    "    for n in range(1, 201):\n",
    "        if n in configs:\n",
    "            c = configs[n]\n",
    "            if check_any_overlap(c['x'], c['y'], c['deg']):\n",
    "                overlaps.append(n)\n",
    "    return overlaps\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all CSV files in santa25-public\n",
    "csv_dir = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa25-public/'\n",
    "csv_files = glob.glob(csv_dir + '*.csv')\n",
    "\n",
    "results = []\n",
    "for fp in csv_files:\n",
    "    configs = load_submission(fp)\n",
    "    if configs is None:\n",
    "        continue\n",
    "    score = score_submission(configs)\n",
    "    overlaps = check_overlaps(configs)\n",
    "    results.append({\n",
    "        'file': os.path.basename(fp),\n",
    "        'score': score,\n",
    "        'n_overlaps': len(overlaps),\n",
    "        'overlaps': overlaps[:5] if len(overlaps) > 5 else overlaps\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('score')\n",
    "print('\\nSanta25-public CSV files:')\n",
    "print(results_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the best valid (no overlaps) submission\n",
    "valid_results = [r for r in results if r['n_overlaps'] == 0]\n",
    "if valid_results:\n",
    "    best_valid = min(valid_results, key=lambda x: x['score'])\n",
    "    print(f\"\\nBest VALID submission: {best_valid['file']} with score {best_valid['score']:.6f}\")\n",
    "else:\n",
    "    print('\\nNo valid submissions found (all have overlaps)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cde93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check telegram-public\n",
    "csv_dir2 = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/telegram-public/'\n",
    "csv_files2 = glob.glob(csv_dir2 + '*.csv')\n",
    "\n",
    "results2 = []\n",
    "for fp in csv_files2:\n",
    "    configs = load_submission(fp)\n",
    "    if configs is None:\n",
    "        continue\n",
    "    score = score_submission(configs)\n",
    "    overlaps = check_overlaps(configs)\n",
    "    results2.append({\n",
    "        'file': os.path.basename(fp),\n",
    "        'score': score,\n",
    "        'n_overlaps': len(overlaps),\n",
    "        'overlaps': overlaps[:5] if len(overlaps) > 5 else overlaps\n",
    "    })\n",
    "\n",
    "results2_df = pd.DataFrame(results2).sort_values('score')\n",
    "print('\\nTelegram-public CSV files:')\n",
    "print(results2_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline and check per-N scores\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa-2025-csv/santa-2025.csv'\n",
    "baseline = load_submission(baseline_path)\n",
    "baseline_score = score_submission(baseline)\n",
    "print(f'Baseline score: {baseline_score:.6f}')\n",
    "\n",
    "# Per-N scores for baseline\n",
    "baseline_per_n = {}\n",
    "for n in range(1, 201):\n",
    "    c = baseline[n]\n",
    "    baseline_per_n[n] = calculate_score(c['x'], c['y'], c['deg'])\n",
    "\n",
    "print('\\nBaseline per-N scores (first 20):')\n",
    "for n in range(1, 21):\n",
    "    print(f'N={n}: {baseline_per_n[n]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eeb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values contribute most to the score\n",
    "print('\\nScore contribution by N range:')\n",
    "ranges = [(1, 10), (11, 30), (31, 50), (51, 100), (101, 150), (151, 200)]\n",
    "for start, end in ranges:\n",
    "    contrib = sum(baseline_per_n[n] for n in range(start, end+1))\n",
    "    print(f'N={start}-{end}: {contrib:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any external CSV has better per-N scores than baseline\n",
    "print('\\nSearching for better per-N configurations...')\n",
    "\n",
    "# Collect all valid configs from all sources\n",
    "all_sources = []\n",
    "for fp in csv_files + csv_files2:\n",
    "    configs = load_submission(fp)\n",
    "    if configs is None:\n",
    "        continue\n",
    "    all_sources.append((os.path.basename(fp), configs))\n",
    "\n",
    "print(f'Loaded {len(all_sources)} sources')\n",
    "\n",
    "# For each N, find the best valid config\n",
    "better_configs = {}\n",
    "for n in range(1, 201):\n",
    "    best_score = baseline_per_n[n]\n",
    "    best_source = 'baseline'\n",
    "    \n",
    "    for source_name, configs in all_sources:\n",
    "        if n not in configs:\n",
    "            continue\n",
    "        c = configs[n]\n",
    "        # Check for overlaps\n",
    "        if check_any_overlap(c['x'], c['y'], c['deg']):\n",
    "            continue\n",
    "        score = calculate_score(c['x'], c['y'], c['deg'])\n",
    "        if score < best_score - 1e-9:\n",
    "            best_score = score\n",
    "            best_source = source_name\n",
    "    \n",
    "    if best_source != 'baseline':\n",
    "        improvement = baseline_per_n[n] - best_score\n",
    "        better_configs[n] = {'source': best_source, 'score': best_score, 'improvement': improvement}\n",
    "\n",
    "print(f'\\nFound {len(better_configs)} N values with better configs than baseline:')\n",
    "for n, info in sorted(better_configs.items()):\n",
    "    print(f'N={n}: {baseline_per_n[n]:.6f} -> {info[\"score\"]:.6f} (improvement: {info[\"improvement\"]:.6f}) from {info[\"source\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The baseline is already the best valid configuration for ALL N values\n",
    "# The only way to improve is to find configurations that:\n",
    "# 1. Are valid (no overlaps)\n",
    "# 2. Have smaller bounding boxes than baseline\n",
    "\n",
    "# Let's check the theoretical minimum for small N values\n",
    "print('\\nTheoretical analysis for small N:')\n",
    "print('N=1: Single tree, minimum bbox = 1.0 (tree height), score = 1.0')\n",
    "print('N=2: Two trees, need to pack efficiently')\n",
    "print('N=3: Three trees, need to pack efficiently')\n",
    "\n",
    "# Check actual baseline scores for small N\n",
    "for n in range(1, 11):\n",
    "    c = baseline[n]\n",
    "    side = calculate_bounding_box(c['x'], c['y'], c['deg'])\n",
    "    print(f'N={n}: side={side:.6f}, score={baseline_per_n[n]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL INSIGHT: The evaluator pointed out that the jiweiliu implementation was severely simplified.\n",
    "# Key missing features:\n",
    "# 1. Multiprocessing - jiweiliu runs SA in parallel across all grid configurations\n",
    "# 2. Deletion cascade - propagates improvements from larger N to smaller N\n",
    "# 3. Initial seeds - pre-computed good starting points\n",
    "# 4. sa_optimize_improved - more sophisticated move types\n",
    "\n",
    "# The baseline (70.734) is ALREADY BETTER than what jiweiliu can produce (71.5)\n",
    "# So SA-with-translations is NOT the right approach for improving our baseline.\n",
    "\n",
    "# The evaluator recommends:\n",
    "# Option A: Run C++ optimizer with proper parameters (150,000+ iterations, 32+ restarts, multiple generations)\n",
    "# Option B: Ensemble approach - collect best N-config from multiple sources\n",
    "# Option C: Fix the SA-with-translations implementation (but this may not help since baseline is already better)\n",
    "\n",
    "print('\\n=== STRATEGIC ANALYSIS ===')\n",
    "print('1. Baseline score: 70.734327')\n",
    "print('2. Target score: 68.931058')\n",
    "print('3. Gap: 1.803269 (2.5%)')\n",
    "print('4. All 7 experiments achieved EXACTLY the same score')\n",
    "print('5. The baseline is at a very strong local optimum')\n",
    "print('')\n",
    "print('Key insight from evaluator:')\n",
    "print('- The jiweiliu kernel improves from 71.657 -> 71.5')\n",
    "print('- Our baseline is 70.734, which is ALREADY BETTER')\n",
    "print('- SA-with-translations cannot improve an already-optimized baseline')\n",
    "print('')\n",
    "print('Recommended approach:')\n",
    "print('- Run C++ optimizer with MUCH higher parameters')\n",
    "print('- 150,000+ iterations (vs 20,000 used before)')\n",
    "print('- 32+ restarts (vs 10 used before)')\n",
    "print('- Multiple generations (keep running until no improvement)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e75321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check what the seshurajup kernel does differently\n",
    "# From the kernel analysis:\n",
    "# 1. Uses 50,000 iterations, 8 restarts\n",
    "# 2. Runs MULTIPLE GENERATIONS until no improvement for 10 generations\n",
    "# 3. Uses OpenMP parallelization\n",
    "# 4. Ensembles from multiple sources\n",
    "\n",
    "# The key difference is MULTIPLE GENERATIONS\n",
    "# Each generation runs SA on all N values, then saves the best\n",
    "# This allows improvements to compound over time\n",
    "\n",
    "print('\\n=== SESHURAJUP KERNEL ANALYSIS ===')\n",
    "print('Key features:')\n",
    "print('1. Ensemble from multiple sources (santa-2025-ensemble-sa-greedy-backtracking, santa-claude)')\n",
    "print('2. C++ optimizer with 50,000 iterations, 8 restarts')\n",
    "print('3. MULTIPLE GENERATIONS - keeps running until no improvement for 10 generations')\n",
    "print('4. OpenMP parallelization for speed')\n",
    "print('')\n",
    "print('This is the key insight: MULTIPLE GENERATIONS')\n",
    "print('Our experiments ran single-pass optimization')\n",
    "print('The seshurajup kernel runs ENDLESS optimization until convergence')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
