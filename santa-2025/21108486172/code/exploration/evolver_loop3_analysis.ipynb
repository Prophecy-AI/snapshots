{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcd024c",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: Understanding the Gap\n",
    "\n",
    "## Key Findings So Far\n",
    "1. Baseline (santa-2025.csv) scores 70.734327 - no overlaps\n",
    "2. Ensemble from cpp_parallel_sa scores 67.77 but has overlaps in 30 N values\n",
    "3. Target is 68.931058 - need to improve by 1.8 points\n",
    "4. SA with collision constraints from baseline shows NO improvement\n",
    "5. The baseline is already at a local optimum\n",
    "\n",
    "## New Strategy: Use External Datasets\n",
    "The jonathanchan kernel shows that top solutions ensemble from MANY sources:\n",
    "- bucket-of-chump dataset\n",
    "- santa25-public dataset\n",
    "- telegram-public dataset\n",
    "- Multiple kernel outputs\n",
    "\n",
    "Let's analyze what's available and build a proper ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numba import njit\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree polygon template\n",
    "@njit\n",
    "def make_polygon_template():\n",
    "    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n",
    "    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n",
    "    x=np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2],np.float64)\n",
    "    y=np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1],np.float64)\n",
    "    return x,y\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r); s = math.sin(r)\n",
    "        xi = xs[i]; yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xi\n",
    "            Y = s * tx[j] + c * ty[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "tx, ty = make_polygon_template()\n",
    "print('Template loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap detection functions\n",
    "def get_shapely_polygon(cx, cy, deg, tx, ty):\n",
    "    r = deg * np.pi / 180.0\n",
    "    c = np.cos(r)\n",
    "    s = np.sin(r)\n",
    "    px = c * tx - s * ty + cx\n",
    "    py = s * tx + c * ty + cy\n",
    "    return Polygon(zip(px, py))\n",
    "\n",
    "def has_overlap(xs, ys, degs, tx, ty):\n",
    "    n = len(xs)\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    polygons = [get_shapely_polygon(xs[i], ys[i], degs[i], tx, ty) for i in range(n)]\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        indices = tree_index.query(poly)\n",
    "        for idx in indices:\n",
    "            if idx == i:\n",
    "                continue\n",
    "            if poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "print('Overlap detection loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcad2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files in external datasets\n",
    "dataset_dirs = [\n",
    "    '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/bucket-of-chump',\n",
    "    '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa25-public',\n",
    "    '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa-2025-csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/telegram-public',\n",
    "    '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa-2025-try3',\n",
    "]\n",
    "\n",
    "all_csv_files = []\n",
    "for d in dataset_dirs:\n",
    "    if os.path.exists(d):\n",
    "        files = glob.glob(os.path.join(d, '*.csv'))\n",
    "        all_csv_files.extend(files)\n",
    "        print(f'{d}: {len(files)} CSV files')\n",
    "\n",
    "print(f'\\nTotal CSV files found: {len(all_csv_files)}')\n",
    "for f in all_csv_files:\n",
    "    print(f'  {os.path.basename(f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each CSV file - score and overlap status\n",
    "file_analysis = []\n",
    "\n",
    "for fp in tqdm(all_csv_files, desc='Analyzing'):\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {fp}: {e}')\n",
    "        continue\n",
    "    \n",
    "    if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "        print(f'Missing columns in {fp}')\n",
    "        continue\n",
    "    \n",
    "    # Check if values have 's' prefix\n",
    "    sample_x = str(df['x'].iloc[0])\n",
    "    if not sample_x.startswith('s'):\n",
    "        print(f'No s prefix in {fp}')\n",
    "        continue\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    \n",
    "    total_score = 0.0\n",
    "    n_with_overlaps = 0\n",
    "    \n",
    "    for n, g in df.groupby('N'):\n",
    "        if n < 1 or n > 200:\n",
    "            continue\n",
    "        \n",
    "        xs = strip(g['x'].to_numpy())\n",
    "        ys = strip(g['y'].to_numpy())\n",
    "        ds = strip(g['deg'].to_numpy())\n",
    "        \n",
    "        sc = score_group(xs, ys, ds, tx, ty)\n",
    "        total_score += sc\n",
    "        \n",
    "        if has_overlap(xs, ys, ds, tx, ty):\n",
    "            n_with_overlaps += 1\n",
    "    \n",
    "    file_analysis.append({\n",
    "        'file': os.path.basename(fp),\n",
    "        'path': fp,\n",
    "        'score': total_score,\n",
    "        'n_overlaps': n_with_overlaps,\n",
    "        'valid': n_with_overlaps == 0\n",
    "    })\n",
    "\n",
    "df_files = pd.DataFrame(file_analysis)\n",
    "df_files = df_files.sort_values('score')\n",
    "print('\\nFile analysis (sorted by score):')\n",
    "print(df_files.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the best VALID ensemble from all sources\n",
    "best = {n: {'score': 1e300, 'data': None, 'src': None} for n in range(1, 201)}\n",
    "\n",
    "for fp in tqdm(all_csv_files, desc='Building ensemble'):\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "    if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "        continue\n",
    "    \n",
    "    sample_x = str(df['x'].iloc[0])\n",
    "    if not sample_x.startswith('s'):\n",
    "        continue\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    \n",
    "    for n, g in df.groupby('N'):\n",
    "        if n < 1 or n > 200:\n",
    "            continue\n",
    "        \n",
    "        xs = strip(g['x'].to_numpy())\n",
    "        ys = strip(g['y'].to_numpy())\n",
    "        ds = strip(g['deg'].to_numpy())\n",
    "        \n",
    "        # Check for overlaps - only keep valid configs\n",
    "        if has_overlap(xs, ys, ds, tx, ty):\n",
    "            continue\n",
    "        \n",
    "        sc = score_group(xs, ys, ds, tx, ty)\n",
    "        if sc < best[n]['score']:\n",
    "            best[n]['score'] = float(sc)\n",
    "            best[n]['data'] = g.drop(columns=['N']).copy()\n",
    "            best[n]['src'] = os.path.basename(fp)\n",
    "\n",
    "print('\\nBest valid ensemble built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21483254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble score and show improvements\n",
    "ensemble_score = sum(best[n]['score'] for n in range(1, 201))\n",
    "print(f'Ensemble score: {ensemble_score:.6f}')\n",
    "print(f'Baseline score: 70.734327')\n",
    "print(f'Target: 68.931058')\n",
    "print(f'Gap to target: {ensemble_score - 68.931058:.6f}')\n",
    "\n",
    "# Show source distribution\n",
    "source_counts = {}\n",
    "for n in range(1, 201):\n",
    "    src = best[n]['src']\n",
    "    if src:\n",
    "        source_counts[src] = source_counts.get(src, 0) + 1\n",
    "\n",
    "print('\\nSource distribution:')\n",
    "for src, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f'  {src}: {count} N values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with baseline for each N\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa-2025-csv/santa-2025.csv'\n",
    "df_baseline = pd.read_csv(baseline_path)\n",
    "df_baseline['N'] = df_baseline['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    g = df_baseline[df_baseline['N'] == n]\n",
    "    xs = strip(g['x'].to_numpy())\n",
    "    ys = strip(g['y'].to_numpy())\n",
    "    ds = strip(g['deg'].to_numpy())\n",
    "    baseline_score = score_group(xs, ys, ds, tx, ty)\n",
    "    \n",
    "    ensemble_n_score = best[n]['score']\n",
    "    improvement = baseline_score - ensemble_n_score\n",
    "    \n",
    "    if improvement > 0.0001:\n",
    "        improvements.append({\n",
    "            'n': n,\n",
    "            'baseline': baseline_score,\n",
    "            'ensemble': ensemble_n_score,\n",
    "            'improvement': improvement,\n",
    "            'source': best[n]['src']\n",
    "        })\n",
    "\n",
    "if improvements:\n",
    "    df_imp = pd.DataFrame(improvements)\n",
    "    print(f'\\nN values with improvement: {len(df_imp)}')\n",
    "    print(f'Total improvement: {df_imp[\"improvement\"].sum():.6f}')\n",
    "    print('\\nTop 20 improvements:')\n",
    "    print(df_imp.sort_values('improvement', ascending=False).head(20).to_string())\n",
    "else:\n",
    "    print('\\nNo improvements found over baseline!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8551b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ensemble submission\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    if best[n]['data'] is not None:\n",
    "        rows.append(best[n]['data'])\n",
    "\n",
    "if rows:\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    out['sn'] = out['id'].str.split('_').str[0].astype(int)\n",
    "    out['si'] = out['id'].str.split('_').str[1].astype(int)\n",
    "    out = out.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "    out = out[['id', 'x', 'y', 'deg']]\n",
    "    \n",
    "    out.to_csv('/home/code/experiments/003_proper_sa/ensemble_submission.csv', index=False)\n",
    "    print('Saved ensemble to /home/code/experiments/003_proper_sa/ensemble_submission.csv')\n",
    "    print(f'Ensemble score: {ensemble_score:.6f}')\n",
    "else:\n",
    "    print('No valid ensemble data!')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
