{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80be217",
   "metadata": {},
   "source": [
    "# Evolver Loop 5 Analysis\n",
    "\n",
    "## Situation Summary\n",
    "- 5 experiments completed, ALL at score 70.734327 (same as baseline)\n",
    "- Target: 68.931058 (need 1.8 points improvement, ~2.5%)\n",
    "- The ensemble with overlaps scores 67.77 but overlaps cannot be repaired\n",
    "- All local optimization approaches have failed\n",
    "\n",
    "## Key Questions\n",
    "1. What are the best public kernels achieving?\n",
    "2. What datasets/CSVs are available that we haven't tried?\n",
    "3. Is there a fundamentally different approach we're missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae177f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from numba import njit\n",
    "import math\n",
    "\n",
    "os.chdir('/home/code')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree polygon template\n",
    "@njit\n",
    "def make_polygon_template():\n",
    "    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n",
    "    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n",
    "    x=np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2],np.float64)\n",
    "    y=np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1],np.float64)\n",
    "    return x, y\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r)\n",
    "        s = math.sin(r)\n",
    "        xi = xs[i]\n",
    "        yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xi\n",
    "            Y = s * tx[j] + c * ty[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "tx, ty = make_polygon_template()\n",
    "print('Template created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b014e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and score a submission\n",
    "def strip(a):\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "def load_and_score(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        total = 0.0\n",
    "        for n, g in df.groupby('N'):\n",
    "            if n < 1 or n > 200:\n",
    "                continue\n",
    "            xs = strip(g['x'].to_numpy())\n",
    "            ys = strip(g['y'].to_numpy())\n",
    "            ds = strip(g['deg'].to_numpy())\n",
    "            total += score_group(xs, ys, ds, tx, ty)\n",
    "        return total\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ff6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all available CSV files in snapshots\n",
    "print('Searching for CSV files in snapshots...')\n",
    "\n",
    "all_csvs = []\n",
    "for root, dirs, files in os.walk('/home/nonroot/snapshots'):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            all_csvs.append(os.path.join(root, f))\n",
    "\n",
    "print(f'Found {len(all_csvs)} CSV files')\n",
    "\n",
    "# Score each file\n",
    "scores = []\n",
    "for fp in all_csvs:\n",
    "    score = load_and_score(fp)\n",
    "    if score is not None:\n",
    "        scores.append((score, fp))\n",
    "\n",
    "scores.sort()\n",
    "print(f'\\nTop 20 best scoring CSVs:')\n",
    "for score, fp in scores[:20]:\n",
    "    print(f'  {score:.6f}: {fp.split(\"/\")[-1]}')\n",
    "\n",
    "print(f'\\nBaseline: 70.734327')\n",
    "print(f'Target: 68.931058')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the jonathanchan kernel's approach\n",
    "# It uses ensemble + SA + fractional translation\n",
    "# Let's see what datasets it references\n",
    "\n",
    "print('Datasets referenced by jonathanchan kernel:')\n",
    "print('1. bucket-of-chump')\n",
    "print('2. santa25-public')\n",
    "print('3. telegram-public-shared-solution-for-santa-2025')\n",
    "print('4. santa-2025-try3')\n",
    "print('5. Various kernel outputs')\n",
    "\n",
    "# Check if we have these datasets\n",
    "print('\\nChecking available datasets...')\n",
    "for name in ['bucket-of-chump', 'santa25-public', 'telegram-public', 'santa-2025-try3']:\n",
    "    found = [f for f in all_csvs if name in f.lower()]\n",
    "    print(f'{name}: {len(found)} files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight from the jonathanchan kernel:\n",
    "# 1. It ensembles MANY sources (20+ different notebooks/datasets)\n",
    "# 2. It runs a C++ SA optimizer (sa_v1_parallel.cpp) with:\n",
    "#    - 15000 iterations\n",
    "#    - 5 restarts\n",
    "#    - Population-based search (keeps top 3)\n",
    "#    - Fractional translation post-processing\n",
    "#    - Backward propagation\n",
    "\n",
    "# The egortrushin kernel uses a different approach:\n",
    "# - SA with translations (structured packing)\n",
    "# - 2 base trees at different angles\n",
    "# - Translate in grid pattern to create N trees\n",
    "# - Works well for large N (>50)\n",
    "\n",
    "print('Key approaches from top kernels:')\n",
    "print('1. jonathanchan: Ensemble + C++ SA + fractional translation')\n",
    "print('2. egortrushin: SA with translations (structured packing)')\n",
    "print('3. saspav: bbox3 binary + fix_direction')\n",
    "print('4. smartmanoj: C++ tree_packer with OpenMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the baseline submission\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa-2025-csv/santa-2025.csv'\n",
    "baseline_score = load_and_score(baseline_path)\n",
    "print(f'Baseline score: {baseline_score:.6f}')\n",
    "\n",
    "# Check if there are any better valid submissions\n",
    "better_valid = [(s, f) for s, f in scores if s < baseline_score - 0.001]\n",
    "print(f'\\nCSVs with better score than baseline: {len(better_valid)}')\n",
    "for s, f in better_valid[:10]:\n",
    "    print(f'  {s:.6f}: {f.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem: ALL better-scoring CSVs have overlaps\n",
    "# The baseline is already at a local optimum\n",
    "\n",
    "# What we need to try:\n",
    "# 1. Run the jonathanchan C++ optimizer with MUCH higher parameters\n",
    "# 2. Try the egortrushin structured packing approach properly\n",
    "# 3. Look for external datasets that might have valid improvements\n",
    "\n",
    "# Let's check the C++ optimizer we have\n",
    "print('Checking C++ optimizer...')\n",
    "import subprocess\n",
    "result = subprocess.run(['ls', '-la', '/home/code/experiments/'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sa_v3_parallel is compiled and working\n",
    "sa_binary = '/home/code/experiments/sa_v3_parallel'\n",
    "if os.path.exists(sa_binary):\n",
    "    print('sa_v3_parallel binary exists')\n",
    "    # Check if it runs\n",
    "    result = subprocess.run([sa_binary, '-h'], capture_output=True, text=True)\n",
    "    print('Help output:', result.stdout[:500] if result.stdout else 'No output')\n",
    "    print('Error:', result.stderr[:500] if result.stderr else 'No error')\n",
    "else:\n",
    "    print('sa_v3_parallel binary not found - need to compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL INSIGHT:\n",
    "# The jonathanchan kernel runs the C++ optimizer in an ENDLESS LOOP\n",
    "# with generation-based optimization until no improvement for 3 generations\n",
    "# This is different from our single-pass approach!\n",
    "\n",
    "# Key parameters from jonathanchan:\n",
    "# - si = 20000 (iterations)\n",
    "# - nr = 80 (restarts)\n",
    "# - max_retries = 3 (generations without improvement before stopping)\n",
    "# - max_retry_retries = 3\n",
    "\n",
    "# Our approach has been:\n",
    "# - si = 15000 (iterations)\n",
    "# - nr = 5-6 (restarts)\n",
    "# - Single pass only\n",
    "\n",
    "print('CRITICAL DIFFERENCE:')\n",
    "print('jonathanchan: 20000 iterations, 80 restarts, multiple generations')\n",
    "print('Our approach: 15000 iterations, 5-6 restarts, single pass')\n",
    "print('')\n",
    "print('We need to run with MUCH higher parameters and multiple generations!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f990ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of what to try next:\n",
    "print('=== RECOMMENDED NEXT STEPS ===')\n",
    "print('')\n",
    "print('1. COMPILE AND RUN C++ OPTIMIZER WITH HIGH PARAMETERS:')\n",
    "print('   - Iterations: 30000-50000')\n",
    "print('   - Restarts: 32-80')\n",
    "print('   - Multiple generations (keep running until no improvement)')\n",
    "print('')\n",
    "print('2. TRY EGORTRUSHIN STRUCTURED PACKING:')\n",
    "print('   - For large N (>50), use grid-based translations')\n",
    "print('   - 2 base trees at different angles')\n",
    "print('   - SA to optimize translation parameters')\n",
    "print('')\n",
    "print('3. ENSEMBLE FROM MULTIPLE SOURCES:')\n",
    "print('   - Combine best per-N from all available CSVs')\n",
    "print('   - Run C++ optimizer on the ensemble')\n",
    "print('')\n",
    "print('4. FOCUS ON SPECIFIC N VALUES:')\n",
    "print('   - Identify N values with most room for improvement')\n",
    "print('   - Target optimization on those specific N values')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
