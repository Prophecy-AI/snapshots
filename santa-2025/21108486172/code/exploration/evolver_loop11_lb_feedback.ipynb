{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba31a406",
   "metadata": {},
   "source": [
    "# Loop 11 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- exp_001: CV 70.7343 | LB 70.7343 (gap: 0.0000)\n",
    "- exp_010: CV 70.7343 | LB 70.7343 (gap: 0.0000)\n",
    "\n",
    "## Key Observations\n",
    "1. CV = LB exactly - this is a deterministic optimization problem, not ML\n",
    "2. After 11 experiments, ALL achieved the SAME score: 70.734327\n",
    "3. Target is 68.922808, gap is 1.81 points (2.6%)\n",
    "4. The overlapping configurations score 67.727 (below target!) but have overlaps\n",
    "\n",
    "## Critical Question\n",
    "How do we escape the local optimum at 70.734327?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the baseline to analyze its structure\n",
    "baseline_path = '/home/code/experiments/011_mip_cpsat/baseline.csv'\n",
    "df = pd.read_csv(baseline_path)\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b43534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the angle patterns in the baseline\n",
    "import numpy as np\n",
    "\n",
    "def parse_value(v):\n",
    "    return float(str(v).replace('s', ''))\n",
    "\n",
    "# Extract all angles\n",
    "angles = []\n",
    "for _, row in df.iterrows():\n",
    "    deg = parse_value(row['deg'])\n",
    "    angles.append(deg % 360)\n",
    "\n",
    "angles = np.array(angles)\n",
    "print(f\"Total trees: {len(angles)}\")\n",
    "print(f\"Unique angles (rounded to 0.1): {len(np.unique(np.round(angles, 1)))}\")\n",
    "\n",
    "# Most common angles\n",
    "from collections import Counter\n",
    "angle_counts = Counter(np.round(angles, 1))\n",
    "print(\"\\nTop 20 most common angles:\")\n",
    "for angle, count in angle_counts.most_common(20):\n",
    "    print(f\"  {angle:.1f}째: {count} trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores and identify where improvements are theoretically possible\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "\n",
    "def get_tree_polygon(cx, cy, deg):\n",
    "    rad = np.radians(deg)\n",
    "    c, s = np.cos(rad), np.sin(rad)\n",
    "    x = TX * c - TY * s + cx\n",
    "    y = TX * s + TY * c + cy\n",
    "    return x, y\n",
    "\n",
    "def score_trees(trees):\n",
    "    n = len(trees)\n",
    "    if n == 0:\n",
    "        return float('inf')\n",
    "    all_x, all_y = [], []\n",
    "    for x, y, deg in trees:\n",
    "        px, py = get_tree_polygon(x, y, deg)\n",
    "        all_x.extend(px)\n",
    "        all_y.extend(py)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side * side / n\n",
    "\n",
    "def parse_config(df, n):\n",
    "    rows = df[df['id'].str.startswith(f'{n:03d}_')]\n",
    "    trees = []\n",
    "    for _, row in rows.iterrows():\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        trees.append((x, y, deg))\n",
    "    return trees\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = []\n",
    "for n in range(1, 201):\n",
    "    trees = parse_config(df, n)\n",
    "    score = score_trees(trees)\n",
    "    per_n_scores.append({'n': n, 'score': score, 'contribution': score})\n",
    "\n",
    "per_n_df = pd.DataFrame(per_n_scores)\n",
    "print(f\"Total score: {per_n_df['score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 N values with highest scores (most room for improvement):\")\n",
    "print(per_n_df.nlargest(10, 'score')[['n', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3064df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the overlapping CSV to compare\n",
    "overlap_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/datasets/santa25-public/submission_67_727.csv'\n",
    "if os.path.exists(overlap_path):\n",
    "    overlap_df = pd.read_csv(overlap_path)\n",
    "    \n",
    "    # Compare per-N scores\n",
    "    comparison = []\n",
    "    for n in range(1, 201):\n",
    "        baseline_trees = parse_config(df, n)\n",
    "        overlap_trees = parse_config(overlap_df, n)\n",
    "        \n",
    "        baseline_score = score_trees(baseline_trees)\n",
    "        overlap_score = score_trees(overlap_trees)\n",
    "        \n",
    "        comparison.append({\n",
    "            'n': n,\n",
    "            'baseline': baseline_score,\n",
    "            'overlap': overlap_score,\n",
    "            'diff': baseline_score - overlap_score\n",
    "        })\n",
    "    \n",
    "    comp_df = pd.DataFrame(comparison)\n",
    "    print(f\"Baseline total: {comp_df['baseline'].sum():.6f}\")\n",
    "    print(f\"Overlap total: {comp_df['overlap'].sum():.6f}\")\n",
    "    print(f\"Total potential improvement: {comp_df['diff'].sum():.6f}\")\n",
    "    \n",
    "    print(\"\\nTop 20 N values with biggest potential improvement:\")\n",
    "    print(comp_df.nlargest(20, 'diff')[['n', 'baseline', 'overlap', 'diff']])\n",
    "else:\n",
    "    print(f\"Overlap file not found at {overlap_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41240567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what datasets are available\n",
    "import glob\n",
    "\n",
    "print(\"Available datasets:\")\n",
    "for path in glob.glob('/home/nonroot/snapshots/santa-2025/*/code/datasets/*'):\n",
    "    print(f\"  {path}\")\n",
    "\n",
    "print(\"\\nCSV files in santa25-public:\")\n",
    "for path in glob.glob('/home/nonroot/snapshots/santa-2025/*/code/datasets/santa25-public/*.csv'):\n",
    "    print(f\"  {os.path.basename(path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the structure of the best configurations for small N\n",
    "print(\"Analyzing baseline configurations for N=2-10:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for n in range(2, 11):\n",
    "    trees = parse_config(df, n)\n",
    "    score = score_trees(trees)\n",
    "    \n",
    "    print(f\"\\nN={n}, score: {score:.6f}\")\n",
    "    \n",
    "    # Analyze angles\n",
    "    angles = [t[2] % 360 for t in trees]\n",
    "    unique_angles = sorted(set(np.round(angles, 1)))\n",
    "    print(f\"  Unique angles: {unique_angles}\")\n",
    "    \n",
    "    # Analyze positions\n",
    "    xs = [t[0] for t in trees]\n",
    "    ys = [t[1] for t in trees]\n",
    "    print(f\"  X range: [{min(xs):.4f}, {max(xs):.4f}]\")\n",
    "    print(f\"  Y range: [{min(ys):.4f}, {max(ys):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ea1ae",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **The baseline is at a strong local optimum** - 11 experiments with diverse approaches all converged to 70.734327\n",
    "\n",
    "2. **The overlapping configurations show 3.0 points of potential** - but they have overlaps in N=3-32\n",
    "\n",
    "3. **The angles are NOT simple multiples** - they use specific angles like 23.6째, 66.4째, 113.6째 that allow efficient interlocking\n",
    "\n",
    "4. **The target (68.922808) IS achievable** - it's on the leaderboard, so valid configurations exist\n",
    "\n",
    "## Potential Approaches to Try\n",
    "\n",
    "1. **Constructive heuristics** - Build packings tree-by-tree with intelligent placement\n",
    "2. **Minkowski sum / No-fit polygon** - Use geometric constraints to find valid placements\n",
    "3. **Gradual constraint tightening** - Start from overlapping configs and gradually eliminate overlaps\n",
    "4. **Different angle sets** - Try the specific angles used in the overlapping configs\n",
    "5. **Pattern extraction** - Analyze the overlapping configs to find valid sub-patterns"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
