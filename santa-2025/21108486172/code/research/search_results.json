{
  "query": "What is the Minkowski sum approach for 2D polygon packing optimization and how does it help find valid non-overlapping configurations?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The Minkowski\u2011sum approach turns the geometric non\u2011overlap condition between two 2\u2011D polygons into a simple point\u2011in\u2011set test.  For two polygons\u202f\\(P\\) and\u202f\\(Q\\) the **Minkowski sum** is defined as  \n\n\\[\nP\\oplus Q=\\{p+q\\;|\\;p\\in P,\\;q\\in Q\\},\n\\]\n\nand the **Minkowski difference** (or sum with a reflected polygon) is \\(P\\ominus Q = P\\oplus (-Q)\\)\u202f([cs.jhu.edu](https://www.cs.jhu.edu/~misha/Spring20/Wein06.pdf)).  If we reflect\u202f\\(Q\\) about the origin and add it to\u202f\\(P\\), the resulting set is exactly the **no\u2011fit polygon (NFP)**: every vector\u202f\\(t\\) that places the reference point of\u202f\\(Q\\) at\u202f\\(t\\) while keeping the two shapes disjoint lies outside the NFP, whereas vectors inside the NFP correspond to overlapping configurations\u202f([ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S0305054806000669);\u202f[PDF](https://eprints.soton.ac.uk/36850/1/CORMSIS-05-05.pdf)).  Computing the NFP therefore provides a complete map of all admissible relative positions and orientations; an optimizer can simply sample translation vectors and test whether they fall in the complement of the NFP, turning a complex polygon\u2011intersection problem into a cheap containment query.\n\nIn practice the approach is used in constructive packing algorithms: a new polygon is placed by first generating its NFP with each already\u2011placed polygon (often with the CGAL 2D Minkowski\u2011sum package\u202f([CGAL manual](https://doc.cgal.org/latest/Minkowski_sum_2/index.html))) and then selecting a feasible point in the free space defined by the union of those NFPs\u202f([Wiley article](https://onlinelibrary.wiley.com/doi/full/10.1002/nme.7318)).  Because the NFP can be built efficiently for convex and even non\u2011convex shapes (via convolution methods), the Minkowski\u2011sum technique enables fast detection of valid, non\u2011overlapping configurations and thus drives high\u2011quality, dense packings in 2\u2011D polygon packing optimisation.",
      "url": ""
    },
    {
      "title": "A Minkowski difference\u2010based advancing front packing technique ...",
      "text": "<div><section>\n <section>\n \n <h2>1 INTRODUCTION</h2>\n \n <p>Particle-based numerical methods, such as the discrete element method (DEM),<span><sup><a href=\"#nme7318-bib-0001\">1</a>-<a href=\"#nme7318-bib-0004\">4</a></sup></span> discontinuous deformation analysis (DDA)<span><sup><a href=\"#nme7318-bib-0005\">5</a>-<a href=\"#nme7318-bib-0007\">7</a></sup></span> and non-smooth contact dynamics (NSCD) method,<span><sup><a href=\"#nme7318-bib-0008\">8</a>-<a href=\"#nme7318-bib-0010\">10</a></sup></span> have been widely used to simulate complex particulate systems from atomic to crustal scale. The first and also an important step for such a simulation is to efficiently generate a high quality particle assemblage that satisfies some pre-requisites in terms of size, shape and volume fraction (or density).</p>\n \n <p>In general, three different types of methods have been developed: the dynamical approach,<span><sup><a href=\"#nme7318-bib-0011\">11</a>-<a href=\"#nme7318-bib-0013\">13</a></sup></span> the constructive approach,<span><sup><a href=\"#nme7318-bib-0014\">14</a>-<a href=\"#nme7318-bib-0020\">20</a></sup></span> and the coupled constructive-dynamic approach.<span><sup><a href=\"#nme7318-bib-0021\">21</a>-<a href=\"#nme7318-bib-0023\">23</a></sup></span></p>\n \n <p>In the dynamical approach, particles are first generated in a domain and then their positions and/or sizes are dynamically changed under the applied compression/gravity force within the standard DEM framework. However, a large number of numerical steps are often required to obtain a satisfactory packing density, making this approach very time consuming. Additionally, there is a certain amount of overlap between particles due to external/internal forces during packing, resulting in a physically unrealistic pre-stress within the particle assembly.</p>\n \n <p>In the constructive approach for generating particle packings, particles are added sequentially to the domain in accordance with certain geometric rules that are based on the existing particles already generated. This method ensures that there is no overlap between particles. The constructive approach is very efficient, typically several orders of magnitude faster than the dynamical approach. This is because the position of a particle is determined by only a few known geometric constraints. In the coupled constructive-dynamical approach, the packing initially generated by the constructive approach can be further densified by dynamic techniques to achieve a higher density. The efficiency of this coupled approach lies between that of the dynamic approach and that of the constructive approach.</p>\n \n <p>Due to the high efficiency, several constructive techniques have been developed in the last two decades: regular arrangements, sequential inhibition, sedimentation techniques, mesh-based approach and advancing front approach.<span><sup><a href=\"#nme7318-bib-0024\">24</a></sup></span> Among them, the advancing front approach (AFA), which is originally proposed in the seminal work by Feng et al.<span><sup><a href=\"#nme7318-bib-0016\">16</a></sup></span> to pack discs in 2D domains, is very efficient with a linear complexity. For example, on a PC with a single 1\u2009GHz processor, it takes only 3.77\u2009s to pack 1 million discs. Another important advantage of AFA is that the particle size distribution can be user defined, which is very versatile.</p>\n \n <p>There are two versions of the AFA: the closed form and the open form. In the closed form, the initial front is formed first by placing three touching discs in the centre of the domain. Then discs are generated in contact with the other two previous discs in an outward direction. The final particle assembly is obtained by deleting those discs generated outside the external boundary (EB) of the domain. Thus, in the closed form, there may be some gaps between the assembly and the boundaries. To overcome this problem, the open form is developed to include the EB in the generation of the discs. However, the gaps at the top of the domains are not addressed. Alternatively, Bagi<span><sup><a href=\"#nme7318-bib-0014\">14</a></sup></span> built the initial front near the EB and then generated discs inwards. This is called the inward-AFA based on the closed form. However, the central region cannot be completely filled. To reduce the gap near the EB, Dong et al.<span><sup><a href=\"#nme7318-bib-0025\">25</a></sup></span> used the Newton-Raphson iteration method to re-determine the radius and position of the new disc near the EB, which can guarantee that the disc is tangent to the boundary and the other two discs simultaneously. Recently, Xu and Xia<span><sup><a href=\"#nme7318-bib-0026\">26</a></sup></span> have extended the method to the open form to eliminate the gaps at the upper boundary. Overviews of AFA can be found in L\u00f6hner and O\u00f1ate<span><sup><a href=\"#nme7318-bib-0018\">18</a></sup></span> and Morfa et al.<span><sup><a href=\"#nme7318-bib-0027\">27</a></sup></span></p>\n \n <p>Due to the simple geometric description of circular particles, it has been widely used in particle-based numerical modelling. However, particle shape has some profound effects on the macro- and micromechanical behaviour of granular materials,<span><sup><a href=\"#nme7318-bib-0028\">28</a>, <a href=\"#nme7318-bib-0029\">29</a></sup></span> and particles are non-circular in reality. Therefore, how to efficiently generate convex non-circular particle assemblies has been a forefront topic in recent years. While the packing of convex non-circular particles has received considerable attention, the ellipse, being the simplest such particle, has been the focus of much research. However, non-elliptical particle packing remains challenging due to the complex geometry involved, making it difficult to achieve efficient handling. Extending previous packing approaches from circular to non-circular particles is not straightforward. Many existing approaches are based on either the dynamic approach or the coupled constructive-dynamic approach.</p>\n \n <p>As mentioned above, these approaches are very time consuming. Therefore, some researchers have mainly used the constructive approach to generate non-circular particles. For example, Feng et al.<span><sup><a href=\"#nme7318-bib-0030\">30</a></sup></span> extended their closed-form AFA to generate convex polygons and ellipses based on Minkowski Sum. Subsequently, the AFA has been modified and extended to generate convex polygons.<span><sup><a href=\"#nme7318-bib-0027\">27</a>, <a href=\"#nme7318-bib-0031\">31</a></sup></span> However, there are three shortcomings: (1) relatively large gaps can be generated near EB, which reduces the quality of particle assemblies; (2) both interior boundary (IB) and EB cannot be well considered; and (3) <i>the one-sided lifting problem</i> during packing (as will be detailed in Section\u00a0<a href=\"#nme7318-sec-0022\">4.1</a>) using the open form is not reported.</p>\n \n <p>In this work, a Minkowski difference-based advancing front approach is developed to overcome the aforementioned shortcomings of AFA in generating convex non-circular particle packings. Furthermore, careful consideration is given to IB/EB to solve the gap problem between particles and domain boundaries. The fundamentals of the Minkowski difference and its application are described in detail in Section\u00a0<a href=\"#nme7318-sec-0002\">2</a>. Then, the closed form and the open form are proposed in Sections\u00a0<a href=\"#nme7318-sec-0008\">3</a> and <a href=\"#nme7318-sec-0021\">4</a>, respectively. In particular, Section\u00a0<a href=\"#nme7318-sec-0021\">4</a> highlights the one-sided lifting problem during packing using the open form, and the corresponding treatment is proposed. Section\u00a0<a href=\"#nme7318-sec-0025\">5</a> presents several examples to illustrate the performance and effectiveness of the proposed approach. Finally, conclusions are drawn in Section\u00a0<a href=\"#nme7318-sec-0026\">6</a>.</p>\n \n <p>It is worth noting that a convex polygon with a certain n...",
      "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/nme.7318"
    },
    {
      "title": "[PDF] Exact and Efficient Construction of Planar Minkowski Sums using the ...",
      "text": "ACS\nAlgorithms for Complex Shapes\nwith Certified Numerics and Topology\nExact and Efficient Construction of Planar\nMinkowski Sums using the Convolution Method\nRon Wein\nACS Technical Report No.: ACS-TR-241300-04\nPart of deliverable: WP-I/D3\nSite: TAU\nMonth: 24\nProject co-funded by the European Commission within FP6 (2002\u20132006)\nunder contract nr. IST-006413\nAbstract\nThe Minkowski sum of two sets A, B \u2208 R\nd\n, denoted A \u2295 B, is defined\nas {a + b | a \u2208 A, b \u2208 B}. We describe an efficient and robust implemen\u0002tation for the construction of Minkowski sums of polygons in R2 using the\nconvolution of the polygon boundaries. This method allows for faster com\u0002putation of the sum of non-convex polygons in comparison to the widely\u0002used methods for Minkowski-sum computation that decompose the input\npolygons into convex sub-polygons and compute the union of the pairwise\nsums of these convex sub-polygons.\n1 Introduction\nGiven two sets A,B \u2208 R\nd\n, their Minkowski sum, denoted by A \u2295 B, is the set\n{a + b | a \u2208 A,b \u2208 B}. Minkowski sums are used in many applications, such as\nmotion planning and computer-aided design and manufacturing. In this paper\nwe focus on an important sub-class of the planar Minkowski-sum computation\nproblem: computing the sum of two simple polygons.\nIf P and Q are simple planar polygons having m and n vertices respectively,\nthen P \u2295 Q is a subset of the arrangement of O(mn) line segments, where each\nsegment is the Minkowski sum of an edge of P with a vertex of Q, or vice\u0002versa. The size of the sum is therefore bounded by O(m2n\n2\n), and this bound\nis tight [11]. However, if both P and Q are convex, then P \u2295 Q is a convex\npolygon with at most m + n vertices, and can be computed in O(m + n) time\n(see, e.g., [3, Chap. 13]). If only P is convex, the Minkowski sum of P and Q\nis bounded by O(mn) [12], and this bound is tight as well.\nAs we mentioned above, computing the Minkowski sum of two convex poly\u0002gons can be performed in linear time using a simple procedure that can be easily\nimplemented in software. The prevailing method for computing the sum of two\nnon-convex polygons P and Q, is therefore based on convex decomposition:\nwe decompose P into convex sub-polygons P1,... ,Pk and Q into convex sub\u0002polygons Q1,... ,Q`\n, obtain the Minkowski sum of each pair of sub-polygons\nand compute the union of the k` pairwise sub-sums. Namely, we calculate\nP \u2295Q =\nS\ni,j (Pi \u2295 Qj ). Flato [4] (see also [1]), implemented a software package\nfor computing Minkowski sums of planar polygons in an exact manner, based on\nthe decomposition method. He implemented about a dozen different polygon\u0002decomposition strategies and several methods for the union computation, and\nconducted thorough experiments to determine the optimal decomposition and\nunion strategies. Flato\u2019s code is robust and produces exact results. It is based\non Cgal Version 2.0,1 and uses exact rational arithmetic. This is the first\nimplementation capable of handling degenerate inputs, and the only one that\ncorrectly identifies low-dimensional elements of the Minkowski sum, such as an\u0002tennas or isolated vertices (see more details in Sec. 3.2). The Leda library [13]\nalso contains functions for robust Minkowski-sum computation based on con\u0002vex polygon decomposition that use exact rational arithmetic.2 However, these\n1See Cgal\u2019s homepage at http://www.cgal.org.\n2For more details and a detailed on-line documentation, see:\nhttp://www.algorithmic-solutions.info/leda guide/geo algs/minkowski.html.\n1\n[0]\n[0]\n[1]\n[2] [2]\n[2]\nFigure 1: Computing the convolution of a convex polygon and a non-convex\npolygon (left). The convolution consists of a single self-intersecting cycle, drawn\nas a sequence of arrows (right). The winding number associated with each\nface of the arrangement induced by the segments forming the cycle appears in\nbrackets. The Minkowski sum of the two polygons is shaded.\nfunctions are limited to performing regularized Minkowski-sum computations,\nwhich eliminate low-dimensional features of the output.\nAnother approach to computing the Minkowski sum of two polygons is cal\u0002culating the convolution of the boundaries of P and Q [7, 8]. Ramkumar [15]\nused this approach to devise an efficient algorithm for computing the outer\nboundary of the Minkowski sum of two polygons.3 To the best of our knowl\u0002edge, our code is the first implementation of software for robust and exact\ncomputation of Minkowski sums that is based on the convolution method. As\nour experiments show, using the convolution method we construct intermedi\u0002ate geometric entities that are more compact than the ones constructed using\nthe decomposition method. Consequently, we are able to obtain faster running\ntimes.\nThe rest of this paper is organized as follows: In Sec. 2 we review the\ndefinition of polygon convolution and develop the notation that will be used\nthroughout the paper. In Sec. 3 we give the details of our implementation of\nthe Minkowski-sum algorithm. We present experimental results in Sec. 4, and\ngive some concluding remarks in Sec. 5.\n2 Preliminaries\nGuibas et al. [7] introduced the concept of convolutions of general planar trac\u0002ings, giving a special attention to polygonal tracings, which are composed of a\nseries of interleaved moves (translations in a fixed direction) and turns (rota\u0002tions at a fixed location).\nGiven two polygons, P with vertices (p0,... ,pm\u22121) and Q with vertices\n(q0,... ,qn\u22121), we make a move by traversing a polygon edge \u2212\u2212\u2212\u2192 pipi+1, and make\na turn be rotating on a polygon vertex pifrom the direction of \u2212\u2212\u2212\u2192 pi\u22121pi to the of\ndirection \u2212\u2212\u2212\u2192 pipi+1.\n4 Without loss of generality, we can assume that both polygons\n3The complexity of this boundary is O(mn \u00b7 \u03b1(n)), where \u03b1(\u00b7) is the functional inverse of\nAckermann\u2019s function [9].\n4Throughout this paper, when we increment or decrement an index of a vertex, we do so\n2\nFigure 2: Computing the convolution of two non-convex octagons (left). The\nconvolution consists of two cycles (right), one (solid arrows) comprises 32 line\nsegments while the other (dashed arrows) contains 48 line segments, non of\nwhich lies on the boundary of the Minkowski sum (shaded).\nare counterclockwise oriented. The convolution of these two polygons, denoted\nP \u2217 Q, is a collection of line segments of the form\n\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 (pi + qj )(pi+1 + qj ), where\nthe vector \u2212\u2212\u2212\u2192 pipi+1 lies between \u2212\u2212\u2212\u2212\u2192 qj\u22121qj and \u2212\u2212\u2212\u2212\u2192 qjqj+1,\n5 and \u2014 symmetrically \u2014 of\nsegments of the form\n\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192\n(pi + qj )(pi + qj+1), where the vector \u2212\u2212\u2212\u2212\u2192 qjqj+1 lies between\n\u2212\u2212\u2212\u2192 pi\u22121pi and \u2212\u2212\u2212\u2192 pipi+1. We can label the convolution segment as h(i,i + 1),ji in the\nformer case or hi,(j,j + 1)i in the latter case. From the definition, it is clear\nthat P \u2217 Q contains at most O(mn) line segments.\nThe segments of the convolution form a number of closed (not necessarily\nsimple) polygonal curves called convolution cycles. The Minkowski sum P \u2295Q is\nthe set of points having a non-zero winding number with respect to these cycles\n(see, e.g., [14, Chap. 7] for the topological definition of the winding number and\nsome examples). See Fig. 1 for an illustration.\nIn case both input polygons P and Q are convex, their convolution is a\nconvex polygonal tracing. If only one polygon (say P) is convex, then P \u2217 Q\nstill contains a single cycle, which may not be simple (see [15] for a proof),\nas illustrated in Fig. 1. If both P and Q are non-convex, the convolution\nmay comprise several cycles, and in order to compute the Minkowski sum of\nthe polygons one has to consider the set of points having a non-zero winding\nnumber with respect to all cycles (see Fig. 2 for an illustration).\n3 Implementation Details\nGiven two simple polygons P and Q having m and n vertices, respectively, we\ncompute their Minkowski sum in three steps: first we compute the cycles of the\nconvolution P \u2217 Q, then we construct the planar arrangement induced by the\nmodulo the size of the polygon. Indeed, \u2212\u2212\u2212\u2212\u2212\u2192 pm\u22121p0 is also a valid polygon edge.\n5We say that a vector ~v lies between two vectors ...",
      "url": "https://www.cs.jhu.edu/~misha/Spring20/Wein06.pdf"
    },
    {
      "title": "A comprehensive and robust procedure for obtaining the nofit ...",
      "text": "Typesetting math: 100%\n\n[Skip to main content](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-title)\n\n- [Access through\u00a0**your organization**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0305054806000669)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S0305054806000669/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-abstract)\n- [Introduction](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-introduction)\n- [Section snippets](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-snippets)\n- [References (24)](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-references)\n- [Cited by (80)](https://www.sciencedirect.com/www.sciencedirect.com#preview-section-cited-by)\n\n## [Computers & Operations Research](https://www.sciencedirect.com/journal/computers-and-operations-research)\n\n[Volume 35, Issue 1](https://www.sciencedirect.com/journal/computers-and-operations-research/vol/35/issue/1), January 2008, Pages 267-281\n\n# A comprehensive and robust procedure for obtaining the nofit polygon using Minkowski sums\n\nAuthor links open overlay panel [Julia ABennell](https://www.sciencedirect.com/author/14627316400/julia-a-bennell), XiangSong\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.cor.2006.02.026](https://doi.org/10.1016/j.cor.2006.02.026) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S0305054806000669&orderBeanReset=true)\n\n## Abstract\n\nThe nofit polygon is a powerful and effective tool for handling the geometric requirements of solution approaches to irregular cutting and [packing problems](https://www.sciencedirect.com/topics/social-sciences/packing-problem). Although the concept was first described in 1966, it was not until the early 90s that the general trend of research moved away from direct trigonometry to favour the nofit polygon. Since then, the ability to calculate the nofit polygon has practically become a pre-requisite for researching irregular packing problems. However, realization of this concept in the form of a robust algorithm is a highly challenging task with few instructive approaches published. In this paper, a procedure using the [mathematical concept](https://www.sciencedirect.com/topics/earth-and-planetary-sciences/mathematical-concept) of Minkowski sums for the calculation of the nofit polygon is presented. The described procedure is more robust than other approaches using Minkowski sum knowledge and includes details of the removal of internal edges to find holes, slits and lock and key positions. The procedure is tested on benchmark data sets and gives examples of complicated cases.\n\n### Scope and purpose\n\nCutting and packing problems involving irregular shapes feature in a wide variety of manufacturing processes. Automated solution techniques that can generate packing arrangements more efficiently than current technology that employs user intervention, must be able to handle the complex geometry that arises from these problems. The nofit polygon has been demonstrated to be an effective tool in providing efficient handling of the geometric characteristics of these problems. The paper presents a new algorithmic procedure for deriving this tool.\n\n## Introduction\n\nCutting and packing problems involving irregular shapes are common in a variety of manufacturing processes. They occur whenever a piece of irregular shape is to be cut from a sheet of stock material. Examples include dye-cutting in the engineering sector, parts nesting for shipbuilding, marker layout in the garment industry, and leather cutting for shoes, furniture and other goods. The paper specifically addresses the geometric calculations required for tackling these problems. Here we consider that shapes are irregular if they are; polygonal, i.e no arcs; simple, i.e. non-self-intersecting; and non-rectangular. Even when all the components are rectangular the problem of finding layouts that minimize waste is known to be NP-hard. Where irregular components are involved an extra dimension of complexity is generated by the geometry.\n\nThe precise requirements of a good layout will differ from industry to industry and this has led to a variety of algorithmic approaches. In spite of their differences, all the methods have a common requirement in which they need to be able to identify whether a layout is feasible or not, i.e. do any of the pieces overlap. Early research handled this problem in a number of ways. Adamowicz and Albano \\[1\\] chose to nest pieces into simpler shapes where the geometry can be more easily calculated. If the shapes are used directly then the intersection of pieces can be handled by direct trigonometric approaches such as the D function \\[2\\], \\[3\\]. Alternatively the stock sheet and the pieces can be approximated as grid squares, often referred to as the raster method. Hence, if a piece occupies, fully or partially, a grid square it is coded as occupied \\[4\\], \\[5\\].\n\nAlthough all these approaches have merit, it is widely recognized that the nofit polygon (NFP) is more efficient, provided you have a robust and efficient NFP generator, and has become the principle approach for handling the geometry in nesting problems. Unfortunately, some researchers believe that despite the value of this tool, its introduction may have stifled research into this variant of packing problems. W\u00e4scher et al. \\[6\\] report that there have been only 21 publications in irregular problems in the last 10 years. Researchers attribute this to the fact that the realization of the NFP as a robust algorithm is, in itself, a highly challenging task. Those considering embarking on research into irregular shaped packing may be discouraged by the significant investment of time required in first developing an NFP generator. Hence, it is essential that robust and easily realizable algorithms are available in order to facilitate new interest into this important problem.\n\nThe primary purpose of this paper is to introduce a new procedure for calculating the NFP. The method is developed from the theory of Minkowski sums \\[7\\] and builds on the principles proposed by Ghosh \\[8\\], \\[9\\] and by Bennell et al. \\[10\\]. Further, the paper includes an algorithmic procedure for eliciting the true boundary of the NFP, including holes, slits and exact fits. It should be noted that the polygons considered in this paper are two-dimensional and restricted to translational motion i.e. rotations are not considered. The next section outlines the most commonly cited approaches for calculating the NFP and points out their positive features and disadvantages. Section 3 reviews in more detail the Minkowski sum approach. This is followed by a description of our new procedure based on Minkowski sums. Section 5, develops our approach for removing redundant internal points and therefore identifying the true boundary. In both cases the full algorithmic steps are provided. Finally, we develop some theoretical and empirical analysis of the approach to demonstrate its robustness with respect to being capable of handling all combinations of simple polygons.\n\n## Section snippets\n\n## Documented approaches for generating the nofit polygon\n\nThe NFP is a combination of the properties of two component polygons that, as a result, represents all the relative positions of the two polygons in which they either touch or overlap. It is well documented that the NFP can reduce the complexity of detecting overlap between two pieces from O(nm+n+m), where n and m are the number of edges in each polygon, obtained from direct trigonometry, to a simple point inclusion test of O(k), where k is the number of edges in the NFP. Full explanations of\n\n## Approache...",
      "url": "https://www.sciencedirect.com/science/article/abs/pii/S0305054806000669"
    },
    {
      "title": "2D Minkowski Sums: User Manual",
      "text": "- [cgal.org](https://www.cgal.org/)\n- [Top](https://doc.cgal.org/Manual/index.html)\n- [Getting Started](https://doc.cgal.org/Manual/general_intro.html)\n- [Tutorials](https://doc.cgal.org/Manual/tutorials.html)\n- [Package Overview](https://doc.cgal.org/Manual/packages.html)\n- [Acknowledging CGAL](https://doc.cgal.org/Manual/how_to_cite_cgal.html)\n\n|     |\n| --- |\n| CGAL 6.1 - 2D Minkowski Sums |\n\nLoading...\n\nSearching...\n\nNo Matches\n\nAuthorsRon Wein, Alon Baram, Efi Fogel, Eyal Flato, Michael Hemmer, and Sebastian Morr\n\n# Introduction\n\nGiven two sets \\\\( A,B \\\\in \\\\mathbb{R}^d\\\\), their _Minkowski sum_, denoted by \\\\( A \\\\oplus B\\\\), is their point-wise sum, namely the set \\\\( \\\\left\\\\{ a + b ~\\|~ a \\\\in A, b \\\\in B \\\\right\\\\}\\\\). Minkowski sums are used in many applications, such as motion planning and computer-aided design and manufacturing. This package contains functions that compute the planar Minkowski sums of two polygons. (Here, \\\\( A\\\\) and \\\\( B\\\\) are two closed polygons in \\\\( \\\\mathbb{R}^2\\\\), which may have holes; see Chapter [2D Regularized Boolean Set-Operations](https://doc.cgal.org/Boolean_set_operations_2/index.html#Chapter_2D_Regularized_Boolean_Set-Operations) for the precise definition of valid polygons), and the planar Minkowski sum of a simple polygon and a disc\u2014an operation also referred to as _offsetting_ or _dilating_ a polygon.The family of valid types of summands is slightly broader for certain operations, e.g., a degenerate polygon consisting of line segments is a valid operand for the approximate-offsetting operation. This package, like the [2D Regularized Boolean Set-Operations](https://doc.cgal.org/Boolean_set_operations_2/index.html#Chapter_2D_Regularized_Boolean_Set-Operations) package, is implemented on top of the arrangement infrastructure provided by the [2D Arrangements](https://doc.cgal.org/Arrangement_on_surface_2/index.html#chapterArrangement_on_surface_2) package. The two packages are integrated well to allow mixed operations. For example, it is possible to apply Boolean set operations on objects that are the result of Minkowski sum computations.The operands of the Minkowski sum operations supported by this package must be (linear) polygons, as opposed to the operands of the Boolean set operations supported by the [2D Regularized Boolean Set-Operations](https://doc.cgal.org/Boolean_set_operations_2/index.html#Chapter_2D_Regularized_Boolean_Set-Operations) package. The latter belong to the broader family of general polygons.\n\n# Computing the Minkowski Sum of Two Polygons\n\n[Figure 22.1](https://doc.cgal.org/index.html#fig__mink_figconvex)\n\nComputing the Minkowski sum of two convex polygons \\\\( P\\\\) and \\\\( Q\\\\) with \\\\( m\\\\) and \\\\( n\\\\) vertices, respectively, is rather easy. Observe that \\\\( P \\\\oplus Q\\\\) is a convex polygon bounded by copies of the \\\\( m + n\\\\) edges ordered according to the angle they form with the \\\\( x\\\\)-axis. As the two input polygons are convex, their edges are already sorted by the angle they form with the \\\\( x\\\\)-axis; see the figure above. The Minkowski sum can therefore be computed using an operation similar to the merge step of the merge-sort algorithmSee, for example, [https://en.wikipedia.org/wiki/Merge\\_sort](https://en.wikipedia.org/wiki/Merge_sort). in \\\\(O(m + n)\\\\) time, starting from the two bottommost vertices in \\\\( P\\\\) and in \\\\( Q\\\\) and merging the ordered list of edges.\n\n[Figure 22.2](https://doc.cgal.org/index.html#fig__mink_figonecyc) The convolution of a convex polygon and a non-convex polygon. The convolution consists of a single self-intersecting cycle, drawn as a sequence of directed line segments. Each face of the arrangement induced by the segments forming the cycle contains its winding number. The Minkowski sum of the two polygons is shaded. Dotted edges are not part of the reduced convolution.\n\nIf the polygons are not convex, you can utilize either the _Decomposition_ or the _Convolution_ approaches described below. Applications of some of the operations in this package are restricted to polygons that do not contain holes. (Resulting sums may contain holes though.)\n\n**Decomposition:**\n\nWe decompose \\\\( P\\\\) and \\\\( Q\\\\) into convex sub-polygons. Namely, we obtain two sets of convex polygons \\\\( P\\_1, \\\\ldots, P\\_k\\\\) and \\\\( Q\\_1, \\\\ldots, Q\\_\\\\ell\\\\), such that \\\\( \\\\bigcup\\_{i = 1}^{k}{P\\_i} = P\\\\) and \\\\( \\\\bigcup\\_{i = j}^{\\\\ell}{Q\\_j} = Q\\\\). We then calculate the pairwise sums \\\\( S\\_{ij} = P\\_i \\\\oplus Q\\_j\\\\) using the simple procedure described above, and finally compute the union \\\\( P \\\\oplus Q = \\\\bigcup\\_{ij}{S\\_{ij}}\\\\); see [Union Functions](https://doc.cgal.org/Boolean_set_operations_2/group__boolean__join.html#ref_bso_union).\n\nThis approach relies on a successful decomposition of the input polygons into convex pieces, and its performance depends on the quality and performance of the decomposition. Some of the supplied decomposition methods do not handle polygons that contain holes.\n\n**Convolution:**\n\nLet \\\\( P = \\\\left( p\\_0, \\\\ldots, p\\_{m-1} \\\\right)\\\\) and \\\\( Q = \\\\left(q\\_0, \\\\ldots, q\\_{n-1} \\\\right)\\\\) denote the vertices of the input polygons. We assume that both \\\\( P\\\\) and \\\\( Q\\\\) have positive orientations (i.e., their boundaries wind in a counterclockwise order around their interiors). The _convolution_ of these two polygons [\\[7\\]](https://doc.cgal.org/citelist.html#CITEREF_grs-kfcg-83), denoted \\\\( P \\* Q\\\\), is a collection of line segments of the form \\\\( \\[p\\_i + q\\_j, p\\_{i+1} + q\\_j\\]\\\\),Throughout this chapter, we increment or decrement an index of a vertex modulo the size of the polygon. where the vector \\\\( {\\\\mathbf{p\\_i p\\_{i+1}}}\\\\) lies between \\\\( {\\\\mathbf{q\\_{j-1} q\\_j}}\\\\) and \\\\( {\\\\mathbf{q\\_j q\\_{j+1}}}\\\\),We say that a vector \\\\( {\\\\mathbf v}\\\\) lies between two vectors \\\\( {\\\\mathbf u}\\\\) and \\\\( {\\\\mathbf w}\\\\) if we reach \\\\( {\\\\mathbf v}\\\\) strictly before reaching \\\\( {\\\\mathbf w}\\\\) if we move all three vectors to the origin and rotate \\\\( {\\\\mathbf u}\\\\) counterclockwise. Note that this also covers the case where \\\\( {\\\\mathbf u}\\\\) has the same direction as \\\\( {\\\\mathbf v}\\\\). and, symmetrically, of segments of the form \\\\( \\[p\\_i + q\\_j, p\\_i + q\\_{j+1}\\]\\\\), where the vector \\\\( {\\\\mathbf{q\\_j\nq\\_{j+1}}}\\\\) lies between \\\\( {\\\\mathbf{p\\_{i-1} p\\_i}}\\\\) and \\\\(\n{\\\\mathbf{p\\_i p\\_{i+1}}}\\\\).\n\nThe segments of the convolution form a number of closed (not necessarily simple) polygonal curves called _convolution cycles_. The Minkowski sum \\\\( P \\\\oplus Q\\\\) is the set of points having a non-zero winding number with respect to the cycles of \\\\( P \\* Q\\\\).Informally speaking, the winding number of a point \\\\( p \\\\in\\\\mathbb{R}^2\\\\) with respect to some planar curve \\\\( \\\\gamma\\\\) is an integer number counting how many times does \\\\( \\\\gamma\\\\) wind in a counterclockwise direction around \\\\( p\\\\). See [Figure 22.2](https://doc.cgal.org/index.html#fig__mink_figonecyc) for an illustration.\n\nWe construct the arrangement induced by the convolution cycles of \\\\(P \\\\) and \\\\(Q \\\\), then compute the winding numbers of the cells of the arrangement. Finally, we extract the Minkowski sum from the arrangement. This variant is referred to as the full-convolution method.\n\nA segment \\\\(\\[p\\_i + q\\_j, p\\_{i+1} + q\\_j\\] \\\\) (resp. \\\\(\\[p\\_i + q\\_j, p\\_i + q\\_{j+1}\\] \\\\)) cannot possibly contribute to the boundary of the Minkowski sum if \\\\(q\\_j \\\\) (resp. \\\\(p\\_i \\\\)) is a reflex vertex (see dotted edges in [Figure 22.2](https://doc.cgal.org/index.html#fig__mink_figonecyc)). The remaining subset of convolution segments is called the _reduced convolution_ [\\[3\\]](https://doc.cgal.org/citelist.html#CITEREF_cgal:bl-frmsurc-11). This subset is still a superset of the Minkowski sum boundary, but the winding number property does not apply any longer as there are no closed cycles anymore. We apply two different filters, which identify holes in the Minkowski sum:\n\n1. A loop that is on the Minkowski sum boundary has to be ...",
      "url": "https://doc.cgal.org/latest/Minkowski_sum_2/index.html"
    },
    {
      "title": "",
      "text": "1\nA comprehensive and robust procedure for obtaining the nofit polygon\nusing Minkowski sums\nJULIA A BENNELL\nSchool of Management, University of Southampton, Southampton SO17 1BJ, United\nKingdom, j.bennell@soton.ac.uk\nXIANG SONG\nSchool of Management, University of Southampton, Southampton SO17 1BJ, United\nKingdom, x.song@soton.ac.uk\nThe nofit polygon an important tool in the area of irregular shape stock cutting problems.\nIt provides efficient handling of the geometric characteristics of the problem. The paper\npresents a new algorithmic procedure for deriving this tool.\nSubmitted: June 2005\nSubject classification: cutting stock, geometric, algorithm\nArea of review: Optimisation\n2\nAbstract\nThe nofit polygon is a powerful and effective tool for handling the geometric\nrequirements of solution approaches to irregular cutting and packing problems. Although\nthe concept was first described in 1966, it was not until the early 90s that the general\ntrend of research moved away from direct trigonometry to favour the nofit polygon. Since\nthen, the ability to calculate the nofit polygon has practically become a pre-requisite for\nresearching irregular packing problems. However, realisation of this concept in the form\nof a robust algorithm is a highly challenging task with few instructive approaches\npublished. In this paper, a procedure using the mathematical concept of Minkowski sums\nfor the calculation of the nofit polygon is presented. The described procedure is more\nrobust than other approaches using Minkowski Sum knowledge and includes details of\nthe removal of internal edges to find holes, slits and lock and key positions. The\nprocedure is tested on benchmark data sets and gives examples of complicated cases. In\naddition the paper includes a description of how the procedure is modified in order to\nrealise the inner-fit polygon.\n3\n1. INTRODUCTION\nThe paper specifically addresses the geometric calculations required for tackling\ncutting and packing problems involving irregular shapes. Such problems are common in\nmanufacturing processes and occur whenever a piece of irregular shape is to be cut from\na sheet of stock material. Examples include dye-cutting in the engineering sector, parts\nnesting for shipbuilding, marker layout in the garment industry, and leather cutting for\nshoes, furniture and other goods. Here we consider that shapes are irregular if they are;\npolygonal, i.e no arcs; simple, i.e. do not self-cross; and non-rectangular. Even when all\nthe components are rectangular the problem of finding layouts that minimize waste is\nknown to be NP-hard. Where irregular components are involved an extra dimension of\ncomplexity is generated by the geometry.\nThe precise requirements of a good layout will differ from industry to industry and\nthis has lead to a variety of algorithmic approaches. In spite of their differences, all the\nmethods have a common requirement in which they need to be able to identify whether a\nlayout is feasible or not, i.e. do any of the pieces overlap. Early research handled this\nproblem in a number of ways. Adamowicz and Albano (1976) chose to nest pieces into\nsimpler shapes where the geometry can be more easily calculated. If the shapes are used\ndirectly then the intersection of pieces can be handled by direct trigonometric approaches\nsuch as the D function (Mehadavan, 1984; Konopasek, 1981). Alternatively the stock\nsheet and the pieces can be approximated as grid squares, often referred to as the raster\nmethod. Hence, if a piece occupies, fully or partially, a grid square it is coded as occupied\n(Oliveira and Ferreira, 1993; Babu and Babu, 2001).\n4\nAlthough all these approaches have merit, it is widely recognized that the nofit\npolygon (NFP) is more efficient, provided you have a robust and efficient NFP generator,\nand has become the principle approach for handling the geometry in nesting problems.\nUnfortunately, some researchers believe that despite the value of this tool, its introduction\nmay have stifled research into this variant of packing problems. W\u00e4scher, Hau\u00dfner and\nSchumann (2005) reports that there have been only 21 publications in irregular problems\nin the last 10 years. Researchers attribute this to the fact that the realization of the NFP as\na robust algorithm is, in itself, a highly challenging task. Those considering embarking on\nresearch into irregular shaped packing may be discouraged by the significant investment\nof time required in first developing an NFP generator. Hence, it is essential that robust\nand easily realizable algorithms are available in order to facilitate new interest into this\nimportant problem.\nThe primary purpose of this paper is to introduce a new procedure for calculating the\nNFP. The method is developed from the theory of Minkowski sums and builds on the\nprinciples proposed by Ghosh (1993) and by Bennell, Dowsland and Dowsland (2001).\nFurther, the paper includes an algorithmic procedure for eliciting the true boundary of the\nNFP, including holes, slits and exact fits. The next section outlines the most commonly\ncited approaches for calculating the NFP and points out their positive features and\ndisadvantages. Section 3 reviews in more detail the Minkowski sum approach. This is\nfollowed by a description of our new procedure based on Minkowski sums. Section 5,\ndevelops our approach for removing redundant internal points and therefore identifying\nthe true boundary. In both cases the full algorithmic steps are provided. Section 6 outlines\n5\nthe modification required in order to determine the inner-fit polygon. Finally, we develop\nsome theoretical and empirical analysis of the approach to demonstrate its robustness.\n2. DOCUMENTED APPROACHES FOR GENERATING THE NOFIT\nPOLYGON\nThe nofit polygon (NFP) is a combination of the properties of two component\npolygons that, as a result, represents all the relative positions of the two polygons in\nwhich they either touch or overlap. It is well documented that the NFP can reduce the\ncomplexity of detecting overlap between two pieces from O(nm+n+m), where n and m\nare the number of edges in each polygon, obtained from direct trigonometry, to a simple\npoint inclusion test of O(k), where k is the number of edges in the NFP. Full explanations\nof the concept can be found in (Mehadevan, 1984; Ghosh, 1991; Bennell, 1998; Bennell\nDowsland and Dowsland, 2001), where the most intuitive description is found in\nCunningham-Green (1989), who describes the motion of one polygon sliding around the\nboundary of the other; often referred to as the orbiting method. Figure 1a and 1b\nillustrates the motion of polygon B, the orbiting polygon, sliding around A, the fixed\npolygon, tracing the locus of a reference point on B. He also notes that when both\npolygons are convex, the NFP is an exact replication of the edges of both polygons, with\nopposite orientation, sorted into their slope order. Figure 1c shows the edges of both\npolygons, where A has counterclockwise orientation and B has clockwise orientation,\nsorted into slope order; these can be directly mapped onto the NFP in figure 1b. Note that\nthis role and orientation of polygons A and B will be adopted for the remainder of the\npaper. Cunningham-Green\u2019s (1989) observations underpin two of the most common\n6\napproaches to generating the NFP; the orbiting method that simulates the sliding motion,\nand Minkowski sums that sort the edges according to the the slope order and edge\nprecedence, i.e the sequential order of edges around the polygons. A further approach\ncommonly employed is that of decomposition. A brief description of each is provided\nhere.\nFigure 1: The locus of the reference point on B traces the NFP as it slides around A.\nThis is equivalent to connecting the edges in slope order.\nMinkowski sum\nClearly, when both component polygons are convex the NFP is very simple to\ncalculate by sorting the edges into slope order. Further, when one of the polygons is\n(b)\n(c)\n(a)\nB\nNFPAB\nA\n= Reference point on B\n7\nconvex and the other is an arbit...",
      "url": "https://eprints.soton.ac.uk/36850/1/CORMSIS-05-05.pdf"
    },
    {
      "title": "[PDF] A General Heuristic Approach for Maximum Polygon Packing - DROPS",
      "text": "A General Heuristic Approach for Maximum\nPolygon Packing\nCanhui Luo #\nHuazhong University of Science and Technology, Wuhan, China\nZhouxing Su1 #\nHuazhong University of Science and Technology, Wuhan, China\nZhipeng L\u00fc #\nHuazhong University of Science and Technology, Wuhan, China\nAbstract\nThis work proposes a general heuristic packing approach to address the Maximum Polygon Packing\nProblem introduced by the CG:SHOP 2024 Challenge. Our solver primarily consists of two steps:\n(1) Partitioning the container and polygons to form a series of small-scale subproblems; (2) For each\nsubproblem, sequentially placing polygons into the container and attempting to eliminate overlaps.\n2012 ACM Subject Classification Theory of computation \u2192 Computational geometry; Computing\nmethodologies \u2192 Search methodologies\nKeywords and phrases packing, polygon, heuristic, differential evolution, local search, tabu search\nDigital Object Identifier 10.4230/LIPIcs.SoCG.2024.86\nCategory CG Challenge\nFunding This work was supported in part by the National Natural Science Foundation of China\n(NSFC) under Grant 72101094 and the Special Project for Knowledge Innovation of Hubei Province\nunder Grant 2022013301015175.\nAcknowledgements We want to thank the organizers of CG:SHOP 2024 and all other participants\nfor creating such an engaging challenge. We also want to thank Dominik Krupke for providing a\nhelpful official validator for solutions.\n1 Introduction\nThe recent CG:SHOP 2024 Challenge introduced a variant of irregular packing problems\nknown as the Maximum Polygon Packing (MPP) problem. The MPP problem involves a\nconvex polygonal container C and a polygon set P = {p1, p2, ..., pN }, where polygon piis\nassociated with a value vi. It seeks for a non-overlapping packing with the maximum total\nvalue. The challenge presents a total of 180 instances whose number of polygons ranges from\n28 to 50,000. The official document [4] gives a detailed description of the challenge.\nOur proposed algorithm employs a general process to solve these instances indiscriminately,\nand the overall framework is presented in Figure 1. We first partition a large-scale problem\ninto multiple small-scale subproblems (Section 2) and then solve each subproblem using\nupper-level polygon ordering (Section 3.1) and lower-level packing optimization techniques\n(Section 3.2). Section 4 presents our experimental results, followed by conclusions.\n1 Corresponding author: Zhouxing Su\n\u00a9 Canhui Luo, Zhouxing Su, and Zhipeng L\u00fc;\nlicensed under Creative Commons License CC-BY 4.0\n40th International Symposium on Computational Geometry (SoCG 2024).\nEditors: Wolfgang Mulzer and Jeff M. Phillips; Article No. 86; pp. 86:1\u201386:9\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\n86:2 A General Heuristic Approach for Maximum Polygon Packing\nInput polygon set P and container C\nUpper-level polygon ordering\nLower-level packing optimization\nFinished?\n \nPacking\nAssemble and return the complete solution\nMPP1 MPP2 MPPm\n( ) 0? Overlap Scurr== ( ) Update Sbest best\nReturn S\nPartitioning\nYes\nNo\nYes\nNo\nSelect next one\nFigure 1 The framework of our proposed algorithm.\n2 Partitioning\nIn this section, we present the decomposition of the original large-scale problem into a series\nof smaller MPP subproblems. It involves two components: partitioning the container C into\nmultiple regions and assigning polygons to each region.\n2.1 Container Partitioning\nThe container partitioning process consists of two steps, as shown in Figure 2. Initially, we\narrange two-dimensional square grids starting from the bottom-left corner of the bounding\nbox until the entire container is covered. The subregions formed by the intersection of the\ncontainer with all the grids constitute its partition C = C1 \u222a C2 \u222a ... \u222a Cm. Subsequently,\nwe merge the small subregions with adjacent grids, which are difficult to be used effectively.\nThe grid is dimensioned to keep the scale of each subproblem at approximately 300 polygons,\nmaking a trade-off between effectiveness and efficiency of lower-level packing optimization.\n2.2 Polygon Assignment\nWe adopt a simple approach of randomly assigning polygons to each subregion. Specifically, for\neach subregion Ci, we randomly select a polygon pj from P until\nP\nj\narea(pj )\narea(Ci) \u2265\nPN\ni=0\narea(pi)\narea(C)\n.\nThe advantage of random assignment lies in ensuring that the overall characteristics of each\nsubproblem align with the original problem.\nC. Luo, Z. Su, and Z. L\u00fc 86:3\nFigure 2 The partitioning process for the instance jigsaw_cf1_4fd4c46e. Step 1 (left): Cover the\ncontainer with squares; Step 2: Intersect and merge small regions (from the middle to the right).\nminimum translation\nminimum translation\nIFP\nContainer\nFigure 3 Examples of NFP between two polygons and IFP between container and polygon.\n3 Packing\n3.1 Upper-Level Polygon Ordering\nWe define a priority for each polygon. We repeatedly select one remaining polygon with the\nhighest priority (ties are broken by value) and try to insert it into the current solution. If the\ninsertion with lower-level packing optimization fails, we skip the current polygon and turn to\nthe next one. For the majority of instances, the priority is defined as the value-to-area ratio\nof a polygon (we also call it unit value). Polygons with higher unit values are prioritized\nfor putting in the container, which is called the Unit Value First (UVF) strategy. For\nsmall-scale instances (N < 100), we employ the \u03b1\u03b2-random strategy. It randomly selects\n\u03b1% and \u03b2% of the polygons and reassigns their UVF-based priority to the highest and the\nlowest, respectively. These instances are run for multiple times to ensure comprehensive\noptimization, with \u03b1 and \u03b2 set to 10 in our implementation.\n3.2 Lower-Level Packing Optimization\nThe position of a polygon can be represented by the coordinates l = (x, y) of a reference point,\nsuch as the bottom-left corner of the boundary. Then, the translation of a polygon can be\nrepresented by a vector pointing from its original position to its new position. Given a feasible\npacking S and a polygon p to be placed, it is impossible to find a non-overlapping position\nfor p without moving other polygons in most cases. This section introduces the algorithm for\neliminating overlaps for an invalid packing, which involves solving an unconstrained nonlinear\nproblem and heuristic polygon movement.\nS o C G 2 0 2 4\n86:4 A General Heuristic Approach for Maximum Polygon Packing\n3.2.1 Overlap Minimization\nTo determine the appropriate translation for the polygons, we utilized the no-fit polygon\n(NFP) and inner-fit polygon (IFP), which are fundamental in algorithmic approaches to\ngeometric design and optimization challenges. For a fixed polygon pi and a movable polygon\npj , NFP(pi, pj ) describes their non-overlapping positions with boundaries in contact precisely,\nwhich can be utilized to determine the minimum translation for pj to avoid overlap. Similarly,\nIFP(pi, pj ) is employed to determine the minimum translation to place pj inside pi. Figure 3\nillustrates the polygon translations determined using NFP (left) and IFP (right). The readers\nmay refer to Burke et al. [2] for a more detailed description.\nFor a packing S, based on NFP and IFP, we define the overlap between polygons pi\nand pj as fij (S), representing the minimum translation to separate them, and f0i(S) as the\nminimum translation for moving pi to fit into the container. Subsequently, we employ the\nseparation algorithm proposed by Imamichi et al. [7] to minimize the overlap, which involves\nsolving an unconstrained nonlinear programming problem as follows:\nmin\nS\nF(S) = X\n0\u2264i<j\u2264N\nf\n2\nij (S) (1)\nThe model relaxes the non-overlapping constraint but introduces repulsion forces between\nany two overlapped polygons. We use the classic L-BFGS (limited memory BFGS) method\nto solve this problem. It makes the packing S converge to a local optimum but strongly\ndepends on the initial layout. ...",
      "url": "https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.86/LIPIcs.SoCG.2024.86.pdf"
    },
    {
      "title": "[PDF] Two approximate Minkowski sum algorithms",
      "text": "Purdue University\nPurdue e-Pubs\nDepartment of Computer Science Faculty\nPublications\nDepartment of Computer Science\n10-7-2011\nTwo approximate Minkowski sum algorithms\nVictor Milenkovic\nUniversity of Miami\nElisha P. Sacks\nPurdue University, eps@cs.purdue.edu\nFollow this and additional works at: http://docs.lib.purdue.edu/cspubs\nPart of the Computer Sciences Commons\nComments\nVictor Milenkovic & Elisha Sacks. 2010. Two approximate Minkowski sum algorithms. International Journal of Computational Geometry and\nApplications, 20(4).\nThis document has been made available through Purdue e-Pubs, a service of the Purdue University Libraries. Please contact epubs@purdue.edu for\nadditional information.\nRepository Citation\nMilenkovic, Victor and Sacks, Elisha P., \"Two approximate Minkowski sum algorithms\" (2011). Department of Computer Science\nFaculty Publications. Paper 2.\nhttp://docs.lib.purdue.edu/cspubs/2\nOctober 7, 2011 8:2 WSPC/Guidelines paper3\nInternational Journal of Computational Geometry & Applications\n\u00b0c World Scientific Publishing Company\nTWO APPROXIMATE MINKOWSKI SUM ALGORITHMS\nVictor Milenkovic\nDepartment of Computer Science, University of Miami\nCoral Gables, FL 33124-4245, USA\nvjm@cs.miami.edu\nElisha Sacks\nComputer Science Department, Purdue University\nWest Lafayette, IN 47907-2066, USA\neps@cs.purdue.edu\nWe present two approximate Minkowski sum algorithms for planar regions bounded\nby line and circle segments. Both algorithms form a convolution curve, construct its\narrangement, and use winding numbers to identify sum cells. The first uses the kinetic\nconvolution and the second uses our monotonic convolution. The asymptotic running\ntimes of the exact algorithms are increased by km log m with m the number of segments\nin the convolution and with k the number of segment triples that are in cyclic vertical\norder due to approximate segment intersection. The approximate Minkowski sum is close\nto the exact sum of perturbation regions that are close to the input regions. We validate\nboth algorithms on part packing tasks with industrial part shapes. The accuracy is\nnear the floating point accuracy even after multiple iterated sums. The programs are 2%\nslower than direct floating point implementations of the exact algorithms. The monotonic\nalgorithm is 42% faster than the kinetic algorithm.\nKeywords: Minkowski sum; kinetic framework; robust computational geometry.\n1. Introduction\nWe present two approximate Minkowski sum algorithms for planar regions bounded\nby line and circle segments. Minkowski sums are an important computational geome\u0002try concept whose applications include robot path planning, part layout, mechanism\ndesign, and computer graphics. Prior algorithms apply to polygonal regions. The\nextension to circle segments is of theoretical and practical interest because line and\ncircle segments are closed under Minkowski sums, so other algorithms can iterate\nthese primitives. Moreover, curved shapes are approximated to a given accuracy\nwith quadratically fewer circle segments than line segments. Applications typically\nmodel curves with 4\u20136 decimal digits accuracy, so employing circles reduces the\nmodel size by a factor of 100\u20131000. Although spline models are even more compact,\nthey are not closed under Minkowski sums.\nThe standard Minkowski sum algorithm1forms the kinetic convolution curve\nof the input regions, constructs its arrangement, and selects the cells with positive\n1\nOctober 7, 2011 8:2 WSPC/Guidelines paper3\n2 Victor Milenkovic and Elisha Sacks\nwinding numbers. The kinetic convolution is suboptimal in that the portion in the\nMinkowski sum interior is formed, arranged, and then discarded. We have developed\na monotonic convolution2 whose size is nearly optimal. In this paper, we describe\nfloating point implementations of both algorithms.\nThe naive approach is to replace real arithmetic with floating point arithmetic.\nThis approach is fast and accurate for most inputs, but is prone to failure when\nrounding errors alter the combinatorial structure of the output.\nThe mainstream implementation strategy is exact arithmetic using algebraic\ngeometry (http://cs.nyu.edu/exact). Wein3 presents an exact kinetic algorithm for\npolygons. Exact Minkowski sum computation with circle segments has not been\nreported. We expect it would be slow, since exact arrangement computation, which\nis the dominant cost, is slow. For example, the latest exact algorithm4takes 220\nseconds to arrange 100 degree 6 curves, versus 22 second for our approximate\nalgorithm5(both using Linux and GNU C++ on similar processors). The run\u0002ning time of the exact algorithm is much larger for degenerate input, whereas ours\nis unchanged.\nA second problem with exact Minkowski sums is that the algebraic degree and\nbit complexity of the output are higher than in the input. Output simplification is re\u0002quired to prevent exponential growth in iterated operations. Iteration is essential to\napplications algorithms for packing,6,7 path planning,8 and mechanical design.9 The\nstate of the art addresses bit complexity growth in 2D polygons,10,11,12,13,14 3D line\nsegments,15 polyhedral subdivisions,16 and polyhedra defined by plane equations.17\nOutput simplification is an open problem for circle segments.\nThese problems motivate our approach of computing approximate Minkowski\nsums in floating point. The asymptotic running times of the exact algorithms are\nincreased by a low-degree polynomial that is negligible in practice. We prove that\nthe approximate sum is close to the exact sum of perturbation regions that are close\nto the input regions. The topology of the approximate sum can differ from that of\nthe exact sum of the input regions or of the perturbed regions. Output simplification\nis automatic, since floating point has constant bit complexity.\nWe validate the algorithms on part packing tasks with industrial part shapes.\nThe accuracy is near the floating point accuracy even after multiple iterated sums.\nThe programs are 2% slower than naive floating point implementations. The mono\u0002tonic algorithm is 42% faster than the kinetic algorithm. The C++ source code is\navailable at http://www.cs.miami.edu/\u02dcvjm/robust for teaching or research.\nThe paper is organized as follows. Section 2 contains definitions. Section 3 de\u0002scribes our formulation of the kinetic Minkowski sum algorithm and Section 4 an\u0002alyzes the approximate algorithm. Section 5 describes our monotonic convolution\nand Section 6 analyzes the approximate algorithm. Section 7 extends the approxi\u0002mate monotonic algorithm to compute accurately the free placements of a moving\npart with respect to a fixed part. Section 8 presents the validation results. The final\nsection contains conclusions and plans for future work.\nOctober 7, 2011 8:2 WSPC/Guidelines paper3\nTwo approximate Minkowski sum algorithms 3\nB\nj h\ng\ni\nd f\na\nb\nk\nn\nl\nm\nc e\nA\nl\nan\nlm\nm\nmn\nj\nn\nk\njk kl 0\n1\n2\n(a) (b)\nFig. 1. Planar regions (a) and their kinetic convolution (b).\n2. Definitions\nA planar region is a closed, connected region whose boundary consists of simple\nloops of line and circle segments. We discuss the core case of a region whose\nboundary consists of one loop (Fig. 1a). The extension to multiple loops is\nstraightforward.2 The endpoints of segment a are designated tail(a) and head(a), so\nthat the region interior is to the left when a is traversed from tail to head. A circle\nsegment also has a center, center(a), and a signed radius, radius(a), that is posi\u0002tive/negative when a is convex/concave, meaning that the center is to the left/right\nwhen the segment is traversed from tail to head.\nThe rightward (outward) normal vector of a line segment, a, is (y, \u2212x) with\n(x,y) = head(a) \u2212 tail(a). The rightward normal vector of a circle segment at p is\n(p \u2212 center(a))/radius(a). The rightward normal angles at tail(a) and head(a) are\ncalled \u03b1(a) and \u03b2(a). The angle interval of a is [\u03b1(a),\u03b2(a)] when a is convex and\nis [\u03b2(a),\u03b1(a)] otherwise. The point on a with angle \u03b8 is called point(a,\u03b8).\nThe input...",
      "url": "https://www.cs.purdue.edu/cgvlab/www/resources/papers/Milenkovic-IJCGA-2010-Two_approximate_Minkowski_sum_Algorithms.pdf"
    },
    {
      "title": "Convex Polygon Packing Based Meshing Algorithm for Modeling of ...",
      "text": "Convex Polygon Packing Based Meshing Algorithm for Modeling of Rock and Porous Media - PMC[Skip to main content](#main-content)\n![](https://pmc.ncbi.nlm.nih.gov/static/img/us_flag.svg)\nAn official website of the United States government\nHere's how you know\nHere's how you know\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-dot-gov.svg)\n**Official websites use .gov**\nA**.gov**website belongs to an official\ngovernment organization in the United States.\n![](https://pmc.ncbi.nlm.nih.gov/static/img/icon-https.svg)\n**Secure .gov websites use HTTPS**\nA**lock**(LockLocked padlock icon) or**https://**means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n[![NCBI home page](https://pmc.ncbi.nlm.nih.gov/static/img/ncbi-logos/nih-nlm-ncbi--white.svg)](https://www.ncbi.nlm.nih.gov/)\nSearch\nLog in\n* [Dashboard](https://www.ncbi.nlm.nih.gov/myncbi/)\n* [Publications](https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/)\n* [Account settings](https://www.ncbi.nlm.nih.gov/account/settings/)\n* Log out\nSearch\u2026Search NCBI\n[](https://pmc.ncbi.nlm.nih.gov/)\nSearch PMC Full-Text ArchiveSearch in PMC![Search](https://pmc.ncbi.nlm.nih.gov/static/img/usa-icons-bg/search--white.svg)\n* [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n* [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n* * [](https://doi.org/10.1007/978-3-030-50426-7_20)\n* [](pdf/978-3-030-50426-7_Chapter_20.pdf)\n* * * ## PERMALINK\nCopy\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)|[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n![Springer Nature - PMC COVID-19 Collection logo](https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-phenaturepg.png)\nComputational Science \u2013ICCS 2020\n. 2020 May 25;12141:257\u2013269. doi:[10.1007/978-3-030-50426-7\\_20](https://doi.org/10.1007/978-3-030-50426-7_20)\n# Convex Polygon Packing Based Meshing Algorithm for Modeling of Rock and Porous Media\n[Joaqu\u00ed\u00adn Torres](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Torres JN\"[Author]>)\n### Joaqu\u00ed\u00adn Torres\n15Departamento de Ciencias de la Computaci\u00f3n, Universidad de Chile, Santiago, Chile\nFind articles by[Joaqu\u00ed\u00adn Torres](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Torres JN\"[Author]>)\n15,\u2709,[Nancy Hitschfeld](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Hitschfeld N\"[Author]>)\n### Nancy Hitschfeld\n15Departamento de Ciencias de la Computaci\u00f3n, Universidad de Chile, Santiago, Chile\nFind articles by[Nancy Hitschfeld](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Hitschfeld N\"[Author]>)\n15,\u2709,[Rafael O Ruiz](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Ruiz RO\"[Author]>)\n### Rafael O Ruiz\n16Departamento de Ingenieria Civil, Universidad de Chile, Santiago, Chile\nFind articles by[Rafael O Ruiz](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Ruiz RO\"[Author]>)\n16,[Alejandro Ortiz-Bernardin](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Ortiz-Bernardin A\"[Author]>)\n### Alejandro Ortiz-Bernardin\n17Departamento de Ingenieria Mec\u00e1nica, Universidad de Chile, Santiago, Chile\nFind articles by[Alejandro Ortiz-Bernardin](<https://pubmed.ncbi.nlm.nih.gov/?term=\"Ortiz-Bernardin A\"[Author]>)\n17\nEditors:Valeria V Krzhizhanovskaya8,G\u00e1bor Z\u00e1vodszky9,Michael H Lees10,Jack J Dongarra11,Peter M A Sloot12,S\u00e9rgio Brissos13,Jo\u00e3o Teixeira14\n* Author information\n* Copyright and License information\n8University of Amsterdam, Amsterdam, The Netherlands\n9University of Amsterdam, Amsterdam, The Netherlands\n10University of Amsterdam, Amsterdam, The Netherlands\n11University of Tennesee, Knoxville, TN USA\n12University of Amsterdam, Amsterdam, The Netherlands\n13Intellegibilis, Set\u00fabal, Portugal\n14Intellegibilis, Set\u00fabal, Portugal\n15Departamento de Ciencias de la Computaci\u00f3n, Universidad de Chile, Santiago, Chile\n16Departamento de Ingenieria Civil, Universidad de Chile, Santiago, Chile\n17Departamento de Ingenieria Mec\u00e1nica, Universidad de Chile, Santiago, Chile\n\u2709Corresponding author.\n\u00a9Springer Nature Switzerland AG 2020\nThis article is made available via the PMC Open Access Subset for unrestricted research re-use and secondary analysis in any form or by any means with acknowledgement of the original source. These permissions are granted for the duration of the World Health Organization (WHO) declaration of COVID-19 as a global pandemic.\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\nPMCID: PMC7302853\n## Abstract\nIn this work, we propose new packing algorithm designed for the generation of polygon meshes to be used for modeling of rock and porous media based on the virtual element method. The packing problem to be solved corresponds to a two-dimensional packing of convex-shape polygons and is based on the locus operation used for the advancing front approach. Additionally, for the sake of simplicity, we decided to restrain the polygon rotation in the packing process. Three heuristics are presented to simplify the packing problem: density heuristic, gravity heuristic and the multi-layer packing. The decision made by those three heuristic are prioritizing on minimizing the area, inserting polygons on the minimum*Y*coordinate and pack polygons in multiple layers dividing the input in multiple lists, respectively. Finally, we illustrate the potential of the generated meshes by solving a diffusion problem, where the discretized domain consisted in polygons and spaces with different conductivities. Due to the arbitrary shape of polygons and spaces that are generated by the packing algorithm, the virtual element method was used to solve the diffusion problem numerically.\n**Keywords:**Polygonal meshes, Geometric packing, Virtual element method, Computational geometry\n## Introduction\nIn the last decade, the use of finite element methods (FEM) have been the common engineering practice to design and evaluate the performance of different systems. However, in many applications, the FEM has shown some limitations related to the complexity involved in the mesh generation, specially for problems in which the domain is defined by an arrangement of irregular sub-domains. In particular, these situations are found in problems related to the flux of fluid and heat in porous media, fracture mechanics of conglomerate rocks, stability of tailing dams, concrete modeling, amount others. Here, one of the issues is to deal with the random nature of the sub-domains, requiring the statistical study of the problem with multiple simulations. As consequence, the computational burden increases since it is required to draw the geometry and create the mesh several times.\nWith the advent of the virtual element method (VEM) [[15](#CR15)] very general polytopal meshes (polygons can even be non-convex) can now be used to simulate problems based on Galerkin methods in a manner similar to FEM. In porous media, microstructure, rock accumulation, among others, the bidimensional domain is composed naturally of arbitrary polytopal shapes, which in a simulation can be represented by virtual elements. In this regard, the mentioned issues could be solved using the packing perspective together with numerical methods that employ polytopal meshes (i.e., Virtual Element Method). In a general perspective, packing is an optimization problem on how to organize the content of a container as densely as possible. A particular example of packing is the geometric packing; this packing comprises fitting geometric figures as much as possible inside a container. For example, packing polygons inside a rectangle container, or packing tetrahedra inside a cube container. Then, these polygons/polyhedrons could be used to define the sub-domains at the same time that could be used as a mesh under VEMs schemes.\nDifferent packing strategies have been developed in the past employing different packing geometries. For example, adopting a circle and sphe...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7302853"
    }
  ]
}