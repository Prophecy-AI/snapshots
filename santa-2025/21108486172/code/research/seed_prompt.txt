# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 7)

## Current Status
- Best CV score: 70.734327 from exp_001 (baseline)
- Best LB score: 70.734327 (verified)
- Target: 68.931058 | Gap to target: 1.803269 (2.5%)
- Experiments: 7 (ALL at exactly the same score - 70.734327)

## Response to Evaluator

The evaluator correctly identified that experiment 007 (SA-with-translations) was a **severely simplified** implementation missing:
1. Multiprocessing (jiweiliu runs 34+ seconds, ours ran 1.5 seconds)
2. Deletion cascade (propagates improvements from larger N to smaller N)
3. Initial seeds (pre-computed good starting points)
4. sa_optimize_improved (more sophisticated move types)

**CRITICAL INSIGHT**: The evaluator noted that jiweiliu improves from 71.657 → 71.5, but our baseline is already at 70.734. This means SA-with-translations CANNOT improve our baseline - it's designed to improve worse baselines.

**AGREED**: We need a fundamentally different approach. The evaluator recommends:
- Option A: C++ optimizer with proper parameters (150,000+ iterations, 32+ restarts, multiple generations)
- Option B: Ensemble approach from multiple sources
- Option C: Fix SA-with-translations (but this won't help since baseline is already better)

## Key Findings from Analysis

1. **All external datasets score WORSE than baseline**:
   - santa25-public best: 70.926 (worse than 70.734)
   - telegram-public best: 72.495 (much worse)
   - The baseline IS the best valid configuration available

2. **The seshurajup kernel insight**:
   - Uses MULTIPLE GENERATIONS - keeps running until no improvement for 10 generations
   - Our experiments ran SINGLE-PASS optimization
   - The key is ENDLESS OPTIMIZATION until convergence

3. **Score breakdown by N range**:
   - N=1-10: 4.33 (6.1%)
   - N=11-30: 7.42 (10.5%)
   - N=31-50: 7.30 (10.3%)
   - N=51-100: 17.66 (25.0%)
   - N=101-150: 17.16 (24.3%)
   - N=151-200: 16.87 (23.8%)
   - Large N (51-200) contributes 73% of total score

## Why Previous Experiments Failed

| Experiment | Approach | Why It Failed |
|------------|----------|---------------|
| 001 | Baseline | N/A - established baseline |
| 002 | C++ optimizer (15K iter, 16 restarts) | Insufficient iterations/restarts |
| 003 | Python SA with collision constraints | Too slow, limited exploration |
| 004 | Structured grid packing | Scores MUCH worse than baseline |
| 005 | Overlap repair SA | Overlapping configs are fundamentally broken |
| 006 | C++ optimizer (20K iter, 10 restarts) | Still insufficient - need 150K+ iterations |
| 007 | SA-with-translations (simplified) | Missing key features, baseline already better |

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY]** Multi-Generation C++ Optimization

The seshurajup kernel shows the key insight: **MULTIPLE GENERATIONS**.

**Implementation**:
```bash
# Compile the C++ optimizer
g++ -O3 -march=native -std=c++17 -fopenmp -o sa_v3_parallel sa_v3_parallel.cpp

# Run with high parameters AND multiple generations
# Generation 1
./sa_v3_parallel -i baseline.csv -o gen1.csv -n 100000 -r 32

# Generation 2 (start from gen1 output)
./sa_v3_parallel -i gen1.csv -o gen2.csv -n 100000 -r 32

# Continue until no improvement for 3 generations
```

**Key parameters**:
- Iterations: 100,000+ (vs 20,000 used before)
- Restarts: 32+ (vs 10 used before)
- Multiple generations: Keep running until convergence
- OpenMP threads: Use all available cores

### 2. **[HIGH PRIORITY]** Per-N Targeted Optimization

Instead of optimizing all N values equally, focus on the N values with the worst efficiency:

**Efficiency metric**: score_n / theoretical_minimum_n

For large N (where most score comes from), the theoretical minimum is approximately:
- N trees need area ≈ N × tree_area
- Minimum side ≈ sqrt(N × tree_area)
- Minimum score ≈ N × tree_area / N = tree_area ≈ 0.35

**Implementation**:
1. Calculate efficiency for each N
2. Identify N values with worst efficiency
3. Run intensive SA on those specific N values

### 3. **[MEDIUM PRIORITY]** Genetic Algorithm / Population-Based Search

The seshurajup kernel uses population-based search (keeps top 3 solutions). This could be extended:

**Implementation**:
1. Maintain a population of solutions for each N
2. Use crossover: combine good configurations from different solutions
3. Use mutation: SA perturbation
4. Selection: keep best configurations

### 4. **[LOWER PRIORITY]** Crystalline/Lattice Packing for Large N

For N ≥ 58, regular geometric patterns may be optimal:
- Hexagonal packing
- Square grid with rotation
- Triangular lattice

**Note**: This was mentioned in web search results but not implemented.

## What NOT to Try

1. ❌ SA-with-translations (baseline already better than what it can produce)
2. ❌ Simple grid packing (scores much worse)
3. ❌ Overlap repair (overlapping configs are fundamentally broken)
4. ❌ Single-pass optimization (need multiple generations)
5. ❌ Low iteration counts (need 100K+ iterations)

## Validation Notes

- CV = LB for this problem (deterministic scoring)
- Always verify no overlaps before submission
- Use the numba-accelerated overlap checker

## SUBMISSION STRATEGY

- Remaining submissions: 95
- Submit after this experiment? **YES** - we have abundant submissions
- Submit ANY improvement over 70.734327

## Technical Notes

The C++ optimizer (sa_v3_parallel) includes:
1. `sa_v3`: SA with 8 move types (translate, rotate, swap, etc.)
2. `ls_v3`: Local search with 8-directional moves
3. `fractional_translation`: Fine-grained position optimization
4. `perturb`: Basin hopping perturbation
5. Population-based search (keeps top 3 solutions)

The key is to run this optimizer in MULTIPLE GENERATIONS, starting each generation from the best solution of the previous generation.