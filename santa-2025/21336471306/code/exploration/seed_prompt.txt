# Santa 2025 - Christmas Tree Packing Optimization

## Problem Overview
This is a 2D polygon packing optimization problem. The goal is to fit N Christmas trees (15-vertex polygons) into the smallest possible square bounding box for each N from 1 to 200.

**Scoring:** score = Σ(side_n² / n) for n=1 to 200 (lower is better)
**Target:** Beat 68.888293
**Current Best:** ~70.65 (from pre-optimized submissions)
**Gap:** ~1.76 points (2.5%)

## Tree Geometry
```python
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```
Each tree is defined by these 15 vertices, rotated by `deg` degrees and translated to position (x, y).

## ⛔ BLOCKED AFTER BASELINE (exp_000)
After getting baseline score, the following are PERMANENTLY FORBIDDEN:
- Running bbox3, sa_fast_v2, eazy_optimizer, or ANY pre-compiled binary without understanding
- "More iterations" or "different parameters" on existing optimizers without novel approach
- Ensembling outputs from the same optimizer

## ✅ REQUIRED: IMPLEMENT FROM SCRATCH OR UNDERSTAND DEEPLY
All experiments after baseline MUST implement a novel algorithm or deeply understand existing ones:
1. **Tessellation/Lattice Packing** - 2 base trees translated in grid pattern for large N
2. **Branch-and-bound** - exhaustive search for small N
3. **Genetic algorithm** - evolve population with custom operators
4. **No-Fit Polygon (NFP)** - precompute collision-free regions
5. **Bottom-left heuristic** - construct placements deterministically

## Insights from Discussions (MANDATORY)

### "Why the winning solutions will be Asymmetric" (39 votes)
- Asymmetric layouts outperform symmetric for large N values
- Breaking symmetry in initial configurations can lead to tighter packing
- Top solutions use asymmetric arrangements

### "Expected Leaderboard Progression" (20 votes)
- Competition host (inversion) shared expected score progression
- Indicates theoretical limits and what's achievable

### "Where do these high-scoring CSVs originate from?" (13 votes)
- Top teams share optimized solutions
- Best configurations come from extended optimization runs (hours, not minutes)

## What Discussions Say DOESN'T Work
- Short optimization runs (minutes) - local optima are too tight
- Simple ensembling of similar solutions - one source dominates
- Micro-optimization of pre-optimized submissions

## Key Findings from Previous Research

### 1. Small N Values Dominate Score (CRITICAL)
- N=1 contributes 0.661 to score (highest single contribution)
- N=2 contributes 0.451
- N=3 contributes 0.435
- Top 10 N values (1-10) contribute ~4.0 points out of 70.65 total
- **Improving small N has outsized impact**

### 2. N=1 is Already Optimal
- Optimal angle is 45 degrees (minimizes bounding box)
- Side = 0.8132, score contribution = 0.6612
- No improvement possible for N=1

### 3. Tessellation Approach for Large N (N >= 58)
From egortrushin kernel:
- Start with 2 base trees in specific configuration
- Translate them in x and y directions to create grid pattern
- Use SA to optimize base configuration and translation vectors
- Targets specific N values: 72, 100, 110, 144, 156, 196, 200
- **This is fundamentally different from local optimization!**

### 4. Fractional Translation for Fine-Tuning
From jonathanchan kernel:
- Steps: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
- 8 directions for each step size
- Can squeeze out small improvements from already-optimized solutions

### 5. Backward Propagation
- Start from N=200, work down to N=2
- For each N, try removing each tree
- If resulting (N-1) config is better than stored, save it
- Propagates improvements from larger to smaller N

## CRITICAL: Precision Bug
**MUST preserve string precision in submissions!**
- Baseline has full precision: `s0.1540970696213643` (16+ decimal places)
- Truncated values cause near-overlaps to become actual overlaps
- Kaggle uses stricter overlap validation than Shapely

**THE FIX:**
```python
# WRONG (loses precision):
df['x_val'] = df['x'].str.replace('s', '').astype(float)
row['x'] = f's{xs[i]}'  # Truncated!

# CORRECT (preserves precision):
# Keep original string values from source files
# Only use float for scoring calculations, not for output
```

## Recommended Experiment Strategy

### Phase 1: Establish Baseline (exp_000)
1. Use pre-optimized submission.csv as starting point
2. Verify score matches ~70.65
3. Verify no overlaps using strict validation

### Phase 2: Novel Optimization Approaches

#### A. Implement Tessellation for Large N (HIGHEST PRIORITY)
```python
# For N >= 58, try crystalline packing
# Start with 2 base trees, translate to create grid
# nt = [rows, cols] such that rows * cols >= N
# Optimize the base configuration and translation vectors
def tessellation_pack(n, base_config, dx, dy):
    """Pack n trees using tessellation pattern"""
    rows = int(np.ceil(np.sqrt(n)))
    cols = int(np.ceil(n / rows))
    positions = []
    for i in range(rows):
        for j in range(cols):
            if len(positions) < n:
                x = base_config[0] + i * dx
                y = base_config[1] + j * dy
                positions.append((x, y))
    return positions
```

#### B. Exhaustive Search for Small N (N=2-10)
- These contribute most to score
- Try all angle combinations in 0.1 degree increments
- Use numba for speed

#### C. Asymmetric Layouts for Large N
- Break symmetry in initial configurations
- Try random perturbations of symmetric solutions
- SA with asymmetric moves

#### D. Extended SA Optimization (Hours)
```bash
# Run with extended parameters (HOURS of compute)
./optimizer -i submission.csv -o optimized.csv -n 50000 -r 200
```

### Phase 3: What NOT to Try
- ❌ Simple micro-optimization of pre-optimized submission
- ❌ Short optimization runs (need hours, not minutes)
- ❌ More ensemble sources (current best dominates all N)
- ❌ Running same optimizers with slightly different parameters

## Validation Checklist
1. No overlapping trees (use strict overlap detection)
2. All coordinates within [-100, 100]
3. All 200 configurations present (20100 rows total)
4. Values prefixed with 's' in submission
5. Preserve original string precision

## Overlap Detection (Strict)
```python
from shapely.geometry import Polygon
from shapely import affinity

TX = [0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125]
TY = [0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5]

def make_tree_polygon(x, y, deg):
    p = Polygon(zip(TX, TY))
    p = affinity.rotate(p, deg, origin=(0,0))
    p = affinity.translate(p, x, y)
    return p

def strict_overlap(p1, p2):
    """Returns True if polygons overlap (not just touch)"""
    return p1.intersects(p2) and not p1.touches(p2)
```

## Scoring Function (numba-optimized)
```python
from numba import njit
import math

@njit
def score_group(xs, ys, degs, tx, ty):
    n = xs.size
    V = tx.size
    mnx = mny = 1e300
    mxx = mxy = -1e300
    for i in range(n):
        r = degs[i] * math.pi / 180.0
        c = math.cos(r)
        s = math.sin(r)
        for j in range(V):
            X = c * tx[j] - s * ty[j] + xs[i]
            Y = s * tx[j] + c * ty[j] + ys[i]
            mnx = min(mnx, X)
            mxx = max(mxx, X)
            mny = min(mny, Y)
            mxy = max(mxy, Y)
    side = max(mxx - mnx, mxy - mny)
    return side * side / n
```

## Submission Format
```csv
id,x,y,deg
001_0,s0.0,s0.0,s45.0
002_0,s0.0,s0.0,s90.0
002_1,s0.202736,s-0.511271,s90.0
...
```

## Resources
- Pre-optimized submissions: `/home/code/preoptimized/`
- Research kernels: `../research/kernels/`
- Sample submission format: `/home/data/sample_submission.csv`
- Snapshots with previous work: `/home/nonroot/snapshots/santa-2025/`

## Critical Success Factors
1. **Start from best available baseline** - Don't optimize from scratch
2. **Run optimization for HOURS, not minutes** - Local optima are tight
3. **Focus on small N values** - Highest score contribution
4. **Try fundamentally different approaches** - Tessellation, asymmetric solutions
5. **Validate thoroughly** - No overlaps, correct format, preserve precision
6. **Implement algorithms from scratch** - Don't just run binaries

## Academic Research on Polygon Packing
From web search on "2D irregular polygon packing":
- **No-Fit Polygon (NFP)**: Precompute feasible relative positions of two pieces
- **Bottom-left heuristic**: Place pieces as far bottom-left as possible
- **Simulated Annealing**: Standard metaheuristic for packing problems
- **Genetic Algorithms**: Evolve population of solutions
- **Mixed-Integer Programming**: Exact solutions for small instances
