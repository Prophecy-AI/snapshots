# Santa 2025 - Christmas Tree Packing Optimization

## Problem Overview
This is a 2D polygon packing optimization problem. The goal is to fit N Christmas trees (15-vertex polygons) into the smallest possible square bounding box for each N from 1 to 200.

**Scoring:** score = Σ(side_n² / n) for n=1 to 200 (lower is better)
**Target:** Beat 68.888293
**Current Best:** ~70.65 (from pre-optimized submissions)
**Gap:** ~1.76 points (2.5%)

## Tree Geometry
```python
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```
Each tree is defined by these 15 vertices, rotated by `deg` degrees and translated to position (x, y).

## ⛔ BLOCKED AFTER BASELINE (exp_000)
After getting baseline score, the following are PERMANENTLY FORBIDDEN:
- Running bbox3, sa_fast_v2, eazy_optimizer, or ANY pre-compiled binary without understanding
- "More iterations" or "different parameters" on existing optimizers without novel approach
- Ensembling outputs from the same optimizer

## ✅ REQUIRED: IMPLEMENT FROM SCRATCH OR UNDERSTAND DEEPLY
All experiments after baseline MUST implement a novel algorithm or deeply understand existing ones:
1. **Tessellation/Lattice Packing** - 2 base trees translated in grid pattern for large N
2. **Branch-and-bound** - exhaustive search for small N
3. **Genetic algorithm** - evolve population with custom operators
4. **No-Fit Polygon (NFP)** - precompute collision-free regions
5. **Bottom-left heuristic** - construct placements deterministically

## Insights from Discussions (MANDATORY)

### "Why the winning solutions will be Asymmetric" (39 votes)
- Asymmetric layouts outperform symmetric for large N values
- Breaking symmetry in initial configurations can lead to tighter packing
- Top solutions use asymmetric arrangements

### "Expected Leaderboard Progression" (20 votes)
- Competition host (inversion) shared expected score progression
- Indicates theoretical limits and what's achievable

### "Where do these high-scoring CSVs originate from?" (13 votes)
- Top teams share optimized solutions
- Best configurations come from extended optimization runs (hours, not minutes)

## What Discussions Say DOESN'T Work
- Short optimization runs (minutes) - local optima are too tight
- Simple ensembling of similar solutions - one source dominates
- Micro-optimization of pre-optimized submissions

## Key Findings from Previous Research

### 1. Small N Values Dominate Score (CRITICAL)
- N=1 contributes 0.661 to score (highest single contribution)
- N=2 contributes 0.451
- N=3 contributes 0.435
- Top 10 N values (1-10) contribute ~4.0 points out of 70.65 total
- **Improving small N has outsized impact**

### 2. N=1 is Already Optimal
- Optimal angle is 45 degrees (minimizes bounding box)
- Side = 0.8132, score contribution = 0.6612
- No improvement possible for N=1

### 3. Tessellation Approach for Large N (N >= 58)
From egortrushin kernel:
- Start with 2 base trees in specific configuration
- Translate them in x and y directions to create grid pattern
- Use SA to optimize base configuration and translation vectors
- Targets specific N values: 72, 100, 110, 144, 156, 196, 200
- **This is fundamentally different from local optimization!**

### 4. Fractional Translation for Fine-Tuning
From jonathanchan kernel:
- Steps: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
- 8 directions for each step size
- Can squeeze out small improvements from already-optimized solutions

### 5. Backward Propagation
From smartmanoj kernel (bp.cpp):
- Start from N=200, work down to N=2
- For each N, try removing each tree
- If resulting (N-1) config is better than stored, save it
- Propagates improvements from larger to smaller N

## CRITICAL: Precision Bug
**MUST preserve string precision in submissions!**
- Baseline has full precision: `s0.1540970696213643` (16+ decimal places)
- Truncated values cause near-overlaps to become actual overlaps
- Kaggle uses stricter overlap validation than Shapely

**THE FIX:**
```python
# WRONG (loses precision):
df['x_val'] = df['x'].str.replace('s', '').astype(float)
row['x'] = f's{xs[i]}'  # Truncated!

# CORRECT (preserves precision):
# Keep original string values from source files
# Only use float for scoring calculations, not for output
```

## Recommended Experiment Strategy

### Phase 1: Establish Baseline (exp_000)
1. Use pre-optimized submission.csv as starting point
2. Verify score matches ~70.65
3. Verify no overlaps using strict validation

### Phase 2: Novel Optimization Approaches

#### A. Implement Tessellation for Large N (HIGHEST PRIORITY)
```python
# For N >= 58, try crystalline packing
# Start with 2 base trees, translate to create grid
# nt = [rows, cols] such that rows * cols >= N
# Optimize the base configuration and translation vectors

def tessellation_pack(n, base_trees, dx, dy):
    """
    Pack n trees using tessellation pattern.
    base_trees: [(x1, y1, deg1), (x2, y2, deg2)] - two base trees
    dx, dy: translation vectors
    """
    positions = []
    rows = int(np.ceil(np.sqrt(n / 2)))
    cols = int(np.ceil(n / (2 * rows)))
    
    for i in range(rows):
        for j in range(cols):
            for base_x, base_y, base_deg in base_trees:
                if len(positions) < n:
                    x = base_x + i * dx
                    y = base_y + j * dy
                    positions.append((x, y, base_deg))
    return positions[:n]
```

#### B. Exhaustive Search for Small N (N=2-10)
- These contribute most to score
- Try all angle combinations in 0.1 degree increments
- Use numba for speed

```python
@njit
def exhaustive_search_n2(tx, ty, angle_step=0.1):
    """Find optimal configuration for N=2"""
    best_score = 1e300
    best_config = None
    
    for deg1 in np.arange(0, 360, angle_step):
        for deg2 in np.arange(0, 360, angle_step):
            # Try different relative positions
            for dx in np.arange(-1, 1, 0.05):
                for dy in np.arange(-1, 1, 0.05):
                    # Check overlap and score
                    ...
    return best_config
```

#### C. Asymmetric Layouts for Large N
- Break symmetry in initial configurations
- Try random perturbations of symmetric solutions
- SA with asymmetric moves

#### D. Implement Custom SA from Scratch
```python
def simulated_annealing(config, n_iterations=10000, T_start=1.0, T_end=0.001):
    """Custom SA implementation"""
    T = T_start
    alpha = (T_end / T_start) ** (1 / n_iterations)
    
    current = config.copy()
    best = config.copy()
    best_score = score_config(best)
    
    for i in range(n_iterations):
        # Generate neighbor
        neighbor = perturb(current)
        
        # Accept or reject
        delta = score_config(neighbor) - score_config(current)
        if delta < 0 or random.random() < np.exp(-delta / T):
            current = neighbor
            if score_config(current) < best_score:
                best = current.copy()
                best_score = score_config(current)
        
        T *= alpha
    
    return best
```

### Phase 3: What NOT to Try
- ❌ Simple micro-optimization of pre-optimized submission
- ❌ Short optimization runs (need hours, not minutes)
- ❌ More ensemble sources (current best dominates all N)
- ❌ Running same optimizers with slightly different parameters

## Validation Checklist
1. No overlapping trees (use strict overlap detection)
2. All coordinates within [-100, 100]
3. All 200 configurations present (20100 rows total)
4. Values prefixed with 's' in submission
5. Preserve original string precision

## Overlap Detection (Strict)
```python
from shapely.geometry import Polygon
from shapely import affinity

TX = [0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125]
TY = [0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5]

def make_tree_polygon(x, y, deg):
    p = Polygon(zip(TX, TY))
    p = affinity.rotate(p, deg, origin=(0,0))
    p = affinity.translate(p, x, y)
    return p

def strict_overlap(p1, p2):
    """Returns True if polygons overlap (not just touch)"""
    return p1.intersects(p2) and not p1.touches(p2)
```

## Scoring Function (numba-optimized)
```python
from numba import njit
import math
import numpy as np

TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])
TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])

@njit
def score_group(xs, ys, degs, tx, ty):
    n = xs.size
    V = tx.size
    mnx = mny = 1e300
    mxx = mxy = -1e300
    for i in range(n):
        r = degs[i] * math.pi / 180.0
        c = math.cos(r)
        s = math.sin(r)
        for j in range(V):
            X = c * tx[j] - s * ty[j] + xs[i]
            Y = s * tx[j] + c * ty[j] + ys[i]
            mnx = min(mnx, X)
            mxx = max(mxx, X)
            mny = min(mny, Y)
            mxy = max(mxy, Y)
    side = max(mxx - mnx, mxy - mny)
    return side * side / n

def calculate_total_score(configs):
    """Calculate total score across all N values"""
    total = 0.0
    for n in range(1, 201):
        xs, ys, degs = configs[n]
        total += score_group(xs, ys, degs, TX, TY)
    return total
```

## Submission Format
```csv
id,x,y,deg
001_0,s0.0,s0.0,s45.0
002_0,s0.0,s0.0,s90.0
002_1,s0.202736,s-0.511271,s90.0
...
```

## Resources
- Pre-optimized submissions: `/home/code/preoptimized/`
- Research kernels: `../research/kernels/`
- Sample submission format: `/home/data/sample_submission.csv`
- Snapshots with previous work: `/home/nonroot/snapshots/santa-2025/`

## C++ Optimizer Reference (from kernels)
```cpp
// Key structures from tree_packer_v21.cpp
constexpr int NV = 15;
alignas(64) const long double TX[NV] = {0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125};
alignas(64) const long double TY[NV] = {0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5};

// Compile: g++ -O3 -march=native -std=c++17 -fopenmp -o optimizer optimizer.cpp
```

## Critical Success Factors
1. **Start from best available baseline** - Don't optimize from scratch
2. **Run optimization for HOURS, not minutes** - Local optima are tight
3. **Focus on small N values** - Highest score contribution
4. **Try fundamentally different approaches** - Tessellation, asymmetric solutions
5. **Validate thoroughly** - No overlaps, correct format, preserve precision
6. **Implement algorithms from scratch** - Don't just run binaries

## Academic Research on Polygon Packing
From web search on "2D irregular polygon packing":
- **No-Fit Polygon (NFP)**: Precompute feasible relative positions of two pieces
- **Bottom-left heuristic**: Place pieces as far bottom-left as possible
- **Simulated Annealing**: Standard metaheuristic for packing problems
- **Genetic Algorithms**: Evolve population of solutions
- **Mixed-Integer Programming**: Exact solutions for small instances

## Unexplored Ideas from Research
1. **No-Fit Polygon (NFP) precomputation** - O(1) overlap checks after precomputation
2. **Constraint Programming** - Model as CSP with rotation and position variables
3. **Branch-and-bound with pruning** - Exact solution for small N
4. **Hybrid approaches** - Combine heuristics with local search
5. **Problem decomposition** - Solve subproblems optimally, then combine
