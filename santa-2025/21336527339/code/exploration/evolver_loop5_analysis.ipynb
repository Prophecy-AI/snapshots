{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da93151",
   "metadata": {},
   "source": [
    "# Loop 5 Analysis: Comprehensive Ensemble from All Sources\n",
    "\n",
    "## Key Insight from jonathanchan kernel:\n",
    "1. Ensemble from 19+ sources (GitHub, Kaggle datasets, notebooks)\n",
    "2. Override N=1 with optimal value (x=0, y=0, deg=45)\n",
    "3. Apply fractional translation (0.001 to 0.00001 steps)\n",
    "\n",
    "## Available Sources:\n",
    "- 88 snapshots (already scanned)\n",
    "- Preoptimized folder: telegram, santa25-public, bucket-of-chump, etc.\n",
    "- 3434 total CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7948306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Tree geometry\n",
    "def make_tree_polygon():\n",
    "    tw, th = 0.15, 0.2\n",
    "    bw, mw, ow = 0.7, 0.4, 0.25\n",
    "    tip, t1, t2, base, tbot = 0.8, 0.5, 0.25, 0.0, -0.2\n",
    "    x = [0, ow/2, ow/4, mw/2, mw/4, bw/2, tw/2, tw/2, -tw/2, -tw/2, -bw/2, -mw/4, -mw/2, -ow/4, -ow/2]\n",
    "    y = [tip, t1, t1, t2, t2, base, base, tbot, tbot, base, base, t2, t2, t1, t1]\n",
    "    return list(zip(x, y))\n",
    "\n",
    "TREE_TEMPLATE = make_tree_polygon()\n",
    "\n",
    "def get_tree_polygon(x, y, deg):\n",
    "    poly = Polygon(TREE_TEMPLATE)\n",
    "    poly = rotate(poly, deg, origin=(0, 0))\n",
    "    poly = translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def score_group(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        r = math.radians(degs[i])\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        for tx, ty in TREE_TEMPLATE:\n",
    "            X = c * tx - s * ty + xs[i]\n",
    "            Y = s * tx + c * ty + ys[i]\n",
    "            all_x.append(X)\n",
    "            all_y.append(Y)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side * side / n\n",
    "\n",
    "def check_overlaps(xs, ys, degs):\n",
    "    n = len(xs)\n",
    "    polys = [get_tree_polygon(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if polys[i].intersects(polys[j]) and not polys[i].touches(polys[j]):\n",
    "                inter = polys[i].intersection(polys[j])\n",
    "                if inter.area > 1e-10:  # Significant overlap\n",
    "                    return True, f\"Trees {i} and {j} overlap (area={inter.area})\"\n",
    "    return False, \"OK\"\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0394c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ALL CSV files in preoptimized folder\n",
    "preopt_base = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/'\n",
    "\n",
    "preopt_files = []\n",
    "for root, dirs, files in os.walk(preopt_base):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            preopt_files.append(os.path.join(root, f))\n",
    "\n",
    "print(f\"Found {len(preopt_files)} preoptimized CSV files\")\n",
    "for f in preopt_files[:20]:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ed06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score each preoptimized file\n",
    "def strip_s(val):\n",
    "    s = str(val)\n",
    "    return float(s[1:] if s.startswith('s') else s)\n",
    "\n",
    "def load_and_score_csv(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None, None\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        \n",
    "        scores = {}\n",
    "        for n, g in df.groupby('N'):\n",
    "            if n < 1 or n > 200:\n",
    "                continue\n",
    "            xs = [strip_s(v) for v in g['x'].values]\n",
    "            ys = [strip_s(v) for v in g['y'].values]\n",
    "            ds = [strip_s(v) for v in g['deg'].values]\n",
    "            scores[n] = score_group(xs, ys, ds)\n",
    "        \n",
    "        total = sum(scores.values())\n",
    "        return total, scores\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "# Score all preoptimized files\n",
    "preopt_scores = {}\n",
    "for fp in tqdm(preopt_files, desc=\"Scoring preoptimized\"):\n",
    "    total, per_n = load_and_score_csv(fp)\n",
    "    if total is not None:\n",
    "        preopt_scores[fp] = {'total': total, 'per_n': per_n}\n",
    "\n",
    "print(f\"\\nScored {len(preopt_scores)} files\")\n",
    "\n",
    "# Sort by total score\n",
    "sorted_preopt = sorted(preopt_scores.items(), key=lambda x: x[1]['total'])\n",
    "print(\"\\nTop 10 preoptimized solutions:\")\n",
    "for fp, data in sorted_preopt[:10]:\n",
    "    print(f\"  {data['total']:.6f}: {os.path.basename(fp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d47266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build the BEST ensemble from ALL sources\n",
    "# 1. Load all snapshot submissions\n",
    "# 2. Load all preoptimized files\n",
    "# 3. For each N, find the best VALID solution\n",
    "\n",
    "# First, let's load the current valid baseline\n",
    "valid_baseline_path = '/home/nonroot/snapshots/santa-2025/21328309254/submission/submission.csv'\n",
    "baseline_df = pd.read_csv(valid_baseline_path)\n",
    "baseline_df['N'] = baseline_df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "\n",
    "baseline_per_n = {}\n",
    "for n, g in baseline_df.groupby('N'):\n",
    "    xs = [strip_s(v) for v in g['x'].values]\n",
    "    ys = [strip_s(v) for v in g['y'].values]\n",
    "    ds = [strip_s(v) for v in g['deg'].values]\n",
    "    baseline_per_n[n] = {\n",
    "        'score': score_group(xs, ys, ds),\n",
    "        'data': g.drop(columns=['N']).copy(),\n",
    "        'source': 'valid_baseline'\n",
    "    }\n",
    "\n",
    "print(f\"Baseline total: {sum(d['score'] for d in baseline_per_n.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build best-per-N from ALL sources (including preoptimized)\n",
    "best_per_n = {n: baseline_per_n[n].copy() for n in range(1, 201)}\n",
    "\n",
    "# Add preoptimized solutions\n",
    "for fp, data in tqdm(preopt_scores.items(), desc=\"Processing preoptimized\"):\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "        \n",
    "        for n, g in df.groupby('N'):\n",
    "            if n < 1 or n > 200:\n",
    "                continue\n",
    "            xs = [strip_s(v) for v in g['x'].values]\n",
    "            ys = [strip_s(v) for v in g['y'].values]\n",
    "            ds = [strip_s(v) for v in g['deg'].values]\n",
    "            score = score_group(xs, ys, ds)\n",
    "            \n",
    "            if score < best_per_n[n]['score']:\n",
    "                best_per_n[n] = {\n",
    "                    'score': score,\n",
    "                    'data': g.drop(columns=['N']).copy(),\n",
    "                    'source': os.path.basename(fp)\n",
    "                }\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Calculate total score (ignoring overlaps for now)\n",
    "total_best = sum(d['score'] for d in best_per_n.values())\n",
    "print(f\"\\nBest ensemble (ignoring overlaps): {total_best:.6f}\")\n",
    "print(f\"Improvement from baseline: {sum(d['score'] for d in baseline_per_n.values()) - total_best:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check which solutions have overlaps\n",
    "print(\"Checking for overlaps in best solutions...\")\n",
    "\n",
    "overlap_ns = []\n",
    "for n in tqdm(range(1, 201), desc=\"Checking overlaps\"):\n",
    "    g = best_per_n[n]['data']\n",
    "    xs = [strip_s(v) for v in g['x'].values]\n",
    "    ys = [strip_s(v) for v in g['y'].values]\n",
    "    ds = [strip_s(v) for v in g['deg'].values]\n",
    "    \n",
    "    has_overlap, msg = check_overlaps(xs, ys, ds)\n",
    "    if has_overlap:\n",
    "        overlap_ns.append(n)\n",
    "        # Revert to baseline\n",
    "        best_per_n[n] = baseline_per_n[n].copy()\n",
    "\n",
    "print(f\"\\nFound {len(overlap_ns)} N values with overlaps: {overlap_ns[:20]}...\")\n",
    "\n",
    "# Calculate valid total\n",
    "valid_total = sum(d['score'] for d in best_per_n.values())\n",
    "print(f\"\\nValid ensemble score: {valid_total:.6f}\")\n",
    "print(f\"Improvement from baseline: {sum(d['score'] for d in baseline_per_n.values()) - valid_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override N=1 with optimal value (from jonathanchan kernel)\n",
    "# x=0, y=0, deg=45 gives score 0.6612499...\n",
    "optimal_n1 = pd.DataFrame({\n",
    "    'id': ['001_0'],\n",
    "    'x': ['s0.0'],\n",
    "    'y': ['s0.0'],\n",
    "    'deg': ['s45.0']\n",
    "})\n",
    "\n",
    "xs = [strip_s(v) for v in optimal_n1['x'].values]\n",
    "ys = [strip_s(v) for v in optimal_n1['y'].values]\n",
    "ds = [strip_s(v) for v in optimal_n1['deg'].values]\n",
    "n1_score = score_group(xs, ys, ds)\n",
    "\n",
    "print(f\"Optimal N=1 score: {n1_score:.10f}\")\n",
    "print(f\"Current N=1 score: {best_per_n[1]['score']:.10f}\")\n",
    "\n",
    "if n1_score < best_per_n[1]['score']:\n",
    "    print(f\"Improvement: {best_per_n[1]['score'] - n1_score:.10f}\")\n",
    "    best_per_n[1] = {\n",
    "        'score': n1_score,\n",
    "        'data': optimal_n1.copy(),\n",
    "        'source': 'optimal_n1'\n",
    "    }\n",
    "\n",
    "# Final score\n",
    "final_total = sum(d['score'] for d in best_per_n.values())\n",
    "print(f\"\\nFinal ensemble score: {final_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5526d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which sources contributed\n",
    "source_counts = {}\n",
    "for n in range(1, 201):\n",
    "    src = best_per_n[n]['source']\n",
    "    source_counts[src] = source_counts.get(src, 0) + 1\n",
    "\n",
    "print(\"Sources contributing to ensemble:\")\n",
    "for src, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {src}: {count} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c01d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final submission\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    rows.append(best_per_n[n]['data'])\n",
    "\n",
    "final_df = pd.concat(rows, ignore_index=True)\n",
    "final_df['sn'] = final_df['id'].str.split('_').str[0].astype(int)\n",
    "final_df['si'] = final_df['id'].str.split('_').str[1].astype(int)\n",
    "final_df = final_df.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "final_df = final_df[['id', 'x', 'y', 'deg']]\n",
    "\n",
    "print(f\"Final submission shape: {final_df.shape}\")\n",
    "print(f\"Expected: (20100, 4)\")\n",
    "\n",
    "# Save\n",
    "os.makedirs('/home/code/experiments/005_comprehensive_ensemble', exist_ok=True)\n",
    "final_df.to_csv('/home/code/experiments/005_comprehensive_ensemble/submission.csv', index=False)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': final_total,\n",
    "    'baseline_score': sum(d['score'] for d in baseline_per_n.values()),\n",
    "    'improvement': sum(d['score'] for d in baseline_per_n.values()) - final_total,\n",
    "    'target': 68.888293,\n",
    "    'gap': final_total - 68.888293,\n",
    "    'num_sources': len(source_counts),\n",
    "    'overlap_ns_reverted': len(overlap_ns)\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/005_comprehensive_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ac6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation - check ALL N values for overlaps\n",
    "print(\"Final validation - checking all N values...\")\n",
    "\n",
    "final_overlaps = []\n",
    "for n in tqdm(range(1, 201), desc=\"Final validation\"):\n",
    "    g = best_per_n[n]['data']\n",
    "    xs = [strip_s(v) for v in g['x'].values]\n",
    "    ys = [strip_s(v) for v in g['y'].values]\n",
    "    ds = [strip_s(v) for v in g['deg'].values]\n",
    "    \n",
    "    has_overlap, msg = check_overlaps(xs, ys, ds)\n",
    "    if has_overlap:\n",
    "        final_overlaps.append((n, msg))\n",
    "\n",
    "if final_overlaps:\n",
    "    print(f\"\\nWARNING: {len(final_overlaps)} N values still have overlaps!\")\n",
    "    for n, msg in final_overlaps[:10]:\n",
    "        print(f\"  N={n}: {msg}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All N values pass overlap validation!\")\n",
    "    print(f\"\\nFinal score: {final_total:.6f}\")\n",
    "    print(f\"Gap to target: {final_total - 68.888293:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
