{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064f1b24",
   "metadata": {},
   "source": [
    "# Experiment 007: Fixed Prefix Ensemble\n",
    "\n",
    "Fix the 's' prefix issue - ensure ALL values have 's' prefix when writing output.\n",
    "Also implement fractional translation for additional improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.ops import unary_union\n",
    "from glob import glob\n",
    "import json\n",
    "import math\n",
    "\n",
    "print(\"Imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6aca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree geometry\n",
    "def get_tree_polygon():\n",
    "    vertices = [\n",
    "        (0.0, 0.8), (0.125, 0.5), (0.0625, 0.5),\n",
    "        (0.2, 0.25), (0.1, 0.25), (0.35, 0.0),\n",
    "        (0.075, 0.0), (0.075, -0.2), (-0.075, -0.2),\n",
    "        (-0.075, 0.0), (-0.35, 0.0), (-0.1, 0.25),\n",
    "        (-0.2, 0.25), (-0.0625, 0.5), (-0.125, 0.5),\n",
    "    ]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "TREE_POLY = get_tree_polygon()\n",
    "print(f\"Tree: {len(TREE_POLY.exterior.coords)} vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca64012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_s(s_val):\n",
    "    \"\"\"Parse s-prefixed value to float for scoring.\"\"\"\n",
    "    if isinstance(s_val, str):\n",
    "        if s_val.startswith('s'):\n",
    "            return float(s_val[1:])\n",
    "        return float(s_val)\n",
    "    return float(s_val)\n",
    "\n",
    "def format_s(val):\n",
    "    \"\"\"Format value with 's' prefix.\"\"\"\n",
    "    return f's{val}'\n",
    "\n",
    "def create_tree(x, y, deg):\n",
    "    return translate(rotate(TREE_POLY, deg, origin=(0, 0)), x, y)\n",
    "\n",
    "def get_bbox_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    combined = unary_union(polygons)\n",
    "    bounds = combined.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "def check_overlaps_zero_tol(polygons):\n",
    "    \"\"\"Check for ANY overlap, no matter how small.\"\"\"\n",
    "    if len(polygons) <= 1:\n",
    "        return False, None\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]):\n",
    "                if not polygons[i].touches(polygons[j]):\n",
    "                    try:\n",
    "                        inter = polygons[i].intersection(polygons[j])\n",
    "                        if inter.area > 0:\n",
    "                            return True, f\"Trees {i},{j} overlap (area={inter.area:.2e})\"\n",
    "                    except:\n",
    "                        return True, f\"Trees {i},{j} error\"\n",
    "    return False, None\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission(path):\n",
    "    \"\"\"Load CSV and parse values to floats.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        if 'x' not in df.columns:\n",
    "            return None\n",
    "        df['x_float'] = df['x'].apply(parse_s)\n",
    "        df['y_float'] = df['y'].apply(parse_s)\n",
    "        df['deg_float'] = df['deg'].apply(parse_s)\n",
    "        df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "        return df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"Load function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d43972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VALID baseline (this PASSED Kaggle validation)\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21328309254/submission/submission.csv'\n",
    "baseline_df = load_submission(baseline_path)\n",
    "print(f\"Loaded baseline: {len(baseline_df)} rows\")\n",
    "\n",
    "# Compute baseline scores and store data\n",
    "baseline_scores = {}\n",
    "baseline_data = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    n_df = baseline_df[baseline_df['n'] == n]\n",
    "    if len(n_df) != n:\n",
    "        print(f\"ERROR: N={n}\")\n",
    "        continue\n",
    "    \n",
    "    xs = n_df['x_float'].tolist()\n",
    "    ys = n_df['y_float'].tolist()\n",
    "    degs = n_df['deg_float'].tolist()\n",
    "    \n",
    "    polygons = [create_tree(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    side = get_bbox_side(polygons)\n",
    "    score = (side ** 2) / n\n",
    "    \n",
    "    baseline_scores[n] = score\n",
    "    baseline_data[n] = {'xs': xs, 'ys': ys, 'degs': degs}\n",
    "\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "print(f\"Baseline total: {baseline_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all submission files\n",
    "csv_files = glob('/home/nonroot/snapshots/santa-2025/*/submission/submission.csv')\n",
    "print(f\"Found {len(csv_files)} submission files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67cce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble - store FLOAT values, not strings\n",
    "best_per_n = {n: {\n",
    "    'score': baseline_scores[n],\n",
    "    'data': baseline_data[n],\n",
    "    'source': 'baseline'\n",
    "} for n in range(1, 201)}\n",
    "\n",
    "improvement_count = 0\n",
    "\n",
    "for idx, csv_path in enumerate(csv_files):\n",
    "    if idx % 20 == 0:\n",
    "        print(f\"Processing {idx+1}/{len(csv_files)}...\")\n",
    "    \n",
    "    df = load_submission(csv_path)\n",
    "    if df is None:\n",
    "        continue\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        n_df = df[df['n'] == n]\n",
    "        if len(n_df) != n:\n",
    "            continue\n",
    "        \n",
    "        xs = n_df['x_float'].tolist()\n",
    "        ys = n_df['y_float'].tolist()\n",
    "        degs = n_df['deg_float'].tolist()\n",
    "        \n",
    "        try:\n",
    "            polygons = [create_tree(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "            side = get_bbox_side(polygons)\n",
    "            score = (side ** 2) / n\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Only consider if better\n",
    "        if score >= best_per_n[n]['score']:\n",
    "            continue\n",
    "        \n",
    "        # ZERO tolerance overlap check\n",
    "        has_overlap, msg = check_overlaps_zero_tol(polygons)\n",
    "        if has_overlap:\n",
    "            continue\n",
    "        \n",
    "        # Valid improvement - store FLOAT values\n",
    "        improvement = best_per_n[n]['score'] - score\n",
    "        if improvement > 0.001:\n",
    "            print(f\"  N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} ({improvement:.6f})\")\n",
    "        \n",
    "        best_per_n[n] = {\n",
    "            'score': score,\n",
    "            'data': {'xs': xs, 'ys': ys, 'degs': degs},\n",
    "            'source': csv_path\n",
    "        }\n",
    "        improvement_count += 1\n",
    "\n",
    "print(f\"\\nFound {improvement_count} valid improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble score before fractional translation\n",
    "ensemble_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "improvement = baseline_total - ensemble_total\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Baseline: {baseline_total:.6f}\")\n",
    "print(f\"Ensemble (before frac trans): {ensemble_total:.6f}\")\n",
    "print(f\"Improvement: {improvement:.6f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement fractional translation\n",
    "def fractional_translation(xs, ys, degs, n, max_iter=100):\n",
    "    \"\"\"Apply fractional translation to improve score.\"\"\"\n",
    "    frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "    \n",
    "    best_xs = xs.copy()\n",
    "    best_ys = ys.copy()\n",
    "    \n",
    "    polygons = [create_tree(best_xs[i], best_ys[i], degs[i]) for i in range(n)]\n",
    "    best_score = (get_bbox_side(polygons) ** 2) / n\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        improved = False\n",
    "        for tree_idx in range(n):\n",
    "            for step in frac_steps:\n",
    "                for dx, dy in directions:\n",
    "                    new_xs = best_xs.copy()\n",
    "                    new_ys = best_ys.copy()\n",
    "                    new_xs[tree_idx] += dx * step\n",
    "                    new_ys[tree_idx] += dy * step\n",
    "                    \n",
    "                    # Create polygons and check\n",
    "                    try:\n",
    "                        new_polygons = [create_tree(new_xs[i], new_ys[i], degs[i]) for i in range(n)]\n",
    "                        has_overlap, _ = check_overlaps_zero_tol(new_polygons)\n",
    "                        if has_overlap:\n",
    "                            continue\n",
    "                        \n",
    "                        new_score = (get_bbox_side(new_polygons) ** 2) / n\n",
    "                        if new_score < best_score - 1e-12:\n",
    "                            best_xs = new_xs\n",
    "                            best_ys = new_ys\n",
    "                            best_score = new_score\n",
    "                            improved = True\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        if not improved:\n",
    "            break\n",
    "    \n",
    "    return best_xs, best_ys, best_score\n",
    "\n",
    "print(\"Fractional translation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fractional translation to all N values\n",
    "print(\"Applying fractional translation...\")\n",
    "frac_improvements = 0\n",
    "\n",
    "for n in range(1, 201):\n",
    "    if n % 20 == 0:\n",
    "        print(f\"  Processing N={n}...\")\n",
    "    \n",
    "    data = best_per_n[n]['data']\n",
    "    xs = data['xs'].copy() if isinstance(data['xs'], list) else list(data['xs'])\n",
    "    ys = data['ys'].copy() if isinstance(data['ys'], list) else list(data['ys'])\n",
    "    degs = data['degs'].copy() if isinstance(data['degs'], list) else list(data['degs'])\n",
    "    \n",
    "    old_score = best_per_n[n]['score']\n",
    "    \n",
    "    # Apply fractional translation (limit iterations for speed)\n",
    "    new_xs, new_ys, new_score = fractional_translation(xs, ys, degs, n, max_iter=50)\n",
    "    \n",
    "    if new_score < old_score - 1e-10:\n",
    "        improvement = old_score - new_score\n",
    "        if improvement > 0.0001:\n",
    "            print(f\"    N={n}: {old_score:.8f} -> {new_score:.8f} ({improvement:.8f})\")\n",
    "        best_per_n[n]['data'] = {'xs': new_xs, 'ys': new_ys, 'degs': degs}\n",
    "        best_per_n[n]['score'] = new_score\n",
    "        frac_improvements += 1\n",
    "\n",
    "print(f\"\\nFractional translation improved {frac_improvements} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final score\n",
    "final_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "frac_improvement = ensemble_total - final_total\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Baseline: {baseline_total:.6f}\")\n",
    "print(f\"After ensemble: {ensemble_total:.6f}\")\n",
    "print(f\"After frac trans: {final_total:.6f}\")\n",
    "print(f\"Frac trans improvement: {frac_improvement:.6f}\")\n",
    "print(f\"Total improvement: {baseline_total - final_total:.6f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\nTarget: 68.888293\")\n",
    "print(f\"Gap: {final_total - 68.888293:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1eda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation\n",
    "print(\"\\nFinal validation (ZERO tolerance)...\")\n",
    "all_valid = True\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    polygons = [create_tree(data['xs'][i], data['ys'][i], data['degs'][i]) for i in range(n)]\n",
    "    has_overlap, msg = check_overlaps_zero_tol(polygons)\n",
    "    if has_overlap:\n",
    "        print(f\"OVERLAP at N={n}: {msg}\")\n",
    "        all_valid = False\n",
    "        # Fall back to baseline\n",
    "        best_per_n[n] = {\n",
    "            'score': baseline_scores[n],\n",
    "            'data': baseline_data[n],\n",
    "            'source': 'fallback'\n",
    "        }\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All 200 configurations VALID!\")\n",
    "else:\n",
    "    final_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "    print(f\"After fallbacks: {final_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission with PROPER 's' prefix formatting\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    for i in range(n):\n",
    "        rows.append({\n",
    "            'id': f'{n:03d}_{i}',\n",
    "            'x': format_s(data['xs'][i]),  # Always add 's' prefix!\n",
    "            'y': format_s(data['ys'][i]),\n",
    "            'deg': format_s(data['degs'][i])\n",
    "        })\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv('/home/code/experiments/007_fixed_prefix_ensemble/submission.csv', index=False)\n",
    "df_out.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved {len(df_out)} rows\")\n",
    "\n",
    "# Verify output format\n",
    "print(\"\\nFirst 5 rows of output:\")\n",
    "print(df_out.head())\n",
    "\n",
    "# Verify N=17 has 's' prefix\n",
    "n17 = df_out[df_out['id'].str.startswith('017_')]\n",
    "print(f\"\\nN=17 sample:\")\n",
    "print(n17.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': final_total,\n",
    "    'baseline_score': baseline_total,\n",
    "    'ensemble_score': ensemble_total,\n",
    "    'frac_trans_improvement': frac_improvement,\n",
    "    'total_improvement': baseline_total - final_total,\n",
    "    'target': 68.888293,\n",
    "    'gap': final_total - 68.888293\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/007_fixed_prefix_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
