{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c681a6",
   "metadata": {},
   "source": [
    "# Experiment 005: Strict Ensemble with 1e-15 Overlap Threshold\n",
    "\n",
    "exp_004 failed on Kaggle with overlaps in group 002. We need stricter overlap validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.ops import unary_union\n",
    "from shapely.strtree import STRtree\n",
    "from decimal import Decimal, getcontext\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "getcontext().prec = 30\n",
    "\n",
    "print(\"Imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree geometry\n",
    "def get_tree_polygon():\n",
    "    trunk_w, trunk_h = Decimal('0.15'), Decimal('0.2')\n",
    "    base_w, mid_w, top_w = Decimal('0.7'), Decimal('0.4'), Decimal('0.25')\n",
    "    tip_y, tier_1_y, tier_2_y, base_y = Decimal('0.8'), Decimal('0.5'), Decimal('0.25'), Decimal('0.0')\n",
    "    trunk_bottom_y = -trunk_h\n",
    "    vertices = [\n",
    "        (float(Decimal('0.0')), float(tip_y)),\n",
    "        (float(top_w / Decimal('2')), float(tier_1_y)),\n",
    "        (float(top_w / Decimal('4')), float(tier_1_y)),\n",
    "        (float(mid_w / Decimal('2')), float(tier_2_y)),\n",
    "        (float(mid_w / Decimal('4')), float(tier_2_y)),\n",
    "        (float(base_w / Decimal('2')), float(base_y)),\n",
    "        (float(trunk_w / Decimal('2')), float(base_y)),\n",
    "        (float(trunk_w / Decimal('2')), float(trunk_bottom_y)),\n",
    "        (float(-(trunk_w / Decimal('2'))), float(trunk_bottom_y)),\n",
    "        (float(-(trunk_w / Decimal('2'))), float(base_y)),\n",
    "        (float(-(base_w / Decimal('2'))), float(base_y)),\n",
    "        (float(-(mid_w / Decimal('4'))), float(tier_2_y)),\n",
    "        (float(-(mid_w / Decimal('2'))), float(tier_2_y)),\n",
    "        (float(-(top_w / Decimal('4'))), float(tier_1_y)),\n",
    "        (float(-(top_w / Decimal('2'))), float(tier_1_y)),\n",
    "    ]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "TREE_POLY = get_tree_polygon()\n",
    "print(f\"Tree polygon: {len(TREE_POLY.exterior.coords)} vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c3401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_s_value(s_val):\n",
    "    if isinstance(s_val, str) and s_val.startswith('s'):\n",
    "        return float(s_val[1:])\n",
    "    return float(s_val)\n",
    "\n",
    "def create_tree(x, y, deg):\n",
    "    return translate(rotate(TREE_POLY, deg, origin=(0, 0)), x, y)\n",
    "\n",
    "def get_bbox_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    combined = unary_union(polygons)\n",
    "    bounds = combined.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "# STRICT overlap check - use 1e-15 threshold (stricter than before)\n",
    "def check_overlaps_strict(polygons, tolerance=1e-15):\n",
    "    \"\"\"Check for overlaps with STRICT tolerance.\"\"\"\n",
    "    if len(polygons) <= 1:\n",
    "        return False, None\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]):\n",
    "                if not polygons[i].touches(polygons[j]):\n",
    "                    intersection = polygons[i].intersection(polygons[j])\n",
    "                    if intersection.area > tolerance:\n",
    "                        return True, f\"Trees {i} and {j} overlap (area={intersection.area:.2e})\"\n",
    "    return False, None\n",
    "\n",
    "print(\"Functions defined with STRICT overlap check (1e-15 threshold)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32024f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission(path):\n",
    "    \"\"\"Load submission CSV and extract per-N data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if 'x' not in df.columns or 'y' not in df.columns or 'deg' not in df.columns:\n",
    "            return None\n",
    "        df['x_val'] = df['x'].apply(parse_s_value)\n",
    "        df['y_val'] = df['y'].apply(parse_s_value)\n",
    "        df['deg_val'] = df['deg'].apply(parse_s_value)\n",
    "        df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "        return df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_n_data(df, n):\n",
    "    \"\"\"Get data for a specific N value.\"\"\"\n",
    "    n_df = df[df['n'] == n]\n",
    "    if len(n_df) != n:\n",
    "        return None\n",
    "    return {\n",
    "        'xs': n_df['x_val'].tolist(),\n",
    "        'ys': n_df['y_val'].tolist(),\n",
    "        'degs': n_df['deg_val'].tolist(),\n",
    "        'x_strs': n_df['x'].tolist(),\n",
    "        'y_strs': n_df['y'].tolist(),\n",
    "        'deg_strs': n_df['deg'].tolist()\n",
    "    }\n",
    "\n",
    "def compute_n_score(xs, ys, degs):\n",
    "    \"\"\"Compute score for N trees.\"\"\"\n",
    "    n = len(xs)\n",
    "    polygons = [create_tree(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    side = get_bbox_side(polygons)\n",
    "    return (side ** 2) / n, polygons\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VALID baseline (this passed Kaggle validation)\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21328309254/submission/submission.csv'\n",
    "baseline_df = load_submission(baseline_path)\n",
    "print(f\"Loaded baseline: {len(baseline_df)} rows\")\n",
    "\n",
    "# Compute baseline scores for each N\n",
    "baseline_scores = {}\n",
    "baseline_data = {}\n",
    "for n in range(1, 201):\n",
    "    data = get_n_data(baseline_df, n)\n",
    "    if data:\n",
    "        score, _ = compute_n_score(data['xs'], data['ys'], data['degs'])\n",
    "        baseline_scores[n] = score\n",
    "        baseline_data[n] = data\n",
    "\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "print(f\"Baseline total score: {baseline_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eaa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all CSV files in snapshots\n",
    "csv_files = glob('/home/nonroot/snapshots/santa-2025/*/submission/submission.csv')\n",
    "csv_files += glob('/home/nonroot/snapshots/santa-2025/*/code/*.csv')\n",
    "csv_files += glob('/home/nonroot/snapshots/santa-2025/*/code/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(csv_files)} CSV files to scan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N, find the best STRICTLY VALID solution\n",
    "best_per_n = {}  # n -> {'score': float, 'data': dict, 'source': str}\n",
    "\n",
    "# Initialize with baseline (known to be valid)\n",
    "for n in range(1, 201):\n",
    "    best_per_n[n] = {\n",
    "        'score': baseline_scores[n],\n",
    "        'data': baseline_data[n],\n",
    "        'source': 'baseline'\n",
    "    }\n",
    "\n",
    "print(\"Initialized with baseline. Now scanning for improvements...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "improvement_count = 0\n",
    "files_processed = 0\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = load_submission(csv_path)\n",
    "    if df is None:\n",
    "        continue\n",
    "    \n",
    "    files_processed += 1\n",
    "    if files_processed % 100 == 0:\n",
    "        print(f\"Processed {files_processed} files...\")\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        data = get_n_data(df, n)\n",
    "        if data is None:\n",
    "            continue\n",
    "        \n",
    "        # Compute score\n",
    "        score, polygons = compute_n_score(data['xs'], data['ys'], data['degs'])\n",
    "        \n",
    "        # Only consider if better than current best\n",
    "        if score >= best_per_n[n]['score']:\n",
    "            continue\n",
    "        \n",
    "        # STRICT overlap check\n",
    "        has_overlap, msg = check_overlaps_strict(polygons)\n",
    "        if has_overlap:\n",
    "            continue\n",
    "        \n",
    "        # Found a valid improvement!\n",
    "        improvement = best_per_n[n]['score'] - score\n",
    "        if improvement > 0.0001:  # Only report significant improvements\n",
    "            print(f\"N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} (improvement: {improvement:.6f})\")\n",
    "        \n",
    "        best_per_n[n] = {\n",
    "            'score': score,\n",
    "            'data': data,\n",
    "            'source': csv_path\n",
    "        }\n",
    "        improvement_count += 1\n",
    "\n",
    "print(f\"\\nProcessed {files_processed} files\")\n",
    "print(f\"Found {improvement_count} valid improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final ensemble score\n",
    "ensemble_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "improvement = baseline_total - ensemble_total\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Baseline score:  {baseline_total:.6f}\")\n",
    "print(f\"Ensemble score:  {ensemble_total:.6f}\")\n",
    "print(f\"Improvement:     {improvement:.6f}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTarget: 68.888293\")\n",
    "print(f\"Gap to target: {ensemble_total - 68.888293:.6f}\")\n",
    "\n",
    "# Count sources used\n",
    "sources = {}\n",
    "for n in range(1, 201):\n",
    "    src = best_per_n[n]['source']\n",
    "    if src not in sources:\n",
    "        sources[src] = []\n",
    "    sources[src].append(n)\n",
    "\n",
    "print(f\"\\nSources used: {len(sources)}\")\n",
    "for src, ns in sorted(sources.items(), key=lambda x: -len(x[1]))[:5]:\n",
    "    print(f\"  {src.split('/')[-3] if 'snapshots' in src else src}: {len(ns)} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2452c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL VALIDATION: Check ALL N values with strict overlap check\n",
    "print(\"\\nFinal validation of entire ensemble...\")\n",
    "all_valid = True\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    polygons = [create_tree(data['xs'][i], data['ys'][i], data['degs'][i]) for i in range(n)]\n",
    "    has_overlap, msg = check_overlaps_strict(polygons)\n",
    "    if has_overlap:\n",
    "        print(f\"OVERLAP at N={n}: {msg}\")\n",
    "        all_valid = False\n",
    "        # Replace with baseline\n",
    "        best_per_n[n] = {\n",
    "            'score': baseline_scores[n],\n",
    "            'data': baseline_data[n],\n",
    "            'source': 'baseline_fallback'\n",
    "        }\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All 200 configurations pass strict overlap validation!\")\n",
    "else:\n",
    "    # Recompute score after fallbacks\n",
    "    ensemble_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "    print(f\"\\nAfter fallbacks, ensemble score: {ensemble_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "print(\"\\nSaving submission...\")\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    for i in range(n):\n",
    "        rows.append({\n",
    "            'id': f'{n:03d}_{i}',\n",
    "            'x': data['x_strs'][i],\n",
    "            'y': data['y_strs'][i],\n",
    "            'deg': data['deg_strs'][i]\n",
    "        })\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv('/home/code/experiments/005_strict_ensemble/submission.csv', index=False)\n",
    "df_out.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved {len(df_out)} rows\")\n",
    "print(f\"First 5 rows:\")\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': ensemble_total,\n",
    "    'baseline_score': baseline_total,\n",
    "    'improvement': baseline_total - ensemble_total,\n",
    "    'target': 68.888293,\n",
    "    'gap': ensemble_total - 68.888293,\n",
    "    'sources_used': len(sources),\n",
    "    'overlap_threshold': 1e-15\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/005_strict_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics saved: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
