{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece8ec0d",
   "metadata": {},
   "source": [
    "# Experiment 006: Preserved Precision Ensemble\n",
    "\n",
    "Fix the coordinate truncation bug by preserving ORIGINAL string values from source CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b909c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.ops import unary_union\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "print(\"Imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree geometry\n",
    "def get_tree_polygon():\n",
    "    vertices = [\n",
    "        (0.0, 0.8), (0.125, 0.5), (0.0625, 0.5),\n",
    "        (0.2, 0.25), (0.1, 0.25), (0.35, 0.0),\n",
    "        (0.075, 0.0), (0.075, -0.2), (-0.075, -0.2),\n",
    "        (-0.075, 0.0), (-0.35, 0.0), (-0.1, 0.25),\n",
    "        (-0.2, 0.25), (-0.0625, 0.5), (-0.125, 0.5),\n",
    "    ]\n",
    "    return Polygon(vertices)\n",
    "\n",
    "TREE_POLY = get_tree_polygon()\n",
    "print(f\"Tree: {len(TREE_POLY.exterior.coords)} vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b149e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_s(s_val):\n",
    "    \"\"\"Parse s-prefixed value to float for scoring.\"\"\"\n",
    "    if isinstance(s_val, str) and s_val.startswith('s'):\n",
    "        return float(s_val[1:])\n",
    "    return float(s_val)\n",
    "\n",
    "def create_tree(x, y, deg):\n",
    "    return translate(rotate(TREE_POLY, deg, origin=(0, 0)), x, y)\n",
    "\n",
    "def get_bbox_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    combined = unary_union(polygons)\n",
    "    bounds = combined.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "def check_overlaps_zero_tol(polygons):\n",
    "    \"\"\"Check for ANY overlap, no matter how small.\"\"\"\n",
    "    if len(polygons) <= 1:\n",
    "        return False, None\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]):\n",
    "                if not polygons[i].touches(polygons[j]):\n",
    "                    try:\n",
    "                        inter = polygons[i].intersection(polygons[j])\n",
    "                        if inter.area > 0:\n",
    "                            return True, f\"Trees {i},{j} overlap (area={inter.area:.2e})\"\n",
    "                    except:\n",
    "                        return True, f\"Trees {i},{j} error\"\n",
    "    return False, None\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb039383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission_preserve_strings(path):\n",
    "    \"\"\"Load CSV and preserve ORIGINAL string values.\"\"\"\n",
    "    try:\n",
    "        # Load as strings to preserve precision\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        if 'x' not in df.columns:\n",
    "            return None\n",
    "        # Parse floats for scoring only\n",
    "        df['x_float'] = df['x'].apply(parse_s)\n",
    "        df['y_float'] = df['y'].apply(parse_s)\n",
    "        df['deg_float'] = df['deg'].apply(parse_s)\n",
    "        df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "        return df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"Load function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2228229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VALID baseline (this PASSED Kaggle validation)\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21328309254/submission/submission.csv'\n",
    "baseline_df = load_submission_preserve_strings(baseline_path)\n",
    "print(f\"Loaded baseline: {len(baseline_df)} rows\")\n",
    "\n",
    "# Verify N=2 precision is preserved\n",
    "n2 = baseline_df[baseline_df['n'] == 2]\n",
    "print(f\"\\nN=2 from baseline (original strings):\")\n",
    "print(f\"  x[0] = {n2['x'].iloc[0]}\")\n",
    "print(f\"  y[0] = {n2['y'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline scores and store data with ORIGINAL strings\n",
    "baseline_scores = {}\n",
    "baseline_data = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    n_df = baseline_df[baseline_df['n'] == n]\n",
    "    if len(n_df) != n:\n",
    "        print(f\"ERROR: N={n}\")\n",
    "        continue\n",
    "    \n",
    "    xs = n_df['x_float'].tolist()\n",
    "    ys = n_df['y_float'].tolist()\n",
    "    degs = n_df['deg_float'].tolist()\n",
    "    \n",
    "    polygons = [create_tree(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "    side = get_bbox_side(polygons)\n",
    "    score = (side ** 2) / n\n",
    "    \n",
    "    baseline_scores[n] = score\n",
    "    baseline_data[n] = {\n",
    "        'xs': xs, 'ys': ys, 'degs': degs,\n",
    "        # CRITICAL: Store ORIGINAL strings\n",
    "        'x_strs': n_df['x'].tolist(),\n",
    "        'y_strs': n_df['y'].tolist(),\n",
    "        'deg_strs': n_df['deg'].tolist()\n",
    "    }\n",
    "\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "print(f\"Baseline total: {baseline_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find submission files\n",
    "csv_files = glob('/home/nonroot/snapshots/santa-2025/*/submission/submission.csv')\n",
    "print(f\"Found {len(csv_files)} submission files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8997cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ensemble with PRESERVED precision\n",
    "best_per_n = {n: {\n",
    "    'score': baseline_scores[n],\n",
    "    'data': baseline_data[n],\n",
    "    'source': 'baseline'\n",
    "} for n in range(1, 201)}\n",
    "\n",
    "improvement_count = 0\n",
    "\n",
    "for idx, csv_path in enumerate(csv_files):\n",
    "    if idx % 20 == 0:\n",
    "        print(f\"Processing {idx+1}/{len(csv_files)}...\")\n",
    "    \n",
    "    df = load_submission_preserve_strings(csv_path)\n",
    "    if df is None:\n",
    "        continue\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        n_df = df[df['n'] == n]\n",
    "        if len(n_df) != n:\n",
    "            continue\n",
    "        \n",
    "        xs = n_df['x_float'].tolist()\n",
    "        ys = n_df['y_float'].tolist()\n",
    "        degs = n_df['deg_float'].tolist()\n",
    "        \n",
    "        try:\n",
    "            polygons = [create_tree(xs[i], ys[i], degs[i]) for i in range(n)]\n",
    "            side = get_bbox_side(polygons)\n",
    "            score = (side ** 2) / n\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Only consider if better\n",
    "        if score >= best_per_n[n]['score']:\n",
    "            continue\n",
    "        \n",
    "        # ZERO tolerance overlap check\n",
    "        has_overlap, msg = check_overlaps_zero_tol(polygons)\n",
    "        if has_overlap:\n",
    "            continue\n",
    "        \n",
    "        # Valid improvement - store with ORIGINAL strings\n",
    "        improvement = best_per_n[n]['score'] - score\n",
    "        if improvement > 0.001:\n",
    "            print(f\"  N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} ({improvement:.6f})\")\n",
    "        \n",
    "        best_per_n[n] = {\n",
    "            'score': score,\n",
    "            'data': {\n",
    "                'xs': xs, 'ys': ys, 'degs': degs,\n",
    "                'x_strs': n_df['x'].tolist(),  # ORIGINAL strings!\n",
    "                'y_strs': n_df['y'].tolist(),\n",
    "                'deg_strs': n_df['deg'].tolist()\n",
    "            },\n",
    "            'source': csv_path\n",
    "        }\n",
    "        improvement_count += 1\n",
    "\n",
    "print(f\"\\nFound {improvement_count} valid improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ensemble score\n",
    "ensemble_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "improvement = baseline_total - ensemble_total\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Baseline: {baseline_total:.6f}\")\n",
    "print(f\"Ensemble: {ensemble_total:.6f}\")\n",
    "print(f\"Improvement: {improvement:.6f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\nTarget: 68.888293\")\n",
    "print(f\"Gap: {ensemble_total - 68.888293:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c250f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation with ZERO tolerance\n",
    "print(\"\\nFinal validation (ZERO tolerance)...\")\n",
    "all_valid = True\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    polygons = [create_tree(data['xs'][i], data['ys'][i], data['degs'][i]) for i in range(n)]\n",
    "    has_overlap, msg = check_overlaps_zero_tol(polygons)\n",
    "    if has_overlap:\n",
    "        print(f\"OVERLAP at N={n}: {msg}\")\n",
    "        all_valid = False\n",
    "        # Fall back to baseline\n",
    "        best_per_n[n] = {\n",
    "            'score': baseline_scores[n],\n",
    "            'data': baseline_data[n],\n",
    "            'source': 'fallback'\n",
    "        }\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All 200 configurations VALID!\")\n",
    "else:\n",
    "    ensemble_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "    print(f\"After fallbacks: {ensemble_total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8aa794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify N=2 precision is preserved in output\n",
    "print(\"\\nVerifying N=2 precision:\")\n",
    "print(f\"  Source: {best_per_n[2]['source']}\")\n",
    "print(f\"  x[0] = {best_per_n[2]['data']['x_strs'][0]}\")\n",
    "print(f\"  y[0] = {best_per_n[2]['data']['y_strs'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission with ORIGINAL strings\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    data = best_per_n[n]['data']\n",
    "    for i in range(n):\n",
    "        rows.append({\n",
    "            'id': f'{n:03d}_{i}',\n",
    "            'x': data['x_strs'][i],  # ORIGINAL string!\n",
    "            'y': data['y_strs'][i],\n",
    "            'deg': data['deg_strs'][i]\n",
    "        })\n",
    "\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv('/home/code/experiments/006_preserved_precision/submission.csv', index=False)\n",
    "df_out.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"Saved {len(df_out)} rows\")\n",
    "\n",
    "# Verify output\n",
    "print(\"\\nFirst 5 rows of output:\")\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': ensemble_total,\n",
    "    'baseline_score': baseline_total,\n",
    "    'improvement': baseline_total - ensemble_total,\n",
    "    'target': 68.888293,\n",
    "    'gap': ensemble_total - 68.888293\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/006_preserved_precision/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
