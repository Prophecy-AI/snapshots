# Christmas Tree Packing - Loop 6 Strategy

## Current Status
- Best CV score: 70.615106 from exp_005 (strict_ensemble)
- Best LB score: 70.647327 from exp_002/exp_003 (valid baseline)
- Target: 68.887226 | Gap to target: 1.76 points (2.6%)
- Submissions remaining: 91/100

## CRITICAL BUG IDENTIFIED - MUST FIX FIRST

**exp_004 and exp_005 both failed with "Overlapping trees in group 002"**

Root cause discovered in exploration/evolver_loop6_analysis.ipynb:
- The ensemble code was TRUNCATING coordinate precision
- Valid baseline: `s0.1540970696213643` (full precision)
- Our submission: `s0.154097069621` (truncated)
- Difference: ~1e-13 but causes overlaps with area ~1e-24

**FIX REQUIRED:** Preserve ORIGINAL string values from source CSVs exactly.
Do NOT parse floats and re-format them. Copy the exact string values.

## Response to Evaluator

The evaluator correctly identified that:
1. exp_005 needs to be submitted to verify strict overlap validation works
2. Fractional translation should be implemented as post-processing
3. More diverse solution sources are needed

However, the evaluator missed the ROOT CAUSE of the overlap failures:
- It's not about the overlap threshold (1e-15 vs 1e-10)
- It's about COORDINATE PRECISION being lost during ensemble
- The fix is to preserve original string values, not use stricter thresholds

## Experiment 006: Fixed Ensemble with Preserved Precision

### STEP 1: Create fixed ensemble that preserves exact coordinates

```python
# CRITICAL: Preserve original string values exactly
# DO NOT do: x_str = f's{float_value}'  # This truncates!
# DO: x_str = original_df['x'].values[i]  # Preserve exact string

def load_submission_preserve_strings(path):
    """Load CSV and keep original string values."""
    df = pd.read_csv(path, dtype=str)  # Load as strings!
    df['x_float'] = df['x'].apply(parse_s)  # For scoring only
    df['y_float'] = df['y'].apply(parse_s)
    df['deg_float'] = df['deg'].apply(parse_s)
    df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))
    return df

# When building ensemble, copy ORIGINAL strings:
best_per_n[n] = {
    'score': score,
    'x_strs': source_df['x'].values.tolist(),  # Original strings!
    'y_strs': source_df['y'].values.tolist(),
    'deg_strs': source_df['deg'].values.tolist(),
}
```

### STEP 2: Use ONLY the valid baseline (21328309254) as fallback

The valid baseline from snapshot 21328309254 has PASSED Kaggle validation.
For any N where we can't find a strictly better valid solution, use this baseline.

### STEP 3: Validate with ZERO tolerance

```python
def check_overlaps_zero_tolerance(polygons):
    """Check for ANY overlap, no matter how small."""
    for i in range(len(polygons)):
        for j in range(i+1, len(polygons)):
            if polygons[i].intersects(polygons[j]):
                if not polygons[i].touches(polygons[j]):
                    return True, f"Trees {i},{j} overlap"
    return False, None
```

## â›” BLOCKED APPROACHES (DO NOT USE)

- Running bbox3/sa_fast with "more iterations" - already at local optimum
- Changing overlap threshold - the issue is precision, not threshold
- Ensemble variations without fixing the precision bug

## Expected Outcome

After fixing the precision bug:
- exp_006 should pass Kaggle validation
- Score should be ~70.615 (same as exp_005 CV)
- This establishes a valid ensemble baseline

## After exp_006 Succeeds: Fractional Translation

Once we have a valid ensemble, implement fractional translation:

```python
frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
directions = [(0,1), (0,-1), (1,0), (-1,0), (1,1), (1,-1), (-1,1), (-1,-1)]

for n in range(1, 201):
    for tree_idx in range(n):
        for step in frac_steps:
            for dx, dy in directions:
                # Try moving tree by (dx*step, dy*step)
                # Keep if: no overlap AND score improves
```

Expected improvement: 0.01-0.1 points from fractional translation.

## Longer-term Strategy

Gap to target is 1.76 points. Ensemble + fractional translation might give ~0.1 points.
To close the remaining ~1.66 point gap, we need:

1. **More diverse solution sources** - The jonathanchan kernel uses 19+ sources
2. **Novel algorithms** - Constructive approaches like zaburo kernel's grid-based method
3. **Per-N specialization** - Different algorithms for different N ranges

## Validation Notes

- CV = LB perfectly for this problem (confirmed from exp_002/exp_003)
- Local validation must use ZERO tolerance for overlaps
- Coordinates must preserve FULL precision from source files
