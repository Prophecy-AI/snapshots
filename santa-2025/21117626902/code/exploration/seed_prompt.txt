# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 1)

## Current Status
- Best CV score: 70.743774 from exp_000 (001_baseline_preoptimized)
- Best LB score: N/A (no submissions yet)
- Target: 68.922808 | Gap to target: 1.82 (2.57% reduction needed)
- Submissions remaining: 94/100

## Public Kernel Status (CRITICAL!)
- Have we implemented the best kernel yet? **NO** - only downloaded pre-optimized CSV
- Top kernels identified:
  1. jazivxt/why-not (bbox3 C++ optimizer) - 292 votes
  2. jonathanchan/santa25-ensemble-sa-fractional-translation (ensemble + SA) - 174 votes
  3. saspav/santa-submission (fix_direction + bbox3) - 401 votes
  4. egortrushin/santa25-simulated-annealing-with-translations - 126 votes
- Kernels we've implemented: None (just downloaded pre-optimized CSV)
- **NEXT STEP**: Run bbox3 C++ optimizer or ensemble approach

## Response to Evaluator
The evaluator correctly identified that:
1. **No actual optimization code was run** - We only downloaded a pre-existing solution
2. **bbox3 C++ optimizer is the key technique** - This needs to be compiled and run
3. **Per-N analysis was needed** - Now done, showing N=1,2,3 are worst performers
4. **Backward propagation hasn't been tried** - This is a valid technique to explore

I agree with all these points. The next experiment MUST run actual optimization code, not just download solutions.

## Key Analysis Findings
From `exploration/evolver_loop1_analysis.ipynb`:
- Baseline has NO overlaps (valid submission)
- Worst-performing N values (highest score contribution):
  - N=1: 0.661 (optimal is 0.661 at 45° rotation - already optimal!)
  - N=2: 0.451
  - N=3: 0.435
  - N=4-7: ~0.40 each
- Need 2.57% total reduction to reach target
- Average reduction needed per N: 0.009

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY]** Run bbox3 C++ Optimizer
The bbox3 optimizer from jazivxt/why-not is the primary technique used by top performers.

```bash
# Extract bbox3.cpp from the kernel
cd /home/code/experiments/002_bbox3_optimizer

# The C++ code is in research/kernels/jazivxt_why-not/why-not.ipynb
# Extract it and compile:
g++ -O3 -march=native -std=c++17 -fopenmp -o bbox3 bbox3.cpp

# Run with high parameters (let it run for hours):
export OMP_NUM_THREADS=$(nproc)
./bbox3 -n 10000 -r 256
```

Key parameters:
- `-n`: Number of SA iterations (try 10000-20000)
- `-r`: Number of restarts (try 64-256)
- The longer it runs, the better the results

### 2. **[HIGH PRIORITY]** Ensemble Multiple Sources
From jonathanchan kernel - combine best configs from multiple sources:

```python
# Ensemble approach: For each N, pick the best configuration from multiple sources
sources = [
    '/home/code/preoptimized_submission.csv',  # Current baseline
    # Download more from Kaggle datasets:
    # - bucket-of-chump
    # - santa-2025-try3
    # - telegram-public-shared-solution-for-santa-2025
]

for n in range(1, 201):
    best_score = float('inf')
    best_config = None
    for source in sources:
        config = load_config(source, n)
        score = get_score(config, n)
        if score < best_score:
            best_score = score
            best_config = config
    save_config(best_config, n)
```

### 3. **[MEDIUM PRIORITY]** Fractional Translation Refinement
From jonathanchan kernel - fine-grained translation optimization:

```python
frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
dx = [0, 0, 1, -1, 1, 1, -1, -1]
dy = [1, -1, 0, 0, 1, -1, 1, -1]

for tree in trees:
    for step in frac_steps:
        for d in range(8):
            # Try moving tree by step in direction d
            # Accept if score improves
```

### 4. **[MEDIUM PRIORITY]** Backward Propagation
From smartmanoj/santa-claude - derive smaller N configs from larger N:

```python
for n in range(200, 1, -1):
    config_n = load_config(n)
    best_config_n_minus_1 = load_config(n-1)
    
    for tree_to_remove in range(n):
        candidate = remove_tree(config_n, tree_to_remove)
        if get_score(candidate, n-1) < get_score(best_config_n_minus_1, n-1):
            best_config_n_minus_1 = candidate
    
    save_config(best_config_n_minus_1, n-1)
```

## What NOT to Try
- ❌ Just downloading more pre-optimized CSVs without running optimization
- ❌ fix_direction alone (already applied to baseline, no improvement)
- ❌ Optimizing N=1 (already at optimal 45° rotation)

## Validation Notes
- This is a deterministic optimization problem - no CV/LB gap concerns
- Score is computed locally and matches LB exactly
- Always validate no overlaps before submitting
- Submission format: 's' prefix on all values, 20100 rows total

## SUBMISSION STRATEGY
- Remaining submissions: 94
- **SUBMIT after this experiment** - we have abundant submissions and need LB feedback
- Submit any improvement over 70.74 baseline

## Technical Details

### bbox3 C++ Optimizer Key Features
- Simulated annealing with geometric cooling
- Local search with translation, rotation, swap moves
- Squeeze/compaction toward center
- Multi-start with different random seeds
- OpenMP parallelization

### Scoring Function
```python
def score(submission):
    total = 0
    for n in range(1, 201):
        trees = get_trees_for_n(submission, n)
        bounds = get_bounding_box(trees)
        side = max(bounds.width, bounds.height)
        total += side**2 / n
    return total
```

### Tree Polygon (15 vertices)
```
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```
