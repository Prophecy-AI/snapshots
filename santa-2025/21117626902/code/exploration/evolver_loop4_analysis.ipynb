{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d44795b",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis - Strategy Assessment\n",
    "\n",
    "## Key Observations:\n",
    "1. Current best: 70.676145 (verified ensemble)\n",
    "2. Target: 68.922808\n",
    "3. Gap: 1.75 points (2.5% reduction needed)\n",
    "4. Current LB #1: 71.19 (terry_u16)\n",
    "5. **Our target is BETTER than the current #1 on the leaderboard!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318aae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# List all available CSV sources\n",
    "print('=== Available Sources ===')\n",
    "for path in glob.glob('/home/code/datasets/**/*.csv', recursive=True):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the jonathanchan kernel for the C++ optimizer\n",
    "print('=== jonathanchan kernel files ===')\n",
    "for f in os.listdir('/home/code/research/kernels/jonathanchan_santa25-ensemble-sa-fractional-translation'):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have the sa_v1_parallel.cpp file\n",
    "sa_cpp_path = '/home/code/research/kernels/jonathanchan_santa25-ensemble-sa-fractional-translation/sa_v1_parallel.cpp'\n",
    "if os.path.exists(sa_cpp_path):\n",
    "    print('sa_v1_parallel.cpp exists!')\n",
    "    with open(sa_cpp_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        print(f'File size: {len(content)} bytes')\n",
    "else:\n",
    "    print('sa_v1_parallel.cpp NOT FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what optimizers we have compiled\n",
    "print('=== Compiled optimizers ===')\n",
    "for path in ['/home/code/datasets/bbox3', '/home/code/datasets/bucket-of-chump/bbox3']:\n",
    "    if os.path.exists(path):\n",
    "        print(f'{path} exists, size: {os.path.getsize(path)} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b007e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the current submission score breakdown by N\n",
    "import math\n",
    "\n",
    "def score_group_simple(xs, ys, degs):\n",
    "    TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125])\n",
    "    TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5])\n",
    "    n = len(xs)\n",
    "    mnx = mny = 1e300\n",
    "    mxx = mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c, s = math.cos(r), math.sin(r)\n",
    "        xi, yi = xs[i], ys[i]\n",
    "        for j in range(15):\n",
    "            X = c * TX[j] - s * TY[j] + xi\n",
    "            Y = s * TX[j] + c * TY[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(val):\n",
    "    return float(str(val).replace('s', ''))\n",
    "\n",
    "# Load current submission\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "df['N'] = df['id'].str.split('_').str[0].astype(int)\n",
    "\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    group = df[df['N'] == n]\n",
    "    xs = np.array([strip(x) for x in group['x']])\n",
    "    ys = np.array([strip(y) for y in group['y']])\n",
    "    degs = np.array([strip(d) for d in group['deg']])\n",
    "    sc = score_group_simple(xs, ys, degs)\n",
    "    scores.append({'N': n, 'score': sc})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(f'Total score: {scores_df[\"score\"].sum():.6f}')\n",
    "print(f'\\nTop 10 worst N values (highest score contribution):')\n",
    "print(scores_df.nlargest(10, 'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Score by N\n",
    "axes[0].bar(scores_df['N'], scores_df['score'])\n",
    "axes[0].set_xlabel('N')\n",
    "axes[0].set_ylabel('Score contribution')\n",
    "axes[0].set_title('Score contribution by N')\n",
    "\n",
    "# Cumulative score\n",
    "scores_df['cumsum'] = scores_df['score'].cumsum()\n",
    "axes[1].plot(scores_df['N'], scores_df['cumsum'])\n",
    "axes[1].axhline(y=68.922808, color='r', linestyle='--', label='Target')\n",
    "axes[1].set_xlabel('N')\n",
    "axes[1].set_ylabel('Cumulative Score')\n",
    "axes[1].set_title('Cumulative score by N')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/score_analysis.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de835ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much improvement is needed per N to reach target\n",
    "target = 68.922808\n",
    "current = scores_df['score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f'Current score: {current:.6f}')\n",
    "print(f'Target: {target:.6f}')\n",
    "print(f'Gap: {gap:.6f}')\n",
    "print(f'Average improvement needed per N: {gap/200:.6f}')\n",
    "\n",
    "# If we could improve the worst N values by X%, what would we get?\n",
    "for pct in [5, 10, 15, 20, 25, 30]:\n",
    "    # Improve top 20 worst N values by pct%\n",
    "    improved = scores_df.copy()\n",
    "    worst_20 = improved.nlargest(20, 'score').index\n",
    "    improved.loc[worst_20, 'score'] *= (1 - pct/100)\n",
    "    new_total = improved['score'].sum()\n",
    "    print(f'If top 20 worst N improved by {pct}%: {new_total:.6f} (gap: {new_total - target:.6f})')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
