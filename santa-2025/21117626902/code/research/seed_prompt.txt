# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 5)

## Current Status
- Best CV score: 70.676145 from exp_003 (verified ensemble)
- Best LB score: 70.676145 (submitted and verified)
- Target: 68.922808 | Gap to target: 1.75 points (2.48% reduction needed)
- Current #1 on LB: 71.19 (terry_u16)
- **CRITICAL: Our target of 68.92 is 2.27 points BELOW the current #1!**

## Public Kernel Status (CRITICAL!)
- Have we implemented the best kernel yet? **YES** - we have ensembled from 17 sources
- Top kernels identified: All public sources score ~70.67 at best
- Kernels we've implemented: bbox3, sa_v1_parallel, backward iteration, ensemble
- **KEY INSIGHT**: No public kernel achieves score < 70.67. Target requires NOVEL solutions.

## CV-LB Relationship Analysis
- CV = LB exactly (this is a deterministic optimization problem)
- No distribution shift - the problem is purely computational
- Improvement requires finding BETTER configurations, not better models

## Response to Evaluator
The evaluator correctly identified that:
1. Extended C++ optimization (1927s bbox3, sa_v1_parallel) achieved 0 improvement
2. The ensemble is at a very strong local optimum
3. The target of 68.92 is BELOW the current #1 (71.19) - no public solution achieves this
4. We need to GENERATE fundamentally new solutions, not optimize existing ones

I fully agree with the evaluator's assessment. The current approach of local optimization has definitively reached its limit. We must pivot to generating new configurations.

## Key Strategic Insights
1. **Target is below LB #1**: Our target of 68.92 is 2.27 points better than the current leaderboard leader (71.19). This means:
   - No public solution achieves this score
   - We cannot reach target by ensembling public sources
   - We need to discover novel optimization techniques

2. **Small N values have highest leverage**: 
   - N=1 contributes 0.66 points (0.93% of total)
   - Top 20 worst N values contribute 8.08 points (11.4% of total)
   - Need 21.7% reduction in worst 20 N values to reach target

3. **Packing efficiency varies by N**:
   - N=1: efficiency 0.53 (worst)
   - N=100: efficiency 1.01
   - N=181: efficiency 1.06 (best)
   - Small N values have the most room for improvement

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY]** Super-Fast SA with Translations (jiweiliu kernel)
The jiweiliu kernel uses a fundamentally different approach:
- **Grid-based initial configurations**: Generate trees on a grid pattern
- **Deletion cascade**: Propagate good large configs to smaller sizes by iteratively removing trees
- **Numba acceleration**: Fast collision detection
- **Key insight**: Instead of optimizing existing configs, GENERATE new ones from scratch

**Implementation:**
```bash
# Copy the kernel code
cp /home/code/research/kernels/jiweiliu_super-fast-simulated-annealing-with-translations/*.ipynb experiments/006_jiweiliu_sa/
cd experiments/006_jiweiliu_sa
# Run the notebook (adapt paths as needed)
```

### 2. **[HIGH PRIORITY]** Generate Random Initial Configurations
Instead of optimizing the existing local optimum, generate 100+ random initial configurations for each N and optimize each:
- For N=1 to N=30, generate random placements
- Run simulated annealing on each
- Keep the best result for each N
- This explores different basins of attraction

### 3. **[MEDIUM PRIORITY]** Crystalline/Lattice Packing for Large N
From the discussions, "symmetric solutions that are apparently optimal" for N > 58:
- Implement structured packing patterns
- Use hexagonal or other lattice arrangements
- May provide mathematically superior solutions for large N

### 4. **[MEDIUM PRIORITY]** Basin Hopping
Combine random perturbation with local optimization:
- Take current best configuration
- Apply large random perturbation (move all trees significantly)
- Run local optimization
- Accept if better, otherwise try again
- This can escape local optima

### 5. **[LOWER PRIORITY]** Genetic Algorithm with Crossover
- Maintain population of diverse configurations
- Crossover: combine good parts from different configurations
- Mutation: random perturbations
- Selection: keep best configurations

## What NOT to Try
- ❌ More bbox3 optimization (0 improvement after 1927s)
- ❌ More sa_v1_parallel (0 improvement)
- ❌ More backward iteration (0 improvement)
- ❌ Ensembling more public sources (all score ~70.67)
- ❌ Any local optimization on current ensemble (at strong local optimum)

## Validation Notes
- CV = LB exactly (deterministic problem)
- Always verify no overlaps before submission
- Use shapely for overlap checking

## SUBMISSION STRATEGY
- Remaining submissions: 92
- Submit after EVERY experiment that produces a valid submission
- LB feedback is free - USE IT!
- We need to find fundamentally better solutions, so every experiment is valuable

## Specific Implementation for Next Experiment

**Experiment 006: Super-Fast SA with Grid Generation**

1. Implement the jiweiliu kernel approach:
   - Generate grid-based initial configurations
   - Use deletion cascade to propagate good configs
   - Apply SA optimization with translations

2. Key parameters from jiweiliu kernel:
   - SA params: Tmax=0.001, Tmin=0.000001, nsteps=10, nsteps_per_T=10000
   - position_delta=0.002, angle_delta=1.0, delta_t=0.002
   - Use Numba for acceleration

3. Expected outcome:
   - Generate new configurations that may be in different basins
   - Deletion cascade may find better small N configurations
   - Even small improvements are valuable given our gap

## Critical Success Factors
1. **Generate NEW configurations** - don't just optimize existing ones
2. **Focus on small N** - highest leverage for improvement
3. **Try multiple random seeds** - explore different basins
4. **Use deletion cascade** - propagate good large configs to smaller sizes
