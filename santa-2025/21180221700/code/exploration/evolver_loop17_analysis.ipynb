{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5f45ff",
   "metadata": {},
   "source": [
    "# Loop 17 Analysis: Strategic Assessment\n",
    "\n",
    "## Current Status\n",
    "- Best CV/LB: 70.630478 (from saspav_best ensemble)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.711324 (2.42%)\n",
    "- Stuck for 7 consecutive experiments (011-017)\n",
    "\n",
    "## Key Insights from This Loop\n",
    "1. jiweiliu kernel starts from 71.657 baseline - our baseline (70.630478) is ALREADY 1.03 points BETTER\n",
    "2. Bottom-left-fill heuristic produced WORSE results\n",
    "3. Subset extraction from larger N produced WORSE results\n",
    "4. All standard optimization approaches have been exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what approaches have NOT been tried\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of approaches tried\n",
    "approaches_tried = [\n",
    "    ('001', 'Baseline from jazivxt/bucket-of-chump', 70.647327, 'baseline'),\n",
    "    ('002', 'Ensemble from 9 sources', 70.647306, 'no improvement'),\n",
    "    ('003', 'Validated ensemble', 70.647327, 'no improvement'),\n",
    "    ('004', 'bbox3 optimization', 70.647326, 'no improvement'),\n",
    "    ('005', 'Baseline validated', 70.647327, 'no improvement'),\n",
    "    ('006', 'Zaburo grid-based', 88.33, 'WORSE'),\n",
    "    ('007', 'SA optimization on zaburo', 88.33, 'WORSE + overlaps'),\n",
    "    ('008', 'Repair + ensemble', 70.647327, 'no improvement'),\n",
    "    ('009', 'Fractional translation SA', 70.647327, 'no improvement'),\n",
    "    ('010', 'Tessellation + saspav ensemble', 70.630478, 'IMPROVEMENT!'),\n",
    "    ('011', 'Random restart SA', 70.630478, 'no improvement'),\n",
    "    ('012', 'Crystalline packing', 70.630478, 'no improvement'),\n",
    "    ('013', 'High restart SA', 70.630478, 'no improvement'),\n",
    "    ('014', 'Extreme SA', 70.630478, 'no improvement'),\n",
    "    ('015', 'Constraint Programming', 70.630478, 'WORSE'),\n",
    "    ('016', 'True CP', 70.630478, 'WORSE'),\n",
    "    ('017', 'Bottom-left fill', 70.630478, 'WORSE'),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(approaches_tried, columns=['Exp', 'Approach', 'Score', 'Result'])\n",
    "print(\"Approaches Tried:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nBest score achieved: {df['Score'].min():.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {df['Score'].min() - 68.919154:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What approaches have NOT been tried?\n",
    "approaches_not_tried = [\n",
    "    ('sparroWASM external solver', 'State-of-the-art nesting algorithm from Jeroen Gar'),\n",
    "    ('spyrrow Python wrapper', 'Python interface to sparrow solver'),\n",
    "    ('Genetic Algorithm with crossover', 'Crossover between good partial solutions'),\n",
    "    ('No-Fit Polygon (NFP) based optimization', 'Proper geometric constraints'),\n",
    "    ('Backward propagation from N=200', 'Start from best large N, remove trees'),\n",
    "    ('Manual tree placement for specific N', 'Interactive editor for fine-tuning'),\n",
    "    ('Different rotation angles', 'Try non-standard angles like 30, 60, 120'),\n",
    "    ('Asymmetric solutions', 'Break symmetry for potentially better packing'),\n",
    "]\n",
    "\n",
    "print(\"\\nApproaches NOT yet tried:\")\n",
    "for name, desc in approaches_not_tried:\n",
    "    print(f\"  - {name}: {desc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score breakdown by N range\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e15\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "\n",
    "        trunk_w = Decimal(\"0.15\")\n",
    "        trunk_h = Decimal(\"0.2\")\n",
    "        base_w = Decimal(\"0.7\")\n",
    "        mid_w = Decimal(\"0.4\")\n",
    "        top_w = Decimal(\"0.25\")\n",
    "        tip_y = Decimal(\"0.8\")\n",
    "        tier_1_y = Decimal(\"0.5\")\n",
    "        tier_2_y = Decimal(\"0.25\")\n",
    "        base_y = Decimal(\"0.0\")\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal(\"0.0\") * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal(\"2\") * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal(\"4\") * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal(\"2\") * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal(\"4\") * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal(\"2\") * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal(\"2\")) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal(\"4\")) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal(\"2\")) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal(\"4\")) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal(\"2\")) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor),\n",
    "        )\n",
    "\n",
    "def calculate_score(trees):\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    score = max(max_x - min_x, max_y - min_y) ** 2 / len(trees)\n",
    "    return score\n",
    "\n",
    "def load_trees(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"]).lstrip('sx')\n",
    "        y = str(row[\"y\"]).lstrip('sy')\n",
    "        deg = str(row[\"deg\"]).lstrip('sd')\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "# Load current best\n",
    "df = pd.read_csv('/home/code/exploration/datasets/saspav_best.csv')\n",
    "\n",
    "print(\"Score breakdown by N:\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for each N and find worst performers\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    score = calculate_score(trees)\n",
    "    scores.append({'N': n, 'Score': score, 'Contribution': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df['Cumulative'] = scores_df['Score'].cumsum()\n",
    "scores_df['Pct'] = scores_df['Score'] / scores_df['Score'].sum() * 100\n",
    "\n",
    "print(f\"Total score: {scores_df['Score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 worst N values (highest contribution):\")\n",
    "print(scores_df.nlargest(10, 'Score')[['N', 'Score', 'Pct']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTop 10 best N values (lowest contribution):\")\n",
    "print(scores_df.nsmallest(10, 'Score')[['N', 'Score', 'Pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0624673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency for each N\n",
    "# Efficiency = (N * tree_area) / (side_length^2)\n",
    "# Tree area is approximately 0.2475 (calculated from polygon)\n",
    "tree_area = 0.2475\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    side = max(max_x - min_x, max_y - min_y)\n",
    "    efficiency = (n * tree_area) / (side ** 2) * 100\n",
    "    efficiencies.append({'N': n, 'Side': side, 'Efficiency': efficiency})\n",
    "\n",
    "eff_df = pd.DataFrame(efficiencies)\n",
    "print(f\"\\nEfficiency analysis:\")\n",
    "print(f\"Mean efficiency: {eff_df['Efficiency'].mean():.2f}%\")\n",
    "print(f\"Min efficiency: {eff_df['Efficiency'].min():.2f}% at N={eff_df.loc[eff_df['Efficiency'].idxmin(), 'N']}\")\n",
    "print(f\"Max efficiency: {eff_df['Efficiency'].max():.2f}% at N={eff_df.loc[eff_df['Efficiency'].idxmax(), 'N']}\")\n",
    "\n",
    "print(f\"\\nLowest efficiency N values:\")\n",
    "print(eff_df.nsmallest(10, 'Efficiency')[['N', 'Side', 'Efficiency']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: What would it take to reach the target?\n",
    "target = 68.919154\n",
    "current = scores_df['Score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"GAP ANALYSIS\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({gap/current*100:.2f}%)\")\n",
    "\n",
    "# If we improved all N values uniformly\n",
    "print(f\"\\nIf we improved ALL N values uniformly by {gap/current*100:.2f}%:\")\n",
    "print(f\"  Each N would need to improve by {gap/200:.6f} on average\")\n",
    "\n",
    "# If we only improved large N (101-200)\n",
    "large_n_score = scores_df[scores_df['N'] > 100]['Score'].sum()\n",
    "print(f\"\\nIf we ONLY improved N=101-200 (current: {large_n_score:.6f}):\")\n",
    "print(f\"  Would need {gap/large_n_score*100:.2f}% improvement in this range\")\n",
    "\n",
    "# What efficiency would we need?\n",
    "print(f\"\\nEfficiency needed to reach target:\")\n",
    "print(f\"  Current avg efficiency: {eff_df['Efficiency'].mean():.2f}%\")\n",
    "print(f\"  Target avg efficiency: ~{eff_df['Efficiency'].mean() * current / target:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a832f3",
   "metadata": {},
   "source": [
    "## Strategic Recommendations\n",
    "\n",
    "### CRITICAL INSIGHT: We need a FUNDAMENTALLY DIFFERENT approach\n",
    "\n",
    "After 17 experiments, all standard optimization approaches have failed:\n",
    "- SA (various parameters) - no improvement\n",
    "- bbox3 optimizer - no improvement  \n",
    "- Constraint Programming - WORSE\n",
    "- Bottom-left-fill - WORSE\n",
    "- Grid-based approaches - WORSE\n",
    "- Random restart - no improvement\n",
    "\n",
    "### The gap (1.711 points, 2.42%) is TOO LARGE for incremental optimization\n",
    "\n",
    "### Recommended Next Steps:\n",
    "\n",
    "1. **Try sparroWASM/spyrrow external solver**\n",
    "   - State-of-the-art nesting algorithm\n",
    "   - May find fundamentally different configurations\n",
    "   - Focus on large N (101-200) where 5% improvement closes the gap\n",
    "\n",
    "2. **Implement backward propagation properly**\n",
    "   - Start from best N=200 solution\n",
    "   - Iteratively remove trees to get N=199, 198, etc.\n",
    "   - This propagates good configurations downward\n",
    "\n",
    "3. **Try asymmetric solutions**\n",
    "   - All current solutions appear symmetric\n",
    "   - Breaking symmetry might find better local optima\n",
    "\n",
    "4. **Focus on specific N values with low efficiency**\n",
    "   - N=1 has 45.4% efficiency (but is already optimal)\n",
    "   - Find N values with room for improvement"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
