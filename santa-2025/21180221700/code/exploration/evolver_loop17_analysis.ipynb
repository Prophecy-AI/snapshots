{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5f45ff",
   "metadata": {},
   "source": [
    "# Loop 17 Analysis: Strategic Assessment\n",
    "\n",
    "## Current Status\n",
    "- Best CV/LB: 70.630478 (from saspav_best ensemble)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.711324 (2.42%)\n",
    "- Stuck for 7 consecutive experiments (011-017)\n",
    "\n",
    "## Key Insights from This Loop\n",
    "1. jiweiliu kernel starts from 71.657 baseline - our baseline (70.630478) is ALREADY 1.03 points BETTER\n",
    "2. Bottom-left-fill heuristic produced WORSE results\n",
    "3. Subset extraction from larger N produced WORSE results\n",
    "4. All standard optimization approaches have been exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd62f99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:07.233134Z",
     "iopub.status.busy": "2026-01-20T23:26:07.232644Z",
     "iopub.status.idle": "2026-01-20T23:26:07.518352Z",
     "shell.execute_reply": "2026-01-20T23:26:07.517965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaches Tried:\n",
      "Exp                              Approach     Score           Result\n",
      "001 Baseline from jazivxt/bucket-of-chump 70.647327         baseline\n",
      "002               Ensemble from 9 sources 70.647306   no improvement\n",
      "003                    Validated ensemble 70.647327   no improvement\n",
      "004                    bbox3 optimization 70.647326   no improvement\n",
      "005                    Baseline validated 70.647327   no improvement\n",
      "006                     Zaburo grid-based 88.330000            WORSE\n",
      "007             SA optimization on zaburo 88.330000 WORSE + overlaps\n",
      "008                     Repair + ensemble 70.647327   no improvement\n",
      "009             Fractional translation SA 70.647327   no improvement\n",
      "010        Tessellation + saspav ensemble 70.630478     IMPROVEMENT!\n",
      "011                     Random restart SA 70.630478   no improvement\n",
      "012                   Crystalline packing 70.630478   no improvement\n",
      "013                       High restart SA 70.630478   no improvement\n",
      "014                            Extreme SA 70.630478   no improvement\n",
      "015                Constraint Programming 70.630478            WORSE\n",
      "016                               True CP 70.630478            WORSE\n",
      "017                      Bottom-left fill 70.630478            WORSE\n",
      "\n",
      "Best score achieved: 70.630478\n",
      "Target: 68.919154\n",
      "Gap: 1.711324\n"
     ]
    }
   ],
   "source": [
    "# Analyze what approaches have NOT been tried\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of approaches tried\n",
    "approaches_tried = [\n",
    "    ('001', 'Baseline from jazivxt/bucket-of-chump', 70.647327, 'baseline'),\n",
    "    ('002', 'Ensemble from 9 sources', 70.647306, 'no improvement'),\n",
    "    ('003', 'Validated ensemble', 70.647327, 'no improvement'),\n",
    "    ('004', 'bbox3 optimization', 70.647326, 'no improvement'),\n",
    "    ('005', 'Baseline validated', 70.647327, 'no improvement'),\n",
    "    ('006', 'Zaburo grid-based', 88.33, 'WORSE'),\n",
    "    ('007', 'SA optimization on zaburo', 88.33, 'WORSE + overlaps'),\n",
    "    ('008', 'Repair + ensemble', 70.647327, 'no improvement'),\n",
    "    ('009', 'Fractional translation SA', 70.647327, 'no improvement'),\n",
    "    ('010', 'Tessellation + saspav ensemble', 70.630478, 'IMPROVEMENT!'),\n",
    "    ('011', 'Random restart SA', 70.630478, 'no improvement'),\n",
    "    ('012', 'Crystalline packing', 70.630478, 'no improvement'),\n",
    "    ('013', 'High restart SA', 70.630478, 'no improvement'),\n",
    "    ('014', 'Extreme SA', 70.630478, 'no improvement'),\n",
    "    ('015', 'Constraint Programming', 70.630478, 'WORSE'),\n",
    "    ('016', 'True CP', 70.630478, 'WORSE'),\n",
    "    ('017', 'Bottom-left fill', 70.630478, 'WORSE'),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(approaches_tried, columns=['Exp', 'Approach', 'Score', 'Result'])\n",
    "print(\"Approaches Tried:\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nBest score achieved: {df['Score'].min():.6f}\")\n",
    "print(f\"Target: 68.919154\")\n",
    "print(f\"Gap: {df['Score'].min() - 68.919154:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0767e2ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:07.519432Z",
     "iopub.status.busy": "2026-01-20T23:26:07.519305Z",
     "iopub.status.idle": "2026-01-20T23:26:07.522454Z",
     "shell.execute_reply": "2026-01-20T23:26:07.522099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approaches NOT yet tried:\n",
      "  - sparroWASM external solver: State-of-the-art nesting algorithm from Jeroen Gar\n",
      "  - spyrrow Python wrapper: Python interface to sparrow solver\n",
      "  - Genetic Algorithm with crossover: Crossover between good partial solutions\n",
      "  - No-Fit Polygon (NFP) based optimization: Proper geometric constraints\n",
      "  - Backward propagation from N=200: Start from best large N, remove trees\n",
      "  - Manual tree placement for specific N: Interactive editor for fine-tuning\n",
      "  - Different rotation angles: Try non-standard angles like 30, 60, 120\n",
      "  - Asymmetric solutions: Break symmetry for potentially better packing\n"
     ]
    }
   ],
   "source": [
    "# What approaches have NOT been tried?\n",
    "approaches_not_tried = [\n",
    "    ('sparroWASM external solver', 'State-of-the-art nesting algorithm from Jeroen Gar'),\n",
    "    ('spyrrow Python wrapper', 'Python interface to sparrow solver'),\n",
    "    ('Genetic Algorithm with crossover', 'Crossover between good partial solutions'),\n",
    "    ('No-Fit Polygon (NFP) based optimization', 'Proper geometric constraints'),\n",
    "    ('Backward propagation from N=200', 'Start from best large N, remove trees'),\n",
    "    ('Manual tree placement for specific N', 'Interactive editor for fine-tuning'),\n",
    "    ('Different rotation angles', 'Try non-standard angles like 30, 60, 120'),\n",
    "    ('Asymmetric solutions', 'Break symmetry for potentially better packing'),\n",
    "]\n",
    "\n",
    "print(\"\\nApproaches NOT yet tried:\")\n",
    "for name, desc in approaches_not_tried:\n",
    "    print(f\"  - {name}: {desc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c0d02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:07.523504Z",
     "iopub.status.busy": "2026-01-20T23:26:07.523378Z",
     "iopub.status.idle": "2026-01-20T23:26:07.562508Z",
     "shell.execute_reply": "2026-01-20T23:26:07.562136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score breakdown by N:\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze score breakdown by N range\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e15\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "\n",
    "        trunk_w = Decimal(\"0.15\")\n",
    "        trunk_h = Decimal(\"0.2\")\n",
    "        base_w = Decimal(\"0.7\")\n",
    "        mid_w = Decimal(\"0.4\")\n",
    "        top_w = Decimal(\"0.25\")\n",
    "        tip_y = Decimal(\"0.8\")\n",
    "        tier_1_y = Decimal(\"0.5\")\n",
    "        tier_2_y = Decimal(\"0.25\")\n",
    "        base_y = Decimal(\"0.0\")\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal(\"0.0\") * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal(\"2\") * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal(\"4\") * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal(\"2\") * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal(\"4\") * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal(\"2\") * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal(\"2\")) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal(\"4\")) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal(\"2\")) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal(\"4\")) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal(\"2\")) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor),\n",
    "        )\n",
    "\n",
    "def calculate_score(trees):\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    score = max(max_x - min_x, max_y - min_y) ** 2 / len(trees)\n",
    "    return score\n",
    "\n",
    "def load_trees(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"]).lstrip('sx')\n",
    "        y = str(row[\"y\"]).lstrip('sy')\n",
    "        deg = str(row[\"deg\"]).lstrip('sd')\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "# Load current best\n",
    "df = pd.read_csv('/home/code/exploration/datasets/saspav_best.csv')\n",
    "\n",
    "print(\"Score breakdown by N:\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a397b365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:07.563490Z",
     "iopub.status.busy": "2026-01-20T23:26:07.563405Z",
     "iopub.status.idle": "2026-01-20T23:26:10.432547Z",
     "shell.execute_reply": "2026-01-20T23:26:10.431895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 70.630478\n",
      "\n",
      "Top 10 worst N values (highest contribution):\n",
      " N    Score      Pct\n",
      " 1 0.661250 0.936211\n",
      " 2 0.450779 0.638222\n",
      " 3 0.434745 0.615521\n",
      " 5 0.416850 0.590184\n",
      " 4 0.416545 0.589752\n",
      " 7 0.399897 0.566181\n",
      " 6 0.399610 0.565776\n",
      " 9 0.387415 0.548510\n",
      " 8 0.385407 0.545667\n",
      "15 0.376978 0.533733\n",
      "\n",
      "Top 10 best N values (lowest contribution):\n",
      "  N    Score      Pct\n",
      "181 0.329945 0.467142\n",
      "156 0.329986 0.467200\n",
      "182 0.329988 0.467203\n",
      "180 0.331000 0.468637\n",
      "155 0.332069 0.470149\n",
      "168 0.332475 0.470724\n",
      "195 0.332578 0.470871\n",
      "179 0.332595 0.470894\n",
      "167 0.332835 0.471234\n",
      "194 0.332999 0.471466\n"
     ]
    }
   ],
   "source": [
    "# Calculate scores for each N and find worst performers\n",
    "scores = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    score = calculate_score(trees)\n",
    "    scores.append({'N': n, 'Score': score, 'Contribution': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df['Cumulative'] = scores_df['Score'].cumsum()\n",
    "scores_df['Pct'] = scores_df['Score'] / scores_df['Score'].sum() * 100\n",
    "\n",
    "print(f\"Total score: {scores_df['Score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 worst N values (highest contribution):\")\n",
    "print(scores_df.nlargest(10, 'Score')[['N', 'Score', 'Pct']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nTop 10 best N values (lowest contribution):\")\n",
    "print(scores_df.nsmallest(10, 'Score')[['N', 'Score', 'Pct']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0624673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:10.433686Z",
     "iopub.status.busy": "2026-01-20T23:26:10.433577Z",
     "iopub.status.idle": "2026-01-20T23:26:13.254471Z",
     "shell.execute_reply": "2026-01-20T23:26:13.253901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efficiency analysis:\n",
      "Mean efficiency: 70.39%\n",
      "Min efficiency: 37.43% at N=1\n",
      "Max efficiency: 75.01% at N=181\n",
      "\n",
      "Lowest efficiency N values:\n",
      " N     Side  Efficiency\n",
      " 1 0.813173   37.429112\n",
      " 2 0.949504   54.904931\n",
      " 3 1.142031   56.929906\n",
      " 5 1.443692   59.373934\n",
      " 4 1.290806   59.417371\n",
      " 7 1.673104   61.891006\n",
      " 6 1.548438   61.935343\n",
      " 9 1.867280   63.884976\n",
      " 8 1.755921   64.217785\n",
      "15 2.377955   65.653692\n"
     ]
    }
   ],
   "source": [
    "# Calculate efficiency for each N\n",
    "# Efficiency = (N * tree_area) / (side_length^2)\n",
    "# Tree area is approximately 0.2475 (calculated from polygon)\n",
    "tree_area = 0.2475\n",
    "\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees(n, df)\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    side = max(max_x - min_x, max_y - min_y)\n",
    "    efficiency = (n * tree_area) / (side ** 2) * 100\n",
    "    efficiencies.append({'N': n, 'Side': side, 'Efficiency': efficiency})\n",
    "\n",
    "eff_df = pd.DataFrame(efficiencies)\n",
    "print(f\"\\nEfficiency analysis:\")\n",
    "print(f\"Mean efficiency: {eff_df['Efficiency'].mean():.2f}%\")\n",
    "print(f\"Min efficiency: {eff_df['Efficiency'].min():.2f}% at N={eff_df.loc[eff_df['Efficiency'].idxmin(), 'N']}\")\n",
    "print(f\"Max efficiency: {eff_df['Efficiency'].max():.2f}% at N={eff_df.loc[eff_df['Efficiency'].idxmax(), 'N']}\")\n",
    "\n",
    "print(f\"\\nLowest efficiency N values:\")\n",
    "print(eff_df.nsmallest(10, 'Efficiency')[['N', 'Side', 'Efficiency']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c4328c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T23:26:13.255494Z",
     "iopub.status.busy": "2026-01-20T23:26:13.255386Z",
     "iopub.status.idle": "2026-01-20T23:26:13.259766Z",
     "shell.execute_reply": "2026-01-20T23:26:13.259415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GAP ANALYSIS\n",
      "============================================================\n",
      "Current score: 70.630478\n",
      "Target score: 68.919154\n",
      "Gap: 1.711324 (2.42%)\n",
      "\n",
      "If we improved ALL N values uniformly by 2.42%:\n",
      "  Each N would need to improve by 0.008557 on average\n",
      "\n",
      "If we ONLY improved N=101-200 (current: 33.979366):\n",
      "  Would need 5.04% improvement in this range\n",
      "\n",
      "Efficiency needed to reach target:\n",
      "  Current avg efficiency: 70.39%\n",
      "  Target avg efficiency: ~72.13%\n"
     ]
    }
   ],
   "source": [
    "# Key insight: What would it take to reach the target?\n",
    "target = 68.919154\n",
    "current = scores_df['Score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"GAP ANALYSIS\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({gap/current*100:.2f}%)\")\n",
    "\n",
    "# If we improved all N values uniformly\n",
    "print(f\"\\nIf we improved ALL N values uniformly by {gap/current*100:.2f}%:\")\n",
    "print(f\"  Each N would need to improve by {gap/200:.6f} on average\")\n",
    "\n",
    "# If we only improved large N (101-200)\n",
    "large_n_score = scores_df[scores_df['N'] > 100]['Score'].sum()\n",
    "print(f\"\\nIf we ONLY improved N=101-200 (current: {large_n_score:.6f}):\")\n",
    "print(f\"  Would need {gap/large_n_score*100:.2f}% improvement in this range\")\n",
    "\n",
    "# What efficiency would we need?\n",
    "print(f\"\\nEfficiency needed to reach target:\")\n",
    "print(f\"  Current avg efficiency: {eff_df['Efficiency'].mean():.2f}%\")\n",
    "print(f\"  Target avg efficiency: ~{eff_df['Efficiency'].mean() * current / target:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a832f3",
   "metadata": {},
   "source": [
    "## Strategic Recommendations\n",
    "\n",
    "### CRITICAL INSIGHT: We need a FUNDAMENTALLY DIFFERENT approach\n",
    "\n",
    "After 17 experiments, all standard optimization approaches have failed:\n",
    "- SA (various parameters) - no improvement\n",
    "- bbox3 optimizer - no improvement  \n",
    "- Constraint Programming - WORSE\n",
    "- Bottom-left-fill - WORSE\n",
    "- Grid-based approaches - WORSE\n",
    "- Random restart - no improvement\n",
    "\n",
    "### The gap (1.711 points, 2.42%) is TOO LARGE for incremental optimization\n",
    "\n",
    "### Recommended Next Steps:\n",
    "\n",
    "1. **Try sparroWASM/spyrrow external solver**\n",
    "   - State-of-the-art nesting algorithm\n",
    "   - May find fundamentally different configurations\n",
    "   - Focus on large N (101-200) where 5% improvement closes the gap\n",
    "\n",
    "2. **Implement backward propagation properly**\n",
    "   - Start from best N=200 solution\n",
    "   - Iteratively remove trees to get N=199, 198, etc.\n",
    "   - This propagates good configurations downward\n",
    "\n",
    "3. **Try asymmetric solutions**\n",
    "   - All current solutions appear symmetric\n",
    "   - Breaking symmetry might find better local optima\n",
    "\n",
    "4. **Focus on specific N values with low efficiency**\n",
    "   - N=1 has 45.4% efficiency (but is already optimal)\n",
    "   - Find N values with room for improvement"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
