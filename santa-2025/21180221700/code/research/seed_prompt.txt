## Current Status
- Best CV score: 70.630478 from exp_010 (saspav_best ensemble)
- Best LB score: 70.6305 (verified, matches CV)
- Target: 68.919154 | Gap to target: 1.711 points (2.48%)

## CRITICAL: 7 EXPERIMENTS WITH ZERO IMPROVEMENT
Experiments 011-017 have ALL produced the same score of 70.630478.
This is a clear signal that we are STUCK at a local optimum.
All single-pass approaches have been exhausted.

## Response to Evaluator
The evaluator correctly identified that:
1. Bottom-left-fill heuristic produces WORSE results (0.905 vs 0.435 for N=3)
2. Extracting subsets from larger N also produces WORSE results
3. The current solutions use PRECISE INTERLOCKING POSITIONS

The evaluator recommends implementing the ITERATIVE MIXING WORKFLOW from jiweiliu kernel.
I AGREE - this is the key insight we've been missing.

## Key Insight from jiweiliu Kernel
The jiweiliu kernel shows ITERATIVE MIXING achieves continuous improvements:
```
71.65 -> 71.46 # SA workflow (Numba-accelerated)
71.46 -> 71.45 # guided refinement (small perturbations)
71.45 -> 71.36 # SA workflow again
```
This achieves 0.29 points improvement through ITERATION.

## What We Have NOT Tried (CRITICAL)
1. **Numba-accelerated SA with specific parameters**:
   - Tmax: 0.001, Tmin: 0.000001
   - nsteps: 10, nsteps_per_T: 10000
   - position_delta: 0.002, angle_delta: 1.0
   - delta_t: 0.002

2. **Grid configuration exploration**:
   - Generate ALL valid (ncols, nrows, append_x, append_y) combinations
   - Run SA on each to find different local optima

3. **Deletion cascade**:
   - For each large N solution, iteratively remove the tree that minimizes bounding box
   - Propagates improvements from large N to small N

4. **Guided refinement** (from sacuscreed kernel):
   - Small perturbations to squeeze out improvements
   - Iterate: SA → guided refinement → SA → guided refinement

5. **ITERATIVE MIXING**:
   - The key is to ITERATE between approaches, not run them once

## Score Breakdown Analysis
- Small N (1-20): 8.05 (11.4%) - worst efficiency but small impact
- Medium N (21-50): 10.98 (15.5%)
- Large N (51-100): 17.62 (24.9%)
- Very Large N (101-200): 33.98 (48.1%) - MOST IMPACT

To close the 1.711 gap:
- Very Large N needs only 5% improvement to close entire gap
- Large N needs 9.7% improvement
- Focus on N=101-200 for maximum impact

## Recommended Approach (Priority Order)

### EXPERIMENT 018: Implement jiweiliu's Full Workflow

**Step 1: Implement Numba-accelerated SA**
- Copy the SA optimization code from jiweiliu kernel
- Use the specific SA parameters that work
- Generate grid configurations for N=1-200

**Step 2: Run SA on grid configurations**
- For each N, generate multiple grid configs (ncols, nrows, append_x, append_y)
- Run SA on each, keep best result
- Compare with current best, keep improvements

**Step 3: Apply deletion cascade**
- For each improved large N solution
- Iteratively remove tree that minimizes bounding box
- Check if resulting smaller N solutions beat current best

**Step 4: Apply guided refinement**
- For each N, try small perturbations (position_delta=0.002, angle_delta=1.0)
- Keep any improvements

**Step 5: ITERATE**
- Repeat steps 2-4 until no more improvements

### Implementation Notes
The jiweiliu kernel is in: research/kernels/jiweiliu_super-fast-simulated-annealing-with-translations/
The sacuscreed kernel is in: research/kernels/sacuscreed_santa2025-solutions-guided-refinement/

Key functions to implement:
1. `sa_optimize_improved()` - Numba-accelerated SA
2. `deletion_cascade_numba()` - Propagate improvements from large to small N
3. `guided_refinement()` - Small perturbations

## What NOT to Try
- ❌ More single-pass SA (already tried 7 times)
- ❌ Constraint programming (produces worse results)
- ❌ Bottom-left-fill heuristic (produces worse results)
- ❌ Random subset extraction (produces worse results)
- ❌ Any approach that doesn't ITERATE

## Validation Notes
- CV scheme: Shapely-based overlap detection matches Kaggle exactly
- All 6 submissions show CV = LB (perfect alignment)
- No validation concerns

## SUBMISSION STRATEGY
- Remaining submissions: 84 (ABUNDANT!)
- Submit after this experiment: YES - we need LB feedback on iterative mixing
- Even if score doesn't improve, LB feedback is valuable