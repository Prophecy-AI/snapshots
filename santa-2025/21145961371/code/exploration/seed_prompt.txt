# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 1)

## Current Status
- Best CV score: 70.676102 from exp_000 (001_baseline)
- Best LB score: N/A (not yet submitted)
- Target: 68.919154 | Gap to target: 1.757 points (2.5%)

## Response to Evaluator
The evaluator correctly identified that:
1. The baseline is established correctly at 70.676102
2. Local search on pre-optimized solutions yields minimal improvement (0.0006 max from corner extraction)
3. Deletion cascade should be the highest priority next step
4. Per-N score analysis is needed to prioritize optimization efforts

**I agree with all evaluator recommendations.** The per-N analysis has now been completed:
- N=1 contributes 0.661 (highest single contribution)
- N=1-10 contributes 6.1% of total score
- N=1-50 contributes 26.9% of total score
- Small N values are critical for improvement

## Key Insights from Analysis
1. **Pre-optimized solutions are at a strong local optimum** - bbox3, SA, backward propagation all yield 0 improvement
2. **Corner extraction gave only 0.000634 improvement** - not enough to close the 1.76 point gap
3. **The target of 68.919 requires fundamentally different configurations**, not just optimization
4. **Crystalline/lattice packing may be superior for large N** (from Medium article)
5. **N < 58: Unstructured SA packings; N > 58: Crystalline packings** (from research)

## Available Resources
1. **Pre-optimized CSVs**: /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/
2. **bbox3 C++ optimizer**: Already compiled at /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bbox3
3. **SA optimizer code**: /home/code/research/kernels/jazivxt_why-not/why-not.ipynb

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY] Submit Baseline for LB Calibration**
We have 95 submissions remaining. Submit the baseline to get LB feedback and calibrate CV-LB relationship.

### 2. **[HIGH PRIORITY] Deletion Cascade Algorithm**
Generate better small-N configurations by iteratively removing trees from large-N configs:
- Start from N=200, propagate down to N=1
- For each N, try removing each tree and keep the best result
- This explores different solution basins
- Expected improvement: ~0.15-0.3 points

### 3. **[HIGH PRIORITY] Grid/Lattice Initialization for Large N**
For N > 58, try crystalline packing patterns:
- Hexagonal lattice
- Square lattice with alternating orientations
- Diamond patterns
- Run SA to refine after initialization

### 4. **[MEDIUM PRIORITY] Multi-Start Random for Small N (N=1-20)**
Small N contributes disproportionately to score:
- N=1 alone contributes 0.661 (almost 1% of total)
- Run 100+ random restarts for each small N
- Use SA to optimize each random start

### 5. **[MEDIUM PRIORITY] Ensemble Best Per-N Configurations**
After generating multiple solution sources:
- Deletion cascade results
- Grid initialization results
- Multi-start random results
- Select best configuration for each N independently

## What NOT to Try
- ❌ Running bbox3 on pre-optimized solutions (yields 0 improvement)
- ❌ More SA iterations on existing solutions (local optimum)
- ❌ Backward propagation (already tried, 0 improvement)
- ❌ Simple corner extraction (only 0.0006 improvement)

## SUBMISSION STRATEGY
- Remaining submissions: 95
- **Submit after this experiment? YES** - We have abundant submissions and need LB calibration
- Submit baseline first, then submit any improvement

## Validation Notes
- Score is calculated as sum of (side²/N) for N=1 to 200
- No overlaps allowed (touching is OK)
- Use Shapely STRtree for efficient collision detection
- Verify no overlaps before submission

## Next Experiment: 002_deletion_cascade
Implement deletion cascade algorithm:
1. Load baseline configurations
2. For N from 200 down to 2:
   - For each tree i in config[N]:
     - Remove tree i, calculate new bbox for N-1
     - If better than current best for N-1, update
3. Apply fix_direction rotation optimization to each result
4. Ensemble with baseline (keep best per-N)
5. Calculate total score and submit if improved
