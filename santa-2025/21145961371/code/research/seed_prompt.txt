# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 4)

## Current Status
- Best CV score: 70.676102 from all 4 experiments (stuck at same score)
- Best LB score: 70.676102 (confirmed via 2 submissions)
- Target: 68.919154 | Gap to target: 1.756948 (2.55%)

## Public Kernel Status (CRITICAL!)
- Have we implemented the best kernel yet? **NO** - We've only used pre-optimized CSVs
- Top kernels identified:
  1. `seshurajup/71-78-jit-parallel-sa-c-tpu-96-cores` - Parallel SA with fractional translation
  2. `egortrushin/santa25-simulated-annealing-with-translations` - Lattice init + SA
  3. `crodoc/74-75-backpacking-christmas-trees` - Backpacking approach
  4. `yongsukprasertsuk/santa-2025-best-keeping-bbox3-runner` - bbox3 runner
- Kernels we've implemented: NONE (only used pre-optimized CSVs)
- **CRITICAL**: We must implement actual optimization algorithms, not just use pre-optimized solutions!

## CV-LB Relationship Analysis
- CV = LB (essentially zero gap: 0.000002)
- Our scoring function is accurate
- The problem is NOT CV-LB gap - it's that we're stuck at a local optimum

## Response to Evaluator
The evaluator correctly identified that:
1. Random initialization WITHOUT optimization is useless (confirmed: 7x worse for N=10)
2. The baseline is at a very strong local optimum
3. We need to try lattice initialization + SA optimization

**I agree with the evaluator's assessment.** The key insight is that random placement alone cannot compete with sophisticated optimization. We must:
1. Generate new configurations (lattice or random)
2. **OPTIMIZE them with SA or bbox3** (this was missing from exp_003!)

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY]** Compile and Run bbox3 C++ Optimizer
The bbox3 optimizer is available at `/home/nonroot/snapshots/santa-2025/21116303805/code/bbox3.cpp`.
This is a fast C++ optimizer that can run millions of iterations.

**Implementation:**
```bash
# Compile bbox3
cd /home/code/experiments/005_bbox3_optimization
cp /home/nonroot/snapshots/santa-2025/21116303805/code/bbox3.cpp .
g++ -O3 -march=native -std=c++17 -fopenmp -o bbox3 bbox3.cpp

# Run optimization on baseline
./bbox3 -i /home/code/experiments/001_baseline/santa-2025.csv -o optimized.csv -n 50000 -r 32
```

**Why this is the right approach:**
- bbox3 is much faster than Python
- Can run millions of iterations
- Uses parallel processing with OpenMP
- Has proven to work in public kernels

### 2. **[HIGH PRIORITY]** Lattice Initialization + SA for Large N
The egortrushin kernel shows that lattice-based configurations for specific N values can be optimized with SA.

**Target N values:**
- N=72: 4x9 grid (36 cells, 2 trees per cell)
- N=100: 5x10 grid
- N=144: 6x12 grid
- N=156: 6x13 grid
- N=196: 7x14 grid
- N=200: 7x15 grid (take first 200)

**Implementation:**
```python
def create_lattice_config(n, nx, ny, dx=0.8, dy=0.8, angle1=0, angle2=180):
    """Create a lattice configuration with 2 trees per cell."""
    trees = []
    for i in range(nx):
        for j in range(ny):
            if len(trees) >= n:
                break
            x1 = i * dx
            y1 = j * dy
            trees.append((x1, y1, angle1))
            if len(trees) < n:
                x2 = x1 + dx/2
                y2 = y1 + dy/2
                trees.append((x2, y2, angle2))
    return trees[:n]

# After creating lattice, MUST optimize with SA or bbox3!
```

### 3. **[MEDIUM PRIORITY]** Parallel SA with Fractional Translation
The seshurajup kernel shows a sophisticated C++ parallel SA optimizer.

**Key features:**
- Multi-threaded optimization
- Fractional translation refinement
- Population-based approach with multiple restarts

**Implementation:**
```bash
# Copy and compile the parallel SA optimizer
cp /home/code/research/kernels/seshurajup_71-78-jit-parallel-sa-c-tpu-96-cores/*.cpp .
g++ -O3 -march=native -std=c++17 -fopenmp -o sa_parallel sa_v1_parallel.cpp
./sa_parallel -i baseline.csv -o optimized.csv -n 50000 -r 8
```

### 4. **[LOWER PRIORITY]** Greedy Backtracking
Build configurations from scratch using greedy placement with backtracking.

**Implementation:**
```python
def greedy_backtracking(n, max_backtracks=100):
    """Build configuration by placing trees one at a time with backtracking."""
    trees = []
    backtrack_count = 0
    
    while len(trees) < n and backtrack_count < max_backtracks:
        # Try to place next tree
        best_pos = find_best_position(trees)
        if best_pos:
            trees.append(best_pos)
        else:
            # Backtrack: remove last tree and try different position
            if trees:
                trees.pop()
                backtrack_count += 1
    
    return trees
```

## What NOT to Try
- ❌ Random initialization WITHOUT optimization (proven useless)
- ❌ Deletion cascade (0 improvements found)
- ❌ Full ensemble from existing CSVs (already at same optimum)
- ❌ Local search on pre-optimized solutions (already at local optimum)

## SUBMISSION STRATEGY
- Remaining submissions: 93
- Submit after this experiment? **YES** - We have abundant submissions
- LB feedback is valuable for calibration

## Validation Notes
- CV scheme: Direct scoring (sum of side^2/N for all N)
- CV = LB (no gap)
- Precision: Use %.18f format when saving CSVs
- Overlap detection: Use Shapely STRtree for efficiency

## Key Insight
**The problem is NOT that we can't find good solutions - it's that we haven't tried OPTIMIZATION.**

All 4 experiments so far have either:
1. Used pre-optimized solutions directly (no improvement possible)
2. Tried random placement WITHOUT optimization (much worse)

**The next experiment MUST include actual optimization (SA, bbox3, or similar).**

## Expected Outcome
If bbox3 optimization works, we should see:
- Small improvements (0.001-0.01) on individual N values
- Cumulative improvement across all N
- Progress toward the target

If no improvement after bbox3, we need to:
- Try lattice initialization + SA for large N
- Try parallel SA with fractional translation
- Consider that the baseline may already be globally optimal (unlikely)
