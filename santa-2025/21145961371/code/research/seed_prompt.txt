# Santa 2025 Christmas Tree Packing - Evolved Seed Prompt (Loop 8)

## Current Status
- Best CV score: 70.676102 from exp_000 (baseline)
- Best LB score: 70.676102 (confirmed via 3 submissions)
- Target: 68.919154 | Gap to target: 1.757 points (2.49%)
- Submissions used: 3/100 (93 remaining)

## CRITICAL INSIGHT: Our Score vs Leaderboard
- Our score (70.676) appears BETTER than current LB #1 (71.19 per web search)
- This suggests either outdated LB data OR we're already competitive
- Regardless, we still need to close the 1.757 point gap to target

## Response to Evaluator
The evaluator correctly identified that:
1. The lattice+SA implementation is broken (ALL moves rejected)
2. We're stuck at a local optimum after 8 experiments
3. We need fundamentally different approaches

I AGREE with the evaluator's assessment. After 8 experiments with zero improvement, we must pivot to completely different approaches. The evaluator's priorities are correct:
1. Create proper ensemble from ALL sources (quick win)
2. Try basin hopping (large random jumps)
3. Research symmetric packing patterns
4. Focus on small N values

## Key Analysis Findings (Loop 8)
1. **Target requires 2.49% UNIFORM improvement** across ALL N values
   - Cannot be achieved by improving just a few N values
   - Need systematic improvement across all 200 configurations

2. **N=1 is already optimal** (45 degrees, score 0.661250)
   - No room for improvement on N=1

3. **Packing efficiency ranges from 37% (N=1) to 73% (N=150-200)**
   - Small N values have lowest efficiency but are already near optimal
   - Large N values have higher efficiency but more room for improvement

4. **All 8 experiments stuck at 70.676102**
   - Local search methods exhausted (bbox3, SA, deletion cascade)
   - Lattice+SA implementation broken
   - Need fundamentally different approaches

## What Has Been Tried (ALL FAILED)
1. exp_000: Baseline (70.676102)
2. exp_001: Full ensemble from 30 CSV files (no improvement)
3. exp_002: Deletion cascade (no improvement)
4. exp_003: Random initialization (much worse)
5. exp_004: bbox3 C++ optimizer (no improvement)
6. exp_005: Parallel SA (no improvement)
7. exp_006: Lattice SA (worse)
8. exp_007: Lattice SA fixed (broken - all moves rejected)

## Recommended Approaches (Priority Order)

### Priority 1: PROPER ENSEMBLE FROM ALL SOURCES
The evaluator noted that candidate_004.csv may have improvements for specific N values.
We should:
1. Load ALL 726 CSV files from snapshots
2. For EACH N value, find the configuration with the LOWEST score
3. Create a new submission that uses the BEST configuration for each N
4. This is a quick win that doesn't require optimization

**CRITICAL**: When loading CSVs, preserve precision by reading as strings!

### Priority 2: BASIN HOPPING
Different from SA because it uses LARGE random jumps:
1. Start from baseline configuration
2. Apply a LARGE random perturbation (completely new positions)
3. Run local optimization (bbox3)
4. Accept if better, otherwise reject
5. Repeat with different random seeds

### Priority 3: GENETIC ALGORITHM
Crossover between different solutions:
1. Create population of solutions from different sources
2. Crossover: For each N, randomly select from parent A or B
3. Mutation: Small perturbations
4. Selection: Keep best solutions
5. Repeat for many generations

### Priority 4: SYMMETRIC PACKING PATTERNS
The "Symmetric solutions that are apparently optimal" discussion (42 votes) suggests:
1. For certain N values, symmetric packings may be optimal
2. Research what symmetric patterns work for which N values
3. Implement and test

### Priority 5: FOCUS ON LARGE N VALUES
Since small N values are near optimal, focus on large N (100-200):
1. These have higher packing efficiency (71-73%)
2. More room for improvement
3. Each improvement contributes to total score

## What NOT to Try
- ❌ More local search on baseline (exhausted)
- ❌ Lattice+SA (broken implementation, 3 failed attempts)
- ❌ Random initialization without optimization (much worse)
- ❌ Deletion cascade (no improvement found)

## Validation Notes
- CV-LB gap is essentially zero (0.000002)
- Our scoring function is accurate
- Precision is critical - read/write CSVs as strings with 's' prefix

## SUBMISSION STRATEGY
- 93 submissions remaining - ABUNDANT!
- Submit after EVERY experiment that produces a valid submission
- LB feedback is FREE information - use it!
- We need to verify if our score is actually competitive on LB

## Next Experiment
**PRIORITY 1: Create proper ensemble from ALL 726 CSV files**
1. Load all CSV files preserving precision
2. For each N, find best configuration across all sources
3. Create ensemble submission
4. Submit to verify score on LB

This is a quick win that could provide immediate improvement without any optimization.