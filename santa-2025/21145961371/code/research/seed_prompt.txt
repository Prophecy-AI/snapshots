# Santa 2025 Christmas Tree Packing - Seed Prompt (Loop 2)

## Current Status
- Best CV score: 70.676102 from exp_000 (baseline) and exp_001 (full ensemble)
- Best LB score: 70.676102 (submitted)
- Target: 68.919154 | Gap to target: 1.757 points (2.55%)
- Submissions used: 1/100 (94 remaining)

## CV-LB Relationship Analysis
- Only 1 submission so far, but CV-LB gap is essentially zero (0.000002)
- Our scoring function is accurate - no calibration issues
- The challenge is purely about finding better configurations

## Response to Evaluator
The evaluator correctly identified that:
1. **All 30 sources converge to the same local optimum** - Confirmed by exp_001
2. **We cannot improve by combining existing solutions** - Must GENERATE new configurations
3. **Deletion cascade has been the top priority for 2 experiments and hasn't been done** - This is the critical gap

I fully agree with the evaluator's assessment. The next experiment MUST implement deletion cascade or another constructive approach that generates novel configurations. We've spent 2 experiments confirming the baseline is optimal among existing solutions - now we must create new ones.

## CRITICAL INSIGHT: The Local Optimum Problem
All 30 pre-optimized CSV files select the same configurations for every N. This means:
- The public solutions are all at the SAME local optimum
- Running more SA/bbox3 on these solutions = 0 improvement
- The 1.76 point gap to target requires escaping this basin entirely

## Recommended Approaches (Priority Order)

### 1. **[HIGHEST PRIORITY] Deletion Cascade Algorithm**
Generate novel small-N configurations by iteratively removing trees from large-N configs:

```python
def deletion_cascade(baseline_configs):
    """Propagate good large configs to smaller sizes."""
    best_configs = {n: baseline_configs[n].copy() for n in range(1, 201)}
    
    for n in range(200, 1, -1):
        trees = best_configs[n]
        current_best_score = get_score(best_configs[n-1], n-1)
        
        for i in range(n):
            # Remove tree i
            new_trees = trees[:i] + trees[i+1:]
            # Recenter and optimize rotation
            new_trees = fix_direction(new_trees)
            new_score = get_score(new_trees, n-1)
            
            if new_score < current_best_score:
                current_best_score = new_score
                best_configs[n-1] = new_trees
                print(f"N={n-1}: Improved to {new_score:.6f} by deletion cascade!")
    
    return best_configs
```

**Why this works:**
- Generates NOVEL configurations that don't exist in any source file
- Naturally targets small N values (which contribute disproportionately to score)
- O(N²) per cascade, easily parallelizable
- Expected improvement: 0.15-0.3 points

### 2. **[HIGH PRIORITY] Exhaustive Search for Small N**
For N=1-10, run exhaustive search over rotation angles:

```python
def exhaustive_small_n(n, trees):
    """Exhaustive search for small N configurations."""
    best_score = float('inf')
    best_config = None
    
    # Try all rotation angles in 0.1° increments
    for angle in np.arange(0, 360, 0.1):
        rotated = rotate_all_trees(trees, angle)
        recentered = recenter(rotated)
        score = get_score(recentered, n)
        if score < best_score:
            best_score = score
            best_config = recentered
    
    return best_config
```

N=1 alone contributes 0.661 to the score. If we can reduce N=1's side from 0.813 to 0.75, that's 0.10 points improvement.

### 3. **[MEDIUM PRIORITY] Multi-Start Random Initialization**
Generate completely new starting configurations for small N:

```python
def multi_start_random(n, num_restarts=1000):
    """Generate random initial configurations and optimize."""
    best_config = None
    best_score = float('inf')
    
    for _ in range(num_restarts):
        # Random placement in a grid
        config = random_placement(n)
        # Run local optimization
        config = local_optimize(config)
        score = get_score(config, n)
        
        if score < best_score:
            best_score = score
            best_config = config
    
    return best_config
```

### 4. **[MEDIUM PRIORITY] Corner Extraction from Larger Configs**
Extract smaller layouts from corners of larger configurations:

```python
def corner_extraction(large_config, target_n):
    """Extract target_n trees from corner of large_config."""
    corners = ['bottom-left', 'bottom-right', 'top-left', 'top-right']
    
    best_config = None
    best_score = float('inf')
    
    for corner in corners:
        extracted = extract_from_corner(large_config, target_n, corner)
        extracted = fix_direction(extracted)
        score = get_score(extracted, target_n)
        
        if score < best_score:
            best_score = score
            best_config = extracted
    
    return best_config
```

## Key Optimization Techniques

### fix_direction Rotation
Optimize global rotation angle to minimize bounding box:
```python
from scipy.optimize import minimize_scalar
from scipy.spatial import ConvexHull

def fix_direction(trees):
    """Optimize global rotation to minimize bounding box."""
    all_points = get_all_polygon_vertices(trees)
    hull_points = all_points[ConvexHull(all_points).vertices]
    
    def bbox_at_angle(angle):
        rotated = rotate_points(hull_points, angle)
        return max(rotated[:, 0].max() - rotated[:, 0].min(),
                   rotated[:, 1].max() - rotated[:, 1].min())
    
    result = minimize_scalar(bbox_at_angle, bounds=(0.001, 89.999), method='bounded')
    return apply_rotation(trees, result.x)
```

### Tree Geometry
```python
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```

## What NOT to Try
- ❌ Running more SA/bbox3 on pre-optimized solutions (already at local optimum)
- ❌ Combining existing CSV files (already done - no improvement)
- ❌ Loading and submitting existing solutions without modification
- ❌ Hyperparameter tuning on existing optimizers

## SUBMISSION STRATEGY
- Remaining submissions: 94
- **Submit after EVERY experiment** - we have abundant submissions
- LB feedback is free information - use it to calibrate our approach
- Even if CV doesn't improve, submit to verify our scoring is accurate

## Validation Notes
- CV scheme: Calculate sum of (side^2 / N) for N=1 to 200
- Overlap detection: Use Shapely STRtree for efficient collision detection
- Always verify no overlaps before submission

## Per-N Score Analysis (from previous analysis)
- N=1: 0.661 (highest individual contribution)
- N=1-10: 6.1% of total score
- N=1-50: 26.9% of total score
- N=1-100: 51.9% of total score

**Focus on small N values - they have the highest impact per tree!**

## Files and Resources
- Baseline: `/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/ensemble.csv`
- All 30 CSVs: `/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/**/*.csv`
- bbox3.cpp: `/home/nonroot/snapshots/santa-2025/21116303805/code/bbox3.cpp` (needs compilation)
- Backpacking kernel: `/home/code/research/kernels/crodoc_74-75-backpacking-christmas-trees/`
