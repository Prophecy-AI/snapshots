# Santa 2025 - Evolved Strategy (Loop 6)

## Current Status
- Best VALID CV score: 87.99 from exp_005 (Zaburo row-based)
- Best VALID LB score: 87.99 (ACCEPTED by Kaggle!)
- Target: 68.887226 | Gap to target: 19.1 points (27.7%)
- Pre-optimized baselines (~70.6) have overlaps - Kaggle REJECTS them

## ⚠️ CRITICAL CONTEXT

**We now have a VALID baseline (87.99) that Kaggle accepts!**

The pre-optimized baselines (~70.6) have subtle overlaps that our local validation misses but Kaggle detects. We CANNOT use them directly.

**The path forward is clear:**
1. Start from Zaburo's valid solution (87.99)
2. Implement simulated annealing (SA) to optimize
3. SA can improve from 88 toward 70 (and beyond)

## Response to Evaluator

The evaluator correctly identified:
1. ✅ exp_005 was ACCEPTED by Kaggle - confirmed!
2. ✅ The gap is large (19 points) but achievable with SA
3. ✅ Small N values (2-10) need special attention
4. ✅ Backward propagation should be implemented after SA

I agree with all points. The next experiment should implement SA from scratch.

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN (pre-compiled binaries)
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- Loading pre-optimized baselines directly (they have overlaps!)

## ✅ REQUIRED: IMPLEMENT SIMULATED ANNEALING FROM SCRATCH

**This is the ONLY path forward.** The top kernels all use SA, but we must implement it ourselves.

### SA Implementation Requirements:

```python
# 1. Load Zaburo's valid solution (87.99)
zaburo_submission = pd.read_csv('/home/code/experiments/005_zaburo_rowbased/submission.csv')

# 2. SA Parameters (from top kernels)
T0 = 1.0           # Initial temperature
T_MIN = 0.000005   # Final temperature
ALPHA = 0.9995     # Cooling rate
MAX_ITERS = 10000  # Per N value

# 3. SA Moves (choose randomly):
def sa_move(trees, move_type):
    if move_type == 'translate':
        # Small translation: ±0.01 to ±0.1
        dx = random.uniform(-0.1, 0.1)
        dy = random.uniform(-0.1, 0.1)
        tree_idx = random.randint(0, len(trees)-1)
        trees[tree_idx].x += dx
        trees[tree_idx].y += dy
    
    elif move_type == 'rotate':
        # Small rotation: ±1° to ±10°
        dangle = random.uniform(-10, 10)
        tree_idx = random.randint(0, len(trees)-1)
        trees[tree_idx].angle += dangle
    
    elif move_type == 'swap':
        # Swap two trees
        i, j = random.sample(range(len(trees)), 2)
        trees[i], trees[j] = trees[j], trees[i]
    
    return trees

# 4. SA Loop:
def simulated_annealing(trees, n):
    current_score = calculate_score(trees)
    best_score = current_score
    best_trees = copy.deepcopy(trees)
    T = T0
    
    for iteration in range(MAX_ITERS):
        # Make a move
        new_trees = copy.deepcopy(trees)
        move_type = random.choice(['translate', 'rotate', 'swap'])
        new_trees = sa_move(new_trees, move_type)
        
        # Check for overlaps
        if has_overlap(new_trees):
            continue  # Reject move
        
        # Calculate new score
        new_score = calculate_score(new_trees)
        
        # Accept or reject
        delta = new_score - current_score
        if delta < 0 or random.random() < math.exp(-delta / T):
            trees = new_trees
            current_score = new_score
            
            if current_score < best_score:
                best_score = current_score
                best_trees = copy.deepcopy(trees)
        
        # Cool down
        T = max(T * ALPHA, T_MIN)
    
    return best_trees, best_score
```

### Focus on High-Impact N Values First:

The analysis shows these N values have the largest gaps vs baseline:
- N=5: gap=0.38 (Zaburo=0.80, Baseline=0.42)
- N=4: gap=0.35 (Zaburo=0.77, Baseline=0.42)
- N=2: gap=0.27 (Zaburo=0.72, Baseline=0.45)
- N=6: gap=0.27 (Zaburo=0.67, Baseline=0.40)

**Start SA optimization with N=2-10 first!** These small N values:
1. Have the highest per-tree score contribution
2. Are fast to optimize (few trees)
3. Can recover ~2-3 points of the gap

### Validation is CRITICAL:

```python
from decimal import Decimal, getcontext
getcontext().prec = 25
SCALE = Decimal('1e15')

def validate_no_overlap(trees):
    """Use integer coordinates to match Kaggle's validation."""
    polygons = []
    for tree in trees:
        # Create polygon with integer coordinates
        coords = [(int(Decimal(str(x)) * SCALE), 
                   int(Decimal(str(y)) * SCALE)) 
                  for x, y in tree.vertices]
        polygons.append(Polygon(coords))
    
    for i in range(len(polygons)):
        for j in range(i+1, len(polygons)):
            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):
                return False, f"Trees {i} and {j} overlap"
    return True, "OK"
```

## Expected Outcome

With proper SA implementation:
- Start: 87.99 (Zaburo)
- After SA on N=2-10: ~85 (recover ~3 points)
- After SA on N=11-50: ~80 (recover ~5 more points)
- After SA on all N: ~75-78 (recover ~10 more points)
- With more iterations and refinement: ~70-72

The target (68.89) is achievable but requires:
1. Good SA implementation
2. Many iterations
3. Per-N optimization
4. Possibly backward propagation

## Experiment Structure

```
experiments/006_sa_from_scratch/
├── sa_optimizer.ipynb      # Main SA implementation
├── submission.csv          # Final submission
└── metrics.json           # Per-N scores and total
```

## Success Criteria

- ✅ Score improves from 87.99
- ✅ No overlaps (Kaggle accepts)
- ✅ Per-N tracking shows improvements
- ✅ SA is implemented in pure Python (no binaries)

## SUBMIT AFTER THIS EXPERIMENT

We have 91 submissions remaining. Submit to get LB feedback on SA performance.