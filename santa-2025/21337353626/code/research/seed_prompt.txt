# Santa 2025 - Christmas Tree Packing Optimization

## Current Status
- Best CV score: 70.572798 (exp_000, but REJECTED by Kaggle - overlaps)
- Best VALID CV score: 72.166269 (exp_004 - 0 overlaps, should be accepted)
- Best LB score: 169.458990 (exp_003 greedy - accepted but terrible)
- Target: 68.887226 | Gap from best valid: 3.28 points (4.8%)
- Submissions used: 4/100 (92 remaining - ABUNDANT!)

## ⚠️ CRITICAL: SUBMIT exp_004 FIRST!

exp_004 has 0 overlaps and score 72.17. We need to verify Kaggle accepts it.
**DO THIS IMMEDIATELY** - we have 92 submissions left!

## Response to Evaluator

The evaluator correctly identified that:
1. The greedy fallback for N=30, 134, 166 costs ~1.55 points
2. Zaburo's row-based approach (88.33) is a much better fallback than greedy (169.5)
3. We should submit exp_004 to verify acceptance

**I AGREE with all points.** The immediate priority is:
1. Submit exp_004 to verify Kaggle accepts it
2. Replace greedy fallback with row-based approach
3. Implement backward propagation for further optimization

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with binaries - FORBIDDEN

## ✅ EXPERIMENT 005: IMPROVED HYBRID WITH ROW-BASED FALLBACK

### Step 1: Submit exp_004 First
Before any new experiment, submit exp_004 to verify Kaggle accepts it.

### Step 2: Implement Row-Based Fallback (Zaburo's Approach)

Replace greedy fallback with row-based placement for N=30, 134, 166:

```python
def find_best_trees_row_based(n: int) -> tuple[float, list[ChristmasTree]]:
    """Zaburo's row-based approach - pure Python, guaranteed no overlaps."""
    best_score, best_trees = float("inf"), None
    for n_even in range(1, n + 1):
        for n_odd in [n_even, n_even - 1]:
            all_trees = []
            rest = n
            r = 0
            while rest > 0:
                m = min(rest, n_even if r % 2 == 0 else n_odd)
                rest -= m
    
                angle = 0 if r % 2 == 0 else 180
                x_offset = 0 if r % 2 == 0 else Decimal("0.7") / 2
                y = r // 2 * Decimal("1.0") if r % 2 == 0 else (Decimal("0.8") + (r - 1) // 2 * Decimal("1.0"))
                row_trees = [ChristmasTree(center_x=Decimal("0.7") * i + x_offset, center_y=y, angle=angle) for i in range(m)]
                all_trees.extend(row_trees)
    
                r += 1
            # Calculate bounding box
            xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in all_trees])
            min_x, min_y = xys.min(axis=0)
            max_x, max_y = xys.max(axis=0)
            score = max(max_x - min_x, max_y - min_y) ** 2
            if score < best_score:
                best_score = score
                best_trees = all_trees
    return best_score, best_trees
```

Expected improvement: ~1.2 points (from 72.17 to ~70.97)

### Step 3: Compare Per-N Scores

For N=30, 134, 166:
- Current (greedy): ~0.85 per-N score
- Row-based: ~0.44 per-N score
- Baseline (pre-optimized): ~0.35 per-N score

### Step 4: Create Hybrid Submission

1. Load pre-optimized baseline (70.6)
2. For N values with overlaps (30, 134, 166), use row-based fallback
3. Validate 0 overlaps for all N
4. Calculate total score
5. Submit to Kaggle

## ✅ EXPERIMENT 006: BACKWARD PROPAGATION

After exp_005, implement Chistyakov's backward propagation:

```python
def backward_propagation(dict_of_tree_list, dict_of_side_length):
    """
    Start from large N, remove trees one by one (prioritizing those touching bbox).
    Use resulting configuration for smaller N if it improves score.
    """
    for group_id_main in range(200, 2, -1):
        group_id_main = f'{int(group_id_main):03n}'
        candidate_tree_list = [tree.clone() for tree in dict_of_tree_list[group_id_main]]

        while len(candidate_tree_list) > 1:
            group_id_prev = f'{len(candidate_tree_list) - 1:03n}'
            best_side_length = dict_of_side_length[group_id_prev]
            
            # Try removing each tree touching bbox
            tree_idx_list = get_bbox_touching_tree_indices(candidate_tree_list)      
            for tree_idx_to_delete in tree_idx_list:
                candidate_tree_list_short = [tree.clone() for tree in candidate_tree_list]
                del candidate_tree_list_short[tree_idx_to_delete]
                candidate_side_length = get_tree_list_side_lenght(candidate_tree_list_short)
                
                if candidate_side_length < best_side_length:
                    # Found improvement!
                    dict_of_tree_list[group_id_prev] = candidate_tree_list_short
                    dict_of_side_length[group_id_prev] = candidate_side_length
                    break
            
            # Remove best tree and continue
            del candidate_tree_list[best_tree_idx_to_delete]
            
            if int(group_id_main) - int(group_id_prev) > 5:
                break
    
    return dict_of_tree_list, dict_of_side_length
```

## ✅ EXPERIMENT 007+: SIMULATED ANNEALING FROM SCRATCH

Implement SA in pure Python:

```python
def simulated_annealing(trees, T_start=1.0, T_end=0.001, iterations=10000):
    """
    SA moves:
    1. Small translation (dx, dy ~ 0.01)
    2. Small rotation (dangle ~ 1°)
    3. Swap two trees
    """
    current_score = calculate_score(trees)
    best_score = current_score
    best_trees = [t.clone() for t in trees]
    
    T = T_start
    cooling_rate = (T_end / T_start) ** (1 / iterations)
    
    for i in range(iterations):
        # Choose random move
        move_type = random.choice(['translate', 'rotate', 'swap'])
        
        if move_type == 'translate':
            idx = random.randint(0, len(trees) - 1)
            dx = random.gauss(0, 0.01)
            dy = random.gauss(0, 0.01)
            trees[idx].center_x += Decimal(str(dx))
            trees[idx].center_y += Decimal(str(dy))
            trees[idx].update_polygon()
        elif move_type == 'rotate':
            idx = random.randint(0, len(trees) - 1)
            dangle = random.gauss(0, 1)
            trees[idx].angle += Decimal(str(dangle))
            trees[idx].update_polygon()
        else:  # swap
            i, j = random.sample(range(len(trees)), 2)
            trees[i], trees[j] = trees[j], trees[i]
        
        # Check for overlaps
        if has_overlap(trees):
            # Reject move
            revert_move(trees, move_type, ...)
            continue
        
        new_score = calculate_score(trees)
        delta = new_score - current_score
        
        if delta < 0 or random.random() < math.exp(-delta / T):
            current_score = new_score
            if new_score < best_score:
                best_score = new_score
                best_trees = [t.clone() for t in trees]
        else:
            revert_move(trees, move_type, ...)
        
        T *= cooling_rate
    
    return best_score, best_trees
```

## SUBMISSION STRATEGY

With 92 submissions remaining, submit AGGRESSIVELY:
1. Submit exp_004 NOW to verify acceptance
2. Submit exp_005 (row-based fallback) 
3. Submit exp_006 (backward propagation)
4. Submit each SA iteration that shows improvement

## Per-N Score Tracking (MANDATORY)

Track improvements for EACH N value:
```python
def compare_per_n_scores(my_solution, baseline):
    improvements = []
    for n in range(1, 201):
        my_score = compute_score_for_n(my_solution, n)
        base_score = compute_score_for_n(baseline, n)
        diff = base_score - my_score  # positive = better
        if diff > 0.0001:
            improvements.append((n, diff))
            print(f"✅ N={n}: IMPROVED by {diff:.6f}")
    return improvements
```

## Key Findings from Research

1. **N=1 is already optimal** at 45° angle (score 0.661) - no improvement possible
2. **N=2 can be improved** by ~0.014 points with better angles (144°, 324°)
3. **Small N (2-10)** could close ~10.6% of gap (0.18 points)
4. **Asymmetric solutions** outperform symmetric ones (discussion 666880)
5. **Backward propagation** can improve smaller N from larger N configurations

## Target Path

Current: 72.17 (exp_004)
→ Row-based fallback: ~70.97 (save 1.2 points)
→ Backward propagation: ~70.5 (save 0.5 points)
→ SA optimization: ~69.5 (save 1.0 points)
→ Small N optimization: ~69.0 (save 0.5 points)
→ Target: 68.89

The target IS reachable with proper optimization!
