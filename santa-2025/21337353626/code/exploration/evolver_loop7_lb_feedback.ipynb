{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ceb1a5",
   "metadata": {},
   "source": [
    "# Evolver Loop 7 - LB Feedback Analysis\n",
    "\n",
    "**exp_006 (SA from scratch)**: CV=87.8112, LB=87.8112 (gap: 0.0000)\n",
    "\n",
    "The SA improved from 87.99 to 87.81 (0.18 points) by optimizing only N=2-4.\n",
    "\n",
    "## Key Insights from Top Kernels\n",
    "\n",
    "1. **Jonathan Chan's kernel** shows the winning approach:\n",
    "   - Ensemble from 15+ sources (best per-N)\n",
    "   - SA with T0=1.0, T_min=0.000005\n",
    "   - **Fractional translation** with step sizes: 0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001\n",
    "   - N=1 is FIXED at optimal: x=0, y=0, deg=45\n",
    "\n",
    "2. **The gap analysis**:\n",
    "   - Current: 87.81 (Zaburo + SA on N=2-4)\n",
    "   - Pre-optimized baseline: 70.6 (but has overlaps)\n",
    "   - Target: 68.89\n",
    "   - Gap: 18.9 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load the pre-optimized baseline per-N scores\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21329067673/submission/submission.csv'\n",
    "zaburo_path = '/home/code/experiments/005_zaburo_rowbased/submission.csv'\n",
    "sa_path = '/home/code/experiments/006_sa_from_scratch/submission.csv'\n",
    "\n",
    "# Load metrics from SA experiment\n",
    "with open('/home/code/experiments/006_sa_from_scratch/metrics.json', 'r') as f:\n",
    "    sa_metrics = json.load(f)\n",
    "\n",
    "print(\"SA Experiment Results:\")\n",
    "print(f\"Initial score (Zaburo): {sa_metrics['initial_score']:.6f}\")\n",
    "print(f\"Final score (SA): {sa_metrics['cv_score']:.6f}\")\n",
    "print(f\"Improvement: {sa_metrics['improvement']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc56443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare per-N scores: SA vs Zaburo\n",
    "sa_per_n = sa_metrics['per_n_scores']\n",
    "\n",
    "print(\"\\nPer-N Score Comparison (SA vs Zaburo):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top 20 N values by score (these contribute most to total)\n",
    "sorted_n = sorted(sa_per_n.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "for n_str, score in sorted_n:\n",
    "    n = int(n_str)\n",
    "    print(f\"N={n:3d}: score={score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum for small N\n",
    "# N=1: optimal is 45 degrees, side = 0.813173, score = 0.661250\n",
    "# This is already optimal in baseline\n",
    "\n",
    "print(\"\\nTheoretical Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(\"N=1: Optimal at 45°, score = 0.661250 (ALREADY OPTIMAL)\")\n",
    "print(\"N=2-4: SA improved these\")\n",
    "print(\"N=5-10: SA showed NO improvement despite many accepted moves\")\n",
    "print(\"\")\n",
    "print(\"PROBLEM: SA move sizes are too coarse!\")\n",
    "print(\"- Our SA uses: ±0.1 translation, ±10° rotation\")\n",
    "print(\"- Top kernels use: ±0.00001 to ±0.001 translation (100-10000x finer!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key insight: We need to use the PRE-OPTIMIZED baseline as starting point\n",
    "# It has better per-N scores, we just need to fix the overlapping N values\n",
    "\n",
    "print(\"\\nSTRATEGY:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Load pre-optimized baseline (score ~70.6)\")\n",
    "print(\"2. Identify N values with overlaps (29 N values)\")\n",
    "print(\"3. For overlapping N values, use Zaburo's valid solution\")\n",
    "print(\"4. Apply fractional translation refinement to ALL N values\")\n",
    "print(\"5. This should give us a valid submission with score ~72-75\")\n",
    "print(\"\")\n",
    "print(\"Then iterate:\")\n",
    "print(\"- Apply SA with MUCH finer moves (0.001 to 0.00001)\")\n",
    "print(\"- Keep best per-N across all experiments\")\n",
    "print(\"- Target: 68.89\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8243832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which N values have overlaps in the pre-optimized baseline\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "        self.polygon = self._create_polygon()\n",
    "    \n",
    "    def _create_polygon(self):\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (float(Decimal('0.0') * scale_factor), float(tip_y * scale_factor)),\n",
    "            (float(top_w / Decimal('2') * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(top_w / Decimal('4') * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(mid_w / Decimal('2') * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(mid_w / Decimal('4') * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(base_w / Decimal('2') * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(trunk_w / Decimal('2') * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(trunk_w / Decimal('2') * scale_factor), float(trunk_bottom_y * scale_factor)),\n",
    "            (float(-(trunk_w / Decimal('2')) * scale_factor), float(trunk_bottom_y * scale_factor)),\n",
    "            (float(-(trunk_w / Decimal('2')) * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(-(base_w / Decimal('2')) * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(-(mid_w / Decimal('4')) * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(-(mid_w / Decimal('2')) * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(-(top_w / Decimal('4')) * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(-(top_w / Decimal('2')) * scale_factor), float(tier_1_y * scale_factor)),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        return affinity.translate(rotated,\n",
    "                                  xoff=float(self.center_x * scale_factor),\n",
    "                                  yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def check_overlap(trees):\n",
    "    polygons = [t.polygon for t in trees]\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "print(\"ChristmasTree class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4092bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-optimized baseline and check overlaps\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return val[1:]\n",
    "    return str(val)\n",
    "\n",
    "def load_submission(path):\n",
    "    df = pd.read_csv(path)\n",
    "    trees_by_n = {}\n",
    "    for _, row in df.iterrows():\n",
    "        id_parts = row['id'].split('_')\n",
    "        n = int(id_parts[0])\n",
    "        x = parse_value(row['x'])\n",
    "        y = parse_value(row['y'])\n",
    "        deg = parse_value(row['deg'])\n",
    "        if n not in trees_by_n:\n",
    "            trees_by_n[n] = []\n",
    "        trees_by_n[n].append(ChristmasTree(center_x=x, center_y=y, angle=deg))\n",
    "    return trees_by_n\n",
    "\n",
    "print(\"Loading pre-optimized baseline...\")\n",
    "baseline_trees = load_submission(baseline_path)\n",
    "print(f\"Loaded {len(baseline_trees)} N values\")\n",
    "\n",
    "# Check for overlaps\n",
    "overlapping_n = []\n",
    "for n in range(1, 201):\n",
    "    if check_overlap(baseline_trees[n]):\n",
    "        overlapping_n.append(n)\n",
    "\n",
    "print(f\"\\nN values with overlaps: {len(overlapping_n)}\")\n",
    "print(f\"Overlapping N: {overlapping_n[:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline per-N scores\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def calculate_side_length(trees):\n",
    "    all_polygons = [t.polygon for t in trees]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    minx = Decimal(str(bounds[0])) / scale_factor\n",
    "    miny = Decimal(str(bounds[1])) / scale_factor\n",
    "    maxx = Decimal(str(bounds[2])) / scale_factor\n",
    "    maxy = Decimal(str(bounds[3])) / scale_factor\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "    return float(max(width, height))\n",
    "\n",
    "def calculate_score(trees, n):\n",
    "    side = calculate_side_length(trees)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "# Calculate baseline scores for valid N values\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    if n not in overlapping_n:\n",
    "        baseline_scores[n] = calculate_score(baseline_trees[n], n)\n",
    "\n",
    "print(f\"\\nBaseline scores for {len(baseline_scores)} valid N values:\")\n",
    "print(f\"Total (valid only): {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"\\nTop 10 valid N by score:\")\n",
    "sorted_valid = sorted(baseline_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for n, score in sorted_valid:\n",
    "    print(f\"N={n:3d}: score={score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d21b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Baseline (valid N) vs SA (all N)\n",
    "print(\"\\nComparison: Baseline vs SA for valid N values\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    if n in baseline_scores:\n",
    "        sa_score = sa_per_n[str(n)]\n",
    "        base_score = baseline_scores[n]\n",
    "        diff = sa_score - base_score  # positive = SA is worse\n",
    "        if abs(diff) > 0.0001:\n",
    "            improvements.append((n, base_score, sa_score, diff))\n",
    "\n",
    "print(f\"\\nN values where baseline is BETTER than SA:\")\n",
    "for n, base, sa, diff in sorted(improvements, key=lambda x: x[3], reverse=True)[:15]:\n",
    "    print(f\"N={n:3d}: baseline={base:.6f}, SA={sa:.6f}, diff={diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2756fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY INSIGHT: The pre-optimized baseline has MUCH better scores for most N values\n",
    "# We just need to fix the overlapping ones\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\")\n",
    "print(\"The pre-optimized baseline has MUCH better per-N scores!\")\n",
    "print(\"But it has overlaps in some N values.\")\n",
    "print(\"\")\n",
    "print(\"STRATEGY:\")\n",
    "print(\"1. Use baseline for N values WITHOUT overlaps\")\n",
    "print(\"2. Use Zaburo/SA for N values WITH overlaps\")\n",
    "print(\"3. Apply fractional translation to improve further\")\n",
    "print(\"\")\n",
    "print(f\"Baseline valid N count: {len(baseline_scores)}\")\n",
    "print(f\"Overlapping N count: {len(overlapping_n)}\")\n",
    "print(f\"\")\n",
    "print(f\"Estimated hybrid score:\")\n",
    "print(f\"  Baseline valid: {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"  SA for overlapping: {sum(sa_per_n[str(n)] for n in overlapping_n):.6f}\")\n",
    "print(f\"  Total: {sum(baseline_scores.values()) + sum(sa_per_n[str(n)] for n in overlapping_n):.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
