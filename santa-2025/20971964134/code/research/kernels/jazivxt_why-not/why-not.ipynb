{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119106,"databundleVersionId":14485445,"sourceType":"competition"},{"sourceId":14488573,"sourceType":"datasetVersion","datasetId":8816659}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Upvote everyone contributing to this great competition\n#!pip install shapely numba","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:18:32.17221Z","iopub.execute_input":"2026-01-09T08:18:32.172453Z","iopub.status.idle":"2026-01-09T08:18:32.177808Z","shell.execute_reply.started":"2026-01-09T08:18:32.172431Z","shell.execute_reply":"2026-01-09T08:18:32.176791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.copy('/kaggle/input/bucket-of-chump/submission.csv', '/kaggle/working/submission.csv')\nshutil.copy('/kaggle/input/bucket-of-chump/bbox3', '/kaggle/working/bbox3')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:18:32.180061Z","iopub.execute_input":"2026-01-09T08:18:32.180327Z","iopub.status.idle":"2026-01-09T08:18:32.250873Z","shell.execute_reply.started":"2026-01-09T08:18:32.180307Z","shell.execute_reply":"2026-01-09T08:18:32.249911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!chmod +x ./bbox3\n#!./bbox3 -n 1000 -r 96\n#!./bbox3 -n 2000 -r 96\n#!./bbox3 -n 1000 -r 4\n!./bbox3 -n 50 -r 4\n#!./bbox3 -n 1000 -r 96\n#!./bbox3 -n 2000 -r 96","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:18:32.25183Z","iopub.execute_input":"2026-01-09T08:18:32.252727Z","iopub.status.idle":"2026-01-09T08:19:28.205949Z","shell.execute_reply.started":"2026-01-09T08:18:32.252692Z","shell.execute_reply":"2026-01-09T08:19:28.204104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom decimal import Decimal, getcontext\nfrom shapely import affinity\nfrom shapely.geometry import Polygon\nfrom shapely.strtree import STRtree\n\n# Set precision for Decimal (25 is good for contest standards)\ngetcontext().prec = 25\nscale_factor = Decimal(\"1e18\")\n\n\nclass ChristmasTree:\n    \"\"\"Represents a single, rotatable Christmas tree of a fixed size.\"\"\"\n\n    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n        \"\"\"Initializes the Christmas tree with a specific position and rotation.\"\"\"\n        self.center_x = Decimal(center_x)\n        self.center_y = Decimal(center_y)\n        self.angle = Decimal(angle)\n\n        trunk_w = Decimal(\"0.15\")\n        trunk_h = Decimal(\"0.2\")\n        base_w = Decimal(\"0.7\")\n        mid_w = Decimal(\"0.4\")\n        top_w = Decimal(\"0.25\")\n        tip_y = Decimal(\"0.8\")\n        tier_1_y = Decimal(\"0.5\")\n        tier_2_y = Decimal(\"0.25\")\n        base_y = Decimal(\"0.0\")\n        trunk_bottom_y = -trunk_h\n\n        # Define the 15 vertices of the tree polygon\n        initial_polygon = Polygon(\n            [\n                (Decimal(\"0.0\") * scale_factor, tip_y * scale_factor),\n                (top_w / Decimal(\"2\") * scale_factor, tier_1_y * scale_factor),\n                (top_w / Decimal(\"4\") * scale_factor, tier_1_y * scale_factor),\n                (mid_w / Decimal(\"2\") * scale_factor, tier_2_y * scale_factor),\n                (mid_w / Decimal(\"4\") * scale_factor, tier_2_y * scale_factor),\n                (base_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n                (trunk_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n                (trunk_w / Decimal(\"2\") * scale_factor, trunk_bottom_y * scale_factor),\n                (-(trunk_w / Decimal(\"2\")) * scale_factor, trunk_bottom_y * scale_factor),\n                (-(trunk_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n                (-(base_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n                (-(mid_w / Decimal(\"4\")) * scale_factor, tier_2_y * scale_factor),\n                (-(mid_w / Decimal(\"2\")) * scale_factor, tier_2_y * scale_factor),\n                (-(top_w / Decimal(\"4\")) * scale_factor, tier_1_y * scale_factor),\n                (-(top_w / Decimal(\"2\")) * scale_factor, tier_1_y * scale_factor),\n            ]\n        )\n        \n        # Apply rotation and translation to the polygon\n        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n        self.polygon = affinity.translate(\n            rotated, \n            xoff=float(self.center_x * scale_factor), \n            yoff=float(self.center_y * scale_factor)\n        )\n\n\ndef load_configuration_from_df(n: int, df: pd.DataFrame) -> list[ChristmasTree]:\n    \"\"\"\n    Loads all trees for a given N from the submission DataFrame.\n    \"\"\"\n    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n    trees = []\n    for _, row in group_data.iterrows():\n        # Remove 's' prefix and convert to string for Decimal constructor\n        x = str(row[\"x\"])[1:]\n        y = str(row[\"y\"])[1:]\n        deg = str(row[\"deg\"])[1:]\n        \n        # Ensure values are present before passing to ChristmasTree constructor\n        if x and y and deg:\n            trees.append(ChristmasTree(x, y, deg))\n        else:\n             # Handle cases where configuration might be incomplete/missing\n             pass \n             \n    return trees\n\n\ndef get_score(trees: list[ChristmasTree], n: int) -> float:\n    \"\"\"\n    Calculates the score (S^2 / N) for a given configuration of trees.\n    S is the side length of the minimum bounding square.\n    \"\"\"\n    if not trees:\n        return 0.0\n\n    # Collect all exterior points from all tree polygons, scale them back down\n    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n    \n    min_x, min_y = xys.min(axis=0)\n    max_x, max_y = xys.max(axis=0)\n    \n    side_length = max(max_x - min_x, max_y - min_y)\n    \n    # Score is S^2 / N\n    score = side_length**2 / n\n    return score\n\ndef has_overlap(trees: list[ChristmasTree]) -> bool:\n    \"\"\"Check if any two ChristmasTree polygons overlap.\"\"\"\n    if len(trees) <= 1:\n        return False\n\n    polygons = [t.polygon for t in trees]\n    # Use STRtree for efficient proximity queries (optimizes checking pairs)\n    tree_index = STRtree(polygons)\n\n    for i, poly in enumerate(polygons):\n        # Query for polygons whose bounding boxes overlap with poly\n        # This returns the indices of potential overlaps\n        indices = tree_index.query(poly)\n        \n        for idx in indices:\n            # Skip checking the polygon against itself\n            if idx == i:\n                continue\n                \n            # Perform the precise intersection check\n            if poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n                # Overlap found!\n                return True\n    return False\n\n# ----------------------------------------------------------------------\n\ndef score_and_validate_submission(file_path: str, max_n: int = 200) -> dict:\n    \"\"\"\n    Reads a submission CSV, calculates the total score, and checks for overlaps \n    in all configurations (N=1 up to max_n).\n    \"\"\"\n    try:\n        df = pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        return {\"status\": \"FAILED\", \"error\": \"File Not Found\"}\n    except Exception as e:\n        print(f\"Error reading CSV: {e}\")\n        return {\"status\": \"FAILED\", \"error\": f\"CSV Read Error: {e}\"}\n\n    total_score = 0.0\n    failed_overlap_n = []\n    \n    print(f\"--- Scoring and Validation: {file_path} (N=1 to {max_n}) ---\")\n\n    for n in range(1, max_n + 1):\n        trees = load_configuration_from_df(n, df)\n        \n        # Only process if there are trees for this N in the file\n        if trees:\n            current_score = get_score(trees, n)\n            total_score += current_score\n\n            if has_overlap(trees):\n                failed_overlap_n.append(n)\n                print(f\"  ❌ N={n:03d}: OVERLAP DETECTED! (Score contribution: {current_score:.6f})\")\n            else:\n                # Optionally print success for each N\n                # print(f\"  ✅ N={n:03d}: OK (Score contribution: {current_score:.6f})\")\n                pass\n        \n    print(\"\\n--- Summary ---\")\n    if failed_overlap_n:\n        print(f\"❌ **Validation FAILED**: Overlaps found in N: {failed_overlap_n}\")\n        status = \"FAILED (Overlaps)\"\n    else:\n        print(\"✅ **Validation SUCCESSFUL**: No overlaps detected.\")\n        status = \"SUCCESS\"\n        \n    print(f\"**Total Submission Score (Σ S²/N): {total_score:.6f}**\")\n    \n    return {\n        \"status\": status,\n        \"total_score\": total_score,\n        \"failed_overlap_n\": failed_overlap_n\n    }\n\n\n# Example usage (assuming 'submission.csv' exists in the current directory)\nresult = score_and_validate_submission(\"submission.csv\", max_n=200)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:19:28.207884Z","iopub.execute_input":"2026-01-09T08:19:28.208204Z","iopub.status.idle":"2026-01-09T08:19:39.995878Z","shell.execute_reply.started":"2026-01-09T08:19:28.20817Z","shell.execute_reply":"2026-01-09T08:19:39.994834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nFAILED_N_LIST =  result['failed_overlap_n']\nGOOD_CSV_PATH = \"/kaggle/input/bucket-of-chump/submission.csv\"\nNEW_CSV_PATH = \"submission.csv\" \nOUTPUT_CSV_PATH = \"submission.csv\" \n\ndef replace_invalid_configurations(new_csv_path, good_csv_path, output_csv_path, failed_n_list):\n    df_new = pd.read_csv(new_csv_path)\n    df_good = pd.read_csv(good_csv_path)\n    failed_prefixes = [f\"{n:03d}_\" for n in failed_n_list]\n    df_to_keep = df_new[~df_new[\"id\"].str.startswith(tuple(failed_prefixes))]\n    df_replacement = df_good[df_good[\"id\"].str.startswith(tuple(failed_prefixes))]\n    df_repaired = pd.concat([df_to_keep, df_replacement]).sort_values(by=\"id\").reset_index(drop=True)\n    df_repaired.to_csv(output_csv_path, index=False) #float_format='%.25f')\n    print(f\"\\n--- SUCCESS ---\")\nreplace_invalid_configurations(NEW_CSV_PATH, GOOD_CSV_PATH, OUTPUT_CSV_PATH, FAILED_N_LIST)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:19:39.996932Z","iopub.execute_input":"2026-01-09T08:19:39.997232Z","iopub.status.idle":"2026-01-09T08:19:40.20581Z","shell.execute_reply.started":"2026-01-09T08:19:39.997201Z","shell.execute_reply":"2026-01-09T08:19:40.204772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage (assuming 'submission.csv' exists in the current directory)\nresult = score_and_validate_submission(\"submission.csv\", max_n=200)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T08:19:40.20735Z","iopub.execute_input":"2026-01-09T08:19:40.207717Z","iopub.status.idle":"2026-01-09T08:19:51.644951Z","shell.execute_reply.started":"2026-01-09T08:19:40.207687Z","shell.execute_reply":"2026-01-09T08:19:51.643562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Added Code that was Vibe Coded from \n# https://gemini.google.com/app","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom decimal import Decimal\nimport matplotlib.patches as patches\n\ndef analyze_crystallization(file_path, target_n=200):\n    # Load data\n    try:\n        df = pd.read_csv(file_path)\n    except:\n        return \"File not found.\"\n\n    # Filter for the specific group\n    group = df[df[\"id\"].str.startswith(f\"{target_n:03d}_\")].copy()\n    \n    # Strip 's' prefix and convert to float for analysis\n    group['xf'] = group['x'].str[1:].astype(float)\n    group['yf'] = group['y'].str[1:].astype(float)\n    group['degf'] = group['deg'].str[1:].astype(float) % 360\n    \n    # Calculate the centroid and relative positions\n    # A summation function for relative x,y patterns\n    cx, cy = group['xf'].mean(), group['yf'].mean()\n    group['rel_x'] = group['xf'] - cx\n    group['rel_y'] = group['yf'] - cy\n\n    # Visualization\n    fig, ax = plt.subplots(figsize=(10, 10))\n    \n    # Define polarity based on vertical orientation\n    # Upward (0 +/- 90) vs Downward (180 +/- 90)\n    for _, row in group.iterrows():\n        angle = row['degf']\n        \n        # Color logic (Blue if pointing up, Pink if pointing down)\n        # Using 90 to 270 as the 'downward' hemisphere\n        if 90 < angle <= 270:\n            tree_color = '#FFB6C1' # Pink\n        else:\n            tree_color = '#1E90FF' # Blue\n            \n        # Draw a simplified \"crystal unit\" (a diamond/triangle)\n        # This shows the \"spin\" of the lattice point\n        rad = np.radians(angle + 90) # Adjust for orientation\n        dx = 0.3 * np.cos(rad)\n        dy = 0.3 * np.sin(rad)\n        \n        # Plotting the lattice point\n        ax.arrow(row['xf'], row['yf'], dx, dy, \n                 head_width=0.1, head_length=0.1, fc=tree_color, ec=tree_color, alpha=0.7)\n        ax.scatter(row['xf'], row['yf'], c=tree_color, s=20, edgecolors='none')\n\n    ax.set_aspect('equal')\n    ax.set_title(f\"Lattice Crystallization Pattern (N={target_n})\", fontsize=14)\n    ax.set_xlabel(\"X-Coordinate (Relative Units)\")\n    ax.set_ylabel(\"Y-Coordinate (Relative Units)\")\n    plt.grid(True, linestyle='--', alpha=0.5)\n    \n    # Summary of the Summation Pattern\n    avg_spacing = np.sqrt((group['xf'].max() - group['xf'].min())**2 + \n                          (group['yf'].max() - group['yf'].min())**2) / np.sqrt(target_n)\n    \n    print(f\"--- Lattice Summary ---\")\n    print(f\"Crystallization Spacing: ~{avg_spacing:.4f} units\")\n    print(f\"Blue Phase Population: {len(group[~((group.degf > 90) & (group.degf <= 270))])}\")\n    print(f\"Pink Phase Population: {len(group[(group.degf > 90) & (group.degf <= 270)])}\")\n    \n    plt.show()\n\n\n\n\nsets = random.sample(range(1, 201), k=10)\nprint(sets)\nfor i in sets:\n    analyze_crystallization(\"submission.csv\", target_n=i)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef generate_geometry_report(file_path):\n    df = pd.read_csv(file_path)\n    # Data Cleaning\n    df['xf'] = df['x'].astype(str).str.replace('s', '').astype(float)\n    df['yf'] = df['y'].astype(str).str.replace('s', '').astype(float)\n    df['degf'] = df['deg'].astype(str).str.replace('s', '').astype(float) % 360\n    df['is_blue'] = ~((df.degf > 90) & (df.degf <= 270))\n    df['n_val'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n\n    # Calculate Score per Group to find the \"Masters\"\n    scores = []\n    for n in df['n_val'].unique():\n        g = df[df['n_val'] == n]\n        side = max(g['xf'].max() - g['xf'].min(), g['yf'].max() - g['yf'].min())\n        scores.append({'n': n, 'score': (side**2)/n})\n    \n    # Analyze the top 10% best groups\n    top_ns = pd.DataFrame(scores).sort_values('score').head(20)['n'].values\n    master_data = df[df['n_val'].isin(top_ns)]\n\n    # Find the relationship between Blue and their nearest Pink neighbors\n    blue = master_data[master_data.is_blue]\n    pink = master_data[~master_data.is_blue]\n    \n    results = []\n    for _, b in blue.iterrows():\n        # Find closest pink tree in the same group\n        group_p = pink[pink['n_val'] == b['n_val']]\n        if group_p.empty: continue\n        \n        dists = np.sqrt((group_p.xf - b.xf)**2 + (group_p.yf - b.yf)**2)\n        idx = dists.idxmin()\n        p_match = group_p.loc[idx]\n        \n        results.append({\n            'dx': round(p_match.xf - b.xf, 2),\n            'dy': round(p_match.yf - b.yf, 2),\n            'blue_deg': round(b.degf, 1),\n            'pink_deg': round(p_match.degf, 1)\n        })\n\n    report = pd.DataFrame(results).value_counts().reset_index(name='frequency')\n    return report.head(10)\n\nreport = generate_geometry_report(\"submission.csv\")\nprint(\"TOP 10 LATTICE OFFSETS & ANGLES:\")\nprint(report)\n\nfrom shapely.geometry import Polygon\nfrom shapely import affinity\nimport matplotlib.pyplot as plt\n\ndef plot_tree_pair(dx, dy, b_deg, p_deg):\n    TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n    TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n    \n    def make_poly(x, y, d):\n        p = Polygon(zip(TX, TY))\n        return affinity.translate(affinity.rotate(p, d, origin=(0,0)), x, y)\n\n    b_poly = make_poly(0, 0, b_deg)\n    p_poly = make_poly(dx, dy, p_deg)\n\n    fig, ax = plt.subplots(figsize=(6,6))\n    ax.fill(*b_poly.exterior.xy, color='#1E90FF', alpha=0.5, label='Blue Tree')\n    ax.fill(*p_poly.exterior.xy, color='#FFB6C1', alpha=0.5, label='Pink Tree')\n    ax.set_aspect('equal')\n    plt.title(f\"Lattice Interlock: Offset ({dx}, {dy})\")\n    plt.legend()\n    plt.show()\n\nplot_tree_pair(report.iloc[0]['dx'], report.iloc[0]['dy'], report.iloc[0]['blue_deg'], report.iloc[0]['pink_deg'])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}