{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c4df01",
   "metadata": {},
   "source": [
    "# Loop 16 Strategic Analysis\n",
    "\n",
    "## Current Situation\n",
    "- Best CV/LB: 70.630465\n",
    "- Target: 68.919154\n",
    "- Gap: 1.711 points (2.42%)\n",
    "- Public LB Leader: 71.19 (we're BETTER by 0.56 points!)\n",
    "\n",
    "## Key Insight from Evaluator\n",
    "The target (68.919) is 2.27 points BELOW the public leader. This means:\n",
    "1. The winning approach is NOT in any public kernel\n",
    "2. We need to discover something fundamentally new\n",
    "3. The solution EXISTS - top teams have found it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc17c319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T20:25:34.598581Z",
     "iopub.status.busy": "2026-01-20T20:25:34.598141Z",
     "iopub.status.idle": "2026-01-20T20:25:34.606560Z",
     "shell.execute_reply": "2026-01-20T20:25:34.606142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTS TRIED:\n",
      "======================================================================\n",
      "  001_baseline: 70.647327\n",
      "    Established baseline using pre-optimized jazivxt/bucket-of-chump submission. Score: 70.647327. Target: 68.919. Gap to close: 1.728 points. Score breakdown: N=1-20 contributes 8.0554 (11.4%), N=21-200 ...\n",
      "\n",
      "  002_ensemble: 70.647306\n",
      "    Implemented ensemble strategy combining 9 different pre-optimized solutions. For each N=1-200, picked the configuration with smallest bounding box. Sources: submission.csv (70.647), santa-2025.csv (70...\n",
      "\n",
      "  003_validated_ensemble: 70.647327\n",
      "    Validated ensemble approach with proper overlap detection. Found that santa-2025.csv has many corrupted rotation angles (>1000 degrees) but these are actually valid when normalized modulo 360. All 4 s...\n",
      "\n",
      "  004_bbox3_optimization: 70.647326\n",
      "    Implemented 3-phase bbox3 optimization as recommended by evaluator. Phase A: 12 runs with n=[1000,1500,2000,3000], r=[30,60,90], 2 min each. Phase B: 5 runs with doubled iterations, 5 min each. Phase ...\n",
      "\n",
      "  005_baseline_validated: 70.647327\n",
      "    Validated baseline submission after bbox3 optimizer failures. The baseline (jazivxt/bucket-of-chump) passes all overlap checks using Shapely. Score: 70.647327. Previous experiments showed: 1) bbox3 pr...\n",
      "\n",
      "  006_zaburo_grid: 70.647327\n",
      "    Implemented zaburo grid-based initial solutions with alternating row orientations (0° and 180°). Generated solutions for N=1-200. Results: Zaburo total score 88.33 vs baseline 70.65 (25% worse). Basel...\n",
      "\n",
      "  007_sa_optimization: 70.647327\n",
      "    Completed the pipeline as recommended by evaluator: Generated zaburo grid-based solutions (score 91.65), then OPTIMIZED them with sa_v1_parallel (score improved to 88.33, a 3.32 point improvement). Ho...\n",
      "\n",
      "  008_repair_ensemble: 70.647327\n",
      "    Implemented REPAIR + ENSEMBLE strategy as recommended by evaluator. Loaded optimized zaburo solutions (88.33 score, 183 overlaps). For each N: checked overlap with Shapely, compared scores, picked bes...\n",
      "\n",
      "  009_fractional_translation: 70.647327\n",
      "    Ran sa_v1_parallel with fractional_translation on BASELINE with high iterations (n=50000, r=10). Result: No improvement after 4 generations. Also analyzed 38 valid submissions from snapshots. Found sn...\n",
      "\n",
      "  010_tessellation_and_ensemble: 70.630478\n",
      "    Tried multiple approaches: 1) Tessellation SA for N=72,100,etc - WORSE than baseline (0.397 vs 0.348 for N=72). 2) Baseline SA with Shapely validation - NO improvement found. 3) Exact solver for N=1,2...\n",
      "\n",
      "  011_random_restart_sa: 70.630478\n",
      "    Tried to generate NEW solutions from scratch since all public sources are exhausted. Approaches: 1) Random restart SA for N=1-10 with 50-100 restarts each - NO improvements (random configs are WORSE t...\n",
      "\n",
      "  012_scanline_packer: 70.630478\n",
      "    Implemented CONSTRUCTIVE heuristics as recommended by strategy: 1) Scanline packer (horizontal/vertical sweep) - WORSE than baseline. 2) Alternating lattice packer (0/180 degree alternation) - WORSE t...\n",
      "\n",
      "  013_long_sa: 70.630478\n",
      "    Tried long-running optimization as recommended: 1) Modified sa_v1_parallel to run 15 generations instead of 3 (max_retries=15). Ran on baseline - NO improvement after 5 generations. 2) Perturbed basel...\n",
      "\n",
      "  014_basin_hopping: 70.630478\n",
      "    Implemented GLOBAL optimization methods as recommended: 1) Basin Hopping with scipy.optimize.basinhopping - doesn't work well with discrete constraints (collision detection). 2) Custom Basin Hopping w...\n",
      "\n",
      "  015_constraint_programming: 70.630478\n",
      "    Analyzed baseline structure and tried exact optimization: 1) Exhaustive search for N=1 - baseline is optimal (angle=45 gives square bounding box). 2) Exhaustive search for N=2 with discrete angles - c...\n",
      "\n",
      "  016_rebuild_corners: 70.630465\n",
      "    Implemented chistyakov's 'rebuild from corners' technique: For each large N layout (50-200), check all 4 corners, sort trees by distance from corner, build up layout from corner adding trees one by on...\n",
      "\n",
      "  017_cross_n_extraction: 70.630465\n",
      "    Implemented two exhaustive extraction approaches: 1) Cross-N extraction: For each target N (2-100), try extracting from ALL larger N layouts (up to +50), using corner-based selection. Found same impro...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze what approaches have been tried and what's left\n",
    "import json\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "print(\"EXPERIMENTS TRIED:\")\n",
    "print(\"=\"*70)\n",
    "for exp in state['experiments']:\n",
    "    print(f\"  {exp['name']}: {exp['score']:.6f}\")\n",
    "    if 'notes' in exp:\n",
    "        # Extract key result\n",
    "        notes = exp['notes'][:200] + '...' if len(exp['notes']) > 200 else exp['notes']\n",
    "        print(f\"    {notes}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778eb5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T20:25:34.607597Z",
     "iopub.status.busy": "2026-01-20T20:25:34.607485Z",
     "iopub.status.idle": "2026-01-20T20:25:34.611560Z",
     "shell.execute_reply": "2026-01-20T20:25:34.611179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROACHES TRIED:\n",
      "  1. Ensemble from 25+ public sources\n",
      "  2. bbox3 optimization\n",
      "  3. sa_v1_parallel optimization\n",
      "  4. Grid-based approaches (zaburo, tessellation)\n",
      "  5. Constructive heuristics (scanline, lattice, chebyshev, BL)\n",
      "  6. Random restart SA\n",
      "  7. Long-running SA (15 generations)\n",
      "  8. Basin hopping (scipy and custom)\n",
      "  9. Genetic algorithm with crossover\n",
      "  10. Tree removal technique\n",
      "  11. Rebuild from corners\n",
      "  12. Exhaustive search for N=1,2\n",
      "  13. Constraint programming analysis\n",
      "  14. Cross-N extraction (exhaustive)\n",
      "  15. Exhaustive tree removal\n",
      "\n",
      "======================================================================\n",
      "WHAT HASN'T BEEN TRIED:\n",
      "======================================================================\n",
      "1. TESSELLATION SA WITH TRANSLATIONS (egortrushin kernel)\n",
      "   - Creates grid of trees with optimized translation distances\n",
      "   - For N=200: [7,15] grid (210 trees), optimize, delete 10 worst\n",
      "   - This creates FUNDAMENTALLY DIFFERENT configurations\n",
      "\n",
      "2. ASYMMETRIC PACKING (mentioned in discussions)\n",
      "   - Discussion 'Why the winning solutions will be Asymmetric' (34 votes)\n",
      "   - Top teams use asymmetric layouts\n",
      "\n",
      "3. VERY HIGH TEMPERATURE SA FROM RANDOM INITIAL\n",
      "   - All SA runs started from baseline or grid\n",
      "   - Try random initial with VERY high temperature\n",
      "   - Goal: find a DIFFERENT basin\n",
      "\n",
      "4. HYBRID: TESSELLATION + TREE DELETION\n",
      "   - Generate tessellation solutions for specific N\n",
      "   - Apply tree deletion to create N-1, N-2, etc.\n"
     ]
    }
   ],
   "source": [
    "# Analyze what's been tried\n",
    "approaches_tried = [\n",
    "    \"Ensemble from 25+ public sources\",\n",
    "    \"bbox3 optimization\",\n",
    "    \"sa_v1_parallel optimization\",\n",
    "    \"Grid-based approaches (zaburo, tessellation)\",\n",
    "    \"Constructive heuristics (scanline, lattice, chebyshev, BL)\",\n",
    "    \"Random restart SA\",\n",
    "    \"Long-running SA (15 generations)\",\n",
    "    \"Basin hopping (scipy and custom)\",\n",
    "    \"Genetic algorithm with crossover\",\n",
    "    \"Tree removal technique\",\n",
    "    \"Rebuild from corners\",\n",
    "    \"Exhaustive search for N=1,2\",\n",
    "    \"Constraint programming analysis\",\n",
    "    \"Cross-N extraction (exhaustive)\",\n",
    "    \"Exhaustive tree removal\"\n",
    "]\n",
    "\n",
    "print(\"APPROACHES TRIED:\")\n",
    "for i, approach in enumerate(approaches_tried, 1):\n",
    "    print(f\"  {i}. {approach}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WHAT HASN'T BEEN TRIED:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "not_tried = [\n",
    "    \"1. TESSELLATION SA WITH TRANSLATIONS (egortrushin kernel)\",\n",
    "    \"   - Creates grid of trees with optimized translation distances\",\n",
    "    \"   - For N=200: [7,15] grid (210 trees), optimize, delete 10 worst\",\n",
    "    \"   - This creates FUNDAMENTALLY DIFFERENT configurations\",\n",
    "    \"\",\n",
    "    \"2. ASYMMETRIC PACKING (mentioned in discussions)\",\n",
    "    \"   - Discussion 'Why the winning solutions will be Asymmetric' (34 votes)\",\n",
    "    \"   - Top teams use asymmetric layouts\",\n",
    "    \"\",\n",
    "    \"3. VERY HIGH TEMPERATURE SA FROM RANDOM INITIAL\",\n",
    "    \"   - All SA runs started from baseline or grid\",\n",
    "    \"   - Try random initial with VERY high temperature\",\n",
    "    \"   - Goal: find a DIFFERENT basin\",\n",
    "    \"\",\n",
    "    \"4. HYBRID: TESSELLATION + TREE DELETION\",\n",
    "    \"   - Generate tessellation solutions for specific N\",\n",
    "    \"   - Apply tree deletion to create N-1, N-2, etc.\"\n",
    "]\n",
    "\n",
    "for item in not_tried:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a787e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T20:25:34.612623Z",
     "iopub.status.busy": "2026-01-20T20:25:34.612518Z",
     "iopub.status.idle": "2026-01-20T20:25:34.615457Z",
     "shell.execute_reply": "2026-01-20T20:25:34.615088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGORTRUSHIN TESSELLATION SA APPROACH:\n",
      "======================================================================\n",
      "\n",
      "The approach uses TWO base trees that are translated in x and y directions:\n",
      "- Tree 1: at origin (0, 0)\n",
      "- Tree 2: rotated 180 degrees\n",
      "\n",
      "The grid is created by translating these two trees:\n",
      "- nt = [nx, ny] = number of translations in x and y\n",
      "- Total trees = nx * ny * 2 (two trees per cell)\n",
      "\n",
      "For specific N values:\n",
      "- N=72:  [4, 9]  grid = 4*9*2 = 72 trees\n",
      "- N=100: [5, 10] grid = 5*10*2 = 100 trees  \n",
      "- N=110: [5, 11] grid = 5*11*2 = 110 trees\n",
      "- N=144: [6, 12] grid = 6*12*2 = 144 trees\n",
      "- N=156: [6, 13] grid = 6*13*2 = 156 trees\n",
      "- N=196: [7, 14] grid = 7*14*2 = 196 trees\n",
      "- N=200: [7, 15] grid = 7*15*2 = 210 trees, then DELETE 10 worst\n",
      "\n",
      "SA optimizes:\n",
      "- Translation distances (delta_x, delta_y)\n",
      "- Position perturbations\n",
      "- Angle perturbations\n",
      "\n",
      "This creates FUNDAMENTALLY DIFFERENT configurations than the baseline!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's understand the egortrushin tessellation approach better\n",
    "# Key insight: Use a grid of TWO trees that are translated\n",
    "\n",
    "print(\"EGORTRUSHIN TESSELLATION SA APPROACH:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "The approach uses TWO base trees that are translated in x and y directions:\n",
    "- Tree 1: at origin (0, 0)\n",
    "- Tree 2: rotated 180 degrees\n",
    "\n",
    "The grid is created by translating these two trees:\n",
    "- nt = [nx, ny] = number of translations in x and y\n",
    "- Total trees = nx * ny * 2 (two trees per cell)\n",
    "\n",
    "For specific N values:\n",
    "- N=72:  [4, 9]  grid = 4*9*2 = 72 trees\n",
    "- N=100: [5, 10] grid = 5*10*2 = 100 trees  \n",
    "- N=110: [5, 11] grid = 5*11*2 = 110 trees\n",
    "- N=144: [6, 12] grid = 6*12*2 = 144 trees\n",
    "- N=156: [6, 13] grid = 6*13*2 = 156 trees\n",
    "- N=196: [7, 14] grid = 7*14*2 = 196 trees\n",
    "- N=200: [7, 15] grid = 7*15*2 = 210 trees, then DELETE 10 worst\n",
    "\n",
    "SA optimizes:\n",
    "- Translation distances (delta_x, delta_y)\n",
    "- Position perturbations\n",
    "- Angle perturbations\n",
    "\n",
    "This creates FUNDAMENTALLY DIFFERENT configurations than the baseline!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078508fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T20:25:34.616365Z",
     "iopub.status.busy": "2026-01-20T20:25:34.616253Z",
     "iopub.status.idle": "2026-01-20T20:26:51.259014Z",
     "shell.execute_reply": "2026-01-20T20:26:51.256996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission (77).csv: 72.135010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  current_best.csv: 70.630478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.647327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission (80).csv: 71.946272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  outer_chain_output.csv: 70.630465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ensemble_best.csv: 70.630478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa-2025.csv: 70.658891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  saspav_best.csv: 70.630478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tree_packer_output.csv: 70.630436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_best.csv: 70.926150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  my_optimized_submission.csv.csv: 74.648019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.49.csv: 72.495739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.97.csv: 71.972027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tree_packer_input.csv: 70.630478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  smartmanoj.csv: 70.743774\n"
     ]
    }
   ],
   "source": [
    "# Let's check if we have any tessellation solutions in our datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated,\n",
    "                                          xoff=float(self.center_x * scale_factor),\n",
    "                                          yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def get_tree_list_side_length(tree_list):\n",
    "    all_polygons = [t.polygon for t in tree_list]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    return Decimal(max(bounds[2] - bounds[0], bounds[3] - bounds[1])) / scale_factor\n",
    "\n",
    "def get_total_score(dict_of_side_length):\n",
    "    score = 0\n",
    "    for k, v in dict_of_side_length.items():\n",
    "        score += v ** 2 / Decimal(k)\n",
    "    return score\n",
    "\n",
    "def parse_csv(csv_path):\n",
    "    result = pd.read_csv(csv_path)\n",
    "    result['x'] = result['x'].str.strip('s')\n",
    "    result['y'] = result['y'].str.strip('s')\n",
    "    result['deg'] = result['deg'].str.strip('s')\n",
    "    result[['group_id', 'item_id']] = result['id'].str.split('_', n=2, expand=True)\n",
    "    dict_of_tree_list = {}\n",
    "    dict_of_side_length = {}\n",
    "    for group_id, group_data in result.groupby('group_id'):\n",
    "        tree_list = [ChristmasTree(center_x=row['x'], center_y=row['y'], angle=row['deg']) for _, row in group_data.iterrows()]\n",
    "        dict_of_tree_list[group_id] = tree_list\n",
    "        dict_of_side_length[group_id] = get_tree_list_side_length(tree_list)\n",
    "    return dict_of_tree_list, dict_of_side_length\n",
    "\n",
    "print(\"Checking available datasets...\")\n",
    "for f in os.listdir('/home/code/exploration/datasets/'):\n",
    "    if f.endswith('.csv'):\n",
    "        try:\n",
    "            _, side_lengths = parse_csv(f'/home/code/exploration/datasets/{f}')\n",
    "            score = get_total_score(side_lengths)\n",
    "            print(f\"  {f}: {score:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {f}: ERROR - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15d936e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T20:26:51.260262Z",
     "iopub.status.busy": "2026-01-20T20:26:51.260140Z",
     "iopub.status.idle": "2026-01-20T20:26:56.390412Z",
     "shell.execute_reply": "2026-01-20T20:26:56.389964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE BREAKDOWN BY N RANGE:\n",
      "======================================================================\n",
      "  N=  1- 10: 4.329128\n",
      "  N= 11- 20: 3.724074\n",
      "  N= 21- 50: 10.980931\n",
      "  N= 51-100: 17.616979\n",
      "  N=101-150: 17.136399\n",
      "  N=151-200: 16.842967\n",
      "\n",
      "  TOTAL: 70.630478\n",
      "  TARGET: 68.919154\n",
      "  GAP: 1.711324\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze the score breakdown by N range\n",
    "# This will help us understand where improvements are possible\n",
    "\n",
    "_, side_lengths = parse_csv('/home/code/exploration/datasets/ensemble_best.csv')\n",
    "\n",
    "print(\"SCORE BREAKDOWN BY N RANGE:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ranges = [(1, 10), (11, 20), (21, 50), (51, 100), (101, 150), (151, 200)]\n",
    "\n",
    "for start, end in ranges:\n",
    "    range_score = sum(side_lengths[f'{n:03d}']**2 / Decimal(n) for n in range(start, end+1))\n",
    "    print(f\"  N={start:3d}-{end:3d}: {float(range_score):.6f}\")\n",
    "\n",
    "print(f\"\\n  TOTAL: {float(get_total_score(side_lengths)):.6f}\")\n",
    "print(f\"  TARGET: 68.919154\")\n",
    "print(f\"  GAP: {float(get_total_score(side_lengths)) - 68.919154:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75ce50",
   "metadata": {},
   "source": [
    "## Key Strategic Insights\n",
    "\n",
    "### 1. The Target IS Achievable\n",
    "- Our score (70.630) is BETTER than public LB leader (71.19)\n",
    "- Target (68.919) requires techniques NOT in public kernels\n",
    "- Top teams have found these techniques - we need to discover them\n",
    "\n",
    "### 2. What's NOT Working\n",
    "- Incremental optimization (SA, bbox3) - stuck at local optimum\n",
    "- Tree removal - only 0.00001 improvement\n",
    "- Ensemble from public sources - all at same local optimum\n",
    "\n",
    "### 3. What MIGHT Work\n",
    "- **Tessellation SA with translations** - creates fundamentally different configurations\n",
    "- **Asymmetric packing** - mentioned in discussions as key to winning\n",
    "- **Very high temperature SA from random initial** - escape current basin\n",
    "\n",
    "### 4. Next Steps\n",
    "1. Implement egortrushin tessellation SA for specific N values\n",
    "2. Compare tessellation solutions with baseline\n",
    "3. If better, apply tree deletion to create solutions for other N values\n",
    "4. Submit to verify on LB"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
