{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75792f44",
   "metadata": {},
   "source": [
    "# Loop 20 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- **Experiment**: 022_cpp_sa_2M_all_n\n",
    "- **CV Score**: 70.6276\n",
    "- **LB Score**: 70.6276\n",
    "- **Gap**: 0.0000 (perfect CV-LB alignment - expected for deterministic optimization)\n",
    "\n",
    "## Current Status\n",
    "- **Best Score**: 70.6276\n",
    "- **Target**: 68.919154\n",
    "- **Gap to Target**: 1.708 (2.48%)\n",
    "\n",
    "## Key Observations from 22 Experiments\n",
    "1. All SA-based approaches converge to ~70.63\n",
    "2. Asymmetric solutions from scratch FAILED (worse than baseline)\n",
    "3. C++ SA with 2M iterations finds tiny improvements (0.0003 per run)\n",
    "4. At current rate, would need ~6,500 runs to reach target (infeasible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analyze submission history\n",
    "submissions = [\n",
    "    ('exp_000', 70.6473, 70.6473),\n",
    "    ('exp_002', 70.6473, 70.6473),\n",
    "    ('exp_009', 70.6305, 70.6305),\n",
    "    ('exp_010', 70.6305, 70.6305),\n",
    "    ('exp_017', 70.6305, 70.6305),\n",
    "    ('exp_018', 70.6305, 70.6305),\n",
    "    ('exp_019', 70.6279, 70.6279),\n",
    "    ('exp_020', 70.6276, 70.6276),\n",
    "]\n",
    "\n",
    "print('Submission History Analysis:')\n",
    "print('=' * 50)\n",
    "for exp, cv, lb in submissions:\n",
    "    print(f'{exp}: CV={cv:.4f}, LB={lb:.4f}, gap={lb-cv:.6f}')\n",
    "\n",
    "# Calculate improvement rate\n",
    "improvements = []\n",
    "for i in range(1, len(submissions)):\n",
    "    imp = submissions[i-1][1] - submissions[i][1]\n",
    "    if imp > 0:\n",
    "        improvements.append(imp)\n",
    "        \n",
    "print(f'\\nTotal improvement: {submissions[0][1] - submissions[-1][1]:.6f}')\n",
    "print(f'Average improvement per submission: {np.mean(improvements):.6f}')\n",
    "print(f'\\nGap to target: {submissions[-1][1] - 68.919154:.6f}')\n",
    "print(f'Submissions needed at current rate: {(submissions[-1][1] - 68.919154) / np.mean(improvements):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5628699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores to find optimization opportunities\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "\n",
    "TREE_TEMPLATE = [\n",
    "    (0.0, 0.8), (0.125, 0.5), (0.0625, 0.5), (0.2, 0.25), (0.1, 0.25),\n",
    "    (0.35, 0.0), (0.075, 0.0), (0.075, -0.2), (-0.075, -0.2), (-0.075, 0.0),\n",
    "    (-0.35, 0.0), (-0.1, 0.25), (-0.2, 0.25), (-0.0625, 0.5), (-0.125, 0.5)\n",
    "]\n",
    "\n",
    "def parse_s_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "def create_tree_polygon(x, y, angle):\n",
    "    tree = Polygon(TREE_TEMPLATE)\n",
    "    tree = rotate(tree, angle, origin=(0, 0), use_radians=False)\n",
    "    tree = translate(tree, x, y)\n",
    "    return tree\n",
    "\n",
    "def get_n_side(df, n):\n",
    "    group = df[df['n'] == n]\n",
    "    all_x, all_y = [], []\n",
    "    for _, row in group.iterrows():\n",
    "        tree = create_tree_polygon(row['x'], row['y'], row['deg'])\n",
    "        minx, miny, maxx, maxy = tree.bounds\n",
    "        all_x.extend([minx, maxx])\n",
    "        all_y.extend([miny, maxy])\n",
    "    return max(max(all_x) - min(all_x), max(all_y) - min(all_y)) if all_x else 0\n",
    "\n",
    "# Load current best\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "df['x'] = df['x'].apply(parse_s_value)\n",
    "df['y'] = df['y'].apply(parse_s_value)\n",
    "df['deg'] = df['deg'].apply(parse_s_value)\n",
    "df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "print('Current best score:', sum((get_n_side(df, n)**2)/n for n in range(1, 201)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum and efficiency gap\n",
    "# Theoretical minimum: if all trees could be packed with perfect efficiency\n",
    "\n",
    "# Tree area (approximate)\n",
    "tree_area = 0.5 * 0.7 * 1.0  # Rough triangle approximation\n",
    "print(f'Approximate tree area: {tree_area:.4f}')\n",
    "\n",
    "# For N trees, minimum square side would be sqrt(N * tree_area)\n",
    "theoretical_scores = []\n",
    "actual_scores = []\n",
    "efficiency_gaps = []\n",
    "\n",
    "for n in range(1, 201):\n",
    "    # Theoretical minimum (perfect packing)\n",
    "    min_side = np.sqrt(n * tree_area)\n",
    "    theoretical_score = (min_side ** 2) / n\n",
    "    \n",
    "    # Actual score\n",
    "    actual_side = get_n_side(df, n)\n",
    "    actual_score = (actual_side ** 2) / n\n",
    "    \n",
    "    theoretical_scores.append(theoretical_score)\n",
    "    actual_scores.append(actual_score)\n",
    "    efficiency_gaps.append(actual_score - theoretical_score)\n",
    "\n",
    "print(f'\\nTheoretical minimum total: {sum(theoretical_scores):.4f}')\n",
    "print(f'Actual total: {sum(actual_scores):.4f}')\n",
    "print(f'Efficiency gap: {sum(efficiency_gaps):.4f}')\n",
    "print(f'\\nTarget: 68.919154')\n",
    "print(f'Theoretical minimum: {sum(theoretical_scores):.4f}')\n",
    "print(f'Gap between target and theoretical: {68.919154 - sum(theoretical_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e402428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify N values with largest efficiency gaps (most room for improvement)\n",
    "n_analysis = []\n",
    "for n in range(1, 201):\n",
    "    actual_side = get_n_side(df, n)\n",
    "    actual_score = (actual_side ** 2) / n\n",
    "    \n",
    "    # Efficiency = side / sqrt(n) - lower is better\n",
    "    efficiency = actual_side / np.sqrt(n)\n",
    "    \n",
    "    n_analysis.append({\n",
    "        'n': n,\n",
    "        'side': actual_side,\n",
    "        'score': actual_score,\n",
    "        'efficiency': efficiency\n",
    "    })\n",
    "\n",
    "df_analysis = pd.DataFrame(n_analysis)\n",
    "\n",
    "# Sort by efficiency (worst first)\n",
    "df_worst = df_analysis.sort_values('efficiency', ascending=False).head(20)\n",
    "print('Top 20 N values with worst efficiency (most room for improvement):')\n",
    "print(df_worst.to_string(index=False))\n",
    "\n",
    "# Sort by score contribution (highest first)\n",
    "df_highest = df_analysis.sort_values('score', ascending=False).head(20)\n",
    "print('\\nTop 20 N values with highest score contribution:')\n",
    "print(df_highest.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b02e10",
   "metadata": {},
   "source": [
    "## Strategic Analysis\n",
    "\n",
    "### What We've Tried (22 experiments):\n",
    "1. **Ensemble from multiple sources** - Found saspav_best.csv with 14 better N values (0.017 improvement)\n",
    "2. **bbox3 optimization** - Negligible improvement (0.000001)\n",
    "3. **SA optimization** - Converges to same local optimum\n",
    "4. **Zaburo grid** - 25% worse than baseline\n",
    "5. **Tessellation** - Worse than baseline\n",
    "6. **Random restart SA** - No improvement\n",
    "7. **Basin hopping** - No improvement\n",
    "8. **Constraint programming** - No improvement\n",
    "9. **Asymmetric solutions** - FAILED (worse than baseline)\n",
    "10. **C++ SA (nicupetridean)** - Small improvements (0.0003 per run)\n",
    "\n",
    "### What's Working:\n",
    "- C++ SA finds tiny improvements on specific N values (N=35, N=64, N=88)\n",
    "- Ensemble from multiple sources\n",
    "\n",
    "### What's NOT Working:\n",
    "- Generating solutions from scratch (all worse than baseline)\n",
    "- Asymmetric placements\n",
    "- Different initial configurations\n",
    "\n",
    "### Key Insight:\n",
    "The baseline is at an EXTREMELY strong local optimum. All approaches that try to generate new solutions from scratch produce WORSE results. The only way to improve is to:\n",
    "1. Find better pre-optimized solutions from other sources\n",
    "2. Run very long SA on the current best\n",
    "\n",
    "### Gap Analysis:\n",
    "- Current: 70.6276\n",
    "- Target: 68.919154\n",
    "- Gap: 1.708 (2.48%)\n",
    "- At current improvement rate (0.0003/run), need ~5,700 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any unexplored sources\n",
    "import os\n",
    "\n",
    "# List all CSV files in snapshots\n",
    "snapshots_dir = '/home/nonroot/snapshots'\n",
    "if os.path.exists(snapshots_dir):\n",
    "    csv_files = [f for f in os.listdir(snapshots_dir) if f.endswith('.csv')]\n",
    "    print(f'Found {len(csv_files)} CSV files in snapshots')\n",
    "    \n",
    "    # Check a few for their scores\n",
    "    for f in csv_files[:5]:\n",
    "        try:\n",
    "            snap_df = pd.read_csv(os.path.join(snapshots_dir, f))\n",
    "            snap_df['x'] = snap_df['x'].apply(parse_s_value)\n",
    "            snap_df['y'] = snap_df['y'].apply(parse_s_value)\n",
    "            snap_df['deg'] = snap_df['deg'].apply(parse_s_value)\n",
    "            snap_df['n'] = snap_df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "            score = sum((get_n_side(snap_df, n)**2)/n for n in range(1, 201))\n",
    "            print(f'  {f}: {score:.6f}')\n",
    "        except Exception as e:\n",
    "            print(f'  {f}: Error - {e}')\n",
    "else:\n",
    "    print('No snapshots directory found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b01ca8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The target of 68.919154 requires a **1.708 point improvement** (2.48%).\n",
    "\n",
    "Current approaches are finding **0.0003 improvement per run** - this is **5,700x too slow**.\n",
    "\n",
    "### The Problem:\n",
    "1. All public solutions are at the same local optimum (~70.63)\n",
    "2. Generating new solutions from scratch produces WORSE results\n",
    "3. SA-based optimization finds only tiny improvements\n",
    "\n",
    "### Potential Solutions:\n",
    "1. **Find better pre-optimized solutions** - Check if there are private solutions with better scores\n",
    "2. **Implement fundamentally different algorithms** - Not SA variations\n",
    "3. **Focus on specific N values** - Some N values may have more room for improvement\n",
    "4. **Longer optimization runs** - But diminishing returns\n",
    "\n",
    "### Next Steps:\n",
    "1. Submit current best (70.6276) to verify LB score\n",
    "2. Research what techniques top teams use (scores below 69)\n",
    "3. Try implementing Chebyshev distance / scan-line packing mentioned in research"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
