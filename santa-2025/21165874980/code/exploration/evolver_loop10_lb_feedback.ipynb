{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf5c434",
   "metadata": {},
   "source": [
    "# Evolver Loop 10 - LB Feedback Analysis\n",
    "\n",
    "**LB Score: 70.6305** (matches CV exactly - perfect calibration!)\n",
    "\n",
    "The saspav_best.csv source improved our score from 70.6473 to 70.6305 (0.017 improvement).\n",
    "\n",
    "Now we need to expand the ensemble with MORE sources from the jonathanchan kernel list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f608f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:15:27.968346Z",
     "iopub.status.busy": "2026-01-20T16:15:27.967769Z",
     "iopub.status.idle": "2026-01-20T16:15:28.334876Z",
     "shell.execute_reply": "2026-01-20T16:15:28.334462Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal('1e15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f0b790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:15:28.336534Z",
     "iopub.status.busy": "2026-01-20T16:15:28.336364Z",
     "iopub.status.idle": "2026-01-20T16:15:28.342599Z",
     "shell.execute_reply": "2026-01-20T16:15:28.342189Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(center_x)\n",
    "        self.center_y = Decimal(center_y)\n",
    "        self.angle = Decimal(angle)\n",
    "        \n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "        \n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d0f835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:15:28.343612Z",
     "iopub.status.busy": "2026-01-20T16:15:28.343501Z",
     "iopub.status.idle": "2026-01-20T16:15:28.348607Z",
     "shell.execute_reply": "2026-01-20T16:15:28.348226Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_score(trees):\n",
    "    \"\"\"Calculate score for a list of trees\"\"\"\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / 1e15 for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    score = max(max_x - min_x, max_y - min_y) ** 2 / len(trees)\n",
    "    return score\n",
    "\n",
    "def has_collision(trees):\n",
    "    \"\"\"Check for collisions between trees using Shapely\"\"\"\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    for i, tree1 in enumerate(trees):\n",
    "        for j, tree2 in enumerate(trees):\n",
    "            if i < j:\n",
    "                if tree1.polygon.intersects(tree2.polygon) and not tree1.polygon.touches(tree2.polygon):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def load_trees_from_df(df, n):\n",
    "    \"\"\"Load trees for a specific N from dataframe\"\"\"\n",
    "    group_data = df[df['id'].str.startswith(f'{n:03d}_')]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row['x'])[1:] if str(row['x']).startswith('s') else str(row['x'])\n",
    "        y = str(row['y'])[1:] if str(row['y']).startswith('s') else str(row['y'])\n",
    "        deg = str(row['deg'])[1:] if str(row['deg']).startswith('s') else str(row['deg'])\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees, group_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08063d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:15:28.349506Z",
     "iopub.status.busy": "2026-01-20T16:15:28.349390Z",
     "iopub.status.idle": "2026-01-20T16:15:28.353454Z",
     "shell.execute_reply": "2026-01-20T16:15:28.353025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files found: 25\n",
      "  /home/code/exploration/datasets/submission.csv\n",
      "  /home/code/exploration/datasets/santa-2025.csv\n",
      "  /home/code/exploration/datasets/saspav_best.csv\n",
      "  /home/code/exploration/datasets/smartmanoj.csv\n",
      "  /home/code/exploration/datasets/submission_best.csv\n",
      "  /home/code/exploration/datasets/telegram/72.49.csv\n",
      "  /home/code/exploration/datasets/telegram/71.97.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_JKoT4.csv\n",
      "  /home/code/exploration/datasets/santa25_public/New_Tree_144_196.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_JKoT3.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v61.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_JKoT2.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v67.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v76.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_70_936673758122.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v65.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_70_926149550346.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v66.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v63.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v69.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_JKoT1.csv\n",
      "  /home/code/exploration/datasets/santa25_public/submission_opt1.csv\n",
      "  /home/code/exploration/datasets/santa25_public/santa2025_ver2_v68.csv\n",
      "  /home/code/exploration/datasets/seowoohyeon/submission.csv\n",
      "  /home/code/exploration/datasets/seowoohyeon/submission_sa.csv\n"
     ]
    }
   ],
   "source": [
    "# Collect ALL available CSV files from all sources\n",
    "all_csv_paths = []\n",
    "\n",
    "# Original sources\n",
    "original_sources = [\n",
    "    '/home/code/exploration/datasets/submission.csv',\n",
    "    '/home/code/exploration/datasets/santa-2025.csv',\n",
    "    '/home/code/exploration/datasets/saspav_best.csv',\n",
    "    '/home/code/exploration/datasets/smartmanoj.csv',\n",
    "    '/home/code/exploration/datasets/submission_best.csv',\n",
    "]\n",
    "all_csv_paths.extend(original_sources)\n",
    "\n",
    "# Telegram sources\n",
    "telegram_csvs = glob.glob('/home/code/exploration/datasets/telegram/*.csv')\n",
    "all_csv_paths.extend(telegram_csvs)\n",
    "\n",
    "# Santa25-public sources\n",
    "santa25_public_csvs = glob.glob('/home/code/exploration/datasets/santa25_public/*.csv')\n",
    "all_csv_paths.extend(santa25_public_csvs)\n",
    "\n",
    "# Seowoohyeon sources\n",
    "seowoohyeon_csvs = glob.glob('/home/code/exploration/datasets/seowoohyeon/*.csv')\n",
    "all_csv_paths.extend(seowoohyeon_csvs)\n",
    "\n",
    "print(f'Total CSV files found: {len(all_csv_paths)}')\n",
    "for p in all_csv_paths:\n",
    "    print(f'  {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96f0c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T16:15:28.354523Z",
     "iopub.status.busy": "2026-01-20T16:15:28.354409Z",
     "iopub.status.idle": "2026-01-20T16:15:28.969169Z",
     "shell.execute_reply": "2026-01-20T16:15:28.968750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all sources...\n",
      "  Loaded submission.csv: 20100 rows\n",
      "  Loaded santa-2025.csv: 20100 rows\n",
      "  Loaded saspav_best.csv: 20100 rows\n",
      "  Loaded smartmanoj.csv: 20100 rows\n",
      "  Loaded submission_best.csv: 20100 rows\n",
      "  Loaded 72.49.csv: 20100 rows\n",
      "  Loaded 71.97.csv: 20100 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded submission_JKoT4.csv: 20100 rows\n",
      "  Loaded New_Tree_144_196.csv: 20100 rows\n",
      "  Loaded submission_JKoT3.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v61.csv: 20100 rows\n",
      "  Loaded submission_JKoT2.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v67.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v76.csv: 20100 rows\n",
      "  Loaded submission_70_936673758122.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v65.csv: 20100 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded submission_70_926149550346.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v66.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v63.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v69.csv: 20100 rows\n",
      "  Loaded submission_JKoT1.csv: 20100 rows\n",
      "  Loaded submission_opt1.csv: 20100 rows\n",
      "  Loaded santa2025_ver2_v68.csv: 20100 rows\n",
      "  Loaded submission.csv: 20100 rows\n",
      "  Loaded submission_sa.csv: 20100 rows\n",
      "\n",
      "Total sources loaded: 24\n"
     ]
    }
   ],
   "source": [
    "# Load all sources and calculate scores for each N\n",
    "print('Loading all sources...')\n",
    "sources = {}\n",
    "\n",
    "for path in all_csv_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            print(f'  Skipping {path} - missing columns')\n",
    "            continue\n",
    "        name = os.path.basename(path)\n",
    "        sources[name] = df\n",
    "        print(f'  Loaded {name}: {len(df)} rows')\n",
    "    except Exception as e:\n",
    "        print(f'  Error loading {path}: {e}')\n",
    "\n",
    "print(f'\\nTotal sources loaded: {len(sources)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for each N from each source\n",
    "print('Calculating scores for each N from each source...')\n",
    "scores_by_source = {name: {} for name in sources}\n",
    "\n",
    "for name, df in sources.items():\n",
    "    for n in range(1, 201):\n",
    "        try:\n",
    "            trees, _ = load_trees_from_df(df, n)\n",
    "            if len(trees) == n:\n",
    "                score = calculate_score(trees)\n",
    "                scores_by_source[name][n] = score\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    print(f'  {name}: {len(scores_by_source[name])} N values')\n",
    "\n",
    "print('Done calculating scores.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deff11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best source for each N (by score, without overlap check yet)\n",
    "print('Finding best source for each N by score...')\n",
    "best_by_n = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_source = None\n",
    "    \n",
    "    for name in sources:\n",
    "        if n in scores_by_source[name]:\n",
    "            score = scores_by_source[name][n]\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_source = name\n",
    "    \n",
    "    if best_source:\n",
    "        best_by_n[n] = {'source': best_source, 'score': best_score}\n",
    "\n",
    "# Count wins by source\n",
    "wins_by_source = {}\n",
    "for n, info in best_by_n.items():\n",
    "    src = info['source']\n",
    "    wins_by_source[src] = wins_by_source.get(src, 0) + 1\n",
    "\n",
    "print('\\nWins by source (before overlap validation):')\n",
    "for src, wins in sorted(wins_by_source.items(), key=lambda x: -x[1]):\n",
    "    print(f'  {src}: {wins} N values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now validate with overlap check and create ensemble\n",
    "print('\\nValidating with overlap check...')\n",
    "baseline_df = pd.read_csv('/home/code/exploration/datasets/submission.csv')\n",
    "\n",
    "ensemble_rows = []\n",
    "ensemble_sources = {}\n",
    "ensemble_scores = {}\n",
    "validation_failures = 0\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_valid_score = float('inf')\n",
    "    best_valid_source = None\n",
    "    best_valid_data = None\n",
    "    \n",
    "    # Try each source in order of score\n",
    "    candidates = []\n",
    "    for name in sources:\n",
    "        if n in scores_by_source[name]:\n",
    "            candidates.append((scores_by_source[name][n], name))\n",
    "    candidates.sort()  # Sort by score\n",
    "    \n",
    "    for score, name in candidates:\n",
    "        try:\n",
    "            trees, data = load_trees_from_df(sources[name], n)\n",
    "            if len(trees) == n and not has_collision(trees):\n",
    "                best_valid_score = score\n",
    "                best_valid_source = name\n",
    "                best_valid_data = data\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Fallback to baseline if no valid source found\n",
    "    if best_valid_data is None:\n",
    "        trees, data = load_trees_from_df(baseline_df, n)\n",
    "        best_valid_score = calculate_score(trees)\n",
    "        best_valid_source = 'submission.csv (fallback)'\n",
    "        best_valid_data = data\n",
    "        validation_failures += 1\n",
    "    \n",
    "    ensemble_rows.append(best_valid_data)\n",
    "    ensemble_sources[n] = best_valid_source\n",
    "    ensemble_scores[n] = best_valid_score\n",
    "\n",
    "print(f'Validation failures (fell back to baseline): {validation_failures}')\n",
    "\n",
    "# Count wins by source after validation\n",
    "wins_after_validation = {}\n",
    "for n, src in ensemble_sources.items():\n",
    "    wins_after_validation[src] = wins_after_validation.get(src, 0) + 1\n",
    "\n",
    "print('\\nWins by source (after overlap validation):')\n",
    "for src, wins in sorted(wins_after_validation.items(), key=lambda x: -x[1]):\n",
    "    print(f'  {src}: {wins} N values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score\n",
    "total_score = sum(ensemble_scores.values())\n",
    "print(f'\\nTotal ensemble score: {total_score:.6f}')\n",
    "print(f'Previous best (saspav ensemble): 70.630478')\n",
    "print(f'Improvement: {70.630478 - total_score:.6f}')\n",
    "print(f'Target: 68.919154')\n",
    "print(f'Gap to target: {total_score - 68.919154:.6f} ({(total_score - 68.919154) / 68.919154 * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "ensemble_df = pd.concat(ensemble_rows, ignore_index=True)\n",
    "\n",
    "# Sort by N and index\n",
    "ensemble_df['sn'] = ensemble_df['id'].str.split('_').str[0].astype(int)\n",
    "ensemble_df['si'] = ensemble_df['id'].str.split('_').str[1].astype(int)\n",
    "ensemble_df = ensemble_df.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "ensemble_df = ensemble_df[['id', 'x', 'y', 'deg']]\n",
    "\n",
    "# Save\n",
    "output_path = '/home/code/submission_candidates/candidate_010.csv'\n",
    "ensemble_df.to_csv(output_path, index=False)\n",
    "print(f'Saved ensemble to {output_path}')\n",
    "print(f'Total rows: {len(ensemble_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f26d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the saved file\n",
    "verify_df = pd.read_csv(output_path)\n",
    "verify_total = 0\n",
    "for n in range(1, 201):\n",
    "    trees, _ = load_trees_from_df(verify_df, n)\n",
    "    score = calculate_score(trees)\n",
    "    verify_total += score\n",
    "\n",
    "print(f'Verified total score: {verify_total:.6f}')\n",
    "print(f'Matches calculated: {abs(verify_total - total_score) < 0.0001}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which N values improved vs previous best\n",
    "print('\\nN values that improved vs saspav ensemble:')\n",
    "prev_best_df = pd.read_csv('/home/code/submission_candidates/candidate_009.csv')\n",
    "\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    prev_trees, _ = load_trees_from_df(prev_best_df, n)\n",
    "    prev_score = calculate_score(prev_trees)\n",
    "    new_score = ensemble_scores[n]\n",
    "    \n",
    "    if new_score < prev_score - 1e-9:\n",
    "        improvements.append((n, prev_score, new_score, prev_score - new_score, ensemble_sources[n]))\n",
    "\n",
    "print(f'Total improvements: {len(improvements)}')\n",
    "for n, prev, new, diff, src in sorted(improvements, key=lambda x: -x[3])[:20]:\n",
    "    print(f'  N={n}: {prev:.6f} -> {new:.6f} (improvement: {diff:.6f}) from {src}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abdeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': total_score,\n",
    "    'sources_used': dict(wins_after_validation),\n",
    "    'improvements_over_previous': len(improvements),\n",
    "    'validation_failures': validation_failures\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/011_expanded_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print('Metrics saved.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
