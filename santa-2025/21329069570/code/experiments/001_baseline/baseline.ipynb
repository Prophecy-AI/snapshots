{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c125df2d",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Santa 2025\n",
    "\n",
    "Validate and score the best pre-optimized submission from snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "import json\n",
    "\n",
    "getcontext().prec = 30\n",
    "\n",
    "# Tree shape definition\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def get_tree_polygon(x, y, angle_deg):\n",
    "    \"\"\"Create a tree polygon at position (x,y) with given rotation angle.\"\"\"\n",
    "    coords = list(zip(TX, TY))\n",
    "    poly = Polygon(coords)\n",
    "    poly = affinity.rotate(poly, angle_deg, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, xoff=x, yoff=y)\n",
    "    return poly\n",
    "\n",
    "def has_overlap(poly1, poly2, tolerance=1e-9):\n",
    "    \"\"\"Check if two polygons overlap (not just touch).\"\"\"\n",
    "    if not poly1.intersects(poly2):\n",
    "        return False\n",
    "    intersection = poly1.intersection(poly2)\n",
    "    return intersection.area > tolerance\n",
    "\n",
    "print(\"Functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best baseline submission\n",
    "baseline_path = '/home/code/best_baseline.csv'\n",
    "df = pd.read_csv(baseline_path)\n",
    "\n",
    "# Parse the submission\n",
    "df['x_val'] = df['x'].astype(str).str.replace('s', '').astype(float)\n",
    "df['y_val'] = df['y'].astype(str).str.replace('s', '').astype(float)\n",
    "df['deg_val'] = df['deg'].astype(str).str.replace('s', '').astype(float)\n",
    "df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"N values: {df['n'].min()} to {df['n'].max()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and score the submission\n",
    "def validate_and_score(df, check_overlaps=True):\n",
    "    \"\"\"Validate submission has no overlaps and calculate score.\"\"\"\n",
    "    total_score = 0\n",
    "    scores_by_n = {}\n",
    "    overlaps_found = []\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        group = df[df['n'] == n]\n",
    "        if len(group) != n:\n",
    "            print(f\"WARNING: N={n} has {len(group)} trees instead of {n}\")\n",
    "            continue\n",
    "            \n",
    "        polys = [get_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "                 for _, row in group.iterrows()]\n",
    "        \n",
    "        # Check overlaps (expensive, can skip for speed)\n",
    "        if check_overlaps:\n",
    "            for i in range(len(polys)):\n",
    "                for j in range(i+1, len(polys)):\n",
    "                    if has_overlap(polys[i], polys[j]):\n",
    "                        overlaps_found.append((n, i, j))\n",
    "        \n",
    "        # Calculate bounding box side length\n",
    "        union = unary_union(polys)\n",
    "        bounds = union.bounds\n",
    "        side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "        score_n = side**2 / n\n",
    "        scores_by_n[n] = score_n\n",
    "        total_score += score_n\n",
    "        \n",
    "        if n <= 10 or n % 50 == 0:\n",
    "            print(f\"N={n}: side={side:.6f}, score_contribution={score_n:.6f}\")\n",
    "    \n",
    "    return total_score, scores_by_n, overlaps_found\n",
    "\n",
    "print(\"Starting validation (this may take a few minutes)...\")\n",
    "total_score, scores_by_n, overlaps = validate_and_score(df, check_overlaps=True)\n",
    "print(f\"\\nTotal Score: {total_score:.6f}\")\n",
    "print(f\"Overlaps found: {len(overlaps)}\")\n",
    "if overlaps:\n",
    "    print(f\"First 10 overlaps: {overlaps[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution\n",
    "print(\"\\nTop 10 worst N values (highest score contribution):\")\n",
    "sorted_scores = sorted(scores_by_n.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_scores[:10]:\n",
    "    print(f\"  N={n}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nTop 10 best N values (lowest score contribution):\")\n",
    "for n, score in sorted_scores[-10:]:\n",
    "    print(f\"  N={n}: {score:.6f}\")\n",
    "\n",
    "# Target comparison\n",
    "target = 68.894234\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Current: {total_score:.6f}\")\n",
    "print(f\"Gap: {total_score - target:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission and metrics\n",
    "import shutil\n",
    "\n",
    "# Copy to submission folder\n",
    "shutil.copy(baseline_path, '/home/submission/submission.csv')\n",
    "shutil.copy(baseline_path, '/home/code/experiments/001_baseline/submission.csv')\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': total_score,\n",
    "    'overlaps': len(overlaps),\n",
    "    'target': target,\n",
    "    'gap_to_target': total_score - target,\n",
    "    'scores_by_n': {str(k): v for k, v in scores_by_n.items()}\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/001_baseline/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Saved submission to /home/submission/submission.csv\")\n",
    "print(f\"Saved metrics to /home/code/experiments/001_baseline/metrics.json\")\n",
    "print(f\"\\nFinal CV Score: {total_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
