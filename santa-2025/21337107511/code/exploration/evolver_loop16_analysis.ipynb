{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ad2ef3",
   "metadata": {},
   "source": [
    "# Loop 16 Analysis: Full CSV Scan\n",
    "\n",
    "## Goal: Find ALL CSV files and check for better per-N solutions\n",
    "\n",
    "The evaluator identified that we have 3476 CSV files but only checked ~109 main submission files.\n",
    "Let's do a comprehensive scan of ALL CSVs including preoptimized folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "getcontext().prec = 30\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125], dtype=np.float64)\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5], dtype=np.float64)\n",
    "\n",
    "def rotate_vertices(tx, ty, angle_deg):\n",
    "    angle_rad = angle_deg * np.pi / 180.0\n",
    "    cos_a = np.cos(angle_rad)\n",
    "    sin_a = np.sin(angle_rad)\n",
    "    rx = tx * cos_a - ty * sin_a\n",
    "    ry = tx * sin_a + ty * cos_a\n",
    "    return rx, ry\n",
    "\n",
    "def compute_score_for_n(df, n):\n",
    "    \"\"\"Compute score for a single N value.\"\"\"\n",
    "    n_df = df[df['id'].str.startswith(f'{n:03d}_')]\n",
    "    if len(n_df) != n:\n",
    "        return None\n",
    "    \n",
    "    min_x = np.inf\n",
    "    max_x = -np.inf\n",
    "    min_y = np.inf\n",
    "    max_y = -np.inf\n",
    "    \n",
    "    for _, row in n_df.iterrows():\n",
    "        x = float(str(row['x']).replace('s', ''))\n",
    "        y = float(str(row['y']).replace('s', ''))\n",
    "        angle = float(str(row['deg']).replace('s', ''))\n",
    "        \n",
    "        rx, ry = rotate_vertices(TX, TY, angle)\n",
    "        vx = rx + x\n",
    "        vy = ry + y\n",
    "        \n",
    "        min_x = min(min_x, vx.min())\n",
    "        max_x = max(max_x, vx.max())\n",
    "        min_y = min(min_y, vy.min())\n",
    "        max_y = max(max_y, vy.max())\n",
    "    \n",
    "    side = max(max_x - min_x, max_y - min_y)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(\"Functions defined. Ready to scan.\")\n",
    "print(f\"Total CSV files: {len(glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files\n",
    "all_csvs = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(all_csvs)} CSV files\")\n",
    "\n",
    "# Categorize by folder type\n",
    "preoptimized_csvs = [f for f in all_csvs if 'preoptimized' in f]\n",
    "submission_csvs = [f for f in all_csvs if 'submission' in f.lower() and 'preoptimized' not in f]\n",
    "other_csvs = [f for f in all_csvs if f not in preoptimized_csvs and f not in submission_csvs]\n",
    "\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  Preoptimized folder CSVs: {len(preoptimized_csvs)}\")\n",
    "print(f\"  Submission CSVs: {len(submission_csvs)}\")\n",
    "print(f\"  Other CSVs: {len(other_csvs)}\")\n",
    "\n",
    "# Show some examples of preoptimized CSVs\n",
    "print(f\"\\nSample preoptimized CSVs:\")\n",
    "for csv in preoptimized_csvs[:10]:\n",
    "    print(f\"  {csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973987cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline for comparison\n",
    "baseline_path = \"/home/nonroot/snapshots/santa-2025/21337353543/submission/submission.csv\"\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "\n",
    "# Compute baseline per-N scores\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    score = compute_score_for_n(baseline_df, n)\n",
    "    if score:\n",
    "        baseline_scores[n] = score\n",
    "\n",
    "baseline_total = sum(baseline_scores.values())\n",
    "print(f\"Baseline total score: {baseline_total:.6f}\")\n",
    "print(f\"Baseline N=1: {baseline_scores[1]:.6f}\")\n",
    "print(f\"Baseline N=10: {baseline_scores[10]:.6f}\")\n",
    "print(f\"Baseline N=100: {baseline_scores[100]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66400ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan ALL CSV files for better per-N solutions\n",
    "import time\n",
    "\n",
    "def scan_csv_for_improvements(csv_path, baseline_scores):\n",
    "    \"\"\"Scan a CSV file and return improvements over baseline.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            return None, {}\n",
    "        \n",
    "        improvements = {}\n",
    "        total_score = 0\n",
    "        valid_n_count = 0\n",
    "        \n",
    "        for n in range(1, 201):\n",
    "            score = compute_score_for_n(df, n)\n",
    "            if score is not None:\n",
    "                total_score += score\n",
    "                valid_n_count += 1\n",
    "                \n",
    "                if n in baseline_scores and score < baseline_scores[n] - 1e-10:\n",
    "                    improvements[n] = {\n",
    "                        'baseline': baseline_scores[n],\n",
    "                        'new': score,\n",
    "                        'improvement': baseline_scores[n] - score\n",
    "                    }\n",
    "        \n",
    "        if valid_n_count == 200:\n",
    "            return total_score, improvements\n",
    "        else:\n",
    "            return None, improvements\n",
    "    except Exception as e:\n",
    "        return None, {}\n",
    "\n",
    "# Scan preoptimized CSVs first (most likely to have different solutions)\n",
    "print(\"Scanning preoptimized CSVs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "best_per_n = {n: {'score': baseline_scores[n], 'source': 'baseline'} for n in range(1, 201)}\n",
    "all_improvements = []\n",
    "\n",
    "for i, csv_path in enumerate(preoptimized_csvs):\n",
    "    total_score, improvements = scan_csv_for_improvements(csv_path, baseline_scores)\n",
    "    \n",
    "    if improvements:\n",
    "        for n, data in improvements.items():\n",
    "            if data['new'] < best_per_n[n]['score']:\n",
    "                best_per_n[n] = {'score': data['new'], 'source': csv_path}\n",
    "                all_improvements.append((csv_path, n, data['improvement']))\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Scanned {i+1}/{len(preoptimized_csvs)} preoptimized CSVs...\")\n",
    "\n",
    "print(f\"\\nScanned {len(preoptimized_csvs)} preoptimized CSVs in {time.time() - start_time:.1f}s\")\n",
    "print(f\"Found {len(all_improvements)} improvements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now scan ALL other CSVs\n",
    "print(\"Scanning all other CSVs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i, csv_path in enumerate(all_csvs):\n",
    "    if csv_path in preoptimized_csvs:\n",
    "        continue\n",
    "    \n",
    "    total_score, improvements = scan_csv_for_improvements(csv_path, baseline_scores)\n",
    "    \n",
    "    if improvements:\n",
    "        for n, data in improvements.items():\n",
    "            if data['new'] < best_per_n[n]['score']:\n",
    "                best_per_n[n] = {'score': data['new'], 'source': csv_path}\n",
    "                all_improvements.append((csv_path, n, data['improvement']))\n",
    "    \n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"  Scanned {i+1}/{len(all_csvs)} CSVs...\")\n",
    "\n",
    "print(f\"\\nScanned all CSVs in {time.time() - start_time:.1f}s\")\n",
    "print(f\"Total improvements found: {len(all_improvements)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ae10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze improvements\n",
    "print(\"=\" * 60)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count N values with improvements\n",
    "improved_ns = [n for n in range(1, 201) if best_per_n[n]['source'] != 'baseline']\n",
    "print(f\"\\nN values with improvements: {len(improved_ns)}\")\n",
    "\n",
    "# Calculate total potential improvement\n",
    "new_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nBaseline total: {baseline_total:.6f}\")\n",
    "print(f\"Best ensemble total: {new_total:.6f}\")\n",
    "print(f\"Potential improvement: {baseline_total - new_total:.6f}\")\n",
    "\n",
    "# Show top improvements\n",
    "if all_improvements:\n",
    "    print(f\"\\nTop 20 improvements:\")\n",
    "    sorted_improvements = sorted(all_improvements, key=lambda x: -x[2])\n",
    "    for csv_path, n, improvement in sorted_improvements[:20]:\n",
    "        source_name = os.path.basename(csv_path)\n",
    "        print(f\"  N={n}: +{improvement:.8f} from {source_name}\")\n",
    "\n",
    "# Show unique sources\n",
    "unique_sources = set(best_per_n[n]['source'] for n in range(1, 201) if best_per_n[n]['source'] != 'baseline')\n",
    "print(f\"\\nUnique sources with improvements: {len(unique_sources)}\")\n",
    "for source in list(unique_sources)[:10]:\n",
    "    print(f\"  {source}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015011e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the improvements come from the same snapshot that had overlaps\n",
    "# (exp_011 found that snapshot 21145966992 had overlaps)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKING IMPROVEMENT SOURCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check which snapshots the improvements come from\n",
    "snapshot_improvements = defaultdict(list)\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n]['source'] != 'baseline':\n",
    "        # Extract snapshot ID from path\n",
    "        source = best_per_n[n]['source']\n",
    "        parts = source.split('/')\n",
    "        for part in parts:\n",
    "            if part.isdigit() and len(part) > 10:\n",
    "                snapshot_improvements[part].append(n)\n",
    "                break\n",
    "\n",
    "print(f\"\\nSnapshots with improvements:\")\n",
    "for snapshot_id, ns in sorted(snapshot_improvements.items(), key=lambda x: -len(x[1])):\n",
    "    print(f\"  {snapshot_id}: {len(ns)} N values improved\")\n",
    "\n",
    "# Check if 21145966992 is in the list (this was the one with overlaps)\n",
    "if '21145966992' in snapshot_improvements:\n",
    "    print(f\"\\n⚠️ WARNING: Snapshot 21145966992 (known to have overlaps) is in the improvements!\")\n",
    "    print(f\"   N values from this snapshot: {snapshot_improvements['21145966992']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the actual scores of the external data sources\n",
    "print(\"=\" * 60)\n",
    "print(\"EXTERNAL DATA SOURCE SCORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "external_sources = [\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/telegram/71.97.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/telegram/72.49.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump/submission.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_70_926149550346.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_70_936673758122.csv',\n",
    "]\n",
    "\n",
    "for source in external_sources:\n",
    "    if os.path.exists(source):\n",
    "        try:\n",
    "            df = pd.read_csv(source)\n",
    "            total = 0\n",
    "            valid = 0\n",
    "            for n in range(1, 201):\n",
    "                score = compute_score_for_n(df, n)\n",
    "                if score:\n",
    "                    total += score\n",
    "                    valid += 1\n",
    "            print(f\"{os.path.basename(source)}: {total:.6f} ({valid} valid N)\")\n",
    "        except Exception as e:\n",
    "            print(f\"{os.path.basename(source)}: ERROR - {e}\")\n",
    "    else:\n",
    "        print(f\"{os.path.basename(source)}: NOT FOUND\")\n",
    "\n",
    "print(f\"\\nBaseline: {baseline_total:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the santa25-public files more carefully - they have scores in their names\n",
    "print(\"=\" * 60)\n",
    "print(\"SANTA25-PUBLIC FILES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "santa25_public_dir = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/'\n",
    "if os.path.exists(santa25_public_dir):\n",
    "    files = os.listdir(santa25_public_dir)\n",
    "    print(f\"Files in santa25-public: {len(files)}\")\n",
    "    \n",
    "    for f in sorted(files):\n",
    "        if f.endswith('.csv'):\n",
    "            path = os.path.join(santa25_public_dir, f)\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                total = 0\n",
    "                valid = 0\n",
    "                for n in range(1, 201):\n",
    "                    score = compute_score_for_n(df, n)\n",
    "                    if score:\n",
    "                        total += score\n",
    "                        valid += 1\n",
    "                print(f\"  {f}: {total:.6f} ({valid} valid N)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {f}: ERROR - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34432642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Check if ANY CSV has a total score better than baseline\n",
    "print(\"=\" * 60)\n",
    "print(\"FINDING BEST TOTAL SCORES ACROSS ALL CSVS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_total_scores = []\n",
    "\n",
    "for csv_path in all_csvs:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        total = 0\n",
    "        valid = 0\n",
    "        for n in range(1, 201):\n",
    "            score = compute_score_for_n(df, n)\n",
    "            if score:\n",
    "                total += score\n",
    "                valid += 1\n",
    "        \n",
    "        if valid == 200:\n",
    "            best_total_scores.append((total, csv_path))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Sort by score\n",
    "best_total_scores.sort()\n",
    "\n",
    "print(f\"\\nTop 20 CSVs by total score:\")\n",
    "for score, path in best_total_scores[:20]:\n",
    "    rel_path = path.replace('/home/nonroot/snapshots/santa-2025/', '')\n",
    "    print(f\"  {score:.6f}: {rel_path}\")\n",
    "\n",
    "print(f\"\\nBaseline: {baseline_total:.6f}\")\n",
    "print(f\"Best found: {best_total_scores[0][0]:.6f}\")\n",
    "print(f\"Gap: {baseline_total - best_total_scores[0][0]:.6f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
