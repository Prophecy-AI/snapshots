{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7126044",
   "metadata": {},
   "source": [
    "# Evolver Loop 5 Analysis\n",
    "\n",
    "## Submission Failure Analysis\n",
    "\n",
    "exp_004 failed with \"Solution and submission values for id do not match\"\n",
    "\n",
    "This is a different error than the overlap errors. Let's investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef201959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the failed submission\n",
    "sub = pd.read_csv('/home/submission/submission.csv')\n",
    "print(f\"Submission shape: {sub.shape}\")\n",
    "print(f\"Unique N values: {len(sub['id'].str.split('_').str[0].unique())}\")\n",
    "\n",
    "# Check expected IDs\n",
    "expected_ids = []\n",
    "for n in range(1, 201):\n",
    "    for i in range(n):\n",
    "        expected_ids.append(f\"{n:03d}_{i}\")\n",
    "\n",
    "print(f\"Expected IDs: {len(expected_ids)}\")\n",
    "print(f\"Actual IDs: {len(sub['id'])}\")\n",
    "\n",
    "# Check for mismatches\n",
    "sub_ids = set(sub['id'].tolist())\n",
    "expected_set = set(expected_ids)\n",
    "\n",
    "missing = expected_set - sub_ids\n",
    "extra = sub_ids - expected_set\n",
    "\n",
    "print(f\"\\nMissing IDs: {len(missing)}\")\n",
    "if missing:\n",
    "    print(f\"First 10 missing: {sorted(list(missing))[:10]}\")\n",
    "print(f\"Extra IDs: {len(extra)}\")\n",
    "if extra:\n",
    "    print(f\"First 10 extra: {sorted(list(extra))[:10]}\")\n",
    "\n",
    "# Identify which N values have wrong format\n",
    "wrong_format_n = set()\n",
    "for id_val in extra:\n",
    "    n = int(id_val.split('_')[0])\n",
    "    wrong_format_n.add(n)\n",
    "print(f\"\\nN values with wrong ID format: {sorted(wrong_format_n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which snapshots have wrong ID format\n",
    "snapshot_base = '/home/nonroot/snapshots/santa-2025/'\n",
    "bad_snapshots = []\n",
    "\n",
    "for snap_dir in sorted(os.listdir(snapshot_base)):\n",
    "    sub_path = os.path.join(snapshot_base, snap_dir, 'submission', 'submission.csv')\n",
    "    if not os.path.exists(sub_path):\n",
    "        continue\n",
    "    \n",
    "    with open(sub_path, 'r') as f:\n",
    "        next(f)  # Skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "            id_val = parts[0]\n",
    "            # Check if any ID has wrong format (e.g., 013_000 instead of 013_0)\n",
    "            n_str, idx_str = id_val.split('_')\n",
    "            n = int(n_str)\n",
    "            if len(idx_str) > len(str(n-1)):  # Wrong format\n",
    "                bad_snapshots.append(snap_dir)\n",
    "                break\n",
    "\n",
    "print(f\"Snapshots with wrong ID format: {len(bad_snapshots)}\")\n",
    "print(f\"Bad snapshots: {bad_snapshots}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30786ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap to target\n",
    "print(\"=\" * 60)\n",
    "print(\"GAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "target = 68.887226\n",
    "best_lb = 70.615107  # exp_001\n",
    "best_cv = 70.522682  # exp_004 (but failed submission)\n",
    "\n",
    "print(f\"Target score: {target}\")\n",
    "print(f\"Best LB score: {best_lb}\")\n",
    "print(f\"Best CV score: {best_cv}\")\n",
    "print(f\"\")\n",
    "print(f\"Gap from best LB to target: {best_lb - target:.6f} ({(best_lb - target) / target * 100:.2f}%)\")\n",
    "print(f\"Gap from best CV to target: {best_cv - target:.6f} ({(best_cv - target) / target * 100:.2f}%)\")\n",
    "print(f\"\")\n",
    "print(\"CRITICAL: We need to improve by ~1.73 points (2.5%)\")\n",
    "print(\"The ensemble approach only gave 0.05 improvement.\")\n",
    "print(\"At this rate, we need ~35x more improvement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N contributions to understand where improvements are possible\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def create_tree_polygon(x, y, angle):\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def calculate_side(trees):\n",
    "    polys = [create_tree_polygon(*t) for t in trees]\n",
    "    union = unary_union(polys)\n",
    "    bounds = union.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "def calculate_score_for_n(trees, n):\n",
    "    side = calculate_side(trees)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(\"Functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd87c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline and calculate per-N scores\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21145966992/submission/submission.csv'\n",
    "baseline = pd.read_csv(baseline_path)\n",
    "\n",
    "# Parse coordinates (handle 's' prefix)\n",
    "def parse_coord(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "baseline['x_float'] = baseline['x'].apply(parse_coord)\n",
    "baseline['y_float'] = baseline['y'].apply(parse_coord)\n",
    "baseline['deg_float'] = baseline['deg'].apply(parse_coord)\n",
    "baseline['n'] = baseline['id'].str.split('_').str[0].astype(int)\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    n_data = baseline[baseline['n'] == n]\n",
    "    trees = list(zip(n_data['x_float'], n_data['y_float'], n_data['deg_float']))\n",
    "    per_n_scores[n] = calculate_score_for_n(trees, n)\n",
    "\n",
    "print(f\"Total baseline score: {sum(per_n_scores.values()):.6f}\")\n",
    "print(f\"\\nTop 10 contributors to score:\")\n",
    "for n, score in sorted(per_n_scores.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  N={n}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum for each N\n",
    "import math\n",
    "\n",
    "# Single tree at 45 degrees has minimum bounding box\n",
    "single_tree_min_side = 0.813173  # Known optimal for N=1\n",
    "\n",
    "print(\"\\nPer-N analysis (baseline vs theoretical):\")\n",
    "print(\"N\\tBaseline\\tTheoretical\\tGap\\t\\t% Gap\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "total_gap = 0\n",
    "for n in [1, 2, 3, 4, 5, 10, 20, 50, 100, 200]:\n",
    "    baseline_score = per_n_scores[n]\n",
    "    # Theoretical minimum: if we could pack n trees with no wasted space\n",
    "    # Area needed = n * single_tree_area, side = sqrt(area)\n",
    "    # But this is a lower bound, not achievable\n",
    "    theoretical = (single_tree_min_side ** 2) / n  # Lower bound (single tree scaled)\n",
    "    gap = baseline_score - theoretical\n",
    "    pct_gap = gap / baseline_score * 100\n",
    "    total_gap += gap\n",
    "    print(f\"{n}\\t{baseline_score:.6f}\\t{theoretical:.6f}\\t{gap:.6f}\\t{pct_gap:.1f}%\")\n",
    "\n",
    "print(f\"\\nTotal gap from theoretical minimum: {total_gap:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what techniques could close the gap\n",
    "print(\"=\" * 60)\n",
    "print(\"STRATEGY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. ENSEMBLE APPROACH (current)\n",
    "   - Combines best per-N from 114 snapshots\n",
    "   - Improvement: 0.05 points\n",
    "   - Problem: All snapshots are from same optimizer family\n",
    "   - Ceiling: ~70.5 (can't go lower with existing solutions)\n",
    "\n",
    "2. FRACTIONAL TRANSLATION (from top kernel)\n",
    "   - Step sizes: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n",
    "   - 8 directions: N, S, E, W, NE, NW, SE, SW\n",
    "   - Can be implemented in pure Python\n",
    "   - Expected improvement: 0.1-0.5 points per N\n",
    "\n",
    "3. NOVEL ALGORITHMS (required for target)\n",
    "   - No-Fit Polygon (NFP) for O(1) collision checks\n",
    "   - Branch-and-bound for small N (exact solutions)\n",
    "   - Genetic algorithm with custom operators\n",
    "   - Constraint programming\n",
    "\n",
    "4. KEY INSIGHT: Top teams have 900+ submissions\n",
    "   - They accumulate best per-N over many experiments\n",
    "   - Each experiment tries to improve SOME N values\n",
    "   - Final = ensemble of all best per-N\n",
    "   - We have 93 submissions remaining - USE THEM!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY FINDINGS FOR NEXT EXPERIMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. exp_004 FAILED because of ID format mismatch\n",
    "   - Some snapshots use '013_000' instead of '013_0'\n",
    "   - Bad snapshots: 21145963314, 21337107511\n",
    "   - FIX: Filter out bad snapshots OR normalize IDs\n",
    "\n",
    "2. Gap to target is 1.73 points (2.5%)\n",
    "   - Ensemble gave only 0.05 improvement\n",
    "   - Need ~35x more improvement\n",
    "   - MUST implement novel algorithms\n",
    "\n",
    "3. Fractional translation is implementable in Python\n",
    "   - Step sizes: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n",
    "   - 8 directions\n",
    "   - Can improve individual N values\n",
    "\n",
    "4. Per-N tracking is critical\n",
    "   - N=1 contributes 0.66 (highest)\n",
    "   - Small N (1-10) contribute ~4.0 total\n",
    "   - Focus on small N for biggest impact\n",
    "\n",
    "5. Validation requirements:\n",
    "   - ID format: NNN_I (e.g., 013_0, not 013_000)\n",
    "   - Precision: 18+ decimal places\n",
    "   - Overlap: Kaggle uses integer scaling (1e18)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
