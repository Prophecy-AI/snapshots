{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87622f35",
   "metadata": {},
   "source": [
    "# Loop 8 Strategic Analysis\n",
    "\n",
    "## Key Findings from Research\n",
    "\n",
    "1. **Top kernels use C++ optimizers (bbox3)** - These are pre-compiled binaries that run simulated annealing\n",
    "2. **The baseline is already at a local optimum** - Fractional translation found ZERO improvements\n",
    "3. **Gap to target: 1.73 points** (70.615 → 68.886)\n",
    "4. **Top teams achieve ~68.5** - This proves the gap IS closable\n",
    "\n",
    "## What's NOT Working\n",
    "- Ensemble approaches (3 failures due to overlaps)\n",
    "- Fractional translation (baseline is already optimized)\n",
    "- Running same optimizer with different parameters\n",
    "\n",
    "## What COULD Work\n",
    "1. **Implement SA from scratch in Python** (not using binaries)\n",
    "2. **Focus on small N values** (N=2-20 have largest theoretical gaps)\n",
    "3. **Use Numba/JIT for speed**\n",
    "4. **Rotation optimization** (not just translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31385200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the theoretical gap for small N values\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load baseline scores\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# The baseline score is 70.615107\n",
    "baseline_total = 70.615107\n",
    "target = 68.885544\n",
    "gap = baseline_total - target\n",
    "\n",
    "print(f\"Current baseline: {baseline_total:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap to close: {gap:.6f}\")\n",
    "print(f\"Gap percentage: {100*gap/baseline_total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c550ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N contributions to understand where improvements are possible\n",
    "# Load the baseline submission\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "VALID_BASELINE = '/home/nonroot/snapshots/santa-2025/21337353543/submission/submission.csv'\n",
    "\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def create_tree(x, y, angle):\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def calculate_side(trees):\n",
    "    polys = [create_tree(*t) for t in trees]\n",
    "    union = unary_union(polys)\n",
    "    bounds = union.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "def load_baseline(path):\n",
    "    trees_by_n = {}\n",
    "    with open(path, 'r') as f:\n",
    "        next(f)  # Skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "            id_val, x_str, y_str, deg_str = parts\n",
    "            n = int(id_val.split('_')[0])\n",
    "            x = float(x_str[1:] if x_str.startswith('s') else x_str)\n",
    "            y = float(y_str[1:] if y_str.startswith('s') else y_str)\n",
    "            angle = float(deg_str[1:] if deg_str.startswith('s') else deg_str)\n",
    "            if n not in trees_by_n:\n",
    "                trees_by_n[n] = []\n",
    "            trees_by_n[n].append((x, y, angle))\n",
    "    return trees_by_n\n",
    "\n",
    "baseline_trees = load_baseline(VALID_BASELINE)\n",
    "print(f\"Loaded {len(baseline_trees)} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-N scores and identify where improvements are most valuable\n",
    "per_n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    side = calculate_side(baseline_trees[n])\n",
    "    score = (side ** 2) / n\n",
    "    per_n_scores[n] = {'side': side, 'score': score}\n",
    "\n",
    "# Sort by score contribution (highest first)\n",
    "sorted_by_score = sorted(per_n_scores.items(), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "print(\"Top 20 N values by score contribution:\")\n",
    "print(\"=\"*50)\n",
    "for n, data in sorted_by_score[:20]:\n",
    "    print(f\"N={n:3d}: side={data['side']:.6f}, score={data['score']:.6f}\")\n",
    "\n",
    "print(f\"\\nTotal score: {sum(d['score'] for d in per_n_scores.values()):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b65f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum for small N\n",
    "# For N=1, the optimal is a single tree at 45 degrees (already known)\n",
    "# For N=2+, we need to estimate based on tree geometry\n",
    "\n",
    "# Tree bounding box at optimal rotation (45 degrees)\n",
    "import math\n",
    "\n",
    "def get_tree_bbox_at_angle(angle):\n",
    "    \"\"\"Get bounding box dimensions for a tree at given angle.\"\"\"\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    bounds = poly.bounds\n",
    "    return bounds[2] - bounds[0], bounds[3] - bounds[1]  # width, height\n",
    "\n",
    "# Find optimal angle for single tree\n",
    "best_angle = 0\n",
    "best_max_dim = float('inf')\n",
    "for angle in range(0, 360):\n",
    "    w, h = get_tree_bbox_at_angle(angle)\n",
    "    max_dim = max(w, h)\n",
    "    if max_dim < best_max_dim:\n",
    "        best_max_dim = max_dim\n",
    "        best_angle = angle\n",
    "\n",
    "print(f\"Optimal single tree angle: {best_angle}°\")\n",
    "print(f\"Optimal single tree side: {best_max_dim:.6f}\")\n",
    "print(f\"Optimal N=1 score: {best_max_dim**2:.6f}\")\n",
    "print(f\"Baseline N=1 score: {per_n_scores[1]['score']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6105dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the gap for small N values\n",
    "# Theoretical minimum assumes perfect packing (which may not be achievable)\n",
    "\n",
    "print(\"\\nAnalysis of small N values:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'N':>3} | {'Baseline':>10} | {'Side':>8} | {'Trees/Area':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for n in range(1, 21):\n",
    "    score = per_n_scores[n]['score']\n",
    "    side = per_n_scores[n]['side']\n",
    "    area = side ** 2\n",
    "    trees_per_area = n / area\n",
    "    print(f\"{n:3d} | {score:10.6f} | {side:8.4f} | {trees_per_area:10.4f}\")\n",
    "\n",
    "print(f\"\\nSum of N=1-20 scores: {sum(per_n_scores[n]['score'] for n in range(1, 21)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: The baseline is already highly optimized\n",
    "# To improve, we need to either:\n",
    "# 1. Find better configurations for specific N values (hard - already optimized)\n",
    "# 2. Use a fundamentally different approach (e.g., simulated annealing from scratch)\n",
    "\n",
    "# Let's check what the top kernels achieve\n",
    "# From research: top kernels achieve ~68.5, we're at 70.6\n",
    "# That's a 2.1 point gap\n",
    "\n",
    "# The gap is distributed across all N values\n",
    "# If we could improve each N by 1%, we'd get:\n",
    "improvement_1pct = sum(per_n_scores[n]['score'] * 0.01 for n in range(1, 201))\n",
    "print(f\"1% improvement across all N: {improvement_1pct:.6f}\")\n",
    "\n",
    "# To close the 1.73 gap, we need:\n",
    "required_pct = 1.73 / sum(per_n_scores[n]['score'] for n in range(1, 201)) * 100\n",
    "print(f\"Required improvement: {required_pct:.2f}%\")\n",
    "\n",
    "# This is achievable with better optimization algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy: Implement simulated annealing from scratch\n",
    "# Key components:\n",
    "# 1. Random perturbation (translation + rotation)\n",
    "# 2. Temperature schedule\n",
    "# 3. Accept worse solutions with probability exp(-delta/T)\n",
    "# 4. Focus on small N first (faster to test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED STRATEGY FOR NEXT EXPERIMENT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. IMPLEMENT SIMULATED ANNEALING FROM SCRATCH (no binaries!)\n",
    "   - Start with small N (N=10, N=20, N=30)\n",
    "   - Use Numba for speed\n",
    "   - Temperature schedule: T_start=1.0, T_end=0.00001, cooling=0.999\n",
    "   - Perturbations: dx, dy in [-0.1, 0.1], da in [-5, 5] degrees\n",
    "\n",
    "2. KEY INSIGHT: The baseline is at a LOCAL optimum\n",
    "   - Fractional translation can't escape it\n",
    "   - SA with temperature can escape local optima\n",
    "   - Need to accept worse solutions temporarily\n",
    "\n",
    "3. FOCUS ON HIGH-IMPACT N VALUES:\n",
    "   - N=1: Already optimal (45°)\n",
    "   - N=2-10: Highest score contribution per tree\n",
    "   - N=11-50: Medium impact\n",
    "   - N=51-200: Lower impact but many values\n",
    "\n",
    "4. VALIDATION:\n",
    "   - Use integer scaling (1e18) for overlap detection\n",
    "   - Match Kaggle's precision requirements\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nTarget: {target:.6f}\")\n",
    "print(f\"Current: {baseline_total:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({required_pct:.2f}% improvement needed)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
