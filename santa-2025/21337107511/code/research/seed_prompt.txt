## Current Status
- Best CV score: 70.615107 from exp_012 (Numba SA)
- Best LB score: 70.615107 (exp_001 and exp_012 both achieved this)
- Target: 68.884125 | Gap to target: 1.73 points (2.45%)

## ⚠️ CRITICAL DIAGNOSIS

### Why We're Stuck at 70.615:
1. **Ensemble attempts (exp_002-006) found CV=70.52** but ALL failed Kaggle validation with "Overlapping trees"
2. **exp_011 analysis revealed**: The 0.09 improvement came from snapshot 21145966992 which has OVERLAPS
3. **All VALID solutions converge to the same score**: 70.615107
4. **Single-source optimization (exp_007-014) found ZERO improvements**: The baseline is at a local optimum

### What the Top Kernel Does (jonathanchan - scores ~68.5):
1. **Ensembles from 19 DIFFERENT sources** (6 datasets + 13 notebooks)
2. **For each N, picks BEST solution across ALL sources**
3. **Runs C++ SA with 20000 iterations × 80 rounds = 1.6M iterations**
4. **Uses fractional translation as final polish**

### The Gap:
- We have access to 3475 CSV files but all converge to same local optimum
- The top kernel uses 19 EXTERNAL sources we don't have (Kaggle datasets/notebooks)
- Without diverse sources, we can't find per-N improvements

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with same optimizer - FORBIDDEN
- Repeating ensemble attempts that already failed validation - FORBIDDEN

## ✅ MANDATORY NEXT EXPERIMENT: GENERATE DIVERSE SOLUTIONS

Since we can't access external sources, we must GENERATE diverse solutions ourselves.

### EXPERIMENT 015: ASYMMETRIC SOLUTION GENERATION

The discussion "Why the winning solutions will be Asymmetric" (39 votes) suggests asymmetric solutions outperform symmetric ones.

**TASK**: Generate DIVERSE solutions using DIFFERENT strategies, then ensemble:

```python
"""
Generate diverse solutions using DIFFERENT algorithms/parameters.
Each algorithm may find a DIFFERENT local optimum.
Then ensemble: for each N, pick the best across all generated solutions.
"""

import numpy as np
from numba import njit
import random

# Strategy 1: Random angle initialization (different from baseline's 45° multiples)
def generate_random_angle_solution(n, seed):
    """Generate solution with random angles (not 45° multiples)."""
    random.seed(seed)
    # Use angles like 30°, 60°, 120° instead of 45°, 90°, 135°
    angles = [random.choice([0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]) for _ in range(n)]
    # Place trees using bottom-left heuristic with these angles
    return place_trees_bottom_left(n, angles)

# Strategy 2: Different packing order (not by index)
def generate_size_ordered_solution(n, seed):
    """Place larger trees first, then fit smaller ones around them."""
    pass

# Strategy 3: Cluster-based placement
def generate_cluster_solution(n, seed):
    """Group trees into clusters, optimize each cluster, then combine."""
    pass

# Strategy 4: Spiral placement
def generate_spiral_solution(n, seed):
    """Place trees in a spiral pattern from center outward."""
    pass

# Generate 100 diverse solutions per N
# Ensemble: pick best per-N across all solutions
```

### IMPLEMENTATION REQUIREMENTS:

1. **Use Numba JIT for speed** - we need to generate many solutions quickly
2. **Validate with Kaggle's exact method** - Decimal + 1e18 integer scaling
3. **Track per-N scores** - even if total is worse, individual N may be better
4. **Generate at least 50 diverse solutions per N** - different seeds, different algorithms

### EXPECTED OUTCOME:
- Different algorithms find DIFFERENT local optima
- Even if each solution is worse than baseline overall, some N values may be better
- Ensemble picks best per-N → potential improvement

## ✅ ALTERNATIVE: IMPLEMENT C++ SA FROM SCRATCH

If Python is too slow, you MAY write your own C++ code (NOT use pre-compiled binaries):

```cpp
// Simple SA that can run 1M+ iterations
// Key: Use fast overlap detection (bounding box first, then polygon)
// Run with different random seeds to find diverse local optima
```

Compile with: `g++ -O3 -march=native -std=c++17 -o my_sa my_sa.cpp`

**NOTE**: Writing your own C++ is ALLOWED. Running pre-compiled binaries (bbox3, sa_fast) is FORBIDDEN.

## ✅ REQUIRED: PER-N TRACKING

Track best solution for EACH N separately:
```python
best_per_n = {}
for source in all_sources:
    for n in range(1, 201):
        score = compute_score_for_n(source, n)
        if n not in best_per_n or score < best_per_n[n]['score']:
            # Validate no overlaps using Kaggle's exact method
            if validate_no_overlap_kaggle(source, n):
                best_per_n[n] = {'score': score, 'source': source}
```

## Key Insight

The path to 68.89 requires:
1. **DIVERSE sources** - not just variations of the same optimizer
2. **Per-N ensembling** - pick best per-N across all sources
3. **Kaggle-exact validation** - use Decimal + 1e18 integer scaling

Since we don't have access to the 19 external sources the top kernel uses, we must GENERATE diverse solutions ourselves using fundamentally different algorithms.

## Submission Strategy
- Remaining submissions: 94
- Submit after this experiment? YES - we need LB feedback on any new approach
- Even if worse than baseline, LB feedback tells us what works

## What NOT to Try
- More iterations on bbox3/sa_fast (already exhausted)
- Ensemble from same snapshots (all converge to same optimum)
- Backpacking on single source (already tested, ZERO improvements)
- Fractional translation on baseline (already tested, ZERO improvements)