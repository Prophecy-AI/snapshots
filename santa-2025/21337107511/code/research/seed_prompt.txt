# Santa 2025 - Christmas Tree Packing Challenge: Evolved Seed Prompt (Loop 2)

## Current Status
- Best CV score: 70.5728 from exp_001 (001_better_baseline)
- Best LB score: 70.6151 (VALIDATED - passed Kaggle!)
- Target: 68.8872 | Gap to target: 1.73 points (2.5%)
- CV-LB gap: +0.0423 (LB slightly worse than CV - expected)

## Response to Evaluator

The evaluator correctly identified that the previous submission (exp_000) failed due to overlapping trees. The exp_001 submission PASSED Kaggle validation, confirming that snapshot 21145966992 is valid. The evaluator's concern about "72 N values with overlaps" was based on a different snapshot analysis - the actual submitted snapshot passed.

**Key insight from evaluator**: The close_pairs metric (trees with distance < 1e-10) correlates with Kaggle validation failures. We should track this metric for future submissions.

## ⛔ ABSOLUTELY FORBIDDEN (EXPERIMENT WILL BE REJECTED)

- bbox3, sa_fast_v2, eazy_optimizer, tree_packer, shake_public - FORBIDDEN
- subprocess.run() or os.system() to run binaries - FORBIDDEN
- ANY pre-compiled binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with external tools - FORBIDDEN

**WHY**: These binaries already produce ~70.6. The target is 68.89. BINARIES CANNOT GET THERE.

## ✅ KEY INSIGHT FROM TOP KERNEL ANALYSIS

The top-scoring kernel (jonathanchan/santa25-ensemble-sa-fractional-translation) reveals the winning strategy:

### 1. ENSEMBLE APPROACH (CRITICAL!)
```python
# Combine best per-N solutions from MULTIPLE sources
# The kernel uses 15+ different sources!
best = {n: {"score": 1e300, "data": None, "src": None} for n in range(1, 201)}

for source in all_sources:
    for n in range(1, 201):
        score = calculate_score_for_n(source, n)
        if score < best[n]["score"]:
            best[n]["score"] = score
            best[n]["data"] = source[n]
```

### 2. FRACTIONAL TRANSLATION (KEY TECHNIQUE!)
The kernel uses very fine-grained translation moves:
```python
frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
dx = [0, 0, 1, -1, 1, 1, -1, -1]
dy = [1, -1, 0, 0, 1, -1, 1, -1]

for step in frac_steps:
    for direction in range(8):
        # Try moving tree by tiny amount
        new_x = tree.x + dx[direction] * step
        new_y = tree.y + dy[direction] * step
        if no_overlap(new_x, new_y) and improves_score():
            accept_move()
```

### 3. N=1 IS ALREADY OPTIMAL
The kernel explicitly sets N=1 to (0, 0, 45°) - this is proven optimal.
**DO NOT try to optimize N=1.**

## ✅ RECOMMENDED APPROACH FOR THIS EXPERIMENT

### Option A: Implement Fractional Translation in Python (RECOMMENDED)

Create `experiments/002_fractional_translation/`:

```python
import numpy as np
from shapely.geometry import Polygon
from shapely import affinity

def fractional_translation(solution, n, max_iter=200):
    """Apply fractional translation to improve N-tree configuration."""
    frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005]
    directions = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]
    
    trees = solution[n].copy()
    best_side = calculate_side(trees)
    
    for iteration in range(max_iter):
        improved = False
        for i in range(len(trees)):
            for step in frac_steps:
                for dx, dy in directions:
                    # Try moving tree i
                    old_x, old_y, angle = trees[i]
                    new_x = old_x + dx * step
                    new_y = old_y + dy * step
                    trees[i] = (new_x, new_y, angle)
                    
                    if not has_overlap(trees) and calculate_side(trees) < best_side - 1e-12:
                        best_side = calculate_side(trees)
                        improved = True
                    else:
                        trees[i] = (old_x, old_y, angle)  # Revert
        
        if not improved:
            break
    
    return trees, best_side

# Apply to each N
for n in range(2, 201):  # Skip N=1 (already optimal)
    improved_trees, new_side = fractional_translation(baseline_solution, n)
    if new_side < baseline_side[n]:
        print(f"N={n}: Improved from {baseline_side[n]:.6f} to {new_side:.6f}")
        solution[n] = improved_trees
```

### Option B: Ensemble from Multiple Snapshots (ALSO VALUABLE)

Create `experiments/002_ensemble_snapshots/`:

```python
# Load all available snapshots
snapshot_base = '/home/nonroot/snapshots/santa-2025/'
snapshots = os.listdir(snapshot_base)

# Find best per-N across all snapshots
best_per_n = {n: {"score": float('inf'), "data": None} for n in range(1, 201)}

for snap_dir in snapshots:
    solution = load_snapshot(snap_dir)
    for n in range(1, 201):
        score = calculate_score_for_n(solution, n)
        if score < best_per_n[n]["score"]:
            best_per_n[n]["score"] = score
            best_per_n[n]["data"] = solution[n]

# Combine into final submission
final_solution = {n: best_per_n[n]["data"] for n in range(1, 201)}
```

## ✅ VALIDATION REQUIREMENTS

Before saving ANY submission:

```python
def validate_solution(solution):
    """Validate solution passes Kaggle's strict checks."""
    for n in range(1, 201):
        trees = solution[n]
        polys = [create_tree_polygon(*t) for t in trees]
        
        # Check for overlaps
        for i in range(len(polys)):
            for j in range(i+1, len(polys)):
                if polys[i].intersects(polys[j]):
                    intersection = polys[i].intersection(polys[j])
                    if intersection.area > 1e-20:
                        raise ValueError(f"N={n}: Trees {i} and {j} overlap!")
        
        # Check for very close pairs (warning)
        close_pairs = 0
        for i in range(len(polys)):
            for j in range(i+1, len(polys)):
                if polys[i].distance(polys[j]) < 1e-10:
                    close_pairs += 1
        if close_pairs > 0:
            print(f"WARNING: N={n} has {close_pairs} very close pairs")
    
    return True
```

## ✅ PER-N TRACKING (MANDATORY)

Track improvements for each N separately:

```python
# Load baseline per-N scores
baseline_per_n = calculate_per_n_scores(baseline_solution)

# After each experiment
new_per_n = calculate_per_n_scores(new_solution)

# Compare and report
improvements = []
for n in range(1, 201):
    diff = baseline_per_n[n] - new_per_n[n]
    if diff > 0.0001:
        improvements.append((n, diff))
        print(f"✅ N={n}: IMPROVED by {diff:.6f}")

print(f"\nTotal improvements: {len(improvements)} N values")
print(f"Total score improvement: {sum(d for _, d in improvements):.6f}")
```

## What NOT to Try

1. ❌ Running bbox3 or any binary with "more iterations"
2. ❌ Trying to optimize N=1 (already optimal at 45°)
3. ❌ Using subprocess.run() or os.system()
4. ❌ Copying existing kernels without understanding them

## Submission Strategy

- Remaining submissions: 93
- **SUBMIT after this experiment** - we have abundant submissions
- LB feedback is valuable for calibrating CV-LB relationship
- Even if score doesn't improve, we learn what doesn't work

## Success Criteria

- ✅ SUCCESS: Score improved by > 0.01 from 70.6151
- ⚠️ MARGINAL: Score improved by 0.001 - 0.01
- ❌ FAILURE: Score same or worse

## Experiment Folder Structure

```
experiments/002_fractional_translation/
├── analysis.ipynb
├── metrics.json
└── improved_solution.csv (if improvements found)
```
