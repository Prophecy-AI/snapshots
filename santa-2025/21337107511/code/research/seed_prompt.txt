## Current Status
- Best CV score: 70.615107 from exp_011 (baseline)
- Best LB score: 70.615107 (from exp_001)
- Target: 68.884199 | Gap to target: 1.73 points (2.45% improvement needed)

## ⚠️ CRITICAL SITUATION ANALYSIS

### What We've Learned (12 Experiments)
1. **All 115 local snapshots converge to SAME local optimum** (70.615107)
2. **Ensemble approach EXHAUSTED**: Only 1.76e-7 valid improvement (numerical noise)
3. **"Rebuild from corners" technique TESTED**: Only 4.6e-7 improvement (noise)
4. **Python SA, fractional translation, random restart**: ZERO improvements
5. **Constructive approaches**: 25-90% WORSE than baseline

### Why We're Stuck
The baseline (snapshot 21337353543) is at a **strong local optimum**. All approaches that:
- Optimize existing solutions (SA, fractional translation)
- Extract subsets from larger solutions (rebuild from corners)
- Use simple patterns (constructive, lattice)

...CANNOT escape this local optimum.

### The ONLY Path Forward: C++ Optimizer with CORRECT Parameters

The top kernels (scoring ~68.5) use bbox3.cpp with:
- **15,000-20,000 iterations** (not 1000 like exp_009)
- **Multiple rounds** (nr=80-96)
- **Proper temperature schedule**: T = 1.0 → 0.000005
- **Metropolis acceptance**: accept if delta < 0 OR random() < exp(-delta/temp)
- **OpenMP parallelization** for speed

The C++ optimizer in exp_009 used WRONG parameters:
- Only 1000 iterations (should be 15000+)
- Scale = 0.1 (should be 0.001 or smaller)
- No proper Metropolis acceptance

## ⛔ FORBIDDEN (WILL BE REJECTED)
- Running bbox3/sa_fast as a binary without fixing parameters
- subprocess.run() or os.system() to run pre-compiled binaries
- "Optimizing" existing CSV files with Python SA (proven to fail)
- Ensemble approaches (EXHAUSTED - only 1.76e-7 improvement)
- "Rebuild from corners" (EXHAUSTED - only 4.6e-7 improvement)

## ✅ REQUIRED: FIX AND RUN C++ OPTIMIZER

### Step 1: Create a PROPER C++ Simulated Annealing

Write a new C++ file with CORRECT parameters:

```cpp
// Key parameters that MUST be correct:
int num_iterations = 15000;  // NOT 1000
int num_rounds = 10;         // Multiple rounds
double initial_temp = 1.0;
double final_temp = 0.000005;

// Proper temperature schedule
double temp = initial_temp * pow(final_temp / initial_temp, (double)iter / num_iterations);

// Proper Metropolis acceptance
double delta = new_score - old_score;
if (delta < 0 || rf() < exp(-delta / temp)) {
    // Accept the move
}

// Small perturbations
double dx = (rf() - 0.5) * 0.002;  // NOT 0.1
double dy = (rf() - 0.5) * 0.002;
double dangle = (rf() - 0.5) * 2.0;  // degrees
```

### Step 2: Compile and Run

```bash
g++ my_sa.cpp -o my_sa -std=c++17 -fopenmp -O3 -march=native
./my_sa -n 15000 -r 10
```

### Step 3: Validate Output with Kaggle's Exact Method

Before submitting, validate using Decimal(prec=25) and 1e18 integer scaling.

## Alternative: Numba JIT for Python SA

If C++ is too complex, use Numba to speed up Python SA by 100x:

```python
from numba import njit
import numpy as np

@njit
def fast_sa(trees_x, trees_y, trees_angle, n_iterations=15000):
    """Numba-accelerated simulated annealing."""
    best_score = compute_score(trees_x, trees_y, trees_angle)
    temp = 1.0
    final_temp = 0.000005
    
    for i in range(n_iterations):
        temp = 1.0 * (final_temp / 1.0) ** (i / n_iterations)
        
        # Random perturbation
        tree_idx = np.random.randint(len(trees_x))
        dx = (np.random.random() - 0.5) * 0.002
        dy = (np.random.random() - 0.5) * 0.002
        dangle = (np.random.random() - 0.5) * 2.0
        
        # Try move
        old_x, old_y, old_angle = trees_x[tree_idx], trees_y[tree_idx], trees_angle[tree_idx]
        trees_x[tree_idx] += dx
        trees_y[tree_idx] += dy
        trees_angle[tree_idx] += dangle
        
        new_score = compute_score(trees_x, trees_y, trees_angle)
        delta = new_score - best_score
        
        # Metropolis acceptance
        if delta < 0 or np.random.random() < np.exp(-delta / temp):
            best_score = new_score
        else:
            # Reject - restore
            trees_x[tree_idx], trees_y[tree_idx], trees_angle[tree_idx] = old_x, old_y, old_angle
    
    return best_score
```

## ✅ REQUIRED: PER-N TRACKING

Track best solution for EACH N separately:
- Load baseline per-N scores
- After each experiment, compare per-N
- Keep only N values where you improved
- Ensemble = best per-N from all sources

## Expected Outcome

With CORRECT C++ SA parameters (15000 iterations, proper temperature):
- Should find improvements for at least SOME N values
- Even 0.001 improvement per N across 200 N values = 0.2 total improvement
- Multiple rounds accumulate improvements

## Response to Evaluator

The evaluator correctly identified that:
1. Local snapshots are EXHAUSTED (all at same optimum)
2. C++ optimizer parameters were WRONG in exp_009
3. Need to either fix C++ or use Numba for speed

I agree with all points. The next experiment MUST:
1. Use CORRECT SA parameters (15000+ iterations, proper temp schedule)
2. Either fix C++ code or use Numba JIT
3. Run on ALL N values
4. Validate with Kaggle's exact method before submitting

## What NOT to Try
- Python SA without Numba (too slow - proven in exp_008)
- Ensemble from local snapshots (EXHAUSTED)
- "Rebuild from corners" (EXHAUSTED)
- Constructive approaches (25-90% WORSE)
- Random restart (24-64% WORSE)

## Validation Notes
- Use Decimal(prec=25) and 1e18 integer scaling
- Validate ALL 200 N values before submission
- Any overlap = Kaggle rejection

## SUBMISSION STRATEGY
- Remaining submissions: 95
- Submit after this experiment? YES - we have abundant submissions
- Even if score doesn't improve, LB feedback is valuable
