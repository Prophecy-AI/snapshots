{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de73ca2",
   "metadata": {},
   "source": [
    "# Find Best Baseline Submission\n",
    "\n",
    "Evaluate multiple snapshots to find the best baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431908f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def create_tree_polygon(x, y, angle):\n",
    "    \"\"\"Create a tree polygon at position (x, y) with rotation angle (degrees).\"\"\"\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def parse_submission(df):\n",
    "    \"\"\"Parse submission dataframe into dict of n -> list of (x, y, angle).\"\"\"\n",
    "    solutions = {}\n",
    "    for _, row in df.iterrows():\n",
    "        id_parts = row['id'].split('_')\n",
    "        n = int(id_parts[0])\n",
    "        x = float(row['x'][1:])  # Remove 's' prefix\n",
    "        y = float(row['y'][1:])  # Remove 's' prefix\n",
    "        angle = float(row['deg'][1:])  # Remove 's' prefix\n",
    "        if n not in solutions:\n",
    "            solutions[n] = []\n",
    "        solutions[n].append((x, y, angle))\n",
    "    return solutions\n",
    "\n",
    "def calculate_score(solutions):\n",
    "    \"\"\"Calculate total score for all N=1 to 200.\"\"\"\n",
    "    total = 0\n",
    "    per_n_scores = {}\n",
    "    for n in range(1, 201):\n",
    "        if n not in solutions:\n",
    "            print(f\"Missing N={n}!\")\n",
    "            continue\n",
    "        trees = solutions[n]\n",
    "        polys = [create_tree_polygon(*t) for t in trees]\n",
    "        union = unary_union(polys)\n",
    "        bounds = union.bounds\n",
    "        side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "        contribution = (side ** 2) / n\n",
    "        per_n_scores[n] = contribution\n",
    "        total += contribution\n",
    "    return total, per_n_scores\n",
    "\n",
    "print(\"Functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b323a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all snapshot directories\n",
    "snapshot_base = '/home/nonroot/snapshots/santa-2025/'\n",
    "snapshot_dirs = sorted(os.listdir(snapshot_base))\n",
    "print(f\"Found {len(snapshot_dirs)} snapshot directories\")\n",
    "\n",
    "# Sample a few to find the best\n",
    "test_dirs = snapshot_dirs[-10:]  # Check last 10 (likely most recent/best)\n",
    "print(f\"Testing: {test_dirs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each snapshot\n",
    "results = []\n",
    "for snap_dir in test_dirs:\n",
    "    sub_path = os.path.join(snapshot_base, snap_dir, 'submission', 'submission.csv')\n",
    "    if os.path.exists(sub_path):\n",
    "        try:\n",
    "            df = pd.read_csv(sub_path)\n",
    "            solutions = parse_submission(df)\n",
    "            score, per_n = calculate_score(solutions)\n",
    "            results.append((snap_dir, score, per_n))\n",
    "            print(f\"{snap_dir}: score = {score:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{snap_dir}: ERROR - {e}\")\n",
    "    else:\n",
    "        print(f\"{snap_dir}: No submission file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b232fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best one\n",
    "if results:\n",
    "    best = min(results, key=lambda x: x[1])\n",
    "    print(f\"\\nBest baseline: {best[0]} with score {best[1]:.6f}\")\n",
    "    best_dir = best[0]\n",
    "    best_score = best[1]\n",
    "    best_per_n = best[2]\n",
    "else:\n",
    "    print(\"No valid submissions found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check the first snapshot mentioned in the seed prompt\n",
    "first_snap = '20952569566'\n",
    "sub_path = os.path.join(snapshot_base, first_snap, 'submission', 'submission.csv')\n",
    "if os.path.exists(sub_path):\n",
    "    df = pd.read_csv(sub_path)\n",
    "    solutions = parse_submission(df)\n",
    "    score, per_n = calculate_score(solutions)\n",
    "    print(f\"First snapshot {first_snap}: score = {score:.6f}\")\n",
    "    if score < best_score:\n",
    "        best_dir = first_snap\n",
    "        best_score = score\n",
    "        best_per_n = per_n\n",
    "        print(f\"This is better! Using this as baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the best baseline to our submission folder\n",
    "import shutil\n",
    "\n",
    "best_path = os.path.join(snapshot_base, best_dir, 'submission', 'submission.csv')\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy(best_path, '/home/submission/submission.csv')\n",
    "print(f\"Copied best baseline from {best_dir} to /home/submission/submission.csv\")\n",
    "print(f\"Baseline score: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb503763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': best_score,\n",
    "    'best_snapshot': best_dir,\n",
    "    'per_n_scores': {str(k): v for k, v in best_per_n.items()}\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/000_baseline/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Saved metrics to experiments/000_baseline/metrics.json\")\n",
    "print(f\"\\nBaseline CV Score: {best_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f12d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-N scores to see where improvements might be possible\n",
    "print(\"\\nTop 10 N values with highest score contribution:\")\n",
    "sorted_per_n = sorted(best_per_n.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_per_n[:10]:\n",
    "    print(f\"  N={n}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nSmall N scores (N=1-10):\")\n",
    "for n in range(1, 11):\n",
    "    print(f\"  N={n}: {best_per_n[n]:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
