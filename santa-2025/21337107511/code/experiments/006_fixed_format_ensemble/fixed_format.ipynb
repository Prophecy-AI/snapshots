{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a98a4c7",
   "metadata": {},
   "source": [
    "# Fixed Format Ensemble - Exclude ALL Bad Snapshots\n",
    "\n",
    "exp_005 has 201 rows with missing 's' prefix.\n",
    "Bad snapshots to exclude:\n",
    "- 21145963314 (wrong ID + no 's')\n",
    "- 21337107511 (wrong ID + no 's')\n",
    "- 21145965159 (no 's' prefix)\n",
    "- 21336527339 (no 's' prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9fc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# ALL bad snapshots to exclude\n",
    "BAD_SNAPSHOTS = {'21145963314', '21337107511', '21145965159', '21336527339'}\n",
    "\n",
    "# Tree polygon vertices for score calculation\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "def create_tree_polygon(x, y, angle):\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def calculate_side(trees):\n",
    "    polys = [create_tree_polygon(*t) for t in trees]\n",
    "    union = unary_union(polys)\n",
    "    bounds = union.bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "\n",
    "def calculate_score_for_n(trees, n):\n",
    "    side = calculate_side(trees)\n",
    "    return (side ** 2) / n\n",
    "\n",
    "print(f\"Bad snapshots to exclude: {BAD_SNAPSHOTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_snapshot_with_full_validation(path):\n",
    "    \"\"\"Load snapshot with BOTH ID format AND 's' prefix validation.\"\"\"\n",
    "    rows_by_n = {}\n",
    "    with open(path, 'r') as f:\n",
    "        next(f)  # Skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) != 4:\n",
    "                continue\n",
    "            id_val, x, y, deg = parts\n",
    "            \n",
    "            # Validate ID format\n",
    "            try:\n",
    "                n_str, idx_str = id_val.split('_')\n",
    "                n = int(n_str)\n",
    "                idx = int(idx_str)\n",
    "                expected_id = f\"{n:03d}_{idx}\"\n",
    "                if id_val != expected_id:\n",
    "                    return None  # Wrong ID format\n",
    "            except:\n",
    "                return None\n",
    "            \n",
    "            # Validate 's' prefix on coordinates\n",
    "            if not (x.startswith('s') and y.startswith('s') and deg.startswith('s')):\n",
    "                return None  # Missing 's' prefix\n",
    "            \n",
    "            if n not in rows_by_n:\n",
    "                rows_by_n[n] = []\n",
    "            rows_by_n[n].append(parts)\n",
    "    return rows_by_n\n",
    "\n",
    "def parse_row_to_tuple(row):\n",
    "    \"\"\"Parse a row to (x, y, angle) tuple for score calculation.\"\"\"\n",
    "    x_str = row[1]\n",
    "    y_str = row[2]\n",
    "    deg_str = row[3]\n",
    "    x = float(x_str[1:] if x_str.startswith('s') else x_str)\n",
    "    y = float(y_str[1:] if y_str.startswith('s') else y_str)\n",
    "    angle = float(deg_str[1:] if deg_str.startswith('s') else deg_str)\n",
    "    return (x, y, angle)\n",
    "\n",
    "def calculate_score_from_rows(rows, n):\n",
    "    \"\"\"Calculate score from raw string rows.\"\"\"\n",
    "    trees = [parse_row_to_tuple(row) for row in rows]\n",
    "    return calculate_score_for_n(trees, n)\n",
    "\n",
    "print(\"Loading functions with full validation defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline (exp_001 which passed Kaggle) as raw strings\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21145966992/submission/submission.csv'\n",
    "baseline_raw = load_snapshot_with_full_validation(baseline_path)\n",
    "\n",
    "if baseline_raw is None:\n",
    "    print(\"ERROR: Baseline has format issues!\")\n",
    "else:\n",
    "    # Calculate baseline scores\n",
    "    baseline_scores = {n: calculate_score_from_rows(baseline_raw[n], n) for n in range(1, 201)}\n",
    "    baseline_total = sum(baseline_scores.values())\n",
    "    print(f\"Baseline total score: {baseline_total:.6f}\")\n",
    "    print(f\"Baseline N=2 rows: {baseline_raw[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best_per_n with baseline\n",
    "best_per_n = {\n",
    "    n: {\n",
    "        'score': baseline_scores[n],\n",
    "        'rows': baseline_raw[n],\n",
    "        'source': 'baseline'\n",
    "    } for n in range(1, 201)\n",
    "}\n",
    "\n",
    "print(\"Initialized with baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5307a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all snapshots and find improvements (excluding ALL bad snapshots)\n",
    "snapshot_base = '/home/nonroot/snapshots/santa-2025/'\n",
    "snapshot_dirs = sorted(os.listdir(snapshot_base))\n",
    "print(f\"Found {len(snapshot_dirs)} snapshot directories\")\n",
    "print(f\"Excluding bad snapshots: {BAD_SNAPSHOTS}\")\n",
    "\n",
    "improvements_found = 0\n",
    "snapshots_processed = 0\n",
    "snapshots_skipped = 0\n",
    "\n",
    "for snap_dir in snapshot_dirs:\n",
    "    # Skip known bad snapshots\n",
    "    if snap_dir in BAD_SNAPSHOTS:\n",
    "        snapshots_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    sub_path = os.path.join(snapshot_base, snap_dir, 'submission', 'submission.csv')\n",
    "    if not os.path.exists(sub_path):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        snap_raw = load_snapshot_with_full_validation(sub_path)\n",
    "        \n",
    "        if snap_raw is None:\n",
    "            # This snapshot has format issues\n",
    "            snapshots_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Check each N\n",
    "        for n in range(1, 201):\n",
    "            if n not in snap_raw:\n",
    "                continue\n",
    "            \n",
    "            rows = snap_raw[n]\n",
    "            score = calculate_score_from_rows(rows, n)\n",
    "            \n",
    "            # Only accept if better score\n",
    "            if score < best_per_n[n]['score'] - 1e-10:\n",
    "                best_per_n[n]['score'] = score\n",
    "                best_per_n[n]['rows'] = rows  # Keep original string rows!\n",
    "                best_per_n[n]['source'] = snap_dir\n",
    "                improvements_found += 1\n",
    "        \n",
    "        snapshots_processed += 1\n",
    "        if snapshots_processed % 20 == 0:\n",
    "            print(f\"Processed {snapshots_processed} snapshots, {improvements_found} improvements...\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        snapshots_skipped += 1\n",
    "\n",
    "print(f\"\\nTotal: {snapshots_processed} snapshots processed\")\n",
    "print(f\"Snapshots skipped (format issues): {snapshots_skipped}\")\n",
    "print(f\"Improvements found: {improvements_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172bd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new total score\n",
    "new_total = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"New total score: {new_total:.6f}\")\n",
    "print(f\"Baseline total: {baseline_total:.6f}\")\n",
    "print(f\"Improvement: {baseline_total - new_total:.6f}\")\n",
    "\n",
    "# Count unique sources\n",
    "sources = set(best_per_n[n]['source'] for n in range(1, 201))\n",
    "print(f\"\\nUnique sources used: {len(sources)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top improvements\n",
    "print(\"\\nTop 20 improvements:\")\n",
    "improved_n = []\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n]['source'] != 'baseline':\n",
    "        old_score = baseline_scores[n]\n",
    "        new_score = best_per_n[n]['score']\n",
    "        improved_n.append((n, old_score - new_score, best_per_n[n]['source']))\n",
    "\n",
    "for n, improvement, source in sorted(improved_n, key=lambda x: -x[1])[:20]:\n",
    "    print(f\"  N={n}: improved by {improvement:.6f} from {source}\")\n",
    "\n",
    "print(f\"\\nTotal N values improved: {len(improved_n)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ffb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write ensemble preserving original string precision\n",
    "def write_ensemble(best_per_n, output_path):\n",
    "    \"\"\"Write ensemble using original string rows (preserves precision).\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('id,x,y,deg\\n')\n",
    "        for n in range(1, 201):\n",
    "            for row in best_per_n[n]['rows']:\n",
    "                f.write(','.join(row) + '\\n')\n",
    "\n",
    "write_ensemble(best_per_n, '/home/submission/submission.csv')\n",
    "print(\"Saved ensemble to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANDATORY: Validate ALL format requirements before submission\n",
    "def validate_submission(path):\n",
    "    \"\"\"Verify ALL format requirements.\"\"\"\n",
    "    errors = []\n",
    "    with open(path, 'r') as f:\n",
    "        next(f)  # Skip header\n",
    "        for line_num, line in enumerate(f, 2):\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) != 4:\n",
    "                errors.append(f\"Line {line_num}: wrong columns\")\n",
    "                continue\n",
    "            id_val, x, y, deg = parts\n",
    "            \n",
    "            # Check ID format\n",
    "            try:\n",
    "                n_str, idx_str = id_val.split('_')\n",
    "                n = int(n_str)\n",
    "                idx = int(idx_str)\n",
    "                expected_id = f\"{n:03d}_{idx}\"\n",
    "                if id_val != expected_id:\n",
    "                    errors.append(f\"Line {line_num}: ID '{id_val}' should be '{expected_id}'\")\n",
    "            except:\n",
    "                errors.append(f\"Line {line_num}: Invalid ID format '{id_val}'\")\n",
    "            \n",
    "            # Check 's' prefix\n",
    "            if not x.startswith('s'):\n",
    "                errors.append(f\"Line {line_num}: x missing 's' prefix: {x[:20]}\")\n",
    "            if not y.startswith('s'):\n",
    "                errors.append(f\"Line {line_num}: y missing 's' prefix: {y[:20]}\")\n",
    "            if not deg.startswith('s'):\n",
    "                errors.append(f\"Line {line_num}: deg missing 's' prefix: {deg[:20]}\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "print(\"Validating submission format...\")\n",
    "errors = validate_submission('/home/submission/submission.csv')\n",
    "if errors:\n",
    "    print(f\"ERRORS FOUND ({len(errors)}):\")\n",
    "    for e in errors[:20]:\n",
    "        print(f\"  {e}\")\n",
    "    print(\"\\n❌ SUBMISSION HAS FORMAT ERRORS - DO NOT SUBMIT!\")\n",
    "else:\n",
    "    print(\"✅ All format requirements passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the score by re-loading\n",
    "verify_raw = load_snapshot_with_full_validation('/home/submission/submission.csv')\n",
    "if verify_raw:\n",
    "    verify_total = sum(calculate_score_from_rows(verify_raw[n], n) for n in range(1, 201))\n",
    "    print(f\"Verified score: {verify_total:.6f}\")\n",
    "    print(f\"Expected score: {new_total:.6f}\")\n",
    "    print(f\"Match: {abs(verify_total - new_total) < 1e-10}\")\n",
    "else:\n",
    "    print(\"ERROR: Verification failed - format issues in output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37499abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': new_total,\n",
    "    'baseline_score': baseline_total,\n",
    "    'improvement': baseline_total - new_total,\n",
    "    'improvements_found': improvements_found,\n",
    "    'unique_sources': len(sources),\n",
    "    'n_values_improved': len(improved_n),\n",
    "    'snapshots_skipped': snapshots_skipped,\n",
    "    'format_errors': len(errors) if errors else 0,\n",
    "    'notes': 'Fixed format ensemble excluding ALL 4 bad snapshots with ID and s-prefix validation.'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/006_fixed_format_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved.\")\n",
    "print(f\"CV Score: {new_total:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
