{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88b98c1",
   "metadata": {},
   "source": [
    "# Loop 3 LB Feedback Analysis\n",
    "\n",
    "## Submission Results\n",
    "- exp_000: CV 70.6600 → LB 70.6600 (gap: 0.0000)\n",
    "- exp_001: CV 70.6595 → LB 70.6595 (gap: 0.0000)\n",
    "- exp_002: CV 70.6594 → LB 70.6594 (gap: 0.0000)\n",
    "\n",
    "## Key Observations\n",
    "1. **Perfect CV-LB alignment**: This is a deterministic optimization problem, not ML. CV = LB exactly.\n",
    "2. **Diminishing returns**: Improvements are getting smaller (0.000465 → 0.000056)\n",
    "3. **Gap to target**: 70.6594 - 68.9192 = 1.74 points (2.5%)\n",
    "\n",
    "## Critical Analysis\n",
    "The target score (68.919154) is the #1 LB score. We need to understand:\n",
    "1. What makes the top solution 2.5% better?\n",
    "2. Where is the improvement coming from (small N vs large N)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78908b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our current best submission\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "df['x'] = df['x'].str.strip('s').astype(float)\n",
    "df['y'] = df['y'].str.strip('s').astype(float)\n",
    "df['deg'] = df['deg'].str.strip('s').astype(float)\n",
    "df['n'] = df['id'].str[:3].astype(int)\n",
    "df['idx'] = df['id'].str[4:].astype(int)\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"N values: {df['n'].min()} to {df['n'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bcae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate side length for each N\n",
    "def calc_side_length(group):\n",
    "    # Get bounding box of all trees\n",
    "    # This is simplified - actual calculation needs polygon geometry\n",
    "    # For now, approximate using x,y positions\n",
    "    x_min, x_max = group['x'].min(), group['x'].max()\n",
    "    y_min, y_max = group['y'].min(), group['y'].max()\n",
    "    # Add tree dimensions (approx 1.0 height, 0.7 width)\n",
    "    side = max(x_max - x_min + 1.0, y_max - y_min + 1.0)\n",
    "    return side\n",
    "\n",
    "# Calculate per-N scores\n",
    "scores_by_n = []\n",
    "for n in range(1, 201):\n",
    "    group = df[df['n'] == n]\n",
    "    if len(group) > 0:\n",
    "        # Approximate side length\n",
    "        x_range = group['x'].max() - group['x'].min()\n",
    "        y_range = group['y'].max() - group['y'].min()\n",
    "        # Add tree dimensions\n",
    "        side = max(x_range + 1.0, y_range + 1.0)\n",
    "        score = side**2 / n\n",
    "        scores_by_n.append({'n': n, 'side': side, 'score': score})\n",
    "\n",
    "scores_df = pd.DataFrame(scores_by_n)\n",
    "print(f\"Total score (approx): {scores_df['score'].sum():.4f}\")\n",
    "print(f\"\\nTop 10 contributors to score:\")\n",
    "print(scores_df.nlargest(10, 'score')[['n', 'side', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Score by N\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(scores_df['n'], scores_df['score'], alpha=0.7)\n",
    "ax1.set_xlabel('N')\n",
    "ax1.set_ylabel('Score (s²/n)')\n",
    "ax1.set_title('Score Contribution by N')\n",
    "\n",
    "# Cumulative score\n",
    "ax2 = axes[0, 1]\n",
    "scores_df['cumsum'] = scores_df['score'].cumsum()\n",
    "ax2.plot(scores_df['n'], scores_df['cumsum'])\n",
    "ax2.axhline(y=70.66, color='r', linestyle='--', label='Current total')\n",
    "ax2.axhline(y=68.92, color='g', linestyle='--', label='Target')\n",
    "ax2.set_xlabel('N')\n",
    "ax2.set_ylabel('Cumulative Score')\n",
    "ax2.set_title('Cumulative Score')\n",
    "ax2.legend()\n",
    "\n",
    "# Side length by N\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(scores_df['n'], scores_df['side'], alpha=0.5, s=10)\n",
    "ax3.set_xlabel('N')\n",
    "ax3.set_ylabel('Side Length')\n",
    "ax3.set_title('Side Length by N')\n",
    "\n",
    "# Efficiency (trees per unit area)\n",
    "scores_df['efficiency'] = scores_df['n'] / (scores_df['side']**2)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(scores_df['n'], scores_df['efficiency'], alpha=0.5, s=10)\n",
    "ax4.set_xlabel('N')\n",
    "ax4.set_ylabel('Efficiency (n/s²)')\n",
    "ax4.set_title('Packing Efficiency by N')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/score_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nLowest efficiency N values (most room for improvement):\")\n",
    "print(scores_df.nsmallest(10, 'efficiency')[['n', 'side', 'score', 'efficiency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what improvement is needed per N to reach target\n",
    "current_total = 70.659437\n",
    "target = 68.919154\n",
    "gap = current_total - target\n",
    "\n",
    "print(f\"Current score: {current_total:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap to close: {gap:.6f}\")\n",
    "print(f\"Gap as %: {gap/current_total*100:.2f}%\")\n",
    "\n",
    "# If we could improve all N equally\n",
    "print(f\"\\nIf improvement distributed equally across 200 N values:\")\n",
    "print(f\"  Need {gap/200:.6f} improvement per N\")\n",
    "\n",
    "# If we focus on small N (1-20)\n",
    "print(f\"\\nSmall N (1-20) contribute: {scores_df[scores_df['n'] <= 20]['score'].sum():.4f}\")\n",
    "print(f\"Large N (100-200) contribute: {scores_df[scores_df['n'] >= 100]['score'].sum():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what the target score implies\n",
    "# Target = 68.919154, Current = 70.659437\n",
    "# If we assume uniform improvement, each N needs ~2.5% better side length\n",
    "\n",
    "print(\"What would 2.5% improvement in side length mean?\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for n in [1, 2, 5, 10, 20, 50, 100, 200]:\n",
    "    row = scores_df[scores_df['n'] == n].iloc[0]\n",
    "    current_side = row['side']\n",
    "    current_score = row['score']\n",
    "    \n",
    "    # 2.5% improvement in side length\n",
    "    improved_side = current_side * 0.975\n",
    "    improved_score = improved_side**2 / n\n",
    "    score_improvement = current_score - improved_score\n",
    "    \n",
    "    print(f\"N={n:3d}: side {current_side:.4f} → {improved_side:.4f}, \"\n",
    "          f\"score {current_score:.6f} → {improved_score:.6f} (save {score_improvement:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe798179",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **The gap is 1.74 points** - This is a HUGE gap for this problem\n",
    "2. **Small N values dominate** - N=1-20 contribute disproportionately to score\n",
    "3. **Local optimization is exhausted** - Three experiments show diminishing returns\n",
    "\n",
    "## What the Top Solution Must Have\n",
    "\n",
    "To achieve 68.919154 from 70.659437, the top solution must have:\n",
    "- Either significantly better small N solutions (N=1-20)\n",
    "- Or fundamentally different packing patterns for large N\n",
    "- Or both\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Search for better pre-optimized CSVs** - The target is the #1 LB score, someone has achieved it\n",
    "2. **Focus on small N exhaustive search** - N=1-12 are small enough for near-exhaustive search\n",
    "3. **Try fundamentally different construction methods** - Not just optimizing existing solutions"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
