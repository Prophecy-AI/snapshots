# Santa 2025 - Christmas Tree Packing Optimization

## Problem Overview
This is a 2D packing optimization problem where we need to pack Christmas tree-shaped polygons (15-vertex shapes) into the smallest square bounding box for N=1 to N=200 trees.

**Scoring:** score = Σ(s_n² / n) for n=1 to 200, where s_n is the side length of the bounding box for n trees.
**Target:** 68.919154 (lower is better)
**Best known baseline:** ~70.66 (from pre-optimized CSVs)
**Gap to target:** ~1.75 points (2.5% improvement needed)

## CRITICAL INSIGHT FROM PREVIOUS EXPERIMENTS
Previous experiments (12+ attempts) tried:
- Simulated Annealing (SA) optimizers (sa_v1_parallel, tree_packer_v18, tree_packer_v21)
- Lattice construction for large N
- Backward propagation (removing trees from N+1 to get N)
- Ensemble of 30+ CSV sources
- Genetic algorithms
- bbox3 C++ optimizer with various parameters
- Rotation optimization (fix_direction)

**ALL FOUND NO IMPROVEMENTS beyond 70.659944!**

The pre-optimized CSVs are at a VERY TIGHT LOCAL OPTIMUM. Local search methods cannot escape this basin.

## Pre-optimized Files Available
- Best baseline: `/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv` (score: 70.676102)
- bbox3 binary: `/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bbox3`
- Multiple ensemble sources in `/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/`

## Tree Geometry (15 vertices)
```python
# Tree shape coordinates (center at origin, pointing up)
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
# Tree dimensions: height=1.0 (from -0.2 to 0.8), max width=0.7 at base
```

## RECOMMENDED APPROACHES (Priority Order)

### 1. **[HIGHEST PRIORITY]** Download Better Pre-optimized Solutions
The target score of 68.919154 suggests solutions exist that are ~1.75 points better than our baseline.
- Search Kaggle datasets for newer/better pre-optimized CSVs
- Look for solutions from top leaderboard teams
- Check discussion forums for shared solutions

**Commands:**
```bash
# Search for Santa 2025 datasets
kaggle datasets list -s "santa 2025" --sort-by votes
# Download promising datasets
kaggle datasets download -d <dataset-name>
```

### 2. **[HIGH PRIORITY]** Greedy Backtracking with Beam Search
Build solutions from scratch instead of optimizing pre-optimized CSVs:
- Start with N=1 (optimal at 45 degrees)
- For each N, try multiple tree placements with beam search
- Keep top K configurations (beam width)
- This explores different basins of attraction

**Implementation:**
```python
def greedy_beam_search(max_n=200, beam_width=10, max_depth=10):
    configs = {1: [optimal_single_tree()]}  # Start with N=1
    
    for n in range(2, max_n + 1):
        candidates = []
        for config in configs[n-1]:
            # Try adding tree at multiple positions/angles
            for angle in range(0, 360, 15):
                for attempt in range(max_depth):
                    new_config = try_add_tree(config, angle, attempt)
                    if new_config and not has_overlap(new_config):
                        candidates.append((score(new_config), new_config))
        
        # Keep top beam_width configurations
        candidates.sort(key=lambda x: x[0])
        configs[n] = [c[1] for c in candidates[:beam_width]]
    
    return configs
```

### 3. **[HIGH PRIORITY]** Random Initialization + Long Optimization
Generate completely NEW starting configurations instead of optimizing pre-optimized CSVs:
```python
def random_initialization(n):
    trees = []
    for i in range(n):
        # Random position in a reasonable area
        x = random.uniform(-5, 5)
        y = random.uniform(-5, 5)
        angle = random.uniform(0, 360)
        trees.append((x, y, angle))
    return trees

# Then apply SA optimization to the random starting point
```

### 4. **[MEDIUM PRIORITY]** Lattice-Based Construction for Large N
For N >= 58, try crystalline packing patterns:
- Start with 2 base trees in optimal configuration
- Translate in x and y to create grid pattern
- Grid configurations: N=72 (4x9), N=100 (5x10), N=144 (6x12), N=196 (7x14), N=200 (7x15)

### 5. **[MEDIUM PRIORITY]** Asymmetric Solutions
From discussion "Why the winning solutions will be Asymmetric":
- Symmetric solutions have been explored extensively
- Asymmetric configurations may have lower scores
- Try breaking symmetry in existing solutions

### 6. **[LOWER PRIORITY]** Extended bbox3 Optimization
If you have the bbox3 binary, try very long runs:
```bash
chmod +x bbox3
./bbox3 -n 100000 -r 256  # Much longer than previous attempts
```

## C++ Optimizer Template (from kernels)
The key techniques from top kernels:
1. **Fractional translation** with micro-steps (0.001 to 0.00001)
2. **Population-based optimization** keeping top 3 candidates
3. **Perturbation** to escape local optima
4. **OpenMP parallelization** for speed

## Validation Requirements
- No overlapping trees (Kaggle rejects overlapping submissions)
- All coordinates in [-100, 100]
- Values must be prefixed with 's' in submission CSV
- Use Shapely STRtree for efficient overlap checking

## Submission Format
```csv
id,x,y,deg
001_0,s0.0,s0.0,s45.0
002_0,s-0.0255,s0.0442,s0.0
002_1,s0.3688,s0.738,s180.0
...
```

## What NOT to Try
- Simple SA on pre-optimized CSV (already at local optimum)
- Short optimization runs (need hours, not minutes)
- Backward propagation alone (already tried, no improvements)
- Ensemble without new sources (santa-2025.csv dominates all N values)

## Key Insight
The gap of 1.75 points suggests the target is achievable, but requires either:
1. Finding better pre-optimized solutions from external sources
2. Using constructive approaches (beam search, random restart) to explore different basins
3. Very long optimization runs with perturbation to escape local optima

**DO NOT waste experiments on local search of pre-optimized CSVs - they are already at local optimum!**
