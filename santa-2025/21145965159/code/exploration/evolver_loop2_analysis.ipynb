{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e876f6ab",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Situation Assessment\n",
    "\n",
    "**Current Status:**\n",
    "- Best CV score: 70.676102 (from ensemble.csv)\n",
    "- Best LB score: N/A (first submission failed due to overlaps)\n",
    "- Target: 68.919154\n",
    "- Gap: 1.756948 points (~2.5% improvement needed)\n",
    "\n",
    "**Key Observations:**\n",
    "1. The pre-optimized solution is at a strong local optimum\n",
    "2. Multiple C++ optimizers (bbox3, tree_packer, backward propagation, fractional translation) found NO improvement\n",
    "3. All available pre-optimized solutions have the same best configurations for each N\n",
    "4. The first submission failed because best_ensemble.csv has overlaps detected by Kaggle\n",
    "\n",
    "**Critical Question:** How do we escape this local optimum to reach the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the current best solution\n",
    "base_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "df = pd.read_csv(f'{base_path}/ensemble.csv')\n",
    "\n",
    "# Parse values\n",
    "def parse_s_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "df['x_val'] = df['x'].apply(parse_s_value)\n",
    "df['y_val'] = df['y'].apply(parse_s_value)\n",
    "df['deg_val'] = df['deg'].apply(parse_s_value)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze score contribution by N\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "TREE_VERTICES = list(zip(TX, TY))\n",
    "\n",
    "def create_tree_polygon(x, y, deg):\n",
    "    poly = Polygon(TREE_VERTICES)\n",
    "    poly = affinity.rotate(poly, deg, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def get_bounding_box_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_coords = []\n",
    "    for poly in polygons:\n",
    "        all_coords.extend(list(poly.exterior.coords))\n",
    "    xs = [c[0] for c in all_coords]\n",
    "    ys = [c[1] for c in all_coords]\n",
    "    return max(max(xs) - min(xs), max(ys) - min(ys))\n",
    "\n",
    "# Calculate score per N\n",
    "scores_per_n = []\n",
    "for n in range(1, 201):\n",
    "    prefix = f'{n:03d}_'\n",
    "    group = df[df['id'].str.startswith(prefix)]\n",
    "    if len(group) == 0:\n",
    "        continue\n",
    "    \n",
    "    polygons = []\n",
    "    for _, row in group.iterrows():\n",
    "        poly = create_tree_polygon(row['x_val'], row['y_val'], row['deg_val'])\n",
    "        polygons.append(poly)\n",
    "    \n",
    "    side = get_bounding_box_side(polygons)\n",
    "    score = side**2 / n\n",
    "    scores_per_n.append({'n': n, 'side': side, 'score': score, 'trees': len(group)})\n",
    "\n",
    "scores_df = pd.DataFrame(scores_per_n)\n",
    "print(f\"Total score: {scores_df['score'].sum():.6f}\")\n",
    "print(f\"\\nTop 10 score contributors:\")\n",
    "print(scores_df.nlargest(10, 'score')[['n', 'side', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the score distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Score by N\n",
    "axes[0, 0].bar(scores_df['n'], scores_df['score'], alpha=0.7)\n",
    "axes[0, 0].set_xlabel('N')\n",
    "axes[0, 0].set_ylabel('Score contribution')\n",
    "axes[0, 0].set_title('Score contribution by N')\n",
    "\n",
    "# Side length by N\n",
    "axes[0, 1].scatter(scores_df['n'], scores_df['side'], alpha=0.5, s=10)\n",
    "axes[0, 1].set_xlabel('N')\n",
    "axes[0, 1].set_ylabel('Bounding box side')\n",
    "axes[0, 1].set_title('Bounding box side by N')\n",
    "\n",
    "# Cumulative score\n",
    "scores_df_sorted = scores_df.sort_values('score', ascending=False)\n",
    "scores_df_sorted['cumsum'] = scores_df_sorted['score'].cumsum()\n",
    "axes[1, 0].plot(range(1, len(scores_df_sorted)+1), scores_df_sorted['cumsum'])\n",
    "axes[1, 0].axhline(y=68.919154, color='r', linestyle='--', label='Target')\n",
    "axes[1, 0].set_xlabel('Number of N values (sorted by score)')\n",
    "axes[1, 0].set_ylabel('Cumulative score')\n",
    "axes[1, 0].set_title('Cumulative score (sorted by contribution)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Score vs theoretical minimum (side = sqrt(n) * tree_area)\n",
    "tree_area = Polygon(TREE_VERTICES).area\n",
    "scores_df['theoretical_min_side'] = np.sqrt(scores_df['n'] * tree_area)\n",
    "scores_df['efficiency'] = scores_df['theoretical_min_side'] / scores_df['side']\n",
    "axes[1, 1].scatter(scores_df['n'], scores_df['efficiency'], alpha=0.5, s=10)\n",
    "axes[1, 1].set_xlabel('N')\n",
    "axes[1, 1].set_ylabel('Packing efficiency')\n",
    "axes[1, 1].set_title('Packing efficiency by N (higher is better)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/code/exploration/score_analysis.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTree area: {tree_area:.6f}\")\n",
    "print(f\"Average efficiency: {scores_df['efficiency'].mean():.4f}\")\n",
    "print(f\"\\nLowest efficiency N values (most room for improvement):\")\n",
    "print(scores_df.nsmallest(10, 'efficiency')[['n', 'side', 'score', 'efficiency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca4d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how much improvement is needed\n",
    "target = 68.919154\n",
    "current = scores_df['score'].sum()\n",
    "gap = current - target\n",
    "\n",
    "print(f\"Current score: {current:.6f}\")\n",
    "print(f\"Target score: {target:.6f}\")\n",
    "print(f\"Gap to close: {gap:.6f}\")\n",
    "print(f\"Percentage improvement needed: {100 * gap / current:.2f}%\")\n",
    "\n",
    "# If we could improve efficiency uniformly\n",
    "print(f\"\\nIf we could improve all N by {100 * gap / current:.2f}%:\")\n",
    "print(f\"  New score would be: {current * (1 - gap/current):.6f}\")\n",
    "\n",
    "# What if we could match the best efficiency for all N?\n",
    "best_efficiency = scores_df['efficiency'].max()\n",
    "print(f\"\\nBest efficiency achieved: {best_efficiency:.4f} at N={scores_df.loc[scores_df['efficiency'].idxmax(), 'n']}\")\n",
    "print(f\"If all N had this efficiency, score would be: {sum(scores_df['theoretical_min_side']**2 / scores_df['n'] / best_efficiency**2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values have the most potential for improvement\n",
    "# based on their current efficiency vs best efficiency\n",
    "\n",
    "scores_df['potential_improvement'] = scores_df['score'] * (1 - (scores_df['efficiency'] / best_efficiency)**2)\n",
    "scores_df['potential_new_score'] = scores_df['score'] - scores_df['potential_improvement']\n",
    "\n",
    "print(\"N values with most improvement potential (if they matched best efficiency):\")\n",
    "print(scores_df.nlargest(15, 'potential_improvement')[['n', 'score', 'efficiency', 'potential_improvement']])\n",
    "\n",
    "print(f\"\\nTotal potential improvement: {scores_df['potential_improvement'].sum():.6f}\")\n",
    "print(f\"Potential new score: {scores_df['potential_new_score'].sum():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f61d5",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **The gap is ~1.76 points** - This is a significant improvement (~2.5%)\n",
    "\n",
    "2. **Small N values contribute most to the score** - N=1,2,3 alone contribute ~1.5 points\n",
    "\n",
    "3. **The pre-optimized solution is at a strong local optimum** - Multiple optimizers found no improvement\n",
    "\n",
    "4. **Different N values have different packing efficiencies** - Some N values are packed more efficiently than others\n",
    "\n",
    "## Strategic Options\n",
    "\n",
    "### Option 1: Submit the overlap-free baseline first\n",
    "- Use ensemble.csv which is verified overlap-free\n",
    "- This establishes a baseline LB score\n",
    "- **Priority: HIGHEST** - We need a valid submission!\n",
    "\n",
    "### Option 2: Focus on low-efficiency N values\n",
    "- Identify N values with worst packing efficiency\n",
    "- Run longer optimization specifically on these N values\n",
    "- Use different starting configurations\n",
    "\n",
    "### Option 3: Try fundamentally different approaches\n",
    "- Genetic algorithms with population diversity\n",
    "- Different initial placements (not from pre-optimized)\n",
    "- Constructive heuristics from scratch\n",
    "\n",
    "### Option 4: Longer optimization runs\n",
    "- The bbox3 runner kernel uses 3+ hours\n",
    "- Our runs were only minutes\n",
    "- Longer runs might find improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the submission file currently contains\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "if os.path.exists(submission_path):\n",
    "    sub_df = pd.read_csv(submission_path)\n",
    "    print(f\"Submission file has {len(sub_df)} rows\")\n",
    "    print(sub_df.head())\n",
    "    \n",
    "    # Verify it matches ensemble.csv\n",
    "    ensemble_df = pd.read_csv(f'{base_path}/ensemble.csv')\n",
    "    if sub_df['id'].equals(ensemble_df['id']) and sub_df['x'].equals(ensemble_df['x']):\n",
    "        print(\"\\n✓ Submission matches ensemble.csv\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Submission differs from ensemble.csv\")\n",
    "else:\n",
    "    print(\"No submission file found\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
