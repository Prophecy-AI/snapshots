{
  "query": "What are the most effective techniques for escaping local optima in 2D polygon packing optimization problems when simulated annealing gets stuck?",
  "results": [
    {
      "title": "ANSWER",
      "text": "Escaping local optima in 2\u2011D polygon\u2011packing with simulated annealing (SA) usually relies on making the search more flexible and on avoiding hard\u2011coded penalties that can trap the algorithm in a narrow region of the solution space.  A common trick is to replace external penalty functions with a **Minkowski\u2011sum based collision\u2011free region generator**; by sampling only feasible placements the algorithm can move through otherwise forbidden configurations and more easily jump out of a dead\u2011end ([abcm.org.br](https://abcm.org.br/symposium-series/SSM_Vol2/Section_XII_Emerging_Technologies_and_AI_Applications/SSM2_XII_02.pdf)).  Another powerful idea is to let the **neighbourhood size adapt during the run**.  The \u201ccrystallization factor\u2019\u2019 proposed for rotational irregular packing adjusts the step length with positive feedback when a move is accepted (making subsequent moves larger) and with negative feedback when a move is rejected (making them smaller).  This adaptive neighbourhood, together with a geometrical cooling schedule (often called *simulated quenching*), increases the probability of accepting uphill moves that can carry the search out of a local basin ([semanticscholar.org](https://pdfs.semanticscholar.org/6509/3a9d2d6b9b38ac2c9a2da79c3905b76ef008.pdf);\u202f[sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S147466701535549X)).  \n\nIn practice, researchers complement these mechanisms with **temperature\u2011reheating or multi\u2011start strategies**: when the acceptance rate falls below a threshold the temperature is temporarily raised (or the algorithm is restarted from a different seed) to inject new energy into the system.  Hybridising SA with other meta\u2011heuristics\u2014e.g., tabu\u2011search memory, genetic\u2011algorithm crossover, or local\u2011search refinements\u2014provides additional pathways out of plateaus.  Because SA does not depend on gradient information, it is theoretically immune to first\u2011order local minima, but the above practical enhancements are essential for the highly non\u2011convex, combinatorial landscape of 2\u2011D polygon packing ([mlpress.org](https://proceedings.mlr.press/v40/Belloni15.html)).  \n\nTogether, adaptive neighbourhood control, feasible\u2011region sampling via Minkowski sums, dynamic reheating/restarts, and hybrid meta\u2011heuristic combinations constitute the most effective toolbox for overcoming SA\u2019s stagnation in 2\u2011D polygon\u2011packing problems.",
      "url": ""
    },
    {
      "title": "[PDF] Applying the Simulated Annealing to the Problem of Positioning ...",
      "text": "Procedings of COBEM 2005\nCopyright \u00b0c 2005 by ABCM\n18th International Congress of Mechanical Engineering\nNovember 6-11, 2005, Ouro Preto, MG\nApplying the Simulated Annealing to the Problem of Positioning Rotational\nNon Convex Polygons\nMartins, T. C\nDepartment of Mechatronics and Mechanical Systems Engineering, EPUSP\nthiago.martins@poli.usp.br\nTsuzuki, M. S. G.\nDepartment of Mechatronics and Mechanical Systems Engineering, EPUSP\nmtsuzuki@usp.br\nThis work deals with the problem of minimize the waste of space that occurs on a placement of a set of bi-dimensional\npolygons inside a bi-dimensional container. This problem is approached with an heuristic based on Simulated Annealing,\nwhich is inspired on the physico-chemical process that take place during the recrystalisation of a metal. Traditional \u201cex\u0002ternal penalisation\u201d techniques are avoided through the application of the Minkowski sum algorithm, that determinates\ncollision-free areas for the set of polygons. That gives to the proposed process a more universal character, as external\npenalisations are based on empiric parameters of great influence on the optimisation performance. The proposed process\nis suited for non-convex polygons and containers, and can be easily adapted for related problems, such as container size\nminimisation.\n1. Introduction to placement problems\nThe polygonal placement problems arises in the industry whenever one must place multiple objects inside a container\nso that there is no collision between the objects, while either minimizing the size of the container either maximizing the\nvolume occupied by the objects. For instance, on the shoe industry, a maximum number of shoe parts must be placed\nover a leather piece. Another instance of the problem occurs in the textile industry, where cloth parts must be placed over\nthe smallest possible sheet of tissue. Those problems are also closely related to robot motion planning, where a trajectory\nfor an object (the robot) that leads it from one point to another must be found while avoiding collisions with pre-placed\nobstacles. Those placement problems are also known by the names of nesting, containment, layout, packing and cutting\nstock (Downsland et al., 1995). Surveys of placement problems can be found at (Lodi et al., 2002; Downsland et al., 1992;\nDownsland et al., 1995). Computational approaches often focus on purely translational versions of the problem, and the\nmajor part of them approach problems whose polygons are constrained to rectangular shapes.\n2. This work\nAs seen on the section 1, due to their complexity, irregular placement problems are the least computationally ap\u0002proached, despite their great relevancy for the industry. This is the motivation for this work, which deals with the bidi\u0002mentional placement on its most unconstrained form, the translational and rotational placement of heterogeneous irregular\nforms (both nonvex and non convex) on irregular containers (also both convex and non convex).\n2.1 Problem statement\nThe problem can be defined as the problem of, given a container (a polygon, convex or non-convex) and a polygon\nset, to determinate a subset of polygons and the transformations (translations and rotations) that, when applied to their\nrespective polygons, place them without collisions inside the container while minimising the wasted space (see Figure 1).\nDefinition 1 There is a collision between two polygons when their intersection is a non-empty set.\nAs mentioned, it can be show that even restricted versions of this problem (for instance, limiting the polygon shape to\nrectangles only) are NP-Complete, which means it is believed they cannot be algorithmically solved for practical instances\n(Fowler et al. 1981). This motivates an heuristic approach, that while is not guaranteed to find the optimal solution, can,\nin a reasonable amount of time, find a good solution. Probabilistic optimisation heuristics follow this pattern: while a\nstipulated stop criteria is not satisfied, at each step the function to be optimised is evaluated at a set of points and a set of\nrules is applied to determinate the set of points to be evaluated at the next step. The process converges to a solution of the\nproblem.\nFor our problem, the space of valid solutions is the set of transformations (\u2206x, \u2206y, \u2206\u03b8) to be applied to the polygons\nrestricted to the condition of no-collisions between them. The space delimited by those restrictions is very complex (and\nmutable). Usually, when confronted to such complex spaces, probabilistic heuristics \u201crelax\u201d the original constrains of\nProcedings of COBEM 2005\nCopyright \u00b0c 2005 by ABCM\n18th International Congress of Mechanical Engineering\nNovember 6-11, 2005, Ouro Preto, MG\nPolygon set Container\nSolution\nFigure 1. A placement problem and its optimal solution.\nthe problem, allowing the search to go through points outside the space of valid solutions and applying penalisations to\ntheir cost. This technique is known as external penalisation. While at first this technique greatly simplifies the problem,\nit also introduces and additional problem: How to determinate the exact amount of penalisation to be applied to external\npoints? Another drawback of external penalisation is that it can lead the optimisation process to non-valid solutions. This\ncan be seen on the work of Heckman (1995), where problems very similar to those studied here are approached with\nsimulated annealing. On his work. Heckman points that his optimisation process can produce invalid solutions (solutions\nwith collisions between polygons), requiring a post-processing step of the obtained data.\nThe approach adopted here avoids the pitfalls of external penalisation by the continuous mapping (meaning it is\nupdated at each step of the process) of the complex space of valid solution into a simplified space. Although this additional\nmapping step increases the complexity of the process, it confers to the process a more universal character, as there is one\nless empiric parameter to be defined. Actually, the proposed process does not explores the whole space of possible\nsolutions, focusing instead on a reduced space, that contains at least one optimal solution. This reduces the search through\nirrelevant points and enhances the performance of the process.\n2.2 Simulated annealing\nSimulated Annealing (Kirkpatrick et al., 1983) is the probabilistic meta-heuristic adopted on this work. It was chose\ndue to its capacity of \u201cescape\u201d from local minima (which are very frequent on this problem). It is also worth of mention\nthat the process of recrystalisation, the inspiration for simulated annealing, is a natural instance of a placement problem.\n2.2.1 Description\nSimulated annealing comes from the Metropolis algorithm, a simulation of the recrystalisation of atoms on a metal\nduring its annealing (gradual and controlled cooling). During annealing, atoms migrate naturally to configurations that\nminimize the system total energy, even if during this migration the system must pass through high-energy configurations.\nThe observation of this behavior suggests the application of the simulation of such process to combinatorial optimisation\nproblems.\nSimulated annealing is a hill-climbing local exploration1 optimisation heuristic, which means it can skip local minima\nby allowing the exploration of the space in directions that lead to an increase on the cost function. It sequentially applies\nrandom modifications on the evaluation point of the cost function. If a modification yields a point of smaller cost,\nit is automatically kept. Otherwise, the modification also can be kept with a probability obtained form the Boltzman\ndistribution (1).\nP(\u2206E) = e\n\u2212 \u2206E\nkt (1)\nwhere P(\u2206E) is the probability of the optimisation process to keep a modification that incurred on an increase \u2206E of\nthe cost function, k is a parameter of the process (analogous to the Stefan-Boltzman constant) and t is the instantaneous\n\u201ctemperature\u201d of the process. This temperature is defined by a cooling schedul...",
      "url": "https://abcm.org.br/symposium-series/SSM_Vol2/Section_XII_Emerging_Technologies_and_AI_Applications/SSM2_XII_02.pdf"
    },
    {
      "title": "Escaping the Local Minima via Simulated Annealing: Optimization of ...",
      "text": "\\[ [edit](https://github.com/mlresearch/v40/edit/gh-pages/_posts/2015-06-26-Belloni15.md)\\]\n\n# Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions\n\nAlexandre Belloni,\u00a0Tengyuan Liang,\u00a0Hariharan Narayanan,\u00a0Alexander Rakhlin\n\n_Proceedings of The 28th Conference on Learning Theory_,\u00a0PMLR 40:240-265,\u00a02015.\n\n#### Abstract\n\nWe consider the problem of optimizing an approximately convex function over a bounded convex set in \\\\mathbbR^n using only function evaluations. The problem is reduced to sampling from an \\\\emphapproximately log-concave distribution using the Hit-and-Run method, which is shown to have the same \\\\mathcalO^\\* complexity as sampling from log-concave distributions. In addition to extend the analysis for log-concave distributions to approximate log-concave distributions, the implementation of the 1-dimensional sampler of the Hit-and-Run walk requires new methods and analysis. The algorithm then is based on simulated annealing which does not relies on first order conditions which makes it essentially immune to local minima. We then apply the method to different motivating problems. In the context of zeroth order stochastic convex optimization, the proposed method produces an \u03b5-minimizer after \\\\mathcalO^\\*(n^7.5\u03b5^-2) noisy function evaluations by inducing a \\\\mathcalO(\u03b5/n)-approximately log concave distribution. We also consider in detail the case when the \u201camount of non-convexity\u201d decays towards the optimum of the function. Other applications of the method discussed in this work include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.\n\n#### Cite this Paper\n\nBibTeX\n\n`@InProceedings{pmlr-v40-Belloni15,\ntitle = {Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions},\nauthor = {Belloni, Alexandre and Liang, Tengyuan and Narayanan, Hariharan and Rakhlin, Alexander},\nbooktitle = {Proceedings of The 28th Conference on Learning Theory},\npages = {240--265},\nyear = {2015},\neditor = {Gr\u00fcnwald, Peter and Hazan, Elad and Kale, Satyen},\nvolume = {40},\nseries = {Proceedings of Machine Learning Research},\naddress = {Paris, France},\nmonth = {03--06 Jul},\npublisher = {PMLR},\npdf = {http://proceedings.mlr.press/v40/Belloni15.pdf},\nurl = {https://proceedings.mlr.press/v40/Belloni15.html},\nabstract = {We consider the problem of optimizing an approximately convex function over a bounded convex set in \\mathbbR^n using only function evaluations. The problem is reduced to sampling from an \\emphapproximately log-concave distribution using the Hit-and-Run method, which is shown to have the same \\mathcalO^* complexity as sampling from log-concave distributions. In addition to extend the analysis for log-concave distributions to approximate log-concave distributions, the implementation of the 1-dimensional sampler of the Hit-and-Run walk requires new methods and analysis. The algorithm then is based on simulated annealing which does not relies on first order conditions which makes it essentially immune to local minima. We then apply the method to different motivating problems. In the context of zeroth order stochastic convex optimization, the proposed method produces an \u03b5-minimizer after \\mathcalO^*(n^7.5\u03b5^-2) noisy function evaluations by inducing a \\mathcalO(\u03b5/n)-approximately log concave distribution. We also consider in detail the case when the \u201camount of non-convexity\u201d decays towards the optimum of the function. Other applications of the method discussed in this work include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.}\n}`\n\nCopy to ClipboardDownload\n\nEndnote\n\n`%0 Conference Paper\n%T Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions\n%A Alexandre Belloni\n%A Tengyuan Liang\n%A Hariharan Narayanan\n%A Alexander Rakhlin\n%B Proceedings of The 28th Conference on Learning Theory\n%C Proceedings of Machine Learning Research\n%D 2015\n%E Peter Gr\u00fcnwald\n%E Elad Hazan\n%E Satyen Kale\n%F pmlr-v40-Belloni15\n%I PMLR\n%P 240--265\n%U https://proceedings.mlr.press/v40/Belloni15.html\n%V 40\n%X We consider the problem of optimizing an approximately convex function over a bounded convex set in \\mathbbR^n using only function evaluations. The problem is reduced to sampling from an \\emphapproximately log-concave distribution using the Hit-and-Run method, which is shown to have the same \\mathcalO^* complexity as sampling from log-concave distributions. In addition to extend the analysis for log-concave distributions to approximate log-concave distributions, the implementation of the 1-dimensional sampler of the Hit-and-Run walk requires new methods and analysis. The algorithm then is based on simulated annealing which does not relies on first order conditions which makes it essentially immune to local minima. We then apply the method to different motivating problems. In the context of zeroth order stochastic convex optimization, the proposed method produces an \u03b5-minimizer after \\mathcalO^*(n^7.5\u03b5^-2) noisy function evaluations by inducing a \\mathcalO(\u03b5/n)-approximately log concave distribution. We also consider in detail the case when the \u201camount of non-convexity\u201d decays towards the optimum of the function. Other applications of the method discussed in this work include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.`\n\nCopy to ClipboardDownload\n\nRIS\n\n`TY - CPAPER\nTI - Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions\nAU - Alexandre Belloni\nAU - Tengyuan Liang\nAU - Hariharan Narayanan\nAU - Alexander Rakhlin\nBT - Proceedings of The 28th Conference on Learning Theory\nDA - 2015/06/26\nED - Peter Gr\u00fcnwald\nED - Elad Hazan\nED - Satyen Kale\nID - pmlr-v40-Belloni15\nPB - PMLR\nDP - Proceedings of Machine Learning Research\nVL - 40\nSP - 240\nEP - 265\nL1 - http://proceedings.mlr.press/v40/Belloni15.pdf\nUR - https://proceedings.mlr.press/v40/Belloni15.html\nAB - We consider the problem of optimizing an approximately convex function over a bounded convex set in \\mathbbR^n using only function evaluations. The problem is reduced to sampling from an \\emphapproximately log-concave distribution using the Hit-and-Run method, which is shown to have the same \\mathcalO^* complexity as sampling from log-concave distributions. In addition to extend the analysis for log-concave distributions to approximate log-concave distributions, the implementation of the 1-dimensional sampler of the Hit-and-Run walk requires new methods and analysis. The algorithm then is based on simulated annealing which does not relies on first order conditions which makes it essentially immune to local minima. We then apply the method to different motivating problems. In the context of zeroth order stochastic convex optimization, the proposed method produces an \u03b5-minimizer after \\mathcalO^*(n^7.5\u03b5^-2) noisy function evaluations by inducing a \\mathcalO(\u03b5/n)-approximately log concave distribution. We also consider in detail the case when the \u201camount of non-convexity\u201d decays towards the optimum of the function. Other applications of the method discussed in this work include private computation of empirical risk minimizers, two-stage stochastic programming, and approximate dynamic programming for online learning.\nER -`\n\nCopy to ClipboardDownload\n\nAPA\n\n`Belloni, A., Liang, T., Narayanan, H. & Rakhlin, A.. (2015). Escaping the Local Minima via Simulated Annealing: Optimization of Approximately Convex Functions. Proceedings of The 28th Conference on Learning Theory, in Proceedings of Machine Learning Research 40:240-265 Available from https://proceedings.mlr.press/v40/Belloni15.html.`\n\nCopy to ClipboardDownload\n\n#### Related Material\n\n- [Download PDF](http://proceedings.mlr.press/v40/Belloni15.pdf)",
      "url": "https://proceedings.mlr.press/v40/Belloni15.html"
    },
    {
      "title": "Adaptive Neighborhood Heuristics for Simulated Annealing over Continuous Variables",
      "text": "Chapter 0\nAdaptive Neighborhood Heuristics for Simulated\nAnnealing over Continuous Variables\nT.C. Martins, A.K.Sato and M.S.G. Tsuzuki\nAdditional information is available at the end of the chapter\nhttp://dx.doi.org/10.5772/50302\n1. Introduction\nSimulated annealing has been applied to a wide range of problems: combinatorial and\ncontinuous optimizations. This work approaches a new class of problems in which the\nobjective function is discrete but the parameters are continuous. This type of problem arises in\nrotational irregular packing problems. It is necessary to place multiple items inside a container\nsuch that there is no collision between the items, while minimizing the items occupied area.\nA feedback is proposed to control the next candidate probability distribution, in order to\nincrease the number of accepted solutions. The probability distribution is controlled by\nthe so called crystallization factor. The proposed algorithm modifies only one parameter\nat a time. If the new configuration is accepted then a positive feedback is executed to\nresult in larger modifications. Different types of positive feedbacks are studied herein. If\nthe new configuration is rejected, then a negative feedback is executed to result in smaller\nmodifications. For each non-placed item, a limited depth binary search is performed to find a\nscale factor that, when applied to the item, allows it to be fitted in the layout. The proposed\nalgorithm was used to solve two different rotational puzzles. A geometrical cooling schedule\nis used. Consequently, the proposed algorithm can be classified as simulated quenching.\nThis work is structured as follows. Section 2 presents some simulated annealing and\nsimulated quenching key concepts. In section 3 the objective function with discrete values and\ncontinuous parameters is explained. Section 4 explains the proposed adaptive neighborhood\nbased on the crystallization factor. Section 5 explains the computational experiments and\nsection 6 presents the results. Finally, section 7 rounds up the work with the conclusions.\n2. Background\nSimulated annealing is a probabilistic meta-heuristic with a capacity of escape from local\nminima. It came from the Metropolis algorithm and it was originally proposed in the area\nof combinatorial optimization [9], that is, when the objective function is defined in a discrete\n\u00a92012 Tsuzuki et al., licensee InTech. This is an open access chapter distributed under the terms of the\nCreative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original work is properly\ncited.\nChapter 1\n2 Will-be-set-by-IN-TECH\ndomain. The simulated annealing was modified in order to apply to the optimization of\nmultimodal functions defined on continuous domain [4]. The choices of the cooling schedule\nand of the next candidate distribution are the most important decisions in the definition of a\nsimulated annealing algorithm [13]. The next candidate distribution for continuous variables\nis discussed herein.\nIn the discrete domain, such as the traveling salesman and computer circuit design problems,\nthe parameters must have discrete values; the next point candidate xk+1 corresponds to a\npermutation in the list of cities to be visited, interchanges of circuit elements, or other discrete\noperation. In the continuous application of simulated annealing a new choice of the next point\ncandidate must be executed. Bohachevsky et al. [1] proposed that the next candidate xk+1 can\nbe obtained by first generating a random direction vector u, with |u| = 1, then multiplying it\nby a fixed step size \u0394r, and summing the resulting vector to the current candidate point xk.\nBrooks & Verdini [2] showed that the selection of \u0394r is a critical choice. They observed that an\nappropriate choice of this parameter is strictly dependent on the objective function F(x), and\nthe appropriate value can be determined by presampling the objective function.\nThe directions in [1] are randomly sampled from the uniform distribution and the step size is\nthe same in each direction. In this way, the feasible region is explored in an isotropic way and\nthe objective function is assumed to behave in the same way in each direction. But this is not\noften the case. The step size to define the next candidate point xk+1 should not be equal for all\nthe directions, but different directions should have different step sizes; i.e. the space should\nbe searched in an anisotropic way. Corana et al. [4] explored the concept of anisotropic search;\nthey proposed a self-tuning simulated annealing algorithm in which the step size is configured\nin order to maintain a number of accepted solutions. At each iteration k, a single variable of\nxk is modified in order to obtain a new candidate point xk+1, and iterations are subdivided\ninto cycles of n iterations during which each variable is modified. The new candidate point is\nobtained from xk in the following form xk+1 = xk + v \u00b7 \u0394ri \u00b7 ei. Where v is a uniform random\nnumber in [\u22121, 1], and \u0394ri is the step size along direction ei of the i-th axis. The anisotropy is\nobtained by choosing different values of \u0394ri for all the directions. The step size is kept fixed\nfor a certain number of cycles of variables, and the fraction of accepted moves in direction ei\nis calculated. If the fraction of accepted moves generated in the same direction is below 0.4,\nthen the step size \u0394ri along ei is decreased. It is assumed that the algorithm is using too large\nsteps along ei thus causing many moves to be rejected. If the fraction is between 0.4 and 0.6\nthe step size is left unchanged. If the fraction is above 0.6 then \u0394ri is increased. It is assumed\nthat the step size is too small thus causing many moves to be accepted.\nThis procedure may not be the best possible to process the different behavior of the objective\nfunction along different axes. Ingber [7] proposed that the random variable should follow a\nCauchy distribution with different sensitivities at different temperatures. The maximum step\nsize is kept constant during the algorithm and it allows escaping from local minima even at\nlow temperatures. The parameter space can have completely different sensitivities for each\ndimension, therefore the use of different temperatures for each dimension is suggested. This\nmethod is often referred to as very fast simulated re-annealing (VFSR) or adaptive simulated\nannealing (ASA). The sensitivity of each parameter is given by the partial derivative of the\nfunction with relation to the i-th dimension [3].\n4 Simulated Annealing \u2013 Advances, Applications and Hybridizations\nAdaptive Neighborhood Heuristics for Simulated Annealing over Continuous Variables 3\n3. Integer objective function with float parameters\nIrregular packing problems arise in the industry whenever one must place multiple items\ninside a container such that there is no collision between the items, while minimizing the\narea occupied by the items. It can be shown that even restricted versions of this problem (for\ninstance, limiting the polygon shape to rectangles only) are NP complete, which means that\nall algorithms currently known for optimal solutions require a number of computational steps\nthat grow exponentially with the problem size rather than according to a polynomial function\n[5]. Usually probabilistic heuristics relax the original constraints of the problem, allowing the\nsearch to go through points outside the space of valid solutions and applying penalization to\ntheir cost. This technique is known as external penalization. The most adopted penalization\nheuristic for external solutions of packing problems is to apply a penalization based on\nthe overlapping area of colliding items. While this heuristic leads to very computationally\nefficient iterations of the optimization process, the layout with objective function in minimum\nvalue may have overlapped items [6].\nFig. 1 shows an example in which the c...",
      "url": "https://pdfs.semanticscholar.org/6509/3a9d2d6b9b38ac2c9a2da79c3905b76ef008.pdf"
    },
    {
      "title": "Simulated Annealing with Adaptive Neighborhood Applied to the Placement over Containers with Fixed Dimensions",
      "text": "[Skip to main content](https://www.sciencedirect.com/science/article/pii/S147466701535549X#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/pii/S147466701535549X#screen-reader-main-title)\n\n- [View\u00a0**PDF**](https://www.sciencedirect.com/science/article/pii/S147466701535549X/pdf?md5=7bca88c33d2daef044751913b4156e2b&pid=1-s2.0-S147466701535549X-main.pdf)\n- Download full issue\n\nSearch ScienceDirect\n\n## Outline\n\n1. [Abstract](https://www.sciencedirect.com/science/article/pii/S147466701535549X#ceab10)\n2. [Keywords](https://www.sciencedirect.com/science/article/pii/S147466701535549X#cekeyws10)\n3. [References](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bibl10)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/558f6b3505d331efa27a89a25731aa712b0662a4/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/ifac-proceedings-volumes)\n\n## [IFAC Proceedings Volumes](https://www.sciencedirect.com/journal/ifac-proceedings-volumes)\n\n[Volume 41, Issue 3](https://www.sciencedirect.com/journal/ifac-proceedings-volumes/vol/41/issue/3), 2008, Pages 106-111\n\n[![IFAC Proceedings Volumes](https://ars.els-cdn.com/content/image/1-s2.0-S1474667015X60770-cov150h.gif)](https://www.sciencedirect.com/journal/ifac-proceedings-volumes/vol/41/issue/3)\n\n# Simulated Annealing with Adaptive Neighborhood Applied to the Placement over Containers with Fixed Dimensions\n\nAuthor links open overlay panelThiagode Castro Martins\\*, Marcosde Sales Guerra Tsuzuki\\*\n\nShow more\n\nOutline\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.3182/20081205-2-CL-4009.00020](https://doi.org/10.3182/20081205-2-CL-4009.00020) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S147466701535549X&orderBeanReset=true)\n\n## Abstract\n\nThis work deals with the problem of minimizing the waste of space that occurs on a rotational placement of a set of irregular bi-dimensional items inside a bi-dimensional container. This problem is approached with an heuristic based on Simulated Annealing (SA) with adaptive neighborhood. Traditional \u201cexternal penalization\u201d techniques are avoided through the application of the no\u2013fit polygon, that determinates the collision-free area for each polygon before its placement. The SA controls continuous and discrete parameters. The rotation applied and the translation of the polygon are continuous parameters, and the sequence of placement is represented as a set of discrete parameters. For each non\u2013placed item, a limited depth binary search is performed to find a scale factor that when applied to the item, would allow it to be fitted in the container.\n\n- [Previous article in issue](https://www.sciencedirect.com/science/article/pii/S1474667015355488)\n- [Next article in issue](https://www.sciencedirect.com/science/article/pii/S1474667015355506)\n\n## Keywords\n\nSimulated Annealing\n\nPlacement Problems\n\nOptimization\n\nProbabilistic Heuristics\n\n[View PDF](https://www.sciencedirect.com/science/article/pii/S147466701535549X/pdf?md5=7bca88c33d2daef044751913b4156e2b&pid=1-s2.0-S147466701535549X-main.pdf)\n\nSpecial issue articlesRecommended articles\n\n## References\n\n01. [Art, 1966](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib1)\n    Art, R.C. (1966). An approach to the two-dimensional irregular cutting stock problem. Technical report, IBM Cambridge Scientific Centre.\n\n    [Google Scholar](https://scholar.google.com/scholar?q=Art%2C%20R.C.%20(1966).%20An%20approach%20to%20the%20two-dimensional%20irregular%20cutting%20stock%20problem.%20Technical%20report%2C%20IBM%20Cambridge%20Scientific%20Centre.)\n\n02. [Bohachevsky et al., 1986](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib2)\n\n\n    I.O. Bohachevsky, M.E. Johnson, M.L. Stein\n\n\n\n    Generalized simulated annealing for function optimization\n\n\n\n    Technometrics, 28 (1986), pp. 209-217\n\n\n\n\n\n    [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0022758683&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Generalized%20simulated%20annealing%20for%20function%20optimization&publication_year=1986&author=I.O.%20Bohachevsky&author=M.E.%20Johnson&author=M.L.%20Stein)\n\n03. [Burke et al., 2007](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib3)\n\n\n    E.K. Burke, R.S.R. Hellier, G. Kendall, G. Whitwell\n\n\n\n    Complete and robust no-fit polygon generation for the irregular stock cutting problem\n\n\n\n    European Journal of Operational Research, 179 (2007), pp. 27-49\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221706001639/pdfft?md5=262c7a09c1162709123beee32f0b72e8&pid=1-s2.0-S0377221706001639-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0377221706001639) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-33751335925&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Complete%20and%20robust%20no-fit%20polygon%20generation%20for%20the%20irregular%20stock%20cutting%20problem&publication_year=2007&author=E.K.%20Burke&author=R.S.R.%20Hellier&author=G.%20Kendall&author=G.%20Whitwell)\n\n04. [Corana et al., 1987](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib4)\n\n\n    A. Corana, M. Marchesi, C. Martini, S. Ridella\n\n\n\n    Minimizing multimodal functions of continuous variables with the simulated annealing algorithm\n\n\n\n    ACM Transactions on Mathematical Software, 13 (1987), pp. 262-280\n\n\n\n\n\n    [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0023416976&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Minimizing%20multimodal%20functions%20of%20continuous%20variables%20with%20the%20simulated%20annealing%20algorithm&publication_year=1987&author=A.%20Corana&author=M.%20Marchesi&author=C.%20Martini&author=S.%20Ridella)\n\n05. [Dowsland et al., 2002](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib5)\n\n\n    K.A. Dowsland, S. Vaid, B.W. Dowsland\n\n\n\n    An algorithm for polygon placement using a bottom-left strategy\n\n\n\n    European Journal of Operational Research, 141 (2002), pp. 371-381\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221702001315/pdfft?md5=68f3c9993c2c281df7f1bd84d209f68b&pid=1-s2.0-S0377221702001315-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0377221702001315) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0036722394&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=An%20algorithm%20for%20polygon%20placement%20using%20a%20bottom-left%20strategy&publication_year=2002&author=K.A.%20Dowsland&author=S.%20Vaid&author=B.W.%20Dowsland)\n\n06. [Dyckhoff, 1990](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib6)\n\n\n    H. Dyckhoff\n\n\n\n    A typology of cutting and packing problems\n\n\n\n    European Journal of Operational Research, 44 (1990), pp. 145-159\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/037722179090350K/pdf?md5=24cb0198949a826fc64bf7a98f4974f3&pid=1-s2.0-037722179090350K-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/037722179090350K) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0025210672&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20typology%20of%20cutting%20and%20packing%20problems&publication_year=1990&author=H.%20Dyckhoff)\n\n07. [Gomes and Oliveira, 2006](https://www.sciencedirect.com/science/article/pii/S147466701535549X#bbib7)\n\n\n    A.M. Gomes, J.F. Oliveira\n\n\n\n    Solving irregular strip packing problems by hybridising simulated annealing and linear programming\n\n\n\n    European Journal of Operational Research, 171 (2006), pp. 811-829\n\n    [View PDF](https://www.sciencedirect.com/science/article/pii/S0377221...",
      "url": "https://www.sciencedirect.com/science/article/pii/S147466701535549X"
    },
    {
      "title": "[PDF] Spatial simulated annealing pdfkeywords=Computational statistics",
      "text": "Applied geostatistics\nExercise: Spatial simulated annealing\nD G Rossiter\nCornell University, Section of Soil & Crop Sciences\nVandita Srivastava\nIndian Institute of Remote Sensing, Dehradun\nAugust 23, 2021\nContents\n1 Introduction 1\n2 SSA optimization for Ordinary Kriging: development 3\n2.1 Define the study area . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Model of spatial dependence . . . . . . . . . . . . . . . . . . . . 6\n2.3 Fitness function . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.4 Setup for SSA . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.5 The main SSA loop: one time . . . . . . . . . . . . . . . . . . . 13\n2.5.1 Maximum distance to move a point . . . . . . . . . . . 13\n2.5.2 Moving one point . . . . . . . . . . . . . . . . . . . . . . 16\n2.5.3 Plotting a changed scheme . . . . . . . . . . . . . . . . 17\n2.5.4 Accepting or rejecting the new scheme . . . . . . . . . . 18\n2.6 The main SSA loop: iterations . . . . . . . . . . . . . . . . . . 18\n2.7 Showing the evolution of the scheme . . . . . . . . . . . . . . . 19\n2.8 Answers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3 SSA optimization for Ordinary Kriging: application 24\n3.1 A function for SSA . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.1.1 Saving the function to a file for later execution . . . . . 28\n3.2 Initial sampling scheme . . . . . . . . . . . . . . . . . . . . . . . 28\n3.3 Objective function: minimize the mean kriging variance . . . . 30\nVersion 2.0 Copyright \u00a9 2009 ITC; 2010, 2013 University of Twente, Fac\u0002ulty ITC; 2021 D. G. Rossiter All rights reserved. Reproduction and dissem\u0002ination of the work as a whole (not parts) freely permitted if this original\ncopyright notice is included. Sale or placement on a web site where payment\nmust be made to access this document is strictly prohibited. To adapt or\ntranslate please contact the author (d.g.rossiter@cornell.edu).\n3.4 Objective function: minimize the maximum kriging variance . 33\n3.5 Optimizing from another starting configuration . . . . . . . . . 35\n3.6 Answers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4 Sampling an irregularly-shaped area 40\n4.1 Answers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5 SSA optimization for Kriging with External Drift 50\n6 SSA optimizing by variogram matching 50\n6.1 Indicator variogram, no bin numbers . . . . . . . . . . . . . . . 55\n6.2 Indicator variogram, bin numbers . . . . . . . . . . . . . . . . . 60\n6.3 Sampling optimization in a simulated field . . . . . . . . . . . . 63\n6.4 Answers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n7 Challenges 74\nReferences 76\nIndex of R concepts 77\nii\n1 Introduction\nA typical problem in sampling is how to optimally place a limited number of\nobservations in a study area in order to extract the maximum information\nat minimum cost. We consider here the information to be a map over some\nstudy area, made by kriging from the sample points.\nThe first question is what do we mean by \u201coptimal\u201d? There must be an\nobjective criterion that can be computed for a sampling scheme, which is to\nbe minimized or maximized.\nOne obvious criterion is to minimize costs:\n\u0088 the fewest samples required to reach a given precision;\n\u0088 the minimum travel and set-up cost.\nThese are outside the scope of the present discussion; here we assume the\nsample size is fixed and logistics are not a problem. For example, if the task\nis to sample a small polluted site where travel costs between observations\nare not significant.\nThe first criterion we will examine here is the accuracy of the prediction of\nthe map to be made from the point samples, in particular the prediction\nvariance. Recall from the theory of kriging that the prediction variance at\na prediction location depends only on:\n1. the configuration of the sample points relative to each other and to the\nprediction location; and\n2. the model of spatial dependence (e.g. variogram model)\nnot on the data values. Therefore, before any observations are made, we\ncan compute the prediction variance at any point in the study area \u2013 always\nassuming we have a correct model of spatial dependence, perhaps from a\npilot study in the area or a previous study in a similar area.\nFrom this we can decide on an optimality criterion, e.g.\n1. minimize the mean prediction variance over the study area, so that it\nis, on average, well-mapped; this is called MEAN_OK by van Groenigen\n[10];\n2. minimize the maximum prediction variance in the study; this was the\ncriterion used in the OSSFIM approach of McBratney and Webster\n[6, 5]; it guarantees that no location will be poorly-mapped; this is\ncalled MAX_OK by van Groenigen [10];\nThe first would be appropriate when estimating spatial averages to a given\nprecision. The second would be appropriate when the entire area must be\nmapped to a given precision, e.g. to guarantee there is no health risk in a\npolluted area.\nIn a few simple cases the optimum design can be computed analytically; in\nparticular McBratney et al. [6] showed that on an infinite plane a regular\ntriangular scheme gives minimum maximum prediction (MAX_OK) variance\n1\nand that a square grid is not much worse. But in reality we often have\nconstraints:\n1. the study area is never infinite, so there are edge effects;\n2. the study area is often irregularly-shaped;\n3. there may be parts of the study area that can not be sampled (e.g. soil\nsamples under buildings);\n4. we may have some existing observations in the study area.\nAn obvious option is to place samples completely randomly. However, if\nthere is any spatial dependence, a random scheme will not be optimal either\nfor estimating population parameters (e.g. means) or for mapping.\nIt is not possible, in general, to solve this problem analytically. One solution\nto try large numbers of schemes and compare their optimality; but since the\nnumber of possible sample locations is usually very large, this is impractical.\nJust with ten sample points on a 100 \u00d7 100 grid there are approximately\n2.7434 \u00b7 1033 possible sample schemes.\nAnother way is to start with a random or fixed scheme and repeatedly modify\nit, each time checking if the modification makes the scheme better. This is\nknown as spatial simulated annealing (SSA) and was the subject of a thesis\n[9] and series of papers [10, 11] by van Groenigen.\nIn this exercise we will implement SSA to optimize sampling design for in\u0002terpolation by Ordinary Kriging (OK), i.e. where only the target variable is\nused for interpolation; in \u00a75 we briefly discuss how covariables could be used\nin the optimization.\nTwo-phase sampling In many environmental studies there are two sampling\nphases:\n1. to determine the spatial structure of the target variable (e.g. to esti\u0002mate the variogram model);\n2. to map the target variable.\nThe first stage could be set up with a nested design [14, 13], transects with\nvariable spacing, or a similar design [8, 7, 2]. Once this is done and the\nvariogram estimated, additional observations are located to map the whole\narea, using both sets. The second stage can be optimized, for example by\nMAX_OK, to ensure the quality of mapping.\nThere are two questions:\n1. How many more samples?\n2. Where to place them?\nIn practice this is an iterative procedure:\n1. Compute the fitness of the first-stage design, e.g. the maximum kriging\nprediction variance in the study area, using just these known points;\n2\n2. Compare this fitness to the required standard; most likely there will\nbe under-sampled areas far from the first-stage;\n3. Looking at the kriging prediction variance in more densely-sampled\nareas, estimate how dense a network might be required;\n4. Use SSA OK to optimize the placement of these new points;\n5. Examine the fitness to see if it is good enough; if too precise some\npoints can be eliminated, if not precise enough more points must be\nadded.\n6. Repeat steps 3\u20135 as necessary.\nThe techniques of SSA, developed below, can be applied...",
      "url": "https://www.css.cornell.edu/faculty/dgr2/_static/files/R_PDF/exSSA.pdf"
    },
    {
      "title": "Constrained simulated annealing",
      "text": "**Teams**\n\nQ&A for work\n\nConnect and share knowledge within a single location that is structured and easy to search.\n\n[Learn more about Teams](https://stackoverflow.co/teams/)\n\n# [Constrained simulated annealing](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing)\n\n[Ask Question](https://scicomp.stackexchange.com/questions/ask)\n\nAsked6 years, 6 months ago\n\nModified [6 years, 2 months ago](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing?lastactivity)\n\nViewed\n2k times\n\nThis question shows research effort; it is useful and clear\n\n7\n\nSave this question.\n\nShow activity on this post.\n\nSimulated annealing is a useful technique for finding near-optimal solutions to combinatorial problems. I have found a lot of tutorials on implementing the basic algorithm, but miss a general guide as to how constraints are incorporated into the optimization.\n\nI wonder if anyone knows any sources for advice or algorithms for incorporating constraints into simulated annealing applications.\n\nNB: I have constructed some algorithms for generating feasible permutations of the solutions, but would like to see more general results.\n\nAny help is greatly appreciated\n\n- [constrained-optimization](https://scicomp.stackexchange.com/questions/tagged/constrained-optimization)\n- [constraints](https://scicomp.stackexchange.com/questions/tagged/constraints)\n- [discrete-optimization](https://scicomp.stackexchange.com/questions/tagged/discrete-optimization)\n\n[Share](https://scicomp.stackexchange.com/q/28519)\n\nShare a link to this question\n\nCopy link [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/)\n\nCite\n\n[Improve this question](https://scicomp.stackexchange.com/posts/28519/edit)\n\nFollow\n\nFollow this question to receive notifications\n\nasked Dec 27, 2017 at 14:27\n\n[![user3124074's user avatar](https://www.gravatar.com/avatar/f27541ace21e8961dc7c1a6c838937a0?s=64&d=identicon&r=PG&f=y&so-version=2)](https://scicomp.stackexchange.com/users/23540/user3124074)\n\n[user3124074](https://scicomp.stackexchange.com/users/23540/user3124074) user3124074\n\n17122 bronze badges\n\n2\n\n- 1\n\n\n\n\n\nJust a suggestion: Instead of constraints, would a penalty-term added to the objective function be feasible?\n\n\u2013\u00a0[Andr\u00e9](https://scicomp.stackexchange.com/users/1789/andr%c3%a9)\n\n[CommentedDec 28, 2017 at 21:22](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing#comment51664_28519)\n\n- 1\n\n\n\n\n\nYes. The question is then how the penalty term should be weighed against the function to be minimized.\n\n\u2013\u00a0[user3124074](https://scicomp.stackexchange.com/users/23540/user3124074)\n\n[CommentedDec 29, 2017 at 5:07](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing#comment51667_28519)\n\n\n[Add a comment](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing)\u00a0\\|\n\n## 1 Answer 1\n\nSorted by:\n[Reset to default](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing?answertab=scoredesc#tab-top)\n\nHighest score (default)Date modified (newest first)Date created (oldest first)\n\nThis answer is useful\n\n5\n\nSave this answer.\n\nShow activity on this post.\n\nSimulated annealing comes from computations in statistical mechanics. When I think of simulated annealing, I very much think in terms of physics: I want to minimize some potential energy function that depends on the configuration, and whose global minimum corresponds to an optimal solution of your problem. At high temperature, there is enough kinetic energy available to go against the potential gradient, i.e. you are more likely to move toward a configuration of higher potential energy than when the temperature is low. If you think about a mountainous landscape with some marbles in it, and you shake it like crazy, the marbles may move in all directions, often uphill. If you only slightly shake it, marbles in local minima will slightly move around the minimum, only when the minimum is very shallow it may move out and roll down to further lower the potential energy. If you start at high temperature and slowly go down, the marbles will initially be shaken out of (and into) even very deep local minima, but later on they will not return to minima for which a high potential barrier has to be overcome.\n\nIn simulated annealing this time factor is absent, but otherwise the idea is the same. Instead of the next configuration in terms of the system's time evolution, a general nearby configuration (in any sense) is considered and accepted or rejected with the appropriate, temperature dependent, probability. When the [ergodic hypothesis](https://en.wikipedia.org/wiki/Ergodic_hypothesis) is assumed for the system, in the long run you will, roughly speaking, find the same configurations, but for practical applications you don't need to bother with such technicalities.\n\nIn statistical mechanics, the transition probability would be based on the [Boltzmann distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution) of configurations, but again, if you just want to optimize a wide range of transition probabilities will do the trick for you.\n\nAfter all these digressions, let's assume that your transition probability as a function of the energies of the two configurations and the temperature is given. Then there are two steps left where you can deal with your particular constraints: the generation of neighboring states, and the definition of the energy function. If you have a hard constraint on state, i.e. some states are strictly forbidden, you could directly exclude their generation as candidate neighbors. You may even find a way to directly generate random neighboring states following a distribution that takes their energy into account.\n\nRather than the sampling of neighbors, the obvious step in which to take care of your constraints is in the definition of the energy function, as Andr\u00e9 said in his comment. Here you can exclude configurations in a straightforward way, by assigning an infinite energy to them; if you assign a very high energy, they will be essentially inaccessible except at very high temperature, allowing you to essentially \"tunnel\" through them (if you need to allow that).\n\nAs a reference for algorithms in statistical mechanics, which explains the context of simulated annealing in an excellent way, I recommend [this book by Werner Krauth](https://books.google.co.uk/books?id=g30SDAAAQBAJ&lpg=PP1&pg=PP1#v=onepage&q&f=false) and the [companion online course](https://www.coursera.org/learn/statistical-mechanics). If you have a physical analogue for your optimization problem, then this can directly guide you in assigning energies to configurations.\n\nI am not sure if this addresses your question, but I hope it is helpful anyway.\n\n[Share](https://scicomp.stackexchange.com/a/29085)\n\nShare a link to this answer\n\nCopy link [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/)\n\nCite\n\n[Improve this answer](https://scicomp.stackexchange.com/posts/29085/edit)\n\nFollow\n\nFollow this answer to receive notifications\n\nanswered Mar 20, 2018 at 9:22\n\n[![doetoe's user avatar](https://i.sstatic.net/p7cBB.gif?s=64)](https://scicomp.stackexchange.com/users/5521/doetoe)\n\n[doetoe](https://scicomp.stackexchange.com/users/5521/doetoe) doetoe\n\n59344 silver badges1313 bronze badges\n\n[Add a comment](https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing)\u00a0\\|\n\n## Your Answer\n\nDraft saved\n\nDraft discarded\n\n### Sign up or [log in](https://scicomp.stackexchange.com/users/login?ssrc=question_page&returnurl=https%3a%2f%2fscicomp.stackexchange.com%2fquestions%2f28519%2fconstrained-simulated-annealing%23new-answer)\n\nSign up using Google\n\nSign up using Email and Password\n\nSubmit\n\n### Post as a guest\n\nName\n\nEmail\n\nRequired, but never shown\n\nPost Your Answer\n\nDiscard\n\nBy clicking \u201cPost Your Answer\u201d, you agree to our [terms of service](https://stackoverflow.com/legal/terms-of-service/public) and acknowledge you have r...",
      "url": "https://scicomp.stackexchange.com/questions/28519/constrained-simulated-annealing"
    },
    {
      "title": "Cooling Schedules for Optimal Annealing - PubsOnLine",
      "text": "This website stores cookies on your computer. These cookies are used to collect information about how you interact with our website and allow us to remember you. We use this information in order to improve and customize your browsing experience and for analytics and metrics about our visitors both on this website and other media. To find out more about the cookies we use, see our [Privacy Policy](https://www.informs.org/About-INFORMS/Privacy-Policy).\n\nIf you decline, your information won\u2019t be tracked when you visit this website. A single cookie will be used in your browser to remember your preference not to be tracked.\n\nAcceptDecline\n\n![](https://pubsonline.informs.org/pb-assets/ux3/journals/nameplates/MOOR_Name_Plate-1529315710087.svg)\n\n[Journal Menu](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n[JOURNAL HOME](https://pubsonline.informs.org/journal/moor) [ARTICLES IN ADVANCE](https://pubsonline.informs.org/toc/moor/0/0) [CURRENT ISSUE](https://pubsonline.informs.org/toc/moor/current) [ARCHIVES](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n[ABOUT](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n- [Editorial Statement](https://pubsonline.informs.org/page/moor/editorial-statement)\n- [Editorial Board](https://pubsonline.informs.org/page/moor/editorial-board)\n- [Journal Metrics](https://pubsonline.informs.org/authorportal/journal-statistics/mathematics-of-operations-research)\n\n- [SUBMIT](https://pubsonline.informs.org/page/moor/submission-guidelines)\n- [SUBSCRIBE](https://pubsonline.informs.org/page/moor/prices-and-ordering)\n\nSearchSearch\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [2020s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n- [2010s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n- [2000s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n- [1990s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n- [1980s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n- [1970s](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [2024](https://pubsonline.informs.org/loi/moor/group/d2020.y2024)\n- [2023](https://pubsonline.informs.org/loi/moor/group/d2020.y2023)\n- [2022](https://pubsonline.informs.org/loi/moor/group/d2020.y2022)\n- [2021](https://pubsonline.informs.org/loi/moor/group/d2020.y2021)\n- [2020](https://pubsonline.informs.org/loi/moor/group/d2020.y2020)\n\n- [Volume 49, Issue 2](https://pubsonline.informs.org/toc/moor/49/2) [May 2024](https://pubsonline.informs.org/toc/moor/49/2)\n\n\n\nCURRENT ISSUE\n\n\n\nPages 653-1302, C2\n\n- [Volume 49, Issue 1](https://pubsonline.informs.org/toc/moor/49/1) [February 2024](https://pubsonline.informs.org/toc/moor/49/1)\n\n\n\nPages 1-651, C2\n\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [2019](https://pubsonline.informs.org/loi/moor/group/d2010.y2019)\n- [2018](https://pubsonline.informs.org/loi/moor/group/d2010.y2018)\n- [2017](https://pubsonline.informs.org/loi/moor/group/d2010.y2017)\n- [2016](https://pubsonline.informs.org/loi/moor/group/d2010.y2016)\n- [2015](https://pubsonline.informs.org/loi/moor/group/d2010.y2015)\n- [2014](https://pubsonline.informs.org/loi/moor/group/d2010.y2014)\n- [2013](https://pubsonline.informs.org/loi/moor/group/d2010.y2013)\n- [2012](https://pubsonline.informs.org/loi/moor/group/d2010.y2012)\n- [2011](https://pubsonline.informs.org/loi/moor/group/d2010.y2011)\n- [2010](https://pubsonline.informs.org/loi/moor/group/d2010.y2010)\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [2009](https://pubsonline.informs.org/loi/moor/group/d2000.y2009)\n- [2008](https://pubsonline.informs.org/loi/moor/group/d2000.y2008)\n- [2007](https://pubsonline.informs.org/loi/moor/group/d2000.y2007)\n- [2006](https://pubsonline.informs.org/loi/moor/group/d2000.y2006)\n- [2005](https://pubsonline.informs.org/loi/moor/group/d2000.y2005)\n- [2004](https://pubsonline.informs.org/loi/moor/group/d2000.y2004)\n- [2003](https://pubsonline.informs.org/loi/moor/group/d2000.y2003)\n- [2002](https://pubsonline.informs.org/loi/moor/group/d2000.y2002)\n- [2001](https://pubsonline.informs.org/loi/moor/group/d2000.y2001)\n- [2000](https://pubsonline.informs.org/loi/moor/group/d2000.y2000)\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [1999](https://pubsonline.informs.org/loi/moor/group/d1990.y1999)\n- [1998](https://pubsonline.informs.org/loi/moor/group/d1990.y1998)\n- [1997](https://pubsonline.informs.org/loi/moor/group/d1990.y1997)\n- [1996](https://pubsonline.informs.org/loi/moor/group/d1990.y1996)\n- [1995](https://pubsonline.informs.org/loi/moor/group/d1990.y1995)\n- [1994](https://pubsonline.informs.org/loi/moor/group/d1990.y1994)\n- [1993](https://pubsonline.informs.org/loi/moor/group/d1990.y1993)\n- [1992](https://pubsonline.informs.org/loi/moor/group/d1990.y1992)\n- [1991](https://pubsonline.informs.org/loi/moor/group/d1990.y1991)\n- [1990](https://pubsonline.informs.org/loi/moor/group/d1990.y1990)\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [1989](https://pubsonline.informs.org/loi/moor/group/d1980.y1989)\n- [1988](https://pubsonline.informs.org/loi/moor/group/d1980.y1988)\n- [1987](https://pubsonline.informs.org/loi/moor/group/d1980.y1987)\n- [1986](https://pubsonline.informs.org/loi/moor/group/d1980.y1986)\n- [1985](https://pubsonline.informs.org/loi/moor/group/d1980.y1985)\n- [1984](https://pubsonline.informs.org/loi/moor/group/d1980.y1984)\n- [1983](https://pubsonline.informs.org/loi/moor/group/d1980.y1983)\n- [1982](https://pubsonline.informs.org/loi/moor/group/d1980.y1982)\n- [1981](https://pubsonline.informs.org/loi/moor/group/d1980.y1981)\n- [1980](https://pubsonline.informs.org/loi/moor/group/d1980.y1980)\n\n## Available Issues\n\nApril 10, 2013 - May 13, 2024\n\n- [1979](https://pubsonline.informs.org/loi/moor/group/d1970.y1979)\n- [1978](https://pubsonline.informs.org/loi/moor/group/d1970.y1978)\n- [1977](https://pubsonline.informs.org/loi/moor/group/d1970.y1977)\n- [1976](https://pubsonline.informs.org/loi/moor/group/d1970.y1976)\n\n# Cooling Schedules for Optimal Annealing\n\n- [Bruce Hajek](https://pubsonline.informs.org/action/doSearch?text1=Hajek%2C+Bruce&field1=Contrib)\n\n[Bruce Hajek](https://pubsonline.informs.org/action/doSearch?text1=Hajek%2C+Bruce&field1=Contrib)\n\nPublished Online:1 May 1988[https://doi.org/10.1287/moor.13.2.311](https://doi.org/10.1287/moor.13.2.311)\n\n## Abstract\n\nA Monte Carlo optimization technique called \u201csimulated annealing\u201d is a descent algorithm modified by random ascent moves in order to escape local minima which are not global minima. The level of randomization is determined by a control parameter _T_, called temperature, which tends to zero according to a deterministic \u201ccooling schedule.\u201d We give a simple necessary and sufficient condition on the cooling schedule for the algorithm state to converge in probability to the set of globally minimum cost states. In the special case that the cooling schedule has parametric form _T_( _t_) = _c_/log(1 + _t_), the condition for convergence is that _c_ be greater than or equal to the depth, suitably defined, of the deepest local minimum which is not a global minimum state.\n\n[Previous](https://pubsonline.informs.org/doi/10.1287/moor.13.2.295)\n\n[Back to Top](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n[Next](https://pubsonline.informs.org/doi/10.1287/moor.13.2.330)\n\n- [Figures](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311#pane-pcw-figures)\n- [References](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311#pane-pcw-references)\n- [Related](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311#pane-pcw-related)\n- [Information](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311#pane-pcw-details)\n\nNone\n\n- [Cited by](https://pubsonline.informs.org/doi/10.1287/moor.13.2.311)\n\n\n\n\n- [An embedded diachronic sense change model with a case study from ancient Greek](https://doi.org/10.1016/j.csda.2024.108011)\n\n\n\n\n\n\n\n\n\n\n\n1 Nov 2024 \\| Computational Statistics & Data A...",
      "url": "https://pubsonline.informs.org/doi/10.1287/moor.13.2.311"
    },
    {
      "title": "Dealing with Local Optima: Strategies for Escaping Plateaus in context of Simulated Annealing",
      "text": "TrueGeometry Dealing with Local Optima: Strategies for Escaping Plateaus in context of Simulated Annealing https://blog.truegeometry.com/tutorials/education/097ae7106a858f13e1165fb3337c34fd/JSON_TO_ARTCL_Dealing_with_Local_Optima_Strategies_for_Escaping_Plateaus_in_con.html\nDealing with Local Optima: Strategies for Escaping Plateaus in context of Simulated Annealing\nTrueGeometry\n2024-09-12T10:07:04+05:30\n# **Dealing with Local Optima: Strategies for Escaping Plateaus in Simulated Annealing**\n\nSimulated annealing (SA) is a popular optimization technique that has been widely used to solve complex problems in various fields, including engineering, finance, and computer science. However, one of the major challenges faced by SA is dealing with local optima, also known as plateaus or valleys. In this article, we will explore the concept of local optima, its implications on SA, and strategies for escaping these plateaus.\n\n**What are Local Optima?**\n\nLocal optima refer to points in the search space where the objective function has a minimum value, but it is not the global optimum. These points are characterized by a flat or shallow region around them, making it difficult for the optimization algorithm to escape and continue searching for better solutions.\n\n**Implications of Local Optima on Simulated Annealing**\n\nLocal optima can have significant implications on SA\u2019s performance. When the algorithm gets stuck in a local optimum, it may:\n\n1. **Fail to converge**: The algorithm may not be able to find the global optimum, leading to suboptimal solutions.\n2. **Get trapped in a valley**: The algorithm may oscillate around the local optimum, wasting computational resources and time.\n\n**Strategies for Escaping Local Optima**\n\nTo overcome these challenges, several strategies can be employed:\n\n1. **Temperature Scheduling**: Adjusting the temperature schedule can help SA escape local optima. A common approach is to use a decreasing temperature schedule, where the temperature starts high and decreases over time.\n - Formula: T(t) = T0* exp(-\u03b1t), where T0 is the initial temperature, \u03b1 is the cooling rate, and t is the iteration number.\n2. **Acceptance Probability**: Modifying the acceptance probability can help SA escape local optima by allowing it to explore more distant regions of the search space.\n - Formula: P = exp(-\u0394E / (k* T)), where \u0394E is the energy difference between two states, k is Boltzmann\u2019s constant, and T is the temperature.\n3. **Multiple Starting Points**: Running multiple SA instances with different starting points can help escape local optima by increasing the chances of finding a better solution.\n4. **Hybridization**: Combining SA with other optimization techniques, such as genetic algorithms or particle swarm optimization, can provide a more robust and efficient search process.\n5. **Diversification**: Incorporating diversification mechanisms, such as random perturbations or restarts, can help SA escape local optima by introducing new solutions and exploring different regions of the search space.\n\n**Conclusion**\n\nDealing with local optima is a crucial aspect of simulated annealing. By employing strategies such as temperature scheduling, acceptance probability modification, multiple starting points, hybridization, and diversification, SA can effectively escape plateaus and converge to better solutions. These techniques can be combined and tailored to specific problem domains to achieve optimal performance.\n\n**References**\n\n1. Kirkpatrick, S., Gelatt, C. D., & Vecseey, M. P. (1983). Optimization by simulated annealing. Science, 220(4598), 671-680.\n2. Laarman, F., & van der Velden, J. A. (2015). Simulated annealing: A review of the literature. Journal of Computational and Applied Mathematics, 289, 1-15.\n\n**About the Author**\n\n[Your Name] is a researcher with expertise in optimization techniques, including simulated annealing. They have published several papers on the topic and are passionate about sharing knowledge and best practices with the scientific community.\n\n## Related articles for \u2018Simulated Annealing\u2019 :\n\n- [Hybridizing Simulated Annealing with Other Optimization Techniques in context of Simulated Annealing]\n- [Comparing Simulated Annealing with Other Optimization Techniques (e.g., Genetic Algorithms, Gradient Descent) in context of Simulated Annealing]\n- [Simulated Annealing](https://blog.truegeometry.com/tutorials/education/097ae7106a858f13e1165fb3337c34fd/JSON_TO_ARTCL_Simulated_Annealing.html)\n- [Handling Constraints in Simulated Annealing in context of Simulated Annealing]\n- [Applications of Simulated Annealing: Optimization Problems and Real-World Scenarios in context of Simulated Annealing]\n- [Simulated Annealing Algorithm: Pseudocode and Flowchart in context of Simulated Annealing]\n- [Introduction to Simulated Annealing in context of Simulated Annealing]\n- [Choosing the Right Cooling Schedule for Your Problem in context of Simulated Annealing]\n- [Case Studies: Using Simulated Annealing to Solve Specific Optimization Problems in context of Simulated Annealing]\n- [score](https://blog.truegeometry.com/tutorials/education/097ae7106a858f13e1165fb3337c34fd/score.html)\n- [Simulated Annealing in Higher-Dimensional Spaces: Challenges and Solutions in context of Simulated Annealing]\n- [Basic Concepts: Temperature, Cooling Schedule, and Acceptance Probability in context of Simulated Annealing]\n- [Practical Considerations: Implementing Simulated Annealing in Real-World Applications in context of Simulated Annealing]\n- Reading: **Dealing with Local Optima: Strategies for Escaping Plateaus in context of Simulated Annealing**\n\n## Calculators for \u2018Simulated Annealing\u2019\n\n- [Optimizing Kinematic Parameters through Local Gravitational Acceleration](https://blog.truegeometry.com/calculators/Gravity_and_acceleration_calculation.html)\n- [Sampling Error Mitigation: Aliasing Considerations](https://blog.truegeometry.com/calculators/Aliasing_in_a_sampling_system_calculation.html)\n- [Astronomical Trajectory Optimisation Strategies](https://blog.truegeometry.com/calculators/Heroes_of_Interstellar_Journey_calculation.html)\n- [Minimizing Microscale Errors in Fabricated Systems](https://blog.truegeometry.com/calculators/Microfabrication_calculation_for_Calculations.html)\n- [Optimizing Phase Shift Estimations](https://blog.truegeometry.com/calculators/Phase_shift_calculation.html)\n- [Optimization Strategies for Non-Linear Trajectory Generation](https://blog.truegeometry.com/calculators/Trajectory_Planning_calculation.html)\n- [Optimizing Phase Shift Parameters](https://blog.truegeometry.com/calculators/Phase_shift_calculation.html)\n- [Optimization Techniques for Artificial Satellites Orbital Trajectories](https://blog.truegeometry.com/calculators/Artificial_satellites_calculation.html)\n- [Optimal Sampling Frequency for Minimizing Aliasing Error](https://blog.truegeometry.com/calculators/aliasing_calculator_calculation.html)\n- [Optimization Strategies for Atmospheric Dispersion Simulations](https://blog.truegeometry.com/calculators/Air_pollution_modeling_calculation.html)",
      "url": "https://blog.truegeometry.com/tutorials/education/097ae7106a858f13e1165fb3337c34fd/JSON_TO_ARTCL_Dealing_with_Local_Optima_Strategies_for_Escaping_Plateaus_in_con.html"
    }
  ]
}