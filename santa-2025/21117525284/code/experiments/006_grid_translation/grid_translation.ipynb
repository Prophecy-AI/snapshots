{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffef845",
   "metadata": {},
   "source": [
    "# Experiment 006: Grid-Based Translation Approach (egortrushin)\n",
    "\n",
    "Implementing the grid-based translation approach that builds configurations from scratch.\n",
    "This is fundamentally different from SA on existing configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafb5704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:33:32.922911Z",
     "iopub.status.busy": "2026-01-18T21:33:32.922281Z",
     "iopub.status.idle": "2026-01-18T21:33:33.213769Z",
     "shell.execute_reply": "2026-01-18T21:33:33.213358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import time\n",
    "\n",
    "getcontext().prec = 30\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecea6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:33:33.215031Z",
     "iopub.status.busy": "2026-01-18T21:33:33.214887Z",
     "iopub.status.idle": "2026-01-18T21:33:33.220800Z",
     "shell.execute_reply": "2026-01-18T21:33:33.220443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChristmasTree class defined\n"
     ]
    }
   ],
   "source": [
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated, xoff=float(self.center_x * scale_factor), yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "    def clone(self):\n",
    "        return ChristmasTree(str(self.center_x), str(self.center_y), str(self.angle))\n",
    "\n",
    "print(\"ChristmasTree class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e170decc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:33:33.221929Z",
     "iopub.status.busy": "2026-01-18T21:33:33.221827Z",
     "iopub.status.idle": "2026-01-18T21:33:33.226543Z",
     "shell.execute_reply": "2026-01-18T21:33:33.226196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def get_side_length(trees):\n",
    "    all_polygons = [t.polygon for t in trees]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    return max(bounds[2] - bounds[0], bounds[3] - bounds[1]) / float(scale_factor)\n",
    "\n",
    "def get_score(trees, n):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    side = get_side_length(trees)\n",
    "    return side ** 2 / n\n",
    "\n",
    "def has_collision(trees):\n",
    "    \"\"\"Check for collisions using Shapely (ground truth).\"\"\"\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    for i, tree1 in enumerate(trees):\n",
    "        for j, tree2 in enumerate(trees):\n",
    "            if i < j:\n",
    "                if tree1.polygon.intersects(tree2.polygon) and not tree1.polygon.touches(tree2.polygon):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def load_configuration_from_df(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f9844f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:33:43.927057Z",
     "iopub.status.busy": "2026-01-18T21:33:43.926482Z",
     "iopub.status.idle": "2026-01-18T21:33:55.213643Z",
     "shell.execute_reply": "2026-01-18T21:33:55.213233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying repaired baseline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total score: 70.682741\n",
      "Overlaps: 0\n",
      "Gap to target: 1.759933 points\n"
     ]
    }
   ],
   "source": [
    "# Verify the repaired baseline\n",
    "print(\"Verifying repaired baseline...\")\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "\n",
    "total_score = 0\n",
    "overlap_count = 0\n",
    "for n in range(1, 201):\n",
    "    trees = load_configuration_from_df(n, df)\n",
    "    if trees:\n",
    "        score = get_score(trees, n)\n",
    "        total_score += score\n",
    "        if has_collision(trees):\n",
    "            overlap_count += 1\n",
    "            if overlap_count <= 5:\n",
    "                print(f\"  N={n}: OVERLAP!\")\n",
    "\n",
    "print(f\"\\nTotal score: {total_score:.6f}\")\n",
    "print(f\"Overlaps: {overlap_count}\")\n",
    "print(f\"Gap to target: {total_score - 68.922808:.6f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb30cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:34:04.829061Z",
     "iopub.status.busy": "2026-01-18T21:34:04.828497Z",
     "iopub.status.idle": "2026-01-18T21:34:04.835816Z",
     "shell.execute_reply": "2026-01-18T21:34:04.835412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid optimization functions defined\n"
     ]
    }
   ],
   "source": [
    "# Grid-based translation approach from egortrushin kernel\n",
    "# Creates trees in a grid pattern and optimizes the translation parameters\n",
    "\n",
    "def create_grid_trees(n, dx, dy, angle1=0, angle2=180):\n",
    "    \"\"\"\n",
    "    Create n trees in a grid pattern with alternating angles.\n",
    "    dx, dy are the translation between adjacent trees.\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    \n",
    "    # Find grid dimensions\n",
    "    cols = int(math.ceil(math.sqrt(n * 1.5)))  # More columns than rows\n",
    "    rows = int(math.ceil(n / cols))\n",
    "    \n",
    "    count = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if count >= n:\n",
    "                break\n",
    "            \n",
    "            # Alternating angles for interlocking\n",
    "            angle = angle1 if (row + col) % 2 == 0 else angle2\n",
    "            \n",
    "            # Position with offset for odd rows\n",
    "            x = col * dx\n",
    "            if row % 2 == 1:\n",
    "                x += dx / 2  # Offset for interlocking\n",
    "            y = row * dy\n",
    "            \n",
    "            trees.append(ChristmasTree(str(x), str(y), str(angle)))\n",
    "            count += 1\n",
    "        if count >= n:\n",
    "            break\n",
    "    \n",
    "    return trees\n",
    "\n",
    "def optimize_grid_sa(n, n_steps=5000, T_max=1.0, T_min=0.001, seed=42):\n",
    "    \"\"\"\n",
    "    Optimize grid parameters using simulated annealing.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Initial parameters (based on tree dimensions)\n",
    "    # Tree width is ~0.7, height is ~1.0\n",
    "    best_dx = 0.7\n",
    "    best_dy = 0.9\n",
    "    best_angle1 = 0\n",
    "    best_angle2 = 180\n",
    "    \n",
    "    trees = create_grid_trees(n, best_dx, best_dy, best_angle1, best_angle2)\n",
    "    if has_collision(trees):\n",
    "        # Increase spacing until no collision\n",
    "        for scale in [1.1, 1.2, 1.3, 1.4, 1.5, 2.0]:\n",
    "            trees = create_grid_trees(n, best_dx * scale, best_dy * scale, best_angle1, best_angle2)\n",
    "            if not has_collision(trees):\n",
    "                best_dx *= scale\n",
    "                best_dy *= scale\n",
    "                break\n",
    "    \n",
    "    best_side = get_side_length(trees)\n",
    "    best_score = get_score(trees, n)\n",
    "    \n",
    "    # SA parameters\n",
    "    alpha = (T_min / T_max) ** (1.0 / n_steps)\n",
    "    T = T_max\n",
    "    \n",
    "    current_dx, current_dy = best_dx, best_dy\n",
    "    current_angle1, current_angle2 = best_angle1, best_angle2\n",
    "    current_side = best_side\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        # Perturb parameters\n",
    "        scale = T / T_max\n",
    "        new_dx = current_dx + random.uniform(-0.05 * scale, 0.05 * scale)\n",
    "        new_dy = current_dy + random.uniform(-0.05 * scale, 0.05 * scale)\n",
    "        new_angle1 = (current_angle1 + random.uniform(-10 * scale, 10 * scale)) % 360\n",
    "        new_angle2 = (current_angle2 + random.uniform(-10 * scale, 10 * scale)) % 360\n",
    "        \n",
    "        # Ensure positive spacing\n",
    "        new_dx = max(0.3, new_dx)\n",
    "        new_dy = max(0.3, new_dy)\n",
    "        \n",
    "        # Create new configuration\n",
    "        trees = create_grid_trees(n, new_dx, new_dy, new_angle1, new_angle2)\n",
    "        \n",
    "        if not has_collision(trees):\n",
    "            new_side = get_side_length(trees)\n",
    "            delta = new_side - current_side\n",
    "            \n",
    "            if delta < 0 or random.random() < math.exp(-delta / T):\n",
    "                current_dx, current_dy = new_dx, new_dy\n",
    "                current_angle1, current_angle2 = new_angle1, new_angle2\n",
    "                current_side = new_side\n",
    "                \n",
    "                if new_side < best_side:\n",
    "                    best_dx, best_dy = new_dx, new_dy\n",
    "                    best_angle1, best_angle2 = new_angle1, new_angle2\n",
    "                    best_side = new_side\n",
    "        \n",
    "        T *= alpha\n",
    "    \n",
    "    # Return best configuration\n",
    "    trees = create_grid_trees(n, best_dx, best_dy, best_angle1, best_angle2)\n",
    "    return trees, best_side\n",
    "\n",
    "print(\"Grid optimization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb54513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:34:04.836964Z",
     "iopub.status.busy": "2026-01-18T21:34:04.836852Z",
     "iopub.status.idle": "2026-01-18T21:36:53.427083Z",
     "shell.execute_reply": "2026-01-18T21:36:53.426641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing grid approach...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=10: baseline=0.376630, grid=1.088212, overlap=False, time=4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=20: baseline=0.376057, grid=0.989167, overlap=False, time=10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=50: baseline=0.360753, grid=0.843694, overlap=False, time=38.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: baseline=0.345531, grid=0.837886, overlap=False, time=115.7s\n"
     ]
    }
   ],
   "source": [
    "# Test grid approach on a few N values\n",
    "print(\"Testing grid approach...\")\n",
    "\n",
    "test_ns = [10, 20, 50, 100]\n",
    "for n in test_ns:\n",
    "    baseline_trees = load_configuration_from_df(n, df)\n",
    "    baseline_score = get_score(baseline_trees, n)\n",
    "    \n",
    "    start = time.time()\n",
    "    grid_trees, grid_side = optimize_grid_sa(n, n_steps=3000, seed=42)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    grid_score = get_score(grid_trees, n)\n",
    "    has_overlap = has_collision(grid_trees)\n",
    "    \n",
    "    print(f\"N={n}: baseline={baseline_score:.6f}, grid={grid_score:.6f}, overlap={has_overlap}, time={elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8b911b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:38:04.309240Z",
     "iopub.status.busy": "2026-01-18T21:38:04.309089Z",
     "iopub.status.idle": "2026-01-18T22:02:11.324581Z",
     "shell.execute_reply": "2026-01-18T22:02:11.324157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting backward propagation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total score: 70.682741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=137: improved 0.345264 -> 0.343528 (removed tree 118 from N=138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward propagation complete!\n",
      "Total improvements: 1\n",
      "New total score: 70.681004\n",
      "Improvement: 0.001737 points\n"
     ]
    }
   ],
   "source": [
    "# Backward propagation approach - start from N=200 and remove trees\n",
    "# This is fundamentally different from local search\n",
    "\n",
    "def backward_propagation(df, max_n=200):\n",
    "    \"\"\"\n",
    "    Start from N=200 configuration and remove trees one by one.\n",
    "    For each N from 199 down to 1, try removing each tree and keep the best.\n",
    "    \"\"\"\n",
    "    print(\"Starting backward propagation...\")\n",
    "    \n",
    "    # Load all configurations\n",
    "    configs = {}\n",
    "    scores = {}\n",
    "    for n in range(1, max_n + 1):\n",
    "        trees = load_configuration_from_df(n, df)\n",
    "        configs[n] = trees\n",
    "        scores[n] = get_score(trees, n)\n",
    "    \n",
    "    original_total = sum(scores.values())\n",
    "    print(f\"Original total score: {original_total:.6f}\")\n",
    "    \n",
    "    improvements = 0\n",
    "    \n",
    "    # Start from N=200 and work down\n",
    "    for n in range(max_n, 1, -1):\n",
    "        target_n = n - 1\n",
    "        current_best_score = scores[target_n]\n",
    "        best_tree_to_remove = None\n",
    "        best_new_trees = None\n",
    "        \n",
    "        # Try removing each tree from the N configuration\n",
    "        source_trees = configs[n]\n",
    "        \n",
    "        for i in range(len(source_trees)):\n",
    "            # Create configuration without tree i\n",
    "            candidate_trees = [t.clone() for j, t in enumerate(source_trees) if j != i]\n",
    "            \n",
    "            # Check for collisions (shouldn't happen if we just remove a tree)\n",
    "            if has_collision(candidate_trees):\n",
    "                continue\n",
    "            \n",
    "            candidate_score = get_score(candidate_trees, target_n)\n",
    "            \n",
    "            if candidate_score < current_best_score:\n",
    "                current_best_score = candidate_score\n",
    "                best_tree_to_remove = i\n",
    "                best_new_trees = candidate_trees\n",
    "        \n",
    "        # If we found an improvement, update\n",
    "        if best_new_trees is not None:\n",
    "            old_score = scores[target_n]\n",
    "            configs[target_n] = best_new_trees\n",
    "            scores[target_n] = current_best_score\n",
    "            improvements += 1\n",
    "            if n % 20 == 0 or improvements <= 5:\n",
    "                print(f\"  N={target_n}: improved {old_score:.6f} -> {current_best_score:.6f} (removed tree {best_tree_to_remove} from N={n})\")\n",
    "    \n",
    "    new_total = sum(scores.values())\n",
    "    print(f\"\\nBackward propagation complete!\")\n",
    "    print(f\"Total improvements: {improvements}\")\n",
    "    print(f\"New total score: {new_total:.6f}\")\n",
    "    print(f\"Improvement: {original_total - new_total:.6f} points\")\n",
    "    \n",
    "    return configs, scores\n",
    "\n",
    "# Run backward propagation\n",
    "bp_configs, bp_scores = backward_propagation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da54f5fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T22:05:09.180456Z",
     "iopub.status.busy": "2026-01-18T22:05:09.180302Z",
     "iopub.status.idle": "2026-01-18T22:05:13.853950Z",
     "shell.execute_reply": "2026-01-18T22:05:13.853527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing score distribution by N...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 N values with highest scores (most room for improvement):\n",
      "  N=1: score=0.661250\n",
      "  N=2: score=0.450779\n",
      "  N=3: score=0.434745\n",
      "  N=5: score=0.416850\n",
      "  N=4: score=0.416545\n",
      "  N=7: score=0.399897\n",
      "  N=6: score=0.399610\n",
      "  N=9: score=0.387415\n",
      "  N=8: score=0.385407\n",
      "  N=15: score=0.379203\n",
      "  N=10: score=0.376630\n",
      "  N=21: score=0.376451\n",
      "  N=20: score=0.376057\n",
      "  N=11: score=0.375736\n",
      "  N=22: score=0.375258\n",
      "  N=16: score=0.374128\n",
      "  N=26: score=0.373997\n",
      "  N=12: score=0.372724\n",
      "  N=13: score=0.372323\n",
      "  N=25: score=0.372144\n",
      "\n",
      "Bottom 20 N values with lowest scores (best optimized):\n",
      "  N=153: score=0.336287\n",
      "  N=197: score=0.336047\n",
      "  N=165: score=0.335569\n",
      "  N=192: score=0.335301\n",
      "  N=166: score=0.334819\n",
      "  N=178: score=0.334442\n",
      "  N=154: score=0.334158\n",
      "  N=193: score=0.333950\n",
      "  N=132: score=0.333818\n",
      "  N=196: score=0.333299\n",
      "  N=194: score=0.333085\n",
      "  N=195: score=0.332901\n",
      "  N=167: score=0.332835\n",
      "  N=179: score=0.332597\n",
      "  N=168: score=0.332475\n",
      "  N=155: score=0.332075\n",
      "  N=180: score=0.331002\n",
      "  N=182: score=0.329988\n",
      "  N=156: score=0.329987\n",
      "  N=181: score=0.329954\n",
      "\n",
      "Cumulative score contribution:\n",
      "  Top 1 N values contribute: 0.661250 (0.9%)\n",
      "  Top 2 N values contribute: 1.112029 (1.6%)\n",
      "  Top 3 N values contribute: 1.546774 (2.2%)\n",
      "  Top 4 N values contribute: 1.963624 (2.8%)\n",
      "  Top 5 N values contribute: 2.380169 (3.4%)\n",
      "  Top 6 N values contribute: 2.780065 (3.9%)\n",
      "  Top 7 N values contribute: 3.179676 (4.5%)\n",
      "  Top 8 N values contribute: 3.567091 (5.0%)\n",
      "  Top 9 N values contribute: 3.952498 (5.6%)\n",
      "  Top 10 N values contribute: 4.331701 (6.1%)\n",
      "  Top 21 N values contribute: 8.447718 (12.0%)\n",
      "  Top 41 N values contribute: 15.801143 (22.4%)\n",
      "  Top 61 N values contribute: 23.013338 (32.6%)\n",
      "  Top 81 N values contribute: 30.074253 (42.5%)\n",
      "  Top 101 N values contribute: 37.057972 (52.4%)\n",
      "  Top 121 N values contribute: 43.962011 (62.2%)\n",
      "  Top 141 N values contribute: 50.802752 (71.9%)\n",
      "  Top 161 N values contribute: 57.600838 (81.5%)\n",
      "  Top 181 N values contribute: 64.354440 (91.0%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze which N values have the most room for improvement\n",
    "# by comparing their scores to theoretical lower bounds\n",
    "\n",
    "print(\"Analyzing score distribution by N...\")\n",
    "\n",
    "# Calculate score per N\n",
    "n_scores = {}\n",
    "for n in range(1, 201):\n",
    "    trees = load_configuration_from_df(n, df)\n",
    "    n_scores[n] = get_score(trees, n)\n",
    "\n",
    "# Find N values with highest scores (most room for improvement)\n",
    "sorted_scores = sorted(n_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 20 N values with highest scores (most room for improvement):\")\n",
    "for n, score in sorted_scores[:20]:\n",
    "    print(f\"  N={n}: score={score:.6f}\")\n",
    "\n",
    "print(\"\\nBottom 20 N values with lowest scores (best optimized):\")\n",
    "for n, score in sorted_scores[-20:]:\n",
    "    print(f\"  N={n}: score={score:.6f}\")\n",
    "\n",
    "# Calculate cumulative contribution\n",
    "cumulative = 0\n",
    "print(\"\\nCumulative score contribution:\")\n",
    "for i, (n, score) in enumerate(sorted_scores):\n",
    "    cumulative += score\n",
    "    if i < 10 or i % 20 == 0:\n",
    "        print(f\"  Top {i+1} N values contribute: {cumulative:.6f} ({100*cumulative/total_score:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598b4197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T22:06:23.900779Z",
     "iopub.status.busy": "2026-01-18T22:06:23.900347Z",
     "iopub.status.idle": "2026-01-18T22:36:10.361323Z",
     "shell.execute_reply": "2026-01-18T22:36:10.360909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing small N values with aggressive SA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=1: 0.661250 (no improvement) [40.3s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=2: 0.450779 (no improvement) [48.0s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=3: 0.434745 (no improvement) [55.1s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=4: 0.416545 (no improvement) [64.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=5: 0.416850 (no improvement) [77.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=6: 0.399610 (no improvement) [87.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=7: 0.399897 (no improvement) [98.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=8: 0.385407 (no improvement) [104.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=9: 0.387415 (no improvement) [111.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=10: 0.376630 (no improvement) [114.9s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=11: 0.375736 (no improvement) [114.4s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=12: 0.372724 (no improvement) [110.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=13: 0.372323 (no improvement) [103.9s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=14: 0.370569 (no improvement) [94.9s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=15: 0.379203 (no improvement) [84.6s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=16: 0.374128 (no improvement) [86.2s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=17: 0.370040 (no improvement) [91.6s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=18: 0.368771 (no improvement) [96.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=19: 0.368615 (no improvement) [98.4s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=20: 0.376057 (no improvement) [100.7s]\n",
      "\n",
      "Total improvement from small N optimization: 0.000000 points\n"
     ]
    }
   ],
   "source": [
    "# Focus on optimizing small N values with aggressive SA\n",
    "# These contribute the most to the total score\n",
    "\n",
    "def optimize_small_n_aggressive(n, trees, n_restarts=10, n_steps=10000, seed=42):\n",
    "    \"\"\"\n",
    "    Aggressive SA optimization for small N values.\n",
    "    Uses multiple restarts with different random seeds.\n",
    "    \"\"\"\n",
    "    best_trees = [t.clone() for t in trees]\n",
    "    best_score = get_score(best_trees, n)\n",
    "    \n",
    "    for restart in range(n_restarts):\n",
    "        random.seed(seed + restart * 1000)\n",
    "        \n",
    "        # Start from current best\n",
    "        current_trees = [t.clone() for t in best_trees]\n",
    "        current_score = best_score\n",
    "        \n",
    "        # SA parameters\n",
    "        T_max = 0.5\n",
    "        T_min = 0.0001\n",
    "        alpha = (T_min / T_max) ** (1.0 / n_steps)\n",
    "        T = T_max\n",
    "        \n",
    "        for step in range(n_steps):\n",
    "            # Pick a random tree\n",
    "            i = random.randint(0, n - 1)\n",
    "            \n",
    "            # Save old state\n",
    "            old_x = current_trees[i].center_x\n",
    "            old_y = current_trees[i].center_y\n",
    "            old_angle = current_trees[i].angle\n",
    "            \n",
    "            # Perturb\n",
    "            scale = T / T_max\n",
    "            dx = Decimal(str(random.uniform(-0.1 * scale, 0.1 * scale)))\n",
    "            dy = Decimal(str(random.uniform(-0.1 * scale, 0.1 * scale)))\n",
    "            dangle = Decimal(str(random.uniform(-30 * scale, 30 * scale)))\n",
    "            \n",
    "            new_x = old_x + dx\n",
    "            new_y = old_y + dy\n",
    "            new_angle = (old_angle + dangle) % Decimal('360')\n",
    "            \n",
    "            # Apply perturbation\n",
    "            current_trees[i] = ChristmasTree(str(new_x), str(new_y), str(new_angle))\n",
    "            \n",
    "            # Check collision\n",
    "            if has_collision(current_trees):\n",
    "                # Revert\n",
    "                current_trees[i] = ChristmasTree(str(old_x), str(old_y), str(old_angle))\n",
    "            else:\n",
    "                new_score = get_score(current_trees, n)\n",
    "                delta = new_score - current_score\n",
    "                \n",
    "                if delta < 0 or random.random() < math.exp(-delta / T):\n",
    "                    current_score = new_score\n",
    "                    if new_score < best_score:\n",
    "                        best_score = new_score\n",
    "                        best_trees = [t.clone() for t in current_trees]\n",
    "                else:\n",
    "                    # Revert\n",
    "                    current_trees[i] = ChristmasTree(str(old_x), str(old_y), str(old_angle))\n",
    "            \n",
    "            T *= alpha\n",
    "    \n",
    "    return best_trees, best_score\n",
    "\n",
    "# Optimize small N values\n",
    "print(\"Optimizing small N values with aggressive SA...\")\n",
    "\n",
    "improved_configs = {}\n",
    "improved_scores = {}\n",
    "total_improvement = 0\n",
    "\n",
    "for n in range(1, 21):  # Focus on N=1 to 20\n",
    "    trees = load_configuration_from_df(n, df)\n",
    "    original_score = get_score(trees, n)\n",
    "    \n",
    "    # More restarts for smaller N\n",
    "    n_restarts = max(5, 20 - n)\n",
    "    n_steps = max(5000, 20000 - n * 500)\n",
    "    \n",
    "    start = time.time()\n",
    "    new_trees, new_score = optimize_small_n_aggressive(n, trees, n_restarts=n_restarts, n_steps=n_steps, seed=42+n)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    improved_configs[n] = new_trees\n",
    "    improved_scores[n] = new_score\n",
    "    \n",
    "    improvement = original_score - new_score\n",
    "    total_improvement += improvement\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(f\"  N={n}: {original_score:.6f} -> {new_score:.6f} (improved by {improvement:.6f}) [{elapsed:.1f}s]\")\n",
    "    else:\n",
    "        print(f\"  N={n}: {original_score:.6f} (no improvement) [{elapsed:.1f}s]\")\n",
    "\n",
    "print(f\"\\nTotal improvement from small N optimization: {total_improvement:.6f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7263df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T22:37:40.109978Z",
     "iopub.status.busy": "2026-01-18T22:37:40.109829Z",
     "iopub.status.idle": "2026-01-18T22:38:40.787247Z",
     "shell.execute_reply": "2026-01-18T22:38:40.786838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying ensemble approach from multiple CSVs...\n",
      "Loaded /home/submission/submission.csv\n",
      "Loaded /home/code/submission_candidates/candidate_000.csv\n",
      "Loaded /home/code/submission_candidates/candidate_001.csv\n",
      "Loaded /home/code/submission_candidates/candidate_002.csv\n",
      "Loaded /home/code/submission_candidates/candidate_003.csv\n",
      "Loaded /home/code/submission_candidates/candidate_004.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble total score: 70.682741\n",
      "Improvement over baseline: 0.000000 points\n",
      "\n",
      "Source contributions:\n",
      "  /home/submission/submission.csv: 200 configurations\n"
     ]
    }
   ],
   "source": [
    "# Try ensemble approach - pick best configuration for each N from multiple CSVs\n",
    "print(\"Trying ensemble approach from multiple CSVs...\")\n",
    "\n",
    "csv_files = [\n",
    "    '/home/submission/submission.csv',  # Current best (repaired baseline)\n",
    "    '/home/code/submission_candidates/candidate_000.csv',\n",
    "    '/home/code/submission_candidates/candidate_001.csv',\n",
    "    '/home/code/submission_candidates/candidate_002.csv',\n",
    "    '/home/code/submission_candidates/candidate_003.csv',\n",
    "    '/home/code/submission_candidates/candidate_004.csv',\n",
    "]\n",
    "\n",
    "# Load all CSVs\n",
    "dfs = {}\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        dfs[csv_file] = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {csv_file}: {e}\")\n",
    "\n",
    "# For each N, find the best configuration across all CSVs\n",
    "best_configs = {}\n",
    "best_scores = {}\n",
    "best_sources = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_trees = None\n",
    "    best_source = None\n",
    "    \n",
    "    for csv_file, csv_df in dfs.items():\n",
    "        try:\n",
    "            trees = load_configuration_from_df(n, csv_df)\n",
    "            if trees and not has_collision(trees):\n",
    "                score = get_score(trees, n)\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_trees = trees\n",
    "                    best_source = csv_file\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    if best_trees:\n",
    "        best_configs[n] = best_trees\n",
    "        best_scores[n] = best_score\n",
    "        best_sources[n] = best_source\n",
    "\n",
    "# Calculate total score\n",
    "ensemble_total = sum(best_scores.values())\n",
    "print(f\"\\nEnsemble total score: {ensemble_total:.6f}\")\n",
    "print(f\"Improvement over baseline: {total_score - ensemble_total:.6f} points\")\n",
    "\n",
    "# Show which CSVs contributed\n",
    "source_counts = {}\n",
    "for n, source in best_sources.items():\n",
    "    source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "print(\"\\nSource contributions:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {count} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30484783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T22:39:35.330447Z",
     "iopub.status.busy": "2026-01-18T22:39:35.330006Z",
     "iopub.status.idle": "2026-01-18T22:46:36.681931Z",
     "shell.execute_reply": "2026-01-18T22:46:36.681287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing swap optimization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=10: 0.376630 (no improvement) [4.8s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=20: 0.376057 (no improvement) [9.5s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=50: 0.360753 (no improvement) [26.3s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=100: 0.345531 (no improvement) [71.1s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=150: 0.337065 (no improvement) [124.9s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=200: 0.337731 (no improvement) [184.6s]\n"
     ]
    }
   ],
   "source": [
    "# Implement swap moves - swap positions of two trees\n",
    "# This can escape local optima that translation moves cannot\n",
    "\n",
    "def swap_trees(trees, i, j):\n",
    "    \"\"\"Swap positions of trees i and j.\"\"\"\n",
    "    new_trees = [t.clone() for t in trees]\n",
    "    \n",
    "    # Swap positions (keep angles)\n",
    "    x_i, y_i = new_trees[i].center_x, new_trees[i].center_y\n",
    "    x_j, y_j = new_trees[j].center_x, new_trees[j].center_y\n",
    "    \n",
    "    new_trees[i] = ChristmasTree(str(x_j), str(y_j), str(new_trees[i].angle))\n",
    "    new_trees[j] = ChristmasTree(str(x_i), str(y_i), str(new_trees[j].angle))\n",
    "    \n",
    "    return new_trees\n",
    "\n",
    "def optimize_with_swaps(n, trees, n_iterations=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Optimize configuration using swap moves.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    best_trees = [t.clone() for t in trees]\n",
    "    best_score = get_score(best_trees, n)\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        # Pick two random trees\n",
    "        i = random.randint(0, n - 1)\n",
    "        j = random.randint(0, n - 1)\n",
    "        if i == j:\n",
    "            continue\n",
    "        \n",
    "        # Try swap\n",
    "        new_trees = swap_trees(best_trees, i, j)\n",
    "        \n",
    "        if not has_collision(new_trees):\n",
    "            new_score = get_score(new_trees, n)\n",
    "            if new_score < best_score:\n",
    "                best_score = new_score\n",
    "                best_trees = new_trees\n",
    "    \n",
    "    return best_trees, best_score\n",
    "\n",
    "# Test swap optimization on a few N values\n",
    "print(\"Testing swap optimization...\")\n",
    "\n",
    "for n in [10, 20, 50, 100, 150, 200]:\n",
    "    trees = load_configuration_from_df(n, df)\n",
    "    original_score = get_score(trees, n)\n",
    "    \n",
    "    start = time.time()\n",
    "    new_trees, new_score = optimize_with_swaps(n, trees, n_iterations=5000, seed=42+n)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    improvement = original_score - new_score\n",
    "    if improvement > 0:\n",
    "        print(f\"  N={n}: {original_score:.6f} -> {new_score:.6f} (improved by {improvement:.6f}) [{elapsed:.1f}s]\")\n",
    "    else:\n",
    "        print(f\"  N={n}: {original_score:.6f} (no improvement) [{elapsed:.1f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27aa8322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T22:50:48.967723Z",
     "iopub.status.busy": "2026-01-18T22:50:48.967181Z",
     "iopub.status.idle": "2026-01-18T22:50:49.238113Z",
     "shell.execute_reply": "2026-01-18T22:50:49.237514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing squeeze optimization...\n",
      "  N=10: 0.376630 (no improvement) [0.0s]\n",
      "  N=20: 0.376057 (no improvement) [0.0s]\n",
      "  N=50: 0.360753 (no improvement) [0.0s]\n",
      "  N=100: 0.345531 (no improvement) [0.0s]\n",
      "  N=150: 0.337065 (no improvement) [0.0s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=200: 0.337731 (no improvement) [0.1s]\n"
     ]
    }
   ],
   "source": [
    "# Implement squeeze operation - scale all trees toward the center\n",
    "# This can sometimes find improvements by compacting the configuration\n",
    "\n",
    "def squeeze_trees(trees, scale_factor_val):\n",
    "    \"\"\"Scale all trees toward the center by scale_factor.\"\"\"\n",
    "    if not trees:\n",
    "        return trees\n",
    "    \n",
    "    # Find center\n",
    "    cx = sum(float(t.center_x) for t in trees) / len(trees)\n",
    "    cy = sum(float(t.center_y) for t in trees) / len(trees)\n",
    "    \n",
    "    new_trees = []\n",
    "    for t in trees:\n",
    "        new_x = cx + (float(t.center_x) - cx) * scale_factor_val\n",
    "        new_y = cy + (float(t.center_y) - cy) * scale_factor_val\n",
    "        new_trees.append(ChristmasTree(str(new_x), str(new_y), str(t.angle)))\n",
    "    \n",
    "    return new_trees\n",
    "\n",
    "def optimize_with_squeeze(n, trees, n_steps=100):\n",
    "    \"\"\"\n",
    "    Try to squeeze the configuration to reduce bounding box.\n",
    "    \"\"\"\n",
    "    best_trees = [t.clone() for t in trees]\n",
    "    best_score = get_score(best_trees, n)\n",
    "    \n",
    "    # Try different squeeze factors\n",
    "    for scale in np.linspace(0.999, 0.95, n_steps):\n",
    "        new_trees = squeeze_trees(best_trees, scale)\n",
    "        \n",
    "        if not has_collision(new_trees):\n",
    "            new_score = get_score(new_trees, n)\n",
    "            if new_score < best_score:\n",
    "                best_score = new_score\n",
    "                best_trees = new_trees\n",
    "        else:\n",
    "            # Can't squeeze further without collision\n",
    "            break\n",
    "    \n",
    "    return best_trees, best_score\n",
    "\n",
    "# Test squeeze optimization\n",
    "print(\"Testing squeeze optimization...\")\n",
    "\n",
    "for n in [10, 20, 50, 100, 150, 200]:\n",
    "    trees = load_configuration_from_df(n, df)\n",
    "    original_score = get_score(trees, n)\n",
    "    \n",
    "    start = time.time()\n",
    "    new_trees, new_score = optimize_with_squeeze(n, trees, n_steps=200)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    improvement = original_score - new_score\n",
    "    if improvement > 0:\n",
    "        print(f\"  N={n}: {original_score:.6f} -> {new_score:.6f} (improved by {improvement:.6f}) [{elapsed:.1f}s]\")\n",
    "    else:\n",
    "        print(f\"  N={n}: {original_score:.6f} (no improvement) [{elapsed:.1f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid optimization on all N values and compare with baseline\n",
    "print(\"\\nRunning grid optimization on all N values...\")\n",
    "\n",
    "best_configs = {}\n",
    "best_scores = {}\n",
    "improvements = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for n in range(1, 201):\n",
    "    baseline_trees = load_configuration_from_df(n, df)\n",
    "    baseline_score = get_score(baseline_trees, n)\n",
    "    \n",
    "    # Adjust iterations based on N\n",
    "    if n <= 20:\n",
    "        n_steps = 5000\n",
    "    elif n <= 50:\n",
    "        n_steps = 3000\n",
    "    else:\n",
    "        n_steps = 2000\n",
    "    \n",
    "    grid_trees, grid_side = optimize_grid_sa(n, n_steps=n_steps, seed=42+n)\n",
    "    grid_score = get_score(grid_trees, n)\n",
    "    \n",
    "    # Use grid if better and no overlap\n",
    "    if grid_score < baseline_score and not has_collision(grid_trees):\n",
    "        best_configs[n] = grid_trees\n",
    "        best_scores[n] = grid_score\n",
    "        improvements += 1\n",
    "        if n % 20 == 0:\n",
    "            print(f\"N={n}: IMPROVED {baseline_score:.6f} -> {grid_score:.6f}\")\n",
    "    else:\n",
    "        best_configs[n] = baseline_trees\n",
    "        best_scores[n] = baseline_score\n",
    "        if n % 20 == 0:\n",
    "            print(f\"N={n}: kept baseline {baseline_score:.6f} (grid={grid_score:.6f})\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal time: {elapsed:.1f}s\")\n",
    "print(f\"Improvements: {improvements}\")\n",
    "\n",
    "new_total = sum(best_scores.values())\n",
    "print(f\"\\nNew total score: {new_total:.6f}\")\n",
    "print(f\"Improvement: {total_score - new_total:.6f} points\")\n",
    "print(f\"Gap to target: {new_total - 68.922808:.6f} points\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
