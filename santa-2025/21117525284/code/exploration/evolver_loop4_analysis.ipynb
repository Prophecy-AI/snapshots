{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c8579",
   "metadata": {},
   "source": [
    "# Loop 4 Analysis: C++ Overlap Detection Mismatch\n",
    "\n",
    "## Problem Identified\n",
    "The jonathanchan C++ SA optimizer improved score from 70.68 to 51.66 but introduced overlaps in 176/200 N configurations. When validated with Python/Shapely, these overlaps were detected and repaired, returning the score to 70.68.\n",
    "\n",
    "## Root Cause\n",
    "The C++ overlap detection algorithm differs from Python/Shapely's algorithm. The C++ code uses:\n",
    "1. Point-in-polygon test (ray casting)\n",
    "2. Segment intersection test\n",
    "\n",
    "But Shapely uses a more robust algorithm that handles edge cases differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe85ba9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:08:20.165702Z",
     "iopub.status.busy": "2026-01-18T21:08:20.165153Z",
     "iopub.status.idle": "2026-01-18T21:08:20.487179Z",
     "shell.execute_reply": "2026-01-18T21:08:20.486765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.strtree import STRtree\n",
    "import os\n",
    "import glob\n",
    "\n",
    "getcontext().prec = 30\n",
    "scale_factor = Decimal('1e15')\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x='0', center_y='0', angle='0'):\n",
    "        self.center_x = Decimal(str(center_x))\n",
    "        self.center_y = Decimal(str(center_y))\n",
    "        self.angle = Decimal(str(angle))\n",
    "        trunk_w = Decimal('0.15')\n",
    "        trunk_h = Decimal('0.2')\n",
    "        base_w = Decimal('0.7')\n",
    "        mid_w = Decimal('0.4')\n",
    "        top_w = Decimal('0.25')\n",
    "        tip_y = Decimal('0.8')\n",
    "        tier_1_y = Decimal('0.5')\n",
    "        tier_2_y = Decimal('0.25')\n",
    "        base_y = Decimal('0.0')\n",
    "        trunk_bottom_y = -trunk_h\n",
    "        initial_polygon = Polygon([\n",
    "            (Decimal('0.0') * scale_factor, tip_y * scale_factor),\n",
    "            (top_w / Decimal('2') * scale_factor, tier_1_y * scale_factor),\n",
    "            (top_w / Decimal('4') * scale_factor, tier_1_y * scale_factor),\n",
    "            (mid_w / Decimal('2') * scale_factor, tier_2_y * scale_factor),\n",
    "            (mid_w / Decimal('4') * scale_factor, tier_2_y * scale_factor),\n",
    "            (base_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, base_y * scale_factor),\n",
    "            (trunk_w / Decimal('2') * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, trunk_bottom_y * scale_factor),\n",
    "            (-(trunk_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(base_w / Decimal('2')) * scale_factor, base_y * scale_factor),\n",
    "            (-(mid_w / Decimal('4')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(mid_w / Decimal('2')) * scale_factor, tier_2_y * scale_factor),\n",
    "            (-(top_w / Decimal('4')) * scale_factor, tier_1_y * scale_factor),\n",
    "            (-(top_w / Decimal('2')) * scale_factor, tier_1_y * scale_factor),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(rotated, xoff=float(self.center_x * scale_factor), yoff=float(self.center_y * scale_factor))\n",
    "\n",
    "def load_configuration_from_df(n, df):\n",
    "    group_data = df[df[\"id\"].str.startswith(f\"{n:03d}_\")]\n",
    "    trees = []\n",
    "    for _, row in group_data.iterrows():\n",
    "        x = str(row[\"x\"])[1:] if str(row[\"x\"]).startswith('s') else str(row[\"x\"])\n",
    "        y = str(row[\"y\"])[1:] if str(row[\"y\"]).startswith('s') else str(row[\"y\"])\n",
    "        deg = str(row[\"deg\"])[1:] if str(row[\"deg\"]).startswith('s') else str(row[\"deg\"])\n",
    "        if x and y and deg:\n",
    "            trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def get_tree_list_side_length(tree_list):\n",
    "    all_polygons = [t.polygon for t in tree_list]\n",
    "    bounds = unary_union(all_polygons).bounds\n",
    "    return Decimal(max(bounds[2] - bounds[0], bounds[3] - bounds[1])) / scale_factor\n",
    "\n",
    "def get_score(trees, n):\n",
    "    if not trees:\n",
    "        return 0.0\n",
    "    side = get_tree_list_side_length(trees)\n",
    "    return float(side ** 2 / Decimal(n))\n",
    "\n",
    "def has_overlap(trees):\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    polygons = [t.polygon for t in trees]\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        indices = tree_index.query(poly)\n",
    "        for idx in indices:\n",
    "            if idx == i:\n",
    "                continue\n",
    "            if poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def score_submission(file_path, max_n=200):\n",
    "    df = pd.read_csv(file_path)\n",
    "    total_score = 0.0\n",
    "    failed_overlap_n = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        trees = load_configuration_from_df(n, df)\n",
    "        if trees:\n",
    "            current_score = get_score(trees, n)\n",
    "            total_score += current_score\n",
    "            if has_overlap(trees):\n",
    "                failed_overlap_n.append(n)\n",
    "    return total_score, failed_overlap_n\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d703b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:08:20.488466Z",
     "iopub.status.busy": "2026-01-18T21:08:20.488331Z",
     "iopub.status.idle": "2026-01-18T21:08:43.464564Z",
     "shell.execute_reply": "2026-01-18T21:08:43.464107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available pre-optimized CSVs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  best_ensemble.csv: score=70.676102, overlaps=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ensemble.csv: score=70.676102, overlaps=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa-2025.csv: score=70.676102, overlaps=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: score=70.676501, overlaps=11\n"
     ]
    }
   ],
   "source": [
    "# Check available pre-optimized CSVs\n",
    "preopt_dir = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "print(\"Available pre-optimized CSVs:\")\n",
    "for f in sorted(os.listdir(preopt_dir)):\n",
    "    if f.endswith('.csv'):\n",
    "        path = os.path.join(preopt_dir, f)\n",
    "        try:\n",
    "            score, overlaps = score_submission(path)\n",
    "            print(f\"  {f}: score={score:.6f}, overlaps={len(overlaps)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {f}: ERROR - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65589f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:08:43.466217Z",
     "iopub.status.busy": "2026-01-18T21:08:43.465707Z",
     "iopub.status.idle": "2026-01-18T21:08:49.240083Z",
     "shell.execute_reply": "2026-01-18T21:08:49.239602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chistyakov CSVs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_best.csv: score=70.926150, overlaps=0\n"
     ]
    }
   ],
   "source": [
    "# Check the chistyakov folder\n",
    "chistyakov_dir = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/chistyakov'\n",
    "if os.path.exists(chistyakov_dir):\n",
    "    print(\"\\nChistyakov CSVs:\")\n",
    "    for f in sorted(os.listdir(chistyakov_dir)):\n",
    "        if f.endswith('.csv'):\n",
    "            path = os.path.join(chistyakov_dir, f)\n",
    "            try:\n",
    "                score, overlaps = score_submission(path)\n",
    "                print(f\"  {f}: score={score:.6f}, overlaps={len(overlaps)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {f}: ERROR - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04a4c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:08:49.241230Z",
     "iopub.status.busy": "2026-01-18T21:08:49.241123Z",
     "iopub.status.idle": "2026-01-18T21:09:00.827229Z",
     "shell.execute_reply": "2026-01-18T21:09:00.826759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Telegram CSVs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.97.csv: score=71.972027, overlaps=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.49.csv: score=72.495739, overlaps=0\n"
     ]
    }
   ],
   "source": [
    "# Check telegram folder\n",
    "telegram_dir = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/telegram'\n",
    "if os.path.exists(telegram_dir):\n",
    "    print(\"\\nTelegram CSVs:\")\n",
    "    for f in sorted(os.listdir(telegram_dir)):\n",
    "        if f.endswith('.csv'):\n",
    "            path = os.path.join(telegram_dir, f)\n",
    "            try:\n",
    "                score, overlaps = score_submission(path)\n",
    "                print(f\"  {f}: score={score:.6f}, overlaps={len(overlaps)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {f}: ERROR - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2c0589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:09:00.828363Z",
     "iopub.status.busy": "2026-01-18T21:09:00.828258Z",
     "iopub.status.idle": "2026-01-18T21:09:06.593189Z",
     "shell.execute_reply": "2026-01-18T21:09:06.592530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current submission:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score: 70.682741\n",
      "  Overlaps: None\n",
      "  Gap to target (68.92): 1.759933 points\n"
     ]
    }
   ],
   "source": [
    "# Check our current best submission\n",
    "print(\"\\nCurrent submission:\")\n",
    "score, overlaps = score_submission('/home/submission/submission.csv')\n",
    "print(f\"  Score: {score:.6f}\")\n",
    "print(f\"  Overlaps: {overlaps if overlaps else 'None'}\")\n",
    "print(f\"  Gap to target (68.92): {score - 68.922808:.6f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df694064",
   "metadata": {},
   "source": [
    "## Key Insight: The Problem is Overlap Detection Mismatch\n",
    "\n",
    "The C++ optimizer is producing configurations that it thinks are valid (no overlaps), but Python/Shapely detects overlaps. This means:\n",
    "\n",
    "1. **The optimizer IS working** - it found better configurations (51.66 vs 70.68)\n",
    "2. **The overlap detection is the bottleneck** - C++ and Python disagree on what's an overlap\n",
    "3. **We need a PURE PYTHON optimizer** that uses Shapely for overlap detection\n",
    "\n",
    "## Options:\n",
    "\n",
    "### Option A: Pure Python Backpacking (crodoc kernel)\n",
    "- Start from N=200, work backward to N=1\n",
    "- For each N, try removing each tree from N+1 configuration\n",
    "- Uses Shapely for overlap detection (guaranteed correct)\n",
    "- Slower but produces valid results\n",
    "\n",
    "### Option B: Fix C++ Overlap Detection\n",
    "- Add buffer/tolerance to C++ overlap detection\n",
    "- Make it stricter than Shapely to ensure no false negatives\n",
    "- Requires modifying C++ code and recompiling\n",
    "\n",
    "### Option C: Hybrid Approach\n",
    "- Run C++ optimizer to generate candidates\n",
    "- Validate each candidate with Python/Shapely\n",
    "- Only keep configurations that pass Python validation\n",
    "- This is what we tried, but 176/200 failed\n",
    "\n",
    "### Option D: Python SA Optimizer with Shapely\n",
    "- Implement SA optimizer in pure Python\n",
    "- Use Shapely for overlap detection\n",
    "- Slower but guaranteed correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb05f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:09:06.594296Z",
     "iopub.status.busy": "2026-01-18T21:09:06.594180Z",
     "iopub.status.idle": "2026-01-18T21:09:16.067587Z",
     "shell.execute_reply": "2026-01-18T21:09:16.067098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score breakdown by N range:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=1-50: 19.0424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=51-100: 17.6414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=101-150: 17.1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=151-200: 16.8495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 70.682741\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze which N values have the most room for improvement\n",
    "# by comparing our baseline to the theoretical minimum\n",
    "\n",
    "df_baseline = pd.read_csv('/home/code/experiments/003_preoptimized/repaired_baseline.csv')\n",
    "\n",
    "print(\"Score breakdown by N range:\")\n",
    "ranges = [(1, 50), (51, 100), (101, 150), (151, 200)]\n",
    "for start, end in ranges:\n",
    "    range_score = 0\n",
    "    for n in range(start, end + 1):\n",
    "        trees = load_configuration_from_df(n, df_baseline)\n",
    "        if trees:\n",
    "            range_score += get_score(trees, n)\n",
    "    print(f\"  N={start}-{end}: {range_score:.4f}\")\n",
    "\n",
    "print(f\"\\nTotal: {sum([get_score(load_configuration_from_df(n, df_baseline), n) for n in range(1, 201)]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a34ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:09:25.405598Z",
     "iopub.status.busy": "2026-01-18T21:09:25.405041Z",
     "iopub.status.idle": "2026-01-18T21:09:30.075960Z",
     "shell.execute_reply": "2026-01-18T21:09:30.075540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst-performing N values (highest score per N):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 worst N values:\n",
      "  N=1: 0.661250\n",
      "  N=2: 0.450779\n",
      "  N=3: 0.434745\n",
      "  N=5: 0.416850\n",
      "  N=4: 0.416545\n",
      "  N=7: 0.399897\n",
      "  N=6: 0.399610\n",
      "  N=9: 0.387415\n",
      "  N=8: 0.385407\n",
      "  N=15: 0.379203\n",
      "  N=10: 0.376630\n",
      "  N=21: 0.376451\n",
      "  N=20: 0.376057\n",
      "  N=11: 0.375736\n",
      "  N=22: 0.375258\n",
      "  N=16: 0.374128\n",
      "  N=26: 0.373997\n",
      "  N=12: 0.372724\n",
      "  N=13: 0.372323\n",
      "  N=25: 0.372144\n",
      "\n",
      "Sum of worst 20: 8.0771\n",
      "If improved by 10%: saves 0.8077 points\n"
     ]
    }
   ],
   "source": [
    "# Find the N values with the worst efficiency (highest score contribution per tree)\n",
    "print(\"\\nWorst-performing N values (highest score per N):\")\n",
    "scores_by_n = []\n",
    "for n in range(1, 201):\n",
    "    trees = load_configuration_from_df(n, df_baseline)\n",
    "    if trees:\n",
    "        score = get_score(trees, n)\n",
    "        scores_by_n.append((n, score))\n",
    "\n",
    "# Sort by score (descending)\n",
    "scores_by_n.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 20 worst N values:\")\n",
    "for n, score in scores_by_n[:20]:\n",
    "    print(f\"  N={n}: {score:.6f}\")\n",
    "\n",
    "print(f\"\\nSum of worst 20: {sum([s for _, s in scores_by_n[:20]]):.4f}\")\n",
    "print(f\"If improved by 10%: saves {sum([s for _, s in scores_by_n[:20]]) * 0.1:.4f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f6b6f",
   "metadata": {},
   "source": [
    "## Key Insight: smartmanoj tree_packer_v21 + backward propagation\n",
    "\n",
    "The smartmanoj kernel has a sophisticated C++ optimizer with:\n",
    "1. **tree_packer_v21**: Multi-start SA with swap moves, squeeze, compaction, local search\n",
    "2. **bp.cpp**: Backward propagation that removes boundary-touching trees\n",
    "\n",
    "The key difference from jonathanchan is that smartmanoj runs backward propagation AFTER the SA optimizer, which can help propagate good configurations from larger N to smaller N.\n",
    "\n",
    "Let me check if this approach might work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47642f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T21:10:03.574088Z",
     "iopub.status.busy": "2026-01-18T21:10:03.573502Z",
     "iopub.status.idle": "2026-01-18T21:10:12.976887Z",
     "shell.execute_reply": "2026-01-18T21:10:12.976460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing best_ensemble.csv vs repaired_baseline.csv:\n",
      "\n",
      "N values where best_ensemble is better (ignoring overlaps):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 N values where best_ensemble is better:\n",
      "  N=134: improvement=0.003286 (HAS OVERLAP)\n",
      "  N=137: improvement=0.002019 (HAS OVERLAP)\n",
      "  N=170: improvement=0.000672 (HAS OVERLAP)\n",
      "  N=61: improvement=0.000217 (HAS OVERLAP)\n",
      "  N=41: improvement=0.000193 (HAS OVERLAP)\n",
      "  N=171: improvement=0.000143 (HAS OVERLAP)\n",
      "  N=77: improvement=0.000060 (HAS OVERLAP)\n",
      "  N=114: improvement=0.000018 (HAS OVERLAP)\n",
      "  N=110: improvement=0.000018 (HAS OVERLAP)\n",
      "  N=117: improvement=0.000008 (HAS OVERLAP)\n",
      "  N=43: improvement=0.000002 (HAS OVERLAP)\n",
      "  N=30: improvement=0.000002 (HAS OVERLAP)\n",
      "\n",
      "With overlap: 12, Without overlap: 0\n"
     ]
    }
   ],
   "source": [
    "# Let's look at what the best_ensemble.csv has that our repaired baseline doesn't\n",
    "# The best_ensemble has 12 overlaps but scores 70.676 vs our 70.683\n",
    "\n",
    "df_best_ensemble = pd.read_csv('/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/best_ensemble.csv')\n",
    "df_repaired = pd.read_csv('/home/code/experiments/003_preoptimized/repaired_baseline.csv')\n",
    "\n",
    "print(\"Comparing best_ensemble.csv vs repaired_baseline.csv:\")\n",
    "print(\"\\nN values where best_ensemble is better (ignoring overlaps):\")\n",
    "\n",
    "better_n = []\n",
    "for n in range(1, 201):\n",
    "    trees_ensemble = load_configuration_from_df(n, df_best_ensemble)\n",
    "    trees_repaired = load_configuration_from_df(n, df_repaired)\n",
    "    \n",
    "    if trees_ensemble and trees_repaired:\n",
    "        score_ensemble = get_score(trees_ensemble, n)\n",
    "        score_repaired = get_score(trees_repaired, n)\n",
    "        \n",
    "        if score_ensemble < score_repaired - 1e-9:\n",
    "            has_ovl = has_overlap(trees_ensemble)\n",
    "            improvement = score_repaired - score_ensemble\n",
    "            better_n.append((n, improvement, has_ovl))\n",
    "\n",
    "print(f\"Found {len(better_n)} N values where best_ensemble is better:\")\n",
    "for n, improvement, has_ovl in sorted(better_n, key=lambda x: -x[1])[:20]:\n",
    "    ovl_str = \" (HAS OVERLAP)\" if has_ovl else \"\"\n",
    "    print(f\"  N={n}: improvement={improvement:.6f}{ovl_str}\")\n",
    "\n",
    "# Count how many have overlaps\n",
    "with_overlap = sum(1 for _, _, has_ovl in better_n if has_ovl)\n",
    "without_overlap = len(better_n) - with_overlap\n",
    "print(f\"\\nWith overlap: {with_overlap}, Without overlap: {without_overlap}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
