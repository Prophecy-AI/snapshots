{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc22b4c",
   "metadata": {},
   "source": [
    "# Experiment 002: Ensemble Best Solutions\n",
    "\n",
    "This notebook:\n",
    "1. Loads all available pre-optimized solutions\n",
    "2. For each N, selects the best configuration\n",
    "3. Creates an ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48213957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree geometry - exact from competition\n",
    "def get_tree_vertices():\n",
    "    trunk_w = 0.15\n",
    "    trunk_h = 0.2\n",
    "    base_w = 0.7\n",
    "    mid_w = 0.4\n",
    "    top_w = 0.25\n",
    "    tip_y = 0.8\n",
    "    tier_1_y = 0.5\n",
    "    tier_2_y = 0.25\n",
    "    base_y = 0.0\n",
    "    trunk_bottom_y = -trunk_h\n",
    "    \n",
    "    vertices = [\n",
    "        (0.0, tip_y),\n",
    "        (top_w / 2, tier_1_y),\n",
    "        (top_w / 4, tier_1_y),\n",
    "        (mid_w / 2, tier_2_y),\n",
    "        (mid_w / 4, tier_2_y),\n",
    "        (base_w / 2, base_y),\n",
    "        (trunk_w / 2, base_y),\n",
    "        (trunk_w / 2, trunk_bottom_y),\n",
    "        (-trunk_w / 2, trunk_bottom_y),\n",
    "        (-trunk_w / 2, base_y),\n",
    "        (-base_w / 2, base_y),\n",
    "        (-mid_w / 4, tier_2_y),\n",
    "        (-mid_w / 2, tier_2_y),\n",
    "        (-top_w / 4, tier_1_y),\n",
    "        (-top_w / 2, tier_1_y),\n",
    "    ]\n",
    "    return vertices\n",
    "\n",
    "BASE_TREE = Polygon(get_tree_vertices())\n",
    "print(f\"Base tree bounds: {BASE_TREE.bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ff16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_value(s):\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def load_submission(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            return None\n",
    "        df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "        df['tree_idx'] = df['id'].apply(lambda x: int(x.split('_')[1]))\n",
    "        df['x_val'] = df['x'].apply(parse_value)\n",
    "        df['y_val'] = df['y'].apply(parse_value)\n",
    "        df['deg_val'] = df['deg'].apply(parse_value)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree_polygon(x, y, deg):\n",
    "    tree = rotate(BASE_TREE, deg, origin=(0, 0))\n",
    "    tree = translate(tree, x, y)\n",
    "    return tree\n",
    "\n",
    "def get_bounding_box_side(trees_df):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for _, row in trees_df.iterrows():\n",
    "        poly = create_tree_polygon(row['x_val'], row['y_val'], row['deg_val'])\n",
    "        minx, miny, maxx, maxy = poly.bounds\n",
    "        all_x.extend([minx, maxx])\n",
    "        all_y.extend([miny, maxy])\n",
    "    width = max(all_x) - min(all_x)\n",
    "    height = max(all_y) - min(all_y)\n",
    "    return max(width, height)\n",
    "\n",
    "def calculate_score_for_n(df, n):\n",
    "    trees_n = df[df['n'] == n]\n",
    "    if len(trees_n) != n:\n",
    "        return float('inf')\n",
    "    side = get_bounding_box_side(trees_n)\n",
    "    return side ** 2 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c37a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files\n",
    "csv_paths = []\n",
    "for pattern in [\n",
    "    '/home/code/santa-2025-csv/*.csv',\n",
    "    '/home/code/bucket-of-chump/*.csv',\n",
    "    '/home/code/telegram/*.csv',\n",
    "    '/home/code/santa25-public/*.csv',\n",
    "]:\n",
    "    csv_paths.extend(glob.glob(pattern))\n",
    "\n",
    "print(f\"Found {len(csv_paths)} CSV files:\")\n",
    "for p in csv_paths:\n",
    "    print(f\"  {os.path.basename(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all submissions\n",
    "submissions = {}\n",
    "for path in csv_paths:\n",
    "    df = load_submission(path)\n",
    "    if df is not None and len(df) == 20100:\n",
    "        submissions[path] = df\n",
    "        print(f\"Loaded: {os.path.basename(path)}\")\n",
    "\n",
    "print(f\"\\nTotal valid submissions: {len(submissions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score for each submission\n",
    "print(\"\\nCalculating scores for each submission...\")\n",
    "submission_scores = {}\n",
    "for path, df in submissions.items():\n",
    "    total_score = 0\n",
    "    for n in range(1, 201):\n",
    "        score_n = calculate_score_for_n(df, n)\n",
    "        total_score += score_n\n",
    "    submission_scores[path] = total_score\n",
    "    print(f\"{os.path.basename(path)}: {total_score:.6f}\")\n",
    "\n",
    "# Sort by score\n",
    "sorted_subs = sorted(submission_scores.items(), key=lambda x: x[1])\n",
    "print(\"\\nRanked submissions:\")\n",
    "for path, score in sorted_subs:\n",
    "    print(f\"  {score:.6f}: {os.path.basename(path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3cd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N, find the best configuration across all submissions\n",
    "print(\"\\nFinding best configuration for each N...\")\n",
    "best_configs = {}\n",
    "best_sources = {}\n",
    "\n",
    "for n in tqdm(range(1, 201)):\n",
    "    best_score = float('inf')\n",
    "    best_df = None\n",
    "    best_source = None\n",
    "    \n",
    "    for path, df in submissions.items():\n",
    "        score_n = calculate_score_for_n(df, n)\n",
    "        if score_n < best_score:\n",
    "            best_score = score_n\n",
    "            best_df = df[df['n'] == n].copy()\n",
    "            best_source = os.path.basename(path)\n",
    "    \n",
    "    best_configs[n] = best_df\n",
    "    best_sources[n] = (best_source, best_score)\n",
    "\n",
    "# Show which sources contributed\n",
    "print(\"\\nSource contributions:\")\n",
    "source_counts = {}\n",
    "for n, (source, score) in best_sources.items():\n",
    "    source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {source}: {count} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble score\n",
    "ensemble_score = sum(best_sources[n][1] for n in range(1, 201))\n",
    "print(f\"\\nEnsemble total score: {ensemble_score:.6f}\")\n",
    "print(f\"Best single submission: {sorted_subs[0][1]:.6f}\")\n",
    "print(f\"Improvement: {sorted_subs[0][1] - ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble submission\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    for _, row in best_configs[n].iterrows():\n",
    "        ensemble_rows.append({\n",
    "            'id': row['id'],\n",
    "            'x': f\"s{row['x_val']}\",\n",
    "            'y': f\"s{row['y_val']}\",\n",
    "            'deg': f\"s{row['deg_val']}\"\n",
    "        })\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_rows)\n",
    "ensemble_df = ensemble_df.sort_values('id')\n",
    "\n",
    "# Save\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "ensemble_df.to_csv('/home/code/experiments/002_ensemble/submission.csv', index=False)\n",
    "\n",
    "print(f\"Saved ensemble submission with {len(ensemble_df)} rows\")\n",
    "print(f\"Score: {ensemble_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'ensemble_score': ensemble_score,\n",
    "    'best_single_score': sorted_subs[0][1],\n",
    "    'improvement': sorted_subs[0][1] - ensemble_score,\n",
    "    'num_sources': len(submissions),\n",
    "    'source_contributions': source_counts\n",
    "}\n",
    "with open('/home/code/experiments/002_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"Metrics saved\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
