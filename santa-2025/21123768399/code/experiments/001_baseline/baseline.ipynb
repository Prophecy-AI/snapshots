{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c701c132",
   "metadata": {},
   "source": [
    "# Experiment 001: Baseline with Pre-Optimized Solutions\n",
    "\n",
    "This notebook:\n",
    "1. Loads pre-optimized solutions from public datasets\n",
    "2. Calculates scores for each\n",
    "3. Applies fix_direction optimization\n",
    "4. Validates for overlaps\n",
    "5. Creates submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9356cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T04:03:55.506831Z",
     "iopub.status.busy": "2026-01-19T04:03:55.506331Z",
     "iopub.status.idle": "2026-01-19T04:03:55.909572Z",
     "shell.execute_reply": "2026-01-19T04:03:55.909261Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "from shapely.strtree import STRtree\n",
    "import math\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.spatial import ConvexHull\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44b6b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T04:03:55.918404Z",
     "iopub.status.busy": "2026-01-19T04:03:55.918252Z",
     "iopub.status.idle": "2026-01-19T04:03:55.925094Z",
     "shell.execute_reply": "2026-01-19T04:03:55.924843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base tree area: 0.457500\n",
      "Base tree bounds: (-0.35, -0.5, 0.35, 0.8)\n"
     ]
    }
   ],
   "source": [
    "# Tree geometry - 15 vertices\n",
    "def get_tree_vertices():\n",
    "    \"\"\"Returns the base tree polygon vertices (centered at origin)\"\"\"\n",
    "    # From the kernel analysis - tree shape\n",
    "    w = 1.0  # width scale\n",
    "    h = 1.0  # height scale\n",
    "    \n",
    "    # Trunk\n",
    "    trunk_w = 0.15 * w\n",
    "    trunk_h = 0.2 * h\n",
    "    \n",
    "    # Tree layers\n",
    "    base_w = 0.7 * w / 2\n",
    "    mid_w = 0.4 * w / 2\n",
    "    top_w = 0.25 * w / 2\n",
    "    \n",
    "    # Heights\n",
    "    trunk_top = -0.3 * h\n",
    "    base_top = 0.1 * h\n",
    "    mid_top = 0.4 * h\n",
    "    top_top = 0.6 * h\n",
    "    tip = 0.8 * h\n",
    "    \n",
    "    vertices = [\n",
    "        (-trunk_w/2, -0.5 * h),  # trunk bottom left\n",
    "        (trunk_w/2, -0.5 * h),   # trunk bottom right\n",
    "        (trunk_w/2, trunk_top),  # trunk top right\n",
    "        (base_w, trunk_top),     # base right\n",
    "        (mid_w, base_top),       # mid right bottom\n",
    "        (base_w, base_top),      # base right top\n",
    "        (top_w, mid_top),        # top right bottom\n",
    "        (mid_w, mid_top),        # mid right top\n",
    "        (top_w/2, top_top),      # top right\n",
    "        (0, tip),                # tip\n",
    "        (-top_w/2, top_top),     # top left\n",
    "        (-mid_w, mid_top),       # mid left top\n",
    "        (-top_w, mid_top),       # top left bottom\n",
    "        (-base_w, base_top),     # base left top\n",
    "        (-mid_w, base_top),      # mid left bottom\n",
    "        (-base_w, trunk_top),    # base left\n",
    "        (-trunk_w/2, trunk_top), # trunk top left\n",
    "    ]\n",
    "    return vertices\n",
    "\n",
    "# Actually use the exact vertices from the kernel\n",
    "def get_tree_vertices_exact():\n",
    "    \"\"\"Exact tree vertices from the competition\"\"\"\n",
    "    return [\n",
    "        (-0.075, -0.5),\n",
    "        (0.075, -0.5),\n",
    "        (0.075, -0.3),\n",
    "        (0.35, -0.3),\n",
    "        (0.2, 0.1),\n",
    "        (0.35, 0.1),\n",
    "        (0.125, 0.4),\n",
    "        (0.2, 0.4),\n",
    "        (0.0625, 0.6),\n",
    "        (0.0, 0.8),\n",
    "        (-0.0625, 0.6),\n",
    "        (-0.2, 0.4),\n",
    "        (-0.125, 0.4),\n",
    "        (-0.35, 0.1),\n",
    "        (-0.2, 0.1),\n",
    "        (-0.35, -0.3),\n",
    "        (-0.075, -0.3),\n",
    "    ]\n",
    "\n",
    "BASE_TREE = Polygon(get_tree_vertices_exact())\n",
    "print(f\"Base tree area: {BASE_TREE.area:.6f}\")\n",
    "print(f\"Base tree bounds: {BASE_TREE.bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e585d733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T04:03:55.926269Z",
     "iopub.status.busy": "2026-01-19T04:03:55.925838Z",
     "iopub.status.idle": "2026-01-19T04:03:56.104583Z",
     "shell.execute_reply": "2026-01-19T04:03:56.104026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saspav dataset: 20100 rows\n",
      "bucket-of-chump dataset: 20100 rows\n",
      "\n",
      "Expected rows: 20100 = 20100\n"
     ]
    }
   ],
   "source": [
    "def parse_value(s):\n",
    "    \"\"\"Parse value from submission format (with 's' prefix)\"\"\"\n",
    "    if isinstance(s, str) and s.startswith('s'):\n",
    "        return float(s[1:])\n",
    "    return float(s)\n",
    "\n",
    "def load_submission(filepath):\n",
    "    \"\"\"Load submission CSV and parse into tree configurations\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Parse the id column to get n and tree_idx\n",
    "    df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "    df['tree_idx'] = df['id'].apply(lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    # Parse x, y, deg values\n",
    "    df['x_val'] = df['x'].apply(parse_value)\n",
    "    df['y_val'] = df['y'].apply(parse_value)\n",
    "    df['deg_val'] = df['deg'].apply(parse_value)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load both pre-optimized solutions\n",
    "df_saspav = load_submission('/home/code/santa-2025-csv/santa-2025.csv')\n",
    "df_bucket = load_submission('/home/code/bucket-of-chump/submission.csv')\n",
    "\n",
    "print(f\"saspav dataset: {len(df_saspav)} rows\")\n",
    "print(f\"bucket-of-chump dataset: {len(df_bucket)} rows\")\n",
    "print(f\"\\nExpected rows: {sum(range(1, 201))} = 20100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76917d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree_polygon(x, y, deg):\n",
    "    \"\"\"Create a tree polygon at position (x, y) with rotation deg\"\"\"\n",
    "    tree = rotate(BASE_TREE, deg, origin=(0, 0))\n",
    "    tree = translate(tree, x, y)\n",
    "    return tree\n",
    "\n",
    "def get_bounding_box_side(trees_df):\n",
    "    \"\"\"Calculate the side length of the bounding square for a set of trees\"\"\"\n",
    "    polygons = []\n",
    "    for _, row in trees_df.iterrows():\n",
    "        poly = create_tree_polygon(row['x_val'], row['y_val'], row['deg_val'])\n",
    "        polygons.append(poly)\n",
    "    \n",
    "    # Get overall bounds\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for poly in polygons:\n",
    "        minx, miny, maxx, maxy = poly.bounds\n",
    "        all_x.extend([minx, maxx])\n",
    "        all_y.extend([miny, maxy])\n",
    "    \n",
    "    width = max(all_x) - min(all_x)\n",
    "    height = max(all_y) - min(all_y)\n",
    "    \n",
    "    return max(width, height)\n",
    "\n",
    "def calculate_total_score(df):\n",
    "    \"\"\"Calculate total score for a submission\"\"\"\n",
    "    total_score = 0\n",
    "    side_lengths = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        trees_n = df[df['n'] == n]\n",
    "        if len(trees_n) != n:\n",
    "            print(f\"Warning: n={n} has {len(trees_n)} trees instead of {n}\")\n",
    "            continue\n",
    "        \n",
    "        side = get_bounding_box_side(trees_n)\n",
    "        side_lengths[n] = side\n",
    "        score_n = side ** 2 / n\n",
    "        total_score += score_n\n",
    "    \n",
    "    return total_score, side_lengths\n",
    "\n",
    "# Calculate scores for both datasets\n",
    "print(\"Calculating score for saspav dataset...\")\n",
    "score_saspav, sides_saspav = calculate_total_score(df_saspav)\n",
    "print(f\"saspav score: {score_saspav:.6f}\")\n",
    "\n",
    "print(\"\\nCalculating score for bucket-of-chump dataset...\")\n",
    "score_bucket, sides_bucket = calculate_total_score(df_bucket)\n",
    "print(f\"bucket-of-chump score: {score_bucket:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlaps in the better solution\n",
    "def check_overlaps(trees_df):\n",
    "    \"\"\"Check if any trees overlap\"\"\"\n",
    "    polygons = []\n",
    "    for _, row in trees_df.iterrows():\n",
    "        poly = create_tree_polygon(row['x_val'], row['y_val'], row['deg_val'])\n",
    "        polygons.append(poly)\n",
    "    \n",
    "    # Use STRtree for efficient spatial queries\n",
    "    tree_index = STRtree(polygons)\n",
    "    \n",
    "    overlaps = []\n",
    "    for i, poly in enumerate(polygons):\n",
    "        candidates = tree_index.query(poly)\n",
    "        for j in candidates:\n",
    "            if j > i:  # Only check each pair once\n",
    "                if poly.intersects(polygons[j]) and not poly.touches(polygons[j]):\n",
    "                    # Check if it's a real overlap (not just touching)\n",
    "                    intersection = poly.intersection(polygons[j])\n",
    "                    if intersection.area > 1e-10:\n",
    "                        overlaps.append((i, j, intersection.area))\n",
    "    \n",
    "    return overlaps\n",
    "\n",
    "# Use the better solution\n",
    "if score_saspav <= score_bucket:\n",
    "    best_df = df_saspav\n",
    "    best_score = score_saspav\n",
    "    best_name = 'saspav'\n",
    "else:\n",
    "    best_df = df_bucket\n",
    "    best_score = score_bucket\n",
    "    best_name = 'bucket-of-chump'\n",
    "\n",
    "print(f\"Best solution: {best_name} with score {best_score:.6f}\")\n",
    "\n",
    "# Check overlaps for a few N values\n",
    "print(\"\\nChecking for overlaps in sample configurations...\")\n",
    "for n in [10, 50, 100, 150, 200]:\n",
    "    trees_n = best_df[best_df['n'] == n]\n",
    "    overlaps = check_overlaps(trees_n)\n",
    "    if overlaps:\n",
    "        print(f\"  n={n}: {len(overlaps)} overlaps found!\")\n",
    "    else:\n",
    "        print(f\"  n={n}: No overlaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement fix_direction optimization\n",
    "def get_all_points(trees_df):\n",
    "    \"\"\"Get all vertices from all tree polygons\"\"\"\n",
    "    points = []\n",
    "    for _, row in trees_df.iterrows():\n",
    "        poly = create_tree_polygon(row['x_val'], row['y_val'], row['deg_val'])\n",
    "        coords = list(poly.exterior.coords)\n",
    "        points.extend(coords)\n",
    "    return np.array(points)\n",
    "\n",
    "def rotate_points(points, angle):\n",
    "    \"\"\"Rotate points around origin by angle (in degrees)\"\"\"\n",
    "    theta = np.radians(angle)\n",
    "    cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "    rotation_matrix = np.array([[cos_t, -sin_t], [sin_t, cos_t]])\n",
    "    return points @ rotation_matrix.T\n",
    "\n",
    "def get_bbox_side_from_points(points):\n",
    "    \"\"\"Get bounding box side length from points\"\"\"\n",
    "    min_x, min_y = points.min(axis=0)\n",
    "    max_x, max_y = points.max(axis=0)\n",
    "    return max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "def optimize_rotation(trees_df):\n",
    "    \"\"\"Find optimal global rotation to minimize bounding box\"\"\"\n",
    "    points = get_all_points(trees_df)\n",
    "    \n",
    "    def objective(angle):\n",
    "        rotated = rotate_points(points, angle)\n",
    "        return get_bbox_side_from_points(rotated)\n",
    "    \n",
    "    # Search in range [0, 90] due to symmetry\n",
    "    result = minimize_scalar(objective, bounds=(0, 90), method='bounded')\n",
    "    \n",
    "    return result.x, result.fun\n",
    "\n",
    "# Test fix_direction on a few configurations\n",
    "print(\"Testing fix_direction optimization...\")\n",
    "for n in [50, 100, 150, 200]:\n",
    "    trees_n = best_df[best_df['n'] == n]\n",
    "    original_side = get_bounding_box_side(trees_n)\n",
    "    optimal_angle, optimal_side = optimize_rotation(trees_n)\n",
    "    improvement = (original_side - optimal_side) / original_side * 100\n",
    "    print(f\"  n={n}: original={original_side:.6f}, optimal={optimal_side:.6f} at {optimal_angle:.2f}Â°, improvement={improvement:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fix_direction to all configurations and recalculate score\n",
    "def apply_fix_direction_to_all(df):\n",
    "    \"\"\"Apply fix_direction optimization to all N configurations\"\"\"\n",
    "    new_rows = []\n",
    "    total_score = 0\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        trees_n = df[df['n'] == n].copy()\n",
    "        \n",
    "        # Get optimal rotation\n",
    "        optimal_angle, optimal_side = optimize_rotation(trees_n)\n",
    "        \n",
    "        # Apply rotation to all trees in this configuration\n",
    "        for _, row in trees_n.iterrows():\n",
    "            # Rotate position around origin\n",
    "            x, y = row['x_val'], row['y_val']\n",
    "            theta = np.radians(optimal_angle)\n",
    "            new_x = x * np.cos(theta) - y * np.sin(theta)\n",
    "            new_y = x * np.sin(theta) + y * np.cos(theta)\n",
    "            \n",
    "            # Add rotation to tree angle\n",
    "            new_deg = row['deg_val'] + optimal_angle\n",
    "            \n",
    "            new_rows.append({\n",
    "                'id': row['id'],\n",
    "                'x': f\"s{new_x}\",\n",
    "                'y': f\"s{new_y}\",\n",
    "                'deg': f\"s{new_deg}\",\n",
    "                'n': n,\n",
    "                'tree_idx': row['tree_idx'],\n",
    "                'x_val': new_x,\n",
    "                'y_val': new_y,\n",
    "                'deg_val': new_deg\n",
    "            })\n",
    "        \n",
    "        score_n = optimal_side ** 2 / n\n",
    "        total_score += score_n\n",
    "        \n",
    "        if n % 50 == 0:\n",
    "            print(f\"  Processed n={n}, running score: {total_score:.6f}\")\n",
    "    \n",
    "    return pd.DataFrame(new_rows), total_score\n",
    "\n",
    "print(\"Applying fix_direction to all configurations...\")\n",
    "optimized_df, optimized_score = apply_fix_direction_to_all(best_df)\n",
    "print(f\"\\nOriginal score: {best_score:.6f}\")\n",
    "print(f\"Optimized score: {optimized_score:.6f}\")\n",
    "print(f\"Improvement: {best_score - optimized_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the optimized solution\n",
    "print(\"Validating optimized solution...\")\n",
    "print(\"Checking for overlaps in all configurations...\")\n",
    "\n",
    "all_valid = True\n",
    "for n in range(1, 201):\n",
    "    trees_n = optimized_df[optimized_df['n'] == n]\n",
    "    overlaps = check_overlaps(trees_n)\n",
    "    if overlaps:\n",
    "        print(f\"  n={n}: {len(overlaps)} overlaps found!\")\n",
    "        all_valid = False\n",
    "\n",
    "if all_valid:\n",
    "    print(\"All configurations are valid (no overlaps)!\")\n",
    "else:\n",
    "    print(\"Some configurations have overlaps - need to fix!\")\n",
    "\n",
    "# Recalculate score to verify\n",
    "verify_score, verify_sides = calculate_total_score(optimized_df)\n",
    "print(f\"\\nVerified score: {verify_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "def create_submission(df, filepath):\n",
    "    \"\"\"Create submission CSV file\"\"\"\n",
    "    # Sort by id to ensure correct order\n",
    "    df_sorted = df.sort_values('id')\n",
    "    \n",
    "    # Create submission dataframe with correct format\n",
    "    submission = df_sorted[['id', 'x', 'y', 'deg']].copy()\n",
    "    \n",
    "    submission.to_csv(filepath, index=False)\n",
    "    print(f\"Submission saved to {filepath}\")\n",
    "    print(f\"Total rows: {len(submission)}\")\n",
    "    return submission\n",
    "\n",
    "# Save submission\n",
    "submission = create_submission(optimized_df, '/home/submission/submission.csv')\n",
    "\n",
    "# Also save to experiment folder\n",
    "submission.to_csv('/home/code/experiments/001_baseline/submission.csv', index=False)\n",
    "\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 001: BASELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best pre-optimized solution: {best_name}\")\n",
    "print(f\"Original score: {best_score:.6f}\")\n",
    "print(f\"After fix_direction: {optimized_score:.6f}\")\n",
    "print(f\"Improvement: {best_score - optimized_score:.6f}\")\n",
    "print(f\"Target score: 68.922808\")\n",
    "print(f\"Gap to target: {optimized_score - 68.922808:.6f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'original_score': best_score,\n",
    "    'optimized_score': optimized_score,\n",
    "    'improvement': best_score - optimized_score,\n",
    "    'source': best_name,\n",
    "    'target': 68.922808\n",
    "}\n",
    "with open('/home/code/experiments/001_baseline/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"\\nMetrics saved to metrics.json\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
