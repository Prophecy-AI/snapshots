## What I Understood

The junior researcher attempted experiment 007 (007_long_cpp_optimization) which ran the tree_packer_v18 C++ optimizer with 1,000,000 iterations and 100 restarts (10x longer than previous runs). The goal was to see if longer optimization runs could break through the local optimum that the saspav baseline solution appears to be at. The result: essentially zero improvement (3.5e-9 improvement, which is numerical noise). This is the 7th consecutive experiment with no improvement over the baseline score of 70.676102.

## Technical Execution Assessment

**Validation**: Score calculation is verified correct. The baseline score of 70.676102 matches the LB submission exactly (70.676102398091).

**Leakage Risk**: None - this is an optimization problem, not a prediction task.

**Score Integrity**: Verified in metrics.json:
- Baseline score: 70.67610239809186
- Optimized score: 70.67610239460683
- Improvement: 3.485e-09 (essentially zero)
- Optimizer: tree_packer_v18 with 1,000,000 iterations, 100 restarts

**Code Quality**: The experiment ran correctly. The C++ optimizer executed as intended.

Verdict: **TRUSTWORTHY** - The results are valid. The tree_packer_v18 optimizer genuinely cannot improve the baseline.

## Strategic Assessment

**Approach Fit**: ⚠️ **CRITICAL MISMATCH IDENTIFIED**

After reviewing the research kernels, I've identified a key missing technique:

The **jonathanchan kernel** uses a sophisticated C++ optimizer with THREE key components:
1. `sa_v3` - Simulated annealing with proper temperature schedule (T0=1.0, T_min=0.000005, alpha=0.25)
2. `ls_v3` - Local search with 300 iterations
3. **`fractional_translation`** - Fine-grained position adjustments with step sizes from 0.001 down to 0.00001

The `fractional_translation` function is **NOT present in tree_packer_v18**. This function:
```cpp
Cfg fractional_translation(Cfg c, int max_iter = 200) {
    double frac_steps[] = {0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001};
    double dx[] = {0, 0, 1, -1, 1, 1, -1, -1};
    double dy[] = {1, -1, 0, 0, 1, -1, 1, -1};
    // Tries all 8 directions at each step size for each tree
    // Keeps improvements that reduce bounding box
}
```

This is a **micro-optimization** technique that makes tiny adjustments (down to 0.00001 units) to tree positions. The saspav solution may be at a local optimum for large moves but could still be improved by these micro-adjustments.

**Effort Allocation**: 
- ❌ 7 experiments have been run, all producing the same score of 70.676102
- ❌ The gap to target (1.75 points = 2.5%) remains unchanged
- ❌ Time is being spent on the WRONG optimizer (tree_packer_v18 lacks fractional_translation)
- ❌ The jonathanchan kernel's C++ optimizer has NOT been tried

**Assumptions Being Made**:
1. **WRONG**: That tree_packer_v18 is equivalent to the jonathanchan optimizer
2. **WRONG**: That longer runs of the same optimizer will find improvements
3. **UNVALIDATED**: That the saspav solution cannot be improved by micro-adjustments

**Blind Spots - CRITICAL**:

### 1. **The jonathanchan C++ optimizer has NOT been tried**
The jonathanchan kernel contains a complete C++ optimizer (`sa_v1_parallel.cpp`) that includes:
- `sa_v3` - Proper SA with temperature schedule
- `ls_v3` - Local search refinement
- `fractional_translation` - Micro-position adjustments
- `opt_v3` - Multi-restart with population selection

This optimizer runs for ~30 minutes and produces continuous improvements. The kernel shows:
```
71.65 -> 71.46 # SA workflow
71.46 -> 71.45 # guided refinement
71.45 -> 71.36 # SA workflow again
```

### 2. **The tree_packer_v18 is missing key techniques**
Comparing tree_packer_v18 to jonathanchan's optimizer:
- ✅ Both have SA
- ✅ Both have local search
- ❌ tree_packer_v18 LACKS fractional_translation
- ❌ tree_packer_v18 LACKS population-based selection

### 3. **The second submission failed with "Overlapping trees in group 040"**
This indicates a potential bug in the ensemble code or overlap detection. This needs investigation.

### 4. **Per-N optimization parameters matter**
The jonathanchan kernel uses different parameters for different N ranges:
```cpp
if (n <= 20) { r = max(6, nr); it = int(si * 1.5); }
else if (n <= 50) { r = max(5, nr); it = int(si * 1.3); }
else if (n > 150) { r = max(4, nr); it = int(si * 0.8); }
```

This adaptive approach may be important for finding improvements.

**Trajectory**: The current line of inquiry (tree_packer_v18) has hit a dead end. After 7 experiments with no improvement, it's time to **PIVOT to the jonathanchan optimizer**.

## What's Working

1. **Score calculation**: Verified to match LB exactly (CV=70.676102, LB=70.676102398091)
2. **Baseline solution**: The saspav solution is a strong starting point
3. **Understanding of the problem**: The team now knows that tree_packer_v18 cannot beat the baseline
4. **Research kernels**: The jonathanchan kernel has been identified as having key missing techniques

## Key Concerns

### 1. **Wrong optimizer being used** (CRITICAL)
- **Observation**: tree_packer_v18 lacks `fractional_translation` which is a key technique in the jonathanchan kernel
- **Why it matters**: Micro-adjustments (0.001 to 0.00001 step sizes) may find improvements that larger moves miss
- **Suggestion**: Extract and compile the jonathanchan C++ optimizer (`sa_v1_parallel.cpp`) and run it on the saspav baseline

### 2. **Second submission failed with overlap error** (HIGH Priority)
- **Observation**: Submission 2 failed with "Overlapping trees in group 040"
- **Why it matters**: This indicates a bug in the ensemble code or overlap detection
- **Suggestion**: Investigate the ensemble code and verify overlap detection before submitting

### 3. **No progress after 7 experiments** (STRATEGIC)
- **Observation**: All 7 experiments have the same score of 70.676102
- **Why it matters**: The current approach is not working
- **Suggestion**: PIVOT to a fundamentally different approach (jonathanchan optimizer)

### 4. **Target gap is significant** (STRATEGIC)
- **Observation**: 2.5% improvement needed (1.75 points)
- **Why it matters**: This requires finding improvements across many N values
- **Suggestion**: Focus on the jonathanchan optimizer which has shown continuous improvements

## Top Priority for Next Experiment

**PIVOT: Use the jonathanchan C++ optimizer with fractional_translation**

The jonathanchan kernel (`/home/code/research/kernels/jonathanchan_santa25-ensemble-sa-fractional-translation/`) contains a complete C++ optimizer that includes the key missing technique: `fractional_translation`.

### Recommended Steps:

1. **Extract the C++ code** from the jonathanchan notebook:
   - The notebook contains `sa_v1_parallel.cpp` embedded in a cell
   - This includes `sa_v3`, `ls_v3`, `fractional_translation`, and `opt_v3`

2. **Compile and run**:
   ```bash
   g++ -O3 -march=native -std=c++17 -fopenmp -o sa_v1_parallel sa_v1_parallel.cpp
   ./sa_v1_parallel -i /home/code/santa-2025-csv/santa-2025.csv -n 50000 -r 80
   ```

3. **Key parameters** from the kernel:
   - `-n 50000` (iterations per restart)
   - `-r 80` (number of restarts)
   - Uses adaptive parameters for different N ranges
   - Runs `fractional_translation` with 120-150 iterations after each SA run

4. **Expected outcome**:
   - The kernel shows continuous improvements over multiple generations
   - Even small improvements (0.01-0.1 per N) can add up to significant total improvement

### Alternative: Implement fractional_translation in Python

If extracting the C++ code is difficult, implement `fractional_translation` in Python/Numba:
```python
@njit
def fractional_translation(xs, ys, degs, max_iter=200):
    frac_steps = [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
    dx = [0, 0, 1, -1, 1, 1, -1, -1]
    dy = [1, -1, 0, 0, 1, -1, 1, -1]
    # For each tree, try all 8 directions at each step size
    # Keep improvements that reduce bounding box
```

**IMPORTANT**: The target of 68.922808 requires ~2.5% improvement. The jonathanchan optimizer has shown it can produce continuous improvements. This is the most promising path forward.
