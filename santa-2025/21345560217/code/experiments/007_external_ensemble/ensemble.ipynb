{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f024e24",
   "metadata": {},
   "source": [
    "# Experiment 007: External Sources Ensemble\n",
    "\n",
    "The evaluator identified that top kernels use 15+ external sources.\n",
    "We have access to many pre-optimized solutions from:\n",
    "- bucket-of-chump (Kaggle dataset)\n",
    "- santa25-public (Kaggle dataset)\n",
    "- telegram shared solutions\n",
    "- chistyakov's packed version\n",
    "\n",
    "Strategy:\n",
    "1. Load ALL external sources\n",
    "2. Validate each for overlaps (STRICT)\n",
    "3. Select best per-N from all valid sources\n",
    "4. Create ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b90189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.588102Z",
     "iopub.status.busy": "2026-01-26T05:28:01.587527Z",
     "iopub.status.idle": "2026-01-26T05:28:01.879372Z",
     "shell.execute_reply": "2026-01-26T05:28:01.878974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "from decimal import Decimal, getcontext\n",
    "import glob\n",
    "\n",
    "# Set high precision for validation\n",
    "getcontext().prec = 30\n",
    "SCALE = 10**18\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc0a738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.880537Z",
     "iopub.status.busy": "2026-01-26T05:28:01.880391Z",
     "iopub.status.idle": "2026-01-26T05:28:01.885805Z",
     "shell.execute_reply": "2026-01-26T05:28:01.885420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_tree_polygon(x, y, deg):\n",
    "    \"\"\"Create a tree polygon at position (x, y) with rotation deg.\"\"\"\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    rotated = affinity.rotate(poly, deg, origin=(0, 0))\n",
    "    return affinity.translate(rotated, x, y)\n",
    "\n",
    "def has_any_overlap_strict(trees):\n",
    "    \"\"\"Check if any trees overlap using STRICT integer-scaled validation.\"\"\"\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    \n",
    "    polys = [create_tree_polygon(t[0], t[1], t[2]) for t in trees]\n",
    "    \n",
    "    for i in range(len(polys)):\n",
    "        for j in range(i+1, len(polys)):\n",
    "            if polys[i].intersects(polys[j]) and not polys[i].touches(polys[j]):\n",
    "                intersection = polys[i].intersection(polys[j])\n",
    "                if intersection.area > 1e-15:  # Very strict threshold\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def calculate_score(trees, n):\n",
    "    \"\"\"Calculate score for a configuration.\"\"\"\n",
    "    if not trees:\n",
    "        return float('inf')\n",
    "    polys = [create_tree_polygon(t[0], t[1], t[2]) for t in trees]\n",
    "    bounds = unary_union(polys).bounds\n",
    "    side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "    return side ** 2 / n\n",
    "\n",
    "print(\"Validation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d004c575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.886637Z",
     "iopub.status.busy": "2026-01-26T05:28:01.886532Z",
     "iopub.status.idle": "2026-01-26T05:28:01.890166Z",
     "shell.execute_reply": "2026-01-26T05:28:01.889814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load function defined\n"
     ]
    }
   ],
   "source": [
    "def load_submission(filepath):\n",
    "    \"\"\"Load a submission CSV and return configs per N.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        configs = defaultdict(list)\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            n = int(row['id'].split('_')[0])\n",
    "            x = float(str(row['x']).replace('s', ''))\n",
    "            y = float(str(row['y']).replace('s', ''))\n",
    "            deg = float(str(row['deg']).replace('s', ''))\n",
    "            configs[n].append([x, y, deg])\n",
    "        \n",
    "        return dict(configs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return {}\n",
    "\n",
    "print(\"Load function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ca0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.891139Z",
     "iopub.status.busy": "2026-01-26T05:28:01.891037Z",
     "iopub.status.idle": "2026-01-26T05:28:01.896375Z",
     "shell.execute_reply": "2026-01-26T05:28:01.896048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 external source files\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/best_ensemble.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/ensemble.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/submission.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump/submission.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT4.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/New_Tree_144_196.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT3.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/santa2025_ver2_v61.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT2.csv\n",
      "  ... and 69 more\n"
     ]
    }
   ],
   "source": [
    "# Find ALL CSV files from external sources\n",
    "external_sources = []\n",
    "\n",
    "# Preoptimized directory\n",
    "preopt_base = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "\n",
    "# Direct files\n",
    "for f in ['best_ensemble.csv', 'ensemble.csv', 'santa-2025.csv', 'submission.csv']:\n",
    "    path = os.path.join(preopt_base, f)\n",
    "    if os.path.exists(path):\n",
    "        external_sources.append(path)\n",
    "\n",
    "# Subdirectories\n",
    "for subdir in ['bucket-of-chump', 'santa25-public', 'telegram', 'telegram/telegram_extracted', \n",
    "               'chistyakov', 'blended', 'santa-2025-csv', 'santa-2025-try3']:\n",
    "    dirpath = os.path.join(preopt_base, subdir)\n",
    "    if os.path.isdir(dirpath):\n",
    "        for f in os.listdir(dirpath):\n",
    "            if f.endswith('.csv'):\n",
    "                external_sources.append(os.path.join(dirpath, f))\n",
    "\n",
    "# Also check other snapshots for good solutions\n",
    "for snapshot_dir in glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission.csv'):\n",
    "    external_sources.append(snapshot_dir)\n",
    "\n",
    "print(f\"Found {len(external_sources)} external source files\")\n",
    "for src in external_sources[:10]:\n",
    "    print(f\"  - {src}\")\n",
    "if len(external_sources) > 10:\n",
    "    print(f\"  ... and {len(external_sources) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bdf134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.897263Z",
     "iopub.status.busy": "2026-01-26T05:28:01.897173Z",
     "iopub.status.idle": "2026-01-26T05:28:05.452294Z",
     "shell.execute_reply": "2026-01-26T05:28:05.451918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline total score: 70.615102\n",
      "Baseline N=1-10: 4.329128\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_path = '/home/code/experiments/002_valid_baseline/submission.csv'\n",
    "baseline_configs = load_submission(baseline_path)\n",
    "\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    if n in baseline_configs:\n",
    "        baseline_scores[n] = calculate_score(baseline_configs[n], n)\n",
    "\n",
    "print(f\"Baseline total score: {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"Baseline N=1-10: {sum(baseline_scores[n] for n in range(1, 11)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd448ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best per-N with baseline\n",
    "best_per_n = {}\n",
    "for n in range(1, 201):\n",
    "    best_per_n[n] = {\n",
    "        'score': baseline_scores[n],\n",
    "        'config': baseline_configs[n],\n",
    "        'source': 'baseline',\n",
    "        'valid': True\n",
    "    }\n",
    "\n",
    "print(f\"Initialized best_per_n with baseline\")\n",
    "print(f\"Initial total: {sum(best_per_n[n]['score'] for n in range(1, 201)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each external source\n",
    "improvements = []\n",
    "processed = 0\n",
    "\n",
    "for filepath in external_sources:\n",
    "    configs = load_submission(filepath)\n",
    "    if not configs:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    source_name = os.path.basename(filepath)\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        if n not in configs or len(configs[n]) != n:\n",
    "            continue\n",
    "        \n",
    "        # Calculate score first (fast)\n",
    "        score = calculate_score(configs[n], n)\n",
    "        \n",
    "        # Only validate if potentially better\n",
    "        if score < best_per_n[n]['score'] - 1e-8:\n",
    "            # Strict overlap validation\n",
    "            if not has_any_overlap_strict(configs[n]):\n",
    "                improvement = best_per_n[n]['score'] - score\n",
    "                improvements.append((n, improvement, source_name))\n",
    "                print(f\"✅ N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} (improved by {improvement:.6f}) from {source_name}\")\n",
    "                best_per_n[n] = {\n",
    "                    'score': score,\n",
    "                    'config': configs[n],\n",
    "                    'source': source_name,\n",
    "                    'valid': True\n",
    "                }\n",
    "    \n",
    "    if processed % 20 == 0:\n",
    "        print(f\"Processed {processed}/{len(external_sources)} files...\")\n",
    "\n",
    "print(f\"\\nProcessed {processed} files\")\n",
    "print(f\"Found {len(improvements)} improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56794c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of improvements\n",
    "if improvements:\n",
    "    print(\"\\nImprovements found:\")\n",
    "    print(\"=\"*60)\n",
    "    total_improvement = sum(imp for _, imp, _ in improvements)\n",
    "    print(f\"Total improvement: {total_improvement:.6f}\")\n",
    "    \n",
    "    # Group by source\n",
    "    by_source = defaultdict(list)\n",
    "    for n, imp, src in improvements:\n",
    "        by_source[src].append((n, imp))\n",
    "    \n",
    "    print(\"\\nBy source:\")\n",
    "    for src, imps in sorted(by_source.items(), key=lambda x: -sum(i for _, i in x[1])):\n",
    "        src_total = sum(i for _, i in imps)\n",
    "        print(f\"  {src}: {len(imps)} improvements, total {src_total:.6f}\")\n",
    "else:\n",
    "    print(\"No improvements found from external sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final ensemble score\n",
    "ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nFinal ensemble score: {ensemble_score:.6f}\")\n",
    "print(f\"Baseline score: {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"Improvement: {sum(baseline_scores.values()) - ensemble_score:.6f}\")\n",
    "\n",
    "# Score breakdown by N range\n",
    "print(\"\\nScore breakdown:\")\n",
    "for start, end in [(1, 10), (11, 50), (51, 100), (101, 150), (151, 200)]:\n",
    "    range_score = sum(best_per_n[n]['score'] for n in range(start, end+1))\n",
    "    baseline_range = sum(baseline_scores[n] for n in range(start, end+1))\n",
    "    print(f\"  N={start}-{end}: {range_score:.4f} (baseline: {baseline_range:.4f}, diff: {baseline_range - range_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313faac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    config = best_per_n[n]['config']\n",
    "    for i, (x, y, deg) in enumerate(config):\n",
    "        rows.append({\n",
    "            'id': f\"{n}_{i}\",\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'deg': deg\n",
    "        })\n",
    "\n",
    "submission_df = pd.DataFrame(rows)\n",
    "submission_df.to_csv('/home/code/experiments/007_external_ensemble/submission.csv', index=False)\n",
    "\n",
    "# Also save to submission directory\n",
    "import shutil\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy('/home/code/experiments/007_external_ensemble/submission.csv', '/home/submission/submission.csv')\n",
    "\n",
    "print(f\"Submission saved with {len(rows)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b16015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation - check a sample of N values\n",
    "print(\"\\nFinal validation (sample):\")\n",
    "for n in [1, 5, 10, 20, 50, 100, 150, 200]:\n",
    "    config = best_per_n[n]['config']\n",
    "    has_overlap = has_any_overlap_strict(config)\n",
    "    score = calculate_score(config, n)\n",
    "    source = best_per_n[n]['source']\n",
    "    status = \"❌ OVERLAP\" if has_overlap else \"✅ OK\"\n",
    "    print(f\"  N={n}: score={score:.6f}, source={source}, {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22585d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': ensemble_score,\n",
    "    'baseline_score': sum(baseline_scores.values()),\n",
    "    'improvement': sum(baseline_scores.values()) - ensemble_score,\n",
    "    'num_improvements': len(improvements),\n",
    "    'sources_processed': processed,\n",
    "    'improvements_by_n': [(n, imp, src) for n, imp, src in improvements]\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/007_external_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics saved\")\n",
    "print(f\"CV Score: {ensemble_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
