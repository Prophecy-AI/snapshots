{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f024e24",
   "metadata": {},
   "source": [
    "# Experiment 007: External Sources Ensemble\n",
    "\n",
    "The evaluator identified that top kernels use 15+ external sources.\n",
    "We have access to many pre-optimized solutions from:\n",
    "- bucket-of-chump (Kaggle dataset)\n",
    "- santa25-public (Kaggle dataset)\n",
    "- telegram shared solutions\n",
    "- chistyakov's packed version\n",
    "\n",
    "Strategy:\n",
    "1. Load ALL external sources\n",
    "2. Validate each for overlaps (STRICT)\n",
    "3. Select best per-N from all valid sources\n",
    "4. Create ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b90189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.588102Z",
     "iopub.status.busy": "2026-01-26T05:28:01.587527Z",
     "iopub.status.idle": "2026-01-26T05:28:01.879372Z",
     "shell.execute_reply": "2026-01-26T05:28:01.878974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.ops import unary_union\n",
    "from decimal import Decimal, getcontext\n",
    "import glob\n",
    "\n",
    "# Set high precision for validation\n",
    "getcontext().prec = 30\n",
    "SCALE = 10**18\n",
    "\n",
    "# Tree polygon vertices\n",
    "TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]\n",
    "TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc0a738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.880537Z",
     "iopub.status.busy": "2026-01-26T05:28:01.880391Z",
     "iopub.status.idle": "2026-01-26T05:28:01.885805Z",
     "shell.execute_reply": "2026-01-26T05:28:01.885420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_tree_polygon(x, y, deg):\n",
    "    \"\"\"Create a tree polygon at position (x, y) with rotation deg.\"\"\"\n",
    "    poly = Polygon(zip(TX, TY))\n",
    "    rotated = affinity.rotate(poly, deg, origin=(0, 0))\n",
    "    return affinity.translate(rotated, x, y)\n",
    "\n",
    "def has_any_overlap_strict(trees):\n",
    "    \"\"\"Check if any trees overlap using STRICT integer-scaled validation.\"\"\"\n",
    "    if len(trees) <= 1:\n",
    "        return False\n",
    "    \n",
    "    polys = [create_tree_polygon(t[0], t[1], t[2]) for t in trees]\n",
    "    \n",
    "    for i in range(len(polys)):\n",
    "        for j in range(i+1, len(polys)):\n",
    "            if polys[i].intersects(polys[j]) and not polys[i].touches(polys[j]):\n",
    "                intersection = polys[i].intersection(polys[j])\n",
    "                if intersection.area > 1e-15:  # Very strict threshold\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def calculate_score(trees, n):\n",
    "    \"\"\"Calculate score for a configuration.\"\"\"\n",
    "    if not trees:\n",
    "        return float('inf')\n",
    "    polys = [create_tree_polygon(t[0], t[1], t[2]) for t in trees]\n",
    "    bounds = unary_union(polys).bounds\n",
    "    side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])\n",
    "    return side ** 2 / n\n",
    "\n",
    "print(\"Validation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d004c575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.886637Z",
     "iopub.status.busy": "2026-01-26T05:28:01.886532Z",
     "iopub.status.idle": "2026-01-26T05:28:01.890166Z",
     "shell.execute_reply": "2026-01-26T05:28:01.889814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load function defined\n"
     ]
    }
   ],
   "source": [
    "def load_submission(filepath):\n",
    "    \"\"\"Load a submission CSV and return configs per N.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        configs = defaultdict(list)\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            n = int(row['id'].split('_')[0])\n",
    "            x = float(str(row['x']).replace('s', ''))\n",
    "            y = float(str(row['y']).replace('s', ''))\n",
    "            deg = float(str(row['deg']).replace('s', ''))\n",
    "            configs[n].append([x, y, deg])\n",
    "        \n",
    "        return dict(configs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return {}\n",
    "\n",
    "print(\"Load function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ca0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.891139Z",
     "iopub.status.busy": "2026-01-26T05:28:01.891037Z",
     "iopub.status.idle": "2026-01-26T05:28:01.896375Z",
     "shell.execute_reply": "2026-01-26T05:28:01.896048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 external source files\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/best_ensemble.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/ensemble.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/submission.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump/submission.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT4.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/New_Tree_144_196.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT3.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/santa2025_ver2_v61.csv\n",
      "  - /home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa25-public/submission_JKoT2.csv\n",
      "  ... and 69 more\n"
     ]
    }
   ],
   "source": [
    "# Find ALL CSV files from external sources\n",
    "external_sources = []\n",
    "\n",
    "# Preoptimized directory\n",
    "preopt_base = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized'\n",
    "\n",
    "# Direct files\n",
    "for f in ['best_ensemble.csv', 'ensemble.csv', 'santa-2025.csv', 'submission.csv']:\n",
    "    path = os.path.join(preopt_base, f)\n",
    "    if os.path.exists(path):\n",
    "        external_sources.append(path)\n",
    "\n",
    "# Subdirectories\n",
    "for subdir in ['bucket-of-chump', 'santa25-public', 'telegram', 'telegram/telegram_extracted', \n",
    "               'chistyakov', 'blended', 'santa-2025-csv', 'santa-2025-try3']:\n",
    "    dirpath = os.path.join(preopt_base, subdir)\n",
    "    if os.path.isdir(dirpath):\n",
    "        for f in os.listdir(dirpath):\n",
    "            if f.endswith('.csv'):\n",
    "                external_sources.append(os.path.join(dirpath, f))\n",
    "\n",
    "# Also check other snapshots for good solutions\n",
    "for snapshot_dir in glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission.csv'):\n",
    "    external_sources.append(snapshot_dir)\n",
    "\n",
    "print(f\"Found {len(external_sources)} external source files\")\n",
    "for src in external_sources[:10]:\n",
    "    print(f\"  - {src}\")\n",
    "if len(external_sources) > 10:\n",
    "    print(f\"  ... and {len(external_sources) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bdf134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:01.897263Z",
     "iopub.status.busy": "2026-01-26T05:28:01.897173Z",
     "iopub.status.idle": "2026-01-26T05:28:05.452294Z",
     "shell.execute_reply": "2026-01-26T05:28:05.451918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline total score: 70.615102\n",
      "Baseline N=1-10: 4.329128\n"
     ]
    }
   ],
   "source": [
    "# Load baseline\n",
    "baseline_path = '/home/code/experiments/002_valid_baseline/submission.csv'\n",
    "baseline_configs = load_submission(baseline_path)\n",
    "\n",
    "baseline_scores = {}\n",
    "for n in range(1, 201):\n",
    "    if n in baseline_configs:\n",
    "        baseline_scores[n] = calculate_score(baseline_configs[n], n)\n",
    "\n",
    "print(f\"Baseline total score: {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"Baseline N=1-10: {sum(baseline_scores[n] for n in range(1, 11)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd448ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:13.540448Z",
     "iopub.status.busy": "2026-01-26T05:28:13.539903Z",
     "iopub.status.idle": "2026-01-26T05:28:13.543435Z",
     "shell.execute_reply": "2026-01-26T05:28:13.543069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized best_per_n with baseline\n",
      "Initial total: 70.615102\n"
     ]
    }
   ],
   "source": [
    "# Initialize best per-N with baseline\n",
    "best_per_n = {}\n",
    "for n in range(1, 201):\n",
    "    best_per_n[n] = {\n",
    "        'score': baseline_scores[n],\n",
    "        'config': baseline_configs[n],\n",
    "        'source': 'baseline',\n",
    "        'valid': True\n",
    "    }\n",
    "\n",
    "print(f\"Initialized best_per_n with baseline\")\n",
    "print(f\"Initial total: {sum(best_per_n[n]['score'] for n in range(1, 201)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a600b738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:28:13.544384Z",
     "iopub.status.busy": "2026-01-26T05:28:13.544282Z",
     "iopub.status.idle": "2026-01-26T05:32:33.212709Z",
     "shell.execute_reply": "2026-01-26T05:32:33.212263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/79 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40/79 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60/79 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 72 files\n",
      "Found 0 improvements\n"
     ]
    }
   ],
   "source": [
    "# Process each external source\n",
    "improvements = []\n",
    "processed = 0\n",
    "\n",
    "for filepath in external_sources:\n",
    "    configs = load_submission(filepath)\n",
    "    if not configs:\n",
    "        continue\n",
    "    \n",
    "    processed += 1\n",
    "    source_name = os.path.basename(filepath)\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        if n not in configs or len(configs[n]) != n:\n",
    "            continue\n",
    "        \n",
    "        # Calculate score first (fast)\n",
    "        score = calculate_score(configs[n], n)\n",
    "        \n",
    "        # Only validate if potentially better\n",
    "        if score < best_per_n[n]['score'] - 1e-8:\n",
    "            # Strict overlap validation\n",
    "            if not has_any_overlap_strict(configs[n]):\n",
    "                improvement = best_per_n[n]['score'] - score\n",
    "                improvements.append((n, improvement, source_name))\n",
    "                print(f\"✅ N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} (improved by {improvement:.6f}) from {source_name}\")\n",
    "                best_per_n[n] = {\n",
    "                    'score': score,\n",
    "                    'config': configs[n],\n",
    "                    'source': source_name,\n",
    "                    'valid': True\n",
    "                }\n",
    "    \n",
    "    if processed % 20 == 0:\n",
    "        print(f\"Processed {processed}/{len(external_sources)} files...\")\n",
    "\n",
    "print(f\"\\nProcessed {processed} files\")\n",
    "print(f\"Found {len(improvements)} improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56794c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of improvements\n",
    "if improvements:\n",
    "    print(\"\\nImprovements found:\")\n",
    "    print(\"=\"*60)\n",
    "    total_improvement = sum(imp for _, imp, _ in improvements)\n",
    "    print(f\"Total improvement: {total_improvement:.6f}\")\n",
    "    \n",
    "    # Group by source\n",
    "    by_source = defaultdict(list)\n",
    "    for n, imp, src in improvements:\n",
    "        by_source[src].append((n, imp))\n",
    "    \n",
    "    print(\"\\nBy source:\")\n",
    "    for src, imps in sorted(by_source.items(), key=lambda x: -sum(i for _, i in x[1])):\n",
    "        src_total = sum(i for _, i in imps)\n",
    "        print(f\"  {src}: {len(imps)} improvements, total {src_total:.6f}\")\n",
    "else:\n",
    "    print(\"No improvements found from external sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final ensemble score\n",
    "ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nFinal ensemble score: {ensemble_score:.6f}\")\n",
    "print(f\"Baseline score: {sum(baseline_scores.values()):.6f}\")\n",
    "print(f\"Improvement: {sum(baseline_scores.values()) - ensemble_score:.6f}\")\n",
    "\n",
    "# Score breakdown by N range\n",
    "print(\"\\nScore breakdown:\")\n",
    "for start, end in [(1, 10), (11, 50), (51, 100), (101, 150), (151, 200)]:\n",
    "    range_score = sum(best_per_n[n]['score'] for n in range(start, end+1))\n",
    "    baseline_range = sum(baseline_scores[n] for n in range(start, end+1))\n",
    "    print(f\"  N={start}-{end}: {range_score:.4f} (baseline: {baseline_range:.4f}, diff: {baseline_range - range_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313faac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    config = best_per_n[n]['config']\n",
    "    for i, (x, y, deg) in enumerate(config):\n",
    "        rows.append({\n",
    "            'id': f\"{n}_{i}\",\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'deg': deg\n",
    "        })\n",
    "\n",
    "submission_df = pd.DataFrame(rows)\n",
    "submission_df.to_csv('/home/code/experiments/007_external_ensemble/submission.csv', index=False)\n",
    "\n",
    "# Also save to submission directory\n",
    "import shutil\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "shutil.copy('/home/code/experiments/007_external_ensemble/submission.csv', '/home/submission/submission.csv')\n",
    "\n",
    "print(f\"Submission saved with {len(rows)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b16015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation - check a sample of N values\n",
    "print(\"\\nFinal validation (sample):\")\n",
    "for n in [1, 5, 10, 20, 50, 100, 150, 200]:\n",
    "    config = best_per_n[n]['config']\n",
    "    has_overlap = has_any_overlap_strict(config)\n",
    "    score = calculate_score(config, n)\n",
    "    source = best_per_n[n]['source']\n",
    "    status = \"❌ OVERLAP\" if has_overlap else \"✅ OK\"\n",
    "    print(f\"  N={n}: score={score:.6f}, source={source}, {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5194e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:32:54.795532Z",
     "iopub.status.busy": "2026-01-26T05:32:54.795000Z",
     "iopub.status.idle": "2026-01-26T05:34:05.886110Z",
     "shell.execute_reply": "2026-01-26T05:34:05.885689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking external source scores (without overlap validation):\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 external sources by score (may have overlaps):\n",
      "  70.676102 - best_ensemble.csv\n",
      "  70.676102 - ensemble.csv\n",
      "  70.676102 - santa-2025.csv\n",
      "  70.676501 - submission.csv\n",
      "  70.676501 - submission.csv\n",
      "  70.926150 - submission_70_926149550346.csv\n",
      "  70.936674 - submission_70_936673758122.csv\n",
      "  70.990692 - submission_opt1.csv\n",
      "  72.489348 - submission_JKoT2.csv\n",
      "  72.489483 - submission_JKoT1.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's check what scores the external sources have WITHOUT validation\n",
    "# to understand if they're better but invalid\n",
    "\n",
    "print(\"Checking external source scores (without overlap validation):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "source_scores = []\n",
    "for filepath in external_sources[:20]:  # Check first 20\n",
    "    configs = load_submission(filepath)\n",
    "    if not configs:\n",
    "        continue\n",
    "    \n",
    "    # Check if all N values present\n",
    "    complete = all(n in configs and len(configs[n]) == n for n in range(1, 201))\n",
    "    if not complete:\n",
    "        continue\n",
    "    \n",
    "    total_score = sum(calculate_score(configs[n], n) for n in range(1, 201))\n",
    "    source_name = os.path.basename(filepath)\n",
    "    source_scores.append((total_score, source_name))\n",
    "\n",
    "source_scores.sort()\n",
    "print(\"Top 10 external sources by score (may have overlaps):\")\n",
    "for score, name in source_scores[:10]:\n",
    "    print(f\"  {score:.6f} - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6426064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T05:34:43.076526Z",
     "iopub.status.busy": "2026-01-26T05:34:43.076116Z",
     "iopub.status.idle": "2026-01-26T06:02:48.204693Z",
     "shell.execute_reply": "2026-01-26T06:02:48.204274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 submission files to check\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading /home/nonroot/snapshots/santa-2025/21145963314/submission/submission.csv: 'deg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 submissions by score:\n",
      "  39.508442 - 21145963314/code/submission.csv\n",
      "  70.523320 - 21337353543/code/experiments/005_multi_source_ensemble/submission.csv\n",
      "  70.523320 - 21328309254/code/experiments/003_valid_ensemble/submission.csv\n",
      "  70.523320 - 21328310048/code/experiments/002_small_n_optimization/submission.csv\n",
      "  70.523320 - 21328310479/code/experiments/002_ensemble_snapshots/submission.csv\n",
      "  70.523320 - 21329068588/code/experiments/005_ensemble/submission.csv\n",
      "  70.523320 - 21345558927/code/experiments/000_baseline/submission.csv\n",
      "  70.523320 - 21345560217/code/experiments/001_baseline/submission.csv\n",
      "  70.559048 - 21156850282/code/experiments/002_ensemble_snapshots/submission.csv\n",
      "  70.572058 - 21145966992/code/experiments/001_baseline/submission.csv\n",
      "  70.572798 - 21145966992/submission/submission.csv\n",
      "  70.572798 - 21329068151/code/submission.csv\n",
      "  70.572798 - 21337353626/code/experiments/000_baseline/submission.csv\n",
      "  70.615101 - 21345558927/code/experiments/002_backward_propagation/submission.csv\n",
      "  70.615101 - 21345560217/code/experiments/004_backward_propagation/submission.csv\n",
      "  70.615102 - 21337107511/submission/submission.csv\n",
      "  70.615102 - 21345558927/code/experiments/001_valid_baseline/submission.csv\n",
      "  70.615102 - 21345558927/code/experiments/003_simulated_annealing/submission.csv\n",
      "  70.615102 - 21345558927/code/experiments/004_exhaustive_n2/submission.csv\n",
      "  70.615102 - 21345558927/code/experiments/005_nfp_placement/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Check ALL snapshot submission.csv files for better scores\n",
    "import glob\n",
    "\n",
    "all_submissions = glob.glob('/home/nonroot/snapshots/santa-2025/*/submission/submission.csv')\n",
    "all_submissions += glob.glob('/home/nonroot/snapshots/santa-2025/*/code/submission.csv')\n",
    "all_submissions += glob.glob('/home/nonroot/snapshots/santa-2025/*/code/experiments/*/submission.csv')\n",
    "\n",
    "print(f\"Found {len(all_submissions)} submission files to check\")\n",
    "\n",
    "# Check scores\n",
    "best_found = []\n",
    "for filepath in all_submissions:\n",
    "    try:\n",
    "        configs = load_submission(filepath)\n",
    "        if not configs:\n",
    "            continue\n",
    "        \n",
    "        # Check if complete\n",
    "        complete = all(n in configs and len(configs[n]) == n for n in range(1, 201))\n",
    "        if not complete:\n",
    "            continue\n",
    "        \n",
    "        total_score = sum(calculate_score(configs[n], n) for n in range(1, 201))\n",
    "        best_found.append((total_score, filepath))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "best_found.sort()\n",
    "print(f\"\\nTop 20 submissions by score:\")\n",
    "for score, path in best_found[:20]:\n",
    "    short_path = path.replace('/home/nonroot/snapshots/santa-2025/', '')\n",
    "    print(f\"  {score:.6f} - {short_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fefd0091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T06:03:29.024722Z",
     "iopub.status.busy": "2026-01-26T06:03:29.024192Z",
     "iopub.status.idle": "2026-01-26T06:03:32.555337Z",
     "shell.execute_reply": "2026-01-26T06:03:32.554878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: /home/nonroot/snapshots/santa-2025/21145963314/code/submission.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 N values\n",
      "Missing N values: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 39.508442\n",
      "\n",
      "Checking for overlaps (sample)...\n",
      "  N=1: score=1.005470, OK\n",
      "  N=5: score=0.637934, OVERLAP\n",
      "  N=10: score=0.388910, OVERLAP\n",
      "  N=20: score=0.268968, OVERLAP\n",
      "  N=50: score=0.201266, OVERLAP\n",
      "  N=100: score=0.157260, OVERLAP\n",
      "  N=150: score=0.126244, OVERLAP\n",
      "  N=200: score=0.124941, OVERLAP\n"
     ]
    }
   ],
   "source": [
    "# Check the best submission found!\n",
    "best_path = '/home/nonroot/snapshots/santa-2025/21145963314/code/submission.csv'\n",
    "print(f\"Checking: {best_path}\")\n",
    "\n",
    "best_configs = load_submission(best_path)\n",
    "print(f\"Loaded {len(best_configs)} N values\")\n",
    "\n",
    "# Check completeness\n",
    "missing = [n for n in range(1, 201) if n not in best_configs or len(best_configs[n]) != n]\n",
    "print(f\"Missing N values: {missing[:20]}...\" if len(missing) > 20 else f\"Missing N values: {missing}\")\n",
    "\n",
    "# Calculate score\n",
    "if not missing:\n",
    "    total_score = sum(calculate_score(best_configs[n], n) for n in range(1, 201))\n",
    "    print(f\"Total score: {total_score:.6f}\")\n",
    "    \n",
    "    # Check for overlaps\n",
    "    print(\"\\nChecking for overlaps (sample)...\")\n",
    "    overlap_count = 0\n",
    "    for n in [1, 5, 10, 20, 50, 100, 150, 200]:\n",
    "        has_overlap = has_any_overlap_strict(best_configs[n])\n",
    "        score = calculate_score(best_configs[n], n)\n",
    "        status = \"OVERLAP\" if has_overlap else \"OK\"\n",
    "        if has_overlap:\n",
    "            overlap_count += 1\n",
    "        print(f\"  N={n}: score={score:.6f}, {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53be266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T06:03:52.470948Z",
     "iopub.status.busy": "2026-01-26T06:03:52.470391Z",
     "iopub.status.idle": "2026-01-26T06:03:53.743755Z",
     "shell.execute_reply": "2026-01-26T06:03:53.743332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking all N values for overlaps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid N values: 1\n",
      "Invalid N values: 199\n",
      "\n",
      "Checking valid N values for improvements...\n",
      "\n",
      "Found 0 improvements from valid N values\n"
     ]
    }
   ],
   "source": [
    "# Check ALL N values for overlaps in the 39.5 submission\n",
    "print(\"Checking all N values for overlaps...\")\n",
    "valid_n = []\n",
    "invalid_n = []\n",
    "\n",
    "for n in range(1, 201):\n",
    "    has_overlap = has_any_overlap_strict(best_configs[n])\n",
    "    if has_overlap:\n",
    "        invalid_n.append(n)\n",
    "    else:\n",
    "        valid_n.append(n)\n",
    "\n",
    "print(f\"Valid N values: {len(valid_n)}\")\n",
    "print(f\"Invalid N values: {len(invalid_n)}\")\n",
    "\n",
    "# Check if any valid N values are better than baseline\n",
    "print(\"\\nChecking valid N values for improvements...\")\n",
    "improvements_from_39 = []\n",
    "for n in valid_n:\n",
    "    score = calculate_score(best_configs[n], n)\n",
    "    if score < baseline_scores[n] - 1e-8:\n",
    "        improvement = baseline_scores[n] - score\n",
    "        improvements_from_39.append((n, improvement, score, baseline_scores[n]))\n",
    "        print(f\"  N={n}: {baseline_scores[n]:.6f} -> {score:.6f} (improved by {improvement:.6f})\")\n",
    "\n",
    "print(f\"\\nFound {len(improvements_from_39)} improvements from valid N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89254fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T06:04:27.385782Z",
     "iopub.status.busy": "2026-01-26T06:04:27.385242Z",
     "iopub.status.idle": "2026-01-26T06:04:39.978751Z",
     "shell.execute_reply": "2026-01-26T06:04:39.978332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 70.523 submissions for valid improvements...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 0 improvements\n"
     ]
    }
   ],
   "source": [
    "# Check the 70.523 submissions for valid improvements\n",
    "submissions_70_5 = [\n",
    "    '/home/nonroot/snapshots/santa-2025/21337353543/code/experiments/005_multi_source_ensemble/submission.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21328309254/code/experiments/003_valid_ensemble/submission.csv',\n",
    "    '/home/nonroot/snapshots/santa-2025/21345558927/code/experiments/000_baseline/submission.csv'\n",
    "]\n",
    "\n",
    "print(\"Checking 70.523 submissions for valid improvements...\")\n",
    "all_improvements = []\n",
    "\n",
    "for filepath in submissions_70_5:\n",
    "    configs = load_submission(filepath)\n",
    "    if not configs:\n",
    "        continue\n",
    "    \n",
    "    source_name = os.path.basename(os.path.dirname(filepath))\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        if n not in configs or len(configs[n]) != n:\n",
    "            continue\n",
    "        \n",
    "        score = calculate_score(configs[n], n)\n",
    "        \n",
    "        # Only check if potentially better\n",
    "        if score < best_per_n[n]['score'] - 1e-8:\n",
    "            if not has_any_overlap_strict(configs[n]):\n",
    "                improvement = best_per_n[n]['score'] - score\n",
    "                all_improvements.append((n, improvement, score, source_name))\n",
    "                print(f\"  N={n}: {best_per_n[n]['score']:.6f} -> {score:.6f} (improved by {improvement:.6f}) from {source_name}\")\n",
    "                best_per_n[n] = {\n",
    "                    'score': score,\n",
    "                    'config': configs[n],\n",
    "                    'source': source_name,\n",
    "                    'valid': True\n",
    "                }\n",
    "\n",
    "print(f\"\\nFound {len(all_improvements)} improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5cf5bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T06:05:16.978755Z",
     "iopub.status.busy": "2026-01-26T06:05:16.978207Z",
     "iopub.status.idle": "2026-01-26T06:07:31.466211Z",
     "shell.execute_reply": "2026-01-26T06:07:31.465800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing Bottom-Left Fill Heuristic...\n",
      "============================================================\n",
      "Testing bottom-left fill on N=2-5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=2: BLF=0.679411, baseline=0.450779 (WORSE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=3: BLF=0.682941, baseline=0.434745 (WORSE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=4: BLF=0.652610, baseline=0.416545 (WORSE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  N=5: BLF=0.720092, baseline=0.416850 (WORSE)\n"
     ]
    }
   ],
   "source": [
    "# Since no external sources have valid improvements, let's try a different approach:\n",
    "# Implement a proper bottom-left constructive heuristic\n",
    "\n",
    "print(\"Implementing Bottom-Left Fill Heuristic...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def bottom_left_fill(n, angles=[0, 45, 90, 135, 180, 225, 270, 315]):\n",
    "    \"\"\"Place trees using bottom-left fill heuristic with multiple angle options.\"\"\"\n",
    "    trees = []\n",
    "    \n",
    "    # First tree at origin with best angle\n",
    "    best_first = None\n",
    "    best_first_score = float('inf')\n",
    "    for angle in angles:\n",
    "        test_tree = [[0, 0, angle]]\n",
    "        score = calculate_score(test_tree, 1)\n",
    "        if score < best_first_score:\n",
    "            best_first_score = score\n",
    "            best_first = [0, 0, angle]\n",
    "    \n",
    "    trees.append(best_first)\n",
    "    \n",
    "    # Place remaining trees\n",
    "    for i in range(1, n):\n",
    "        best_pos = None\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        # Try different positions and angles\n",
    "        for angle in angles:\n",
    "            # Try positions in a grid around existing trees\n",
    "            for dx in np.arange(-3, 3, 0.1):\n",
    "                for dy in np.arange(-3, 3, 0.1):\n",
    "                    test_trees = [list(t) for t in trees] + [[dx, dy, angle]]\n",
    "                    \n",
    "                    # Check for overlaps\n",
    "                    if has_any_overlap_strict(test_trees):\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate score\n",
    "                    score = calculate_score(test_trees, i + 1)\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best_pos = [dx, dy, angle]\n",
    "        \n",
    "        if best_pos is None:\n",
    "            print(f\"  Could not place tree {i+1}\")\n",
    "            return None, float('inf')\n",
    "        \n",
    "        trees.append(best_pos)\n",
    "    \n",
    "    return trees, calculate_score(trees, n)\n",
    "\n",
    "# Test on small N\n",
    "print(\"Testing bottom-left fill on N=2-5...\")\n",
    "for n in range(2, 6):\n",
    "    trees, score = bottom_left_fill(n)\n",
    "    if trees:\n",
    "        baseline_score = baseline_scores[n]\n",
    "        status = \"BETTER\" if score < baseline_score else \"WORSE\"\n",
    "        print(f\"  N={n}: BLF={score:.6f}, baseline={baseline_score:.6f} ({status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22585d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': ensemble_score,\n",
    "    'baseline_score': sum(baseline_scores.values()),\n",
    "    'improvement': sum(baseline_scores.values()) - ensemble_score,\n",
    "    'num_improvements': len(improvements),\n",
    "    'sources_processed': processed,\n",
    "    'improvements_by_n': [(n, imp, src) for n, imp, src in improvements]\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/007_external_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics saved\")\n",
    "print(f\"CV Score: {ensemble_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
