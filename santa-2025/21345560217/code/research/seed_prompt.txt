# Santa 2025 - Christmas Tree Packing Challenge Seed Prompt

## Current Status
- Best CV score: 70.615101 from exp_003 (004_backward_propagation)
- Best LB score: 70.615102 (exp_001, 002_valid_baseline)
- Target: 68.881647 | Gap to target: 1.73 points (2.5%)
- Submissions used: 2/100 (98 remaining)

## ⚠️ CRITICAL SITUATION: STUCK AT LOCAL OPTIMUM

**Last 3 experiments produced IDENTICAL scores (~70.615):**
- exp_001: 70.615102 (valid baseline)
- exp_002: 70.615102 (fractional translation - NO improvement)
- exp_003: 70.615101 (backward propagation - NO improvement)

**This proves:** Local search CANNOT improve the baseline. We need fundamentally different approaches.

## Submission Log
| Exp | Approach | CV | LB | Notes |
|-----|----------|----|----|-------|
| 000 | baseline | 70.523 | REJECTED | Had 69 N values with overlaps |
| 001 | valid_baseline | 70.615 | 70.615 | From snapshot 21345558927 |
| 002 | fractional_translation | 70.615 | - | NO improvement |
| 003 | backward_propagation | 70.615 | - | NO improvement |

## Response to Evaluator

The evaluator correctly identified that:
1. **Local search is exhausted** - Two experiments with zero improvement confirms the baseline is at a strong local optimum
2. **Per-N ensemble was NOT properly implemented** - The notes claim ensemble was tried but there's no evidence of systematic scanning of all 116 snapshots
3. **Simulated annealing has NOT been tried** - SA can escape local optima by accepting worse moves probabilistically

**I agree with the evaluator's top priority:** Implement proper per-N ensemble from 116 snapshots FIRST, then try simulated annealing if that doesn't work.

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast_v2, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files with any tool - FORBIDDEN
- Running "more iterations" on any optimizer - FORBIDDEN

## ✅ EXPERIMENT 005: PROPER PER-N ENSEMBLE FROM 116 SNAPSHOTS

**This is the HIGHEST-LEVERAGE, LOWEST-RISK improvement available.**

### Why This Will Work:
1. We have 116 snapshots from previous optimization runs
2. Different runs may have found better solutions for different N values
3. Top kernels achieve their scores primarily through ensemble
4. The jonathanchan kernel combines solutions from 15+ sources

### Implementation (MUST DO THIS):

```python
import os
import pandas as pd
import math
from collections import defaultdict

# Tree shape constants
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]

def get_polygon_bounds(cx, cy, deg):
    """Calculate bounding box of rotated tree polygon"""
    rad = deg * math.pi / 180.0
    s, c = math.sin(rad), math.cos(rad)
    x_coords = [TX[i] * c - TY[i] * s + cx for i in range(len(TX))]
    y_coords = [TX[i] * s + TY[i] * c + cy for i in range(len(TX))]
    return min(x_coords), max(x_coords), min(y_coords), max(y_coords)

def calculate_score_for_n(trees):
    """Calculate score for a single N configuration"""
    if not trees:
        return float('inf')
    
    global_x_min, global_x_max = float('inf'), float('-inf')
    global_y_min, global_y_max = float('inf'), float('-inf')
    
    for idx, cx, cy, deg in trees:
        x_min, x_max, y_min, y_max = get_polygon_bounds(cx, cy, deg)
        global_x_min = min(global_x_min, x_min)
        global_x_max = max(global_x_max, x_max)
        global_y_min = min(global_y_min, y_min)
        global_y_max = max(global_y_max, y_max)
    
    side = max(global_x_max - global_x_min, global_y_max - global_y_min)
    return side * side / len(trees)

def load_submission(filepath):
    """Load submission file, returns dict mapping n -> list of (idx, x, y, deg)"""
    configurations = defaultdict(list)
    try:
        df = pd.read_csv(filepath)
        for _, row in df.iterrows():
            id_parts = row['id'].split('_')
            n = int(id_parts[0])
            idx = int(id_parts[1])
            x = float(str(row['x']).replace('s', ''))
            y = float(str(row['y']).replace('s', ''))
            deg = float(str(row['deg']).replace('s', ''))
            configurations[n].append((idx, x, y, deg))
        for n in configurations:
            configurations[n].sort(key=lambda t: t[0])
        return dict(configurations)
    except Exception as e:
        return {}

# SCAN ALL 116 SNAPSHOTS
SNAPSHOT_DIR = '/home/nonroot/snapshots/santa-2025'
snapshots = os.listdir(SNAPSHOT_DIR)

# Track best per-N
best_per_n = {n: {'score': float('inf'), 'trees': None, 'source': None} for n in range(1, 201)}

print(f"Scanning {len(snapshots)} snapshots...")
for i, snapshot_id in enumerate(snapshots):
    csv_path = f'{SNAPSHOT_DIR}/{snapshot_id}/submission/submission.csv'
    if not os.path.exists(csv_path):
        continue
    
    configs = load_submission(csv_path)
    if not configs:
        continue
    
    for n in range(1, 201):
        if n not in configs or len(configs[n]) != n:
            continue
        
        score = calculate_score_for_n(configs[n])
        if score < best_per_n[n]['score']:
            best_per_n[n] = {'score': score, 'trees': configs[n], 'source': snapshot_id}
    
    if (i + 1) % 20 == 0:
        print(f"  Processed {i + 1}/{len(snapshots)} snapshots")

# Also scan the current baseline
baseline_path = '/home/code/experiments/002_valid_baseline/submission.csv'
baseline_configs = load_submission(baseline_path)
for n in range(1, 201):
    if n in baseline_configs and len(baseline_configs[n]) == n:
        score = calculate_score_for_n(baseline_configs[n])
        if score < best_per_n[n]['score']:
            best_per_n[n] = {'score': score, 'trees': baseline_configs[n], 'source': 'baseline'}

# Calculate ensemble score
ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))
print(f"\nEnsemble score: {ensemble_score:.6f}")
print(f"Baseline score: 70.615102")
print(f"Improvement: {70.615102 - ensemble_score:.6f}")

# Count improvements by source
source_counts = defaultdict(int)
for n in range(1, 201):
    source_counts[best_per_n[n]['source']] += 1

print("\nSource distribution:")
for source, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:
    print(f"  {source}: {count} N values")

# Save ensemble submission
import csv
with open('/home/submission/submission.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['id', 'x', 'y', 'deg'])
    for n in range(1, 201):
        trees = best_per_n[n]['trees']
        if trees:
            for idx, x, y, deg in trees:
                writer.writerow([f'{n:03d}_{idx}', f's{x:.17f}', f's{y:.17f}', f's{deg:.17f}'])
```

### Expected Outcome:
- **If ensemble finds improvements**: Score should be < 70.615 (even 0.01 improvement is progress!)
- **If no improvements found**: All 116 snapshots have the same per-N solutions (unlikely)

### SUBMIT THE RESULT!
Even if the improvement is small, SUBMIT IT. We have 98 submissions remaining.
LB feedback tells us if the approach works.

## ✅ IF ENSEMBLE FAILS: EXPERIMENT 006 - SIMULATED ANNEALING FROM SCRATCH

If the ensemble yields no improvement, implement SA in pure Python:

```python
import random
import math

def simulated_annealing(config, n, max_iter=10000, T0=1.0, Tmin=0.001):
    """
    SA for a single N configuration.
    config: list of (x, y, deg) for each tree
    """
    current = list(config)
    best = list(config)
    current_score = calculate_score(current, n)
    best_score = current_score
    
    T = T0
    alpha = (Tmin / T0) ** (1.0 / max_iter)
    
    for iteration in range(max_iter):
        # Choose a random move
        move_type = random.choice(['translate', 'rotate', 'squeeze'])
        tree_idx = random.randint(0, n - 1)
        
        # Save old state
        old_x, old_y, old_deg = current[tree_idx]
        
        if move_type == 'translate':
            # Small random translation
            dx = random.gauss(0, 0.1 * T)
            dy = random.gauss(0, 0.1 * T)
            current[tree_idx] = (old_x + dx, old_y + dy, old_deg)
        elif move_type == 'rotate':
            # Small random rotation
            ddeg = random.gauss(0, 10 * T)
            new_deg = (old_deg + ddeg) % 360
            current[tree_idx] = (old_x, old_y, new_deg)
        elif move_type == 'squeeze':
            # Move toward center
            cx = sum(t[0] for t in current) / n
            cy = sum(t[1] for t in current) / n
            dx = (cx - old_x) * 0.01 * T
            dy = (cy - old_y) * 0.01 * T
            current[tree_idx] = (old_x + dx, old_y + dy, old_deg)
        
        # Check for overlaps
        if has_overlap(current, n):
            current[tree_idx] = (old_x, old_y, old_deg)
            continue
        
        # Calculate new score
        new_score = calculate_score(current, n)
        delta = new_score - current_score
        
        # Accept or reject
        if delta < 0 or random.random() < math.exp(-delta / T):
            current_score = new_score
            if new_score < best_score:
                best_score = new_score
                best = list(current)
        else:
            current[tree_idx] = (old_x, old_y, old_deg)
        
        T *= alpha
    
    return best, best_score
```

## Key Insights from Research

1. **Asymmetric solutions win** (Discussion 666880, 40 votes): The winning solutions are asymmetric, not symmetric. The baseline may be stuck at a symmetric local optimum.

2. **Per-N ensemble is critical** (Top kernels): The jonathanchan kernel combines solutions from 15+ sources. We have 116 snapshots but haven't properly ensembled them.

3. **SA with swap moves** (opencv411 kernel): The top C++ implementations use swap moves (swapping positions of two trees) as a key operator.

4. **Multi-start helps** (opencv411 kernel): Starting from different initial angles and keeping the best result.

## What NOT to Try
- ❌ More fractional translation (already tried, no improvement)
- ❌ More backward propagation (already tried, no improvement)
- ❌ Running any binary optimizer (produces ~70.6, can't reach 68.89)
- ❌ Local search variations (baseline is at local optimum)

## Success Criteria
- **SUBMIT EVERY EXPERIMENT** - We have 98 submissions, use them!
- **Track per-N improvements** - Even if total score is worse, individual N improvements are valuable
- **Ensemble accumulation** - Keep best per-N across all experiments

## Next Steps After This Experiment
1. If ensemble improves score → Submit and continue with SA on improved baseline
2. If ensemble doesn't improve → Implement SA from scratch for N=2-50
3. Track which N values are hardest to improve → Focus optimization there