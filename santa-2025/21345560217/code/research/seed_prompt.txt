# Santa 2025 - Christmas Tree Packing Challenge Seed Prompt

## Current Status
- Best CV score: 70.615102 from exp_001 (002_valid_baseline)
- Best LB score: 70.615102 (verified submission)
- Target: 68.881647 | Gap to target: 1.733 points (2.5%)
- Submissions used: 2/100 (98 remaining - ABUNDANT!)

## ⚠️ CRITICAL SITUATION ANALYSIS

**ALL 5 experiments have produced the SAME score (70.615):**
- exp_000: 70.523 (rejected - overlaps)
- exp_001: 70.615 (valid baseline)
- exp_002: 70.615 (fractional translation - NO improvement)
- exp_003: 70.615 (backward propagation - NO improvement)
- exp_004: 70.615 (per-N ensemble - 199/200 N values had overlaps!)

**KEY INSIGHT FROM exp_004:** The 116 snapshots contain INVALID solutions with overlapping trees. The "improvements" found (score 27.48) were all from invalid solutions. After strict validation, 199/200 N values had to fall back to baseline.

**CONCLUSION:** We cannot improve by ensembling existing solutions. We must BUILD better solutions from scratch.

## Response to Evaluator

The evaluator correctly identified that:
1. The snapshots are a dead end - they contain invalid solutions
2. We need to BUILD solutions from scratch using global search (SA)
3. Focus on small N values (N=2-20) where improvements have highest impact

I agree with this assessment. The next experiment MUST implement simulated annealing from scratch in pure Python.

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files - FORBIDDEN
- Loading solutions then running optimizer on them - FORBIDDEN
- Trying to ensemble from snapshots again - FORBIDDEN (proven invalid)

## ✅ NEXT EXPERIMENT: SIMULATED ANNEALING FROM SCRATCH

**Experiment 006: Pure Python Simulated Annealing**

Create `experiments/006_python_sa/` and implement SA from scratch:

### Step 1: Tree Geometry Functions
```python
import math
import random
from shapely.geometry import Polygon
from shapely import affinity

TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]

def create_tree_polygon(x, y, deg):
    """Create a tree polygon at position (x, y) with rotation deg."""
    poly = Polygon(zip(TX, TY))
    rotated = affinity.rotate(poly, deg, origin=(0, 0))
    return affinity.translate(rotated, x, y)

def has_any_overlap(trees):
    """Check if any trees overlap (strict validation)."""
    if len(trees) <= 1:
        return False
    polys = [create_tree_polygon(x, y, deg) for x, y, deg in trees]
    for i in range(len(polys)):
        for j in range(i+1, len(polys)):
            if polys[i].intersects(polys[j]) and not polys[i].touches(polys[j]):
                if polys[i].intersection(polys[j]).area > 1e-15:
                    return True
    return False

def calculate_score(trees, n):
    """Calculate score for a configuration."""
    if not trees or has_any_overlap(trees):
        return float('inf')
    polys = [create_tree_polygon(x, y, deg) for x, y, deg in trees]
    from shapely.ops import unary_union
    bounds = unary_union(polys).bounds
    side = max(bounds[2] - bounds[0], bounds[3] - bounds[1])
    return side ** 2 / n
```

### Step 2: Initial Placement (Grid-based)
```python
def create_initial_placement(n):
    """Create initial grid-based placement for n trees."""
    trees = []
    cols = int(math.ceil(math.sqrt(n)))
    for i in range(n):
        row, col = i // cols, i % cols
        x = col * 0.8 - (cols * 0.8) / 2
        y = row * 1.1 - (n // cols * 1.1) / 2
        deg = 45.0 if (row + col) % 2 == 0 else 225.0  # Alternating angles
        trees.append([x, y, deg])
    
    # Repair overlaps by spreading trees
    max_attempts = 1000
    for _ in range(max_attempts):
        if not has_any_overlap(trees):
            break
        for i in range(n):
            trees[i][0] += random.uniform(-0.1, 0.1)
            trees[i][1] += random.uniform(-0.1, 0.1)
    
    return trees
```

### Step 3: Simulated Annealing with Adaptive Neighborhood
```python
def simulated_annealing(n, max_iter=100000, T0=1.0, Tmin=0.0001):
    """SA for a single N configuration - start from scratch."""
    # Initialize
    current = create_initial_placement(n)
    if has_any_overlap(current):
        print(f"N={n}: Could not create valid initial placement")
        return None, float('inf')
    
    best = [list(t) for t in current]
    current_score = calculate_score(current, n)
    best_score = current_score
    
    T = T0
    alpha = (Tmin / T0) ** (1.0 / max_iter)
    
    # Adaptive step sizes
    step_translate = 0.1
    step_rotate = 30.0
    accepted = 0
    rejected = 0
    
    for iteration in range(max_iter):
        # Choose random move
        tree_idx = random.randint(0, n - 1)
        old = list(current[tree_idx])
        
        move = random.choice(['translate', 'rotate', 'swap'])
        if move == 'translate':
            current[tree_idx][0] += random.gauss(0, step_translate * T)
            current[tree_idx][1] += random.gauss(0, step_translate * T)
        elif move == 'rotate':
            current[tree_idx][2] = (current[tree_idx][2] + random.gauss(0, step_rotate * T)) % 360
        elif move == 'swap' and n > 1:
            j = random.randint(0, n - 1)
            if j != tree_idx:
                current[tree_idx], current[j] = current[j], current[tree_idx]
        
        # Check validity
        if has_any_overlap(current):
            current[tree_idx] = old
            if move == 'swap' and n > 1:
                current[tree_idx], current[j] = current[j], current[tree_idx]
            rejected += 1
            continue
        
        new_score = calculate_score(current, n)
        delta = new_score - current_score
        
        # Metropolis criterion
        if delta < 0 or random.random() < math.exp(-delta / T):
            current_score = new_score
            accepted += 1
            if new_score < best_score:
                best_score = new_score
                best = [list(t) for t in current]
        else:
            current[tree_idx] = old
            if move == 'swap' and n > 1:
                current[tree_idx], current[j] = current[j], current[tree_idx]
            rejected += 1
        
        # Adaptive step size adjustment (every 1000 iterations)
        if iteration > 0 and iteration % 1000 == 0:
            acceptance_rate = accepted / (accepted + rejected + 1e-10)
            if acceptance_rate > 0.6:
                step_translate *= 1.1
                step_rotate *= 1.1
            elif acceptance_rate < 0.4:
                step_translate *= 0.9
                step_rotate *= 0.9
            accepted = 0
            rejected = 0
        
        T *= alpha
    
    return best, best_score
```

### Step 4: Run SA for Small N First (TEST BEFORE FULL RUN!)
```python
# MANDATORY: Test on small N first
print("Testing SA on N=2-10 first...")
baseline_per_n = load_baseline_per_n()  # Load from baseline submission

improvements = []
for n in range(2, 11):
    best_trees, best_score = simulated_annealing(n, max_iter=50000)
    baseline_score = baseline_per_n[n]
    
    if best_score < baseline_score:
        improvement = baseline_score - best_score
        improvements.append((n, improvement))
        print(f"✅ N={n}: {baseline_score:.6f} -> {best_score:.6f} (improved by {improvement:.6f})")
    else:
        print(f"❌ N={n}: {baseline_score:.6f} (no improvement)")

if not improvements:
    print("\n⚠️ SA did not improve any N=2-10. Need to adjust parameters or try different approach.")
else:
    print(f"\n✅ Found {len(improvements)} improvements! Proceeding to full N=1-200...")
```

### Step 5: Only If Small N Test Shows Promise → Scale Up
```python
# Only run full optimization if small N test showed improvements
if improvements:
    print("\nRunning SA for all N values...")
    for n in range(2, 201):
        best_trees, best_score = simulated_annealing(n, max_iter=100000)
        if best_score < baseline_per_n[n]:
            # Save improved solution
            save_solution(n, best_trees)
            print(f"✅ N={n}: improved by {baseline_per_n[n] - best_score:.6f}")
```

## ✅ MANDATORY: OVERLAP VALIDATION BEFORE SUBMISSION

```python
def validate_submission(filepath):
    """Validate entire submission for overlaps."""
    from collections import defaultdict
    import pandas as pd
    
    df = pd.read_csv(filepath)
    configs = defaultdict(list)
    for _, row in df.iterrows():
        n = int(row['id'].split('_')[0])
        x = float(str(row['x']).replace('s', ''))
        y = float(str(row['y']).replace('s', ''))
        deg = float(str(row['deg']).replace('s', ''))
        configs[n].append((x, y, deg))
    
    invalid_n = []
    for n in range(1, 201):
        trees = configs[n]
        if has_any_overlap(trees):
            invalid_n.append(n)
    
    if invalid_n:
        print(f"⚠️ INVALID: {len(invalid_n)} N values have overlaps: {invalid_n[:10]}...")
        return False
    else:
        print("✅ All N values are valid!")
        return True

# MANDATORY: Validate before submission
if not validate_submission('/home/submission/submission.csv'):
    raise ValueError("Submission has overlaps - DO NOT SUBMIT!")
```

## Expected Outcome

- **Best case:** SA finds improvements for some N values, total score improves
- **Worst case:** SA cannot beat baseline for any N (baseline is already optimal)

If SA doesn't work, next approaches to try:
1. Genetic algorithm with crossover operators
2. Constructive heuristics (bottom-left fill)
3. Branch-and-bound for exact solutions on N≤10

## SUBMIT AFTER EVERY EXPERIMENT!

With 98 submissions remaining, submit EVERY experiment to get LB feedback.
Even if CV score is the same, submit to verify LB matches CV.

## Key Research Insights (from web search)

1. **Adaptive neighborhood SA:** Adjust step sizes based on acceptance rate
   - If acceptance > 60%: increase step size (exploring too locally)
   - If acceptance < 40%: decrease step size (steps too large)

2. **No-fit polygon (NFP):** Precompute collision-free regions for O(1) overlap checks
   - Can dramatically speed up SA by avoiding expensive polygon intersection tests

3. **Bottom-left fill:** Place trees one at a time at lowest-leftmost valid position
   - Good for constructive initial placement

## Score Breakdown (from baseline)
- N=1-10: 4.329 pts (6.1%) - HIGHEST IMPACT PER N
- N=11-50: 14.704 pts (20.8%)
- N=51-100: 17.606 pts (24.9%)
- N=101-150: 17.134 pts (24.3%)
- N=151-200: 16.842 pts (23.9%)

Focus on N=2-20 first - these have highest impact per improvement!
