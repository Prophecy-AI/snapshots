# Santa 2025 - Evolved Seed Prompt (Loop 6)

## Current Status
- Best CV score: 70.615102 from exp_001 (002_valid_baseline)
- Best LB score: 70.615102 (verified)
- Target: 68.881647 | Gap to target: 1.733 points (2.5%)

## Critical Finding from This Loop
**Comprehensive external source analysis completed:**
- Checked 79 external source files from bucket-of-chump, santa25-public, telegram, etc.
- Checked 492 snapshot submission files
- Result: **NO VALID IMPROVEMENTS FOUND**
- All external sources either have overlaps or scores >= 70.67 (worse than baseline)
- The baseline (70.615102) is confirmed as the BEST VALID solution available

## What We've Learned
1. **The baseline is at a strong local optimum** - No local search method (fractional translation, backward propagation, SA) can improve it
2. **External sources don't help** - They either have overlaps or worse scores
3. **Top kernels use C++ binaries** - They achieve better scores by running sophisticated C++ optimizers (bbox3, shake_public, eazy_optimizer) for hours
4. **The gap to target (1.733 points) requires fundamentally different approach**

## Response to Evaluator
The evaluator correctly identified that:
1. SA from scratch starts from wrong point (grid placement instead of baseline)
2. External sources should be explored
3. Fractional translation should be applied to baseline

I've now verified:
- External sources have been exhaustively checked - no valid improvements
- The baseline IS the best starting point available
- SA starting from baseline would need C++ speed to compete

## The Real Problem
The target score (68.89) was achieved by teams running C++ optimizers for DAYS with:
- 953 submissions (top team)
- Multiple C++ binaries (bbox3, shake_public, eazy_optimizer)
- Hours of compute time per submission
- Ensemble from 15+ sources accumulated over weeks

We cannot replicate this with Python in a single session.

## ⛔ FORBIDDEN (WILL BE REJECTED)
- bbox3, sa_fast, eazy_optimizer, tree_packer - FORBIDDEN (we don't have access)
- subprocess.run() or os.system() - FORBIDDEN
- Running ANY binary or executable - FORBIDDEN
- "Optimizing" existing CSV files - FORBIDDEN
- Loading solutions then running optimizer on them - FORBIDDEN

## ✅ NEXT EXPERIMENT: ASYMMETRIC PLACEMENT EXPLORATION

The discussion "Why the winning solutions will be Asymmetric" (40 votes) suggests asymmetric solutions outperform symmetric ones. Our baseline may be stuck at a symmetric local optimum.

### Approach: Implement Asymmetric Placement Generator

```python
# Instead of grid-based symmetric placement, try:
# 1. Diagonal placement patterns
# 2. Spiral placement patterns  
# 3. Random perturbation of baseline with asymmetric bias

def asymmetric_placement(n, baseline_config):
    """Generate asymmetric variations of baseline."""
    # Start from baseline
    trees = [list(t) for t in baseline_config]
    
    # Apply asymmetric perturbations
    for i in range(n):
        # Bias toward one direction
        trees[i][0] += random.gauss(0.01, 0.005)  # Slight x-bias
        trees[i][2] += random.uniform(-5, 5)  # Angle variation
    
    # Validate and return if no overlaps
    if not has_any_overlap(trees):
        return trees
    return None
```

### Expected Outcome
- May find configurations that escape the symmetric local optimum
- Even small improvements (0.01-0.1 points) are valuable
- Focus on N=50-150 where there's most room for improvement

## ✅ ALTERNATIVE: GENETIC ALGORITHM WITH CROSSOVER

If asymmetric placement doesn't work, implement a genetic algorithm:

```python
def genetic_algorithm(n, population_size=20, generations=100):
    """GA with crossover between different configurations."""
    # Initialize population with variations of baseline
    population = [create_variation(baseline_config[n]) for _ in range(population_size)]
    
    for gen in range(generations):
        # Evaluate fitness (lower score = better)
        fitness = [(calculate_score(p, n), p) for p in population]
        fitness.sort()
        
        # Select top 50%
        survivors = [p for _, p in fitness[:population_size//2]]
        
        # Crossover: swap tree positions between parents
        children = []
        for i in range(0, len(survivors), 2):
            child = crossover(survivors[i], survivors[i+1])
            children.append(child)
        
        # Mutate
        for child in children:
            mutate(child)
        
        population = survivors + children
    
    return min(population, key=lambda p: calculate_score(p, n))
```

## Per-N Tracking (MANDATORY)
Track best solution for EACH N separately:
- Load baseline per-N scores
- After each experiment, compare per-N
- Keep only N values where you improved
- Even if total score is worse, individual N improvements are valuable

## Score Breakdown (from baseline)
- N=1-10: 4.329 pts (6.1%) - Already optimal
- N=11-50: 14.704 pts (20.8%) - Some room for improvement
- N=51-100: 17.606 pts (24.9%) - Most room for improvement
- N=101-150: 17.134 pts (24.3%) - Most room for improvement
- N=151-200: 16.842 pts (23.9%) - Some room for improvement

## SUBMIT EVERY EXPERIMENT
With 98 submissions remaining, submit after every experiment for LB feedback.
