{
  "query": "What is k-mer exploration technique for combinatorial optimization and polygon packing problems?",
  "results": [
    {
      "title": "ANSWER",
      "text": "The available sources do not describe a \u201ck\u2011mer exploration\u201d method that is applied to combinatorial\u2011optimization or polygon\u2011packing problems. The results that mention **k\u2011mers** focus on their use in bio\u2011informatics (optimising k\u2011mer size for genome assembly\u202f[pmc.ncbi.nlm.nih.gov] and memory\u2011efficient k\u2011mer counting with Bloom\u2011filter tricks\u202f[comp.nus.edu.sg]), while the papers on polygon packing discuss heuristic and integer\u2011programming approaches for the CG:SHOP 2024 challenge\u202f[arxiv.org] and related heuristics\u202f[drops.dagstuhl.de]. None of the excerpts link the k\u2011mer concept to the formulation or solution of packing or other combinatorial\u2011optimization problems. Consequently, a concrete definition or description of a \u201ck\u2011mer exploration technique\u201d for these domains cannot be provided from the current search results.",
      "url": ""
    },
    {
      "title": "Optimizing k-mer size - Enhance de novo genome assembly",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nBioinformation\n\n. 2016 Apr 10;12(2):36\u201340. doi: [10.6026/97320630012036](https://doi.org/10.6026/97320630012036)\n\n# Optimizing k-mer size using a variant grid search to enhance _de novo_ genome assembly\n\n[Soyeon Cha](https://pubmed.ncbi.nlm.nih.gov/?term=%22Cha%20S%22%5BAuthor%5D)\n\n### Soyeon Cha\n\n1Bioinformatics Research Center and Department of Plant Pathology, NC State University, Raleigh, NC, USA\n\nFind articles by [Soyeon Cha](https://pubmed.ncbi.nlm.nih.gov/?term=%22Cha%20S%22%5BAuthor%5D)\n\n1, [David McK Bird](https://pubmed.ncbi.nlm.nih.gov/?term=%22Bird%20DM%22%5BAuthor%5D)\n\n### David McK Bird\n\n1Bioinformatics Research Center and Department of Plant Pathology, NC State University, Raleigh, NC, USA\n\nFind articles by [David McK Bird](https://pubmed.ncbi.nlm.nih.gov/?term=%22Bird%20DM%22%5BAuthor%5D)\n\n1,\\*\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1Bioinformatics Research Center and Department of Plant Pathology, NC State University, Raleigh, NC, USA\n\n\\*\n\nDavid McK Bird: bird@ncsu.edu\n\nReceived 2016 Mar 18; Revised 2016 Apr 6; Accepted 2016 Apr 6; Collection date 2016.\n\n\u00a9 2016 Biomedical Informatics\n\nThis is an Open Access article which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work is properly credited. This is distributed under the terms of the Creative Commons Attribution License.\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC5237644\u00a0\u00a0PMID: [28104957](https://pubmed.ncbi.nlm.nih.gov/28104957/)\n\n## Abstract\n\nLargely driven by huge reductions in per-base costs, sequencing nucleic acids has become a near-ubiquitous technique in\nlaboratories performing biological and biomedical research. Most of the effort goes to re-sequencing, but assembly of de novogenerated,\nraw sequence reads into contigs that span as much of the genome as possible is central to many projects. Although truly\ncomplete coverage is not realistically attainable, maximizing the amount of sequence that can be correctly assembled into contigs\ncontributes to coverage. Here we compare three commonly used assembly algorithms (ABySS, Velvet and SOAPdenovo2), and\nshow that empirical optimization of k-mer values has a disproportionate influence on de novo assembly of a eukaryotic genome, the\nnematode parasite Meloidogynechitwoodi. Each assembler was challenged with about 40 million Iluumina II paired-end reads, and\nassemblies performed under a range of k-mer sizes. In each instance, the optimal k-mer was 127, although based on N50\nvalues,ABySS was more efficient than the others. That the assembly was not spurious was established using the \u201cCore Eukaryotic\nGene Mapping Approach\u201d, which indicated that 98.79% of the M. chitwoodi genome was accounted for by the assembly.\nSubsequent gene finding and annotation are consistent with this and suggest that k-mer optimization contributes to the robustness\nof assembly.\n\n**Keywords:** ABySS, CEGMA, contigs, KmerGenie, N50, next-generation sequencing, SOAPdonovo, Velvet\n\n## Background\n\nThe progression of technology from Sanger sequencing to the\ncurrent \u201cnext-generation\u201d platforms has heralded striking\nreductions in the cost of generating data. Sequencing nucleic\nacids has become a near-ubiquitous technique in laboratories\nperforming biological and bio-medical research. Sequencing\ncomes in two forms, distinguished by their needs for assembly\ninto a contiguous reconstruction of a larger molecule. Most\nprevalent are various forms of \u201cre-sequencing\u201d in which the\nsequencing reads are aligned with a reference genome to reveal\nbases polymorphic between samples. Computationally, this is not\na difficult undertaking. The other mode is the assembly of de\nnovo-generated, raw sequence reads into contigs that are, as close\nas possible a full accounting of the genome of the organism in\nquestion. In practice, except for the smallest of genomes,\ncomplete coverage is neither attainable nor usually needed.\nNone-the-less, maximizing the amount of sequence that can be\ncorrectly assembled into contigs is desirable. Reference-free\nassembly is based on stacking overlapping sequences of genomic\nfragments of a defined size (the k-mer), generated by breaking\neach read into k-mer size. Here we examined three commonly used\nassembly platforms, and showed that optimization of k-mer\nvalues has a disproportionate influence on de novo assembly of a\neukaryotic genome.\n\nGenome assembly algorithms permit adjustment of k-mer size,\nand also of the related feature coverage (or depth) of the k-mer\nassembly. The k-mer optimizing tool \u201cVelvetadvisor\u201d \\[ [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R01)\\], for\nexample, estimates a theoretically optimal k-mer size as follows:\n\nk-mer siz=e 1 + read length - (k-mer coverage \\* read length)/(Genome coverage)\n\nwhere, Genome coverage = (A total number of reads \\* read length)/ (Estimated genome size)\n\nThus,k-mer size and k-mer coverage approximatean inverse\nrelationship.Because k-mer size and coverage impact the\nassembly, methods to predict optimal k-mer size have been\nproposed.\n\nIn particular, Chikhi and Medvedev (2013) developed the\nKmerGenie algorithm \\[ [2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R02)\\] to guide selection of k-mer size, and\ndemonstrated its utility with the assembly tools Velvet \\[ [3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R03)\\] and\nSOAPdenovo2 \\[ [4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R04)\\].\n\nIn our lab, we study plant-parasitic, root-knotnematodes\n(Meloidogyne spp.), which are responsible for annual crop losses\napproaching USD 80 billion worldwide. These pathogens have\ngenomes in the 50 Mbp to 150 Mbp range, with marked\ndifferences in gene number betweenspecies. In cool climates, two\nspecies (M. hapla and M. chitwoodi) predominate and appear to\noccupy the same niche (i.e., are sympatric). Whole genome\ncomparison would likely shed much light on the basis for\nsympatry. A well-annotated draft sequence is available for M.\nhapla \\[ [5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R05), [6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#R06)\\] and we recently sequenced the M. chitwoodi genome; a\ncomprehensive biological annotation will be published\nelsewhere.\n\nPrior to assembly of the M. chitwoodi reads, we queried\n\u201cVelvetadvisor\u201d and \u201cKmerGenie\u201d to compute a value for kmer\nsize (247 and 260 respectively). Although similar, these\nvalues are not identical, and led us to explore empirical\noptimization of k-mer size. In this study, we show that a\n\u2018Simple Grid Search\u2019, a widely used optimization algorithm,\nachieves the best k-mer value for assembly. Our proposed\nmethod has three steps. Firstly, we explicitly specified an\nequally-spaced interval including the k-mer size predicted by\n'Velvet advisor' or 'KmerGenie'. Those k-mers were evaluated\naccording to N50.Secondly, we selected a next set of k-mers in a\nmore-narrow interval around those k-mers with the largest N50\nfrom the first evaluation. Lastly, we chose the best k-mer by\nassessin...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC5237644"
    },
    {
      "title": "[PDF] K-mers count packing - NUS Computing",
      "text": "Wong Limsoon, CS4330, AY2024/2025\n\u00a9 Copyright National University of Singapore. All Rights Reserved.\nCS4330: Combinatorial Methods in Bioinformatics\nK-mers count packing\nWong Limsoon\n1\nWong Limsoon, CS4330, AY2024/2025\nToo many K-mers to keep in memory for\nconvenient access\n2\nDistribution of 31-mers in dataset D3\n(human chr 14) having value larger than 2.\nJiang et al., \u201ckmcEx: memory frugal and retrieval efficient encoding\nof counted k-mers\u201d, Bioinformatics 35(23):4871-4878, 2019\nWong Limsoon, CS4330, AY2024/2025\nKeep in one big\nBloom filter?\n3\nOptimal size of Bloom filter is n = -2.08 m (ln \uf065) bits\nFor dataset D5,\n# of K-mers \uf0bb 7 billions\nn = -2.08 (7 x 109) (ln \uf065)\n\uf0bb 100 x 109 bits \uf0bb 12 GB at \uf065 = 0.01%\nBut this Bloom filter cannot tell you frequency of K-mers \uf04c\nn = size of Bloom filter\nm = # of elements inserted\n\uf065 = false positive rate\nWong Limsoon, CS4330, AY2024/2025\nSeparation trick\n4\nUse separate Bloom filters to store K-mers of different\nfrequency; i.e., use Hjto store K-mers of frequency j\nK-mer frequencies can go from 1, 2, \u2026, to thousands\nUse H1, \u2026, Hhto store K-mers of frequencies 1 to h\nAnd look for clever idea to deal with K-mers having\nfrequency > h\nWong Limsoon, CS4330, AY2024/2025\nExercise\nCf. D5, suppose\n4 x 109 K-mers with freq = 1\n90 x 106 K-mers with freq = 2\n15 x 106 K-mers with freq = 3\n18 x 106 K-mers with freq = 4\n21 x 106 K-mers with freq = 5\n3 x 109 K-mers with freq > 5\nWhat space is needed to store them in H1, \u2026, H5 and a\nhash table (for the counts of K-mers with freq > 5) ?\n5\nDistribution of 31-mers in dataset D3\n(human chr 14) having value larger than 2.\nWong Limsoon, CS4330, AY2024/2025\nThe coupled bit arrays of kmcEx\n7\nkmcEx stores K-mers and their counts using a pair of\nBloom filter-like bit arrays B = (B+, B\uf02d)\nJiang et al., \u201ckmcEx: Memory-frugal and retrieval-efficient encoding\nof counted k-mers\u201d, Bioinformatics 35(23):4871-4878, 2019\nWong Limsoon, CS4330, AY2024/2025\nExample\n8\nJiang et al., \u201ckmcEx: Memory-frugal and retrieval-efficient encoding\nof counted k-mers\u201d, Bioinformatics 35(23):4871-4878, 2019\nWong Limsoon, CS4330, AY2024/2025\nCollisions\n9\nTraditional Bloom filters no need to care for collisions\nBut kmcEx must take care of collisions in B\uf02d because the\nbits can change from 0 to 1 and 1 to 0\nCollison happens in B\uf02d\nIf there i \uf0ce { 0, 1,\u2026, h \u2013 1} such that\nB+[Hi(\uf06b)] = 1 and B\uf02d[Hi(\uf06b)] \uf0b9 B\u2019\uf02d[Hi(\uf06b)]\nwhere \uf06b is the K-mer to be inserted and B\u2019 is the updated\ncoupled bit-arrays if \uf06b is inserted\nWong Limsoon, CS4330, AY2024/2025\nExercise\n10\nSuggest a simple and effective way for kmcEx to deal\nwith collisions\nWong Limsoon, CS4330, AY2024/2025\nOther ideas in kmcEx\n12\nFalse positive reduction\nCheck if any of \uf06b\u2019s neighbours is found and has similar\ncount as \uf06b\nFrequency binning\nDiscretize counts into bins of progressively larger width\ne.g., use 60 to represent frequencies 59, 60, & 61\nK-mer separation\nUse separate vanilla Bloom filter for K-mers of freq = 1\nWong Limsoon, CS4330, AY2024/2025\nMemory usage, count fidelity, & FPR\n13 Jiang et al., \u201ckmcEx: Memory-frugal and retrieval-efficient encoding\nof counted k-mers\u201d, Bioinformatics 35(23):4871-4878, 2019\nWong Limsoon, CS4330, AY2024/2025\nRunning time\n14\nEncoding = ~1.3 mps (mil K-mers per sec)\nDecoding = ~0.5 mps (present K-mers),\n~0.7 mps (absent K-mers)\nJiang et al., \u201ckmcEx: Memory-frugal and retrieval-efficient encoding\nof counted k-mers\u201d, Bioinformatics 35(23):4871-4878, 2019\nExpt performed on a computer w/ 256GB RAM, 2 x E5-2683V4 CPU, CentOS 7.0\nWong Limsoon, CS4330, AY2024/2025\nGood to read\nkmcEx\nP. Jiang et al., \u201ckmcEx: Memory-frugal and retrieval-efficient encoding of counted\nk-mers\u201d, Bioinformatics 35(23):4871-4878, 2019.\nhttps://pubmed.ncbi.nlm.nih.gov/31038666/\n15",
      "url": "https://www.comp.nus.edu.sg/~wongls/courses/cs4330/2025/10-kmer-count-packing.pdf"
    },
    {
      "title": "Maximum Polygon Packing: The CG:SHOP Challenge 2024 - arXiv",
      "text": "HTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\n\n- failed: nth\n- failed: complexity\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\n\nLicense: arXiv.org perpetual non-exclusive license\n\narXiv:2403.16203v1 \\[cs.CG\\] 24 Mar 2024\n\n\\\\hideLIPIcs\n\nDepartment of Computer Science, TU Braunschweig, Germanys.fekete@tu-bs.dehttps://orcid.org/0000-0002-9062-4241\nDepartment of Computer Science, TU Braunschweig, Germanyp.keldenich@tu-bs.dehttps://orcid.org/0000-0002-6677-5090\nDepartment of Computer Science, TU Braunschweig, Germanyd.krupke@tu-bs.dehttps://orcid.org/0000-0003-1573-3496\nDepartment for Simulation and Graphics, OvGU Magdeburg, Germanystschirr@isg.cs.uni-magdeburg.dehttps://orcid.org/0009-0006-5928-1494\n\\\\CopyrightS.\u00a0P.\u00a0Fekete, P.\u00a0Keldenich, D.\u00a0Krupke, S.\u00a0Schirra\n\\\\ccsdescTheory of computation \u2192\u2192\\\\rightarrow\u2192 Computational geometry\n\\\\ccsdescTheory of computation \u2192\u2192\\\\rightarrow\u2192 Design and analysis of algorithms\n\\\\supplement\\\\fundingWork at TU Braunschweig has been partially supported by the German Research Foundation (DFG),\nproject \u201cComputational Geometry: Solving Hard Optimization Problems\u201d (CG:SHOP), grant FE407/21-1.\n\n###### Acknowledgements.\n\nWe thank the members of the CG:SHOP Challenge Advisory Board for their valuable input:\nWilliam J.\u00a0Cook, Andreas Fabri, Dan Halperin, Michael Kerber, Philipp Kindermann, Joe Mitchell, Kevin Verbeek.\n\\\\EventAcronymCG:SHOP 2024\n\n# Maximum Polygon Packing: The CG:SHOP Challenge 2024\n\nS\u00e1ndor P.\u00a0Fekete\nPhillip Keldenich\nDominik Krupke\nStefan Schirra\n\n###### Abstract\n\nWe give an overview of the 2024 Computational Geometry Challenge\ntargeting the problem Maximum Polygon Packing:\nGiven a convex region P\ud835\udc43Pitalic\\_P in the plane, and a collection of simple polygons Q1,\u2026,Qnsubscript\ud835\udc441\u2026subscript\ud835\udc44\ud835\udc5bQ\\_{1},\\\\ldots,Q\\_{n}italic\\_Q start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT , \u2026 , italic\\_Q start\\_POSTSUBSCRIPT italic\\_n end\\_POSTSUBSCRIPT, each Qisubscript\ud835\udc44\ud835\udc56Q\\_{i}italic\\_Q start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT\nwith a respective value cisubscript\ud835\udc50\ud835\udc56c\\_{i}italic\\_c start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT,\nfind a subset S\u2286{1,\u2026,n}\ud835\udc461\u2026\ud835\udc5bS\\\\subseteq\\\\{1,\\\\ldots,n\\\\}italic\\_S \u2286 { 1 , \u2026 , italic\\_n }\nand a feasible packing within P\ud835\udc43Pitalic\\_P of the polygons Qisubscript\ud835\udc44\ud835\udc56Q\\_{i}italic\\_Q start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT (without rotation) for i\u2208S\ud835\udc56\ud835\udc46i\\\\in Sitalic\\_i \u2208 italic\\_S,\nmaximizing \u2211i\u2208Scisubscript\ud835\udc56\ud835\udc46subscript\ud835\udc50\ud835\udc56\\\\sum\\_{i\\\\in S}c\\_{i}\u2211 start\\_POSTSUBSCRIPT italic\\_i \u2208 italic\\_S end\\_POSTSUBSCRIPT italic\\_c start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT.\nGeometric packing problems, such as this, present significant computational challenges and are of substantial practical importance.\n\n###### keywords:\n\nComputational Geometry, geometric optimization, packing, Algorithm Engineering, contest\n\n## 1 Introduction\n\nThe \u201cCG:SHOP Challenge\u201d (Computational Geometry: Solving Hard\nOptimization Problems) originated as a workshop at the 2019\nComputational Geometry Week (CG Week) in Portland, Oregon in June,\n2019\\. The goal was to conduct a computational challenge competition\nthat focused attention on a specific hard geometric optimization\nproblem, encouraging researchers to devise and implement solution\nmethods that could be compared scientifically based on how well they\nperformed on a database of carefully selected and varied instances.\nWhile much of computational\ngeometry research is theoretical, often seeking provable approximation\nalgorithms for \\\\NP-hard optimization problems,\nthe goal of the Challenge was to set the metric of success based on\ncomputational results on a specific set of benchmark geometric\ninstances. The 2019 Challenge\u00a0\\[ [26](https://arxiv.org/html/2403.16203v1#bib.bib26)\\] focused on the problem of computing\nsimple polygons of minimum and maximum area for given sets of vertices in the\nplane. It generated a strong response from many research\ngroups\u00a0\\[ [11](https://arxiv.org/html/2403.16203v1#bib.bib11), [38](https://arxiv.org/html/2403.16203v1#bib.bib38), [22](https://arxiv.org/html/2403.16203v1#bib.bib22), [25](https://arxiv.org/html/2403.16203v1#bib.bib25), [58](https://arxiv.org/html/2403.16203v1#bib.bib58), [45](https://arxiv.org/html/2403.16203v1#bib.bib45)\\] from both the computational geometry and the combinatorial\noptimization communities, and resulted in a lively exchange of\nsolution ideas.\n\nSubsequently, the CG:SHOP Challenge became an event within the CG Week\nprogram, with top performing solutions reported in the Symposium on\nComputational Geometry (SoCG) proceedings.\nThe schedule for the Challenge was\nadvanced earlier, to give an opportunity for more participation, particularly\namong students, e.g., as part of course projects.\nFor CG Weeks 2020, 2021, 2022, and 2023, the Challenge problems were Minimum Convex Partition\\[ [19](https://arxiv.org/html/2403.16203v1#bib.bib19), [67](https://arxiv.org/html/2403.16203v1#bib.bib67), [56](https://arxiv.org/html/2403.16203v1#bib.bib56), [21](https://arxiv.org/html/2403.16203v1#bib.bib21)\\],\nCoordinated Motion Planning\\[ [27](https://arxiv.org/html/2403.16203v1#bib.bib27), [14](https://arxiv.org/html/2403.16203v1#bib.bib14), [15](https://arxiv.org/html/2403.16203v1#bib.bib15), [66](https://arxiv.org/html/2403.16203v1#bib.bib66), [13](https://arxiv.org/html/2403.16203v1#bib.bib13), [47](https://arxiv.org/html/2403.16203v1#bib.bib47), [65](https://arxiv.org/html/2403.16203v1#bib.bib65)\\],\nMinimum Partition into Plane Subgraphs\\[ [28](https://arxiv.org/html/2403.16203v1#bib.bib28), [10](https://arxiv.org/html/2403.16203v1#bib.bib10), [60](https://arxiv.org/html/2403.16203v1#bib.bib60), [12](https://arxiv.org/html/2403.16203v1#bib.bib12), [61](https://arxiv.org/html/2403.16203v1#bib.bib61), [36](https://arxiv.org/html/2403.16203v1#bib.bib36), [59](https://arxiv.org/html/2403.16203v1#bib.bib59)\\],\nand Minimum Convex Covering\\[ [29](https://arxiv.org/html/2403.16203v1#bib.bib29), [16](https://arxiv.org/html/2403.16203v1#bib.bib16), [1](https://arxiv.org/html/2403.16203v1#bib.bib1)\\],\nrespectively.\n\nThe sixth edition of the Challenge in 2024 continued\nthis format, leading to contributions in the SoCG proceedings.\n\n## 2 The Challenge: Maximum Polygon Packing\n\nA suitable contest problem has a number of desirable properties.\n\n- \u2022\n\n\nThe problem is of geometric nature.\n\n- \u2022\n\n\nThe problem is of general scientific interest and has received previous attention.\n\n- \u2022\n\n\nOptimization problems tend to be more suitable than feasibility problems; in principle,\nfeasibility problems are also possible, but they need to be suitable for sufficiently\nfine-grained scoring to produce an interesting contest.\n\n- \u2022\n\n\nComputing optimal solutions is difficult for instances of reasonable size.\n\n- \u2022\n\n\nThis difficulty is of a fundamental algorithmic nature, and not only due to\nissues of encoding or access to sophisticated software or hardware.\n\n- \u2022\n\n\nVerifying feasibility of provided solutions is relatively easy.\n\n\nIn this sixth year, a call for suitable problems was communicated in March\n2023\\. In response, a number of interesting problems were proposed for the 2024\nChallenge. These were evaluated with respect to difficulty, distinctiveness\nfrom previous years, and existing literature and related work. In the end, the\nAdvisory Board selected the chosen problem. Special thanks go to Mikkel Abrahamsen\n(University of Copenhagen) who suggested this problem, motivated by a rich history\nin geometry and optimization, including\u00a0\\[ [46](https://arxiv.org/html/2403.16203v1#bib.bib46)\\] and a wide range of\nprevious work described further down.\n\n### 2.1 The Proble...",
      "url": "https://arxiv.org/html/2403.16203v1"
    },
    {
      "title": "[PDF] Two-Dimensional Bin Packing Problem with Guillotine ...",
      "text": "Alma Mater Studiorum Universit`a di Bologna\nDEI - Dipartimento di Ingegneria dell\u2019Energia Elettrica e dell\u2019Informazione\n\u201cGuglielmo Marconi\u201d\nDottorato di Ricerca in Automatica e Ricerca Operativa\nCiclo XXVI\nSettore concorsuale di afferenza: 01/A6 - RICERCA OPERATIVA\nSettore scientifico disciplinare: MAT/09 - RICERCA OPERATIVA\nTwo-Dimensional Bin Packing Problem\nwith Guillotine Restrictions\nEnrico Pietrobuoni\nCoordinatore Relatore\nProf. Daniele Vigo Prof. Andrea Lodi\nIng. Michele Monaci\nEsame Finale 2015\n\nContents\nList of Figures v\n1 Outline 1\n2 The Two-Dimensional Bin Packing Problem 3\n2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2.2 Cutting and Packing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.3 Rectangle Packing Problem . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.5 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.5.1 One-dimensional bin packing problem . . . . . . . . . . . . . . . 7\n2.5.2 Two-dimensional bin packing problem . . . . . . . . . . . . . . . 7\n2.5.3 ILP models for level packing . . . . . . . . . . . . . . . . . . . . 9\n2.6 The asymptotic and the absolute worst-case performance ratios . . . . . 11\n2.7 Upper Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.7.1 Strip packing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.7.2 Bin packing: Two-phase heuristics . . . . . . . . . . . . . . . . . 15\n2.7.3 Bin packing: One-phase level heuristics . . . . . . . . . . . . . . 17\n2.7.4 Bin packing: One-phase non-level heuristics . . . . . . . . . . . . 18\n2.7.5 Metaheuristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.7.6 Approximation algorithms . . . . . . . . . . . . . . . . . . . . . . 23\n2.8 Lower Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.9 Exact Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n3 Two-Dimensional Bin Packing: the 2BP|O|G case 31\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.1.1 Our goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.1.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.1.3 Convexification Algorithm . . . . . . . . . . . . . . . . . . . . . . 34\n3.1.4 Algorithm and assumptions . . . . . . . . . . . . . . . . . . . . . 37\n3.2 Smallest non-separable pattern . . . . . . . . . . . . . . . . . . . . . . . 38\n3.2.1 Rows and Intersections . . . . . . . . . . . . . . . . . . . . . . . 38\n3.3 Blocked Ring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n3.3.1 Detecting a Blocked Ring . . . . . . . . . . . . . . . . . . . . . . 41\n3.4 Blocked Ring characterization . . . . . . . . . . . . . . . . . . . . . . . . 48\n3.4.1 Single Blocked Ring . . . . . . . . . . . . . . . . . . . . . . . . . 48\n3.4.2 Multiple Blocked Ring . . . . . . . . . . . . . . . . . . . . . . . . 49\n3.5 Worst-case analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n3.5.1 Case 1: P is a Simple Blocked Ring . . . . . . . . . . . . . . . . 53\n3.5.2 Case 2: P is a Single Blocked Ring . . . . . . . . . . . . . . . . . 53\n4 Partial enumeration algorithms for 2BP|O|G 59\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.2 Basic Heuristic Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n4.2.1 Packing the current bin . . . . . . . . . . . . . . . . . . . . . . . 61\n4.2.2 Selection rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n4.2.3 Guillotine split rule . . . . . . . . . . . . . . . . . . . . . . . . . 63\n4.3 Enhanced Heuristic Algorithm . . . . . . . . . . . . . . . . . . . . . . . 64\n4.3.1 Removing duplicated nodes . . . . . . . . . . . . . . . . . . . . . 64\n4.3.2 Heuristic pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n4.4 Computational experiments . . . . . . . . . . . . . . . . . . . . . . . . . 65\n4.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\nList of Figures\n2.1 Fekete and Schepers modeling approach. . . . . . . . . . . . . . . . . . 9\n2.2 Three classical strategies for the level packing. . . . . . . . . . . . . . . 13\n2.3 Algorithm HFF. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.4 Algorithm FBS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.5 Algorithm FC. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.6 Algorithm FNF. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.7 Algorithm FFF. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.8 Algorithm FBL. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.9 Algorithm NBL. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.10 Algorithm AD. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.11 Worst-case of the area bound. . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.12 (a) items in I1, I2 and I3; (b) relaxed instance with reduced items. . . . 26\n3.1 Example of guillotine pattern. . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.2 The convexification algorithm. . . . . . . . . . . . . . . . . . . . . . . . 34\n3.3 Convexification algorithm: step 2. . . . . . . . . . . . . . . . . . . . . . 34\n3.4 Convexification algorithm: step 3. . . . . . . . . . . . . . . . . . . . . . 35\n3.5 Convexification algorithm: step 5. . . . . . . . . . . . . . . . . . . . . . 35\n3.6 Convexification Algorithm on a separable pattern that produces a non\u0002separable pattern. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n3.7 Patterns with 3 items. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.8 Patterns with 4 items. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n3.9 The packing algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n3.10 Separable and non-separable rows. . . . . . . . . . . . . . . . . . . . . . 39\n3.11 Pattern with 5 items, x = 3 and y = 1. . . . . . . . . . . . . . . . . . . . 40\n3.12 Patterns with 5 items: xh = 4, xv = 0 e y = 0, xh = 3, xv = 1 e y = 0. . 40\n3.13 Simple Blocked Ring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.14 Two examples where we apply the algorithm to detect Blocked Ring. . . 42\n3.15 Step 1: Items interested by the selected vertical rows (ex.1). . . . . . . . 42\n3.16 Step 1: Items interested by the selected vertical rows (ex.2). . . . . . . . 43\n3.17 Step 1: Items interested by the selected horizontal rows (ex.1). . . . . . 43\n3.18 Step 1: Items interested by the selected horizontal rows (ex.2). . . . . . 43\n3.19 Step 2: Items to keep (ex.1). . . . . . . . . . . . . . . . . . . . . . . . . 43\n3.20 Step 2: Items to keep (ex.2). . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.21 Step 3: Items after Convexification Algorithm execution (ex.1). . . . . . 44\n3.22 Step 3: Items after Convexification Algorithm execution (ex.2). . . . . . 44\n3.23 Edge-to-edge cut on a non-separable rows pattern. . . . . . . . . . . . . 45\n3.24 How to place row C. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\nv\n3.25 How to place row D (case 1). . . . . . . . . . . . . . . . . . . . . . . . . 47\n3.26 How to place row D (case 2). . . . . . . . . . . . . . . . . . . . . . . . . 47\n3.27 Single Blocked Ring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n3.28 Nested Blocked Ring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n3.29 Concatenated Blocked Ring. . . . . . . . . . . . . . . . . . . . . . . . . . 50\n3.30 Complex Blocked Ring. . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n3.31 Non guillotinable pattern. . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n3.32 Worst-case for problem P1 when P is a Single Blocked Ring. . . . . . . 54\n4.1 Example of...",
      "url": "https://amsdottorato.unibo.it/id/eprint/6810/1/PhD_Pietrobuoni.pdf"
    },
    {
      "title": "[PDF] A General Heuristic Approach for Maximum Polygon Packing",
      "text": "A General Heuristic Approach for Maximum\nPolygon Packing\nCanhui Luo #\nHuazhong University of Science and Technology, Wuhan, China\nZhouxing Su1 #\nHuazhong University of Science and Technology, Wuhan, China\nZhipeng L\u00fc #\nHuazhong University of Science and Technology, Wuhan, China\nAbstract\nThis work proposes a general heuristic packing approach to address the Maximum Polygon Packing\nProblem introduced by the CG:SHOP 2024 Challenge. Our solver primarily consists of two steps:\n(1) Partitioning the container and polygons to form a series of small-scale subproblems; (2) For each\nsubproblem, sequentially placing polygons into the container and attempting to eliminate overlaps.\n2012 ACM Subject Classification Theory of computation \u2192 Computational geometry; Computing\nmethodologies \u2192 Search methodologies\nKeywords and phrases packing, polygon, heuristic, differential evolution, local search, tabu search\nDigital Object Identifier 10.4230/LIPIcs.SoCG.2024.86\nCategory CG Challenge\nFunding This work was supported in part by the National Natural Science Foundation of China\n(NSFC) under Grant 72101094 and the Special Project for Knowledge Innovation of Hubei Province\nunder Grant 2022013301015175.\nAcknowledgements We want to thank the organizers of CG:SHOP 2024 and all other participants\nfor creating such an engaging challenge. We also want to thank Dominik Krupke for providing a\nhelpful official validator for solutions.\n1 Introduction\nThe recent CG:SHOP 2024 Challenge introduced a variant of irregular packing problems\nknown as the Maximum Polygon Packing (MPP) problem. The MPP problem involves a\nconvex polygonal container C and a polygon set P = {p1, p2, ..., pN }, where polygon piis\nassociated with a value vi. It seeks for a non-overlapping packing with the maximum total\nvalue. The challenge presents a total of 180 instances whose number of polygons ranges from\n28 to 50,000. The official document [4] gives a detailed description of the challenge.\nOur proposed algorithm employs a general process to solve these instances indiscriminately,\nand the overall framework is presented in Figure 1. We first partition a large-scale problem\ninto multiple small-scale subproblems (Section 2) and then solve each subproblem using\nupper-level polygon ordering (Section 3.1) and lower-level packing optimization techniques\n(Section 3.2). Section 4 presents our experimental results, followed by conclusions.\n1 Corresponding author: Zhouxing Su\n\u00a9 Canhui Luo, Zhouxing Su, and Zhipeng L\u00fc;\nlicensed under Creative Commons License CC-BY 4.0\n40th International Symposium on Computational Geometry (SoCG 2024).\nEditors: Wolfgang Mulzer and Jeff M. Phillips; Article No. 86; pp. 86:1\u201386:9\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\n86:2 A General Heuristic Approach for Maximum Polygon Packing\nInput polygon set P and container C\nUpper-level polygon ordering\nLower-level packing optimization\nFinished?\n \nPacking\nAssemble and return the complete solution\nMPP1 MPP2 MPPm\n( ) 0? Overlap Scurr== ( ) Update Sbest best\nReturn S\nPartitioning\nYes\nNo\nYes\nNo\nSelect next one\nFigure 1 The framework of our proposed algorithm.\n2 Partitioning\nIn this section, we present the decomposition of the original large-scale problem into a series\nof smaller MPP subproblems. It involves two components: partitioning the container C into\nmultiple regions and assigning polygons to each region.\n2.1 Container Partitioning\nThe container partitioning process consists of two steps, as shown in Figure 2. Initially, we\narrange two-dimensional square grids starting from the bottom-left corner of the bounding\nbox until the entire container is covered. The subregions formed by the intersection of the\ncontainer with all the grids constitute its partition C = C1 \u222a C2 \u222a ... \u222a Cm. Subsequently,\nwe merge the small subregions with adjacent grids, which are difficult to be used effectively.\nThe grid is dimensioned to keep the scale of each subproblem at approximately 300 polygons,\nmaking a trade-off between effectiveness and efficiency of lower-level packing optimization.\n2.2 Polygon Assignment\nWe adopt a simple approach of randomly assigning polygons to each subregion. Specifically, for\neach subregion Ci, we randomly select a polygon pj from P until\nP\nj\narea(pj )\narea(Ci) \u2265\nPN\ni=0\narea(pi)\narea(C)\n.\nThe advantage of random assignment lies in ensuring that the overall characteristics of each\nsubproblem align with the original problem.\nC. Luo, Z. Su, and Z. L\u00fc 86:3\nFigure 2 The partitioning process for the instance jigsaw_cf1_4fd4c46e. Step 1 (left): Cover the\ncontainer with squares; Step 2: Intersect and merge small regions (from the middle to the right).\nminimum translation\nminimum translation\nIFP\nContainer\nFigure 3 Examples of NFP between two polygons and IFP between container and polygon.\n3 Packing\n3.1 Upper-Level Polygon Ordering\nWe define a priority for each polygon. We repeatedly select one remaining polygon with the\nhighest priority (ties are broken by value) and try to insert it into the current solution. If the\ninsertion with lower-level packing optimization fails, we skip the current polygon and turn to\nthe next one. For the majority of instances, the priority is defined as the value-to-area ratio\nof a polygon (we also call it unit value). Polygons with higher unit values are prioritized\nfor putting in the container, which is called the Unit Value First (UVF) strategy. For\nsmall-scale instances (N < 100), we employ the \u03b1\u03b2-random strategy. It randomly selects\n\u03b1% and \u03b2% of the polygons and reassigns their UVF-based priority to the highest and the\nlowest, respectively. These instances are run for multiple times to ensure comprehensive\noptimization, with \u03b1 and \u03b2 set to 10 in our implementation.\n3.2 Lower-Level Packing Optimization\nThe position of a polygon can be represented by the coordinates l = (x, y) of a reference point,\nsuch as the bottom-left corner of the boundary. Then, the translation of a polygon can be\nrepresented by a vector pointing from its original position to its new position. Given a feasible\npacking S and a polygon p to be placed, it is impossible to find a non-overlapping position\nfor p without moving other polygons in most cases. This section introduces the algorithm for\neliminating overlaps for an invalid packing, which involves solving an unconstrained nonlinear\nproblem and heuristic polygon movement.\nS o C G 2 0 2 4\n86:4 A General Heuristic Approach for Maximum Polygon Packing\n3.2.1 Overlap Minimization\nTo determine the appropriate translation for the polygons, we utilized the no-fit polygon\n(NFP) and inner-fit polygon (IFP), which are fundamental in algorithmic approaches to\ngeometric design and optimization challenges. For a fixed polygon pi and a movable polygon\npj , NFP(pi, pj ) describes their non-overlapping positions with boundaries in contact precisely,\nwhich can be utilized to determine the minimum translation for pj to avoid overlap. Similarly,\nIFP(pi, pj ) is employed to determine the minimum translation to place pj inside pi. Figure 3\nillustrates the polygon translations determined using NFP (left) and IFP (right). The readers\nmay refer to Burke et al. [2] for a more detailed description.\nFor a packing S, based on NFP and IFP, we define the overlap between polygons pi\nand pj as fij (S), representing the minimum translation to separate them, and f0i(S) as the\nminimum translation for moving pi to fit into the container. Subsequently, we employ the\nseparation algorithm proposed by Imamichi et al. [7] to minimize the overlap, which involves\nsolving an unconstrained nonlinear programming problem as follows:\nmin\nS\nF(S) = X\n0\u2264i<j\u2264N\nf\n2\nij (S) (1)\nThe model relaxes the non-overlapping constraint but introduces repulsion forces between\nany two overlapped polygons. We use the classic L-BFGS (limited memory BFGS) method\nto solve this problem. It makes the packing S converge to a local optimum but strongly\ndepends on the initial layout. ...",
      "url": "https://drops.dagstuhl.de/storage/00lipics/lipics-vol293-socg2024/LIPIcs.SoCG.2024.86/LIPIcs.SoCG.2024.86.pdf"
    },
    {
      "title": "A new approach for bin packing problem - Knowledge reuse",
      "text": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nSci Rep\n\n. 2024 Dec 30;14:31708. doi: [10.1038/s41598-024-81749-5](https://doi.org/10.1038/s41598-024-81749-5)\n\n# A new approach for bin packing problem using knowledge reuse and improved heuristic\n\n[Jie Fang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Fang%20J%22%5BAuthor%5D)\n\n### Jie Fang\n\n1Hubei Provincial Key Laboratory of Chemical Equipment Intensification and Intrinsic Safety, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n2School of Mechanical & Electrical Engineering, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n3Hubei Engineering Research Center for Intelligent Detection and Identification of Complex Parts, Wuhan, 430205 P. R. China\n\nFind articles by [Jie Fang](https://pubmed.ncbi.nlm.nih.gov/?term=%22Fang%20J%22%5BAuthor%5D)\n\n1,2,3, [Xubing Chen](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20X%22%5BAuthor%5D)\n\n### Xubing Chen\n\n1Hubei Provincial Key Laboratory of Chemical Equipment Intensification and Intrinsic Safety, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n2School of Mechanical & Electrical Engineering, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\nFind articles by [Xubing Chen](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20X%22%5BAuthor%5D)\n\n1,2,\u2709, [Yunqing Rao](https://pubmed.ncbi.nlm.nih.gov/?term=%22Rao%20Y%22%5BAuthor%5D)\n\n### Yunqing Rao\n\n4State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, 430205 P. R. China\n\nFind articles by [Yunqing Rao](https://pubmed.ncbi.nlm.nih.gov/?term=%22Rao%20Y%22%5BAuthor%5D)\n\n4, [Yili Peng](https://pubmed.ncbi.nlm.nih.gov/?term=%22Peng%20Y%22%5BAuthor%5D)\n\n### Yili Peng\n\n1Hubei Provincial Key Laboratory of Chemical Equipment Intensification and Intrinsic Safety, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n2School of Mechanical & Electrical Engineering, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\nFind articles by [Yili Peng](https://pubmed.ncbi.nlm.nih.gov/?term=%22Peng%20Y%22%5BAuthor%5D)\n\n1,2, [kuan Yan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yan%20K%22%5BAuthor%5D)\n\n### kuan Yan\n\n2School of Mechanical & Electrical Engineering, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\nFind articles by [kuan Yan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yan%20K%22%5BAuthor%5D)\n\n2\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1Hubei Provincial Key Laboratory of Chemical Equipment Intensification and Intrinsic Safety, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n2School of Mechanical & Electrical Engineering, Wuhan Institute of Technology, Wuhan, 430205 P. R. China\n\n3Hubei Engineering Research Center for Intelligent Detection and Identification of Complex Parts, Wuhan, 430205 P. R. China\n\n4State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, 430205 P. R. China\n\n\u2709\n\nCorresponding author.\n\nReceived 2024 Jun 3; Accepted 2024 Nov 28; Collection date 2024.\n\n\u00a9 The Author(s) 2024\n\n**Open Access** This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit [http://creativecommons.org/licenses/by-nc-nd/4.0/](https://creativecommons.org/licenses/by-nc-nd/4.0/).\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC11685533\u00a0\u00a0PMID: [39738365](https://pubmed.ncbi.nlm.nih.gov/39738365/)\n\n## Abstract\n\nThe two-dimensional (2D) irregular packing problem is a combinatorial optimization problem with NP-complete characteristics, which is common in the production process of clothing, ships, and plate metals. The classic packing solution is a hybrid algorithm based on heuristic positioning and meta-heuristic sequencing, which has the problems of complex solving rules and high time cost. In this study, the similarity measurement method based on the twin neural network model is used to evaluate the similarity of pieces in the source task and the target task. The reusability evaluation of packing tasks is designed to select appropriate source task knowledge. The transfer operator is used to transfer the piece sequence knowledge from the source task to complete the reuse of packing knowledge in the target task. The bottom-left algorithm is improved to complete the placement of 2D irregular pieces. The computational experiments show that the proposed algorithm for the bin packing problem using knowledge reuse and improved heuristic (KRIH) has good robustness. The KRIH algorithm can obtain 8 equal or better results on 16 instances in a relatively short time compared with some classical heuristic algorithms, which has good application potential.\n\n**Keywords:** Packing problem, Irregular piece, Knowledge reuse, Knowledge transfer, Heuristic algorithms\n\n**Subject terms:** Computational science, Applied mathematics, Mechanical engineering\n\n## Introduction\n\nPacking problems are commonly found in industries such as mechanical manufacturing, aviation, clothing, automotive manufacturing, shipbuilding, and furniture manufacturing. The manufacturing process of typical heavy industry products is shown in Fig.\u00a0[1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#Fig1). In actual production, efficient packing algorithms can improve the utilization of raw materials and reduce production costs within an acceptable time. In a sense, the reduction of raw material consumption can have a beneficial impact on the environment[1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR1). Packing problems, also known as bin packing problems or nesting problems, can be divided into three categories[2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR2): the one-dimensional (1D) packing problem (wire cutting stock problem)[3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR3), [4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR4), the two-dimensional (2D) packing problem (planar packing problem)[5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR5), [6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR6) and the three-dimensional (3D) packing problem[7](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR7). The 2D packing problem is...",
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC11685533"
    },
    {
      "title": "Compact Universal k-mer Hitting Sets",
      "text": "<div><div>\n<p><span>\nYaron Orenstein</span>, <span>\nDavid Pellow</span>, , <span>\nRon Shamir</span>, <span>\nCarl Kingsford</span>\n</p>\n<p><span>\nAugust, 2016\n</span>\n</p></div><div>\n<h3>Abstract</h3>\n<p>We address the problem of finding a minimum-size set of k-mers that hits L-long sequences. The problem arises in the design of compact hash functions and other data structures for efficient handling of large sequencing datasets. We prove that the problem of hitting a given set of L-long sequences is NP-hard and give a heuristic solution that finds a compact universal k-mer set that hits any set of L-long sequences. The algorithm, called DOCKS (design of compact k-mer sets), works in two phases: (i) finding a minimum-size k-mer set that hits every infinite sequence; (ii) greedily adding k-mers such that together they hit all remaining L-long sequences. We show that DOCKS works well in practice and produces a set of k-mers that is much smaller than a random choice of k-mers. We present results for various values of k and sequence lengths L and by applying them to two bacterial genomes show that universal hitting k-mers improve on minimizers. The software and exemplary sets are freely available at acgt.cs.tau.ac.il/docks/\"</p>\n<div>\n<p>Publication</p>\n<p>International Workshop on Algorithms in Bioinformatics</p>\n</div>\n<div>\n<p><a href=\"https://www.cs.cmu.edu/~gmarcais/\"></a></p><div>\n<h5><a href=\"https://www.cs.cmu.edu/~gmarcais/\">Guillaume Mar\u00e7ais</a></h5>\n<h6>Professor of Artificial Intelligence</h6>\n<p>My research interests include computational biology, algorithm design, graph theory</p>\n</div>\n</div>\n</div></div>",
      "url": "https://www.cs.cmu.edu/~gmarcais/publication/universal_sets"
    },
    {
      "title": "Global Optimization for \n Combinatorial Geometry Problems \n Revisited in the Era of LLMs",
      "text": "Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs\n11institutetext:Fair Isaac Deutschland GmbH, Germany,11email:timoberthold@fico.com22institutetext:Technische Universit\u00e4t Berlin, Institut f\u00fcr Mathematik, Germany33institutetext:Zuse Institute Berlin, Germany44institutetext:Fair Isaac Corporation, USA,44email:imre@polik.net# Global Optimization for\nCombinatorial Geometry Problems\nRevisited in the Era of LLMs\nTimo BertholdDominik KampGioni MexiSebastian PokuttaImre P\u00f3lik\n###### Abstract\nRecent progress in LLM-driven algorithm discovery, exemplified by DeepMind\u2019s AlphaEvolve, has produced new best-known solutions for a range of hard geometric and combinatorial problems. This raises a natural question: to what extent can modern off-the-shelf global optimization solvers match such results when the problems are formulated directly as nonlinear optimization problems (NLPs)?\nWe revisit a subset of problems from the AlphaEvolve benchmark suite and evaluate straightforward NLP formulations with two state-of-the-art solvers, the commercial FICO Xpress and the open-source SCIP. Without any solver modifications, both solvers reproduce, and in several cases improve upon, the best solutions previously reported in the literature, including the recent LLM-driven discoveries. Our results not only highlight the maturity of generic NLP technology and its ability to tackle nonlinear mathematical problems that were out of reach for general-purpose solvers only a decade ago, but also position global NLP solvers as powerful tools that may be exploited within LLM-driven algorithm discovery.\n## 1Introduction\nThe rapid progress in global optimization technology over the past decade has substantially expanded the range of nonlinear, nonconvex problems that can be solved to proven global optimality, or at least to very high-quality solutions with reliable dual bounds.\nState-of-the-art academic solvers like SCIP> [\n[> 20\n](https://arxiv.org/html/2601.05943v1#bib.bib9)> ]\nand commercial solvers like FICO\u00aeXpress> [\n[> 3\n](https://arxiv.org/html/2601.05943v1#bib.bib10)> ]\ncombine spatial branch-and-bound, automatic linearization and convexification, sophisticated presolving, and increasingly powerful primal heuristics> [\n[> 5\n](https://arxiv.org/html/2601.05943v1#bib.bib27)> , [> 6\n](https://arxiv.org/html/2601.05943v1#bib.bib28)> , [> 4\n](https://arxiv.org/html/2601.05943v1#bib.bib29)> ]\n, enabling them to solve instances that would have been considered computationally prohibitive only a few years ago.\nAt the same time, recent developments in algorithm design based on Large Language Models (LLMs) have drawn renewed attention to long-standing geometric and combinatorial problems that can be formulated as nonlinear optimization models.\nSpecifically, DeepMind presented the AlphaEvolve framework> [\n[> 19\n](https://arxiv.org/html/2601.05943v1#bib.bib4)> , [> 25\n](https://arxiv.org/html/2601.05943v1#bib.bib1)> ]\n, which uses LLM-generated code in an evolutionary search to produce high-quality solutions for an extensive set of mathematical problems, including variants of circle packing, hexagon packing, and minimum-distance configurations of points.\nThese breakthrough results raise a natural question: to what extent can state-of-the-art global optimization solvers match, or even surpass, such automatically discovered algorithms on challenging nonlinear problems?\nMore broadly, the last few years have seen rapid progress in LLM-driven discovery workflows that couple generative models with structured search and automated evaluation or verification.\nFunSearch combines an LLM with evolutionary program search and task-specific evaluators, enabling improvements for several discrete mathematical and algorithmic problems> [\n[> 28\n](https://arxiv.org/html/2601.05943v1#bib.bib5)> ]\n.\nComplementary advances include AlphaDev, which used learning-based search to rediscover and improve low-level algorithms such as sorting routines> [\n[> 24\n](https://arxiv.org/html/2601.05943v1#bib.bib6)> ]\n, and AlphaGeometry, which combines neural generation with symbolic reasoning to solve olympiad-level geometry problems without human demonstrations> [\n[> 33\n](https://arxiv.org/html/2601.05943v1#bib.bib7)> ]\n.\nRelated LLM+evolution approaches have also been used to design effective heuristics for combinatorial optimization> [\n[> 23\n](https://arxiv.org/html/2601.05943v1#bib.bib8)> ]\n.\nTaken together, these advances motivate revisiting classical mathematical optimization as a competitive and reliable baseline on the same challenging benchmarks.\nIn this work we revisit three problems from the AlphaEvolve benchmark suite and study them through the lens of Nonlinear Programming (NLP).\nAn*NLP*is an optimization problem minimizing a nonlinear objective function over a feasible set defined by nonlinear constraints on continuous variables:\n|min\u2061{f\u200b(x)\u2223gk\u200b(x)\u22640,\u2200k\u2208\ud835\udca6,\u2113\u2264x\u2264u},\\\\displaystyle\\\\min\\\\{f(x)\\\\mid g\\_{k}(x)\\\\leq 0,\\\\forall k\\\\in\\\\mathcal{K},\\\\ell\\\\leq x\\\\leq u\\\\},||(1)|\nwhere the objectivef\u200b(x)f(x)and all constraint functionsgk:\u211dn\u2192\u211dg\\_{k}:\\\\mathbb{R}^{n}\\\\rightarrow\\\\mathbb{R}are factorable and all variable bounds\u2113,u\u2208\u211d\u00af:=\u211d\u222a{\u00b1\u221e}\\\\ell,u\\\\in\\\\bar{\\\\mathbb{R}}:=\\\\mathbb{R}\\\\cup\\\\{\\\\pm\\\\infty\\\\}.\nThe set\ud835\udca6:={1,\u2026,m}\\\\mathcal{K}:=\\\\{1,\\\\dots,m\\\\}indexes the constraints.\nThe circle packing problem, the minimum-distance ratio problem and the hexagon packing problem admit compact NLP models.\nThis makes them good showcases for the power of modern global optimization tools: these combinatorial problems can be very intuitively modelled and effectively solved in their most natural form, as nonlinear optimization instances.\nWe show that combined with off-the-shelf global optimization technology, these straightforward NLP formulations not only reproduce the best solutions reported in> [\n[> 19\n](https://arxiv.org/html/2601.05943v1#bib.bib4)> , [> 25\n](https://arxiv.org/html/2601.05943v1#bib.bib1)> ]\n, but in several cases produce significantly better solutions.\nOur goal in doing so is to illustrate the power of modern general-purpose nonlinear optimization solvers rather than to perform a head-to-head comparison of solvers.\nNext to presenting simple formulations that work and identifying some key modeling decisions that drive performance, our main contributions are:\n##### Stronger solutions with unmodified solvers.\nWith off-the-shelf Xpress and SCIP we obtain solutions that match, and in multiple cases improve, previously reported best-known results. Some problems were solved with only one solver, some used both. In this paper we do not make a distinction of which solver found which solution. All the solutions that our solvers produced were verified using the validation code in the AlphaEvolve repository.\n##### Lessons learned.\nWe reflect on the respective strengths and limitations of LLM-based approaches and nonlinear optimization, discuss modeling insights, and how global optimization software has become a complementary, industry-ready tool for challenging combinatorial problems.\nThese insights are discussed in Section[5](https://arxiv.org/html/2601.05943v1#S5), while Sections[2](https://arxiv.org/html/2601.05943v1#S2)\u2013[4](https://arxiv.org/html/2601.05943v1#S4)present one model each, together with the accompanying computational results. Due to lack of space we will not comment on the dual bounds and how they could be improved (such as stronger formulations or symmetry breaking), even though it is a key differentiator between ad-hoc heuristics and general optimization solvers.\n## 2Minimizing the Ratio of Maximum to Minimum Distance\nThe problem of minimizing the ratio between the maximum and minimum pairwise distances in a finite point set, called the*min-max ratio problem*, has its origins in classical extremal geometry.\nBateman and Erd\u0151s> [\n[> 2\n](https://arxiv.org/html/2601.05943v1#bib.bib2)> ]\nformulated the question in terms of determining, for a given number of points, the configuration of point...",
      "url": "https://arxiv.org/html/2601.05943v1"
    }
  ]
}