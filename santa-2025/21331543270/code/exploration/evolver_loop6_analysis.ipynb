{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc740247",
   "metadata": {},
   "source": [
    "# Evolver Loop 6 Analysis: Fixing Overlap Detection\n",
    "\n",
    "## Critical Issue\n",
    "exp_005 failed with \"Overlapping trees in group 126\"\n",
    "\n",
    "Our relate() method found N=60 but missed N=126. We need:\n",
    "1. More robust overlap detection\n",
    "2. OR just use baseline for ALL N values that differ from baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import affinity\n",
    "from shapely.strtree import STRtree\n",
    "\n",
    "# Load submissions\n",
    "baseline_path = '/home/code/experiments/000_baseline/submission.csv'\n",
    "failed_path = '/home/code/experiments/005_fixed_submission/submission.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "failed_df = pd.read_csv(failed_path)\n",
    "\n",
    "print(f\"Baseline shape: {baseline_df.shape}\")\n",
    "print(f\"Failed submission shape: {failed_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06202d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Christmas tree polygon\n",
    "def get_tree_polygon(x, y, angle):\n",
    "    \"\"\"Create a Christmas tree polygon at (x, y) with given rotation angle.\"\"\"\n",
    "    trunk_w = 0.15\n",
    "    trunk_h = 0.2\n",
    "    base_w = 0.7\n",
    "    mid_w = 0.4\n",
    "    top_w = 0.25\n",
    "    tip_y = 0.8\n",
    "    tier_1_y = 0.5\n",
    "    tier_2_y = 0.25\n",
    "    base_y = 0.0\n",
    "    trunk_bottom_y = -trunk_h\n",
    "    \n",
    "    vertices = [\n",
    "        (0.0, tip_y),\n",
    "        (top_w / 2, tier_1_y),\n",
    "        (top_w / 4, tier_1_y),\n",
    "        (mid_w / 2, tier_2_y),\n",
    "        (mid_w / 4, tier_2_y),\n",
    "        (base_w / 2, base_y),\n",
    "        (trunk_w / 2, base_y),\n",
    "        (trunk_w / 2, trunk_bottom_y),\n",
    "        (-trunk_w / 2, trunk_bottom_y),\n",
    "        (-trunk_w / 2, base_y),\n",
    "        (-base_w / 2, base_y),\n",
    "        (-mid_w / 4, tier_2_y),\n",
    "        (-mid_w / 2, tier_2_y),\n",
    "        (-top_w / 4, tier_1_y),\n",
    "        (-top_w / 2, tier_1_y),\n",
    "    ]\n",
    "    \n",
    "    poly = Polygon(vertices)\n",
    "    poly = affinity.rotate(poly, angle, origin=(0, 0))\n",
    "    poly = affinity.translate(poly, xoff=x, yoff=y)\n",
    "    return poly\n",
    "\n",
    "def get_trees_for_n(df, n):\n",
    "    \"\"\"Extract trees for a specific N value.\"\"\"\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    n_data = df[df['id'].str.startswith(prefix)].copy()\n",
    "    \n",
    "    trees = []\n",
    "    for _, row in n_data.iterrows():\n",
    "        x = float(str(row['x']).lstrip('s'))\n",
    "        y = float(str(row['y']).lstrip('s'))\n",
    "        angle = float(str(row['deg']).lstrip('s'))\n",
    "        trees.append((x, y, angle))\n",
    "    return trees\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check N=126 specifically - this is where Kaggle found the overlap\n",
    "n = 126\n",
    "failed_trees = get_trees_for_n(failed_df, n)\n",
    "baseline_trees = get_trees_for_n(baseline_df, n)\n",
    "\n",
    "print(f\"N={n}: Failed has {len(failed_trees)} trees, Baseline has {len(baseline_trees)} trees\")\n",
    "\n",
    "# Check if they're the same\n",
    "same = True\n",
    "for i, (f, b) in enumerate(zip(failed_trees, baseline_trees)):\n",
    "    if f != b:\n",
    "        same = False\n",
    "        print(f\"Tree {i} differs:\")\n",
    "        print(f\"  Failed: {f}\")\n",
    "        print(f\"  Baseline: {b}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nN={n} same in both? {same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlaps in N=126 using multiple methods\n",
    "def check_overlaps_area(trees, tolerance=0):\n",
    "    \"\"\"Check for overlaps using intersection area.\"\"\"\n",
    "    polygons = [get_tree_polygon(x, y, a) for x, y, a in trees]\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]):\n",
    "                intersection = polygons[i].intersection(polygons[j])\n",
    "                area = intersection.area\n",
    "                if area > tolerance:\n",
    "                    overlaps.append((i, j, area))\n",
    "    return overlaps\n",
    "\n",
    "def check_overlaps_relate(trees):\n",
    "    \"\"\"Check for overlaps using relate() - more accurate.\"\"\"\n",
    "    polygons = [get_tree_polygon(x, y, a) for x, y, a in trees]\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            relate = polygons[i].relate(polygons[j])\n",
    "            # relate[0] == '2' means 2D interior intersection\n",
    "            if relate[0] == '2':\n",
    "                intersection = polygons[i].intersection(polygons[j])\n",
    "                overlaps.append((i, j, intersection.area, relate))\n",
    "    return overlaps\n",
    "\n",
    "def check_overlaps_buffer(trees, buffer_size=1e-10):\n",
    "    \"\"\"Check for overlaps using buffer method.\"\"\"\n",
    "    polygons = [get_tree_polygon(x, y, a) for x, y, a in trees]\n",
    "    \n",
    "    overlaps = []\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            # Shrink polygons slightly and check intersection\n",
    "            p1 = polygons[i].buffer(-buffer_size)\n",
    "            p2 = polygons[j].buffer(-buffer_size)\n",
    "            if p1.intersects(p2) and not p1.touches(p2):\n",
    "                overlaps.append((i, j, p1.intersection(p2).area))\n",
    "    return overlaps\n",
    "\n",
    "print(\"Checking N=126 for overlaps...\")\n",
    "print(f\"\\nArea method (tol=0): {len(check_overlaps_area(failed_trees, 0))} overlaps\")\n",
    "print(f\"Relate method: {len(check_overlaps_relate(failed_trees))} overlaps\")\n",
    "print(f\"Buffer method: {len(check_overlaps_buffer(failed_trees))} overlaps\")\n",
    "\n",
    "# Show details\n",
    "relate_overlaps = check_overlaps_relate(failed_trees)\n",
    "if relate_overlaps:\n",
    "    print(f\"\\nRelate overlaps:\")\n",
    "    for o in relate_overlaps[:5]:\n",
    "        print(f\"  Trees {o[0]}-{o[1]}: area={o[2]:.2e}, relate={o[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf447ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ALL N values in the failed submission for overlaps using relate()\n",
    "print(\"Checking ALL N values for overlaps using relate() method...\")\n",
    "\n",
    "problematic_ns = []\n",
    "for n in range(1, 201):\n",
    "    trees = get_trees_for_n(failed_df, n)\n",
    "    overlaps = check_overlaps_relate(trees)\n",
    "    if overlaps:\n",
    "        problematic_ns.append((n, overlaps))\n",
    "        print(f\"N={n}: {len(overlaps)} overlaps\")\n",
    "        for o in overlaps[:3]:\n",
    "            print(f\"  Trees {o[0]}-{o[1]}: area={o[2]:.2e}, relate={o[3]}\")\n",
    "\n",
    "print(f\"\\nTotal problematic N values: {len(problematic_ns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which N values differ from baseline\n",
    "print(\"Checking which N values differ from baseline...\")\n",
    "\n",
    "differing_ns = []\n",
    "for n in range(1, 201):\n",
    "    failed_trees = get_trees_for_n(failed_df, n)\n",
    "    baseline_trees = get_trees_for_n(baseline_df, n)\n",
    "    \n",
    "    same = True\n",
    "    for f, b in zip(failed_trees, baseline_trees):\n",
    "        if f != b:\n",
    "            same = False\n",
    "            break\n",
    "    \n",
    "    if not same:\n",
    "        differing_ns.append(n)\n",
    "\n",
    "print(f\"N values that differ from baseline: {len(differing_ns)}\")\n",
    "print(f\"First 20: {differing_ns[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAFEST APPROACH: Use baseline for ALL N values\n",
    "# The baseline passes Kaggle validation, so it's guaranteed to work\n",
    "# We can only improve by finding configurations that:\n",
    "# 1. Are better than baseline\n",
    "# 2. Pass Kaggle's strict validation\n",
    "\n",
    "# For now, let's just submit the baseline to confirm it still works\n",
    "print(\"Creating a submission using ONLY baseline configurations...\")\n",
    "\n",
    "import shutil\n",
    "shutil.copy(baseline_path, '/home/submission/submission.csv')\n",
    "\n",
    "print(\"Copied baseline to /home/submission/submission.csv\")\n",
    "print(\"This should pass Kaggle validation with score 70.676102\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fe681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Create a TRULY safe ensemble\n",
    "# Only use non-baseline configurations if they:\n",
    "# 1. Have a better score\n",
    "# 2. Pass ALL overlap checks (area, relate, buffer)\n",
    "\n",
    "def is_config_safe(trees):\n",
    "    \"\"\"Check if a configuration is safe using multiple methods.\"\"\"\n",
    "    # Method 1: Area check\n",
    "    area_overlaps = check_overlaps_area(trees, tolerance=0)\n",
    "    if area_overlaps:\n",
    "        return False, \"area\"\n",
    "    \n",
    "    # Method 2: Relate check\n",
    "    relate_overlaps = check_overlaps_relate(trees)\n",
    "    if relate_overlaps:\n",
    "        return False, \"relate\"\n",
    "    \n",
    "    # Method 3: Buffer check\n",
    "    buffer_overlaps = check_overlaps_buffer(trees, buffer_size=1e-12)\n",
    "    if buffer_overlaps:\n",
    "        return False, \"buffer\"\n",
    "    \n",
    "    return True, \"safe\"\n",
    "\n",
    "print(\"Checking which differing N values are actually safe...\")\n",
    "\n",
    "safe_improvements = []\n",
    "for n in differing_ns:\n",
    "    failed_trees = get_trees_for_n(failed_df, n)\n",
    "    is_safe, method = is_config_safe(failed_trees)\n",
    "    \n",
    "    if is_safe:\n",
    "        # Calculate scores\n",
    "        failed_polys = [get_tree_polygon(x, y, a) for x, y, a in failed_trees]\n",
    "        baseline_trees = get_trees_for_n(baseline_df, n)\n",
    "        baseline_polys = [get_tree_polygon(x, y, a) for x, y, a in baseline_trees]\n",
    "        \n",
    "        def get_score(polys, n):\n",
    "            all_coords = []\n",
    "            for p in polys:\n",
    "                all_coords.extend(list(p.exterior.coords))\n",
    "            all_coords = np.array(all_coords)\n",
    "            x_range = all_coords[:, 0].max() - all_coords[:, 0].min()\n",
    "            y_range = all_coords[:, 1].max() - all_coords[:, 1].min()\n",
    "            side = max(x_range, y_range)\n",
    "            return (side ** 2) / n\n",
    "        \n",
    "        failed_score = get_score(failed_polys, n)\n",
    "        baseline_score = get_score(baseline_polys, n)\n",
    "        \n",
    "        if failed_score < baseline_score:\n",
    "            improvement = baseline_score - failed_score\n",
    "            safe_improvements.append((n, improvement, failed_score, baseline_score))\n",
    "            print(f\"N={n}: SAFE improvement of {improvement:.6f}\")\n",
    "    else:\n",
    "        print(f\"N={n}: UNSAFE ({method})\")\n",
    "\n",
    "print(f\"\\nTotal safe improvements: {len(safe_improvements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a truly safe submission using only verified safe improvements\n",
    "print(\"\\nCreating truly safe submission...\")\n",
    "\n",
    "safe_df = baseline_df.copy()\n",
    "\n",
    "if safe_improvements:\n",
    "    for n, improvement, _, _ in safe_improvements:\n",
    "        # Remove baseline N data\n",
    "        prefix = f\"{n:03d}_\"\n",
    "        safe_df = safe_df[~safe_df['id'].str.startswith(prefix)]\n",
    "        \n",
    "        # Add failed N data (which is safe and better)\n",
    "        failed_n_data = failed_df[failed_df['id'].str.startswith(prefix)]\n",
    "        safe_df = pd.concat([safe_df, failed_n_data], ignore_index=True)\n",
    "\n",
    "# Sort by id\n",
    "safe_df['n'] = safe_df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "safe_df['tree_idx'] = safe_df['id'].apply(lambda x: int(x.split('_')[1]))\n",
    "safe_df = safe_df.sort_values(['n', 'tree_idx']).drop(columns=['n', 'tree_idx'])\n",
    "\n",
    "print(f\"Safe submission shape: {safe_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ce4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and verify the safe submission score\n",
    "from utils import score_submission\n",
    "\n",
    "safe_score, scores_by_n, overlapping_ns = score_submission(safe_df, check_overlaps=True)\n",
    "baseline_score_check, _, _ = score_submission(baseline_df, check_overlaps=False)\n",
    "\n",
    "print(f\"Safe submission score: {safe_score:.6f}\")\n",
    "print(f\"Baseline score: {baseline_score_check:.6f}\")\n",
    "print(f\"Improvement over baseline: {baseline_score_check - safe_score:.6f}\")\n",
    "print(f\"Overlapping N values (utils check): {overlapping_ns}\")\n",
    "print(f\"\\nTarget: 68.888293\")\n",
    "print(f\"Gap to target: {safe_score - 68.888293:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1289ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification using all three overlap methods\n",
    "print(\"\\nFinal verification of safe submission...\")\n",
    "\n",
    "final_problems = []\n",
    "for n in range(1, 201):\n",
    "    trees = get_trees_for_n(safe_df, n)\n",
    "    is_safe, method = is_config_safe(trees)\n",
    "    if not is_safe:\n",
    "        final_problems.append((n, method))\n",
    "        print(f\"N={n}: PROBLEM ({method})\")\n",
    "\n",
    "if not final_problems:\n",
    "    print(\"✅ All N values pass all overlap checks!\")\n",
    "else:\n",
    "    print(f\"❌ {len(final_problems)} problematic N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the safe submission\n",
    "import os\n",
    "import json\n",
    "\n",
    "work_dir = '/home/code/experiments/006_truly_safe'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "safe_df.to_csv(f'{work_dir}/submission.csv', index=False)\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': safe_score,\n",
    "    'baseline_score': baseline_score_check,\n",
    "    'improvement_over_baseline': baseline_score_check - safe_score,\n",
    "    'safe_improvements_count': len(safe_improvements),\n",
    "    'is_valid': len(final_problems) == 0\n",
    "}\n",
    "\n",
    "with open(f'{work_dir}/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Copy to submission folder\n",
    "import shutil\n",
    "shutil.copy(f'{work_dir}/submission.csv', '/home/submission/submission.csv')\n",
    "\n",
    "print(f\"Saved to {work_dir}/submission.csv\")\n",
    "print(f\"Copied to /home/submission/submission.csv\")\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
