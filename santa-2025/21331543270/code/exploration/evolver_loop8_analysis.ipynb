{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f66db6",
   "metadata": {},
   "source": [
    "# Loop 8 Analysis: Understanding the Gap and Validation Issues\n",
    "\n",
    "## Key Problems:\n",
    "1. **Validation mismatch**: 4 consecutive ensemble submissions failed Kaggle validation\n",
    "2. **Gap to target**: 70.676 vs 68.887 = 1.79 points (2.6%)\n",
    "3. **Local optimum**: bbox3, SA, fix_direction all found NO improvement on baseline\n",
    "\n",
    "## Strategy Analysis:\n",
    "- The baseline (70.676) is the ONLY valid submission\n",
    "- Ensemble approach finds 0.06 point improvement but fails validation\n",
    "- Need fundamentally different approach to close 1.79 point gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load session state\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "# Analyze experiments\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for exp in state['experiments']:\n",
    "    fallback = exp.get('used_baseline_fallback', False)\n",
    "    approach_score = exp.get('approach_score', exp['cv_score'])\n",
    "    print(f\"\\n{exp['id']}: {exp['name']}\")\n",
    "    print(f\"  CV Score: {exp['cv_score']:.6f}\")\n",
    "    print(f\"  Approach Score: {approach_score:.6f}\")\n",
    "    print(f\"  Fallback to baseline: {fallback}\")\n",
    "    if fallback:\n",
    "        print(f\"  ⚠️ APPROACH FAILED - fell back to baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze submissions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBMISSION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sub in state['submissions']:\n",
    "    lb = sub.get('lb_score')\n",
    "    error = sub.get('error')\n",
    "    print(f\"\\n{sub['experiment_id']}: {sub['model_name']}\")\n",
    "    print(f\"  CV: {sub['cv_score']:.6f}\")\n",
    "    if lb:\n",
    "        print(f\"  LB: {lb:.6f} ✅\")\n",
    "    elif error:\n",
    "        print(f\"  LB: FAILED - {error}\")\n",
    "    else:\n",
    "        print(f\"  LB: pending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theoretical minimum and gap analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_valid_lb = 70.676102\n",
    "target = 68.887226\n",
    "gap = best_valid_lb - target\n",
    "gap_pct = (gap / target) * 100\n",
    "\n",
    "print(f\"Best valid LB: {best_valid_lb:.6f}\")\n",
    "print(f\"Target: {target:.6f}\")\n",
    "print(f\"Gap: {gap:.6f} ({gap_pct:.2f}%)\")\n",
    "print()\n",
    "print(\"To reach target, we need:\")\n",
    "print(f\"  - Reduce score by {gap:.6f} points\")\n",
    "print(f\"  - That's {gap / 200:.6f} points per N on average\")\n",
    "print(f\"  - Or {gap / 200 / 0.35 * 100:.1f}% improvement per N (assuming avg score ~0.35)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec330c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline and analyze per-N scores\n",
    "baseline_path = '/home/code/experiments/000_baseline/submission.csv'\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PER-N SCORE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from decimal import Decimal, getcontext\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "\n",
    "getcontext().prec = 25\n",
    "scale_factor = Decimal(\"1e15\")\n",
    "\n",
    "class ChristmasTree:\n",
    "    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n",
    "        self.center_x = Decimal(str(center_x).replace('s', ''))\n",
    "        self.center_y = Decimal(str(center_y).replace('s', ''))\n",
    "        self.angle = Decimal(str(angle).replace('s', ''))\n",
    "\n",
    "        trunk_w = Decimal(\"0.15\")\n",
    "        trunk_h = Decimal(\"0.2\")\n",
    "        base_w = Decimal(\"0.7\")\n",
    "        mid_w = Decimal(\"0.4\")\n",
    "        top_w = Decimal(\"0.25\")\n",
    "        tip_y = Decimal(\"0.8\")\n",
    "        tier_1_y = Decimal(\"0.5\")\n",
    "        tier_2_y = Decimal(\"0.25\")\n",
    "        base_y = Decimal(\"0.0\")\n",
    "        trunk_bottom_y = -trunk_h\n",
    "\n",
    "        initial_polygon = Polygon([\n",
    "            (float(Decimal(\"0.0\") * scale_factor), float(tip_y * scale_factor)),\n",
    "            (float(top_w / Decimal(\"2\") * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(top_w / Decimal(\"4\") * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(mid_w / Decimal(\"2\") * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(mid_w / Decimal(\"4\") * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(base_w / Decimal(\"2\") * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(trunk_w / Decimal(\"2\") * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(trunk_w / Decimal(\"2\") * scale_factor), float(trunk_bottom_y * scale_factor)),\n",
    "            (float(-(trunk_w / Decimal(\"2\")) * scale_factor), float(trunk_bottom_y * scale_factor)),\n",
    "            (float(-(trunk_w / Decimal(\"2\")) * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(-(base_w / Decimal(\"2\")) * scale_factor), float(base_y * scale_factor)),\n",
    "            (float(-(mid_w / Decimal(\"4\")) * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(-(mid_w / Decimal(\"2\")) * scale_factor), float(tier_2_y * scale_factor)),\n",
    "            (float(-(top_w / Decimal(\"4\")) * scale_factor), float(tier_1_y * scale_factor)),\n",
    "            (float(-(top_w / Decimal(\"2\")) * scale_factor), float(tier_1_y * scale_factor)),\n",
    "        ])\n",
    "        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n",
    "        self.polygon = affinity.translate(\n",
    "            rotated,\n",
    "            xoff=float(self.center_x * scale_factor),\n",
    "            yoff=float(self.center_y * scale_factor),\n",
    "        )\n",
    "\n",
    "def load_trees_for_n(df, n):\n",
    "    prefix = f\"{n:03d}_\"\n",
    "    subset = df[df['id'].str.startswith(prefix)]\n",
    "    trees = []\n",
    "    for _, row in subset.iterrows():\n",
    "        x = str(row['x']).replace('s', '')\n",
    "        y = str(row['y']).replace('s', '')\n",
    "        deg = str(row['deg']).replace('s', '')\n",
    "        trees.append(ChristmasTree(x, y, deg))\n",
    "    return trees\n",
    "\n",
    "def calculate_score(trees, n):\n",
    "    xys = np.concatenate([np.asarray(t.polygon.exterior.xy).T / float(scale_factor) for t in trees])\n",
    "    min_x, min_y = xys.min(axis=0)\n",
    "    max_x, max_y = xys.max(axis=0)\n",
    "    side_length = max(max_x - min_x, max_y - min_y)\n",
    "    return side_length**2 / n\n",
    "\n",
    "print(\"Loading baseline scores...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19172d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-N scores\n",
    "scores = {}\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees_for_n(baseline_df, n)\n",
    "    if len(trees) == n:\n",
    "        scores[n] = calculate_score(trees, n)\n",
    "\n",
    "print(f\"Calculated scores for {len(scores)} N values\")\n",
    "print(f\"Total score: {sum(scores.values()):.6f}\")\n",
    "\n",
    "# Find N values with highest scores (most room for improvement)\n",
    "scores_sorted = sorted(scores.items(), key=lambda x: -x[1])\n",
    "print(\"\\nTop 20 N values by score (highest = most room for improvement):\")\n",
    "for n, score in scores_sorted[:20]:\n",
    "    print(f\"  N={n:3d}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d28700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theoretical minimum analysis\n",
    "# The minimum score per N is approximately 0.355 (from eazy optimizer comments)\n",
    "theoretical_min_per_n = 0.355\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"THEORETICAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "theoretical_total = sum(theoretical_min_per_n for _ in range(1, 201))\n",
    "print(f\"Theoretical minimum (0.355 * 200): {theoretical_total:.2f}\")\n",
    "print(f\"Current baseline total: {sum(scores.values()):.6f}\")\n",
    "print(f\"Gap from theoretical: {sum(scores.values()) - theoretical_total:.2f}\")\n",
    "print()\n",
    "print(\"Note: The theoretical minimum of 0.355 per N is an approximation.\")\n",
    "print(\"Actual minimum varies by N and may be lower for some N values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which N values are furthest from theoretical minimum\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"N VALUES FURTHEST FROM THEORETICAL MINIMUM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gaps = [(n, score - theoretical_min_per_n) for n, score in scores.items()]\n",
    "gaps_sorted = sorted(gaps, key=lambda x: -x[1])\n",
    "\n",
    "print(\"\\nTop 20 N values with largest gap from theoretical minimum:\")\n",
    "for n, gap in gaps_sorted[:20]:\n",
    "    print(f\"  N={n:3d}: score={scores[n]:.6f}, gap={gap:.6f}\")\n",
    "\n",
    "print(\"\\nBottom 20 N values (closest to theoretical minimum):\")\n",
    "for n, gap in gaps_sorted[-20:]:\n",
    "    print(f\"  N={n:3d}: score={scores[n]:.6f}, gap={gap:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919742cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and recommendations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "1. VALIDATION PROBLEM:\n",
    "   - 4 consecutive ensemble submissions failed Kaggle validation\n",
    "   - Local overlap detection doesn't match Kaggle's\n",
    "   - Need to use Kaggle's EXACT validation (scale_factor=1e18, intersects() and not touches())\n",
    "\n",
    "2. LOCAL OPTIMUM PROBLEM:\n",
    "   - Baseline is at a tight local optimum\n",
    "   - bbox3, SA, fix_direction all found NO improvement\n",
    "   - Need fundamentally different approach\n",
    "\n",
    "3. GAP ANALYSIS:\n",
    "   - Current: 70.676, Target: 68.887, Gap: 1.79 points (2.6%)\n",
    "   - Small N values (1-20) have highest scores - most room for improvement\n",
    "   - N=1 alone contributes 0.66 points (optimal is 0.35)\n",
    "\n",
    "4. RECOMMENDED APPROACHES:\n",
    "   a) Focus on small N values (1-30) where gap is largest\n",
    "   b) Try eazy optimizer with multi-scale approach\n",
    "   c) Implement fractional translation from jonathanchan kernel\n",
    "   d) Use ultra-conservative validation before submission\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d86c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have eazy optimizer available\n",
    "import os\n",
    "\n",
    "eazy_paths = []\n",
    "for root, dirs, files in os.walk('/home/nonroot/snapshots'):\n",
    "    for f in files:\n",
    "        if 'eazy' in f.lower():\n",
    "            eazy_paths.append(os.path.join(root, f))\n",
    "\n",
    "print(\"Eazy optimizer files found:\")\n",
    "for p in eazy_paths[:10]:\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "if not eazy_paths:\n",
    "    print(\"No eazy optimizer found - need to compile from source\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
