# Santa 2025 - Christmas Tree Packing Challenge - Loop 2 Strategy

## Current Status
- Best CV score: 70.676102 from exp_000 (baseline)
- Best LB score: 70.676102 (submitted, CV-LB gap: 0.0000 - perfect calibration!)
- Target: 68.890873 | Gap to target: 1.785 points (2.59%)
- Submissions remaining: 93/100

## Key Findings from Analysis

### 1. Better Baseline Available - CRITICAL!
- Best snapshot found: **70.627569** (snapshot 21329069570)
- Path: `/home/nonroot/snapshots/santa-2025/21329069570/code/code/solutions/submission_70.627569.csv`
- This is **0.049 points better** than current baseline
- **FIRST PRIORITY: Use this better baseline**

### 2. Per-N Score Analysis
- Small N values (1-10) contribute disproportionately to total score
- N=1 alone contributes 0.66 points (0.94% of total)
- Theoretical minimum (perfect packing): 49.125
- Current packing efficiency: 69.51%
- Need to improve efficiency to ~71.2% to hit target

### 3. Techniques from Top Kernels
From saspav/santa-submission and jonathanchan kernels:
1. **Ensemble approach** - Collect best per-N solutions from multiple sources
2. **fix_direction** - Optimize rotation angle for entire configuration  
3. **fractional_translation** - Micro-adjustments (0.001 to 0.00001 step sizes)
4. **SA with translations** - Simulated annealing with position perturbations

### 4. Research Insights (from WebSearch)
- Top competitors use SA with C++ optimization, NOT neural networks
- Strategy: N<58 use chaotic SA packing, N>58 use crystalline/lattice packing
- The 'shake' approach dominates (high temp random, low temp micro-adjust)
- Fractional translation is critical for final refinement

## Response to Evaluator

The evaluator correctly identified:
1. **Better baseline available** - Agreed, will use 70.627569 snapshot
2. **No code infrastructure** - Will create reusable utils.py
3. **Per-N analysis not actionable** - Now have detailed breakdown

## EXPERIMENT 1: Better Baseline + Ensemble (DO THIS NOW)

### Goal
Improve from 70.676 to ~70.55 by using better sources and ensemble

### Steps
1. **Create code infrastructure** (`/home/code/utils.py`):
   - ChristmasTree class with 15-vertex polygon
   - Score calculation function
   - Overlap detection function (use Shapely with STRtree)
   - Submission I/O functions

2. **Load best available baseline**:
   ```python
   best_path = '/home/nonroot/snapshots/santa-2025/21329069570/code/code/solutions/submission_70.627569.csv'
   ```

3. **Scan ALL snapshots for best per-N solutions**:
   - Search all CSV files in `/home/nonroot/snapshots/santa-2025/`
   - For each N (1-200), find the configuration with lowest score
   - Validate no overlaps before accepting

4. **Create ensemble submission**:
   - For each N, select the best valid configuration
   - Combine into single submission.csv
   - Calculate total score

5. **Save and submit**:
   - Save to `/home/code/experiments/001_ensemble/submission.csv`
   - Copy to `/home/submission/submission.csv`
   - Submit for LB feedback

### Key Files to Reference
- `/home/code/research/kernels/saspav_santa-submission/santa-submission.ipynb` - Has ensemble code
- `/home/code/research/kernels/jonathanchan_santa25-ensemble-sa-fractional-translation/` - Has scoring code

### Expected Improvement
- From 70.676 to ~70.55-70.60
- Improvement of 0.05-0.15 points

## SUBMISSION STRATEGY
- **SUBMIT AFTER THIS EXPERIMENT** - We have 93 submissions remaining
- LB feedback is critical for calibration
- Even if score doesn't improve much, we learn what works

## What NOT to Try
- ❌ Running bbox3/shake_public binaries (blocked after baseline)
- ❌ Neural network approaches (research shows SA dominates)
- ❌ Pure Python SA (too slow)
- ❌ "More iterations" on same optimizer

## Validation Notes
- CV-LB gap is 0.0000 - scoring is perfectly calibrated
- Always validate no overlaps before submission
- Use Shapely with high precision (scale_factor = 1e18) for collision detection