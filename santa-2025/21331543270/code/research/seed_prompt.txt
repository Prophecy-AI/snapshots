# Santa 2025 - Christmas Tree Packing Challenge - Loop 4 Strategy

## Current Status
- Best CV score: 70.615786 from exp_002 (fixed ensemble)
- Best LB score: 70.676102 (baseline - ONLY submission that passed Kaggle validation)
- Target: 68.888293 | Gap to target: 1.79 points (2.6%)
- Submissions remaining: 93/100 (ABUNDANT - use them!)

## ⚠️ CRITICAL ISSUE: ENSEMBLE APPROACHES KEEP FAILING KAGGLE VALIDATION

**Submission History:**
- exp_000 (baseline, 70.676): ✅ PASSED Kaggle validation
- exp_001 (ensemble, 70.615): ❌ FAILED - "Overlapping trees in group 002"
- exp_002 (fixed ensemble, 70.615): ❌ FAILED - "Overlapping trees in group 003"

**Root Cause:** Our overlap detection (tolerance=1e-15) is STILL not strict enough to match Kaggle's validation. Ensemble approaches select configurations from different sources that have tiny numerical precision issues.

**The Baseline is at a Local Optimum:**
- C++ optimizer sa_v1_parallel: No improvement on baseline
- C++ optimizer bbox3: No improvement on baseline
- The baseline (70.676) cannot be improved by local search

## Response to Evaluator

The evaluator suggested running C++ optimizers on the ensemble. I tested this:
- sa_v1_parallel on safe_ensemble: 70.615788 → 70.615754 (improvement of 0.00003)
- This is negligible and the ensemble still fails Kaggle validation

**The evaluator's key insight is correct:** We need to use available tools. But the problem is that:
1. The baseline is at a local optimum (optimizers can't improve it)
2. Ensemble approaches fail Kaggle validation
3. We're stuck between a valid-but-suboptimal baseline and invalid-but-better ensembles

## STRATEGIC DECISION: USE C++ OPTIMIZER TO GENERATE VALID CONFIGURATIONS

The key insight is that C++ optimizers (bbox3, sa_v1_parallel) produce VALID configurations. If we:
1. Start from the baseline (which passes Kaggle)
2. Run the C++ optimizer on INDIVIDUAL N values that have room for improvement
3. The optimizer will produce valid configurations

### EXPERIMENT 3: Optimize Individual N Values with C++ Tools

**Goal:** Improve specific N values using C++ optimizers, which produce valid output.

**Steps:**
1. Identify N values where the baseline has the most room for improvement
2. For each target N, create a mini-submission with just that N
3. Run bbox3/sa_v1_parallel on that mini-submission with MANY iterations
4. If improved, replace that N in the baseline
5. Verify the combined submission passes validation
6. Submit to get LB feedback

**Target N Values (from per-N analysis):**
- N=54: baseline=0.361, potential improvement ~0.005
- N=57: baseline=0.358, potential improvement ~0.005
- N=43: baseline=0.370, potential improvement ~0.003
- N=128: baseline=0.344, potential improvement ~0.003
- N=88: baseline=0.351, potential improvement ~0.002

**Implementation:**
```python
# For each target N:
# 1. Extract N from baseline
# 2. Run: bbox3 -i n_only.csv -n 100000 (many iterations)
# 3. Check if improved
# 4. If improved, replace in baseline
```

**Expected Outcome:**
- Small improvement over baseline (0.01-0.05 points)
- VALID submission that passes Kaggle

## ALTERNATIVE: Research Fundamentally Different Approaches

The gap to target (1.79 points) is too large for optimization-based approaches. In parallel, research:

1. **Tessellation patterns for large N** - Chris Deotte's discussion mentions this
2. **Asymmetric solutions** - Discussion "Why the winning solutions will be Asymmetric" (39 votes)
3. **Different optimization algorithms** - Genetic algorithms, constraint programming

## SUBMISSION STRATEGY
- **SUBMIT AFTER THIS EXPERIMENT** - We have 93 submissions remaining
- Even small improvements give us LB feedback
- We need to verify our approach produces valid submissions

## What NOT to Try
- ❌ More ensemble attempts (they keep failing validation)
- ❌ Running optimizers on the full baseline (it's at a local optimum)
- ❌ Expecting micro-optimizations to close the 1.79 point gap

## Validation Notes
- ONLY the baseline (70.676102) has passed Kaggle validation
- All ensemble attempts have failed
- Use C++ optimizers to generate configurations (they produce valid output)
- Test each N value individually before combining

## Key Files
- Baseline: `/home/code/experiments/000_baseline/submission.csv`
- C++ optimizers: `/home/nonroot/snapshots/santa-2025/21329069570/code/code/bbox3` and `sa_v1_parallel`
- Utils: `/home/code/utils.py`
