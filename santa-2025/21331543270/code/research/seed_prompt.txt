# Santa 2025 - Christmas Tree Packing Challenge - Loop 4 Strategy

## Current Status
- Best CV score: 70.615786 from exp_002 (fixed ensemble)
- Best LB score: 70.676102 (baseline - ensemble failed due to overlaps, fixed version NOT YET SUBMITTED)
- Target: 68.888293 | Gap to target: 1.727 points (2.50%)
- Submissions remaining: 93/100

## ⚠️ CRITICAL: SUBMIT THE FIXED ENSEMBLE FIRST!

The fixed ensemble (70.615786) has NOT been submitted to LB yet. With 93 submissions remaining:
1. **SUBMIT exp_002 IMMEDIATELY** to verify CV-LB calibration
2. This gives us LB feedback on the ensemble approach
3. Then proceed with optimization experiments

## Response to Evaluator

The evaluator correctly identified:
1. **C++ optimizers can improve the score** - TESTED: sa_v1_parallel only improved by 0.00003 points (70.615786 → 70.615753). We're at a local optimum.
2. **Fixed ensemble not submitted** - AGREED. Must submit to get LB feedback.
3. **Small N values underoptimized** - Valid concern, but micro-optimizations won't close 1.727 point gap.

**Key insight from testing**: Running C++ optimizers longer does NOT help. The ensemble is already at a local optimum. We need a fundamentally different approach.

## ⛔ BLOCKED APPROACHES (DO NOT USE)
- ❌ Running bbox3/sa_v1_parallel/sa_fast_v2 with "more iterations" - PROVEN INEFFECTIVE
- ❌ Parameter tuning on existing optimizers - We're at local optimum
- ❌ Ensemble from same sources - Already done, only 0.06 improvement

## ✅ REQUIRED: FUNDAMENTALLY DIFFERENT APPROACH

The gap is 1.727 points (2.50%). This requires a PARADIGM SHIFT, not micro-optimization.

### Research Insights:
1. **Tessellation patterns** are key for efficient packing
2. **Crystalline/lattice patterns** work better for large N (N > 58)
3. **Chaotic SA packing** works better for small N (N < 58)
4. Top competitors achieve scores below 69 using these techniques

### Experiment 3: Implement Tessellation-Based Packing for Large N

**Goal**: Improve scores for N > 100 using tessellation patterns

**Approach**:
1. Study the structure of optimal solutions for large N
2. Identify tessellation patterns (hexagonal, diagonal, etc.)
3. Implement constructive algorithm that builds from tessellation template
4. Test on N=100, 150, 200 first

**Implementation Steps**:
```python
# 1. Analyze current best solutions for large N
# What patterns do they exhibit?
# Are trees arranged in rows? Diagonal patterns? Hexagonal?

# 2. Create tessellation template
# For N trees, calculate optimal grid arrangement
# Consider tree dimensions: height=1.0, width=0.7

# 3. Build solution from template
# Place trees according to tessellation pattern
# Optimize rotation angles to minimize overlap

# 4. Compare with current best
# If better, use as new baseline
# If worse, analyze why and adjust
```

**Expected Outcome**:
- Large N values (100-200) have more room for improvement
- Tessellation patterns can achieve better packing density
- Even small improvements per N add up across 100 N values

### Alternative: Genetic Algorithm with Population Diversity

If tessellation doesn't work, try:
1. Initialize population with diverse solutions (not just SA results)
2. Custom crossover: swap partial solutions between candidates
3. Custom mutation: rotate/translate clusters of trees
4. Selection based on per-N improvement potential

## SUBMISSION STRATEGY
- **SUBMIT exp_002 FIRST** - Get LB feedback on fixed ensemble
- **SUBMIT after each experiment** - We have 93 submissions, use them!
- LB feedback is critical for understanding what works

## Validation Notes
- CV-LB gap is 0.0000 for baseline (perfect calibration)
- Always verify no overlaps with tolerance=1e-15 before submission
- Use utils.py functions for scoring and validation

## Files to Reference
- `/home/code/utils.py` - Scoring and validation utilities
- `/home/code/experiments/002_fixed_ensemble/submission.csv` - Current best valid submission
- `/home/nonroot/snapshots/santa-2025/21329069570/code/code/sa_v1_parallel` - C++ optimizer (limited effectiveness)

## What NOT to Try
- ❌ More SA iterations (proven ineffective)
- ❌ Different SA parameters (local optimum)
- ❌ Python-based micro-optimization (too slow, limited improvement)
- ❌ Ensemble from same snapshot sources (already done)
