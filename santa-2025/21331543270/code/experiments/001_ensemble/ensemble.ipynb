{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84f57e7",
   "metadata": {},
   "source": [
    "# Experiment 001: Ensemble from All Snapshots\n",
    "\n",
    "Goal: Improve from 70.676 to ~70.55 by using better sources and ensemble approach.\n",
    "\n",
    "Strategy:\n",
    "1. Load best available baseline (70.627569)\n",
    "2. Scan ALL snapshots for best per-N solutions\n",
    "3. For each N, select the configuration with lowest score that has no overlaps\n",
    "4. Create ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/code')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import (\n",
    "    ChristmasTree, load_submission, load_trees_for_n, get_trees_data_for_n,\n",
    "    has_overlap, get_bounding_box_side, calculate_score_for_n, score_submission,\n",
    "    find_all_submission_csvs, is_valid_submission, save_submission\n",
    ")\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "print(\"Utilities loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best available baseline\n",
    "best_baseline_path = '/home/nonroot/snapshots/santa-2025/21329069570/code/code/solutions/submission_70.627569.csv'\n",
    "baseline_df = load_submission(best_baseline_path)\n",
    "print(f\"Baseline loaded: {baseline_df.shape}\")\n",
    "\n",
    "# Score the baseline\n",
    "baseline_score, baseline_scores_by_n, baseline_overlaps = score_submission(baseline_df, check_overlaps=True)\n",
    "print(f\"Baseline score: {baseline_score:.6f}\")\n",
    "print(f\"Baseline overlaps: {baseline_overlaps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files in snapshots\n",
    "snapshot_base = '/home/nonroot/snapshots/santa-2025/'\n",
    "all_csvs = find_all_submission_csvs(snapshot_base)\n",
    "print(f\"Found {len(all_csvs)} CSV files in snapshots\")\n",
    "\n",
    "# Filter to only valid submissions\n",
    "valid_submissions = []\n",
    "for csv_path in all_csvs:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if is_valid_submission(df):\n",
    "            valid_submissions.append(csv_path)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"Found {len(valid_submissions)} valid submission files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efaf7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each N, find the best score across all submissions\n",
    "# Store: best_per_n[n] = {'score': score, 'source': path, 'data': df_rows}\n",
    "\n",
    "best_per_n = {}\n",
    "\n",
    "# Initialize with baseline\n",
    "for n in range(1, 201):\n",
    "    trees = load_trees_for_n(baseline_df, n)\n",
    "    score_n = calculate_score_for_n(trees, n)\n",
    "    data = get_trees_data_for_n(baseline_df, n)\n",
    "    best_per_n[n] = {\n",
    "        'score': score_n,\n",
    "        'source': best_baseline_path,\n",
    "        'data': data,\n",
    "        'has_overlap': False\n",
    "    }\n",
    "\n",
    "print(f\"Initialized best_per_n with baseline scores\")\n",
    "print(f\"Sample - N=1: score={best_per_n[1]['score']:.6f}\")\n",
    "print(f\"Sample - N=100: score={best_per_n[100]['score']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan all valid submissions for better per-N scores\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "improvements = defaultdict(list)\n",
    "processed = 0\n",
    "\n",
    "for csv_path in valid_submissions:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        for n in range(1, 201):\n",
    "            trees = load_trees_for_n(df, n)\n",
    "            if len(trees) != n:\n",
    "                continue\n",
    "            \n",
    "            # Calculate score\n",
    "            score_n = calculate_score_for_n(trees, n)\n",
    "            \n",
    "            # Only consider if better than current best\n",
    "            if score_n < best_per_n[n]['score']:\n",
    "                # Check for overlaps\n",
    "                has_ovlp, _ = has_overlap(trees, tolerance=1e-12)\n",
    "                \n",
    "                if not has_ovlp:\n",
    "                    improvement = best_per_n[n]['score'] - score_n\n",
    "                    improvements[n].append({\n",
    "                        'improvement': improvement,\n",
    "                        'new_score': score_n,\n",
    "                        'old_score': best_per_n[n]['score'],\n",
    "                        'source': csv_path\n",
    "                    })\n",
    "                    \n",
    "                    # Update best\n",
    "                    data = get_trees_data_for_n(df, n)\n",
    "                    best_per_n[n] = {\n",
    "                        'score': score_n,\n",
    "                        'source': csv_path,\n",
    "                        'data': data,\n",
    "                        'has_overlap': False\n",
    "                    }\n",
    "        \n",
    "        processed += 1\n",
    "        if processed % 50 == 0:\n",
    "            print(f\"Processed {processed}/{len(valid_submissions)} submissions...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nProcessed {processed} submissions\")\n",
    "print(f\"Found improvements for {len(improvements)} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top improvements\n",
    "all_improvements = []\n",
    "for n, imps in improvements.items():\n",
    "    for imp in imps:\n",
    "        all_improvements.append((n, imp['improvement'], imp['new_score'], imp['source']))\n",
    "\n",
    "all_improvements.sort(key=lambda x: -x[1])  # Sort by improvement descending\n",
    "\n",
    "print(\"Top 20 improvements found:\")\n",
    "print(\"-\" * 80)\n",
    "for n, imp, new_score, source in all_improvements[:20]:\n",
    "    short_source = source.split('/')[-1]\n",
    "    print(f\"N={n:3d}: improvement={imp:.6f}, new_score={new_score:.6f}, source={short_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02179261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble score\n",
    "ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201))\n",
    "print(f\"\\nEnsemble score: {ensemble_score:.6f}\")\n",
    "print(f\"Baseline score: {baseline_score:.6f}\")\n",
    "print(f\"Improvement: {baseline_score - ensemble_score:.6f}\")\n",
    "print(f\"\\nTarget: 68.890873\")\n",
    "print(f\"Gap to target: {ensemble_score - 68.890873:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ced0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble submission\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    ensemble_rows.append(best_per_n[n]['data'])\n",
    "\n",
    "ensemble_df = pd.concat(ensemble_rows, ignore_index=True)\n",
    "print(f\"Ensemble submission shape: {ensemble_df.shape}\")\n",
    "\n",
    "# Verify the ensemble\n",
    "ensemble_verify_score, _, ensemble_overlaps = score_submission(ensemble_df, check_overlaps=True)\n",
    "print(f\"Verified ensemble score: {ensemble_verify_score:.6f}\")\n",
    "print(f\"Ensemble overlaps: {ensemble_overlaps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764111a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble submission\n",
    "ensemble_path = '/home/code/experiments/001_ensemble/submission.csv'\n",
    "ensemble_df.to_csv(ensemble_path, index=False)\n",
    "print(f\"Saved ensemble to {ensemble_path}\")\n",
    "\n",
    "# Copy to submission folder\n",
    "import shutil\n",
    "shutil.copy(ensemble_path, '/home/submission/submission.csv')\n",
    "print(\"Copied to /home/submission/submission.csv\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'cv_score': ensemble_verify_score,\n",
    "    'baseline_score': baseline_score,\n",
    "    'improvement': baseline_score - ensemble_verify_score,\n",
    "    'n_improved': len(improvements),\n",
    "    'overlaps': ensemble_overlaps\n",
    "}\n",
    "with open('/home/code/experiments/001_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"\\nMetrics saved: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ad682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 001: ENSEMBLE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Baseline score: {baseline_score:.6f}\")\n",
    "print(f\"Ensemble score: {ensemble_verify_score:.6f}\")\n",
    "print(f\"Improvement: {baseline_score - ensemble_verify_score:.6f}\")\n",
    "print(f\"N values improved: {len(improvements)}\")\n",
    "print(f\"Overlaps: {len(ensemble_overlaps)}\")\n",
    "print(f\"\\nTarget: 68.890873\")\n",
    "print(f\"Gap to target: {ensemble_verify_score - 68.890873:.6f} ({(ensemble_verify_score - 68.890873) / 68.890873 * 100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
