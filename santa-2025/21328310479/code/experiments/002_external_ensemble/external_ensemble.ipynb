{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a51a98",
   "metadata": {},
   "source": [
    "# External Ensemble - Access External Data Sources\n",
    "\n",
    "Access external data sources to find better solutions for specific N values:\n",
    "1. SmartManoj GitHub submission\n",
    "2. Kaggle datasets (bucket-of-chump, santa25-public, telegram-shared)\n",
    "3. Kernel outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8ed7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T07:20:30.747493Z",
     "iopub.status.busy": "2026-01-25T07:20:30.746949Z",
     "iopub.status.idle": "2026-01-25T07:20:31.084614Z",
     "shell.execute_reply": "2026-01-25T07:20:31.084183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import STRtree\n",
    "\n",
    "os.chdir('/home/code/experiments/002_external_ensemble')\n",
    "\n",
    "# Tree vertices\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def get_tree_polygon(x, y, deg):\n",
    "    \"\"\"Get tree polygon at position (x, y) with rotation deg\"\"\"\n",
    "    rad = np.radians(deg)\n",
    "    c, s = np.cos(rad), np.sin(rad)\n",
    "    vertices = []\n",
    "    for j in range(len(TX)):\n",
    "        vx = TX[j] * c - TY[j] * s + x\n",
    "        vy = TX[j] * s + TY[j] * c + y\n",
    "        vertices.append((vx, vy))\n",
    "    return Polygon(vertices)\n",
    "\n",
    "def score_group(xs, ys, degs):\n",
    "    \"\"\"Calculate score for a single N-tree configuration\"\"\"\n",
    "    n = len(xs)\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        for j in range(len(TX)):\n",
    "            x = TX[j] * c - TY[j] * s + xs[i]\n",
    "            y = TX[j] * s + TY[j] * c + ys[i]\n",
    "            all_x.append(x)\n",
    "            all_y.append(y)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side * side / n\n",
    "\n",
    "def check_overlaps(xs, ys, degs):\n",
    "    \"\"\"Check if any trees overlap using Shapely\"\"\"\n",
    "    polygons = [get_tree_polygon(xs[i], ys[i], degs[i]) for i in range(len(xs))]\n",
    "    tree = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        candidates = tree.query(poly)\n",
    "        for j in candidates:\n",
    "            if i < j:\n",
    "                if polygons[i].intersection(polygons[j]).area > 0:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def parse_submission(df):\n",
    "    \"\"\"Parse submission dataframe\"\"\"\n",
    "    df = df.copy()\n",
    "    df['x_val'] = df['x'].str[1:].astype(float)\n",
    "    df['y_val'] = df['y'].str[1:].astype(float)\n",
    "    df['deg_val'] = df['deg'].str[1:].astype(float)\n",
    "    df['n'] = df['id'].str.split('_').str[0].astype(int)\n",
    "    return df\n",
    "\n",
    "def calculate_per_n_scores(df):\n",
    "    \"\"\"Calculate score for each N value\"\"\"\n",
    "    per_n_scores = {}\n",
    "    for n in range(1, 201):\n",
    "        group = df[df['n'] == n]\n",
    "        if len(group) == n:\n",
    "            xs = group['x_val'].values\n",
    "            ys = group['y_val'].values\n",
    "            degs = group['deg_val'].values\n",
    "            per_n_scores[n] = score_group(xs, ys, degs)\n",
    "    return per_n_scores\n",
    "\n",
    "print(\"Functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22576ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T07:20:31.085966Z",
     "iopub.status.busy": "2026-01-25T07:20:31.085813Z",
     "iopub.status.idle": "2026-01-25T07:20:31.255239Z",
     "shell.execute_reply": "2026-01-25T07:20:31.254828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://raw.githubusercontent.com/SmartManoj/Santa-Scoreboard/main/submission.csv...\n",
      "Downloaded SmartManoj submission!\n",
      "Shape: (20100, 4)\n",
      "      id                       x                      y  \\\n",
      "0  001_0  s-48.19608619421424578  s58.77098461521422479   \n",
      "1  002_0    s0.15409706962136058  s-0.03854074269477708   \n",
      "2  002_1   s-0.15409706962135647  s-0.56145925730522794   \n",
      "3  003_0    s1.12365581614030097   s0.78110181599256301   \n",
      "4  003_1    s1.23405569584216002   s1.27599950066375900   \n",
      "\n",
      "                      deg  \n",
      "0   s45.00000000000000000  \n",
      "1  s203.62937773064953717  \n",
      "2   s23.62937773064970415  \n",
      "3  s111.12513229289299943  \n",
      "4   s66.37062226934300213  \n"
     ]
    }
   ],
   "source": [
    "# Try to download SmartManoj GitHub submission\n",
    "import urllib.request\n",
    "\n",
    "smartmanoj_url = 'https://raw.githubusercontent.com/SmartManoj/Santa-Scoreboard/main/submission.csv'\n",
    "\n",
    "try:\n",
    "    print(f\"Downloading from {smartmanoj_url}...\")\n",
    "    urllib.request.urlretrieve(smartmanoj_url, 'smartmanoj_submission.csv')\n",
    "    print(\"Downloaded SmartManoj submission!\")\n",
    "    \n",
    "    df_smartmanoj = pd.read_csv('smartmanoj_submission.csv')\n",
    "    print(f\"Shape: {df_smartmanoj.shape}\")\n",
    "    print(df_smartmanoj.head())\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download: {e}\")\n",
    "    df_smartmanoj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8683265d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T07:20:31.256282Z",
     "iopub.status.busy": "2026-01-25T07:20:31.256176Z",
     "iopub.status.idle": "2026-01-25T07:20:31.260100Z",
     "shell.execute_reply": "2026-01-25T07:20:31.259729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking research kernels for submission files...\n",
      "Found 0 submission files in kernels:\n",
      "\n",
      "All CSV files in kernels (0):\n"
     ]
    }
   ],
   "source": [
    "# Check for Kaggle datasets in research folder\n",
    "import glob\n",
    "\n",
    "print(\"Checking research kernels for submission files...\")\n",
    "kernel_paths = glob.glob('/home/code/research/kernels/*/submission*.csv')\n",
    "print(f\"Found {len(kernel_paths)} submission files in kernels:\")\n",
    "for p in kernel_paths:\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "# Also check for any CSV files that might be submissions\n",
    "all_csvs = glob.glob('/home/code/research/kernels/*/*.csv')\n",
    "print(f\"\\nAll CSV files in kernels ({len(all_csvs)}):\")\n",
    "for p in all_csvs[:20]:  # Show first 20\n",
    "    print(f\"  {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c88c96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T07:20:31.261232Z",
     "iopub.status.busy": "2026-01-25T07:20:31.261129Z",
     "iopub.status.idle": "2026-01-25T07:20:31.264402Z",
     "shell.execute_reply": "2026-01-25T07:20:31.264023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data folder...\n",
      "Found 1 CSV files in data:\n",
      "  /home/data/sample_submission.csv\n",
      "\n",
      "Checking for Kaggle input datasets...\n",
      "  /kaggle/input not found\n"
     ]
    }
   ],
   "source": [
    "# Check for datasets in data folder\n",
    "print(\"Checking data folder...\")\n",
    "data_csvs = glob.glob('/home/data/*.csv')\n",
    "print(f\"Found {len(data_csvs)} CSV files in data:\")\n",
    "for p in data_csvs:\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "# Check for any additional data sources\n",
    "print(\"\\nChecking for Kaggle input datasets...\")\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    for d in os.listdir('/kaggle/input'):\n",
    "        print(f\"  /kaggle/input/{d}\")\n",
    "else:\n",
    "    print(\"  /kaggle/input not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848dacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all available submissions and score them\n",
    "submissions = {}\n",
    "\n",
    "# 1. Current best ensemble from snapshots\n",
    "print(\"Loading current ensemble submission...\")\n",
    "df_current = pd.read_csv('/home/submission/submission.csv')\n",
    "df_current = parse_submission(df_current)\n",
    "submissions['current_ensemble'] = df_current\n",
    "print(f\"  Current ensemble loaded: {df_current.shape}\")\n",
    "\n",
    "# 2. SmartManoj if available\n",
    "if df_smartmanoj is not None:\n",
    "    try:\n",
    "        df_sm = parse_submission(df_smartmanoj)\n",
    "        submissions['smartmanoj'] = df_sm\n",
    "        print(f\"  SmartManoj loaded: {df_sm.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to parse SmartManoj: {e}\")\n",
    "\n",
    "# 3. Load all snapshot submissions\n",
    "print(\"\\nLoading snapshot submissions...\")\n",
    "snapshot_dir = '/home/nonroot/snapshots/santa-2025'\n",
    "for snap_id in os.listdir(snapshot_dir):\n",
    "    sub_path = os.path.join(snapshot_dir, snap_id, 'submission', 'submission.csv')\n",
    "    if os.path.exists(sub_path):\n",
    "        try:\n",
    "            df = pd.read_csv(sub_path)\n",
    "            df = parse_submission(df)\n",
    "            submissions[f'snapshot_{snap_id}'] = df\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"Total submissions loaded: {len(submissions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-N scores for all submissions\n",
    "print(\"Calculating per-N scores for all submissions...\")\n",
    "all_per_n_scores = {}\n",
    "\n",
    "for name, df in submissions.items():\n",
    "    try:\n",
    "        scores = calculate_per_n_scores(df)\n",
    "        if len(scores) == 200:  # Valid submission\n",
    "            all_per_n_scores[name] = scores\n",
    "            total = sum(scores.values())\n",
    "            print(f\"  {name}: total={total:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {name}: ERROR - {e}\")\n",
    "\n",
    "print(f\"\\nValid submissions: {len(all_per_n_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeab0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best score for each N across all submissions\n",
    "print(\"Finding best score for each N...\")\n",
    "best_per_n = {}\n",
    "best_source = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    best_score = float('inf')\n",
    "    best_src = None\n",
    "    for name, scores in all_per_n_scores.items():\n",
    "        if n in scores and scores[n] < best_score:\n",
    "            best_score = scores[n]\n",
    "            best_src = name\n",
    "    best_per_n[n] = best_score\n",
    "    best_source[n] = best_src\n",
    "\n",
    "# Calculate total score\n",
    "total_best = sum(best_per_n.values())\n",
    "print(f\"\\nBest ensemble total score: {total_best:.6f}\")\n",
    "\n",
    "# Compare to current ensemble\n",
    "current_scores = all_per_n_scores.get('current_ensemble', {})\n",
    "current_total = sum(current_scores.values()) if current_scores else 0\n",
    "print(f\"Current ensemble total: {current_total:.6f}\")\n",
    "print(f\"Improvement: {current_total - total_best:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae577022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which N values improved and from which source\n",
    "print(\"\\nN values with improvements:\")\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    if n in current_scores and n in best_per_n:\n",
    "        diff = current_scores[n] - best_per_n[n]\n",
    "        if diff > 1e-10:\n",
    "            improvements.append((n, diff, best_source[n]))\n",
    "\n",
    "improvements.sort(key=lambda x: x[1], reverse=True)\n",
    "print(f\"Total N values improved: {len(improvements)}\")\n",
    "print(\"\\nTop 20 improvements:\")\n",
    "for n, diff, src in improvements[:20]:\n",
    "    print(f\"  N={n}: improved by {diff:.6f} from {src}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43443297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new ensemble submission by taking best solution for each N\n",
    "print(\"Creating new ensemble submission...\")\n",
    "\n",
    "new_rows = []\n",
    "for n in range(1, 201):\n",
    "    best_src = best_source[n]\n",
    "    df_best = submissions[best_src]\n",
    "    group = df_best[df_best['n'] == n]\n",
    "    for _, row in group.iterrows():\n",
    "        new_rows.append({\n",
    "            'id': row['id'],\n",
    "            'x': row['x'],\n",
    "            'y': row['y'],\n",
    "            'deg': row['deg']\n",
    "        })\n",
    "\n",
    "df_new = pd.DataFrame(new_rows)\n",
    "print(f\"New ensemble shape: {df_new.shape}\")\n",
    "print(df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f057dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no overlaps in new ensemble\n",
    "print(\"Verifying no overlaps in new ensemble...\")\n",
    "df_new_parsed = parse_submission(df_new)\n",
    "\n",
    "has_overlap = False\n",
    "for n in range(1, 201):\n",
    "    group = df_new_parsed[df_new_parsed['n'] == n]\n",
    "    xs = group['x_val'].values\n",
    "    ys = group['y_val'].values\n",
    "    degs = group['deg_val'].values\n",
    "    \n",
    "    if check_overlaps(xs, ys, degs):\n",
    "        print(f\"  WARNING: Overlap detected in N={n}!\")\n",
    "        has_overlap = True\n",
    "\n",
    "if not has_overlap:\n",
    "    print(\"  No overlaps detected!\")\n",
    "else:\n",
    "    print(\"  OVERLAPS FOUND - submission may be rejected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final score\n",
    "final_scores = calculate_per_n_scores(df_new_parsed)\n",
    "final_total = sum(final_scores.values())\n",
    "print(f\"\\nFinal ensemble score: {final_total:.6f}\")\n",
    "print(f\"Target: 68.894234\")\n",
    "print(f\"Gap to target: {final_total - 68.894234:.6f}\")\n",
    "\n",
    "# Save submission\n",
    "df_new.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"\\nSaved to /home/submission/submission.csv\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {'cv_score': final_total}\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "print(f\"Saved metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
