{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7099b86a",
   "metadata": {},
   "source": [
    "# Baseline Verification\n",
    "\n",
    "Verify the pre-optimized baseline submission score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tree vertices\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def score_group(xs, ys, degs):\n",
    "    \"\"\"Calculate score for a single N-tree configuration\"\"\"\n",
    "    n = len(xs)\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        for j in range(len(TX)):\n",
    "            x = TX[j] * c - TY[j] * s + xs[i]\n",
    "            y = TX[j] * s + TY[j] * c + ys[i]\n",
    "            all_x.append(x)\n",
    "            all_y.append(y)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side * side / n\n",
    "\n",
    "def calculate_total_score(df):\n",
    "    \"\"\"Calculate total score for a submission\"\"\"\n",
    "    # Parse the 's' prefix from values\n",
    "    df['x_val'] = df['x'].str[1:].astype(float)\n",
    "    df['y_val'] = df['y'].str[1:].astype(float)\n",
    "    df['deg_val'] = df['deg'].str[1:].astype(float)\n",
    "    \n",
    "    # Extract N from id (e.g., '003_1' -> 3)\n",
    "    df['n'] = df['id'].str.split('_').str[0].astype(int)\n",
    "    \n",
    "    total_score = 0\n",
    "    per_n_scores = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        group = df[df['n'] == n]\n",
    "        if len(group) == n:\n",
    "            xs = group['x_val'].values\n",
    "            ys = group['y_val'].values\n",
    "            degs = group['deg_val'].values\n",
    "            score = score_group(xs, ys, degs)\n",
    "            per_n_scores[n] = score\n",
    "            total_score += score\n",
    "        else:\n",
    "            print(f\"Warning: N={n} has {len(group)} trees instead of {n}\")\n",
    "    \n",
    "    return total_score, per_n_scores\n",
    "\n",
    "print(\"Loading baseline submission...\")\n",
    "df = pd.read_csv('baseline.csv')\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total score\n",
    "total_score, per_n_scores = calculate_total_score(df)\n",
    "print(f\"\\nTotal Score: {total_score:.6f}\")\n",
    "print(f\"\\nScore breakdown by N range:\")\n",
    "print(f\"  N=1-50:   {sum(per_n_scores[n] for n in range(1, 51)):.4f}\")\n",
    "print(f\"  N=51-100: {sum(per_n_scores[n] for n in range(51, 101)):.4f}\")\n",
    "print(f\"  N=101-150: {sum(per_n_scores[n] for n in range(101, 151)):.4f}\")\n",
    "print(f\"  N=151-200: {sum(per_n_scores[n] for n in range(151, 201)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cddc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show worst N values (highest per-N scores)\n",
    "print(\"\\nTop 20 worst N values (highest per-N scores):\")\n",
    "sorted_scores = sorted(per_n_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "for n, score in sorted_scores[:20]:\n",
    "    print(f\"  N={n}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to submission folder\n",
    "import shutil\n",
    "shutil.copy('baseline.csv', '/home/submission/submission.csv')\n",
    "print(\"Copied baseline to /home/submission/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eacde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "import json\n",
    "metrics = {'cv_score': total_score}\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "print(f\"Saved metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
