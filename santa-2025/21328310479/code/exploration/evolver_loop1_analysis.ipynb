{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedfbcb8",
   "metadata": {},
   "source": [
    "# Loop 1 Analysis: Ensemble Strategy\n",
    "\n",
    "## Goal\n",
    "1. Score all available snapshots per-N\n",
    "2. Find the best solution for each N value\n",
    "3. Create an ensemble submission\n",
    "4. Identify which N values have the most room for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree vertices\n",
    "TX = np.array([0,0.125,0.0625,0.2,0.1,0.35,0.075,0.075,-0.075,-0.075,-0.35,-0.1,-0.2,-0.0625,-0.125])\n",
    "TY = np.array([0.8,0.5,0.5,0.25,0.25,0,0,-0.2,-0.2,0,0,0.25,0.25,0.5,0.5])\n",
    "\n",
    "def score_group(xs, ys, degs):\n",
    "    \"\"\"Calculate score for a single N-tree configuration\"\"\"\n",
    "    n = len(xs)\n",
    "    all_x, all_y = [], []\n",
    "    for i in range(n):\n",
    "        rad = np.radians(degs[i])\n",
    "        c, s = np.cos(rad), np.sin(rad)\n",
    "        for j in range(len(TX)):\n",
    "            x = TX[j] * c - TY[j] * s + xs[i]\n",
    "            y = TX[j] * s + TY[j] * c + ys[i]\n",
    "            all_x.append(x)\n",
    "            all_y.append(y)\n",
    "    side = max(max(all_x) - min(all_x), max(all_y) - min(all_y))\n",
    "    return side * side / n\n",
    "\n",
    "def parse_submission(df):\n",
    "    \"\"\"Parse submission and return per-N scores\"\"\"\n",
    "    df = df.copy()\n",
    "    # Parse the 's' prefix from values\n",
    "    df['x_val'] = df['x'].astype(str).str.replace('s', '', regex=False).astype(float)\n",
    "    df['y_val'] = df['y'].astype(str).str.replace('s', '', regex=False).astype(float)\n",
    "    df['deg_val'] = df['deg'].astype(str).str.replace('s', '', regex=False).astype(float)\n",
    "    \n",
    "    # Extract N from id (e.g., '003_1' -> 3)\n",
    "    df['n'] = df['id'].str.split('_').str[0].astype(int)\n",
    "    \n",
    "    per_n_scores = {}\n",
    "    per_n_data = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        group = df[df['n'] == n]\n",
    "        if len(group) == n:\n",
    "            xs = group['x_val'].values\n",
    "            ys = group['y_val'].values\n",
    "            degs = group['deg_val'].values\n",
    "            score = score_group(xs, ys, degs)\n",
    "            per_n_scores[n] = score\n",
    "            per_n_data[n] = group[['id', 'x', 'y', 'deg']].copy()\n",
    "    \n",
    "    return per_n_scores, per_n_data\n",
    "\n",
    "print('Functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a56f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all submission files in snapshots\n",
    "snapshot_dir = '/home/nonroot/snapshots/santa-2025'\n",
    "snapshot_dirs = sorted(glob.glob(f'{snapshot_dir}/*/'))\n",
    "print(f'Found {len(snapshot_dirs)} snapshot directories')\n",
    "\n",
    "# Collect all submission files\n",
    "submission_files = []\n",
    "for d in snapshot_dirs:\n",
    "    sub_file = os.path.join(d, 'submission', 'submission.csv')\n",
    "    if os.path.exists(sub_file):\n",
    "        submission_files.append(sub_file)\n",
    "\n",
    "print(f'Found {len(submission_files)} submission files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de76d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score all submissions and track best per-N\n",
    "best_per_n = {n: {'score': float('inf'), 'data': None, 'source': None} for n in range(1, 201)}\n",
    "\n",
    "for sub_file in tqdm(submission_files, desc='Scoring submissions'):\n",
    "    try:\n",
    "        df = pd.read_csv(sub_file)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            continue\n",
    "        per_n_scores, per_n_data = parse_submission(df)\n",
    "        \n",
    "        for n, score in per_n_scores.items():\n",
    "            if score < best_per_n[n]['score']:\n",
    "                best_per_n[n]['score'] = score\n",
    "                best_per_n[n]['data'] = per_n_data[n]\n",
    "                best_per_n[n]['source'] = sub_file\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {sub_file}: {e}')\n",
    "\n",
    "print('\\nDone scoring all submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ceea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total ensemble score\n",
    "total_ensemble_score = sum(best_per_n[n]['score'] for n in range(1, 201) if best_per_n[n]['data'] is not None)\n",
    "print(f'Total ensemble score from snapshots: {total_ensemble_score:.6f}')\n",
    "\n",
    "# Compare to baseline\n",
    "baseline_score = 70.625918\n",
    "print(f'Baseline score: {baseline_score:.6f}')\n",
    "print(f'Improvement: {baseline_score - total_ensemble_score:.6f}')\n",
    "\n",
    "# Show score breakdown by range\n",
    "print('\\nScore breakdown by N range:')\n",
    "for start, end in [(1, 50), (51, 100), (101, 150), (151, 200)]:\n",
    "    range_score = sum(best_per_n[n]['score'] for n in range(start, end+1))\n",
    "    print(f'  N={start}-{end}: {range_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which N values improved vs baseline\n",
    "baseline_df = pd.read_csv('/home/code/experiments/001_baseline/baseline.csv')\n",
    "baseline_per_n, _ = parse_submission(baseline_df)\n",
    "\n",
    "improvements = []\n",
    "for n in range(1, 201):\n",
    "    baseline_n = baseline_per_n.get(n, float('inf'))\n",
    "    ensemble_n = best_per_n[n]['score']\n",
    "    if ensemble_n < baseline_n - 1e-9:\n",
    "        improvements.append((n, baseline_n, ensemble_n, baseline_n - ensemble_n))\n",
    "\n",
    "print(f'\\nN values with improvements: {len(improvements)}')\n",
    "if improvements:\n",
    "    improvements.sort(key=lambda x: x[3], reverse=True)\n",
    "    print('\\nTop 20 improvements:')\n",
    "    for n, old, new, diff in improvements[:20]:\n",
    "        print(f'  N={n}: {old:.6f} -> {new:.6f} (improvement: {diff:.6f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76051dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble submission\n",
    "ensemble_rows = []\n",
    "for n in range(1, 201):\n",
    "    if best_per_n[n]['data'] is not None:\n",
    "        ensemble_rows.append(best_per_n[n]['data'])\n",
    "\n",
    "ensemble_df = pd.concat(ensemble_rows, ignore_index=True)\n",
    "\n",
    "# Sort by N and index\n",
    "ensemble_df['sn'] = ensemble_df['id'].str.split('_').str[0].astype(int)\n",
    "ensemble_df['si'] = ensemble_df['id'].str.split('_').str[1].astype(int)\n",
    "ensemble_df = ensemble_df.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "ensemble_df = ensemble_df[['id', 'x', 'y', 'deg']]\n",
    "\n",
    "print(f'Ensemble submission shape: {ensemble_df.shape}')\n",
    "print(ensemble_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c08eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble submission\n",
    "os.makedirs('/home/code/experiments/002_ensemble_snapshots', exist_ok=True)\n",
    "ensemble_df.to_csv('/home/code/experiments/002_ensemble_snapshots/submission.csv', index=False)\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "\n",
    "print(f'Saved ensemble submission with score: {total_ensemble_score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77478647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check research kernels for additional solutions\n",
    "kernel_dir = '/home/code/research/kernels'\n",
    "kernel_submissions = []\n",
    "\n",
    "for root, dirs, files in os.walk(kernel_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            kernel_submissions.append(os.path.join(root, f))\n",
    "\n",
    "print(f'Found {len(kernel_submissions)} CSV files in research kernels')\n",
    "for f in kernel_submissions:\n",
    "    print(f'  {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4de809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score kernel submissions and update best_per_n\n",
    "for sub_file in kernel_submissions:\n",
    "    try:\n",
    "        df = pd.read_csv(sub_file)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            continue\n",
    "        per_n_scores, per_n_data = parse_submission(df)\n",
    "        \n",
    "        for n, score in per_n_scores.items():\n",
    "            if score < best_per_n[n]['score']:\n",
    "                best_per_n[n]['score'] = score\n",
    "                best_per_n[n]['data'] = per_n_data[n]\n",
    "                best_per_n[n]['source'] = sub_file\n",
    "                print(f'Found better N={n}: {score:.6f} from {sub_file}')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "# Recalculate total\n",
    "total_with_kernels = sum(best_per_n[n]['score'] for n in range(1, 201) if best_per_n[n]['data'] is not None)\n",
    "print(f'\\nTotal score with kernels: {total_with_kernels:.6f}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
