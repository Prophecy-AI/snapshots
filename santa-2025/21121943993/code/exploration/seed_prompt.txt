# Santa 2025 Christmas Tree Packing - Seed Prompt

## Problem Overview
This is a 2D irregular polygon packing optimization problem. Pack 1-200 Christmas trees into the smallest square bounding boxes.

**Scoring:** score = sum(s_n^2 / n) for n=1 to 200, where s_n is the side length of the bounding square for n trees.
**Target:** Beat 68.922808 (lower is better)
**Best public kernel:** 71.78

**Tree geometry:** 15-vertex polygon with:
- Trunk: 0.15 wide x 0.2 tall
- Three tiers: base (0.7 wide), mid (0.4 wide), top (0.25 wide)
- Tip at y=0.8, trunk bottom at y=-0.2
- Position defined by (x, y) at trunk top center and rotation angle (deg)

## CRITICAL: Strategy to Beat Public Kernels

The best public kernel scores 71.78, but target is 68.92. To beat this:

1. **Ensemble MORE sources** - Collect solutions from every available source
2. **Run SA LONGER** - Public kernels have time limits; we can run longer
3. **Focus on HIGH-IMPACT N values** - Score contribution varies by N
4. **Use MULTIPLE random restarts** - Escape local minima
5. **Implement NOVEL construction** - Don't just optimize existing solutions

### Score Impact Analysis
The score formula s_n^2/n means:
- Small N (1-20): Each tree contributes ~1.0 to score
- Medium N (50-100): Each tree contributes ~0.5 to score  
- Large N (150-200): Each tree contributes ~0.3 to score

**Focus optimization effort on small N values for maximum impact!**

## Top Approaches from Public Kernels

### 1. Ensemble Strategy (CRITICAL - Start Here)
**Source:** `../research/kernels/seshurajup_71-78-jit-parallel-sa-c-tpu-96-cores/`

The foundation of all top solutions:
1. Collect solutions from multiple sources (CSV files, kernels, datasets)
2. For each N (1-200), select the configuration with the smallest bounding box
3. Combine into a single ensemble submission
4. Apply optimization on top

**Key code pattern:**
```python
best = {n: {"score": 1e300, "data": None} for n in range(1, 201)}
for each_csv_file:
    for n, group in df.groupby("N"):
        score = calculate_score(group)
        if score < best[n]["score"]:
            best[n] = {"score": score, "data": group}
```

### 2. Simulated Annealing with Translations (C++ Implementation)
**Source:** `../research/kernels/seshurajup_71-78-jit-parallel-sa-c-tpu-96-cores/`

High-performance C++ implementation with OpenMP parallelization:
- **Iterations:** 15,000-50,000 per configuration
- **Restarts:** 5-8 per N
- **Temperature schedule:** Start 1.0, end 0.000005
- **Moves:** Translation (x, y shifts), rotation changes
- **Acceptance:** Metropolis criterion with temperature decay

**Key parameters to tune:**
- More iterations for small N (n <= 20): 1.5x iterations
- Fewer iterations for large N (n > 150): 0.8x iterations
- More restarts for small N

### 3. Fractional Translation Refinement
**Source:** `../research/kernels/jonathanchan_santa25-ensemble-sa-fractional-translation/`

Fine-grained optimization after SA:
- Step sizes: [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]
- 8 directions: up, down, left, right, and 4 diagonals
- For each tree, try all step sizes and directions
- Accept if bounding box shrinks without overlap

### 4. BackPacking Strategy (Backward Iteration)
**Source:** `../research/kernels/crodoc_74-75-backpacking-christmas-trees/`

Start from n=200 and work backward to n=1:
1. Track the best-performing configuration at each step
2. When configuration at n trees performs poorly, copy best config found so far
3. Drop extra trees from the copied configuration
4. Propagates successful patterns to smaller tree counts

### 5. Greedy Construction with Beam Search
**Source:** `../research/kernels/inversion_santa-2025-getting-started/`

Build configurations tree-by-tree:
1. Place first tree at origin
2. For each new tree:
   - Start far from center (radius ~20)
   - Move inward along random angle until collision
   - Back up until no overlap
3. Use weighted angle distribution: abs(sin(2*angle)) to favor diagonal placements

**ENHANCEMENT: Add beam search**
- Keep top K configurations at each step
- Explore multiple placement options per tree
- Select best final configuration

## Advanced Techniques for Beating Target

### 1. Greedy Backtracking with Beam Search (HIGH PRIORITY)
Build solutions from scratch with exploration:
```
BEAM = 10  # Keep top 10 configurations
DEPTH = 10  # Look ahead 10 trees
MAX_STATES = 4000  # Limit search space

for n in range(1, 201):
    states = [empty_config]
    for tree_idx in range(n):
        new_states = []
        for state in states:
            for angle in [0, 45, 90, 135, 180, 225, 270, 315]:
                for position in candidate_positions(state, angle):
                    new_state = place_tree(state, position, angle)
                    new_states.append(new_state)
        states = select_top_k(new_states, BEAM)
    best[n] = min(states, key=score)
```

### 2. Random Initialization Strategy
Don't just optimize pre-optimized solutions:
```
for trial in range(100):
    config = random_valid_configuration(n)
    optimized = simulated_annealing(config)
    if score(optimized) < best_score:
        best_score = score(optimized)
        best_config = optimized
```

### 3. Per-N Construction
For each N, try multiple construction strategies:
- Greedy from scratch
- Copy from N+1 and remove worst tree
- Copy from N-1 and add best tree
- Random valid configuration + SA

### 4. No-Fit Polygon (NFP) for Speed
Precompute collision-free regions:
- For each pair of rotation angles, compute NFP
- Use NFP to quickly find valid positions
- Dramatically speeds up placement search

### 5. Genetic Algorithm for Configuration
Evolve good configurations:
- Chromosome: sequence of (position, angle) for each tree
- Crossover: combine partial configurations
- Mutation: small position/angle changes
- Selection: tournament based on score

## Collision Detection (Critical for Performance)

Fast collision detection using:
1. **Bounding box pre-check:** Skip detailed check if bboxes don't overlap
2. **Point-in-polygon test:** Check if any vertex is inside other polygon
3. **Segment intersection:** Check if any edges cross
4. **STRtree spatial index:** For efficient neighbor queries

```python
def overlap(poly_a, poly_b):
    # Quick bbox check
    if a.x1 < b.x0 or b.x1 < a.x0 or a.y1 < b.y0 or b.y1 < a.y0:
        return False
    # Detailed check...
```

## Recommended Experiment Strategy

### Experiment 1: Baseline Ensemble (MUST DO FIRST)
1. Download ALL available public solutions
2. Create ensemble by selecting best per N
3. Submit to establish baseline
4. **Expected score: ~71-72**

### Experiment 2: Extended SA Optimization
1. Copy C++ SA optimizer from kernel
2. Run with 2-3x more iterations than public kernels
3. Use fractional translation refinement
4. **Target: ~70-71**

### Experiment 3: Fresh Construction + Ensemble
1. Implement greedy construction with beam search
2. Build fresh configurations for N=1 to 50 (high impact)
3. Ensemble with existing solutions
4. **Target: ~69-70**

### Experiment 4: Intensive Small-N Optimization
1. Focus on N=1 to 30 (highest score impact)
2. Run 10x more SA iterations on these
3. Try 100+ random restarts per N
4. **Target: ~68.5-69**

### Experiment 5: Novel Approaches
1. Implement genetic algorithm
2. Use NFP for faster search
3. Try completely different construction heuristics
4. **Target: Beat 68.922808**

## Key Implementation Notes

### Submission Format
```
id,x,y,deg
001_0,s0.0,s0.0,s90.0
002_0,s0.0,s0.0,s90.0
002_1,s0.202736,s-0.511271,s90.0
...
```
- Values must be prefixed with 's' to preserve precision
- Coordinates constrained to [-100, 100]
- No overlapping trees allowed

### Score Calculation
```python
@njit
def score_group(xs, ys, degs, tx, ty):
    n = xs.size
    V = tx.size
    mnx = mny = 1e300
    mxx = mxy = -1e300
    for i in range(n):
        r = degs[i] * math.pi / 180.0
        c, s = math.cos(r), math.sin(r)
        for j in range(V):
            X = c * tx[j] - s * ty[j] + xs[i]
            Y = s * tx[j] + c * ty[j] + ys[i]
            mnx, mxx = min(mnx, X), max(mxx, X)
            mny, mxy = min(mny, Y), max(mxy, Y)
    side = max(mxx - mnx, mxy - mny)
    return side * side / n
```

### Tree Polygon Template
```python
TX = [0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125]
TY = [0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5]
```

## Data Sources for Ensemble

Public datasets and kernels to ensemble:
1. SmartManoj Santa Scoreboard: https://raw.githubusercontent.com/SmartManoj/Santa-Scoreboard/main/submission.csv
2. Kaggle datasets: bucket-of-chump, santa25-public, telegram-public-shared-solution
3. All kernel outputs from top solutions
4. Sample submission (baseline)

## Critical Success Factors

1. **Start with ensemble** - Don't build from scratch
2. **Use C++ for SA** - Python is too slow for intensive optimization
3. **Parallelize** - Use OpenMP for multi-core processing
4. **Focus on small N** - Highest score impact per improvement
5. **Fractional translation** - Critical for final score improvement
6. **Multiple restarts** - SA can get stuck in local minima
7. **Fresh construction** - Don't just optimize pre-optimized solutions
8. **Run LONGER** - We have more time than public kernels

## WARNING: Local Search Limitations

If starting from a pre-optimized CSV (like public kernel outputs):
- Local search (SA, hill climbing) may not improve much
- The solution is likely already at a local optimum
- Need CONSTRUCTIVE approaches to find new basins
- Random restarts from scratch can find better solutions
