{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160ee46d",
   "metadata": {},
   "source": [
    "# Loop 2 Analysis: Pre-optimized Solutions Evaluation\n",
    "\n",
    "The evaluator correctly identified that pre-optimized solutions with scores ~70 are available.\n",
    "Let's evaluate them and understand the gap to target (68.92)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numba import njit\n",
    "import os\n",
    "\n",
    "# Tree polygon template\n",
    "@njit\n",
    "def make_polygon_template():\n",
    "    tw=0.15; th=0.2; bw=0.7; mw=0.4; ow=0.25\n",
    "    tip=0.8; t1=0.5; t2=0.25; base=0.0; tbot=-th\n",
    "    x = np.array([0,ow/2,ow/4,mw/2,mw/4,bw/2,tw/2,tw/2,-tw/2,-tw/2,-bw/2,-mw/4,-mw/2,-ow/4,-ow/2], np.float64)\n",
    "    y = np.array([tip,t1,t1,t2,t2,base,base,tbot,tbot,base,base,t2,t2,t1,t1], np.float64)\n",
    "    return x, y\n",
    "\n",
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    \"\"\"Calculate score = side^2 / n for a group of trees.\"\"\"\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300; mny = 1e300; mxx = -1e300; mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r); s = math.sin(r)\n",
    "        xi = xs[i]; yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c*tx[j] - s*ty[j] + xi\n",
    "            Y = s*tx[j] + c*ty[j] + yi\n",
    "            if X < mnx: mnx = X\n",
    "            if X > mxx: mxx = X\n",
    "            if Y < mny: mny = Y\n",
    "            if Y > mxy: mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "# Warm up JIT\n",
    "tx, ty = make_polygon_template()\n",
    "test_xs = np.array([0.0], np.float64)\n",
    "test_ys = np.array([0.0], np.float64)\n",
    "test_degs = np.array([0.0], np.float64)\n",
    "_ = score_group(test_xs, test_ys, test_degs, tx, ty)\n",
    "print(\"JIT compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede53e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(a):\n",
    "    \"\"\"Convert string values to float array.\"\"\"\n",
    "    return np.array([float(str(v).replace('s','')) for v in a], np.float64)\n",
    "\n",
    "def load_submission(filepath):\n",
    "    \"\"\"Load submission and return dict of (xs, ys, degs) arrays per n.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    \n",
    "    configs = {}\n",
    "    for n, g in df.groupby('N'):\n",
    "        xs = strip(g['x'].to_numpy())\n",
    "        ys = strip(g['y'].to_numpy())\n",
    "        degs = strip(g['deg'].to_numpy())\n",
    "        configs[n] = (xs, ys, degs)\n",
    "    return configs\n",
    "\n",
    "def calculate_total_score(configs, tx, ty):\n",
    "    \"\"\"Calculate total score across all configurations.\"\"\"\n",
    "    total = 0.0\n",
    "    for n, (xs, ys, degs) in configs.items():\n",
    "        total += score_group(xs, ys, degs, tx, ty)\n",
    "    return total\n",
    "\n",
    "def get_per_n_scores(configs, tx, ty):\n",
    "    \"\"\"Get score contribution for each n.\"\"\"\n",
    "    scores = {}\n",
    "    for n, (xs, ys, degs) in configs.items():\n",
    "        scores[n] = score_group(xs, ys, degs, tx, ty)\n",
    "    return scores\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all pre-optimized solutions\n",
    "preopt_dir = '/home/code/preoptimized'\n",
    "results = {}\n",
    "\n",
    "for fname in os.listdir(preopt_dir):\n",
    "    if fname.endswith('.csv'):\n",
    "        fpath = os.path.join(preopt_dir, fname)\n",
    "        try:\n",
    "            configs = load_submission(fpath)\n",
    "            score = calculate_total_score(configs, tx, ty)\n",
    "            results[fname] = score\n",
    "            print(f\"{fname}: {score:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{fname}: ERROR - {e}\")\n",
    "\n",
    "print(f\"\\nTarget: 68.922808\")\n",
    "print(f\"Best pre-optimized: {min(results.values()):.6f}\")\n",
    "print(f\"Gap: {min(results.values()) - 68.922808:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef135ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best pre-optimized solution\n",
    "best_file = min(results, key=results.get)\n",
    "print(f\"Best file: {best_file}\")\n",
    "best_configs = load_submission(os.path.join(preopt_dir, best_file))\n",
    "best_scores = get_per_n_scores(best_configs, tx, ty)\n",
    "\n",
    "# Analyze which N values contribute most to the score\n",
    "contributions = sorted(best_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 20 N values by score contribution:\")\n",
    "for n, score in contributions[:20]:\n",
    "    print(f\"  N={n}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with our current best\n",
    "our_configs = load_submission('/home/code/experiments/006_jit_optimizer/submission.csv')\n",
    "our_score = calculate_total_score(our_configs, tx, ty)\n",
    "our_scores = get_per_n_scores(our_configs, tx, ty)\n",
    "\n",
    "print(f\"Our current score: {our_score:.6f}\")\n",
    "print(f\"Best pre-optimized: {min(results.values()):.6f}\")\n",
    "print(f\"Difference: {our_score - min(results.values()):.6f}\")\n",
    "\n",
    "# Find where we're worse\n",
    "print(\"\\nN values where pre-optimized is better:\")\n",
    "for n in range(1, 201):\n",
    "    diff = our_scores[n] - best_scores[n]\n",
    "    if diff > 0.001:\n",
    "        print(f\"  N={n}: ours={our_scores[n]:.6f}, best={best_scores[n]:.6f}, diff={diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble: take best of our solution and pre-optimized for each N\n",
    "ensemble_configs = {}\n",
    "ensemble_score = 0.0\n",
    "\n",
    "for n in range(1, 201):\n",
    "    if our_scores[n] < best_scores[n]:\n",
    "        ensemble_configs[n] = our_configs[n]\n",
    "        ensemble_score += our_scores[n]\n",
    "    else:\n",
    "        ensemble_configs[n] = best_configs[n]\n",
    "        ensemble_score += best_scores[n]\n",
    "\n",
    "print(f\"Ensemble score: {ensemble_score:.6f}\")\n",
    "print(f\"Target: 68.922808\")\n",
    "print(f\"Gap: {ensemble_score - 68.922808:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b841c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble as new submission\n",
    "rows = []\n",
    "for n in range(1, 201):\n",
    "    xs, ys, degs = ensemble_configs[n]\n",
    "    for i in range(n):\n",
    "        rows.append({\n",
    "            'id': f'{n:03d}_{i}',\n",
    "            'x': f's{xs[i]:.6f}',\n",
    "            'y': f's{ys[i]:.6f}',\n",
    "            'deg': f's{degs[i]:.6f}'\n",
    "        })\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "submission.to_csv('/home/code/preoptimized/ensemble_best.csv', index=False)\n",
    "print(f\"Ensemble saved with score: {ensemble_score:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
