{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29954f93",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Key Findings from Research:\n",
    "1. **Ensemble approach is critical** - Top kernels combine best solutions from 15+ sources per N\n",
    "2. **Lattice/crystallization patterns** - Blue Phase (0° ± 90°) + Pink Phase (180° ± 90°) interlock efficiently\n",
    "3. **Long SA runs needed** - sa_v1_parallel with -n 15000+ iterations, -r 80+ rounds\n",
    "4. **Fractional translation** - Fine-tuning with steps [0.001, 0.0005, 0.0002, 0.0001, 0.00005, 0.00002, 0.00001]\n",
    "\n",
    "## Current Status:\n",
    "- Best CV: 70.673023 (exp_001)\n",
    "- Best LB: 70.676102 (exp_000)\n",
    "- Target: 68.894234\n",
    "- Gap: 1.78 points (2.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5aaee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:36:14.551196Z",
     "iopub.status.busy": "2026-01-25T08:36:14.550767Z",
     "iopub.status.idle": "2026-01-25T08:36:14.870920Z",
     "shell.execute_reply": "2026-01-25T08:36:14.870577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Tree geometry\n",
    "TREE_VERTICES = [\n",
    "    (0, 0.8), (-0.125, 0.5), (-0.05, 0.5), (-0.2, 0.25), (-0.1, 0.25),\n",
    "    (-0.35, 0), (-0.075, 0), (-0.075, -0.2), (0.075, -0.2), (0.075, 0),\n",
    "    (0.35, 0), (0.1, 0.25), (0.2, 0.25), (0.05, 0.5), (0.125, 0.5),\n",
    "]\n",
    "\n",
    "def create_tree_polygon(x, y, angle_deg):\n",
    "    poly = Polygon(TREE_VERTICES)\n",
    "    poly = rotate(poly, angle_deg, origin=(0, 0))\n",
    "    poly = translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def get_bounding_box_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_coords = []\n",
    "    for poly in polygons:\n",
    "        all_coords.extend(list(poly.exterior.coords))\n",
    "    xs = [c[0] for c in all_coords]\n",
    "    ys = [c[1] for c in all_coords]\n",
    "    width = max(xs) - min(xs)\n",
    "    height = max(ys) - min(ys)\n",
    "    return max(width, height)\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ec8948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:36:14.871982Z",
     "iopub.status.busy": "2026-01-25T08:36:14.871844Z",
     "iopub.status.idle": "2026-01-25T08:36:14.942429Z",
     "shell.execute_reply": "2026-01-25T08:36:14.942090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3297 CSV files\n",
      "\n",
      "Sample files:\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/004_sa_v1_parallel/submission_best.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/004_sa_v1_parallel/submission_v18.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/005_backward_propagation/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/005_backward_propagation/submission_v21.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/005_backward_propagation/optimized.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/experiments/002_preoptimized/submission.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_000.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_004.csv\n",
      "  /home/nonroot/snapshots/santa-2025/21116303805/code/submission_candidates/candidate_002.csv\n"
     ]
    }
   ],
   "source": [
    "# Find all available CSV files for ensemble\n",
    "csv_sources = []\n",
    "\n",
    "# Snapshots\n",
    "snapshot_csvs = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)\n",
    "csv_sources.extend(snapshot_csvs)\n",
    "\n",
    "# Local preoptimized\n",
    "local_csvs = glob.glob('/home/code/preoptimized/**/*.csv', recursive=True)\n",
    "csv_sources.extend(local_csvs)\n",
    "\n",
    "print(f\"Found {len(csv_sources)} CSV files\")\n",
    "print(\"\\nSample files:\")\n",
    "for f in csv_sources[:10]:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f37f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:36:14.943345Z",
     "iopub.status.busy": "2026-01-25T08:36:14.943235Z",
     "iopub.status.idle": "2026-01-25T08:38:17.543434Z",
     "shell.execute_reply": "2026-01-25T08:38:17.542998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CSVs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:02<01:59,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:04<01:57,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_best.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:07<01:54,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_v18.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:09<01:52,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:12<01:50,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_v21.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:14<01:48,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  optimized.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:17<01:46,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:19<01:43,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate_000.csv: 150.809780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:22<01:41,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate_004.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:24<01:38,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate_002.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:27<01:36,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate_003.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:29<01:33,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  candidate_001.csv: 70.676099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:31<01:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ensemble.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:34<01:28,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:36<01:25,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa-2025.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:39<01:23,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  best_ensemble.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:41<01:20,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.49.csv: 72.495739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [00:44<01:18,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.97.csv: 71.972027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:46<01:16,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  72.49.csv: 72.495739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [00:49<01:13,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.97.csv: 71.972027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [00:51<01:11,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_JKoT4.csv: 72.489504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [00:54<01:08,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  New_Tree_144_196.csv: 72.927920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [00:56<01:06,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_JKoT3.csv: 72.489488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [00:58<01:03,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v61.csv: 72.951925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [01:01<01:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_JKoT2.csv: 72.489348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [01:03<00:58,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v67.csv: 72.938567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [01:06<00:56,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v76.csv: 72.826444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [01:08<00:53,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_70_936673758122.csv: 70.936674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [01:11<00:51,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v65.csv: 72.935294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [01:13<00:49,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_70_926149550346.csv: 70.926150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [01:16<00:46,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v66.csv: 72.938599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [01:18<00:44,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v63.csv: 72.947427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [01:21<00:41,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v69.csv: 72.850110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [01:23<00:39,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_JKoT1.csv: 72.489483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [01:25<00:36,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_opt1.csv: 70.990692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [01:28<00:34,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa2025_ver2_v68.csv: 72.939233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [01:30<00:31,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  santa-2025.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [01:33<00:29,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [01:35<00:26,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission (77).csv: 72.135010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [01:38<00:24,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 72.935294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [01:40<00:22,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_sa.csv: 72.935294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [01:43<00:19,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission_best.csv: 70.926150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [01:45<00:17,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.676102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [01:47<00:14,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample_submission.csv: 173.652299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [01:50<00:12,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample_submission.csv: 173.652299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [01:52<00:09,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.647327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [01:55<00:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission2.csv: 70.615744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [01:57<00:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission1.csv: 70.615745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [02:00<00:02,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.647327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [02:02<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [02:02<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  submission.csv: 70.624381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-N scores for all CSVs and find best per N\n",
    "def calculate_per_n_scores(csv_path):\n",
    "    \"\"\"Calculate score contribution for each N in a submission.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "            return None\n",
    "        \n",
    "        df['x_val'] = df['x'].apply(parse_value)\n",
    "        df['y_val'] = df['y'].apply(parse_value)\n",
    "        df['deg_val'] = df['deg'].apply(parse_value)\n",
    "        df['n'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "        \n",
    "        scores = {}\n",
    "        for n in range(1, 201):\n",
    "            n_data = df[df['n'] == n]\n",
    "            if len(n_data) != n:\n",
    "                continue\n",
    "            polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "                       for _, row in n_data.iterrows()]\n",
    "            side = get_bounding_box_side(polygons)\n",
    "            scores[n] = side**2 / n\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Process all CSVs (this may take a while)\n",
    "all_scores = {}\n",
    "valid_csvs = []\n",
    "\n",
    "print(\"Processing CSVs...\")\n",
    "for csv_path in tqdm(csv_sources[:50]):  # Limit to first 50 for speed\n",
    "    scores = calculate_per_n_scores(csv_path)\n",
    "    if scores and len(scores) == 200:\n",
    "        name = os.path.basename(csv_path)\n",
    "        all_scores[name] = scores\n",
    "        valid_csvs.append(csv_path)\n",
    "        total = sum(scores.values())\n",
    "        print(f\"  {name}: {total:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d631dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:38:34.350059Z",
     "iopub.status.busy": "2026-01-25T08:38:34.349680Z",
     "iopub.status.idle": "2026-01-25T08:38:34.355197Z",
     "shell.execute_reply": "2026-01-25T08:38:34.354834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble score (best per N): 70.615744\n",
      "Current best: 70.676102\n",
      "Improvement: 0.060358\n",
      "\n",
      "Source contributions:\n",
      "  submission.csv: 116 N values\n",
      "  submission2.csv: 83 N values\n",
      "  submission_v18.csv: 1 N values\n"
     ]
    }
   ],
   "source": [
    "# Find best per-N across all sources\n",
    "if all_scores:\n",
    "    best_per_n = {}\n",
    "    best_source_per_n = {}\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        best_score = float('inf')\n",
    "        best_source = None\n",
    "        for name, scores in all_scores.items():\n",
    "            if n in scores and scores[n] < best_score:\n",
    "                best_score = scores[n]\n",
    "                best_source = name\n",
    "        best_per_n[n] = best_score\n",
    "        best_source_per_n[n] = best_source\n",
    "    \n",
    "    ensemble_score = sum(best_per_n.values())\n",
    "    print(f\"\\nEnsemble score (best per N): {ensemble_score:.6f}\")\n",
    "    print(f\"Current best: 70.676102\")\n",
    "    print(f\"Improvement: {70.676102 - ensemble_score:.6f}\")\n",
    "    \n",
    "    # Show which sources contribute most\n",
    "    source_counts = {}\n",
    "    for n, source in best_source_per_n.items():\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "    \n",
    "    print(\"\\nSource contributions:\")\n",
    "    for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {source}: {count} N values\")\n",
    "else:\n",
    "    print(\"No valid CSVs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5fef50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T08:38:55.946203Z",
     "iopub.status.busy": "2026-01-25T08:38:55.945715Z",
     "iopub.status.idle": "2026-01-25T10:52:15.967641Z",
     "shell.execute_reply": "2026-01-25T10:52:15.967263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALL CSVs for best ensemble...\n",
      "Processing batch 1/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 11/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 12/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 13/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 14/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 15/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 16/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 17/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 18/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 19/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 20/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 21/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 22/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 23/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 24/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 25/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 26/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 27/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 28/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 29/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 30/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 31/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 33/33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 544 valid CSVs with score < 75\n"
     ]
    }
   ],
   "source": [
    "# Process ALL CSVs to find the best ensemble\n",
    "print(\"Processing ALL CSVs for best ensemble...\")\n",
    "\n",
    "all_scores_full = {}\n",
    "valid_csvs_full = []\n",
    "\n",
    "# Process in batches to avoid memory issues\n",
    "batch_size = 100\n",
    "for i in range(0, len(csv_sources), batch_size):\n",
    "    batch = csv_sources[i:i+batch_size]\n",
    "    print(f\"Processing batch {i//batch_size + 1}/{(len(csv_sources) + batch_size - 1)//batch_size}...\")\n",
    "    \n",
    "    for csv_path in batch:\n",
    "        try:\n",
    "            scores = calculate_per_n_scores(csv_path)\n",
    "            if scores and len(scores) == 200:\n",
    "                name = f\"{os.path.dirname(csv_path).split('/')[-1]}_{os.path.basename(csv_path)}\"\n",
    "                total = sum(scores.values())\n",
    "                if total < 75:  # Only keep good ones\n",
    "                    all_scores_full[name] = scores\n",
    "                    valid_csvs_full.append(csv_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"\\nFound {len(all_scores_full)} valid CSVs with score < 75\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the baseline solution to understand the lattice pattern\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv'\n",
    "df = pd.read_csv(baseline_path)\n",
    "df['x_val'] = df['x'].apply(parse_value)\n",
    "df['y_val'] = df['y'].apply(parse_value)\n",
    "df['deg_val'] = df['deg'].apply(parse_value)\n",
    "df['n'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "\n",
    "# Analyze angle distribution for large N\n",
    "print(\"Angle distribution analysis for large N:\")\n",
    "for n in [50, 100, 150, 200]:\n",
    "    n_data = df[df['n'] == n]\n",
    "    angles = n_data['deg_val'].values % 360\n",
    "    \n",
    "    # Blue phase: 0° ± 90° (i.e., -90 to 90 or 270 to 360 and 0 to 90)\n",
    "    # Pink phase: 180° ± 90° (i.e., 90 to 270)\n",
    "    blue_count = sum((angles <= 90) | (angles > 270))\n",
    "    pink_count = sum((angles > 90) & (angles <= 270))\n",
    "    \n",
    "    print(f\"\\nN={n}:\")\n",
    "    print(f\"  Blue phase (up): {blue_count} ({100*blue_count/n:.1f}%)\")\n",
    "    print(f\"  Pink phase (down): {pink_count} ({100*pink_count/n:.1f}%)\")\n",
    "    print(f\"  Angle mean: {angles.mean():.1f}°, std: {angles.std():.1f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spacing patterns for large N\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for n in [100, 200]:\n",
    "    n_data = df[df['n'] == n].copy()\n",
    "    x = n_data['x_val'].values\n",
    "    y = n_data['y_val'].values\n",
    "    angles = n_data['deg_val'].values % 360\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    from scipy.spatial.distance import pdist\n",
    "    distances = pdist(np.column_stack([x, y]))\n",
    "    \n",
    "    print(f\"\\nN={n} spacing analysis:\")\n",
    "    print(f\"  Min distance: {distances.min():.4f}\")\n",
    "    print(f\"  Mean distance: {distances.mean():.4f}\")\n",
    "    print(f\"  Most common distance: {np.median(distances):.4f}\")\n",
    "    \n",
    "    # Find nearest neighbor distances\n",
    "    from scipy.spatial import cKDTree\n",
    "    tree = cKDTree(np.column_stack([x, y]))\n",
    "    nn_dists, _ = tree.query(np.column_stack([x, y]), k=2)\n",
    "    nn_dists = nn_dists[:, 1]  # Second nearest (first is self)\n",
    "    \n",
    "    print(f\"  Nearest neighbor mean: {nn_dists.mean():.4f}\")\n",
    "    print(f\"  Nearest neighbor std: {nn_dists.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are better CSVs in the bucket-of-chump dataset\n",
    "bucket_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/bucket-of-chump'\n",
    "if os.path.exists(bucket_path):\n",
    "    bucket_csvs = glob.glob(f'{bucket_path}/**/*.csv', recursive=True)\n",
    "    print(f\"Found {len(bucket_csvs)} CSVs in bucket-of-chump\")\n",
    "    \n",
    "    for csv_path in bucket_csvs[:5]:\n",
    "        scores = calculate_per_n_scores(csv_path)\n",
    "        if scores:\n",
    "            total = sum(scores.values())\n",
    "            print(f\"  {os.path.basename(csv_path)}: {total:.6f}\")\n",
    "else:\n",
    "    print(\"bucket-of-chump not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Current best score: 70.676102\")\n",
    "print(f\"2. Target score: 68.894234\")\n",
    "print(f\"3. Gap to close: 1.78 points (2.5%)\")\n",
    "print(f\"\\n4. Key insights:\")\n",
    "print(f\"   - Baseline is at a VERY tight local optimum\")\n",
    "print(f\"   - Standard optimization (bbox3, SA) cannot improve it\")\n",
    "print(f\"   - Need ENSEMBLE approach: combine best per-N from multiple sources\")\n",
    "print(f\"   - Need LONG optimization runs (hours, not minutes)\")\n",
    "print(f\"   - Lattice patterns: Blue (up) + Pink (down) phases interlock\")\n",
    "print(f\"\\n5. Next steps:\")\n",
    "print(f\"   - Implement ensemble from all available CSVs\")\n",
    "print(f\"   - Run sa_v1_parallel with -n 15000 -r 80 for hours\")\n",
    "print(f\"   - Try lattice-based generation for large N\")\n",
    "print(f\"   - Use fractional translation for fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6aab15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:52:58.662120Z",
     "iopub.status.busy": "2026-01-25T10:52:58.661587Z",
     "iopub.status.idle": "2026-01-25T10:52:58.688995Z",
     "shell.execute_reply": "2026-01-25T10:52:58.688605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best ensemble score (from 544 CSVs): 51.247022\n",
      "Current best: 70.676102\n",
      "Improvement: 19.429080\n",
      "Target: 68.894234\n",
      "Gap to target: -17.647212\n",
      "\n",
      "Top 10 source contributions:\n",
      "  004_jonathanchan_optimizer_submission_opt.csv: 141 N values\n",
      "  code_submission.csv: 19 N values\n",
      "  003_valid_ensemble_submission.csv: 16 N values\n",
      "  code_submission2.csv: 12 N values\n",
      "  005_cpp_fixed_overlap_test_invalid.csv: 4 N values\n",
      "  003_bbox3_optimization_submission.csv: 4 N values\n",
      "  experiments_submission.csv: 1 N values\n",
      "  experiments_submission_v21.csv: 1 N values\n",
      "  005_sa_valid_baseline_submission2.csv: 1 N values\n",
      "  001_baseline_bp_output.csv: 1 N values\n"
     ]
    }
   ],
   "source": [
    "# Find best per-N across ALL sources\n",
    "if all_scores_full:\n",
    "    best_per_n_full = {}\n",
    "    best_source_per_n_full = {}\n",
    "    best_data_per_n = {}  # Store actual data for ensemble\n",
    "    \n",
    "    for n in range(1, 201):\n",
    "        best_score = float('inf')\n",
    "        best_source = None\n",
    "        for name, scores in all_scores_full.items():\n",
    "            if n in scores and scores[n] < best_score:\n",
    "                best_score = scores[n]\n",
    "                best_source = name\n",
    "        best_per_n_full[n] = best_score\n",
    "        best_source_per_n_full[n] = best_source\n",
    "    \n",
    "    ensemble_score_full = sum(best_per_n_full.values())\n",
    "    print(f\"\\nBest ensemble score (from {len(all_scores_full)} CSVs): {ensemble_score_full:.6f}\")\n",
    "    print(f\"Current best: 70.676102\")\n",
    "    print(f\"Improvement: {70.676102 - ensemble_score_full:.6f}\")\n",
    "    print(f\"Target: 68.894234\")\n",
    "    print(f\"Gap to target: {ensemble_score_full - 68.894234:.6f}\")\n",
    "    \n",
    "    # Show which sources contribute most\n",
    "    source_counts = {}\n",
    "    for n, source in best_source_per_n_full.items():\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "    \n",
    "    print(\"\\nTop 10 source contributions:\")\n",
    "    for source, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "        print(f\"  {source}: {count} N values\")\n",
    "else:\n",
    "    print(\"No valid CSVs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73adc99f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:53:31.475190Z",
     "iopub.status.busy": "2026-01-25T10:53:31.474685Z",
     "iopub.status.idle": "2026-01-25T10:53:31.479749Z",
     "shell.execute_reply": "2026-01-25T10:53:31.479388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding file paths for top contributors...\n",
      "\n",
      "004_jonathanchan_optimizer_submission_opt.csv:\n",
      "  Path: /home/nonroot/snapshots/santa-2025/21105319338/code/experiments/004_jonathanchan_optimizer/submission_opt.csv\n",
      "  Total score: 51.663965\n",
      "\n",
      "code_submission.csv:\n",
      "  Path: /home/nonroot/snapshots/santa-2025/21116303805/code/submission.csv\n",
      "  Total score: 70.624424\n",
      "\n",
      "003_valid_ensemble_submission.csv:\n",
      "  Path: /home/nonroot/snapshots/santa-2025/21328309254/code/experiments/003_valid_ensemble/submission.csv\n",
      "  Total score: 70.523320\n"
     ]
    }
   ],
   "source": [
    "# The 51.247 score seems too good - let me check if these solutions are valid (no overlaps)\n",
    "# First, let's find the actual file paths for the top contributors\n",
    "\n",
    "print(\"Finding file paths for top contributors...\")\n",
    "top_sources = ['004_jonathanchan_optimizer_submission_opt.csv', 'code_submission.csv', '003_valid_ensemble_submission.csv']\n",
    "\n",
    "for source in top_sources:\n",
    "    # Find the actual file\n",
    "    for csv_path in valid_csvs_full:\n",
    "        name = f\"{os.path.dirname(csv_path).split('/')[-1]}_{os.path.basename(csv_path)}\"\n",
    "        if name == source:\n",
    "            print(f\"\\n{source}:\")\n",
    "            print(f\"  Path: {csv_path}\")\n",
    "            \n",
    "            # Calculate total score\n",
    "            scores = all_scores_full[name]\n",
    "            total = sum(scores.values())\n",
    "            print(f\"  Total score: {total:.6f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9622af2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:54:11.740848Z",
     "iopub.status.busy": "2026-01-25T10:54:11.740351Z",
     "iopub.status.idle": "2026-01-25T10:54:11.876286Z",
     "shell.execute_reply": "2026-01-25T10:54:11.875938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for overlaps in suspicious file...\n",
      "N=10: No overlap\n",
      "N=50: No overlap\n",
      "N=100: No overlap\n",
      "N=150: No overlap\n",
      "N=200: No overlap\n",
      "\n",
      "Total overlaps found in sample: 0\n",
      "File appears valid - this is a GREAT score!\n"
     ]
    }
   ],
   "source": [
    "# Check if the 51.66 score file has overlaps\n",
    "from shapely.strtree import STRtree\n",
    "\n",
    "def has_overlap(polygons):\n",
    "    \"\"\"Check if any polygons overlap.\"\"\"\n",
    "    if len(polygons) <= 1:\n",
    "        return False\n",
    "    tree_index = STRtree(polygons)\n",
    "    for i, poly in enumerate(polygons):\n",
    "        indices = tree_index.query(poly)\n",
    "        for idx in indices:\n",
    "            if idx != i and poly.intersects(polygons[idx]) and not poly.touches(polygons[idx]):\n",
    "                intersection = poly.intersection(polygons[idx])\n",
    "                if intersection.area > 1e-10:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Check the suspicious file\n",
    "suspicious_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/experiments/004_jonathanchan_optimizer/submission_opt.csv'\n",
    "df = pd.read_csv(suspicious_path)\n",
    "df['x_val'] = df['x'].apply(parse_value)\n",
    "df['y_val'] = df['y'].apply(parse_value)\n",
    "df['deg_val'] = df['deg'].apply(parse_value)\n",
    "df['n'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "\n",
    "print(\"Checking for overlaps in suspicious file...\")\n",
    "overlap_count = 0\n",
    "for n in [10, 50, 100, 150, 200]:  # Sample some N values\n",
    "    n_data = df[df['n'] == n]\n",
    "    if len(n_data) != n:\n",
    "        print(f\"N={n}: Wrong number of trees ({len(n_data)} instead of {n})\")\n",
    "        continue\n",
    "    polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "               for _, row in n_data.iterrows()]\n",
    "    if has_overlap(polygons):\n",
    "        print(f\"N={n}: OVERLAP DETECTED!\")\n",
    "        overlap_count += 1\n",
    "    else:\n",
    "        print(f\"N={n}: No overlap\")\n",
    "\n",
    "print(f\"\\nTotal overlaps found in sample: {overlap_count}\")\n",
    "if overlap_count > 0:\n",
    "    print(\"This file has INVALID solutions - cannot use it!\")\n",
    "else:\n",
    "    print(\"File appears valid - this is a GREAT score!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b32d870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:54:43.608196Z",
     "iopub.status.busy": "2026-01-25T10:54:43.607704Z",
     "iopub.status.idle": "2026-01-25T10:54:46.799988Z",
     "shell.execute_reply": "2026-01-25T10:54:46.799593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying ALL N values in the 51.66 score file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NO OVERLAPS FOUND! This file is VALID!\n",
      "Score: 51.66 - This BEATS the target of 68.894!\n",
      "\n",
      "We should use this file as our submission!\n"
     ]
    }
   ],
   "source": [
    "# Verify ALL N values in the suspicious file\n",
    "print(\"Verifying ALL N values in the 51.66 score file...\")\n",
    "\n",
    "overlap_ns = []\n",
    "for n in range(1, 201):\n",
    "    n_data = df[df['n'] == n]\n",
    "    if len(n_data) != n:\n",
    "        print(f\"N={n}: Wrong number of trees ({len(n_data)} instead of {n})\")\n",
    "        continue\n",
    "    polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "               for _, row in n_data.iterrows()]\n",
    "    if has_overlap(polygons):\n",
    "        overlap_ns.append(n)\n",
    "\n",
    "if overlap_ns:\n",
    "    print(f\"\\nOverlaps found in N values: {overlap_ns}\")\n",
    "    print(f\"Total invalid N values: {len(overlap_ns)}\")\n",
    "else:\n",
    "    print(\"\\nNO OVERLAPS FOUND! This file is VALID!\")\n",
    "    print(f\"Score: 51.66 - This BEATS the target of 68.894!\")\n",
    "    print(\"\\nWe should use this file as our submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f084ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:55:34.452532Z",
     "iopub.status.busy": "2026-01-25T10:55:34.452137Z",
     "iopub.status.idle": "2026-01-25T10:55:34.456195Z",
     "shell.execute_reply": "2026-01-25T10:55:34.455835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved!\n",
      "\n",
      "Final score: 51.663965\n",
      "Target: 68.894234\n",
      "BEATS TARGET BY: 17.230269 points!\n"
     ]
    }
   ],
   "source": [
    "# Save the experiment metrics\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs('/home/code/experiments/003_found_better_csv', exist_ok=True)\n",
    "\n",
    "metrics = {\n",
    "    'cv_score': 51.663965,\n",
    "    'baseline_score': 70.676102,\n",
    "    'improvement': 70.676102 - 51.663965,\n",
    "    'target': 68.894234,\n",
    "    'gap_to_target': 51.663965 - 68.894234,\n",
    "    'source_file': '/home/nonroot/snapshots/santa-2025/21105319338/code/experiments/004_jonathanchan_optimizer/submission_opt.csv',\n",
    "    'notes': 'Found existing optimized CSV in snapshots that beats target by 17.23 points! No overlaps detected in validation.'\n",
    "}\n",
    "\n",
    "with open('/home/code/experiments/003_found_better_csv/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved!\")\n",
    "print(f\"\\nFinal score: {metrics['cv_score']:.6f}\")\n",
    "print(f\"Target: {metrics['target']:.6f}\")\n",
    "print(f\"BEATS TARGET BY: {-metrics['gap_to_target']:.6f} points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cab13b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:58:44.478137Z",
     "iopub.status.busy": "2026-01-25T10:58:44.477541Z",
     "iopub.status.idle": "2026-01-25T10:58:44.513626Z",
     "shell.execute_reply": "2026-01-25T10:58:44.513079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has 20100 rows\n",
      "Expected: 20100 rows (1+2+...+200)\n",
      "Columns: ['id', 'x', 'y', 'deg']\n",
      "\n",
      "First 10 rows:\n",
      "      id                    x                     y                   deg\n",
      "0  001_0  s43.591192092102148  s-31.783267068741779   s44.999999999999979\n",
      "1  002_0   s0.154097069621361   s-0.038540742694777  s203.629377730650162\n",
      "2  002_1  s-0.154097069621359   s-0.561459257305227   s23.629377730649704\n",
      "3  003_0   s1.131270585068746    s0.792202872326949  s113.563260441729483\n",
      "4  003_1   s1.234055695842160    s1.275999500663759   s66.370622269343002\n",
      "5  003_2   s0.641714640229075    s1.180458566613381  s155.134051937100821\n",
      "6  004_0  s-0.324747789585767    s0.132109978100993  s156.370622143280201\n",
      "7  004_1   s0.315354346193797    s0.132109978070379  s156.370622271937407\n",
      "8  004_2   s0.324747789585715   s-0.732109978075982  s336.370622269343755\n",
      "9  004_3  s-0.315354348186837   s-0.732109978101171  s336.370622143244020\n",
      "\n",
      "N value distribution (first 10):\n",
      "n\n",
      "1      1\n",
      "2      2\n",
      "3      3\n",
      "4      4\n",
      "5      5\n",
      "6      6\n",
      "7      7\n",
      "8      8\n",
      "9      9\n",
      "10    10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "N value distribution (last 10):\n",
      "n\n",
      "191    191\n",
      "192    192\n",
      "193    193\n",
      "194    194\n",
      "195    195\n",
      "196    196\n",
      "197    197\n",
      "198    198\n",
      "199    199\n",
      "200    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing N values: []\n",
      "N values with wrong count: []\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Re-verify the score calculation\n",
    "# The metrics.json shows 70.734 but our calculation shows 51.66 - something is wrong\n",
    "\n",
    "suspicious_path = '/home/nonroot/snapshots/santa-2025/21105319338/code/experiments/004_jonathanchan_optimizer/submission_opt.csv'\n",
    "df = pd.read_csv(suspicious_path)\n",
    "\n",
    "print(f\"File has {len(df)} rows\")\n",
    "print(f\"Expected: 20100 rows (1+2+...+200)\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Check N distribution\n",
    "df['n'] = df['id'].apply(lambda x: int(str(x).split('_')[0]))\n",
    "n_counts = df['n'].value_counts().sort_index()\n",
    "print(f\"\\nN value distribution (first 10):\")\n",
    "print(n_counts.head(10))\n",
    "print(f\"\\nN value distribution (last 10):\")\n",
    "print(n_counts.tail(10))\n",
    "\n",
    "# Check if all N values are present\n",
    "missing_n = [n for n in range(1, 201) if n not in n_counts.index]\n",
    "print(f\"\\nMissing N values: {missing_n}\")\n",
    "\n",
    "# Check if any N has wrong count\n",
    "wrong_count = [(n, count) for n, count in n_counts.items() if count != n]\n",
    "print(f\"N values with wrong count: {wrong_count[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dad4374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:58:35.647542Z",
     "iopub.status.busy": "2026-01-25T10:58:35.647039Z",
     "iopub.status.idle": "2026-01-25T10:58:35.942375Z",
     "shell.execute_reply": "2026-01-25T10:58:35.942003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "\n",
    "# Tree geometry\n",
    "TREE_VERTICES = [\n",
    "    (0, 0.8), (-0.125, 0.5), (-0.05, 0.5), (-0.2, 0.25), (-0.1, 0.25),\n",
    "    (-0.35, 0), (-0.075, 0), (-0.075, -0.2), (0.075, -0.2), (0.075, 0),\n",
    "    (0.35, 0), (0.1, 0.25), (0.2, 0.25), (0.05, 0.5), (0.125, 0.5),\n",
    "]\n",
    "\n",
    "def create_tree_polygon(x, y, angle_deg):\n",
    "    poly = Polygon(TREE_VERTICES)\n",
    "    poly = rotate(poly, angle_deg, origin=(0, 0))\n",
    "    poly = translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "def get_bounding_box_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_coords = []\n",
    "    for poly in polygons:\n",
    "        all_coords.extend(list(poly.exterior.coords))\n",
    "    xs = [c[0] for c in all_coords]\n",
    "    ys = [c[1] for c in all_coords]\n",
    "    width = max(xs) - min(xs)\n",
    "    height = max(ys) - min(ys)\n",
    "    return max(width, height)\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc620d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T10:59:10.806726Z",
     "iopub.status.busy": "2026-01-25T10:59:10.806345Z",
     "iopub.status.idle": "2026-01-25T10:59:13.254983Z",
     "shell.execute_reply": "2026-01-25T10:59:13.254620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 70.734327\n",
      "Target: 68.894234\n",
      "Gap: 1.840093\n",
      "\n",
      "Per-N breakdown (first 20):\n",
      "N=  1: side=0.813173, score_contrib=0.661250\n",
      "N=  2: side=0.949504, score_contrib=0.450779\n",
      "N=  3: side=1.142031, score_contrib=0.434745\n",
      "N=  4: side=1.290806, score_contrib=0.416545\n",
      "N=  5: side=1.443692, score_contrib=0.416850\n",
      "N=  6: side=1.548438, score_contrib=0.399610\n",
      "N=  7: side=1.673104, score_contrib=0.399897\n",
      "N=  8: side=1.755921, score_contrib=0.385407\n",
      "N=  9: side=1.867280, score_contrib=0.387415\n",
      "N= 10: side=1.940696, score_contrib=0.376630\n",
      "N= 11: side=2.033002, score_contrib=0.375736\n",
      "N= 12: side=2.114873, score_contrib=0.372724\n",
      "N= 13: side=2.200046, score_contrib=0.372323\n",
      "N= 14: side=2.279381, score_contrib=0.371113\n",
      "N= 15: side=2.384962, score_contrib=0.379203\n",
      "N= 16: side=2.446640, score_contrib=0.374128\n",
      "N= 17: side=2.508124, score_contrib=0.370040\n",
      "N= 18: side=2.576409, score_contrib=0.368771\n",
      "N= 19: side=2.646449, score_contrib=0.368615\n",
      "N= 20: side=2.742469, score_contrib=0.376057\n"
     ]
    }
   ],
   "source": [
    "# Calculate score step by step\n",
    "df['x_val'] = df['x'].apply(parse_value)\n",
    "df['y_val'] = df['y'].apply(parse_value)\n",
    "df['deg_val'] = df['deg'].apply(parse_value)\n",
    "\n",
    "# Calculate per-N scores\n",
    "per_n_scores = {}\n",
    "per_n_sides = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    n_data = df[df['n'] == n]\n",
    "    polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "               for _, row in n_data.iterrows()]\n",
    "    side = get_bounding_box_side(polygons)\n",
    "    per_n_sides[n] = side\n",
    "    per_n_scores[n] = side**2 / n\n",
    "\n",
    "total_score = sum(per_n_scores.values())\n",
    "print(f\"Total score: {total_score:.6f}\")\n",
    "print(f\"Target: 68.894234\")\n",
    "print(f\"Gap: {total_score - 68.894234:.6f}\")\n",
    "\n",
    "# Show per-N breakdown for first 20\n",
    "print(\"\\nPer-N breakdown (first 20):\")\n",
    "for n in range(1, 21):\n",
    "    print(f\"N={n:3d}: side={per_n_sides[n]:.6f}, score_contrib={per_n_scores[n]:.6f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
