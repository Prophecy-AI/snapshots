{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa48c03",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis\n",
    "\n",
    "## Issue: Submission failed with \"Overlapping trees in group 002\"\n",
    "\n",
    "Need to:\n",
    "1. Understand why the overlap occurred\n",
    "2. Fix the submission\n",
    "3. Identify a fundamentally different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate, translate\n",
    "import os\n",
    "\n",
    "# Tree geometry\n",
    "TREE_VERTICES = [\n",
    "    (0, 0.8), (-0.125, 0.5), (-0.05, 0.5), (-0.2, 0.25), (-0.1, 0.25),\n",
    "    (-0.35, 0), (-0.075, 0), (-0.075, -0.2), (0.075, -0.2), (0.075, 0),\n",
    "    (0.35, 0), (0.1, 0.25), (0.2, 0.25), (0.05, 0.5), (0.125, 0.5),\n",
    "]\n",
    "\n",
    "def create_tree_polygon(x, y, angle_deg):\n",
    "    poly = Polygon(TREE_VERTICES)\n",
    "    poly = rotate(poly, angle_deg, origin=(0, 0))\n",
    "    poly = translate(poly, x, y)\n",
    "    return poly\n",
    "\n",
    "def parse_value(val):\n",
    "    if isinstance(val, str) and val.startswith('s'):\n",
    "        return float(val[1:])\n",
    "    return float(val)\n",
    "\n",
    "def get_bounding_box_side(polygons):\n",
    "    if not polygons:\n",
    "        return 0\n",
    "    all_coords = []\n",
    "    for poly in polygons:\n",
    "        all_coords.extend(list(poly.exterior.coords))\n",
    "    xs = [c[0] for c in all_coords]\n",
    "    ys = [c[1] for c in all_coords]\n",
    "    width = max(xs) - min(xs)\n",
    "    height = max(ys) - min(ys)\n",
    "    return max(width, height)\n",
    "\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check N=2 in the failed submission for overlaps\n",
    "df = pd.read_csv('/home/submission/submission.csv')\n",
    "df['x_val'] = df['x'].apply(parse_value)\n",
    "df['y_val'] = df['y'].apply(parse_value)\n",
    "df['deg_val'] = df['deg'].apply(parse_value)\n",
    "df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "n2_data = df[df['n'] == 2]\n",
    "print(f\"N=2 has {len(n2_data)} trees\")\n",
    "print(n2_data[['id', 'x_val', 'y_val', 'deg_val']])\n",
    "\n",
    "# Create polygons and check overlap\n",
    "polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "           for _, row in n2_data.iterrows()]\n",
    "\n",
    "if len(polygons) == 2:\n",
    "    p1, p2 = polygons\n",
    "    print(f\"\\nIntersects: {p1.intersects(p2)}\")\n",
    "    if p1.intersects(p2):\n",
    "        intersection = p1.intersection(p2)\n",
    "        print(f\"Intersection area: {intersection.area:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline and verify it has no overlaps\n",
    "baseline_path = '/home/nonroot/snapshots/santa-2025/21116303805/code/preoptimized/santa-2025.csv'\n",
    "baseline_df = pd.read_csv(baseline_path)\n",
    "baseline_df['x_val'] = baseline_df['x'].apply(parse_value)\n",
    "baseline_df['y_val'] = baseline_df['y'].apply(parse_value)\n",
    "baseline_df['deg_val'] = baseline_df['deg'].apply(parse_value)\n",
    "baseline_df['n'] = baseline_df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Check ALL N values for overlaps in baseline\n",
    "print(\"Checking baseline for overlaps...\")\n",
    "overlap_count = 0\n",
    "for n in range(1, 201):\n",
    "    n_data = baseline_df[baseline_df['n'] == n]\n",
    "    if len(n_data) != n:\n",
    "        print(f\"WARNING: N={n} has {len(n_data)} trees\")\n",
    "        continue\n",
    "    \n",
    "    polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "               for _, row in n_data.iterrows()]\n",
    "    \n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):\n",
    "                intersection = polygons[i].intersection(polygons[j])\n",
    "                if intersection.area > 1e-10:\n",
    "                    overlap_count += 1\n",
    "                    if overlap_count <= 5:\n",
    "                        print(f\"Overlap in N={n}: trees {i} and {j}, area={intersection.area:.10f}\")\n",
    "\n",
    "print(f\"\\nTotal overlaps found: {overlap_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The baseline should have no overlaps - let's use it\n",
    "# Copy baseline to submission\n",
    "import shutil\n",
    "shutil.copy(baseline_path, '/home/submission/submission.csv')\n",
    "print(\"Copied baseline to /home/submission/submission.csv\")\n",
    "\n",
    "# Calculate baseline score\n",
    "def calculate_full_score(df):\n",
    "    df = df.copy()\n",
    "    df['x_val'] = df['x'].apply(parse_value)\n",
    "    df['y_val'] = df['y'].apply(parse_value)\n",
    "    df['deg_val'] = df['deg'].apply(parse_value)\n",
    "    df['n'] = df['id'].apply(lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    total_score = 0\n",
    "    for n in range(1, 201):\n",
    "        n_data = df[df['n'] == n]\n",
    "        if len(n_data) != n:\n",
    "            continue\n",
    "        polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "                   for _, row in n_data.iterrows()]\n",
    "        side = get_bounding_box_side(polygons)\n",
    "        total_score += side**2 / n\n",
    "    return total_score\n",
    "\n",
    "baseline_score = calculate_full_score(baseline_df)\n",
    "print(f\"Baseline score: {baseline_score:.6f}\")\n",
    "print(f\"Target: 68.894234\")\n",
    "print(f\"Gap: {baseline_score - 68.894234:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's think about FUNDAMENTALLY DIFFERENT approaches\n",
    "# The key insight from discussions and kernels:\n",
    "# 1. Lattice/tessellation patterns for large N\n",
    "# 2. Blue Phase (trees up) + Pink Phase (trees down) interlock\n",
    "\n",
    "# Let's analyze the baseline to understand the structure\n",
    "print(\"Analyzing baseline structure...\")\n",
    "\n",
    "# For each N, calculate efficiency (trees per unit area)\n",
    "efficiencies = []\n",
    "for n in range(1, 201):\n",
    "    n_data = baseline_df[baseline_df['n'] == n]\n",
    "    if len(n_data) != n:\n",
    "        continue\n",
    "    polygons = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "               for _, row in n_data.iterrows()]\n",
    "    side = get_bounding_box_side(polygons)\n",
    "    area = side ** 2\n",
    "    tree_area = n * polygons[0].area  # All trees have same area\n",
    "    efficiency = tree_area / area\n",
    "    efficiencies.append({'n': n, 'side': side, 'area': area, 'efficiency': efficiency, \n",
    "                        'score_contrib': side**2/n})\n",
    "\n",
    "eff_df = pd.DataFrame(efficiencies)\n",
    "print(f\"\\nEfficiency statistics:\")\n",
    "print(f\"Min efficiency: {eff_df['efficiency'].min():.4f} at N={eff_df.loc[eff_df['efficiency'].idxmin(), 'n']}\")\n",
    "print(f\"Max efficiency: {eff_df['efficiency'].max():.4f} at N={eff_df.loc[eff_df['efficiency'].idxmax(), 'n']}\")\n",
    "\n",
    "# Show worst 10 N values by score contribution\n",
    "print(f\"\\nTop 10 N values by score contribution (most room for improvement):\")\n",
    "worst = eff_df.nlargest(10, 'score_contrib')\n",
    "print(worst[['n', 'side', 'efficiency', 'score_contrib']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaace86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: N=1 contributes 0.66 to score, but it's already optimal (45 degree angle)\n",
    "# The real opportunity is in LARGE N values where lattice patterns can help\n",
    "\n",
    "# Let's look at what angles are used in the baseline for large N\n",
    "print(\"Analyzing angles in baseline for large N...\")\n",
    "\n",
    "for n in [50, 100, 150, 200]:\n",
    "    n_data = baseline_df[baseline_df['n'] == n]\n",
    "    angles = n_data['deg_val'].values % 360\n",
    "    \n",
    "    # Categorize angles\n",
    "    # Blue Phase: trees pointing up (tip at top) - angles around 0° or 180°\n",
    "    # Pink Phase: trees pointing down (tip at bottom) - angles around 180° or 0°\n",
    "    \n",
    "    print(f\"\\nN={n}:\")\n",
    "    print(f\"  Angle range: [{angles.min():.1f}°, {angles.max():.1f}°]\")\n",
    "    print(f\"  Mean angle: {angles.mean():.1f}°\")\n",
    "    print(f\"  Std angle: {angles.std():.1f}°\")\n",
    "    \n",
    "    # Count angles in different quadrants\n",
    "    q1 = sum(1 for a in angles if 0 <= a < 90)\n",
    "    q2 = sum(1 for a in angles if 90 <= a < 180)\n",
    "    q3 = sum(1 for a in angles if 180 <= a < 270)\n",
    "    q4 = sum(1 for a in angles if 270 <= a < 360)\n",
    "    print(f\"  Quadrants: Q1={q1}, Q2={q2}, Q3={q3}, Q4={q4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fea6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a simple lattice approach for large N\n",
    "# The idea: create a grid of trees with alternating angles\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def create_lattice_packing(n, base_angle1, base_angle2, dx, dy, offset_x, offset_y):\n",
    "    \"\"\"Create a lattice packing for N trees.\"\"\"\n",
    "    trees = []\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_cells = (n + 1) // 2\n",
    "    nx = int(np.ceil(np.sqrt(n_cells * dy / dx))) if dx > 0 else int(np.ceil(np.sqrt(n_cells)))\n",
    "    ny = int(np.ceil(n_cells / max(nx, 1)))\n",
    "    \n",
    "    for i in range(nx + 1):\n",
    "        for j in range(ny + 1):\n",
    "            if len(trees) >= n:\n",
    "                break\n",
    "            # First tree in unit cell\n",
    "            x1 = i * dx\n",
    "            y1 = j * dy\n",
    "            trees.append((x1, y1, base_angle1))\n",
    "            \n",
    "            if len(trees) >= n:\n",
    "                break\n",
    "            # Second tree in unit cell (offset)\n",
    "            x2 = x1 + offset_x\n",
    "            y2 = y1 + offset_y\n",
    "            trees.append((x2, y2, base_angle2))\n",
    "    \n",
    "    return trees[:n]\n",
    "\n",
    "def evaluate_lattice(params, n):\n",
    "    \"\"\"Evaluate a lattice configuration.\"\"\"\n",
    "    base_angle1, base_angle2, dx, dy, offset_x, offset_y = params\n",
    "    \n",
    "    trees = create_lattice_packing(n, base_angle1, base_angle2, dx, dy, offset_x, offset_y)\n",
    "    if len(trees) < n:\n",
    "        return 1000  # Not enough trees\n",
    "    \n",
    "    polygons = [create_tree_polygon(x, y, a) for x, y, a in trees]\n",
    "    \n",
    "    # Check for overlaps\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(i+1, len(polygons)):\n",
    "            if polygons[i].intersects(polygons[j]) and not polygons[i].touches(polygons[j]):\n",
    "                intersection = polygons[i].intersection(polygons[j])\n",
    "                if intersection.area > 1e-10:\n",
    "                    return 1000 + intersection.area * 1000\n",
    "    \n",
    "    return get_bounding_box_side(polygons)\n",
    "\n",
    "# Test on N=100\n",
    "print(\"Testing lattice optimization for N=100...\")\n",
    "\n",
    "# Get baseline score for N=100\n",
    "n100_data = baseline_df[baseline_df['n'] == 100]\n",
    "baseline_polys = [create_tree_polygon(row['x_val'], row['y_val'], row['deg_val']) \n",
    "                 for _, row in n100_data.iterrows()]\n",
    "baseline_side_100 = get_bounding_box_side(baseline_polys)\n",
    "print(f\"Baseline N=100 side: {baseline_side_100:.6f}\")\n",
    "print(f\"Baseline N=100 score contrib: {baseline_side_100**2/100:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to optimize lattice for N=100\n",
    "bounds = [\n",
    "    (0, 360),    # base_angle1\n",
    "    (0, 360),    # base_angle2\n",
    "    (0.3, 1.0),  # dx\n",
    "    (0.3, 1.0),  # dy\n",
    "    (-0.5, 0.5), # offset_x\n",
    "    (-0.5, 0.5), # offset_y\n",
    "]\n",
    "\n",
    "print(\"Running differential evolution for N=100...\")\n",
    "result = differential_evolution(\n",
    "    lambda p: evaluate_lattice(p, 100),\n",
    "    bounds,\n",
    "    seed=42,\n",
    "    maxiter=100,\n",
    "    workers=1,\n",
    "    disp=False,\n",
    "    tol=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimized lattice N=100 side: {result.fun:.6f}\")\n",
    "if result.fun < 1000:\n",
    "    print(f\"Baseline N=100 side: {baseline_side_100:.6f}\")\n",
    "    print(f\"Improvement: {baseline_side_100 - result.fun:.6f}\")\n",
    "    print(f\"Parameters: angle1={result.x[0]:.1f}, angle2={result.x[1]:.1f}\")\n",
    "    print(f\"            dx={result.x[2]:.4f}, dy={result.x[3]:.4f}\")\n",
    "    print(f\"            offset=({result.x[4]:.4f}, {result.x[5]:.4f})\")\n",
    "else:\n",
    "    print(\"Optimization failed - overlaps detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lattice approach is finding solutions but they may have overlaps\n",
    "# Let's try a different approach: study the why-not kernel's lattice analysis\n",
    "\n",
    "# First, let's look at what the top kernels actually do\n",
    "# The key insight from the kernels:\n",
    "# 1. bbox3 C++ optimizer - sophisticated local search\n",
    "# 2. sa_v1_parallel - simulated annealing with perturbation\n",
    "# 3. Ensemble of multiple sources\n",
    "\n",
    "# The problem is that all these are LOCAL optimizers\n",
    "# They can't escape the local optimum we're stuck in\n",
    "\n",
    "# What we need is a GLOBAL approach:\n",
    "# 1. Generate many diverse starting configurations\n",
    "# 2. Optimize each one\n",
    "# 3. Take the best\n",
    "\n",
    "# Let's check what other CSVs are available in the snapshots\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob('/home/nonroot/snapshots/santa-2025/*/code/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(csv_files)} CSV files in snapshots\")\n",
    "\n",
    "# Filter to submission-like files\n",
    "submission_csvs = [f for f in csv_files if 'submission' in f.lower() or 'santa' in f.lower()]\n",
    "print(f\"Found {len(submission_csvs)} submission-like CSVs\")\n",
    "\n",
    "# Show first 20\n",
    "for f in submission_csvs[:20]:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ca86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate all available CSVs and find the best one\n",
    "print(\"Evaluating all available CSVs...\")\n",
    "\n",
    "best_score = float('inf')\n",
    "best_file = None\n",
    "scores = []\n",
    "\n",
    "for csv_path in submission_csvs:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'id' not in df.columns or 'x' not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Check if it has the right format\n",
    "        if len(df) < 20100:  # Should have sum(1..200) = 20100 rows\n",
    "            continue\n",
    "            \n",
    "        score = calculate_full_score(df)\n",
    "        scores.append({'file': csv_path, 'score': score})\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_file = csv_path\n",
    "            print(f\"New best: {score:.6f} from {csv_path}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nEvaluated {len(scores)} valid CSVs\")\n",
    "print(f\"Best score: {best_score:.6f}\")\n",
    "print(f\"Best file: {best_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 CSVs by score\n",
    "if scores:\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df = scores_df.sort_values('score')\n",
    "    print(\"\\nTop 10 CSVs by score:\")\n",
    "    print(scores_df.head(10))\n",
    "    \n",
    "    # Check if any beat the target\n",
    "    target = 68.894234\n",
    "    beating_target = scores_df[scores_df['score'] < target]\n",
    "    if len(beating_target) > 0:\n",
    "        print(f\"\\n{len(beating_target)} CSVs beat the target!\")\n",
    "        print(beating_target)\n",
    "    else:\n",
    "        print(f\"\\nNo CSVs beat the target ({target})\")\n",
    "        print(f\"Best is {best_score:.6f}, gap of {best_score - target:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we found a better CSV, use it\n",
    "if best_score < baseline_score:\n",
    "    print(f\"Found better CSV: {best_file}\")\n",
    "    print(f\"Score: {best_score:.6f} vs baseline {baseline_score:.6f}\")\n",
    "    print(f\"Improvement: {baseline_score - best_score:.6f}\")\n",
    "    \n",
    "    # Copy to submission\n",
    "    import shutil\n",
    "    shutil.copy(best_file, '/home/submission/submission.csv')\n",
    "    print(f\"Copied to /home/submission/submission.csv\")\n",
    "else:\n",
    "    print(f\"No better CSV found. Using baseline.\")\n",
    "    print(f\"Baseline score: {baseline_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86520e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of findings\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBaseline score: {baseline_score:.6f}\")\n",
    "print(f\"Target: 68.894234\")\n",
    "print(f\"Gap: {baseline_score - 68.894234:.6f} ({(baseline_score - 68.894234)/68.894234*100:.2f}%)\")\n",
    "print(f\"\\nBest CSV found: {best_file if best_file else 'baseline'}\")\n",
    "print(f\"Best score: {best_score:.6f}\")\n",
    "\n",
    "print(f\"\\nKey findings:\")\n",
    "print(f\"1. The baseline is at a VERY tight local optimum\")\n",
    "print(f\"2. Local refinement only found 0.003 improvement\")\n",
    "print(f\"3. bbox3 optimizer could not improve baseline\")\n",
    "print(f\"4. Lattice optimization for N=100 found overlapping solutions\")\n",
    "print(f\"5. Need fundamentally different approach\")\n",
    "\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Study the why-not kernel's lattice analysis more carefully\")\n",
    "print(f\"2. Try generating diverse starting configurations\")\n",
    "print(f\"3. Run VERY long optimization (hours, not minutes)\")\n",
    "print(f\"4. Consider constraint programming or branch-and-bound for small N\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
