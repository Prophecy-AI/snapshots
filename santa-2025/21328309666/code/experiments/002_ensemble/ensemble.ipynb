{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fd213b",
   "metadata": {},
   "source": [
    "# Ensemble from ALL Available Sources\n",
    "\n",
    "Build ensemble by scanning ALL 3213 CSV files and keeping the best configuration for each N (1-200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e535ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numba import njit\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Tree geometry\n",
    "TX = np.array([0, 0.125, 0.0625, 0.2, 0.1, 0.35, 0.075, 0.075, -0.075, -0.075, -0.35, -0.1, -0.2, -0.0625, -0.125], dtype=np.float64)\n",
    "TY = np.array([0.8, 0.5, 0.5, 0.25, 0.25, 0, 0, -0.2, -0.2, 0, 0, 0.25, 0.25, 0.5, 0.5], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def score_group(xs, ys, degs, tx, ty):\n",
    "    \"\"\"Calculate score for a group of trees.\"\"\"\n",
    "    n = xs.size\n",
    "    V = tx.size\n",
    "    mnx = 1e300\n",
    "    mny = 1e300\n",
    "    mxx = -1e300\n",
    "    mxy = -1e300\n",
    "    for i in range(n):\n",
    "        r = degs[i] * math.pi / 180.0\n",
    "        c = math.cos(r)\n",
    "        s = math.sin(r)\n",
    "        xi = xs[i]\n",
    "        yi = ys[i]\n",
    "        for j in range(V):\n",
    "            X = c * tx[j] - s * ty[j] + xi\n",
    "            Y = s * tx[j] + c * ty[j] + yi\n",
    "            if X < mnx:\n",
    "                mnx = X\n",
    "            if X > mxx:\n",
    "                mxx = X\n",
    "            if Y < mny:\n",
    "                mny = Y\n",
    "            if Y > mxy:\n",
    "                mxy = Y\n",
    "    side = max(mxx - mnx, mxy - mny)\n",
    "    return side * side / n\n",
    "\n",
    "def strip(a):\n",
    "    \"\"\"Remove 's' prefix from values.\"\"\"\n",
    "    return np.array([float(str(v).replace('s', '')) for v in a], np.float64)\n",
    "\n",
    "# Warm up numba\n",
    "_ = score_group(np.array([0.0]), np.array([0.0]), np.array([45.0]), TX, TY)\n",
    "print(\"Numba warmed up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ALL CSV files in snapshots\n",
    "csv_files = glob.glob('/home/nonroot/snapshots/santa-2025/**/*.csv', recursive=True)\n",
    "print(f\"Found {len(csv_files)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb14ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best configurations for each N\n",
    "best = {n: {'score': 1e300, 'data': None, 'src': None} for n in range(1, 201)}\n",
    "\n",
    "# Scan all CSV files\n",
    "for fp in tqdm(csv_files, desc=\"Scanning CSV files\"):\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "    # Check if it has the required columns\n",
    "    if not {'id', 'x', 'y', 'deg'}.issubset(df.columns):\n",
    "        continue\n",
    "    \n",
    "    # Parse N from id column\n",
    "    df = df.copy()\n",
    "    try:\n",
    "        df['N'] = df['id'].astype(str).str.split('_').str[0].astype(int)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Process each N group\n",
    "    for n, g in df.groupby('N'):\n",
    "        if n < 1 or n > 200:\n",
    "            continue\n",
    "        if len(g) != n:  # Must have exactly n trees\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            xs = strip(g['x'].to_numpy())\n",
    "            ys = strip(g['y'].to_numpy())\n",
    "            ds = strip(g['deg'].to_numpy())\n",
    "            sc = score_group(xs, ys, ds, TX, TY)\n",
    "            \n",
    "            if sc < best[n]['score']:\n",
    "                best[n]['score'] = float(sc)\n",
    "                best[n]['data'] = g.drop(columns=['N']).copy()\n",
    "                best[n]['src'] = fp.split('/')[-1]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(\"\\nScanning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override N=1 with optimal 45 degree rotation (theoretical minimum)\n",
    "manual_data = pd.DataFrame({\n",
    "    'id': ['001_0'],\n",
    "    'x': ['s0.0'],\n",
    "    'y': ['s0.0'],\n",
    "    'deg': ['s45.0']\n",
    "})\n",
    "xs = strip(manual_data['x'].to_numpy())\n",
    "ys = strip(manual_data['y'].to_numpy())\n",
    "ds = strip(manual_data['deg'].to_numpy())\n",
    "sc = score_group(xs, ys, ds, TX, TY)\n",
    "best[1]['score'] = float(sc)\n",
    "best[1]['data'] = manual_data.copy()\n",
    "best[1]['src'] = 'optimal_45deg'\n",
    "print(f\"N=1 set to optimal 45Â° rotation, score: {sc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ensemble submission\n",
    "rows = []\n",
    "total_score = 0.0\n",
    "source_counts = {}\n",
    "\n",
    "for n in range(1, 201):\n",
    "    entry = best[n]\n",
    "    if entry['data'] is None:\n",
    "        print(f\"WARNING: No data for N={n}\")\n",
    "        continue\n",
    "    rows.append(entry['data'])\n",
    "    total_score += entry['score']\n",
    "    src = entry['src']\n",
    "    source_counts[src] = source_counts.get(src, 0) + 1\n",
    "\n",
    "print(f\"\\nTotal ensemble score: {total_score:.6f}\")\n",
    "print(f\"\\nTop sources by contribution:\")\n",
    "for src, count in sorted(source_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  {src}: {count} N values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and sort\n",
    "ensemble_df = pd.concat(rows, ignore_index=True)\n",
    "ensemble_df['sn'] = ensemble_df['id'].str.split('_').str[0].astype(int)\n",
    "ensemble_df['si'] = ensemble_df['id'].str.split('_').str[1].astype(int)\n",
    "ensemble_df = ensemble_df.sort_values(['sn', 'si']).drop(columns=['sn', 'si'])\n",
    "ensemble_df = ensemble_df[['id', 'x', 'y', 'deg']]\n",
    "\n",
    "print(f\"Ensemble has {len(ensemble_df)} rows\")\n",
    "print(f\"Expected: {sum(range(1, 201))} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1985bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble\n",
    "ensemble_df.to_csv('/home/code/experiments/002_ensemble/ensemble.csv', index=False)\n",
    "ensemble_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(\"Saved ensemble to experiment folder and submission folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb65e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with baseline\n",
    "baseline_score = 70.619825\n",
    "improvement = baseline_score - total_score\n",
    "print(f\"\\nBaseline score: {baseline_score:.6f}\")\n",
    "print(f\"Ensemble score: {total_score:.6f}\")\n",
    "print(f\"Improvement: {improvement:.6f} ({improvement/baseline_score*100:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076350e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score breakdown by N range\n",
    "print(\"\\nScore breakdown by N range:\")\n",
    "ranges = [(1, 10), (11, 50), (51, 100), (101, 150), (151, 200)]\n",
    "for start, end in ranges:\n",
    "    range_score = sum(best[n]['score'] for n in range(start, end+1))\n",
    "    pct = range_score / total_score * 100\n",
    "    print(f\"  N={start}-{end}: {range_score:.4f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics = {'cv_score': total_score}\n",
    "with open('/home/code/experiments/002_ensemble/metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "print(f\"Saved metrics: {metrics}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
