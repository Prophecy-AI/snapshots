{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443d401",
   "metadata": {},
   "source": [
    "# Experiment 003: Winning Kernel Approach\n",
    "\n",
    "Implementing the winning kernel's techniques:\n",
    "- ExtractFeatures: BMI calculation and column rounding\n",
    "- MEstimateEncoder on select categorical features\n",
    "- 9-fold CV\n",
    "- XGBoost with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e29e3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:41:09.583555Z",
     "iopub.status.busy": "2026-01-15T13:41:09.583310Z",
     "iopub.status.idle": "2026-01-15T13:41:10.517061Z",
     "shell.execute_reply": "2026-01-15T13:41:10.516497Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import MEstimateEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "RANDOM_SEED = 73\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49028e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:41:10.521297Z",
     "iopub.status.busy": "2026-01-15T13:41:10.518505Z",
     "iopub.status.idle": "2026-01-15T13:41:10.591788Z",
     "shell.execute_reply": "2026-01-15T13:41:10.588688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (20758, 18)\n",
      "Test shape: (13840, 17)\n",
      "Target distribution:\n",
      "NObeyesdad\n",
      "Obesity_Type_III       4046\n",
      "Obesity_Type_II        3248\n",
      "Normal_Weight          3082\n",
      "Obesity_Type_I         2910\n",
      "Insufficient_Weight    2523\n",
      "Overweight_Level_II    2522\n",
      "Overweight_Level_I     2427\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "FILE_PATH = \"/home/data\"\n",
    "train = pd.read_csv(os.path.join(FILE_PATH, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(FILE_PATH, \"test.csv\"))\n",
    "sample_sub = pd.read_csv(os.path.join(FILE_PATH, \"sample_submission.csv\"))\n",
    "\n",
    "TARGET = \"NObeyesdad\"\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Target distribution:\\n{train[TARGET].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888e8bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:41:10.592979Z",
     "iopub.status.busy": "2026-01-15T13:41:10.592816Z",
     "iopub.status.idle": "2026-01-15T13:41:10.597789Z",
     "shell.execute_reply": "2026-01-15T13:41:10.597364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering functions from winning kernel\n",
    "def extract_features(x):\n",
    "    \"\"\"Extract BMI and round certain columns\"\"\"\n",
    "    x_copy = x.copy()\n",
    "    # Calculate BMI\n",
    "    x_copy['BMI'] = x_copy['Weight'] / (x_copy['Height'] ** 2)\n",
    "    \n",
    "    # Round specific columns (as done in winning kernel)\n",
    "    cols_to_round = ['FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "    for col in cols_to_round:\n",
    "        x_copy[col] = round(x_copy[col])\n",
    "        x_copy[col] = x_copy[col].astype('int')\n",
    "    \n",
    "    return x_copy\n",
    "\n",
    "# Create transformer\n",
    "ExtractFeatures = FunctionTransformer(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63387b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:41:10.602781Z",
     "iopub.status.busy": "2026-01-15T13:41:10.599920Z",
     "iopub.status.idle": "2026-01-15T13:41:10.605331Z",
     "shell.execute_reply": "2026-01-15T13:41:10.605017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to encode with MEstimateEncoder: ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Define columns for MEstimateEncoder (from winning kernel)\n",
    "# These are the 8 columns they used MEstimateEncoder on\n",
    "cols_to_encode = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "                  'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "\n",
    "print(f\"Columns to encode with MEstimateEncoder: {cols_to_encode}\")\n",
    "print(f\"Number of columns: {len(cols_to_encode)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with feature extraction\n",
    "X = train.drop(columns=[TARGET, 'id'])\n",
    "y = train[TARGET]\n",
    "X_test = test.drop(columns=['id'])\n",
    "\n",
    "# Apply feature extraction\n",
    "X = extract_features(X)\n",
    "X_test = extract_features(X_test)\n",
    "\n",
    "print(f\"Feature extracted X shape: {X.shape}\")\n",
    "print(f\"New features: {[col for col in X.columns if col not in train.columns]}\")\n",
    "print(f\"BMI stats: min={X['BMI'].min():.2f}, max={X['BMI'].max():.2f}, mean={X['BMI'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost hyperparameters from winning kernel\n",
    "# These are the tuned parameters they used\n",
    "xgb_params = {\n",
    "    'n_estimators': 131,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.0937675874371929,\n",
    "    'subsample': 0.8552791251123193,\n",
    "    'colsample_bytree': 0.8490259266383225,\n",
    "    'min_child_weight': 3,\n",
    "    'reg_alpha': 0.00019085504732938993,\n",
    "    'reg_lambda': 0.0004776998473727695,\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameters:\")\n",
    "for k, v in xgb_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18932afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with MEstimateEncoder\n",
    "model = make_pipeline(\n",
    "    MEstimateEncoder(cols=cols_to_encode),\n",
    "    XGBClassifier(**xgb_params)\n",
    ")\n",
    "\n",
    "print(\"Pipeline created:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 9\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "print(f\"Using {n_splits}-fold Stratified CV\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Samples per fold: ~{len(X) // n_splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63192376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros((len(X), len(y.unique())))\n",
    "class_names = sorted(y.unique())\n",
    "target_mapping = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "print(\"Starting cross-validation...\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Target mapping: {target_mapping}\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Clone and fit model\n",
    "    fold_model = clone(model)\n",
    "    fold_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = fold_model.predict(X_val)\n",
    "    fold_acc = accuracy_score(y_val, val_pred)\n",
    "    fold_scores.append(fold_acc)\n",
    "    \n",
    "    print(f\"  Fold accuracy: {fold_acc:.4f}\")\n",
    "    \n",
    "    # Store OOF predictions\n",
    "    val_pred_proba = fold_model.predict_proba(X_val)\n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "\n",
    "# Calculate overall CV score\n",
    "cv_score = np.mean(fold_scores)\n",
    "cv_std = np.std(fold_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CV Results:\")\n",
    "print(f\"  Mean accuracy: {cv_score:.4f} Â± {cv_std:.4f}\")\n",
    "print(f\"  Individual folds: {[f'{score:.4f}' for score in fold_scores]}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "print(\"Training final model on full training data...\")\n",
    "final_model = clone(model)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    TARGET: test_predictions\n",
    "})\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Prediction distribution:\\n{submission[TARGET].value_counts()}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = \"/home/submission/submission_003.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed142f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "# Get the XGBoost model from the pipeline\n",
    "xgb_model = final_model.named_steps['xgbclassifier']\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Check BMI importance\n",
    "bmi_importance = importance_df[importance_df['feature'] == 'BMI']['importance'].iloc[0]\n",
    "print(f\"\\nBMI importance: {bmi_importance:.4f}\")\n",
    "print(f\"BMI rank: {importance_df[importance_df['feature'] == 'BMI'].index[0] + 1}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
