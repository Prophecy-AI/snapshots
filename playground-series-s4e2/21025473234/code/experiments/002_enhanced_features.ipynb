{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e142e7",
   "metadata": {},
   "source": [
    "# Enhanced Features Experiment\n",
    "\n",
    "Addressing data leakage and adding high-impact features from the analysis.\n",
    "\n",
    "**Priority improvements:**\n",
    "1. Fix data leakage with ColumnTransformer + OrdinalEncoder\n",
    "2. Add WHO_BMI_Categories (71.88% accuracy standalone)\n",
    "3. Add Weight_Height_Ratio (correlation 0.4543)\n",
    "4. Add lifestyle interactions (FCVC_NCP, CH2O_FAF, FAF_TUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced feature engineering\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # BMI calculation\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "    \n",
    "    # Weight/Height ratio (second most important feature)\n",
    "    df['Weight_Height_Ratio'] = df['Weight'] / df['Height']\n",
    "    \n",
    "    # WHO BMI Categories (highest impact - 71.88% accuracy standalone)\n",
    "    def categorize_bmi(bmi):\n",
    "        if bmi < 18.5:\n",
    "            return 'Underweight'\n",
    "        elif bmi < 25:\n",
    "            return 'Normal'\n",
    "        elif bmi < 30:\n",
    "            return 'Overweight'\n",
    "        elif bmi < 35:\n",
    "            return 'Obese_I'\n",
    "        elif bmi < 40:\n",
    "            return 'Obese_II'\n",
    "        else:\n",
    "            return 'Obese_III'\n",
    "    \n",
    "    df['WHO_BMI_Category'] = df['BMI'].apply(categorize_bmi)\n",
    "    \n",
    "    # Age groups\n",
    "    df['Age_Group'] = pd.cut(df['Age'], \n",
    "                            bins=[0, 18, 30, 45, 60, 100], \n",
    "                            labels=['0-18', '19-30', '31-45', '46-60', '60+'])\n",
    "    \n",
    "    # Lifestyle interactions (medium-high impact)\n",
    "    df['FCVC_NCP'] = df['FCVC'] * df['NCP']  # Food consumption frequency × meals\n",
    "    df['CH2O_FAF'] = df['CH2O'] * df['FAF']  # Water consumption × physical activity\n",
    "    df['FAF_TUE'] = df['FAF'] * df['TUE']    # Physical activity × technology use\n",
    "    \n",
    "    # Simple interactions\n",
    "    df['Age_Height'] = df['Age'] * df['Height']\n",
    "    df['Age_Weight'] = df['Age'] * df['Weight']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "print(f\"- BMI: {train_fe['BMI'].describe()}\")\n",
    "print(f\"- WHO_BMI_Category distribution:\\n{train_fe['WHO_BMI_Category'].value_counts()}\")\n",
    "print(f\"- Weight_Height_Ratio: {train_fe['Weight_Height_Ratio'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features - FIX DATA LEAKAGE with ColumnTransformer\n",
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "                       'SMOKE', 'SCC', 'CALC', 'MTRANS', 'Age_Group', 'WHO_BMI_Category']\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', \n",
    "                     'BMI', 'Weight_Height_Ratio', 'Age_Height', 'Age_Weight',\n",
    "                     'FCVC_NCP', 'CH2O_FAF', 'FAF_TUE']\n",
    "\n",
    "feature_names = numerical_features + categorical_features\n",
    "\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"Numerical: {len(numerical_features)}\")\n",
    "print(f\"Categorical: {len(categorical_features)}\")\n",
    "\n",
    "# Target encoding\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(train_fe['NObeyesdad'])\n",
    "class_names = le_target.classes_\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified 5-fold CV with proper encoding (no leakage)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros((len(train_fe), len(class_names)))\n",
    "test_predictions = np.zeros((len(test_fe), len(class_names)))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_fe, y_encoded)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_df = train_fe.iloc[train_idx]\n",
    "    X_val_df = train_fe.iloc[val_idx]\n",
    "    y_train = y_encoded[train_idx]\n",
    "    y_val = y_encoded[val_idx]\n",
    "    \n",
    "    # Create ColumnTransformer - FIT ONLY ON TRAINING DATA (no leakage!)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numerical_features),\n",
    "            ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit preprocessor on training data only\n",
    "    X_train_processed = preprocessor.fit_transform(X_train_df)\n",
    "    X_val_processed = preprocessor.transform(X_val_df)\n",
    "    X_test_processed = preprocessor.transform(test_fe)\n",
    "    \n",
    "    # Create XGBoost datasets\n",
    "    dtrain = xgb.DMatrix(X_train_processed, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val_processed, label=y_val)\n",
    "    \n",
    "    # Parameters (slightly tuned for more features)\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(class_names),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'max_depth': 7,  # Slightly deeper for more features\n",
    "        'learning_rate': 0.08,  # Slightly lower for more iterations\n",
    "        'subsample': 0.85,\n",
    "        'colsample_bytree': 0.85,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1500,  # More rounds for better convergence\n",
    "        evals=[(dval, 'val')],\n",
    "        early_stopping_rounds=75,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict(dval)\n",
    "    test_pred = model.predict(xgb.DMatrix(X_test_processed))\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / 5\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    val_pred_labels = np.argmax(val_pred, axis=1)\n",
    "    fold_accuracy = accuracy_score(y_val, val_pred_labels)\n",
    "    fold_scores.append(fold_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Accuracy: {fold_accuracy:.4f}\")\n",
    "    print(f\"Best iteration: {model.best_iteration}\")\n",
    "\n",
    "# Overall CV score\n",
    "oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "cv_accuracy = accuracy_score(y_encoded, oof_pred_labels)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CV Accuracy: {cv_accuracy:.4f} ± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual folds: {fold_scores}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db80ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'NObeyesdad': le_target.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission_002_enhanced_features.csv', index=False)\n",
    "print(f\"Submission saved. Shape: {submission.shape}\")\n",
    "print(f\"Submission distribution:\\n{submission['NObeyesdad'].value_counts(normalize=True)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
