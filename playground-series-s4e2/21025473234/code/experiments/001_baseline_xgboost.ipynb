{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340e6794",
   "metadata": {},
   "source": [
    "# Baseline XGBoost Model\n",
    "\n",
    "Simple baseline following the seed prompt strategy with basic feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f14020d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:43:43.744490Z",
     "iopub.status.busy": "2026-01-15T09:43:43.744187Z",
     "iopub.status.idle": "2026-01-15T09:43:44.560222Z",
     "shell.execute_reply": "2026-01-15T09:43:44.559771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (20758, 18)\n",
      "Test shape: (13840, 17)\n",
      "Target distribution:\n",
      "NObeyesdad\n",
      "Obesity_Type_III       0.194913\n",
      "Obesity_Type_II        0.156470\n",
      "Normal_Weight          0.148473\n",
      "Obesity_Type_I         0.140187\n",
      "Insufficient_Weight    0.121544\n",
      "Overweight_Level_II    0.121495\n",
      "Overweight_Level_I     0.116919\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Target distribution:\\n{train['NObeyesdad'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f737c57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:43:44.561378Z",
     "iopub.status.busy": "2026-01-15T09:43:44.561204Z",
     "iopub.status.idle": "2026-01-15T09:43:44.570141Z",
     "shell.execute_reply": "2026-01-15T09:43:44.569778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic feature engineering\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # BMI calculation - critical feature\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "    \n",
    "    # Age groups\n",
    "    df['Age_Group'] = pd.cut(df['Age'], \n",
    "                            bins=[0, 18, 30, 45, 60, 100], \n",
    "                            labels=['0-18', '19-30', '31-45', '46-60', '60+'])\n",
    "    \n",
    "    # Simple interactions\n",
    "    df['Age_Height'] = df['Age'] * df['Height']\n",
    "    df['Age_Weight'] = df['Age'] * df['Weight']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_fe = engineer_features(train)\n",
    "test_fe = engineer_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14122971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:43:44.571621Z",
     "iopub.status.busy": "2026-01-15T09:43:44.571344Z",
     "iopub.status.idle": "2026-01-15T09:43:44.635071Z",
     "shell.execute_reply": "2026-01-15T09:43:44.634523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (20758, 20)\n",
      "Test matrix shape: (13840, 20)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features\n",
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "                       'SMOKE', 'SCC', 'CALC', 'MTRANS', 'Age_Group']\n",
    "numerical_features = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', \n",
    "                     'BMI', 'Age_Height', 'Age_Weight']\n",
    "\n",
    "# Encode categorical features\n",
    "encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined data to handle any unseen categories\n",
    "    combined = pd.concat([train_fe[col], test_fe[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    train_fe[col] = le.transform(train_fe[col].astype(str))\n",
    "    test_fe[col] = le.transform(test_fe[col].astype(str))\n",
    "    encoders[col] = le\n",
    "\n",
    "X = train_fe[numerical_features + categorical_features]\n",
    "y = train_fe['NObeyesdad']\n",
    "X_test = test_fe[numerical_features + categorical_features]\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Test matrix shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdc7143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:43:44.636316Z",
     "iopub.status.busy": "2026-01-15T09:43:44.636139Z",
     "iopub.status.idle": "2026-01-15T09:43:54.075826Z",
     "shell.execute_reply": "2026-01-15T09:43:54.075035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Insufficient_Weight' 'Normal_Weight' 'Obesity_Type_I' 'Obesity_Type_II'\n",
      " 'Obesity_Type_III' 'Overweight_Level_I' 'Overweight_Level_II']\n",
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.9109\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.9037\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.9121\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.9034\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.9056\n",
      "\n",
      "CV Accuracy: 0.9071 ± 0.0037\n",
      "Individual folds: [0.9108863198458574, 0.9036608863198459, 0.9120905587668593, 0.9033967718622019, 0.9055649241146712]\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "oof_predictions = np.zeros((len(X), len(train['NObeyesdad'].unique())))\n",
    "test_predictions = np.zeros((len(X_test), len(train['NObeyesdad'].unique())))\n",
    "\n",
    "# Get class labels\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "class_names = le_target.classes_\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # Create XGBoost datasets\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(class_names),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dval, 'val')],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict(dval)\n",
    "    test_pred = model.predict(xgb.DMatrix(X_test))\n",
    "    \n",
    "    # Store predictions\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / 5\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    val_pred_labels = np.argmax(val_pred, axis=1)\n",
    "    fold_accuracy = accuracy_score(y_val, val_pred_labels)\n",
    "    fold_scores.append(fold_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Accuracy: {fold_accuracy:.4f}\")\n",
    "\n",
    "# Overall CV score\n",
    "oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "cv_accuracy = accuracy_score(y_encoded, oof_pred_labels)\n",
    "print(f\"\\nCV Accuracy: {cv_accuracy:.4f} ± {np.std(fold_scores):.4f}\")\n",
    "print(f\"Individual folds: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df745379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:43:54.078296Z",
     "iopub.status.busy": "2026-01-15T09:43:54.078052Z",
     "iopub.status.idle": "2026-01-15T09:43:54.105180Z",
     "shell.execute_reply": "2026-01-15T09:43:54.101657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved. Shape: (13840, 2)\n",
      "Submission distribution:\n",
      "NObeyesdad\n",
      "Obesity_Type_III       0.189668\n",
      "Normal_Weight          0.153324\n",
      "Obesity_Type_II        0.152890\n",
      "Obesity_Type_I         0.149566\n",
      "Overweight_Level_II    0.126445\n",
      "Insufficient_Weight    0.123916\n",
      "Overweight_Level_I     0.104191\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'NObeyesdad': le_target.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "})\n",
    "\n",
    "submission.to_csv('/home/submission/submission_001_baseline_xgboost.csv', index=False)\n",
    "print(f\"Submission saved. Shape: {submission.shape}\")\n",
    "print(f\"Submission distribution:\\n{submission['NObeyesdad'].value_counts(normalize=True)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
