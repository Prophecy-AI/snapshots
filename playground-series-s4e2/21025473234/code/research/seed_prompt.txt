## Current Status
- Best CV score: 0.9052 from exp_002 (MEstimateEncoder approach)
- Best LB score: Not yet submitted (CRITICAL GAP)
- CV-LB gap: Unknown - need submission for calibration
- Score trend: DECLINING (0.9071 → 0.9060 → 0.9052) - 3 consecutive decreases
- Gap to target: 0.0064 (0.911570 - 0.9052)

## Response to Evaluator
- **Technical verdict**: TRUSTWORTHY - Execution is sound, but strategy is fundamentally flawed
- **Evaluator's historical concern**: Data leakage with LabelEncoder (addressed in exp_001)
- **My assessment**: The declining trend indicates we're optimizing the wrong things. MEstimateEncoder with enhanced features causes overfitting (double-encoding target signal). Prediction overlap of 97-99% across experiments proves our "enhancements" aren't actually improving diversity.
- **Key insight**: Winning kernel's 0.92160 score comes from MODEL DIVERSITY + ENSEMBLING, not just better features. We're stuck on single-model thinking while winners use 4-model ensembles.

## Data Understanding
- Reference notebooks: See `exploration/evolver_loop4_analysis.ipynb` for winning kernel deep-dive
- **Critical finding**: Winning kernel uses 4 models (RandomForest, LGBM, XGBoost, CatBoost) with weights rfc=0, lgbm=3, xgb=1, cat=0
- **MEstimateEncoder failure**: When combined with WHO_BMI_Categories (71.88% standalone accuracy), it creates double-encoding of target signal → overfitting → worse CV
- **Prediction overlap**: 97-99% same predictions across all 3 experiments - we're not creating meaningful variation
- **Ensemble opportunity**: Simple weighted averaging with LGBM+XGBoost can capture 0.0156 of missing performance

## Recommended Approaches (Priority Order)

### 1. SUBMIT exp_002 FOR LB CALIBRATION (URGENT - DO FIRST)
- We have ZERO LB submissions - flying blind on CV-LB gap
- exp_002 represents our best validated model (leakage-free, 9-fold CV)
- Need to understand if our CV is optimistic/pessimistic before further experiments
- **Action**: Submit exp_002 immediately, then wait for feedback before proceeding

### 2. STOP THE DECLINING TREND (CRITICAL)
- Current trajectory: 0.9071 → 0.9060 → 0.9052 (losing 0.0019)
- MEstimateEncoder + enhanced features is OVERFITTING
- **Action**: Revert to exp_001 approach (enhanced features + OrdinalEncoder) which gave 0.9060
- Build ensemble from STABLE baseline, not declining one

### 3. IMPLEMENT LGBM MODEL (HIGH IMPACT)
- Winning kernel's top performer (weight=3 vs XGB weight=1)
- LightGBM often outperforms XGBoost on tabular data
- Provides critical model diversity for ensembling
- **Action**: Train LGBMClassifier with SAME preprocessing as XGBoost (enhanced features)
- Use Optuna tuning: focus on num_leaves, learning_rate, min_child_samples

### 4. BUILD SIMPLE WEIGHTED ENSEMBLE (HIGH IMPACT)
- Winning kernel uses simple averaging: `final = 3*LGBM + 1*XGB`
- No complex stacking needed - just weighted predictions
- **Action**: 
  - Generate predictions from LGBM and XGBoost models
  - Apply weights: LGBM=3, XGB=1 (from winning kernel)
  - Normalize to get final probabilities
  - This alone should recover 0.010-0.015 of performance

### 5. MODEL-SPECIFIC PREPROCESSING (MEDIUM-HIGH IMPACT)
- Winning kernel uses DIFFERENT preprocessing per model
- **Action**:
  - XGBoost: Use enhanced features (BMI, WHO_BMI_Categories, interactions) - works well with tree models
  - LGBM: Try raw features + MEstimateEncoder (LGBM handles target encoding better)
  - This creates diversity in feature representations

### 6. ADD CATBOOST MODEL (MEDIUM IMPACT)
- Winning kernel includes CatBoost (weight=0, but still provides diversity)
- Handles categorical features natively - no encoding needed
- **Action**: Train CatBoostClassifier with raw categorical features
- Use small learning_rate, many iterations with early stopping

### 7. HYPERPARAMETER TUNING PER MODEL (MEDIUM IMPACT)
- Current parameters are basic
- **Action**: Run Optuna for each model separately
- Focus on: max_depth/num_leaves, learning_rate, min_child_weight/samples, subsample/colsample
- Winning kernel used extensive tuning - we need to match this

### 8. INCREASE CV FOLDS TO 9 (LOW-MEDIUM IMPACT)
- Winning kernel uses 9-fold vs our 5-fold
- More stable estimates, better for ensemble selection
- **Action**: Change from 5-fold to 9-fold StratifiedKFold
- Monitor if std decreases (should be more stable)

## What NOT to Try
- **Don't** continue with MEstimateEncoder on enhanced features (proven to hurt: 0.9071 → 0.9052)
- **Don't** add more BMI-derived features (WHO_BMI_Categories already captures this signal at 71.88% accuracy)
- **Don't** implement complex stacking before simple weighted averaging (winning kernel uses simple weights)
- **Don't** tune hyperparameters aggressively before building ensemble (ensemble provides bigger gains)
- **Don't** ignore the declining trend - we need to stabilize first before optimizing further

## Validation Notes
- **Immediate**: Submit exp_002 to get LB feedback
- **CV Strategy**: Use 9-fold StratifiedKFold (matching winning kernel)
- **Ensemble Validation**: Generate OOF predictions from each model, then optimize weights on validation set
- **Target**: Aim for ensemble CV of 0.9150+ (beating target by healthy margin)
- **Stability Check**: If ensemble std > 0.005, investigate model correlation (need diversity)