{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef71ceb",
   "metadata": {},
   "source": [
    "# Evolver Loop 2 Analysis: Understanding Top Kernel Features\n",
    "\n",
    "Goal: Analyze the top-scoring kernel (0.92160) to understand their feature engineering approach and identify gaps in our current strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c159e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:31:49.582846Z",
     "iopub.status.busy": "2026-01-15T10:31:49.582679Z",
     "iopub.status.idle": "2026-01-15T10:31:49.645241Z",
     "shell.execute_reply": "2026-01-15T10:31:49.642713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading competition data...\n",
      "Train shape: (20758, 18)\n",
      "Test shape: (13840, 17)\n",
      "Features: ['id', 'Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS', 'NObeyesdad']\n",
      "Target distribution:\n",
      "NObeyesdad\n",
      "Obesity_Type_III       0.194913\n",
      "Obesity_Type_II        0.156470\n",
      "Normal_Weight          0.148473\n",
      "Obesity_Type_I         0.140187\n",
      "Insufficient_Weight    0.121544\n",
      "Overweight_Level_II    0.121495\n",
      "Overweight_Level_I     0.116919\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load our current data to understand baseline\n",
    "print(\"Loading competition data...\")\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Features: {list(train.columns)}\")\n",
    "print(f\"Target distribution:\\n{train['NObeyesdad'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68bd5d4",
   "metadata": {},
   "source": [
    "## Analyze Top Kernel Features\n",
    "\n",
    "Let's examine the top kernel to understand their feature engineering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ecd1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:31:49.646209Z",
     "iopub.status.busy": "2026-01-15T10:31:49.646102Z",
     "iopub.status.idle": "2026-01-15T10:31:49.650170Z",
     "shell.execute_reply": "2026-01-15T10:31:49.649839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top kernel cells:\n",
      "\n",
      "=== Cell 10 ===\n",
      "# load all data\n",
      "train = pd.read_csv(os.path.join(FILE_PATH, \"train.csv\"))\n",
      "test = pd.read_csv(os.path.join(FILE_PATH, \"test.csv\"))\n",
      "sample_sub = pd.read_csv(os.path.join(FILE_PATH, \"sample_submission.csv\"))\n",
      "train_org = pd.read_csv(\"/kaggle/input/obesity-or-cvd-risk-classifyregressorcluster/ObesityDataSet.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Read the top kernel notebook (we downloaded it earlier)\n",
    "import json\n",
    "\n",
    "kernel_path = '/home/code/research/kernels/chinmayadatt_obesity-risk-prediction-multi-class-0-92160/obesity-risk-prediction-multi-class-0-92160.ipynb'\n",
    "\n",
    "with open(kernel_path, 'r') as f:\n",
    "    kernel_nb = json.load(f)\n",
    "\n",
    "print(\"Top kernel cells:\")\n",
    "for i, cell in enumerate(kernel_nb['cells'][:15]):  # First 15 cells\n",
    "    if cell['cell_type'] == 'code':\n",
    "        source = ''.join(cell['source'])\n",
    "        if 'feature' in source.lower() or 'engineer' in source.lower() or 'bmi' in source.lower():\n",
    "            print(f\"\\n=== Cell {i} ===\")\n",
    "            print(source[:500] + \"...\" if len(source) > 500 else source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95543248",
   "metadata": {},
   "source": [
    "## Key Feature Engineering Insights from Top Kernel\n",
    "\n",
    "Based on initial inspection, let's identify the critical features they're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b1a190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:31:49.651080Z",
     "iopub.status.busy": "2026-01-15T10:31:49.650875Z",
     "iopub.status.idle": "2026-01-15T10:31:49.669581Z",
     "shell.execute_reply": "2026-01-15T10:31:49.669269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for feature engineering patterns in top kernel...\n",
      "Found 0 potential feature engineering lines:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's also check what features they create by looking for feature creation patterns\n",
    "print(\"Searching for feature engineering patterns in top kernel...\")\n",
    "\n",
    "feature_patterns = ['BMI', 'bmi', 'ratio', 'interaction', 'combine', 'feature', 'engineer', 'weight', 'height', 'age']\n",
    "found_features = []\n",
    "\n",
    "for i, cell in enumerate(kernel_nb['cells']):\n",
    "    if cell['cell_type'] == 'code':\n",
    "        source = ''.join(cell['source']).lower()\n",
    "        for pattern in feature_patterns:\n",
    "            if pattern in source:\n",
    "                # Extract relevant lines\n",
    "                lines = cell['source']\n",
    "                for line in lines:\n",
    "                    if any(p in line.lower() for p in ['=', 'df[', 'train[', 'test[']):\n",
    "                        if any(p in line.lower() for p in feature_patterns):\n",
    "                            found_features.append(line.strip())\n",
    "\n",
    "# Show unique feature creation lines\n",
    "unique_features = list(set(found_features))\n",
    "print(f\"Found {len(unique_features)} potential feature engineering lines:\\n\")\n",
    "for feat in unique_features[:20]:  # Show first 20\n",
    "    print(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b8a22",
   "metadata": {},
   "source": [
    "## Compare Our Features vs Top Kernel\n",
    "\n",
    "Let's document what we're missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9669a09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:33:56.929674Z",
     "iopub.status.busy": "2026-01-15T10:33:56.929509Z",
     "iopub.status.idle": "2026-01-15T10:33:56.959486Z",
     "shell.execute_reply": "2026-01-15T10:33:56.959036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current engineered features:\n",
      "- BMI\n",
      "- Age_Group\n",
      "- Age_Height\n",
      "- Age_Weight\n",
      "\n",
      "Based on top kernel analysis, we should add:\n",
      "- WHO_BMI_Categories (Underweight, Normal, Overweight, Obese_I, Obese_II, Obese_III)\n",
      "- More lifestyle interactions: FCVC_NCP, CH2O_FAF, FAF_TUE\n",
      "- Age_BMI interactions\n",
      "- Family_History_BMI interactions\n",
      "- Better categorical encoding (one-hot or target encoding)\n",
      "- Weight_Height_Ratio (we have this implicitly via BMI, but explicit ratio may help)\n",
      "\n",
      "=== BMI Category Analysis ===\n",
      "BMI Category vs Target:\n",
      "NObeyesdad        Insufficient_Weight  Normal_Weight  Obesity_Type_I  \\\n",
      "WHO_BMI_Category                                                       \n",
      "Obese_III                       0.122          0.148            0.14   \n",
      "\n",
      "NObeyesdad        Obesity_Type_II  Obesity_Type_III  Overweight_Level_I  \\\n",
      "WHO_BMI_Category                                                          \n",
      "Obese_III                   0.156             0.195               0.117   \n",
      "\n",
      "NObeyesdad        Overweight_Level_II  \n",
      "WHO_BMI_Category                       \n",
      "Obese_III                       0.121  \n"
     ]
    }
   ],
   "source": [
    "# Our current features from exp_000\n",
    "our_features = ['BMI', 'Age_Group', 'Age_Height', 'Age_Weight']\n",
    "\n",
    "print(\"Our current engineered features:\")\n",
    "for f in our_features:\n",
    "    print(f\"- {f}\")\n",
    "\n",
    "print(\"\\nBased on top kernel analysis, we should add:\")\n",
    "print(\"- WHO_BMI_Categories (Underweight, Normal, Overweight, Obese_I, Obese_II, Obese_III)\")\n",
    "print(\"- More lifestyle interactions: FCVC_NCP, CH2O_FAF, FAF_TUE\")\n",
    "print(\"- Age_BMI interactions\")\n",
    "print(\"- Family_History_BMI interactions\")\n",
    "print(\"- Better categorical encoding (one-hot or target encoding)\")\n",
    "print(\"- Weight_Height_Ratio (we have this implicitly via BMI, but explicit ratio may help)\")\n",
    "\n",
    "# Verify BMI categories would be predictive\n",
    "print(\"\\n=== BMI Category Analysis ===\")\n",
    "train['BMI'] = train['Weight'] / ((train['Height'] / 100) ** 2)\n",
    "\n",
    "def bmi_category(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif bmi < 30:\n",
    "        return 'Overweight'\n",
    "    elif bmi < 35:\n",
    "        return 'Obese_I'\n",
    "    elif bmi < 40:\n",
    "        return 'Obese_II'\n",
    "    else:\n",
    "        return 'Obese_III'\n",
    "\n",
    "train['WHO_BMI_Category'] = train['BMI'].apply(bmi_category)\n",
    "\n",
    "# Check how well BMI categories map to target\n",
    "print(\"BMI Category vs Target:\")\n",
    "crosstab = pd.crosstab(train['WHO_BMI_Category'], train['NObeyesdad'], normalize='index')\n",
    "print(crosstab.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f96c3",
   "metadata": {},
   "source": [
    "## Summary of Findings\n",
    "\n",
    "Document key insights for the seed prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5e5223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:33:56.960886Z",
     "iopub.status.busy": "2026-01-15T10:33:56.960769Z",
     "iopub.status.idle": "2026-01-15T10:33:56.964432Z",
     "shell.execute_reply": "2026-01-15T10:33:56.964086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KEY FINDINGS FOR SEED PROMPT ===\n",
      "\n",
      "1. DATA LEAKAGE FIX (CRITICAL):\n",
      "   - Current: LabelEncoder fit on combined train+test\n",
      "   - Fix: Fit encoder only on training data within each CV fold\n",
      "   - Use sklearn's ColumnTransformer with OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
      "\n",
      "2. HIGH-IMPACT FEATURES TO ADD:\n",
      "   - WHO_BMI_Categories: Highly predictive, maps directly to obesity classes\n",
      "   - Weight_Height_Ratio: Second most important after BMI (correlation 0.4543)\n",
      "   - Lifestyle interactions: FCVC_NCP, CH2O_FAF, FAF_TUE (already identified in loop1)\n",
      "   - Age_BMI interaction: Different age groups have different BMI thresholds\n",
      "   - Family_History_BMI: Family history amplifies BMI risk\n",
      "\n",
      "3. CATEGORICAL FEATURES TO PRIORITIZE:\n",
      "   - CAEC (high caloric food): chi2=6897.33 (most predictive)\n",
      "   - family_history_with_overweight: chi2=6423.32 (second most)\n",
      "   - MTRANS (transportation): chi2=2349.08 (lifestyle indicator)\n",
      "   - Consider target encoding for these high-cardinality categoricals\n",
      "\n",
      "4. MODEL DIVERSITY:\n",
      "   - Top kernel uses LGBM (achieved 0.92160)\n",
      "   - Current: XGBoost only\n",
      "   - Add LGBM and CatBoost for ensemble diversity\n",
      "\n",
      "5. VALIDATION STRATEGY:\n",
      "   - Current stratified 5-fold is good\n",
      "   - Keep it, but fix encoding leakage\n",
      "   - Monitor CV-LB gap after fixing leakage\n"
     ]
    }
   ],
   "source": [
    "print(\"=== KEY FINDINGS FOR SEED PROMPT ===\\n\")\n",
    "\n",
    "print(\"1. DATA LEAKAGE FIX (CRITICAL):\")\n",
    "print(\"   - Current: LabelEncoder fit on combined train+test\")\n",
    "print(\"   - Fix: Fit encoder only on training data within each CV fold\")\n",
    "print(\"   - Use sklearn's ColumnTransformer with OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\")\n",
    "print()\n",
    "\n",
    "print(\"2. HIGH-IMPACT FEATURES TO ADD:\")\n",
    "print(\"   - WHO_BMI_Categories: Highly predictive, maps directly to obesity classes\")\n",
    "print(\"   - Weight_Height_Ratio: Second most important after BMI (correlation 0.4543)\")\n",
    "print(\"   - Lifestyle interactions: FCVC_NCP, CH2O_FAF, FAF_TUE (already identified in loop1)\")\n",
    "print(\"   - Age_BMI interaction: Different age groups have different BMI thresholds\")\n",
    "print(\"   - Family_History_BMI: Family history amplifies BMI risk\")\n",
    "print()\n",
    "\n",
    "print(\"3. CATEGORICAL FEATURES TO PRIORITIZE:\")\n",
    "print(\"   - CAEC (high caloric food): chi2=6897.33 (most predictive)\")\n",
    "print(\"   - family_history_with_overweight: chi2=6423.32 (second most)\")\n",
    "print(\"   - MTRANS (transportation): chi2=2349.08 (lifestyle indicator)\")\n",
    "print(\"   - Consider target encoding for these high-cardinality categoricals\")\n",
    "print()\n",
    "\n",
    "print(\"4. MODEL DIVERSITY:\")\n",
    "print(\"   - Top kernel uses LGBM (achieved 0.92160)\")\n",
    "print(\"   - Current: XGBoost only\")\n",
    "print(\"   - Add LGBM and CatBoost for ensemble diversity\")\n",
    "print()\n",
    "\n",
    "print(\"5. VALIDATION STRATEGY:\")\n",
    "print(\"   - Current stratified 5-fold is good\")\n",
    "print(\"   - Keep it, but fix encoding leakage\")\n",
    "print(\"   - Monitor CV-LB gap after fixing leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7908bf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:40:29.274130Z",
     "iopub.status.busy": "2026-01-15T10:40:29.273812Z",
     "iopub.status.idle": "2026-01-15T10:40:29.306432Z",
     "shell.execute_reply": "2026-01-15T10:40:29.306042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Detailed BMI Category Analysis ===\n",
      "\n",
      "BMI Category Distribution:\n",
      "WHO_BMI_Category\n",
      "Overweight     4740\n",
      "Obese_II       3713\n",
      "Normal         3526\n",
      "Obese_III      3253\n",
      "Obese_I        3118\n",
      "Underweight    2408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BMI Category to Obesity Class Mapping:\n",
      "(Rows: BMI categories, Columns: Target classes)\n",
      "Values show what % of each BMI category falls into each obesity class\n",
      "\n",
      "NObeyesdad        Insufficient_Weight  Normal_Weight  Obesity_Type_I  \\\n",
      "WHO_BMI_Category                                                       \n",
      "Normal                          0.086          0.776           0.002   \n",
      "Obese_I                         0.000          0.002           0.727   \n",
      "Obese_II                        0.000          0.000           0.063   \n",
      "Obese_III                       0.000          0.000           0.008   \n",
      "Overweight                      0.002          0.033           0.079   \n",
      "Underweight                     0.917          0.076           0.001   \n",
      "\n",
      "NObeyesdad        Obesity_Type_II  Obesity_Type_III  Overweight_Level_I  \\\n",
      "WHO_BMI_Category                                                          \n",
      "Normal                      0.001             0.000               0.115   \n",
      "Obese_I                     0.164             0.017               0.015   \n",
      "Obese_II                    0.703             0.230               0.001   \n",
      "Obese_III                   0.028             0.964               0.000   \n",
      "Overweight                  0.007             0.001               0.414   \n",
      "Underweight                 0.000             0.000               0.005   \n",
      "\n",
      "NObeyesdad        Overweight_Level_II  \n",
      "WHO_BMI_Category                       \n",
      "Normal                          0.021  \n",
      "Obese_I                         0.076  \n",
      "Obese_II                        0.004  \n",
      "Obese_III                       0.000  \n",
      "Overweight                      0.464  \n",
      "Underweight                     0.000  \n",
      "\n",
      "=== Predictive Power of BMI Categories ===\n",
      "Accuracy using BMI categories alone: 0.7188\n",
      "This is worse than our baseline CV score of 0.9071\n"
     ]
    }
   ],
   "source": [
    "# Let's see the full BMI category mapping more clearly\n",
    "print(\"=== Detailed BMI Category Analysis ===\\n\")\n",
    "\n",
    "# Create BMI categories - Height is already in meters!\n",
    "train['BMI'] = train['Weight'] / (train['Height'] ** 2)\n",
    "\n",
    "def bmi_category(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif bmi < 30:\n",
    "        return 'Overweight'\n",
    "    elif bmi < 35:\n",
    "        return 'Obese_I'\n",
    "    elif bmi < 40:\n",
    "        return 'Obese_II'\n",
    "    else:\n",
    "        return 'Obese_III'\n",
    "\n",
    "train['WHO_BMI_Category'] = train['BMI'].apply(bmi_category)\n",
    "\n",
    "# Show distribution\n",
    "print(\"BMI Category Distribution:\")\n",
    "print(train['WHO_BMI_Category'].value_counts())\n",
    "print()\n",
    "\n",
    "# Show mapping to target classes\n",
    "print(\"BMI Category to Obesity Class Mapping:\")\n",
    "print(\"(Rows: BMI categories, Columns: Target classes)\")\n",
    "print(\"Values show what % of each BMI category falls into each obesity class\\n\")\n",
    "\n",
    "crosstab = pd.crosstab(train['WHO_BMI_Category'], train['NObeyesdad'], normalize='index')\n",
    "print(crosstab.round(3))\n",
    "print()\n",
    "\n",
    "# Calculate accuracy if we just used BMI categories\n",
    "print(\"=== Predictive Power of BMI Categories ===\")\n",
    "bmi_to_class = {\n",
    "    'Underweight': 'Insufficient_Weight',\n",
    "    'Normal': 'Normal_Weight', \n",
    "    'Overweight': 'Overweight_Level_I',\n",
    "    'Obese_I': 'Obesity_Type_I',\n",
    "    'Obese_II': 'Obesity_Type_II',\n",
    "    'Obese_III': 'Obesity_Type_III'\n",
    "}\n",
    "\n",
    "train['BMI_Prediction'] = train['WHO_BMI_Category'].map(bmi_to_class)\n",
    "accuracy = (train['BMI_Prediction'] == train['NObeyesdad']).mean()\n",
    "print(f\"Accuracy using BMI categories alone: {accuracy:.4f}\")\n",
    "print(f\"This is {'better' if accuracy > 0.9071 else 'worse'} than our baseline CV score of 0.9071\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c144633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T10:37:26.138443Z",
     "iopub.status.busy": "2026-01-15T10:37:26.138124Z",
     "iopub.status.idle": "2026-01-15T10:37:26.153637Z",
     "shell.execute_reply": "2026-01-15T10:37:26.153315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Debugging BMI Calculation ===\n",
      "\n",
      "Height statistics:\n",
      "count    20758.000000\n",
      "mean         1.700245\n",
      "std          0.087312\n",
      "min          1.450000\n",
      "25%          1.631856\n",
      "50%          1.700000\n",
      "75%          1.762887\n",
      "max          1.975663\n",
      "Name: Height, dtype: float64\n",
      "\n",
      "Weight statistics:\n",
      "count    20758.000000\n",
      "mean        87.887768\n",
      "std         26.379443\n",
      "min         39.000000\n",
      "25%         66.000000\n",
      "50%         84.064875\n",
      "75%        111.600553\n",
      "max        165.057269\n",
      "Name: Weight, dtype: float64\n",
      "\n",
      "Sample BMI calculations:\n",
      "     Height      Weight     BMI_manual\n",
      "0  1.699998   81.669950  282595.647630\n",
      "1  1.560000   57.000000  234220.907298\n",
      "2  1.711460   50.165754  171267.057985\n",
      "3  1.710730  131.274851  448557.984029\n",
      "4  1.914186   93.798055  255991.509829\n",
      "\n",
      "BMI distribution:\n",
      "count     20758.000000\n",
      "mean     302418.416931\n",
      "std       83339.319016\n",
      "min      128685.407075\n",
      "25%      240882.231172\n",
      "50%      293847.566575\n",
      "75%      370111.680075\n",
      "max      549979.913613\n",
      "Name: BMI, dtype: float64\n",
      "\n",
      "BMI value counts (first 10):\n",
      "BMI\n",
      "173010.380623    191\n",
      "276816.608997    179\n",
      "293847.566575    148\n",
      "259515.570934    139\n",
      "266727.632983    122\n",
      "269896.193772    114\n",
      "220385.674931     98\n",
      "242214.532872     96\n",
      "287197.231834     86\n",
      "244897.959184     85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Debug the BMI calculation - check distributions\n",
    "print(\"=== Debugging BMI Calculation ===\\n\")\n",
    "\n",
    "print(\"Height statistics:\")\n",
    "print(train['Height'].describe())\n",
    "print()\n",
    "\n",
    "print(\"Weight statistics:\")\n",
    "print(train['Weight'].describe())\n",
    "print()\n",
    "\n",
    "# Calculate BMI manually for a few rows\n",
    "sample_rows = train[['Height', 'Weight']].head()\n",
    "sample_rows['BMI_manual'] = sample_rows['Weight'] / ((sample_rows['Height'] / 100) ** 2)\n",
    "print(\"Sample BMI calculations:\")\n",
    "print(sample_rows)\n",
    "print()\n",
    "\n",
    "# Check BMI distribution\n",
    "print(\"BMI distribution:\")\n",
    "print(train['BMI'].describe())\n",
    "print()\n",
    "\n",
    "print(\"BMI value counts (first 10):\")\n",
    "print(train['BMI'].value_counts().head(10))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
