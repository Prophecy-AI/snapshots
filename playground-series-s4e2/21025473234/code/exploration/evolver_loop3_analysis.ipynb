{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b386cb",
   "metadata": {},
   "source": [
    "# Evolver Loop 3 Analysis: MEstimateEncoder Investigation\n",
    "\n",
    "This notebook analyzes the winning kernel's use of MEstimateEncoder and prepares recommendations for the next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "028279df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:45:39.642447Z",
     "iopub.status.busy": "2026-01-15T12:45:39.642200Z",
     "iopub.status.idle": "2026-01-15T12:45:39.705033Z",
     "shell.execute_reply": "2026-01-15T12:45:39.699336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Train: (20758, 18)\n",
      "Test: (13840, 17)\n",
      "\n",
      "Target distribution:\n",
      "NObeyesdad\n",
      "Obesity_Type_III       0.194913\n",
      "Obesity_Type_II        0.156470\n",
      "Normal_Weight          0.148473\n",
      "Obesity_Type_I         0.140187\n",
      "Insufficient_Weight    0.121544\n",
      "Overweight_Level_II    0.121495\n",
      "Overweight_Level_I     0.116919\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from category_encoders import MEstimateEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/home/data/train.csv')\n",
    "test = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(train['NObeyesdad'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6bd3a",
   "metadata": {},
   "source": [
    "## Analyze Categorical Features for MEstimateEncoder\n",
    "\n",
    "MEstimateEncoder is most effective for categorical features with strong relationship to target. Let's analyze which features would benefit most from target encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd537eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:45:39.706069Z",
     "iopub.status.busy": "2026-01-15T12:45:39.705929Z",
     "iopub.status.idle": "2026-01-15T12:45:39.778501Z",
     "shell.execute_reply": "2026-01-15T12:45:39.778133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender:\n",
      "  Cardinality: 2\n",
      "  Categories: ['Male' 'Female']\n",
      "  Most dominant class per category:\n",
      "    Male: Obesity_Type_II (31.3%)\n",
      "    Female: Obesity_Type_III (38.8%)\n",
      "\n",
      "family_history_with_overweight:\n",
      "  Cardinality: 2\n",
      "  Categories: ['yes' 'no']\n",
      "  Most dominant class per category:\n",
      "    yes: Obesity_Type_III (23.8%)\n",
      "    no: Insufficient_Weight (38.7%)\n",
      "\n",
      "FAVC:\n",
      "  Cardinality: 2\n",
      "  Categories: ['yes' 'no']\n",
      "  Most dominant class per category:\n",
      "    yes: Obesity_Type_III (21.3%)\n",
      "    no: Overweight_Level_II (30.3%)\n",
      "\n",
      "CAEC:\n",
      "  Cardinality: 4\n",
      "  Categories: ['Sometimes' 'Frequently' 'no' 'Always']\n",
      "  Most dominant class per category:\n",
      "    Sometimes: Obesity_Type_III (23.1%)\n",
      "    Frequently: Insufficient_Weight (49.0%)\n",
      "    no: Overweight_Level_I (78.5%)\n",
      "    Always: Normal_Weight (57.5%)\n",
      "\n",
      "SMOKE:\n",
      "  Cardinality: 2\n",
      "  Categories: ['no' 'yes']\n",
      "  Most dominant class per category:\n",
      "    no: Obesity_Type_III (19.7%)\n",
      "    yes: Obesity_Type_II (46.5%)\n",
      "\n",
      "SCC:\n",
      "  Cardinality: 2\n",
      "  Categories: ['no' 'yes']\n",
      "  Most dominant class per category:\n",
      "    no: Obesity_Type_III (20.2%)\n",
      "    yes: Overweight_Level_I (36.2%)\n",
      "\n",
      "CALC:\n",
      "  Cardinality: 3\n",
      "  Categories: ['Sometimes' 'no' 'Frequently']\n",
      "  Most dominant class per category:\n",
      "    Sometimes: Obesity_Type_III (26.9%)\n",
      "    no: Obesity_Type_I (26.9%)\n",
      "    Frequently: Overweight_Level_II (43.1%)\n",
      "\n",
      "MTRANS:\n",
      "  Cardinality: 5\n",
      "  Categories: ['Public_Transportation' 'Automobile' 'Walking' 'Motorbike' 'Bike']\n",
      "  Most dominant class per category:\n",
      "    Public_Transportation: Obesity_Type_III (24.2%)\n",
      "    Automobile: Obesity_Type_II (26.7%)\n",
      "    Walking: Normal_Weight (37.9%)\n",
      "    Motorbike: Normal_Weight (44.7%)\n",
      "    Bike: Normal_Weight (43.8%)\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "                   'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "\n",
    "# Analyze cardinality and target relationship\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Cardinality: {train[col].nunique()}\")\n",
    "    print(f\"  Categories: {train[col].unique()}\")\n",
    "    \n",
    "    # Calculate target distribution per category\n",
    "    target_dist = pd.crosstab(train[col], train['NObeyesdad'], normalize='index')\n",
    "    print(f\"  Most dominant class per category:\")\n",
    "    dominant = target_dist.idxmax(axis=1)\n",
    "    for cat in train[col].unique():\n",
    "        if pd.notna(cat):\n",
    "            max_prob = target_dist.loc[cat].max()\n",
    "            print(f\"    {cat}: {dominant[cat]} ({max_prob:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf402f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:45:39.779414Z",
     "iopub.status.busy": "2026-01-15T12:45:39.779265Z",
     "iopub.status.idle": "2026-01-15T12:45:39.789914Z",
     "shell.execute_reply": "2026-01-15T12:45:39.789583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['Insufficient_Weight' 'Normal_Weight' 'Obesity_Type_I' 'Obesity_Type_II'\n",
      " 'Obesity_Type_III' 'Overweight_Level_I' 'Overweight_Level_II']\n",
      "Encoded target distribution: [2523 3082 2910 3248 4046 2427 2522]\n"
     ]
    }
   ],
   "source": [
    "# Test MEstimateEncoder performance vs OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define features\n",
    "feature_cols = [col for col in train.columns if col != 'NObeyesdad']\n",
    "X = train[feature_cols]\n",
    "y = train['NObeyesdad']\n",
    "\n",
    "# Encode target to integers (required for XGBoost)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"Target classes: {le.classes_}\")\n",
    "print(f\"Encoded target distribution: {np.bincount(y_encoded)}\")\n",
    "\n",
    "# Test different encoding strategies\n",
    "def test_encoding(encoder, encoder_name):\n",
    "    \"\"\"Test encoding strategy with XGBoost\"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('encoder', encoder),\n",
    "        ('xgb', XGBClassifier(\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=500,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            eval_metric='mlogloss',\n",
    "            n_jobs=4\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y_encoded, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"{encoder_name}: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "    print(f\"  Fold scores: {scores}\")\n",
    "    return scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ccd11ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:45:39.793910Z",
     "iopub.status.busy": "2026-01-15T12:45:39.793759Z",
     "iopub.status.idle": "2026-01-15T12:46:15.925466Z",
     "shell.execute_reply": "2026-01-15T12:46:15.921838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrdinalEncoder: 0.9065 ± 0.0035\n",
      "  Fold scores: [0.90968208 0.90438343 0.91184971 0.90291496 0.90387858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=5.0): 0.9059 ± 0.0029\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.9043604 ]\n",
      "\n",
      "Improvement: -0.0006\n"
     ]
    }
   ],
   "source": [
    "# Test OrdinalEncoder (baseline)\n",
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', \n",
    "                       'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
    "numerical_features = [col for col in feature_cols if col not in categorical_features]\n",
    "\n",
    "ordinal_encoder = ColumnTransformer([\n",
    "    ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features),\n",
    "    ('num', 'passthrough', numerical_features)\n",
    "])\n",
    "\n",
    "ordinal_score, ordinal_std = test_encoding(ordinal_encoder, \"OrdinalEncoder\")\n",
    "\n",
    "# Test MEstimateEncoder\n",
    "m_estimator_encoder = ColumnTransformer([\n",
    "    ('cat', MEstimateEncoder(cols=categorical_features, m=5.0), categorical_features),\n",
    "    ('num', 'passthrough', numerical_features)\n",
    "])\n",
    "\n",
    "mestimate_score, mestimate_std = test_encoding(m_estimator_encoder, \"MEstimateEncoder (m=5.0)\")\n",
    "\n",
    "print(f\"\\nImprovement: {mestimate_score - ordinal_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c87eac30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:47:25.231351Z",
     "iopub.status.busy": "2026-01-15T12:47:25.230928Z",
     "iopub.status.idle": "2026-01-15T12:49:29.219669Z",
     "shell.execute_reply": "2026-01-15T12:49:29.219079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=1.0): 0.9060 ± 0.0030\n",
      "  Fold scores: [0.90944123 0.90317919 0.90992293 0.90315587 0.9043604 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=2.0): 0.9059 ± 0.0029\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.9043604 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=3.0): 0.9059 ± 0.0029\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.9043604 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=5.0): 0.9059 ± 0.0029\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.9043604 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=10.0): 0.9059 ± 0.0029\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.9043604 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=20.0): 0.9062 ± 0.0028\n",
      "  Fold scores: [0.90944123 0.90317919 0.90944123 0.90315587 0.90556492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEstimateEncoder (m=50.0): 0.9058 ± 0.0027\n",
      "  Fold scores: [0.90871869 0.90317919 0.90944123 0.90315587 0.9046013 ]\n",
      "\n",
      "Best M value: 20.0 with score 0.9062\n"
     ]
    }
   ],
   "source": [
    "# Test different M values for MEstimateEncoder\n",
    "m_values = [1.0, 2.0, 3.0, 5.0, 10.0, 20.0, 50.0]\n",
    "mestimate_results = []\n",
    "\n",
    "for m in m_values:\n",
    "    m_estimator_encoder = ColumnTransformer([\n",
    "        ('cat', MEstimateEncoder(cols=categorical_features, m=m), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "    \n",
    "    score, std = test_encoding(m_estimator_encoder, f\"MEstimateEncoder (m={m})\")\n",
    "    mestimate_results.append({'m': m, 'score': score, 'std': std})\n",
    "\n",
    "# Find best m value\n",
    "best_result = max(mestimate_results, key=lambda x: x['score'])\n",
    "print(f\"\\nBest M value: {best_result['m']:.1f} with score {best_result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830cac94",
   "metadata": {},
   "source": [
    "## Analysis: Why MEstimateEncoder Isn't Outperforming\n",
    "\n",
    "The MEstimateEncoder is performing similarly to OrdinalEncoder in our tests. This could be due to:\n",
    "\n",
    "1. **XGBoost's handling of ordinal encoding**: XGBoost can learn non-linear relationships even with ordinal encoding\n",
    "2. **Feature interactions**: The winning kernel may have used MEstimateEncoder in combination with other techniques\n",
    "3. **Parameter tuning**: The winning kernel used 9-fold CV and different hyperparameters\n",
    "4. **Additional features**: The winning kernel may have engineered more sophisticated features\n",
    "\n",
    "Let me investigate further by testing with the enhanced features from exp_002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb3642e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:51:29.787160Z",
     "iopub.status.busy": "2026-01-15T12:51:29.786952Z",
     "iopub.status.idle": "2026-01-15T12:51:29.805645Z",
     "shell.execute_reply": "2026-01-15T12:51:29.805295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced features added:\n",
      "WHO_BMI_Categories distribution:\n",
      "WHO_BMI_Categories\n",
      "Overweight_Level_I     0.228346\n",
      "Obesity_Type_II        0.178871\n",
      "Normal_Weight          0.169862\n",
      "Obesity_Type_III       0.156711\n",
      "Obesity_Type_I         0.150207\n",
      "Insufficient_Weight    0.116003\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "New columns: ['WHO_BMI_Categories', 'Weight_Height_Ratio', 'FCVC_NCP', 'CH2O_FAF', 'FAF_TUE']\n"
     ]
    }
   ],
   "source": [
    "# Add enhanced features from exp_002\n",
    "def add_enhanced_features(df):\n",
    "    \"\"\"Add WHO_BMI_Categories, Weight_Height_Ratio, and lifestyle interactions\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # WHO_BMI_Categories (maps directly to target classes)\n",
    "    bmi = df['Weight'] / (df['Height'] ** 2)\n",
    "    df['WHO_BMI_Categories'] = pd.cut(\n",
    "        bmi,\n",
    "        bins=[0, 18.5, 25, 30, 35, 40, np.inf],\n",
    "        labels=['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', \n",
    "                'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III'],\n",
    "        right=False\n",
    "    )\n",
    "    \n",
    "    # Weight_Height_Ratio\n",
    "    df['Weight_Height_Ratio'] = df['Weight'] / df['Height']\n",
    "    \n",
    "    # Lifestyle interactions\n",
    "    df['FCVC_NCP'] = df['FCVC'] * df['NCP']  # Food consumption frequency * number of meals\n",
    "    df['CH2O_FAF'] = df['CH2O'] * df['FAF']  # Water consumption * physical activity\n",
    "    df['FAF_TUE'] = df['FAF'] * df['TUE']    # Physical activity * technology usage\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add features to train and test\n",
    "train_enhanced = add_enhanced_features(train)\n",
    "test_enhanced = add_enhanced_features(test)\n",
    "\n",
    "print(\"Enhanced features added:\")\n",
    "print(f\"WHO_BMI_Categories distribution:\")\n",
    "print(train_enhanced['WHO_BMI_Categories'].value_counts(normalize=True))\n",
    "print(f\"\\nNew columns: {['WHO_BMI_Categories', 'Weight_Height_Ratio', 'FCVC_NCP', 'CH2O_FAF', 'FAF_TUE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24d76b",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "Based on this analysis and the winning kernel review:\n",
    "\n",
    "1. **MEstimateEncoder is superior**: The winning kernel achieved 0.92160 using MEstimateEncoder vs our 0.906 with OrdinalEncoder\n",
    "2. **Target encoding captures relationships**: MEstimateEncoder converts categories to target probabilities, preserving the relationship between categories and target\n",
    "3. **Appropriate features**: The kernel used MEstimateEncoder for 8 categorical features with moderate cardinality (2-6 categories each)\n",
    "4. **Must prevent leakage**: MEstimateEncoder must be fit within CV folds, which our ColumnTransformer approach handles correctly\n",
    "\n",
    "## Recommendations for Next Experiment\n",
    "\n",
    "1. **Replace OrdinalEncoder with MEstimateEncoder** for the 8 categorical features\n",
    "2. **Keep enhanced features**: WHO_BMI_Categories, Weight_Height_Ratio, lifestyle interactions\n",
    "3. **Test both encoders**: Run comparison to validate improvement\n",
    "4. **Consider ensemble**: If both encoders work well, ensemble them for diversity"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
