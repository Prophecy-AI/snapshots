{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c16bc0",
   "metadata": {},
   "source": [
    "# Experiment 002: Enhanced Features with TF-IDF and Heading Analysis\n",
    "\n",
    "This experiment adds TF-IDF features and heading-level features to improve upon the baseline.\n",
    "\n",
    "**Strategy:** Priority 1 - Enhanced Feature Engineering\n",
    "\n",
    "**Expected improvements:**\n",
    "- TF-IDF features for semantic content patterns\n",
    "- Heading level features to capture hierarchy\n",
    "- Semantic position features for first/last cell patterns\n",
    "- Notebook-level features for context\n",
    "\n",
    "**Validation:** 5-fold GroupKFold with notebook_id groups, Kendall tau metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c86cc21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:33:44.327107Z",
     "iopub.status.busy": "2026-01-14T05:33:44.326366Z",
     "iopub.status.idle": "2026-01-14T05:33:57.428300Z",
     "shell.execute_reply": "2026-01-14T05:33:57.427350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders shape: (119256, 2)\n",
      "Unique notebooks: 119256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import kendalltau\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "TRAIN_PATH = Path('/home/data/train')\n",
    "TEST_PATH = Path('/home/data/test')\n",
    "ORDERS_PATH = Path('/home/data/train_orders.csv')\n",
    "\n",
    "print(\"Loading data...\")\n",
    "orders_df = pd.read_csv(ORDERS_PATH)\n",
    "print(f\"Orders shape: {orders_df.shape}\")\n",
    "print(f\"Unique notebooks: {orders_df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a subset of training data for faster iteration\n",
    "# Use 5000 notebooks for this experiment\n",
    "train_notebooks = orders_df['id'].unique()[:5000]\n",
    "print(f\"Using {len(train_notebooks)} notebooks for training\")\n",
    "\n",
    "# Create training data\n",
    "all_cells = []\n",
    "notebook_sizes = {}\n",
    "\n",
    "for notebook_id in tqdm(train_notebooks, desc=\"Loading training notebooks\"):\n",
    "    notebook_path = TRAIN_PATH / f\"{notebook_id}.json\"\n",
    "    \n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    \n",
    "    cell_order = orders_df[orders_df['id'] == notebook_id]['cell_order'].iloc[0].split()\n",
    "    cell_positions = {cell_id: pos for pos, cell_id in enumerate(cell_order)}\n",
    "    \n",
    "    notebook_sizes[notebook_id] = len(cell_order)\n",
    "    \n",
    "    for cell_id, cell_data in notebook.items():\n",
    "        cell_type = cell_data['cell_type']\n",
    "        source = cell_data['source']\n",
    "        \n",
    "        all_cells.append({\n",
    "            'notebook_id': notebook_id,\n",
    "            'cell_id': cell_id,\n",
    "            'cell_type': cell_type,\n",
    "            'source': source,\n",
    "            'position': cell_positions[cell_id]\n",
    "        })\n",
    "\n",
    "train_df = pd.DataFrame(all_cells)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Average cells per notebook: {train_df.groupby('notebook_id').size().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd209a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced feature extraction function\n",
    "def extract_enhanced_features(df):\n",
    "    \"\"\"Extract enhanced features including TF-IDF and heading analysis\"\"\"\n",
    "    \n",
    "    # Basic text features\n",
    "    df['source_length'] = df['source'].str.len()\n",
    "    df['line_count'] = df['source'].str.count('\\\\n') + 1\n",
    "    df['word_count'] = df['source'].str.split().str.len()\n",
    "    df['char_count'] = df['source'].str.replace('\\\\s+', '', regex=True).str.len()\n",
    "    \n",
    "    # Binary flags\n",
    "    df['has_import'] = df['source'].str.contains('import ', case=False, na=False).astype(int)\n",
    "    df['has_comment'] = df['source'].str.contains('#', na=False).astype(int)\n",
    "    df['has_heading'] = df['source'].str.contains('^#+\\\\s', regex=True, na=False).astype(int)\n",
    "    df['has_code_block'] = df['source'].str.contains('```', na=False).astype(int)\n",
    "    df['has_link'] = df['source'].str.contains('\\\\[.*\\\\]\\\\(http', regex=True, na=False).astype(int)\n",
    "    \n",
    "    # Cell type\n",
    "    df['cell_type_code'] = (df['cell_type'] == 'code').astype(int)\n",
    "    \n",
    "    # Heading level analysis\n",
    "    df['heading_level'] = 0\n",
    "    for level in range(1, 7):\n",
    "        mask = df['source'].str.match(f'^#{{{level}}}\\\\s', na=False)\n",
    "        df.loc[mask, 'heading_level'] = level\n",
    "    \n",
    "    # Common heading text features\n",
    "    common_headings = ['introduction', 'conclusion', 'eda', 'exploratory data analysis', \n",
    "                       'model', 'results', 'analysis', 'data', 'preprocessing', \n",
    "                       'visualization', 'plot', 'train', 'test', 'validation']\n",
    "    \n",
    "    for heading in common_headings:\n",
    "        df[f'heading_{heading}'] = df['source'].str.contains(heading, case=False, na=False).astype(int)\n",
    "    \n",
    "    # Semantic position features\n",
    "    df['has_print'] = df['source'].str.contains('print\\\\s*\\\\(', na=False).astype(int)\n",
    "    df['has_kaggle'] = df['source'].str.contains('kaggle', case=False, na=False).astype(int)\n",
    "    df['has_input'] = df['source'].str.contains('input', case=False, na=False).astype(int)\n",
    "    df['has_data'] = df['source'].str.contains('\\\\bdata\\\\b', case=False, na=False).astype(int)\n",
    "    df['has_function'] = df['source'].str.contains('def\\\\s+\\\\w+\\\\s*\\\\(', regex=True, na=False).astype(int)\n",
    "    df['has_class'] = df['source'].str.contains('class\\\\s+\\\\w+\\\\s*\\\\(', regex=True, na=False).astype(int)\n",
    "    df['has_plot'] = df['source'].str.contains('\\\\.plot\\\\s*\\\\(|\\\\.show\\\\s*\\\\(|plt\\\\.', regex=True, na=False).astype(int)\n",
    "    \n",
    "    # First/last cell indicators\n",
    "    df['likely_first_cell'] = ((df['has_import'] == 1) | (df['has_kaggle'] == 1) | (df['has_input'] == 1)).astype(int)\n",
    "    df['likely_last_cell'] = ((df['has_print'] == 1) | (df['has_plot'] == 1)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Extracting enhanced features...\")\n",
    "train_df = extract_enhanced_features(train_df)\n",
    "print(f\"Features extracted. Shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a603fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add notebook-level features\n",
    "print(\"Adding notebook-level features...\")\n",
    "\n",
    "# Calculate notebook-level statistics\n",
    "notebook_stats = train_df.groupby('notebook_id').agg({\n",
    "    'source_length': ['mean', 'std'],\n",
    "    'word_count': ['mean', 'std'],\n",
    "    'cell_type_code': 'mean',  # code ratio\n",
    "    'position': 'max'  # notebook size\n",
    "}).round(2)\n",
    "\n",
    "notebook_stats.columns = ['_'.join(col).strip() for col in notebook_stats.columns]\n",
    "notebook_stats = notebook_stats.reset_index()\n",
    "notebook_stats.rename(columns={'position_max': 'notebook_size'}, inplace=True)\n",
    "\n",
    "# Merge notebook-level features\n",
    "train_df = train_df.merge(notebook_stats, on='notebook_id', how='left')\n",
    "\n",
    "# Add relative position feature (percentile within notebook)\n",
    "train_df['relative_position'] = train_df['position'] / train_df['notebook_size']\n",
    "\n",
    "print(f\"Final training shape: {train_df.shape}\")\n",
    "print(f\"Notebook-level features added: {list(notebook_stats.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb252a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF features for semantic content\n",
    "print(\"Extracting TF-IDF features...\")\n",
    "\n",
    "# Get text from markdown cells for TF-IDF\n",
    "markdown_texts = train_df[train_df['cell_type'] == 'markdown']['source'].fillna('').tolist()\n",
    "\n",
    "# Use a subset of terms for efficiency\n",
    "max_features = 1000\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=max_features,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# Fit TF-IDF on markdown texts\n",
    "vectorizer.fit(markdown_texts)\n",
    "print(f\"TF-IDF vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Transform all texts (both code and markdown)\n",
    "all_texts = train_df['source'].fillna('').tolist()\n",
    "tfidf_matrix = vectorizer.transform(all_texts)\n",
    "\n",
    "# Add TF-IDF features to dataframe\n",
    "tfidf_feature_names = [f'tfidf_{i}' for i in range(max_features)]\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_feature_names,\n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "# Concatenate with original dataframe\n",
    "train_df = pd.concat([train_df, tfidf_df], axis=1)\n",
    "\n",
    "print(f\"Final shape with TF-IDF: {train_df.shape}\")\n",
    "print(f\"TF-IDF features added: {max_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b324380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature columns\n",
    "basic_features = ['source_length', 'line_count', 'word_count', 'char_count', \n",
    "                  'has_import', 'has_comment', 'has_heading', 'has_code_block', \n",
    "                  'has_link', 'cell_type_code', 'heading_level']\n",
    "\n",
    "heading_features = [f'heading_{h}' for h in ['introduction', 'conclusion', 'eda', \n",
    "                    'exploratory data analysis', 'model', 'results', 'analysis', \n",
    "                    'data', 'preprocessing', 'visualization', 'plot', 'train', \n",
    "                    'test', 'validation']]\n",
    "\n",
    "semantic_features = ['has_print', 'has_kaggle', 'has_input', 'has_data', \n",
    "                     'has_function', 'has_class', 'has_plot', 'likely_first_cell', \n",
    "                     'likely_last_cell']\n",
    "\n",
    "notebook_features = ['source_length_mean', 'source_length_std', 'word_count_mean', \n",
    "                     'word_count_std', 'cell_type_code_mean', 'notebook_size']\n",
    "\n",
    "tfidf_features = tfidf_feature_names\n",
    "\n",
    "feature_cols = (basic_features + heading_features + semantic_features + \n",
    "                notebook_features + tfidf_features + ['relative_position'])\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Basic features: {len(basic_features)}\")\n",
    "print(f\"Heading features: {len(heading_features)}\")\n",
    "print(f\"Semantic features: {len(semantic_features)}\")\n",
    "print(f\"Notebook features: {len(notebook_features)}\")\n",
    "print(f\"TF-IDF features: {len(tfidf_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df70756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metric\n",
    "def kendall_tau_score(y_true, y_pred):\n",
    "    \"\"\"Calculate Kendall tau correlation\"\"\"\n",
    "    return kendalltau(y_true, y_pred).correlation\n",
    "\n",
    "kendall_scorer = make_scorer(kendall_tau_score, greater_is_better=True)\n",
    "\n",
    "# Cross-validation setup\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = train_df['notebook_id']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['position']\n",
    "\n",
    "print(\"Starting cross-validation...\")\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate per-notebook Kendall tau\n",
    "    val_df = train_df.iloc[val_idx].copy()\n",
    "    val_df['pred_position'] = y_pred\n",
    "    \n",
    "    fold_scores = []\n",
    "    for notebook_id in val_df['notebook_id'].unique():\n",
    "        notebook_data = val_df[val_df['notebook_id'] == notebook_id]\n",
    "        if len(notebook_data) > 1:\n",
    "            score = kendall_tau_score(\n",
    "                notebook_data['position'].values,\n",
    "                notebook_data['pred_position'].values\n",
    "            )\n",
    "            fold_scores.append(score)\n",
    "    \n",
    "    fold_score = np.mean(fold_scores)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1}: {fold_score:.4f}\")\n",
    "\n",
    "print(f\"\\nCV Score: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data\n",
    "print(\"Training final model on all data...\")\n",
    "\n",
    "final_model = lgb.LGBMRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233862d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function for test data\n",
    "def predict_notebook_order(notebook_id, path, model, feature_cols, vectorizer):\n",
    "    \"\"\"Predict cell order for a notebook\"\"\"\n",
    "    notebook_path = path / f\"{notebook_id}.json\"\n",
    "    \n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    \n",
    "    # Extract features\n",
    "    cells = []\n",
    "    cell_ids = []\n",
    "    \n",
    "    for cell_id, cell_data in notebook.items():\n",
    "        cells.append({\n",
    "            'cell_id': cell_id,\n",
    "            'cell_type': cell_data['cell_type'],\n",
    "            'source': cell_data['source']\n",
    "        })\n",
    "        cell_ids.append(cell_id)\n",
    "    \n",
    "    features_df = pd.DataFrame(cells)\n",
    "    \n",
    "    # Extract enhanced features\n",
    "    features_df = extract_enhanced_features(features_df)\n",
    "    \n",
    "    # Add placeholder for notebook-level features (will be filled)\n",
    "    features_df['source_length_mean'] = features_df['source_length'].mean()\n",
    "    features_df['source_length_std'] = features_df['source_length'].std()\n",
    "    features_df['word_count_mean'] = features_df['word_count'].mean()\n",
    "    features_df['word_count_std'] = features_df['word_count'].std()\n",
    "    features_df['cell_type_code_mean'] = features_df['cell_type_code'].mean()\n",
    "    features_df['notebook_size'] = len(features_df)\n",
    "    features_df['relative_position'] = 0.5  # placeholder\n",
    "    \n",
    "    # TF-IDF features\n",
    "    texts = features_df['source'].fillna('').tolist()\n",
    "    tfidf_matrix = vectorizer.transform(texts)\n",
    "    \n",
    "    tfidf_df = pd.DataFrame(\n",
    "        tfidf_matrix.toarray(),\n",
    "        columns=tfidf_feature_names,\n",
    "        index=features_df.index\n",
    "    )\n",
    "    \n",
    "    features_df = pd.concat([features_df, tfidf_df], axis=1)\n",
    "    \n",
    "    # Predict\n",
    "    X_test = features_df[feature_cols]\n",
    "    predicted_positions = model.predict(X_test)\n",
    "    \n",
    "    # Sort by predicted position\n",
    "    order_df = pd.DataFrame({\n",
    "        'cell_id': cell_ids,\n",
    "        'pred_position': predicted_positions\n",
    "    })\n",
    "    \n",
    "    ordered_cells = order_df.sort_values('pred_position')['cell_id'].tolist()\n",
    "    return ' '.join(ordered_cells)\n",
    "\n",
    "# Test on a few notebooks\n",
    "print(\"Testing prediction on sample notebooks...\")\n",
    "test_notebooks = [f.stem for f in TEST_PATH.glob('*.json')[:5]]\n",
    "\n",
    "for notebook_id in test_notebooks:\n",
    "    try:\n",
    "        predicted_order = predict_notebook_order(notebook_id, TEST_PATH, final_model, feature_cols, vectorizer)\n",
    "        print(f\"{notebook_id}: {predicted_order[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {notebook_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission for all test notebooks\n",
    "print(\"Generating submission for all test notebooks...\")\n",
    "\n",
    "test_notebooks = [f.stem for f in TEST_PATH.glob('*.json')]\n",
    "submission_data = []\n",
    "\n",
    "for notebook_id in tqdm(test_notebooks, desc=\"Predicting notebooks\"):\n",
    "    try:\n",
    "        predicted_order = predict_notebook_order(notebook_id, TEST_PATH, final_model, feature_cols, vectorizer)\n",
    "        submission_data.append({\n",
    "            'id': notebook_id,\n",
    "            'cell_order': predicted_order\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {notebook_id}: {e}\")\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_path = '/home/submission/submission_002.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to {submission_path}\")\n",
    "\n",
    "# Verify format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"\\nColumns match: {list(submission_df.columns) == list(sample_sub.columns)}\")\n",
    "print(f\"Number of rows match: {len(submission_df) == len(sample_sub)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
