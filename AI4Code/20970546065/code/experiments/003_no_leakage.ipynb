{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855ca65c",
   "metadata": {},
   "source": [
    "# Experiment 003: Remove Data Leakage\n",
    "\n",
    "**Objective:** Remove the data leakage from 'relative_position' feature and measure true model performance.\n",
    "\n",
    "**Issue identified:** In exp_002, 'relative_position' = position / notebook_size, where 'position' is the target variable. This is data leakage.\n",
    "\n",
    "**Changes:**\n",
    "- Remove 'relative_position' feature from training\n",
    "- Keep all other features (TF-IDF, headings, notebook-level stats)\n",
    "- Use same 5-fold GroupKFold validation\n",
    "\n",
    "**Expected outcome:** CV score will drop significantly, revealing true model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import kendalltau\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "TRAIN_PATH = Path('/home/data/train')\n",
    "TEST_PATH = Path('/home/data/test')\n",
    "ORDERS_PATH = Path('/home/data/train_orders.csv')\n",
    "\n",
    "print(\"Loading data...\")\n",
    "orders_df = pd.read_csv(ORDERS_PATH)\n",
    "print(f\"Orders shape: {orders_df.shape}\")\n",
    "print(f\"Unique notebooks: {orders_df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a subset of training data for faster iteration\n",
    "# Using 5,000 notebooks like exp_002\n",
    "np.random.seed(42)\n",
    "all_notebooks = orders_df['id'].unique()\n",
    "selected_notebooks = np.random.choice(all_notebooks, size=5000, replace=False)\n",
    "\n",
    "print(f\"Selected {len(selected_notebooks)} notebooks for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e50937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def extract_basic_features(df):\n",
    "    \"\"\"Extract basic text statistics\"\"\"\n",
    "    df['source_length'] = df['source'].str.len()\n",
    "    df['line_count'] = df['source'].str.count('\\\\n') + 1\n",
    "    df['word_count'] = df['source'].str.split().str.len()\n",
    "    df['char_count'] = df['source'].str.len()\n",
    "    \n",
    "    # Binary flags\n",
    "    df['has_import'] = df['source'].str.contains('import\\\\s+\\\\w+', regex=True, na=False).astype(int)\n",
    "    df['has_comment'] = df['source'].str.contains('#', na=False).astype(int)\n",
    "    df['has_heading'] = df['source'].str.contains('^#+\\\\s+', regex=True, na=False).astype(int)\n",
    "    df['has_code_block'] = df['source'].str.contains('```', na=False).astype(int)\n",
    "    df['has_link'] = df['source'].str.contains('\\\\[.*\\\\]\\\\(.*\\\\)', regex=True, na=False).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_heading_features(df):\n",
    "    \"\"\"Extract heading-related features\"\"\"\n",
    "    # Extract heading level (1-6)\n",
    "    df['heading_level'] = 0\n",
    "    for level in range(1, 7):\n",
    "        mask = df['source'].str.match(f'^#{{{level}}}\\\\s+', na=False)\n",
    "        df.loc[mask, 'heading_level'] = level\n",
    "    \n",
    "    # Binary flags for common heading texts\n",
    "    common_headings = ['introduction', 'conclusion', 'summary', 'results', 'methods', \n",
    "                       'analysis', 'eda', 'exploratory', 'data', 'preprocessing',\n",
    "                       'model', 'training', 'evaluation', 'references', 'appendix',\n",
    "                       'setup', 'imports', 'installation', 'requirements',\n",
    "                       'visualization', 'plot', 'train', 'test', 'validation']\n",
    "    \n",
    "    for heading in common_headings:\n",
    "        df[f'heading_{heading}'] = df['source'].str.contains(heading, case=False, na=False).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_semantic_features(df):\n",
    "    \"\"\"Extract semantic position features\"\"\"\n",
    "    df['has_print'] = df['source'].str.contains('print\\\\s*\\\\(', na=False).astype(int)\n",
    "    df['has_kaggle'] = df['source'].str.contains('kaggle', case=False, na=False).astype(int)\n",
    "    df['has_input'] = df['source'].str.contains('input', case=False, na=False).astype(int)\n",
    "    df['has_data'] = df['source'].str.contains('\\\\bdata\\\\b', case=False, na=False).astype(int)\n",
    "    df['has_function'] = df['source'].str.contains('def\\\\s+\\\\w+\\\\s*\\\\(', regex=True, na=False).astype(int)\n",
    "    df['has_class'] = df['source'].str.contains('class\\\\s+\\\\w+', regex=True, na=False).astype(int)\n",
    "    df['has_model'] = df['source'].str.contains('\\\\bmodel\\\\b', case=False, na=False).astype(int)\n",
    "    df['has_train'] = df['source'].str.contains('\\\\btrain\\\\b', case=False, na=False).astype(int)\n",
    "    df['has_test'] = df['source'].str.contains('\\\\btest\\\\b', case=False, na=False).astype(int)\n",
    "    df['has_plot'] = df['source'].str.contains('\\\\.plot\\\\s*\\\\(|\\\\.show\\\\s*\\\\(', regex=True, na=False).astype(int)\n",
    "    df['has_import'] = df['source'].str.contains('^\\\\s*import\\\\s+|^\\\\s*from\\\\s+', regex=True, na=False).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71186bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process training data\n",
    "print(\"Loading training notebooks...\")\n",
    "train_data = []\n",
    "notebook_sizes = {}\n",
    "\n",
    "for notebook_id in tqdm(selected_notebooks, desc=\"Processing notebooks\"):\n",
    "    notebook_path = TRAIN_PATH / f\"{notebook_id}.json\"\n",
    "    \n",
    "    if not notebook_path.exists():\n",
    "        continue\n",
    "    \n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    \n",
    "    cell_order = orders_df[orders_df['id'] == notebook_id]['cell_order'].iloc[0].split()\n",
    "    cell_positions = {cell_id: pos for pos, cell_id in enumerate(cell_order)}\n",
    "    \n",
    "    notebook_sizes[notebook_id] = len(cell_order)\n",
    "    \n",
    "    # The notebook structure has cell_type and source as separate dictionaries\n",
    "    cell_types = notebook['cell_type']\n",
    "    sources = notebook['source']\n",
    "    \n",
    "    for cell_id in cell_order:\n",
    "        cell_type = 1 if cell_types[cell_id] == 'code' else 0\n",
    "        source = sources[cell_id]\n",
    "        \n",
    "        train_data.append({\n",
    "            'notebook_id': notebook_id,\n",
    "            'cell_id': cell_id,\n",
    "            'cell_type': cell_type,\n",
    "            'source': source,\n",
    "            'position': cell_positions[cell_id]\n",
    "        })\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Average cells per notebook: {train_df.groupby('notebook_id').size().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "print(\"Extracting features...\")\n",
    "train_df = extract_basic_features(train_df)\n",
    "train_df = extract_heading_features(train_df)\n",
    "train_df = extract_semantic_features(train_df)\n",
    "\n",
    "# Calculate notebook-level statistics (WITHOUT relative_position to avoid leakage)\n",
    "notebook_stats = train_df.groupby('notebook_id').agg({\n",
    "    'source_length': ['mean', 'std'],\n",
    "    'word_count': ['mean', 'std'],\n",
    "    'cell_type_code': 'mean',  # code ratio\n",
    "    'position': 'max'  # notebook size\n",
    "}).round(2)\n",
    "\n",
    "notebook_stats.columns = ['_'.join(col).strip() for col in notebook_stats.columns]\n",
    "notebook_stats = notebook_stats.reset_index()\n",
    "notebook_stats.rename(columns={'position_max': 'notebook_size'}, inplace=True)\n",
    "\n",
    "# Merge notebook-level features\n",
    "train_df = train_df.merge(notebook_stats, on='notebook_id', how='left')\n",
    "\n",
    "# NOTE: DELIBERATELY NOT adding relative_position to avoid data leakage\n",
    "# train_df['relative_position'] = train_df['position'] / train_df['notebook_size']\n",
    "\n",
    "print(f\"Final training shape: {train_df.shape}\")\n",
    "print(f\"Notebook-level features added: {list(notebook_stats.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare TF-IDF features\n",
    "print(\"Preparing TF-IDF features...\")\n",
    "# Get all markdown cells for TF-IDF\n",
    "markdown_cells = train_df[train_df['cell_type'] == 0]['source'].fillna('').tolist()\n",
    "\n",
    "# Fit TF-IDF vectorizer on markdown content\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "vectorizer.fit(markdown_cells)\n",
    "tfidf_feature_names = [f'tfidf_{i}' for i in range(len(vectorizer.get_feature_names_out()))]\n",
    "\n",
    "print(f\"TF-IDF features created: {len(tfidf_feature_names)}\")\n",
    "\n",
    "# Transform all cells (both code and markdown)\n",
    "all_texts = train_df['source'].fillna('').tolist()\n",
    "tfidf_matrix = vectorizer.transform(all_texts)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_feature_names)\n",
    "\n",
    "# Concatenate with main dataframe\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), tfidf_df], axis=1)\n",
    "print(f\"Final shape with TF-IDF: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (WITHOUT relative_position)\n",
    "basic_features = ['source_length', 'line_count', 'word_count', 'char_count',\n",
    "                  'has_import', 'has_comment', 'has_heading', 'has_code_block', 'has_link']\n",
    "\n",
    "heading_features = ['heading_level'] + [f'heading_{h}' for h in ['introduction', 'conclusion', 'summary', 'results', 'methods', \n",
    "                       'analysis', 'eda', 'exploratory', 'data', 'preprocessing',\n",
    "                       'model', 'training', 'evaluation', 'references', 'appendix',\n",
    "                       'setup', 'imports', 'installation', 'requirements',\n",
    "                       'visualization', 'plot', 'train', 'test', 'validation']]\n",
    "\n",
    "semantic_features = ['has_print', 'has_kaggle', 'has_input', 'has_data', 'has_function',\n",
    "                     'has_class', 'has_model', 'has_train', 'has_test', 'has_plot', 'has_import']\n",
    "\n",
    "notebook_features = ['source_length_mean', 'source_length_std', 'word_count_mean', \n",
    "                     'word_count_std', 'cell_type_code_mean', 'notebook_size']\n",
    "\n",
    "tfidf_features = tfidf_feature_names\n",
    "\n",
    "# NOTE: relative_position is DELIBERATELY excluded to avoid data leakage\n",
    "feature_cols = (basic_features + heading_features + semantic_features + \n",
    "                notebook_features + tfidf_features)\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Basic features: {len(basic_features)}\")\n",
    "print(f\"Heading features: {len(heading_features)}\")\n",
    "print(f\"Semantic features: {len(semantic_features)}\")\n",
    "print(f\"Notebook features: {len(notebook_features)}\")\n",
    "print(f\"TF-IDF features: {len(tfidf_features)}\")\n",
    "print(f\"\\nIMPORTANT: relative_position feature EXCLUDED to avoid data leakage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebedadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "def kendall_tau_score(y_true, y_pred):\n",
    "    \"\"\"Calculate Kendall tau correlation\"\"\"\n",
    "    return kendalltau(y_true, y_pred)[0]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = train_df['notebook_id']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['position']\n",
    "\n",
    "print(\"Starting cross-validation...\")\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate per-notebook Kendall tau\n",
    "    val_df = train_df.iloc[val_idx].copy()\n",
    "    val_df['pred_position'] = y_pred\n",
    "    \n",
    "    fold_scores = []\n",
    "    for notebook_id in val_df['notebook_id'].unique():\n",
    "        notebook_data = val_df[val_df['notebook_id'] == notebook_id]\n",
    "        if len(notebook_data) > 1:\n",
    "            score = kendall_tau_score(\n",
    "                notebook_data['position'].values,\n",
    "                notebook_data['pred_position'].values\n",
    "            )\n",
    "            fold_scores.append(score)\n",
    "    \n",
    "    fold_score = np.mean(fold_scores)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1}: {fold_score:.4f}\")\n",
    "\n",
    "print(f\"\\nCV Score: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d14b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data\n",
    "print(\"Training final model on all training data...\")\n",
    "final_model = lgb.LGBMRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test set\n",
    "print(\"Generating predictions for test set...\")\n",
    "test_notebooks = list(TEST_PATH.glob('*.json'))\n",
    "print(f\"Total test notebooks: {len(test_notebooks)}\")\n",
    "\n",
    "def predict_notebook_order(notebook_path, model, vectorizer, feature_cols):\n",
    "    \"\"\"Predict cell order for a single notebook\"\"\"\n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    \n",
    "    notebook_id = notebook_path.stem\n",
    "    cell_types = notebook['cell_type']\n",
    "    sources = notebook['source']\n",
    "    cell_ids = list(cell_types.keys())\n",
    "    \n",
    "    # Create features dataframe\n",
    "    features_df = pd.DataFrame({\n",
    "        'cell_id': cell_ids,\n",
    "        'cell_type': [1 if cell_types[cid] == 'code' else 0 for cid in cell_ids],\n",
    "        'source': [sources[cid] for cid in cell_ids]\n",
    "    })\n",
    "    \n",
    "    # Extract features\n",
    "    features_df = extract_basic_features(features_df)\n",
    "    features_df = extract_heading_features(features_df)\n",
    "    features_df = extract_semantic_features(features_df)\n",
    "    \n",
    "    # Calculate notebook-level statistics (same as training)\n",
    "    features_df['source_length_mean'] = features_df['source_length'].mean()\n",
    "    features_df['source_length_std'] = features_df['source_length'].std()\n",
    "    features_df['word_count_mean'] = features_df['word_count'].mean()\n",
    "    features_df['word_count_std'] = features_df['word_count'].std()\n",
    "    features_df['cell_type_code_mean'] = features_df['cell_type_code'].mean()\n",
    "    features_df['notebook_size'] = len(features_df)\n",
    "    \n",
    "    # NOTE: NO relative_position feature (avoiding leakage)\n",
    "    # features_df['relative_position'] = 0.5  # placeholder\n",
    "    \n",
    "    # Transform TF-IDF features\n",
    "    all_texts = features_df['source'].fillna('').tolist()\n",
    "    tfidf_matrix = vectorizer.transform(all_texts)\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_feature_names)\n",
    "    \n",
    "    features_df = pd.concat([features_df.reset_index(drop=True), tfidf_df], axis=1)\n",
    "    \n",
    "    # Ensure all feature columns exist\n",
    "    for col in feature_cols:\n",
    "        if col not in features_df.columns:\n",
    "            features_df[col] = 0\n",
    "    \n",
    "    # Predict positions\n",
    "    X_test = features_df[feature_cols]\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Sort by predicted position\n",
    "    features_df['predicted_position'] = predictions\n",
    "    features_df = features_df.sort_values('predicted_position')\n",
    "    \n",
    "    # Return ordered cell IDs as space-separated string\n",
    "    ordered_cells = features_df['cell_id'].tolist()\n",
    "    return ' '.join(ordered_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all test notebooks\n",
    "submission_data = []\n",
    "\n",
    "for notebook_path in tqdm(test_notebooks, desc=\"Predicting test notebooks\"):\n",
    "    try:\n",
    "        notebook_id = notebook_path.stem\n",
    "        ordered_cells = predict_notebook_order(notebook_path, final_model, vectorizer, feature_cols)\n",
    "        \n",
    "        submission_data.append({\n",
    "            'id': notebook_id,\n",
    "            'cell_order': ordered_cells\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {notebook_id}: {e}\")\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_path = '/home/submission/submission_003.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to {submission_path}\")\n",
    "\n",
    "# Verify format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"\\nColumns match: {list(submission_df.columns) == list(sample_sub.columns)}\")\n",
    "print(f\"Number of rows match: {len(submission_df) == len(sample_sub)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
