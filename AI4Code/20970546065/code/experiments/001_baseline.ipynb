{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f818b5",
   "metadata": {},
   "source": [
    "# AI4Code Baseline Model\n",
    "\n",
    "This notebook implements a baseline solution for the AI4Code competition.\n",
    "\n",
    "## Approach\n",
    "1. Extract basic features from cells (length, type, etc.)\n",
    "2. Train a model to predict cell ordering\n",
    "3. Use Kendall tau correlation as evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a04b751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:12:28.535078Z",
     "iopub.status.busy": "2026-01-14T01:12:28.534434Z",
     "iopub.status.idle": "2026-01-14T01:12:30.467215Z",
     "shell.execute_reply": "2026-01-14T01:12:30.466484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data paths...\n",
      "Train path: /home/data/train\n",
      "Test path: /home/data/test\n",
      "Train orders: /home/data/train_orders.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = Path('/home/data')\n",
    "TRAIN_PATH = DATA_PATH / 'train'\n",
    "TEST_PATH = DATA_PATH / 'test'\n",
    "TRAIN_ORDERS_PATH = DATA_PATH / 'train_orders.csv'\n",
    "\n",
    "print(\"Loading data paths...\")\n",
    "print(f\"Train path: {TRAIN_PATH}\")\n",
    "print(f\"Test path: {TEST_PATH}\")\n",
    "print(f\"Train orders: {TRAIN_ORDERS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8a7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:12:30.472548Z",
     "iopub.status.busy": "2026-01-14T01:12:30.471824Z",
     "iopub.status.idle": "2026-01-14T01:12:31.240952Z",
     "shell.execute_reply": "2026-01-14T01:12:31.240152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train orders shape: (119256, 2)\n",
      "First few rows:\n",
      "               id                                         cell_order\n",
      "0  00001756c60be8  1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 7...\n",
      "1  0001daf4c2c76d  97266564 a898e555 86605076 76cc2642 ef279279 d...\n",
      "2  0002115f48f982  9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a...\n",
      "3  00035108e64677  3496fbfe 2fa1f27b 719854c4 f3c2de19 d75feb42 5...\n",
      "4  00038c2941faa0  3e551fb7 45049ad8 8bb41691 123b4f4c 0b92cb59 5...\n"
     ]
    }
   ],
   "source": [
    "# Load train orders\n",
    "train_orders = pd.read_csv(TRAIN_ORDERS_PATH)\n",
    "print(f\"Train orders shape: {train_orders.shape}\")\n",
    "print(f\"First few rows:\")\n",
    "print(train_orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237f8257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:16:37.849018Z",
     "iopub.status.busy": "2026-01-14T01:16:37.848149Z",
     "iopub.status.idle": "2026-01-14T01:16:37.856500Z",
     "shell.execute_reply": "2026-01-14T01:16:37.855711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook keys: ['cell_type', 'source']\n",
      "\n",
      "Cell types: [('18281c6c', 'code'), ('e3b6b115', 'code'), ('4a044c54', 'code'), ('365fe576', 'code'), ('a3188e54', 'code')]\n",
      "\n",
      "Sample code cell: ('18281c6c', 'import numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline\\nimport os\\nprint(os.listdir(\"../input\"))\\n')\n",
      "\n",
      "Sample markdown cell: ('9ec225f0', 'Hi there,\\n\\nIs it ok that the same measurement have different target labels between signals?\\nAccording to data description it should be the same (or not really?) . There are 38 cases of measurements with not consistent labels between signals.\\n\\nQuick and dirty code to show the problem below:')\n"
     ]
    }
   ],
   "source": [
    "# Load a sample notebook to understand structure\n",
    "def load_notebook(notebook_id, path):\n",
    "    \"\"\"Load a notebook from JSON file\"\"\"\n",
    "    with open(path / f\"{notebook_id}.json\", 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    return notebook\n",
    "\n",
    "# Load sample notebook\n",
    "sample_nb = load_notebook('0002115f48f982', TRAIN_PATH)\n",
    "print(\"Notebook keys:\", list(sample_nb.keys()))\n",
    "print(\"\\nCell types:\", list(sample_nb['cell_type'].items())[:5])\n",
    "print(\"\\nSample code cell:\", list(sample_nb['source'].items())[0])\n",
    "print(\"\\nSample markdown cell:\", list(sample_nb['source'].items())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac59f42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:16:37.859208Z",
     "iopub.status.busy": "2026-01-14T01:16:37.858610Z",
     "iopub.status.idle": "2026-01-14T01:16:37.877504Z",
     "shell.execute_reply": "2026-01-14T01:16:37.876648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features shape: (9, 12)\n",
      "      notebook_id   cell_id cell_type  source_length  line_count  word_count  \\\n",
      "0  0002115f48f982  18281c6c      code            220           8          32   \n",
      "1  0002115f48f982  e3b6b115      code             57           2           4   \n",
      "2  0002115f48f982  4a044c54      code              9           1           1   \n",
      "3  0002115f48f982  365fe576      code            164           3          15   \n",
      "4  0002115f48f982  a3188e54      code            119           2          18   \n",
      "\n",
      "   char_count  has_import  has_comment  has_heading  has_code_block  has_link  \n",
      "0         188           1            1            0               0         0  \n",
      "1          54           0            0            0               0         0  \n",
      "2           9           0            0            0               0         0  \n",
      "3         150           0            1            0               0         0  \n",
      "4         101           0            1            0               0         0  \n"
     ]
    }
   ],
   "source": [
    "# Create features for a notebook\n",
    "def extract_features(notebook_id, path):\n",
    "    \"\"\"Extract features from a notebook\"\"\"\n",
    "    notebook = load_notebook(notebook_id, path)\n",
    "    \n",
    "    features = []\n",
    "    cell_ids = []\n",
    "    \n",
    "    for cell_id, cell_type in notebook['cell_type'].items():\n",
    "        source = notebook['source'][cell_id]\n",
    "        \n",
    "        # Basic features\n",
    "        feature_dict = {\n",
    "            'notebook_id': notebook_id,\n",
    "            'cell_id': cell_id,\n",
    "            'cell_type': cell_type,\n",
    "            'source_length': len(source),\n",
    "            'line_count': source.count('\\n') + 1,\n",
    "            'word_count': len(source.split()),\n",
    "            'char_count': len(source.replace('\\n', '').replace(' ', '')),\n",
    "            'has_import': int('import ' in source or 'from ' in source) if cell_type == 'code' else 0,\n",
    "            'has_comment': int('#' in source) if cell_type == 'code' else 0,\n",
    "            'has_heading': int(any(heading in source for heading in ['# ', '## ', '### '])) if cell_type == 'markdown' else 0,\n",
    "            'has_code_block': int('```' in source) if cell_type == 'markdown' else 0,\n",
    "            'has_link': int('http' in source or 'www.' in source) if cell_type == 'markdown' else 0,\n",
    "        }\n",
    "        \n",
    "        features.append(feature_dict)\n",
    "        cell_ids.append(cell_id)\n",
    "    \n",
    "    return pd.DataFrame(features), cell_ids\n",
    "\n",
    "# Test feature extraction\n",
    "sample_features, sample_cell_ids = extract_features('0002115f48f982', TRAIN_PATH)\n",
    "print(\"Sample features shape:\", sample_features.shape)\n",
    "print(sample_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c042bab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T01:16:37.880522Z",
     "iopub.status.busy": "2026-01-14T01:16:37.879918Z",
     "iopub.status.idle": "2026-01-14T01:16:49.834142Z",
     "shell.execute_reply": "2026-01-14T01:16:49.833532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   1%|          | 8/1000 [00:00<00:13, 74.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   2%|▏         | 16/1000 [00:00<00:13, 73.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   2%|▏         | 24/1000 [00:00<00:13, 73.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   3%|▎         | 32/1000 [00:00<00:12, 75.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   4%|▍         | 41/1000 [00:00<00:12, 78.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   5%|▌         | 50/1000 [00:00<00:11, 80.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   6%|▌         | 59/1000 [00:00<00:11, 82.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   7%|▋         | 68/1000 [00:00<00:11, 83.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   8%|▊         | 77/1000 [00:00<00:10, 84.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:   9%|▊         | 86/1000 [00:01<00:10, 85.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  10%|▉         | 95/1000 [00:01<00:10, 83.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  10%|█         | 104/1000 [00:01<00:10, 82.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  11%|█▏        | 113/1000 [00:01<00:10, 83.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  12%|█▏        | 122/1000 [00:01<00:10, 83.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  13%|█▎        | 131/1000 [00:01<00:10, 82.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  14%|█▍        | 140/1000 [00:01<00:10, 81.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  15%|█▍        | 149/1000 [00:01<00:10, 81.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  16%|█▌        | 158/1000 [00:01<00:10, 81.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  17%|█▋        | 167/1000 [00:02<00:10, 82.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  18%|█▊        | 176/1000 [00:02<00:10, 81.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  18%|█▊        | 185/1000 [00:02<00:10, 79.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  19%|█▉        | 193/1000 [00:02<00:10, 78.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  20%|██        | 201/1000 [00:02<00:10, 78.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  21%|██        | 210/1000 [00:02<00:09, 80.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  22%|██▏       | 219/1000 [00:02<00:09, 81.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  23%|██▎       | 228/1000 [00:02<00:09, 82.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  24%|██▎       | 237/1000 [00:02<00:09, 84.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  25%|██▍       | 246/1000 [00:03<00:08, 84.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  26%|██▌       | 255/1000 [00:03<00:08, 84.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  26%|██▋       | 264/1000 [00:03<00:08, 84.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  27%|██▋       | 273/1000 [00:03<00:08, 85.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  28%|██▊       | 282/1000 [00:03<00:08, 83.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  29%|██▉       | 291/1000 [00:03<00:08, 81.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  30%|███       | 300/1000 [00:03<00:08, 79.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  31%|███       | 309/1000 [00:03<00:08, 80.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  32%|███▏      | 318/1000 [00:03<00:08, 81.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  33%|███▎      | 327/1000 [00:04<00:08, 82.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  34%|███▎      | 336/1000 [00:04<00:07, 83.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  34%|███▍      | 345/1000 [00:04<00:07, 85.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  35%|███▌      | 354/1000 [00:04<00:07, 83.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  36%|███▋      | 363/1000 [00:04<00:07, 83.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  37%|███▋      | 373/1000 [00:04<00:07, 85.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  38%|███▊      | 383/1000 [00:04<00:07, 87.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  39%|███▉      | 392/1000 [00:04<00:06, 87.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  40%|████      | 401/1000 [00:04<00:06, 87.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  41%|████      | 411/1000 [00:04<00:06, 89.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  42%|████▏     | 420/1000 [00:05<00:06, 87.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  43%|████▎     | 429/1000 [00:05<00:06, 87.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  44%|████▍     | 438/1000 [00:05<00:06, 86.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  45%|████▍     | 447/1000 [00:05<00:06, 85.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  46%|████▌     | 456/1000 [00:05<00:06, 86.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  46%|████▋     | 465/1000 [00:05<00:06, 84.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  47%|████▋     | 474/1000 [00:05<00:06, 83.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  48%|████▊     | 483/1000 [00:05<00:06, 83.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  49%|████▉     | 492/1000 [00:05<00:06, 81.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  50%|█████     | 501/1000 [00:06<00:06, 80.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  51%|█████     | 510/1000 [00:06<00:06, 79.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  52%|█████▏    | 518/1000 [00:06<00:06, 79.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  53%|█████▎    | 526/1000 [00:06<00:06, 78.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  53%|█████▎    | 534/1000 [00:06<00:05, 78.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  54%|█████▍    | 542/1000 [00:06<00:07, 62.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  55%|█████▌    | 552/1000 [00:06<00:06, 70.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  56%|█████▌    | 562/1000 [00:06<00:05, 76.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  57%|█████▋    | 572/1000 [00:06<00:05, 80.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  58%|█████▊    | 582/1000 [00:07<00:05, 83.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  59%|█████▉    | 591/1000 [00:07<00:04, 84.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  60%|██████    | 600/1000 [00:07<00:04, 85.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  61%|██████    | 610/1000 [00:07<00:04, 87.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  62%|██████▏   | 620/1000 [00:07<00:04, 88.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  63%|██████▎   | 629/1000 [00:07<00:04, 88.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  64%|██████▍   | 638/1000 [00:07<00:04, 87.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  65%|██████▍   | 647/1000 [00:07<00:04, 87.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  66%|██████▌   | 656/1000 [00:07<00:03, 87.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  66%|██████▋   | 665/1000 [00:08<00:03, 87.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  67%|██████▋   | 674/1000 [00:08<00:03, 87.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  68%|██████▊   | 683/1000 [00:08<00:03, 85.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  69%|██████▉   | 692/1000 [00:08<00:03, 83.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  70%|███████   | 701/1000 [00:08<00:03, 83.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  71%|███████   | 711/1000 [00:08<00:03, 87.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  72%|███████▏  | 721/1000 [00:08<00:03, 88.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  73%|███████▎  | 731/1000 [00:08<00:02, 90.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  74%|███████▍  | 741/1000 [00:08<00:02, 91.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  75%|███████▌  | 751/1000 [00:09<00:02, 92.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  76%|███████▌  | 761/1000 [00:09<00:02, 93.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  77%|███████▋  | 771/1000 [00:09<00:02, 94.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  78%|███████▊  | 781/1000 [00:09<00:02, 91.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  79%|███████▉  | 791/1000 [00:09<00:02, 92.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  80%|████████  | 801/1000 [00:09<00:02, 92.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  81%|████████  | 811/1000 [00:09<00:02, 92.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  82%|████████▏ | 821/1000 [00:09<00:02, 89.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  83%|████████▎ | 830/1000 [00:09<00:01, 88.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  84%|████████▍ | 839/1000 [00:09<00:01, 88.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  85%|████████▍ | 848/1000 [00:10<00:01, 86.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  86%|████████▌ | 857/1000 [00:10<00:01, 86.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  87%|████████▋ | 866/1000 [00:10<00:01, 84.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  88%|████████▊ | 875/1000 [00:10<00:01, 84.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  88%|████████▊ | 884/1000 [00:10<00:01, 80.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  89%|████████▉ | 893/1000 [00:10<00:01, 79.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  90%|█████████ | 902/1000 [00:10<00:01, 79.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  91%|█████████ | 911/1000 [00:10<00:01, 80.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  92%|█████████▏| 920/1000 [00:10<00:00, 81.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  93%|█████████▎| 929/1000 [00:11<00:00, 82.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  94%|█████████▍| 938/1000 [00:11<00:00, 82.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  95%|█████████▍| 948/1000 [00:11<00:00, 85.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  96%|█████████▌| 958/1000 [00:11<00:00, 87.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  97%|█████████▋| 968/1000 [00:11<00:00, 88.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  98%|█████████▊| 978/1000 [00:11<00:00, 90.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks:  99%|█████████▉| 988/1000 [00:11<00:00, 90.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks: 100%|█████████▉| 998/1000 [00:11<00:00, 89.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing notebooks: 100%|██████████| 1000/1000 [00:11<00:00, 84.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (46232, 13)\n",
      "      notebook_id   cell_id cell_type  source_length  line_count  word_count  \\\n",
      "0  00001756c60be8  1862f0a6      code            930          17         140   \n",
      "1  00001756c60be8  2a9e43d6      code            498          17          55   \n",
      "2  00001756c60be8  038b763d      code             49           2           3   \n",
      "3  00001756c60be8  2eefe0ef      code             45           1           2   \n",
      "4  00001756c60be8  0beab1cd      code            694          19          39   \n",
      "\n",
      "   char_count  has_import  has_comment  has_heading  has_code_block  has_link  \\\n",
      "0         774           1            1            0               0         0   \n",
      "1         441           1            0            0               0         0   \n",
      "2          47           1            0            0               0         0   \n",
      "3          44           0            0            0               0         0   \n",
      "4         584           0            0            0               0         0   \n",
      "\n",
      "   position  \n",
      "0         0  \n",
      "1         2  \n",
      "2         4  \n",
      "3         6  \n",
      "4         8  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "def create_training_data(notebook_ids, path, orders_df):\n",
    "    \"\"\"Create training dataset with features and target positions\"\"\"\n",
    "    all_features = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for notebook_id in tqdm(notebook_ids, desc=\"Processing notebooks\"):\n",
    "        # Extract features\n",
    "        features, cell_ids = extract_features(notebook_id, path)\n",
    "        \n",
    "        # Get correct order\n",
    "        correct_order = orders_df[orders_df['id'] == notebook_id]['cell_order'].iloc[0].split()\n",
    "        \n",
    "        # Create position mapping\n",
    "        position_map = {cell_id: pos for pos, cell_id in enumerate(correct_order)}\n",
    "        \n",
    "        # Add target position\n",
    "        features['position'] = features['cell_id'].map(position_map)\n",
    "        \n",
    "        all_features.append(features)\n",
    "    \n",
    "    return pd.concat(all_features, ignore_index=True)\n",
    "\n",
    "# Load a subset for initial training\n",
    "sample_notebooks = train_orders['id'].head(1000).tolist()\n",
    "train_df = create_training_data(sample_notebooks, TRAIN_PATH, train_orders)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f83ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_cols = [col for col in train_df.columns if col not in ['notebook_id', 'cell_id', 'position', 'cell_type']]\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "\n",
    "# Add cell type as categorical feature\n",
    "train_df['cell_type_code'] = (train_df['cell_type'] == 'code').astype(int)\n",
    "feature_cols.append('cell_type_code')\n",
    "\n",
    "print(f\"Final feature columns: {feature_cols}\")\n",
    "print(f\"Training data shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kendall tau metric for evaluation\n",
    "def kendall_tau_score(y_true, y_pred):\n",
    "    \"\"\"Calculate Kendall tau correlation\"\"\"\n",
    "    from scipy.stats import kendalltau\n",
    "    return kendalltau(y_true, y_pred).correlation\n",
    "\n",
    "kendall_scorer = make_scorer(kendall_tau_score, greater_is_better=True)\n",
    "\n",
    "# Train model\n",
    "print(\"Training LightGBM model...\")\n",
    "\n",
    "# Use a subset for faster training\n",
    "sample_df = train_df.sample(frac=0.3, random_state=42)\n",
    "\n",
    "X = sample_df[feature_cols]\n",
    "y = sample_df['position']\n",
    "\n",
    "# Train LightGBM model\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Feature importances: {dict(zip(feature_cols, model.feature_importances_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaacbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "def predict_notebook_order(notebook_id, path, model, feature_cols):\n",
    "    \"\"\"Predict cell order for a notebook\"\"\"\n",
    "    features, cell_ids = extract_features(notebook_id, path)\n",
    "    \n",
    "    # Add cell type code\n",
    "    features['cell_type_code'] = (features['cell_type'] == 'code').astype(int)\n",
    "    \n",
    "    # Predict positions\n",
    "    X = features[feature_cols]\n",
    "    predicted_positions = model.predict(X)\n",
    "    \n",
    "    # Sort by predicted position\n",
    "    order_df = pd.DataFrame({\n",
    "        'cell_id': cell_ids,\n",
    "        'predicted_position': predicted_positions\n",
    "    })\n",
    "    \n",
    "    # Sort and get ordered cell IDs\n",
    "    ordered_cells = order_df.sort_values('predicted_position')['cell_id'].tolist()\n",
    "    \n",
    "    return ' '.join(ordered_cells)\n",
    "\n",
    "# Test on a few notebooks\n",
    "test_notebooks = [f.stem for f in TEST_PATH.glob('*.json')][:5]\n",
    "print(\"Testing prediction on sample notebooks:\")\n",
    "for nb_id in test_notebooks:\n",
    "    try:\n",
    "        predicted_order = predict_notebook_order(nb_id, TEST_PATH, model, feature_cols)\n",
    "        print(f\"{nb_id}: {predicted_order[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {nb_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9181fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission for all test notebooks\n",
    "print(\"Generating submission for all test notebooks...\")\n",
    "\n",
    "test_notebooks = [f.stem for f in TEST_PATH.glob('*.json')]\n",
    "submission_data = []\n",
    "\n",
    "for notebook_id in tqdm(test_notebooks, desc=\"Predicting notebooks\"):\n",
    "    try:\n",
    "        predicted_order = predict_notebook_order(notebook_id, TEST_PATH, model, feature_cols)\n",
    "        submission_data.append({\n",
    "            'id': notebook_id,\n",
    "            'cell_order': predicted_order\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {notebook_id}: {e}\")\n",
    "        # Use default order (code cells first, then markdown cells in random order)\n",
    "        submission_data.append({\n",
    "            'id': notebook_id,\n",
    "            'cell_order': ''\n",
    "        })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to {submission_path}\")\n",
    "\n",
    "# Verify format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"\\nSample submission format:\")\n",
    "print(sample_sub.head())\n",
    "print(f\"\\nOur submission format:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "print(f\"\\nColumns match: {list(submission_df.columns) == list(sample_sub.columns)}\")\n",
    "print(f\"Number of rows match: {len(submission_df) == len(sample_sub)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
