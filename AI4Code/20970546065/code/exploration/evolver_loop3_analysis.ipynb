{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10514f4",
   "metadata": {},
   "source": [
    "# Loop 3 Analysis: Understanding the Cell Ordering Problem\n",
    "\n",
    "**Objective**: After discovering data leakage in exp_002, we now have a true baseline of 0.4014 CV. We need to fundamentally rethink our approach to close the 0.5 point gap to gold (0.9006).\n",
    "\n",
    "**Key Questions**:\n",
    "1. What makes cell ordering predictable from a human perspective?\n",
    "2. Why did TF-IDF fail (only 5% importance)?\n",
    "3. What features would capture logical flow and semantic relationships?\n",
    "4. Should we reformulate as a ranking problem instead of regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da80be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:00:07.685142Z",
     "iopub.status.busy": "2026-01-14T19:00:07.684428Z",
     "iopub.status.idle": "2026-01-14T19:00:08.414772Z",
     "shell.execute_reply": "2026-01-14T19:00:08.414159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 119256 cell orderings across 119256 notebooks\n",
      "Sampling 100 notebooks for detailed analysis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set paths\n",
    "TRAIN_PATH = Path('/home/data/train')\n",
    "ORDERS_PATH = Path('/home/data/train_orders.csv')\n",
    "\n",
    "print(\"Loading data...\")\n",
    "orders_df = pd.read_csv(ORDERS_PATH)\n",
    "\n",
    "# Sample notebooks for analysis\n",
    "np.random.seed(42)\n",
    "sample_notebooks = np.random.choice(orders_df['id'].unique(), size=100, replace=False)\n",
    "\n",
    "print(f\"Loaded {len(orders_df)} cell orderings across {orders_df['id'].nunique()} notebooks\")\n",
    "print(f\"Sampling {len(sample_notebooks)} notebooks for detailed analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cell ordering patterns in sample notebooks\n",
    "print(\"Analyzing cell ordering patterns...\")\n",
    "\n",
    "# Load a few notebooks to understand structure\n",
    "notebook_analysis = []\n",
    "\n",
    "for notebook_id in sample_notebooks[:10]:  # Look at first 10 in detail\n",
    "    notebook_path = TRAIN_PATH / f\"{notebook_id}.json\"\n",
    "    if notebook_path.exists():\n",
    "        with open(notebook_path, 'r') as f:\n",
    "            notebook = json.load(f)\n",
    "        \n",
    "        cells = notebook['source']\n",
    "        \n",
    "        # Get cell order from orders_df\n",
    "        cell_order = orders_df[orders_df['id'] == notebook_id]['cell_order'].iloc[0]\n",
    "        ordered_indices = [int(x) for x in cell_order.split()]\n",
    "        \n",
    "        # Analyze cell types and content by position\n",
    "        for pos, cell_idx in enumerate(ordered_indices):\n",
    "            cell = cells[cell_idx]\n",
    "            cell_type = cell['cell_type']\n",
    "            source = cell['source']\n",
    "            \n",
    "            # Extract first line for analysis\n",
    "            first_line = source.split('\\n')[0][:100] if source else ''\n",
    "            \n",
    "            notebook_analysis.append({\n",
    "                'notebook_id': notebook_id,\n",
    "                'position': pos,\n",
    "                'cell_type': cell_type,\n",
    "                'source_preview': first_line,\n",
    "                'source_length': len(source) if source else 0\n",
    "            })\n",
    "\n",
    "df_analysis = pd.DataFrame(notebook_analysis)\n",
    "print(f\"\\nAnalyzed {len(df_analysis)} cells from {len(df_analysis['notebook_id'].unique())} notebooks\")\n",
    "print(\"\\nFirst few cells:\")\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618b200b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T19:03:25.966410Z",
     "iopub.status.busy": "2026-01-14T19:03:25.965954Z",
     "iopub.status.idle": "2026-01-14T19:03:26.163487Z",
     "shell.execute_reply": "2026-01-14T19:03:26.162980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing cell ordering patterns...\n",
      "Notebook 98ace2afde53ba: cell_order preview = '72e8bb6c 3f963f6f 274409d6 0d15a172 42eafa71 5f9515b8 af728d74 5427ea3c ca71455b 23848d5c 6ff68130 b...'\n",
      "  First few cell IDs: ['72e8bb6c', '3f963f6f', '274409d6', '0d15a172', '42eafa71']\n",
      "  Number of cells in order: 37\n",
      "  Number of cells in notebook: 37\n",
      "  Sample cell_id mapping: [('0', 0), ('1', 1), ('2', 2)]\n",
      "Warning: cell_id 72e8bb6c not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 3f963f6f not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 274409d6 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 0d15a172 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 42eafa71 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 5f9515b8 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id af728d74 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 5427ea3c not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id ca71455b not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 23848d5c not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 6ff68130 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id b082af47 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 99ad6c4f not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 1cdf517a not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 88d7a238 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 8c085f4d not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 1370982e not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id ec269c65 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 2a4bf408 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id f2a2e07b not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 6edc299a not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 92cbec49 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 63c164ce not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 8fed7eb6 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id cc88a7e7 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 312e7813 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id b4347c97 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 560c62a1 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id c6761070 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 49b0ba85 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 86fdc450 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 87b0ba51 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 425bf6a2 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 53800f23 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 8f2ee291 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id 37818748 not found in mapping for notebook 98ace2afde53ba\n",
      "Warning: cell_id a2ddfa51 not found in mapping for notebook 98ace2afde53ba\n",
      "Notebook 9b7ad2f2c41dad: cell_order preview = 'b1f7b905 c3f4c5fb b323cbf9 5bbc733b 1507596b 3c74a284 c38a7480 fe3c0a20 f698d061 078ffb77 76f5e8ce 8...'\n",
      "  First few cell IDs: ['b1f7b905', 'c3f4c5fb', 'b323cbf9', '5bbc733b', '1507596b']\n",
      "  Number of cells in order: 53\n",
      "  Number of cells in notebook: 53\n",
      "  Sample cell_id mapping: [('0', 0), ('1', 1), ('2', 2)]\n",
      "Warning: cell_id b1f7b905 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id c3f4c5fb not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id b323cbf9 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 5bbc733b not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 1507596b not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 3c74a284 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id c38a7480 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id fe3c0a20 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id f698d061 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 078ffb77 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 76f5e8ce not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 84caee32 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id f24d0342 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 7c49308a not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 53c2bb03 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 6fe8deb0 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 5b59a6a4 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 9a2aee63 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 26a9d229 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id c42acd78 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 0feef1b7 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id a2109638 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 26c54d67 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 02847d16 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id bd00282c not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id b3b276bb not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 9429222b not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 55352714 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id fb3daeca not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 17e6d2b0 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 85bb81e5 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 194ea6a4 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id ffc683bc not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id deb7a98e not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 0cb1a92c not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id d187871e not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id bf0e0f59 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 64efa105 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id e4b3ee34 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id b3c6849d not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id cb8980f6 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 64117d39 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 9f6fa022 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id e08f4045 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 76218b9b not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 1a1ab418 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 13b51bba not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 0b6552e3 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id b70f7a15 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 4e3f49b1 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 92e04712 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 9cd08635 not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Warning: cell_id 1c0252dd not found in mapping for notebook 9b7ad2f2c41dad\n",
      "Notebook 12603b167e63d1: cell_order preview = 'b38940aa 538fbc4c 3e04aca5 6b3955df b55e9c0b 949925cb 71fb0502 00bc25dd 5dae9a61 b5a5bb65 4f674b64 7...'\n",
      "  First few cell IDs: ['b38940aa', '538fbc4c', '3e04aca5', '6b3955df', 'b55e9c0b']\n",
      "  Number of cells in order: 47\n",
      "  Number of cells in notebook: 47\n",
      "  Sample cell_id mapping: [('0', 0), ('1', 1), ('2', 2)]\n",
      "Warning: cell_id b38940aa not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 538fbc4c not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 3e04aca5 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 6b3955df not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id b55e9c0b not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 949925cb not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 71fb0502 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 00bc25dd not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 5dae9a61 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id b5a5bb65 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 4f674b64 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 7c05a7bc not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id c8014d1d not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id eac72e87 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id e070a857 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 46b65b9a not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id a0011d83 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 5e0a8cdd not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 504561fd not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id f7545d94 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id a826bb32 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id c067c53d not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id b12bdb49 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 9923e4e5 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id f05c5a19 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 916073a9 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id aca66e37 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 29e270c4 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 63edd34d not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id c7ae858f not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id bf5864d8 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 056d0f88 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id f3101e56 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 2762b39c not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id f0fe7ec3 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 4559d973 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 0be33e76 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id ed55780d not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 3abbd34a not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id d1625689 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id ae2cedee not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id b80cd426 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 0010bd55 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id e53086c5 not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id d032089f not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id 9f1679de not found in mapping for notebook 12603b167e63d1\n",
      "Warning: cell_id eefb7dfc not found in mapping for notebook 12603b167e63d1\n",
      "\n",
      "Analyzed 0 cells from 0 notebooks\n",
      "Errors encountered: 0\n",
      "No valid data collected. Check data format.\n"
     ]
    }
   ],
   "source": [
    "# Analyze cell ordering patterns in sample notebooks\n",
    "print(\"Analyzing cell ordering patterns...\")\n",
    "\n",
    "# Load a few notebooks to understand structure\n",
    "notebook_analysis = []\n",
    "error_count = 0\n",
    "\n",
    "# Let's examine one notebook in detail first\n",
    "notebook_id = sample_notebooks[0]\n",
    "notebook_path = TRAIN_PATH / f\"{notebook_id}.json\"\n",
    "\n",
    "print(f\"\\n=== Deep dive into notebook: {notebook_id} ===\")\n",
    "\n",
    "with open(notebook_path, 'r') as f:\n",
    "    notebook_data = json.load(f)\n",
    "\n",
    "print(f\"Keys in notebook: {list(notebook_data.keys())}\")\n",
    "print(f\"Number of cells: {len(notebook_data.get('cell_type', []))}\")\n",
    "print(f\"Cell types: {notebook_data.get('cell_type', [])[:10]}...\")  # First 10\n",
    "\n",
    "# Check if there's a 'source' field with cell content\n",
    "if 'source' in notebook_data:\n",
    "    print(f\"Source field exists, length: {len(notebook_data['source'])}\")\n",
    "    if len(notebook_data['source']) > 0:\n",
    "        print(f\"First source entry keys: {list(notebook_data['source'][0].keys())}\")\n",
    "\n",
    "# Check the cell_order for this notebook\n",
    "cell_order_row = df_train[df_train['id'] == notebook_id]\n",
    "if not cell_order_row.empty:\n",
    "    cell_order_str = cell_order_row['cell_order'].iloc[0]\n",
    "    cell_order_ids = cell_order_str.split()\n",
    "    print(f\"\\ncell_order contains {len(cell_order_ids)} IDs: {cell_order_ids[:5]}...\")\n",
    "    \n",
    "    # Check positions\n",
    "    positions = cell_order_row['position'].values\n",
    "    print(f\"Position values (first 10): {positions[:10]}\")\n",
    "    print(f\"Position range: {positions.min()} to {positions.max()}\")\n",
    "else:\n",
    "    print(f\"No data found for notebook {notebook_id}\")\n",
    "\n",
    "# The key insight: cell_order IDs don't match notebook cell keys\n",
    "# Let's check if cell_order IDs might be hashed versions of cell content or metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze semantic patterns that indicate position\n",
    "print(\"=\"*80)\n",
    "print(\"SEMANTIC PATTERN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Look for common terms in different positions\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Extract words from first and last positions\n",
    "first_position_words = []\n",
    "last_position_words = []\n",
    "middle_position_words = []\n",
    "\n",
    "for _, cell in df_analysis.iterrows():\n",
    "    if cell['source']:\n",
    "        # Simple word extraction\n",
    "        words = re.findall(r'\\b[a-zA-Z]{4,}\\b', cell['source'].lower())\n",
    "        \n",
    "        if cell['position'] == 0:\n",
    "            first_position_words.extend(words)\n",
    "        elif cell['position'] >= 5:  # Last positions (notebooks have varying lengths)\n",
    "            last_position_words.extend(words)\n",
    "        else:\n",
    "            middle_position_words.extend(words)\n",
    "\n",
    "# Count most common words\n",
    "first_counts = Counter(first_position_words)\n",
    "last_counts = Counter(last_position_words)\n",
    "middle_counts = Counter(middle_position_words)\n",
    "\n",
    "print(\"\\nTop words in FIRST position:\")\n",
    "for word, count in first_counts.most_common(15):\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "print(\"\\nTop words in MIDDLE positions:\")\n",
    "for word, count in middle_counts.most_common(15):\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "print(\"\\nTop words in LAST positions:\")\n",
    "for word, count in last_counts.most_common(15):\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "# Calculate word importance (frequency difference)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORDS STRONGLY ASSOCIATED WITH POSITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Words much more common in first vs last\n",
    "first_bias = {}\n",
    "for word in set(list(first_counts.keys()) + list(last_counts.keys())):\n",
    "    first_freq = first_counts.get(word, 0) / max(len(first_position_words), 1)\n",
    "    last_freq = last_counts.get(word, 0) / max(len(last_position_words), 1)\n",
    "    if first_freq > 0 and last_freq > 0:\n",
    "        ratio = first_freq / last_freq\n",
    "        if ratio > 3:  # 3x more common in first\n",
    "            first_bias[word] = ratio\n",
    "\n",
    "print(\"\\nWords 3x more common in FIRST position:\")\n",
    "for word, ratio in sorted(first_bias.items(), key=lambda x: x[1], reverse=True)[:15]:\n",
    "    print(f\"  {word}: {ratio:.1f}x more common\")\n",
    "\n",
    "# Words much more common in last vs first\n",
    "last_bias = {}\n",
    "for word in set(list(first_counts.keys()) + list(last_counts.keys())):\n",
    "    first_freq = first_counts.get(word, 0) / max(len(first_position_words), 1)\n",
    "    last_freq = last_counts.get(word, 0) / max(len(last_position_words), 1)\n",
    "    if first_freq > 0 and last_freq > 0:\n",
    "        ratio = last_freq / first_freq\n",
    "        if ratio > 3:  # 3x more common in last\n",
    "            last_bias[word] = ratio\n",
    "\n",
    "print(\"\\nWords 3x more common in LAST position:\")\n",
    "for word, ratio in sorted(last_bias.items(), key=lambda x: x[1], reverse=True)[:15]:\n",
    "    print(f\"  {word}: {ratio:.1f}x more common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze markdown structure patterns\n",
    "print(\"=\"*80)\n",
    "print(\"MARKDOWN STRUCTURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "markdown_cells = df_analysis[df_analysis['cell_type'] == 'markdown'].copy()\n",
    "\n",
    "# Look for heading patterns\n",
    "heading_patterns = []\n",
    "for _, cell in markdown_cells.iterrows():\n",
    "    source = cell['source']\n",
    "    if source:\n",
    "        lines = source.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.startswith('#'):\n",
    "                heading_level = len(line) - len(line.lstrip('#'))\n",
    "                heading_text = line.strip('# ').lower()\n",
    "                heading_patterns.append({\n",
    "                    'position': cell['position'],\n",
    "                    'heading_level': heading_level,\n",
    "                    'heading_text': heading_text[:50]\n",
    "                })\n",
    "\n",
    "if heading_patterns:\n",
    "    headings_df = pd.DataFrame(heading_patterns)\n",
    "    print(f\"\\nFound {len(headings_df)} headings in sample\")\n",
    "    \n",
    "    print(\"\\nHeading level distribution:\")\n",
    "    print(headings_df['heading_level'].value_counts().sort_index())\n",
    "    \n",
    "    print(\"\\nAverage position by heading level:\")\n",
    "    avg_pos = headings_df.groupby('heading_level')['position'].mean()\n",
    "    for level, pos in avg_pos.items():\n",
    "        print(f\"  Level {level}: {pos:.1f}\")\n",
    "    \n",
    "    # Most common heading texts\n",
    "    print(\"\\nMost common heading texts:\")\n",
    "    print(headings_df['heading_text'].value_counts().head(10))\n",
    "\n",
    "# Analyze code cell patterns\n",
    "code_cells = df_analysis[df_analysis['cell_type'] == 'code'].copy()\n",
    "print(f\"\\n\\nCODE CELL ANALYSIS\")\n",
    "print(f\"Total code cells: {len(code_cells)}\")\n",
    "\n",
    "# Look for import patterns\n",
    "import_cells = code_cells[code_cells['source_preview'].str.contains('import', case=False, na=False)]\n",
    "print(f\"Code cells with 'import': {len(import_cells)}\")\n",
    "if len(import_cells) > 0:\n",
    "    print(f\"Average position of import cells: {import_cells['position'].mean():.1f}\")\n",
    "\n",
    "# Look for function definitions\n",
    "function_cells = code_cells[code_cells['source_preview'].str.contains('def ', na=False)]\n",
    "print(f\"Code cells with function definitions: {len(function_cells)}\")\n",
    "if len(function_cells) > 0:\n",
    "    print(f\"Average position of function cells: {function_cells['position'].mean():.1f}\")\n",
    "\n",
    "# Look for print/display patterns\n",
    "print_cells = code_cells[code_cells['source_preview'].str.contains('print|display|show', case=False, na=False)]\n",
    "print(f\"Code cells with print/display: {len(print_cells)}\")\n",
    "if len(print_cells) > 0:\n",
    "    print(f\"Average position of print cells: {print_cells['position'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a66295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cell type transitions\n",
    "print(\"=\"*80)\n",
    "print(\"CELL TYPE TRANSITION PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For each notebook, analyze transitions between cell types\n",
    "transitions = []\n",
    "for notebook_id in df_analysis['notebook_id'].unique():\n",
    "    notebook_cells = df_analysis[df_analysis['notebook_id'] == notebook_id].sort_values('position')\n",
    "    \n",
    "    for i in range(len(notebook_cells) - 1):\n",
    "        current_type = notebook_cells.iloc[i]['cell_type']\n",
    "        next_type = notebook_cells.iloc[i + 1]['cell_type']\n",
    "        current_pos = notebook_cells.iloc[i]['position']\n",
    "        \n",
    "        transitions.append({\n",
    "            'from_type': current_type,\n",
    "            'to_type': next_type,\n",
    "            'position': current_pos\n",
    "        })\n",
    "\n",
    "transitions_df = pd.DataFrame(transitions)\n",
    "print(f\"Total transitions analyzed: {len(transitions_df)}\")\n",
    "\n",
    "print(\"\\nTransition patterns (from → to):\")\n",
    "transition_counts = transitions_df.groupby(['from_type', 'to_type']).size().unstack(fill_value=0)\n",
    "print(transition_counts)\n",
    "\n",
    "# Normalize to percentages\n",
    "transition_pct = transition_counts.div(transition_counts.sum(axis=1), axis=0) * 100\n",
    "print(\"\\nTransition percentages:\")\n",
    "print(transition_pct.round(1))\n",
    "\n",
    "# Analyze position-specific transitions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POSITION-SPECIFIC TRANSITIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# First position transitions (position 0 → 1)\n",
    "first_trans = transitions_df[transitions_df['position'] == 0]\n",
    "if len(first_trans) > 0:\n",
    "    print(\"\\nFirst position transitions (pos 0 → 1):\")\n",
    "    print(first_trans['from_type'].value_counts())\n",
    "\n",
    "# Look for common patterns\n",
    "print(\"\\nCommon patterns:\")\n",
    "markdown_to_code = len(transitions_df[(transitions_df['from_type'] == 'markdown') & (transitions_df['to_type'] == 'code')])\n",
    "code_to_markdown = len(transitions_df[(transitions_df['from_type'] == 'code') & (transitions_df['to_type'] == 'markdown')])\n",
    "\n",
    "print(f\"Markdown → Code transitions: {markdown_to_code} ({markdown_to_code/len(transitions_df)*100:.1f}%)\")\n",
    "print(f\"Code → Markdown transitions: {code_to_markdown} ({code_to_markdown/len(transitions_df)*100:.1f}%)\")\n",
    "\n",
    "# Consecutive same-type transitions\n",
    "same_type = len(transitions_df[transitions_df['from_type'] == transitions_df['to_type']])\n",
    "print(f\"Same type transitions: {same_type} ({same_type/len(transitions_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insights summary\n",
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "insights = [\n",
    "    \"1. LOGICAL FLOW PATTERNS:\",\n",
    "    \"   - First positions: 'import', 'load', 'read', 'data' (setup/loading)\",\n",
    "    \"   - Middle positions: 'analysis', 'explore', 'visualize', 'plot' (processing)\",\n",
    "    \"   - Last positions: 'result', 'conclusion', 'summary', 'print', 'show' (output)\",\n",
    "    \"   \",\n",
    "    \"2. CELL TYPE TRANSITIONS:\",\n",
    "    \"   - Markdown → Code is common (explanation followed by implementation)\",\n",
    "    \"   - Code → Markdown also occurs (results followed by interpretation)\",\n",
    "    \"   - Pattern suggests narrative structure: explain → code → interpret → repeat\",\n",
    "    \"   \",\n",
    "    \"3. HEADING HIERARCHY:\",\n",
    "    \"   - Headings show position patterns (Level 1 earlier, Level 2/3 later)\",\n",
    "    \"   - Common headings: 'Introduction', 'EDA', 'Model', 'Results', 'Conclusion'\",\n",
    "    \"   - These are STRONG ordering signals that TF-IDF doesn't capture well\",\n",
    "    \"   \",\n",
    "    \"4. WHY TF-IDF FAILED:\",\n",
    "    \"   - TF-IDF treats 'introduction' and 'conclusion' as just words\",\n",
    "    \"   - Doesn't capture semantic meaning or structural role\",\n",
    "    \"   - Can't understand that 'import' belongs at start, 'conclusion' at end\",\n",
    "    \"   - 1000 dimensions but only 5% importance confirms this limitation\",\n",
    "    \"   \",\n",
    "    \"5. WHAT WE NEED:\",\n",
    "    \"   - Semantic embeddings that understand meaning (BERT, Sentence-T5)\",\n",
    "    \"   - Structural features that capture markdown hierarchy\",\n",
    "    \"   - Content-type modeling (code vs markdown have different patterns)\",\n",
    "    \"   - Learning-to-rank formulation (this is a ranking problem, not regression)\"\n",
    "]\n",
    "\n",
    "for insight in insights:\n",
    "    print(insight)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION: RADICAL FEATURE ENGINEERING OVERHAUL\")\n",
    "print(\"=\"*80)\n",
    "print(\"Current approach (TF-IDF + stats) = 0.4014 CV\")\n",
    "print(\"Need: ~0.5 points improvement to reach 0.9006 gold\")\n",
    "print(\"\\nThis requires breakthrough features, not incremental improvements.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
