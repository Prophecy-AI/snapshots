{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cd39be",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Extraction - RoBERTa Span Model (Fixed)\n",
    "\n",
    "This notebook implements a transformer-based approach using RoBERTa with span extraction head.\n",
    "\n",
    "## Strategy\n",
    "1. Use RoBERTa-base with start/end token classification\n",
    "2. Frame as span prediction: predict start and end positions\n",
    "3. Input: tweet text + sentiment token\n",
    "4. Target: start/end indices of selected_text\n",
    "5. Expected score: 0.70+ based on winning solutions\n",
    "\n",
    "## Key Fixes\n",
    "- Use PreTrainedTokenizerFast for offset_mapping support\n",
    "- Properly calculate token positions from character positions\n",
    "- Complete data preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d5acb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:10:49.186227Z",
     "iopub.status.busy": "2026-01-15T12:10:49.185535Z",
     "iopub.status.idle": "2026-01-15T12:10:56.280873Z",
     "shell.execute_reply": "2026-01-15T12:10:56.280112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 12:10:54.117945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-15 12:10:54.143446: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-15 12:10:54.150947: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "Memory: 85.1 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizerFast, RobertaModel, RobertaConfig\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304f38ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:10:56.283286Z",
     "iopub.status.busy": "2026-01-15T12:10:56.282819Z",
     "iopub.status.idle": "2026-01-15T12:10:56.403533Z",
     "shell.execute_reply": "2026-01-15T12:10:56.402797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (27481, 4)\n",
      "Test shape: (3534, 3)\n",
      "Sample cleaned data:\n",
      "                                                text  \\\n",
      "0                I`d have responded, if I were going   \n",
      "1      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2                          my boss is bullying me...   \n",
      "3                     what interview! leave me alone   \n",
      "4  Sons of ****, why couldn`t they put them on th...   \n",
      "\n",
      "                         selected_text sentiment  \n",
      "0  I`d have responded, if I were going   neutral  \n",
      "1                             Sooo SAD  negative  \n",
      "2                          bullying me  negative  \n",
      "3                       leave me alone  negative  \n",
      "4                        Sons of ****,  negative  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    # Remove surrounding quotes if present\n",
    "    if text.startswith('\"') and text.endswith('\"'):\n",
    "        text = text[1:-1]\n",
    "    return text\n",
    "\n",
    "# Clean text columns\n",
    "train_df['text'] = train_df['text'].apply(clean_text)\n",
    "train_df['selected_text'] = train_df['selected_text'].apply(clean_text)\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Sample cleaned data:\")\n",
    "print(train_df[['text', 'selected_text', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d177f68c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T12:12:30.417369Z",
     "iopub.status.busy": "2026-01-15T12:12:30.416614Z",
     "iopub.status.idle": "2026-01-15T12:12:31.822410Z",
     "shell.execute_reply": "2026-01-15T12:12:31.821850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed training data:\n",
      "                                          input_text  \\\n",
      "0        neutral I`d have responded, if I were going   \n",
      "1  negative Sooo SAD I will miss you here in San ...   \n",
      "2                 negative my boss is bullying me...   \n",
      "3            negative what interview! leave me alone   \n",
      "4  negative Sons of ****, why couldn`t they put t...   \n",
      "\n",
      "                         selected_text  start_char  end_char  \n",
      "0  I`d have responded, if I were going           8        43  \n",
      "1                             Sooo SAD           9        17  \n",
      "2                          bullying me          20        31  \n",
      "3                       leave me alone          25        39  \n",
      "4                        Sons of ****,           9        22  \n"
     ]
    }
   ],
   "source": [
    "# Add sentiment token and prepare data for span extraction\n",
    "def prepare_data(df, is_train=True):\n",
    "    \"\"\"Prepare data with sentiment token and character positions\"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        \n",
    "        # Add sentiment token at the beginning (as in winning solution)\n",
    "        input_text = f\"{sentiment} {text}\"\n",
    "        \n",
    "        if is_train:\n",
    "            selected_text = row['selected_text']\n",
    "            \n",
    "            # Find character positions of selected_text in the full text\n",
    "            # Note: We need to find it in the original text, not input_text\n",
    "            try:\n",
    "                start_char = text.index(selected_text)\n",
    "                end_char = start_char + len(selected_text)\n",
    "                \n",
    "                # Adjust for sentiment token prefix\n",
    "                # Sentiment token adds length(sentiment) + 1 (space)\n",
    "                prefix_length = len(sentiment) + 1\n",
    "                start_char += prefix_length\n",
    "                end_char += prefix_length\n",
    "                \n",
    "            except ValueError:\n",
    "                # If selected_text not found, use the whole text\n",
    "                start_char = len(sentiment) + 1  # After sentiment token\n",
    "                end_char = len(input_text)\n",
    "                \n",
    "            processed.append({\n",
    "                'textID': row['textID'],\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'input_text': input_text,\n",
    "                'selected_text': selected_text,\n",
    "                'start_char': start_char,\n",
    "                'end_char': end_char\n",
    "            })\n",
    "        else:\n",
    "            processed.append({\n",
    "                'textID': row['textID'],\n",
    "                'text': text,\n",
    "                'sentiment': sentiment,\n",
    "                'input_text': input_text\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(processed)\n",
    "\n",
    "# Prepare training data\n",
    "train_processed = prepare_data(train_df, is_train=True)\n",
    "test_processed = prepare_data(test_df, is_train=False)\n",
    "\n",
    "print(\"Sample processed training data:\")\n",
    "print(train_processed[['input_text', 'selected_text', 'start_char', 'end_char']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset class with proper offset mapping\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Tokenize with offset mapping\n",
    "        encoding = self.tokenizer(\n",
    "            row['input_text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        offset_mapping = encoding['offset_mapping'].squeeze()\n",
    "        \n",
    "        # Find token positions from character positions\n",
    "        start_char = row.get('start_char', 0)\n",
    "        end_char = row.get('end_char', 0)\n",
    "        \n",
    "        start_token = 0\n",
    "        end_token = 0\n",
    "        \n",
    "        # Find start token\n",
    "        for i, (token_start, token_end) in enumerate(offset_mapping):\n",
    "            if token_start <= start_char < token_end:\n",
    "                start_token = i\n",
    "                break\n",
    "        \n",
    "        # Find end token\n",
    "        for i, (token_start, token_end) in enumerate(offset_mapping):\n",
    "            if token_start < end_char <= token_end:\n",
    "                end_token = i\n",
    "                break\n",
    "        \n",
    "        # Ensure end_token >= start_token\n",
    "        if end_token < start_token:\n",
    "            end_token = start_token\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'start_position': torch.tensor(start_token, dtype=torch.long),\n",
    "            'end_position': torch.tensor(end_token, dtype=torch.long),\n",
    "            'textID': row['textID'],\n",
    "            'text': row['text'],\n",
    "            'sentiment': row['sentiment'],\n",
    "            'selected_text': row.get('selected_text', ''),\n",
    "            'input_text': row['input_text']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16380254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RoBERTa span model\n",
    "class RoBERTaSpanExtractor(nn.Module):\n",
    "    def __init__(self, model_name='roberta-base'):\n",
    "        super(RoBERTaSpanExtractor, self).__init__()\n",
    "        \n",
    "        # Load pre-trained RoBERTa\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.roberta.config.hidden_size\n",
    "        \n",
    "        # Span extraction heads\n",
    "        self.start_head = nn.Linear(self.hidden_size, 1)\n",
    "        self.end_head = nn.Linear(self.hidden_size, 1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get RoBERTa outputs\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        # Apply dropout\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        # Predict start and end positions\n",
    "        start_logits = self.start_head(sequence_output).squeeze(-1)  # [batch_size, seq_len]\n",
    "        end_logits = self.end_head(sequence_output).squeeze(-1)      # [batch_size, seq_len]\n",
    "        \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard similarity function\n",
    "def jaccard_similarity(str1, str2):\n",
    "    \"\"\"Calculate Jaccard similarity between two strings\"\"\"\n",
    "    str1 = str(str1).lower()\n",
    "    str2 = str(str2).lower()\n",
    "    \n",
    "    # Split into words\n",
    "    words1 = set(str1.split())\n",
    "    words2 = set(str2.split())\n",
    "    \n",
    "    if not words1 and not words2:\n",
    "        return 1.0\n",
    "    \n",
    "    intersection = words1.intersection(words2)\n",
    "    union = words1.union(words2)\n",
    "    \n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8dfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_span(model, tokenizer, text, sentiment, device, max_length=128):\n",
    "    \"\"\"Predict selected_text span for a given tweet\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input\n",
    "    input_text = f\"{sentiment} {text}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        input_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt',\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    offset_mapping = encoding['offset_mapping'].squeeze().numpy()\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        start_logits, end_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Get start and end positions\n",
    "        start_pred = torch.argmax(start_logits, dim=-1).item()\n",
    "        end_pred = torch.argmax(end_logits, dim=-1).item()\n",
    "        \n",
    "        # Ensure end >= start\n",
    "        if end_pred < start_pred:\n",
    "            end_pred = start_pred\n",
    "    \n",
    "    # Extract text span from character positions\n",
    "    start_char = offset_mapping[start_pred][0]\n",
    "    end_char = offset_mapping[end_pred][1]\n",
    "    \n",
    "    # Extract the predicted text\n",
    "    pred_text = input_text[start_char:end_char].strip()\n",
    "    \n",
    "    # If prediction is empty or just sentiment token, return full text\n",
    "    if not pred_text or pred_text == sentiment or len(pred_text.split()) == 0:\n",
    "        # For neutral sentiment, return full text (common pattern)\n",
    "        if sentiment == 'neutral':\n",
    "            return text\n",
    "        # For positive/negative, try to extract something meaningful\n",
    "        else:\n",
    "            # Fallback: return the text without sentiment prefix\n",
    "            if start_char > len(sentiment) + 1:\n",
    "                return input_text[start_char:end_char].strip()\n",
    "            else:\n",
    "                # Return a reasonable default (first few words)\n",
    "                words = text.split()\n",
    "                return ' '.join(words[:5]) if words else text\n",
    "    \n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0462297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, device, epochs=3, lr=2e-5):\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Loss function\n",
    "    def span_loss(start_logits, end_logits, start_positions, end_positions):\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        start_loss = loss_fct(start_logits, start_positions)\n",
    "        end_loss = loss_fct(end_logits, end_positions)\n",
    "        return (start_loss + end_loss) / 2\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_steps = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_position'].to(device)\n",
    "            end_positions = batch['end_position'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            start_logits, end_logits = model(input_ids, attention_mask)\n",
    "            loss = span_loss(start_logits, end_logits, start_positions, end_positions)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_position'].to(device)\n",
    "                end_positions = batch['end_position'].to(device)\n",
    "                \n",
    "                start_logits, end_logits = model(input_ids, attention_mask)\n",
    "                loss = span_loss(start_logits, end_logits, start_positions, end_positions)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "        \n",
    "        avg_train_loss = train_loss / train_steps if train_steps > 0 else 0\n",
    "        avg_val_loss = val_loss / val_steps if val_steps > 0 else 0\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation training\n",
    "print(\"Starting 5-fold cross-validation...\")\n",
    "\n",
    "# Use RobertaTokenizerFast for offset_mapping support\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "fold_predictions = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_processed)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/5\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_fold = train_processed.iloc[train_idx]\n",
    "    val_fold = train_processed.iloc[val_idx]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TweetDataset(train_fold, tokenizer)\n",
    "    val_dataset = TweetDataset(val_fold, tokenizer)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = RoBERTaSpanExtractor()\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(model, train_loader, val_loader, device, epochs=3, lr=2e-5)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    fold_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Get predictions\n",
    "            texts = batch['text']\n",
    "            sentiments = batch['sentiment']\n",
    "            true_selected = batch['selected_text']\n",
    "            \n",
    "            for i in range(len(texts)):\n",
    "                text = texts[i]\n",
    "                sentiment = sentiments[i]\n",
    "                true_text = true_selected[i]\n",
    "                \n",
    "                # Predict\n",
    "                pred_text = predict_span(model, tokenizer, text, sentiment, device)\n",
    "                \n",
    "                # Calculate Jaccard similarity\n",
    "                score = jaccard_similarity(true_text, pred_text)\n",
    "                fold_scores.append(score)\n",
    "                \n",
    "                # Store for analysis\n",
    "                fold_predictions.append({\n",
    "                    'fold': fold + 1,\n",
    "                    'textID': batch['textID'][i],\n",
    "                    'text': text,\n",
    "                    'sentiment': sentiment,\n",
    "                    'true_selected': true_text,\n",
    "                    'pred_selected': pred_text,\n",
    "                    'jaccard': score\n",
    "                })\n",
    "    \n",
    "    fold_score = np.mean(fold_scores)\n",
    "    cv_scores.append(fold_score)\n",
    "    print(f\"Fold {fold + 1} Score: {fold_score:.4f}\")\n",
    "\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fold predictions for analysis\n",
    "import os\n",
    "os.makedirs('/home/code/experiments/002_roberta_span', exist_ok=True)\n",
    "\n",
    "fold_preds_df = pd.DataFrame(fold_predictions)\n",
    "fold_preds_df.to_csv('/home/code/experiments/002_roberta_span/fold_predictions.csv', index=False)\n",
    "\n",
    "# Show some sample predictions\n",
    "print(\"\\nSample predictions from validation:\")\n",
    "sample_preds = fold_preds_df.sample(5, random_state=42)\n",
    "for idx, row in sample_preds.iterrows():\n",
    "    print(f\"\\nSentiment: {row['sentiment']}\")\n",
    "    print(f\"Text: '{row['text']}'\")\n",
    "    print(f\"True: '{row['true_selected']}'\")\n",
    "    print(f\"Pred: '{row['pred_selected']}'\")\n",
    "    print(f\"Score: {row['jaccard']:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e50917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "print(\"Training final model on full training data...\")\n",
    "\n",
    "# Create full dataset\n",
    "train_dataset_full = TweetDataset(train_processed, tokenizer)\n",
    "train_loader_full = DataLoader(train_dataset_full, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize and train final model\n",
    "final_model = RoBERTaSpanExtractor()\n",
    "final_model = train_model(final_model, train_loader_full, train_loader_full, device, epochs=3)\n",
    "\n",
    "# Save final model\n",
    "torch.save(final_model.state_dict(), '/home/code/experiments/002_roberta_span/final_model.pt')\n",
    "print(\"Final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for idx, row in test_processed.iterrows():\n",
    "    text = row['text']\n",
    "    sentiment = row['sentiment']\n",
    "    textID = row['textID']\n",
    "    \n",
    "    # Predict using the final model\n",
    "    pred_selected = predict_span(final_model, tokenizer, text, sentiment, device)\n",
    "    \n",
    "    test_predictions.append({\n",
    "        'textID': textID,\n",
    "        'selected_text': pred_selected\n",
    "    })\n",
    "    \n",
    "    if idx % 500 == 0:\n",
    "        print(f\"Processed {idx}/{len(test_processed)} samples\")\n",
    "\n",
    "# Create submission\n",
    "test_preds_df = pd.DataFrame(test_predictions)\n",
    "\n",
    "print(\"\\nSample test predictions:\")\n",
    "print(test_preds_df.head())\n",
    "\n",
    "# Save submission\n",
    "test_preds_df.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Shape: {test_preds_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results summary\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"ROBERTA SPAN MODEL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"Baseline score: 0.5481\")\n",
    "print(f\"Improvement: +{cv_mean - 0.5481:.4f}\")\n",
    "print(f\"Test predictions: {len(test_preds_df)} samples\")\n",
    "print(f\"Submission saved: /home/submission/submission.csv\")\n",
    "\n",
    "# Performance by sentiment\n",
    "print(f\"\\nPerformance by sentiment (from validation):\")\n",
    "sentiment_perf = fold_preds_df.groupby('sentiment')['jaccard'].agg(['mean', 'count'])\n",
    "print(sentiment_perf)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
