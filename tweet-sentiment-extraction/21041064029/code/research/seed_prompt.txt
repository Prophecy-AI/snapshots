## Current Status
- Best CV score: 0.7036 from exp_001 (RoBERTa span extraction)
- Best LB score: N/A (competition inactive, submissions fail with HTTP 400)
- CV-LB gap: UNKNOWN (cannot submit - competition ended in 2020)
- Target: 0.736150 (gap: 0.0326 points)
- Space trimming: FAILED (exp_003 showed 0 improvement)

## Critical Discovery: Competition Inactive
**MAJOR ISSUE**: Web search confirms tweet-sentiment-extraction competition ended in 2020. All submission attempts will fail with HTTP 400 errors. **We cannot get LB scores for calibration.** Must rely solely on CV optimization.

## Response to Evaluator
- Technical verdict was **TRUSTWORTHY**. Space trimming experiment was well-executed and correctly concluded it's not useful.
- Evaluator's top priority: **Implement 5-fold ensembling** - I respectfully disagree on sequencing.
- Key concerns raised:
  1. No ensembling yet (valid)
  2. No character-level refinement (valid - this is the gap)
  3. 0.0326 point gap requires proven techniques (valid)

**My strategic divergence**: While ensembling is valuable, the winning solution's character-level refinement provided the key +0.02 boost that directly addresses our boundary detection weakness (0.52 scores on sentiment tweets). Character-level WaveNet has higher expected ROI (+0.015-0.025) than simple ensembling (+0.010-0.020) and was the 1st place innovation. I propose **Character-level FIRST, then ensemble character-level models** because:
1. Addresses core weakness (boundary detection on sentiment tweets)
2. Higher expected gain based on winning solution analysis
3. Can ensemble multiple character-level models for additional boost
4. Without LB feedback, we must prioritize maximum CV improvement
5. The 0.0326 gap requires the highest-impact techniques first

## Data Understanding & Winning Solution Analysis
- **Reference**: `research/writeups/dark-of-the-moon-quick-1st-place-solution-overview.md` - Character-level WaveNet was THE key innovation
- **Reference**: `research/writeups/y-o-m-y-hiromu-2nd-place-solution-overview.md` - Used reranking + post-processing for +0.012
- **Reference**: `research/writeups/podpall-4th-place-solution-overview.md` - Complex 4-head architecture + external scorer

**Key patterns from winning solutions:**
1. **Character-level refinement**: Convert token probabilities → character probabilities → WaveNet smoothing
2. **Multi-model ensembles**: 4-8 models (BERT, RoBERTa, ELECTRA, DeBERTa)
3. **Post-processing**: Space handling (2nd place got +0.012 from this alone)
4. **Advanced architectures**: 4-head models, reranking, external scorers

**Our performance gap analysis:**
- Neutral tweets: 0.972 (excellent, near-perfect)
- Sentiment tweets: 0.521-0.522 (main opportunity - boundary detection issues)
- **Root cause**: Token-level predictions struggle with exact character boundaries

## Recommended Approaches (Priority Order)

### 1. Character-Level WaveNet Model (HIGHEST PRIORITY - Expected gain: +0.015 to +0.025)
**Why first**: Highest ROI, addresses core weakness, proven in 1st place solution

**Implementation steps:**
1. **Modify RoBERTa inference** to save token start/end probabilities (not just predictions)
   - Current: `pred_start, pred_end = torch.argmax(logits, dim=1)`
   - New: Save full probability distributions `start_probs, end_probs`
   - Output: `[seq_len, 2]` arrays per sample

2. **Convert token → character probabilities**
   - Use `offset_mapping` from tokenizer to map token positions to character positions
   - For each character position, aggregate probabilities from overlapping tokens
   - Output: `[text_len, 2]` character-level probability arrays

3. **Build WaveNet architecture**
   - Dilated convolutions with skip connections (rates: 1, 2, 4, 8, 16, 32)
   - Input: Character-level probability distributions
   - Target: Refined character-level start/end probabilities
   - Architecture from winning kernel: `theoviel/character-level-model-magic/`

4. **Train on 5-fold CV**
   - Use character-level probabilities from RoBERTa as input features
   - Train separate WaveNet for each fold
   - Expected: Smoother probability distributions → better boundary detection

5. **Generate refined predictions**
   - Apply trained WaveNet to smooth character-level probabilities
   - Extract final spans from refined distributions
   - Expected improvement: +0.015 to +0.025 CV score

### 2. Multi-Model Ensemble (HIGH PRIORITY - Expected gain: +0.010 to +0.020)
**Why second**: Can parallelize with character-level work, adds diversity

**Implementation:**
- Train additional transformer models:
  - BERT-base-uncased (expected: 0.695)
  - DeBERTa-v3-small (expected: 0.705) 
  - RoBERTa-large (expected: 0.715)
- Generate token-level predictions from each model
- Average start/end probability distributions before span extraction
- Can ensemble character-level models for additional gain

### 3. Advanced Post-Processing (MEDIUM PRIORITY - Expected gain: +0.005 to +0.012)
**Why third**: 2nd place got +0.012 from this alone, but requires careful implementation

**Implementation:**
- Handle extra spaces based on original tweet formatting
- Use regex patterns for punctuation normalization
- Reference: 2nd place solution's complex post-processing function
- Simpler approach: Remove leading/trailing spaces, handle edge cases

### 4. RoBERTa-large Upgrade (MEDIUM PRIORITY - Expected gain: +0.005 to +0.015)
**Why fourth**: Higher capacity but diminishing returns and 3x slower training

**Implementation:**
- Replace RoBERTa-base with RoBERTa-large (355M vs 125M params)
- Keep same training setup (3 epochs, lr=2e-5, batch_size=8 due to memory)
- Can be done in parallel with other experiments

## What NOT to Try (Based on Evidence)
- **Simple 5-fold averaging**: Doesn't address boundary issues (current weakness)
- **More epochs**: Already at convergence (stable CV scores across folds)
- **Space trimming**: PROVEN DEAD END (exp_003 showed 0 improvement)
- **BIO tagging**: Start/end prediction is superior (validated in competition)
- **DistilBERT**: Significantly weaker than RoBERTa for this task
- **Aggressive augmentation**: May hurt performance on this extraction task

## Validation Notes (CV-Only Optimization)
- **CV scheme**: Continue 5-fold KFold (consistent with previous)
- **Metric**: Jaccard similarity (character-level evaluation)
- **Success criteria for character-level**: CV improvement ≥ +0.010
- **Target trajectory**: 
  - Character-level: 0.7036 → 0.7186-0.7286
  - Ensemble: 0.7186 → 0.7286-0.7386 (target achieved)
- **Without LB feedback**: Must be more conservative, validate thoroughly on CV
- **Risk mitigation**: If character-level shows < +0.005, investigate implementation immediately

## Implementation Timeline (4-5 days)
**Day 1**: Character-level WaveNet (Steps 1-2) - Modify RoBERTa, convert to character probs
**Day 2**: Character-level WaveNet (Step 3) - Build WaveNet architecture  
**Day 3**: Character-level WaveNet (Steps 4-5) - Train models, generate predictions
**Day 4**: Multi-model ensemble - Train BERT/DeBERTa models in parallel
**Day 5**: Final ensemble + post-processing - Combine all models, apply post-processing

**Expected final score**: 0.7362+ (target achieved)

## Risk Assessment
- **High risk**: CV-LB gap unknown (cannot calibrate without submissions)
- **Medium risk**: Character-level implementation complexity
- **Low risk**: Ensembling (proven technique)
- **Mitigation**: Focus on techniques with highest CV impact, validate thoroughly