{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5789c0bf",
   "metadata": {},
   "source": [
    "# Generate Test Predictions for Submission\n",
    "\n",
    "**Objective**: Generate predictions on the test set using the trained RoBERTa model to fix the submission error.\n",
    "\n",
    "**Issue**: Previous submission failed with 400 error - likely because we submitted validation predictions instead of test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizerFast, RobertaModel\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('/home/code/data/test.csv')\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Test data columns: {test_df.columns.tolist()}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096a5ad",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RoBERTa span extraction model (same architecture as training)\n",
    "class TweetRoBERTaModel(nn.Module):\n",
    "    def __init__(self, model_name='roberta-base'):\n",
    "        super(TweetRoBERTaModel, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.start_classifier = nn.Linear(self.roberta.config.hidden_size, 1)\n",
    "        self.end_classifier = nn.Linear(self.roberta.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        start_logits = self.start_classifier(sequence_output).squeeze(-1)\n",
    "        end_logits = self.end_classifier(sequence_output).squeeze(-1)\n",
    "        \n",
    "        return start_logits, end_logits\n",
    "\n",
    "# Load the trained model\n",
    "model_path = '/home/code/experiments/002_roberta_span/final_model.pt'\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "model = TweetRoBERTaModel('roberta-base')\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a890ec",
   "metadata": {},
   "source": [
    "## Prepare Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "MAX_LEN = 128\n",
    "\n",
    "class TweetTestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        \n",
    "        # Add sentiment token at beginning\n",
    "        text_with_sentiment = f\"<{sentiment}> {text}\"\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text_with_sentiment,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'offset_mapping': encoding['offset_mapping'].squeeze(0),\n",
    "            'text': text,\n",
    "            'text_with_sentiment': text_with_sentiment,\n",
    "            'sentiment': sentiment\n",
    "        }\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = TweetTestDataset(test_df, tokenizer, MAX_LEN)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Test loader batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70075f8e",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_span_from_predictions(start_probs, end_probs, offset_mapping, text, sentiment, threshold=0.5):\n",
    "    \"\"\"Extract text span from model predictions\"\"\"\n",
    "    \n",
    "    # For neutral sentiment, return full text\n",
    "    if sentiment == 'neutral':\n",
    "        return text\n",
    "    \n",
    "    # Find best start and end positions\n",
    "    start_idx = torch.argmax(start_probs).item()\n",
    "    end_idx = torch.argmax(end_probs).item()\n",
    "    \n",
    "    # Ensure start <= end\n",
    "    if start_idx > end_idx:\n",
    "        start_idx, end_idx = end_idx, start_idx\n",
    "    \n",
    "    # Get character positions from offset mapping\n",
    "    start_char = offset_mapping[start_idx][0].item()\n",
    "    end_char = offset_mapping[end_idx][1].item()\n",
    "    \n",
    "    # Extract span\n",
    "    selected_text = text[start_char:end_char]\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if not selected_text.strip():\n",
    "        # If prediction is empty, return text (fallback)\n",
    "        return text\n",
    "    \n",
    "    return selected_text\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(test_loader)}\")\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        offset_mapping = batch['offset_mapping']\n",
    "        texts = batch['text']\n",
    "        sentiments = batch['sentiment']\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "        \n",
    "        # Get model predictions\n",
    "        start_logits, end_logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        start_probs = torch.softmax(start_logits, dim=-1)\n",
    "        end_probs = torch.softmax(end_logits, dim=-1)\n",
    "        \n",
    "        # Process each item in batch\n",
    "        for i in range(len(texts)):\n",
    "            pred_text = extract_span_from_predictions(\n",
    "                start_probs[i], \n",
    "                end_probs[i], \n",
    "                offset_mapping[i], \n",
    "                texts[i], \n",
    "                sentiments[i]\n",
    "            )\n",
    "            \n",
    "            predictions.append(pred_text)\n",
    "\n",
    "print(f\"Generated {len(predictions)} predictions\")\n",
    "print(f\"Sample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"  {i+1}. {predictions[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62629e",
   "metadata": {},
   "source": [
    "## Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'textID': test_df['textID'],\n",
    "    'selected_text': predictions\n",
    "})\n",
    "\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Sample submission:\")\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission file\n",
    "submission_path = '/home/code/submission_candidates/candidate_002_roberta_test.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "\n",
    "# Verify file format\n",
    "print(f\"\\nFile verification:\")\n",
    "print(f\"- File exists: {Path(submission_path).exists()}\")\n",
    "print(f\"- File size: {Path(submission_path).stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"- Number of rows: {len(submission_df)}\")\n",
    "print(f\"- Expected rows: 3535\")\n",
    "print(f\"- Match: {len(submission_df) == 3535}\")\n",
    "\n",
    "# Check for any issues\n",
    "print(f\"\\nData quality checks:\")\n",
    "print(f\"- Missing predictions: {submission_df['selected_text'].isna().sum()}\")\n",
    "print(f\"- Empty predictions: {(submission_df['selected_text'] == '').sum()}\")\n",
    "\n",
    "# Show some examples by sentiment\n",
    "print(f\"\\nExamples by sentiment:\")\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    mask = test_df['sentiment'] == sentiment\n",
    "    sample_idx = test_df[mask].index[0]\n",
    "    print(f\"\\n{sentiment.upper()}:\")\n",
    "    print(f\"  Text: {test_df.loc[sample_idx, 'text'][:100]}...\")\n",
    "    print(f\"  Prediction: {submission_df.loc[sample_idx, 'selected_text'][:100]}...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
