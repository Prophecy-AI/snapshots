{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0909c47",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Extraction - Baseline Model\n",
    "\n",
    "This notebook implements a baseline approach for the tweet sentiment extraction competition.\n",
    "\n",
    "## Strategy\n",
    "1. Simple rule-based approach based on sentiment\n",
    "2. For positive/negative: extract the most relevant word/phrase\n",
    "3. For neutral: use the entire text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f52160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:15.000498Z",
     "iopub.status.busy": "2026-01-15T09:57:15.000151Z",
     "iopub.status.idle": "2026-01-15T09:57:16.263387Z",
     "shell.execute_reply": "2026-01-15T09:57:16.262544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (27481, 4)\n",
      "Test shape: (3534, 3)\n",
      "Sample submission shape: (3534, 2)\n",
      "\n",
      "Train data info:\n",
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                         selected_text sentiment  \n",
      "0  I`d have responded, if I were going   neutral  \n",
      "1                             Sooo SAD  negative  \n",
      "2                          bullying me  negative  \n",
      "3                       leave me alone  negative  \n",
      "4                        Sons of ****,  negative  \n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in train:\n",
      "textID           0\n",
      "text             1\n",
      "selected_text    1\n",
      "sentiment        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/home/data/train.csv')\n",
    "test_df = pd.read_csv('/home/data/test.csv')\n",
    "sample_submission = pd.read_csv('/home/data/sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nTrain data info:\")\n",
    "print(train_df.head())\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(train_df['sentiment'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values in train:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89c96b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:16.267291Z",
     "iopub.status.busy": "2026-01-15T09:57:16.267029Z",
     "iopub.status.idle": "2026-01-15T09:57:16.273210Z",
     "shell.execute_reply": "2026-01-15T09:57:16.272385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Jaccard function:\n",
      "jaccard('very good', 'very good'): 1.0\n",
      "jaccard('very good', 'good'): 0.5\n",
      "jaccard('very good', 'bad'): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define Jaccard score function for evaluation\n",
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c)) if (len(a) + len(b) - len(c)) > 0 else 0.0\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing Jaccard function:\")\n",
    "print(f\"jaccard('very good', 'very good'): {jaccard('very good', 'very good')}\")\n",
    "print(f\"jaccard('very good', 'good'): {jaccard('very good', 'good')}\")\n",
    "print(f\"jaccard('very good', 'bad'): {jaccard('very good', 'bad')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b72a6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:16.275604Z",
     "iopub.status.busy": "2026-01-15T09:57:16.275317Z",
     "iopub.status.idle": "2026-01-15T09:57:16.323026Z",
     "shell.execute_reply": "2026-01-15T09:57:16.322229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned data:\n",
      "                                                text  \\\n",
      "0                I`d have responded, if I were going   \n",
      "1      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2                          my boss is bullying me...   \n",
      "3                     what interview! leave me alone   \n",
      "4  Sons of ****, why couldn`t they put them on th...   \n",
      "\n",
      "                         selected_text sentiment  \n",
      "0  I`d have responded, if I were going   neutral  \n",
      "1                             Sooo SAD  negative  \n",
      "2                          bullying me  negative  \n",
      "3                       leave me alone  negative  \n",
      "4                        Sons of ****,  negative  \n"
     ]
    }
   ],
   "source": [
    "# Simple baseline: \n",
    "# - For neutral sentiment: use the entire text\n",
    "# - For positive/negative: extract the most relevant part\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing extra spaces and quotes\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    # Remove surrounding quotes if present\n",
    "    if text.startswith('\"') and text.endswith('\"'):\n",
    "        text = text[1:-1]\n",
    "    return text\n",
    "\n",
    "# Clean the text columns\n",
    "train_df['text'] = train_df['text'].apply(clean_text)\n",
    "train_df['selected_text'] = train_df['selected_text'].apply(clean_text)\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"Sample cleaned data:\")\n",
    "print(train_df[['text', 'selected_text', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45d397c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:16.325630Z",
     "iopub.status.busy": "2026-01-15T09:57:16.325004Z",
     "iopub.status.idle": "2026-01-15T09:57:16.439048Z",
     "shell.execute_reply": "2026-01-15T09:57:16.438182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing selected_text patterns by sentiment:\n",
      "\n",
      "=== POSITIVE ===\n",
      "Examples:\n",
      "  Text: '2am feedings for the baby are fun when he is all smiles and coos'\n",
      "  Selected: 'fun'\n",
      "\n",
      "  Text: 'Journey!? Wow... u just became cooler.  hehe... (is that possible!?)'\n",
      "  Selected: 'Wow... u just became cooler.'\n",
      "\n",
      "  Text: 'I really really like the song Love Story by Taylor Swift'\n",
      "  Selected: 'like'\n",
      "\n",
      "Avg text length: 69.9\n",
      "Avg selected length: 18.1\n",
      "Selected is full text: 13.0%\n",
      "\n",
      "=== NEGATIVE ===\n",
      "Examples:\n",
      "  Text: 'Sooo SAD I will miss you here in San Diego!!!'\n",
      "  Selected: 'Sooo SAD'\n",
      "\n",
      "  Text: 'my boss is bullying me...'\n",
      "  Selected: 'bullying me'\n",
      "\n",
      "  Text: 'what interview! leave me alone'\n",
      "  Selected: 'leave me alone'\n",
      "\n",
      "Avg text length: 70.1\n",
      "Avg selected length: 20.0\n",
      "Selected is full text: 14.7%\n",
      "\n",
      "=== NEUTRAL ===\n",
      "Examples:\n",
      "  Text: 'I`d have responded, if I were going'\n",
      "  Selected: 'I`d have responded, if I were going'\n",
      "\n",
      "  Text: 'http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth'\n",
      "  Selected: 'http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth'\n",
      "\n",
      "  Text: 'Soooo high'\n",
      "  Selected: 'Soooo high'\n",
      "\n",
      "Avg text length: 64.8\n",
      "Avg selected length: 62.8\n",
      "Selected is full text: 90.0%\n"
     ]
    }
   ],
   "source": [
    "# Analyze what selected_text looks like for each sentiment\n",
    "print(\"Analyzing selected_text patterns by sentiment:\")\n",
    "\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    print(f\"\\n=== {sentiment.upper()} ===\")\n",
    "    subset = train_df[train_df['sentiment'] == sentiment]\n",
    "    \n",
    "    # Show some examples\n",
    "    print(\"Examples:\")\n",
    "    for i in range(min(3, len(subset))):\n",
    "        row = subset.iloc[i]\n",
    "        print(f\"  Text: '{row['text']}'\")\n",
    "        print(f\"  Selected: '{row['selected_text']}'\")\n",
    "        print()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    text_lengths = subset['text'].str.len()\n",
    "    selected_lengths = subset['selected_text'].str.len()\n",
    "    \n",
    "    print(f\"Avg text length: {text_lengths.mean():.1f}\")\n",
    "    print(f\"Avg selected length: {selected_lengths.mean():.1f}\")\n",
    "    print(f\"Selected is full text: {(subset['text'] == subset['selected_text']).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8fc4ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:16.441959Z",
     "iopub.status.busy": "2026-01-15T09:57:16.441414Z",
     "iopub.status.idle": "2026-01-15T09:57:17.998482Z",
     "shell.execute_reply": "2026-01-15T09:57:17.997589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Jaccard score: 0.5481\n",
      "\n",
      "Sample predictions:\n",
      "Sentiment: negative\n",
      "Text: 'Know I`m not the only one.  Just harder on me.'\n",
      "Actual: 'st harde'\n",
      "Predicted: 'Know I`m not the only one'\n",
      "Score: 0.000\n",
      "---\n",
      "Sentiment: positive\n",
      "Text: 'wow, great to know a piece of software ensures our timely project delivery  #ProductNamingRulez'\n",
      "Actual: 'wow, great to know'\n",
      "Predicted: 'wow, great to know a piece of software ensures our timely project delivery  #ProductNamingRulez'\n",
      "Score: 0.286\n",
      "---\n",
      "Sentiment: neutral\n",
      "Text: 'good morning  6.15 am: plans for the day ...nope, nothing interesting'\n",
      "Actual: 'good morning  6.15 am: plans for the day ...nope, nothing interesting'\n",
      "Predicted: 'good morning  6.15 am: plans for the day ...nope, nothing interesting'\n",
      "Score: 1.000\n",
      "---\n",
      "Sentiment: neutral\n",
      "Text: 'The WHITE DICE are coming into the studio this eve 6-7pm, on 1386AM Radio City'\n",
      "Actual: 'The WHITE DICE are coming into the studio this eve 6-7pm, on 1386AM Radio City'\n",
      "Predicted: 'The WHITE DICE are coming into the studio this eve 6-7pm, on 1386AM Radio City'\n",
      "Score: 1.000\n",
      "---\n",
      "Sentiment: negative\n",
      "Text: 'I don`t think any of what i just said it true, i just had a rant about mcfly, i cant belive i did that  i feel ashamed'\n",
      "Actual: 'i feel ashamed'\n",
      "Predicted: 'I don`t think any of what i just said it true, i just had a rant about mcfly, i cant belive i did that  i feel ashamed'\n",
      "Score: 0.143\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Create a simple baseline model\n",
    "# For neutral: use full text\n",
    "# For positive/negative: use some simple heuristics\n",
    "\n",
    "def baseline_predict(text, sentiment):\n",
    "    \"\"\"Simple baseline prediction\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # For neutral sentiment, use the entire text\n",
    "    if sentiment == 'neutral':\n",
    "        return text\n",
    "    \n",
    "    # For positive/negative, try to extract key phrases\n",
    "    # Simple approach: look for sentiment words and extract around them\n",
    "    \n",
    "    words = text.split()\n",
    "    if len(words) <= 3:\n",
    "        return text\n",
    "    \n",
    "    # For very short texts, return the whole thing\n",
    "    if len(text) < 20:\n",
    "        return text\n",
    "    \n",
    "    # Otherwise, return a reasonable subset\n",
    "    # Try to extract the first sentence or first part\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    if sentences and sentences[0].strip():\n",
    "        first_sentence = sentences[0].strip()\n",
    "        if len(first_sentence) >= 10:\n",
    "            return first_sentence\n",
    "    \n",
    "    # Fallback: return first few words\n",
    "    return ' '.join(words[:min(5, len(words))])\n",
    "\n",
    "# Test on training data\n",
    "train_df['baseline_pred'] = train_df.apply(lambda row: baseline_predict(row['text'], row['sentiment']), axis=1)\n",
    "\n",
    "# Calculate Jaccard score\n",
    "scores = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    score = jaccard(row['selected_text'], row['baseline_pred'])\n",
    "    scores.append(score)\n",
    "\n",
    "train_df['jaccard_score'] = scores\n",
    "baseline_score = np.mean(scores)\n",
    "\n",
    "print(f\"Baseline Jaccard score: {baseline_score:.4f}\")\n",
    "\n",
    "# Show some predictions vs actuals\n",
    "print(\"\\nSample predictions:\")\n",
    "sample_idx = np.random.choice(len(train_df), 5, replace=False)\n",
    "for idx in sample_idx:\n",
    "    row = train_df.iloc[idx]\n",
    "    print(f\"Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Text: '{row['text']}'\")\n",
    "    print(f\"Actual: '{row['selected_text']}'\")\n",
    "    print(f\"Predicted: '{row['baseline_pred']}'\")\n",
    "    print(f\"Score: {row['jaccard_score']:.3f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3c54ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:18.001741Z",
     "iopub.status.busy": "2026-01-15T09:57:18.001007Z",
     "iopub.status.idle": "2026-01-15T09:57:18.098353Z",
     "shell.execute_reply": "2026-01-15T09:57:18.097517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample submission:\n",
      "       textID                                      selected_text\n",
      "0  f87dea47db  \"Last session of the day  http://twitpic.com/6...\n",
      "1  96d74cb729  \"Shanghai is also really exciting (precisely -...\n",
      "2  eee518ae67  \"Recession hit Veronique Branquinho, she has t...\n",
      "3  01082688c6                                      \"happy bday!\"\n",
      "4  33987a8ee5                                   \"http://twitpic\"\n",
      "\n",
      "Submission saved to /home/submission/submission.csv\n",
      "Shape: (3534, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "test_df['selected_text'] = test_df.apply(lambda row: baseline_predict(row['text'], row['sentiment']), axis=1)\n",
    "\n",
    "# Create submission file\n",
    "submission = test_df[['textID', 'selected_text']].copy()\n",
    "\n",
    "# Ensure the selected_text is properly quoted\n",
    "submission['selected_text'] = '\"' + submission['selected_text'].astype(str) + '\"'\n",
    "\n",
    "print(\"Sample submission:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('/home/submission/submission.csv', index=False)\n",
    "print(f\"\\nSubmission saved to /home/submission/submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546d44d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T09:57:18.101259Z",
     "iopub.status.busy": "2026-01-15T09:57:18.100547Z",
     "iopub.status.idle": "2026-01-15T09:57:19.585329Z",
     "shell.execute_reply": "2026-01-15T09:57:19.584755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.5481 ± 0.0046\n",
      "\n",
      "==================================================\n",
      "BASELINE MODEL RESULTS\n",
      "==================================================\n",
      "Training score: 0.5481\n",
      "CV score: 0.5481 ± 0.0046\n",
      "Test predictions: 3534 samples\n",
      "Submission saved: /home/submission/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate cross-validation score for more robust evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Simple CV to get a better estimate\n",
    "def cv_score(df, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        val_df = df.iloc[val_idx]\n",
    "        \n",
    "        # Predict on validation set\n",
    "        pred_scores = []\n",
    "        for _, row in val_df.iterrows():\n",
    "            pred = baseline_predict(row['text'], row['sentiment'])\n",
    "            score = jaccard(row['selected_text'], pred)\n",
    "            pred_scores.append(score)\n",
    "        \n",
    "        cv_scores.append(np.mean(pred_scores))\n",
    "    \n",
    "    return np.mean(cv_scores), np.std(cv_scores)\n",
    "\n",
    "cv_mean, cv_std = cv_score(train_df)\n",
    "print(f\"CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"BASELINE MODEL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Training score: {baseline_score:.4f}\")\n",
    "print(f\"CV score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"Test predictions: {len(test_df)} samples\")\n",
    "print(f\"Submission saved: /home/submission/submission.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
