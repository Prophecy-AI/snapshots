{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c96f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T22:19:15.019940Z",
     "iopub.status.busy": "2026-01-12T22:19:15.019219Z",
     "iopub.status.idle": "2026-01-12T22:19:20.179009Z",
     "shell.execute_reply": "2026-01-12T22:19:20.178401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 22500\n",
      "Cat images: 11242\n",
      "Dog images: 11258\n",
      "Test images: 2500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Set paths\n",
    "train_dir = '/home/data/train'\n",
    "test_dir = '/home/data/test'\n",
    "\n",
    "# Get list of training images\n",
    "train_files = os.listdir(train_dir)\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "\n",
    "# Separate cats and dogs\n",
    "cat_files = [f for f in train_files if f.startswith('cat')]\n",
    "dog_files = [f for f in train_files if f.startswith('dog')]\n",
    "\n",
    "print(f\"Cat images: {len(cat_files)}\")\n",
    "print(f\"Dog images: {len(dog_files)}\")\n",
    "\n",
    "# Check test images\n",
    "test_files = os.listdir(test_dir)\n",
    "print(f\"Test images: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image dimensions and characteristics\n",
    "def analyze_images(image_files, directory, sample_size=1000):\n",
    "    widths = []\n",
    "    heights = []\n",
    "    channels = []\n",
    "    file_sizes = []\n",
    "    \n",
    "    # Sample random images for analysis\n",
    "    sample_files = np.random.choice(image_files, min(sample_size, len(image_files)), replace=False)\n",
    "    \n",
    "    for img_file in sample_files:\n",
    "        try:\n",
    "            img_path = os.path.join(directory, img_file)\n",
    "            \n",
    "            # Get file size\n",
    "            file_sizes.append(os.path.getsize(img_path) / 1024)  # in KB\n",
    "            \n",
    "            # Open image\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                widths.append(width)\n",
    "                heights.append(height)\n",
    "                \n",
    "                # Get channels\n",
    "                if img.mode == 'RGB':\n",
    "                    channels.append(3)\n",
    "                elif img.mode == 'L':\n",
    "                    channels.append(1)\n",
    "                else:\n",
    "                    channels.append(len(img.getbands()))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "    \n",
    "    return widths, heights, channels, file_sizes\n",
    "\n",
    "# Analyze training images\n",
    "print(\"Analyzing training images...\")\n",
    "train_widths, train_heights, train_channels, train_sizes = analyze_images(train_files, train_dir)\n",
    "\n",
    "print(f\"Sample size: {len(train_widths)} images\")\n",
    "print(f\"Width - Mean: {np.mean(train_widths):.1f}, Std: {np.std(train_widths):.1f}\")\n",
    "print(f\"Height - Mean: {np.mean(train_heights):.1f}, Std: {np.std(train_heights):.1f}\")\n",
    "print(f\"File size (KB) - Mean: {np.mean(train_sizes):.1f}, Std: {np.std(train_sizes):.1f}\")\n",
    "print(f\"Channel distribution: {np.unique(train_channels, return_counts=True)}\")\n",
    "\n",
    "# Check aspect ratios\n",
    "aspect_ratios = np.array(train_widths) / np.array(train_heights)\n",
    "print(f\"Aspect ratio - Mean: {np.mean(aspect_ratios):.2f}, Std: {np.std(aspect_ratios):.2f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
