{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71db0549",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis: Dogs vs Cats Redux\n",
    "\n",
    "## Goals\n",
    "1. Analyze data distribution and image characteristics\n",
    "2. Examine baseline experiment results\n",
    "3. Identify key gaps and opportunities\n",
    "4. Establish proper validation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = \"/home/data\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "print(\"Loading data information...\")\n",
    "print(f\"Train directory: {TRAIN_DIR}\")\n",
    "print(f\"Test directory: {TEST_DIR}\")\n",
    "\n",
    "# Check directory contents\n",
    "train_files = os.listdir(TRAIN_DIR) if os.path.exists(TRAIN_DIR) else []\n",
    "test_files = os.listdir(TEST_DIR) if os.path.exists(TEST_DIR) else []\n",
    "\n",
    "print(f\"\\nTraining images: {len(train_files)}\")\n",
    "print(f\"Test images: {len(test_files)}\")\n",
    "\n",
    "# Sample some images to understand distribution\n",
    "if train_files:\n",
    "    sample_files = train_files[:10]\n",
    "    print(f\"\\nSample training files: {sample_files[:5]}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    dog_count = sum(1 for f in train_files if f.startswith('dog'))\n",
    "    cat_count = sum(1 for f in train_files if f.startswith('cat'))\n",
    "    \n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(f\"Dogs: {dog_count} ({dog_count/len(train_files)*100:.1f}%)\")\n",
    "    print(f\"Cats: {cat_count} ({cat_count/len(train_files)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78cdb4",
   "metadata": {},
   "source": [
    "## Image Characteristics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29219627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image sizes and characteristics\n",
    "def analyze_images(file_list, sample_size=500):\n",
    "    \"\"\"Analyze image dimensions and properties\"\"\"\n",
    "    if not file_list:\n",
    "        return None\n",
    "    \n",
    "    # Sample random images\n",
    "    sample_files = np.random.choice(file_list, min(sample_size, len(file_list)), replace=False)\n",
    "    \n",
    "    widths, heights, modes = [], [], []\n",
    "    \n",
    "    for filename in sample_files:\n",
    "        try:\n",
    "            img_path = os.path.join(TRAIN_DIR, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                widths.append(img.width)\n",
    "                heights.append(img.height)\n",
    "                modes.append(img.mode)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return {\n",
    "        'widths': widths,\n",
    "        'heights': heights,\n",
    "        'modes': modes,\n",
    "        'count': len(widths)\n",
    "    }\n",
    "\n",
    "# Analyze training images\n",
    "if train_files:\n",
    "    print(\"Analyzing training image characteristics...\")\n",
    "    train_analysis = analyze_images(train_files, sample_size=1000)\n",
    "    \n",
    "    if train_analysis:\n",
    "        print(f\"\\nAnalyzed {train_analysis['count']} images\")\n",
    "        print(f\"Width - Mean: {np.mean(train_analysis['widths']):.0f}, Std: {np.std(train_analysis['widths']):.0f}\")\n",
    "        print(f\"Height - Mean: {np.mean(train_analysis['heights']):.0f}, Std: {np.std(train_analysis['heights']):.0f}\")\n",
    "        print(f\"Min dimensions: {min(train_analysis['widths'])}x{min(train_analysis['heights'])}\")\n",
    "        print(f\"Max dimensions: {max(train_analysis['widths'])}x{max(train_analysis['heights'])}\")\n",
    "        \n",
    "        # Check color modes\n",
    "        mode_counts = {}\n",
    "        for mode in train_analysis['modes']:\n",
    "            mode_counts[mode] = mode_counts.get(mode, 0) + 1\n",
    "        \n",
    "        print(f\"\\nColor modes:\")\n",
    "        for mode, count in mode_counts.items():\n",
    "            print(f\"  {mode}: {count} ({count/len(train_analysis['modes'])*100:.1f}%)\")\n",
    "\n",
    "# Visualize size distribution\n",
    "if train_analysis:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(train_analysis['widths'], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title('Distribution of Image Widths')\n",
    "    plt.xlabel('Width (pixels)')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(train_analysis['heights'], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    plt.title('Distribution of Image Heights')\n",
    "    plt.xlabel('Height (pixels)')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8859d4",
   "metadata": {},
   "source": [
    "## Baseline Experiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze baseline experiment results\n",
    "baseline_path = \"/home/code/experiments/001_baseline_cnn.ipynb\"\n",
    "\n",
    "if os.path.exists(baseline_path):\n",
    "    print(\"Loading baseline experiment notebook...\")\n",
    "    \n",
    "    # Read the notebook to understand what was done\n",
    "    import json\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        nb = json.load(f)\n",
    "    \n",
    "    # Check model architecture from the code cells\n",
    "    architecture_found = False\n",
    "    for cell in nb['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            source = ''.join(cell['source'])\n",
    "            if 'class SimpleCNN' in source or 'nn.Conv2d' in source:\n",
    "                print(\"\\nModel architecture found:\")\n",
    "                print(source[:500] + \"...\" if len(source) > 500 else source)\n",
    "                architecture_found = True\n",
    "                break\n",
    "    \n",
    "    if not architecture_found:\n",
    "        print(\"Could not find model architecture in notebook\")\n",
    "else:\n",
    "    print(\"Baseline experiment notebook not found\")\n",
    "\n",
    "# Analyze the session state to understand performance\n",
    "session_path = \"/home/code/session_state.json\"\n",
    "if os.path.exists(session_path):\n",
    "    with open(session_path, 'r') as f:\n",
    "        session = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BASELINE EXPERIMENT SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if session['experiments']:\n",
    "        exp = session['experiments'][0]\n",
    "        print(f\"Experiment: {exp['name']}\")\n",
    "        print(f\"Score: {exp['score']:.4f}\")\n",
    "        print(f\"\\nNotes: {exp['notes']}\")\n",
    "        \n",
    "        # Key issues identified\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"KEY ISSUES IDENTIFIED\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"1. ⚠️  Overfitting: 98% train vs 86% validation accuracy\")\n",
    "        print(\"2. ⚠️  Numerical instability: NaN log loss\")\n",
    "        print(\"3. ⚠️  Timeout: Training interrupted\")\n",
    "        print(\"4. ⚠️  Simple architecture: No transfer learning\")\n",
    "        print(\"5. ⚠️  No data augmentation\")\n",
    "        print(\"6. ⚠️  Low resolution: 128x128 images\")\n",
    "else:\n",
    "    print(\"Session state not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346cf6a",
   "metadata": {},
   "source": [
    "## Validation Strategy Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design proper validation strategy for this competition\n",
    "print(\"DESIGNING VALIDATION STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For Dogs vs Cats, we need to consider:\n",
    "# 1. Class balance\n",
    "# 2. Image diversity\n",
    "# 3. Potential data leakage\n",
    "\n",
    "# Recommended approach: Stratified split preserving class distribution\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get all training files\n",
    "train_files = [f for f in os.listdir(TRAIN_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Create labels (0 for cat, 1 for dog)\n",
    "labels = [1 if f.startswith('dog') else 0 for f in train_files]\n",
    "\n",
    "print(f\"Total samples: {len(train_files)}\")\n",
    "print(f\"Class distribution: {sum(labels)} dogs, {len(labels)-sum(labels)} cats\")\n",
    "print(f\"Class ratio: {sum(labels)/len(labels):.3f} (should be ~0.5 for balanced)\")\n",
    "\n",
    "# Create stratified split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(train_files)),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nProposed split:\")\n",
    "print(f\"Training set: {len(train_idx)} images\")\n",
    "print(f\"Validation set: {len(val_idx)} images\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "train_labels = [labels[i] for i in train_idx]\n",
    "val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "print(f\"\\nTraining set - Dogs: {sum(train_labels)}, Cats: {len(train_labels)-sum(train_labels)}\")\n",
    "print(f\"Validation set - Dogs: {sum(val_labels)}, Cats: {len(val_labels)-sum(val_labels)}\")\n",
    "\n",
    "# Save split for reproducibility\n",
    "split_info = {\n",
    "    'train_files': [train_files[i] for i in train_idx],\n",
    "    'val_files': [train_files[i] for i in val_idx],\n",
    "    'train_labels': train_labels,\n",
    "    'val_labels': val_labels\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "import pickle\n",
    "with open('/home/code/splits/stratified_split_20pct.pkl', 'wb') as f:\n",
    "    pickle.dump(split_info, f)\n",
    "\n",
    "print(f\"\\n✓ Split saved to: /home/code/splits/stratified_split_20pct.pkl\")\n",
    "print(f\"✓ Use this split for all future experiments for consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05ec3f",
   "metadata": {},
   "source": [
    "## Key Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key findings\n",
    "print(\"KEY FINDINGS FROM ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. DATA CHARACTERISTICS:\")\n",
    "print(\"   - Balanced dataset (~50% dogs, 50% cats)\")\n",
    "print(\"   - Variable image sizes (need resizing)\")\n",
    "print(\"   - RGB images (3 channels)\")\n",
    "print(\"   - 22,503 training images\")\n",
    "\n",
    "print(\"\\n2. BASELINE PERFORMANCE:\")\n",
    "print(\"   - Score: 0.8602 (far from gold: 0.0388)\")\n",
    "print(\"   - Severe overfitting (98% → 86% accuracy)\")\n",
    "print(\"   - Numerical instability (NaN loss)\")\n",
    "print(\"   - Undertrained (only 2 epochs)\")\n",
    "\n",
    "print(\"\\n3. CRITICAL GAPS:\")\n",
    "print(\"   - ❌ No transfer learning (biggest issue)\")\n",
    "print(\"   - ❌ No data augmentation\")\n",
    "print(\"   - ❌ Low resolution (128x128)\")\n",
    "print(\"   - ❌ No regularization\")\n",
    "print(\"   - ❌ Simple architecture\")\n",
    "print(\"   - ❌ No proper validation split\")\n",
    "\n",
    "print(\"\\n4. IMMEDIATE OPPORTUNITIES:\")\n",
    "print(\"   - ✅ Transfer learning (ResNet, EfficientNet)\")\n",
    "print(\"   - ✅ Data augmentation (rotation, flip, color jitter)\")\n",
    "print(\"   - ✅ Higher resolution (224x224 or 299x299)\")\n",
    "print(\"   - ✅ Better optimizer & scheduler\")\n",
    "print(\"   - ✅ Proper validation strategy\")\n",
    "print(\"   - ✅ Ensemble methods\")\n",
    "\n",
    "print(\"\\n5. NEXT STEPS PRIORITY:\")\n",
    "print(\"   1. Implement transfer learning with ResNet/EfficientNet\")\n",
    "print(\"   2. Add aggressive data augmentation\")\n",
    "print(\"   3. Increase image resolution to 224x224\")\n",
    "print(\"   4. Fix numerical stability with proper loss handling\")\n",
    "print(\"   5. Train for more epochs with early stopping\")\n",
    "print(\"   6. Implement proper validation monitoring\")\n",
    "\n",
    "# Record findings\n",
    "from mlebench import RecordFinding\n",
    "\n",
    "RecordFinding(\n",
    "    finding=\"Dataset is balanced with ~50% dogs and 50% cats across 22,503 training images\",\n",
    "    source=\"exploration/evolver_loop1_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    finding=\"Baseline CNN severely overfits: 98% train accuracy vs 86% validation accuracy\",\n",
    "    source=\"exploration/evolver_loop1_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    finding=\"No transfer learning used in baseline - this is the biggest opportunity for improvement\",\n",
    "    source=\"exploration/evolver_loop1_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    finding=\"Numerical instability causing NaN log loss - need proper probability clipping\",\n",
    "    source=\"exploration/evolver_loop1_analysis.ipynb\"\n",
    ")\n",
    "\n",
    "RecordFinding(\n",
    "    finding=\"Stratified 80/20 split created for consistent validation across experiments\",\n",
    "    source=\"exploration/evolver_loop1_analysis.ipynb\"\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
