{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4fff2b9",
   "metadata": {},
   "source": [
    "# Evolver Loop 1 Analysis\n",
    "\n",
    "## Objective\n",
    "Analyze the baseline experiment results and verify the evaluator's observations about undertraining and model capacity constraints.\n",
    "\n",
    "## Key Questions\n",
    "1. Are the validation loss curves still decreasing at epoch 3?\n",
    "2. What's the learning rate behavior?\n",
    "3. How much capacity is left untapped by frozen layers?\n",
    "4. What are the misclassification patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74934c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:03:24.190628Z",
     "iopub.status.busy": "2026-01-13T17:03:24.190046Z",
     "iopub.status.idle": "2026-01-13T17:03:25.761968Z",
     "shell.execute_reply": "2026-01-13T17:03:25.761351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading session state and experiment data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Loading session state and experiment data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87b9799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:03:25.764098Z",
     "iopub.status.busy": "2026-01-13T17:03:25.763795Z",
     "iopub.status.idle": "2026-01-13T17:03:25.770237Z",
     "shell.execute_reply": "2026-01-13T17:03:25.769718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Experiments:\n",
      "- 001_baseline_cnn: 0.0479 (ResNet50, 3 epochs)\n",
      "\n",
      "Target Score: 0.0388\n",
      "Current Gap: 0.0091 (23.5% relative gap)\n",
      "\n",
      "Fold Scores: [0.0441, 0.0537, 0.0522, 0.0428, 0.0467]\n",
      "Std Dev: 0.0043 (reasonable variance)\n",
      "Range: 0.0109\n"
     ]
    }
   ],
   "source": [
    "# Load session state to see experiment details\n",
    "import json\n",
    "\n",
    "session_path = '/home/code/session_state.json'\n",
    "with open(session_path, 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(\"Current Experiments:\")\n",
    "for exp in session_state['experiments']:\n",
    "    print(f\"- {exp['name']}: {exp['score']:.4f} (ResNet50, 3 epochs)\")\n",
    "\n",
    "print(f\"\\nTarget Score: 0.0388\")\n",
    "print(f\"Current Gap: {0.0479 - 0.0388:.4f} ({(0.0479 - 0.0388) / 0.0388 * 100:.1f}% relative gap)\")\n",
    "\n",
    "# Show fold scores\n",
    "fold_scores = [0.0441, 0.0537, 0.0522, 0.0428, 0.0467]\n",
    "print(f\"\\nFold Scores: {fold_scores}\")\n",
    "print(f\"Std Dev: {np.std(fold_scores):.4f} (reasonable variance)\")\n",
    "print(f\"Range: {np.max(fold_scores) - np.min(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df911aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:03:25.771988Z",
     "iopub.status.busy": "2026-01-13T17:03:25.771797Z",
     "iopub.status.idle": "2026-01-13T17:03:25.788639Z",
     "shell.execute_reply": "2026-01-13T17:03:25.788098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Dynamics Analysis ===\n",
      "Training duration: 3 epochs per fold\n",
      "Mean validation log loss: 0.0479\n",
      "Best fold: 0.0428\n",
      "Worst fold: 0.0537\n",
      "\n",
      "=== Undertraining Assessment ===\n",
      "Evaluator's observation: 'Fold scores (0.0441 to 0.0428) are still decreasing'\n",
      "This suggests the model hasn't converged and is undertrained.\n",
      "\n",
      "If we assume linear improvement continues:\n",
      "- Current rate: ~0.0027 improvement per fold\n",
      "- Projected 10 epochs: potentially 0.0429\n",
      "- Projected 15 epochs: potentially 0.0399\n",
      "\n",
      "=== Gap Analysis ===\n",
      "Need to improve by: 0.0091\n",
      "This is a 19.0% relative improvement\n",
      "If training longer gives 0.008 improvement, we'd reach: 0.0399\n",
      "That would be ✗ BELOW gold threshold\n"
     ]
    }
   ],
   "source": [
    "# Analyze training dynamics from evaluator's observations\n",
    "# The evaluator noted that fold scores were still decreasing, suggesting undertraining\n",
    "\n",
    "fold_scores = [0.0441, 0.0537, 0.0522, 0.0428, 0.0467]\n",
    "epochs_per_fold = 3\n",
    "\n",
    "print(\"=== Training Dynamics Analysis ===\")\n",
    "print(f\"Training duration: {epochs_per_fold} epochs per fold\")\n",
    "print(f\"Mean validation log loss: {np.mean(fold_scores):.4f}\")\n",
    "print(f\"Best fold: {np.min(fold_scores):.4f}\")\n",
    "print(f\"Worst fold: {np.max(fold_scores):.4f}\")\n",
    "\n",
    "# The evaluator observed that validation loss was still decreasing\n",
    "# This is a critical finding - let's quantify the undertraining\n",
    "print(\"\\n=== Undertraining Assessment ===\")\n",
    "print(\"Evaluator's observation: 'Fold scores (0.0441 to 0.0428) are still decreasing'\")\n",
    "print(\"This suggests the model hasn't converged and is undertrained.\")\n",
    "print(f\"\\nIf we assume linear improvement continues:\")\n",
    "print(f\"- Current rate: ~{(0.0537 - 0.0428) / (5-1):.4f} improvement per fold\")\n",
    "print(f\"- Projected 10 epochs: potentially {np.mean(fold_scores) - 0.005:.4f}\")\n",
    "print(f\"- Projected 15 epochs: potentially {np.mean(fold_scores) - 0.008:.4f}\")\n",
    "\n",
    "# Check if we're close to target\n",
    "print(f\"\\n=== Gap Analysis ===\")\n",
    "print(f\"Need to improve by: {0.0479 - 0.0388:.4f}\")\n",
    "print(f\"This is a {(0.0479 - 0.0388) / 0.0479 * 100:.1f}% relative improvement\")\n",
    "print(f\"If training longer gives 0.008 improvement, we'd reach: {0.0479 - 0.008:.4f}\")\n",
    "print(f\"That would be {'✓ ABOVE' if 0.0479 - 0.008 <= 0.0388 else '✗ BELOW'} gold threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66035418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:03:25.790809Z",
     "iopub.status.busy": "2026-01-13T17:03:25.790341Z",
     "iopub.status.idle": "2026-01-13T17:03:25.852983Z",
     "shell.execute_reply": "2026-01-13T17:03:25.852398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Analysis ===\n",
      "Total training images: 22500\n",
      "Dog images: 11258\n",
      "Cat images: 11242\n",
      "Class balance: 50.0% dogs, 50.0% cats\n",
      "\n",
      "Sample image sizes: {(499, 351), (300, 315), (415, 480), (342, 418), (500, 282), (499, 375), (319, 240), (412, 230), (500, 374)}\n",
      "Note: Images have varying sizes, will be resized to 224x224 for ResNet\n"
     ]
    }
   ],
   "source": [
    "# Check data distribution and potential issues\n",
    "print(\"=== Data Analysis ===\")\n",
    "\n",
    "# Load a few sample images to understand quality\n",
    "TRAIN_DIR = '/home/data/train'\n",
    "train_files = [os.path.join(TRAIN_DIR, f) for f in os.listdir(TRAIN_DIR) if f.endswith('.jpg')]\n",
    "\n",
    "# Separate dogs and cats\n",
    "dog_files = [f for f in train_files if 'dog' in os.path.basename(f)]\n",
    "cat_files = [f for f in train_files if 'cat' in os.path.basename(f)]\n",
    "\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "print(f\"Dog images: {len(dog_files)}\")\n",
    "print(f\"Cat images: {len(cat_files)}\")\n",
    "print(f\"Class balance: {len(dog_files) / len(train_files) * 100:.1f}% dogs, {len(cat_files) / len(train_files) * 100:.1f}% cats\")\n",
    "\n",
    "# Check image sizes (potential issue for model input)\n",
    "sample_images = train_files[:10]\n",
    "sizes = []\n",
    "for img_path in sample_images:\n",
    "    with Image.open(img_path) as img:\n",
    "        sizes.append(img.size)\n",
    "\n",
    "print(f\"\\nSample image sizes: {set(sizes)}\")\n",
    "print(\"Note: Images have varying sizes, will be resized to 224x224 for ResNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9d514e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T17:03:25.855027Z",
     "iopub.status.busy": "2026-01-13T17:03:25.854828Z",
     "iopub.status.idle": "2026-01-13T17:03:25.859706Z",
     "shell.execute_reply": "2026-01-13T17:03:25.859177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Blind Spot Analysis ===\n",
      "1. No learning curves shown to verify convergence\n",
      "2. No analysis of misclassified images\n",
      "3. No test-time augmentation (TTA)\n",
      "4. No model ensembling beyond 5-fold average\n",
      "5. No exploration of other architectures\n",
      "6. No mention of image size optimization\n",
      "\n",
      "=== Priority Ranking ===\n",
      "1. ⭐⭐⭐ TRAINING DURATION (biggest bottleneck)\n",
      "2. ⭐⭐ PROGRESSIVE UNFREEZING (unlock capacity)\n",
      "3. ⭐⭐ LEARNING RATE TUNING (optimize training)\n",
      "4. ⭐ TEST-TIME AUGMENTATION (easy win)\n",
      "5. ⭐ HYPERPARAMETER SEARCH (refinement)\n",
      "6. Architecture exploration (if above plateau)\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the evaluator identified as blind spots\n",
    "print(\"=== Blind Spot Analysis ===\")\n",
    "\n",
    "blind_spots = [\n",
    "    \"No learning curves shown to verify convergence\",\n",
    "    \"No analysis of misclassified images\", \n",
    "    \"No test-time augmentation (TTA)\",\n",
    "    \"No model ensembling beyond 5-fold average\",\n",
    "    \"No exploration of other architectures\",\n",
    "    \"No mention of image size optimization\"\n",
    "]\n",
    "\n",
    "for i, spot in enumerate(blind_spots, 1):\n",
    "    print(f\"{i}. {spot}\")\n",
    "\n",
    "print(\"\\n=== Priority Ranking ===\")\n",
    "print(\"1. ⭐⭐⭐ TRAINING DURATION (biggest bottleneck)\")\n",
    "print(\"2. ⭐⭐ PROGRESSIVE UNFREEZING (unlock capacity)\")\n",
    "print(\"3. ⭐⭐ LEARNING RATE TUNING (optimize training)\")\n",
    "print(\"4. ⭐ TEST-TIME AUGMENTATION (easy win)\")\n",
    "print(\"5. ⭐ HYPERPARAMETER SEARCH (refinement)\")\n",
    "print(\"6. Architecture exploration (if above plateau)\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
