{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20412f20",
   "metadata": {},
   "source": [
    "# Baseline CNN Model - Dogs vs Cats\n",
    "\n",
    "## Experiment 001: Transfer Learning with ResNet\n",
    "\n",
    "This notebook implements a baseline CNN model using transfer learning for the Dogs vs Cats classification problem.\n",
    "\n",
    "### Approach:\n",
    "- Use pretrained ResNet50 model\n",
    "- 5-fold stratified cross-validation\n",
    "- Binary classification (dog vs cat)\n",
    "- Evaluation metric: Log Loss\n",
    "- Generate predictions for test set submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183fb27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:58:07.294390Z",
     "iopub.status.busy": "2026-01-13T15:58:07.293760Z",
     "iopub.status.idle": "2026-01-13T15:58:34.788622Z",
     "shell.execute_reply": "2026-01-13T15:58:34.787678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "GPU Memory: 85.1 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424fb987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:58:34.792366Z",
     "iopub.status.busy": "2026-01-13T15:58:34.791285Z",
     "iopub.status.idle": "2026-01-13T15:58:34.809204Z",
     "shell.execute_reply": "2026-01-13T15:58:34.808300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory exists: True\n",
      "Test directory exists: True\n",
      "Sample training files: ['dog.5.jpg', 'cat.8112.jpg', 'cat.1197.jpg', 'dog.8491.jpg', 'dog.9129.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_DIR = '/home/data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# Verify data exists\n",
    "print(f\"Train directory exists: {os.path.exists(TRAIN_DIR)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(TEST_DIR)}\")\n",
    "\n",
    "# List some training images\n",
    "train_files = os.listdir(TRAIN_DIR)[:5]\n",
    "print(f\"Sample training files: {train_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239e51ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:58:34.812006Z",
     "iopub.status.busy": "2026-01-13T15:58:34.811355Z",
     "iopub.status.idle": "2026-01-13T15:58:35.011552Z",
     "shell.execute_reply": "2026-01-13T15:58:35.010772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataset class\n",
    "class DogsCatsDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels=None, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        return image\n",
    "\n",
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba114bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:59:25.653966Z",
     "iopub.status.busy": "2026-01-13T15:59:25.653037Z",
     "iopub.status.idle": "2026-01-13T15:59:25.707868Z",
     "shell.execute_reply": "2026-01-13T15:59:25.707003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Total training images: 22500\n",
      "Dog images: 11258\n",
      "Cat images: 11242\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "print(\"Loading training data...\")\n",
    "train_files = [os.path.join(TRAIN_DIR, f) for f in os.listdir(TRAIN_DIR) if f.endswith('.jpg')]\n",
    "train_labels = [1 if 'dog' in os.path.basename(f) else 0 for f in train_files]\n",
    "\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "print(f\"Dog images: {sum(train_labels)}\")\n",
    "print(f\"Cat images: {len(train_labels) - sum(train_labels)}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "train_files = np.array(train_files)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb207b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:59:25.710146Z",
     "iopub.status.busy": "2026-01-13T15:59:25.709900Z",
     "iopub.status.idle": "2026-01-13T15:59:25.720155Z",
     "shell.execute_reply": "2026-01-13T15:59:25.719589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model function\n",
    "def create_model():\n",
    "    # Load pretrained ResNet50\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace final layer for binary classification\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=5):\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device).float()\n",
    "                output = model(data).squeeze()\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                val_preds.extend(output.cpu().numpy())\n",
    "                val_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_log_loss = log_loss(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}')\n",
    "        print(f'  Val Log Loss: {val_log_loss:.4f}')\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "    return model, val_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7da0f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:59:25.722305Z",
     "iopub.status.busy": "2026-01-13T15:59:25.721786Z",
     "iopub.status.idle": "2026-01-13T15:59:25.731963Z",
     "shell.execute_reply": "2026-01-13T15:59:25.731431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Starting 5-fold cross-validation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Store results\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(train_files))\n",
    "\n",
    "print(f\"\\nStarting {n_splits}-fold cross-validation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e134398b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T15:59:25.733783Z",
     "iopub.status.busy": "2026-01-13T15:59:25.733582Z",
     "iopub.status.idle": "2026-01-13T16:16:21.712738Z",
     "shell.execute_reply": "2026-01-13T16:16:21.711941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Training samples: 18000\n",
      "Validation samples: 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/nonroot/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 416k/97.8M [00:00<00:24, 4.22MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 4.66M/97.8M [00:00<00:03, 27.8MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 18.9M/97.8M [00:00<00:00, 83.0MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 33.1M/97.8M [00:00<00:00, 109MB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 47.4M/97.8M [00:00<00:00, 124MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 61.8M/97.8M [00:00<00:00, 133MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 76.0M/97.8M [00:00<00:00, 138MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 90.4M/97.8M [00:00<00:00, 142MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 120MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.1324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1430\n",
      "  Val Loss: 0.0531\n",
      "  Val Log Loss: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.1037\n",
      "  Val Loss: 0.0456\n",
      "  Val Log Loss: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0964\n",
      "  Val Loss: 0.0443\n",
      "  Val Log Loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Log Loss: 0.0441\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Training samples: 18000\n",
      "Validation samples: 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.1105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1453\n",
      "  Val Loss: 0.0656\n",
      "  Val Log Loss: 0.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.1944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.1361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0983\n",
      "  Val Loss: 0.0571\n",
      "  Val Log Loss: 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.2837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0933\n",
      "  Val Loss: 0.0536\n",
      "  Val Log Loss: 0.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Log Loss: 0.0537\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Training samples: 18000\n",
      "Validation samples: 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.0751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1476\n",
      "  Val Loss: 0.0635\n",
      "  Val Log Loss: 0.0635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.1166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.1499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0949\n",
      "  Val Loss: 0.0579\n",
      "  Val Log Loss: 0.0578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.1425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0960\n",
      "  Val Loss: 0.0521\n",
      "  Val Log Loss: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Log Loss: 0.0522\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Training samples: 18000\n",
      "Validation samples: 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.6881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1465\n",
      "  Val Loss: 0.0586\n",
      "  Val Log Loss: 0.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.1665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.1356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0989\n",
      "  Val Loss: 0.0461\n",
      "  Val Log Loss: 0.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.1213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0975\n",
      "  Val Loss: 0.0427\n",
      "  Val Log Loss: 0.0428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Log Loss: 0.0428\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Training samples: 18000\n",
      "Validation samples: 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.1105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1441\n",
      "  Val Loss: 0.0601\n",
      "  Val Log Loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.1090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.1022\n",
      "  Val Loss: 0.0558\n",
      "  Val Log Loss: 0.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.3858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0949\n",
      "  Val Loss: 0.0467\n",
      "  Val Log Loss: 0.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Log Loss: 0.0467\n",
      "\n",
      "==================================================\n",
      "CROSS-VALIDATION RESULTS\n",
      "==================================================\n",
      "Mean Log Loss: 0.0479 ± 0.0043\n",
      "Individual folds: [0.044094325701767995, 0.05371179078450418, 0.05216084367308546, 0.04278605528187914, 0.04670264739165255]\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(train_files, train_labels):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold}/{n_splits}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train_files[train_idx], train_files[val_idx]\n",
    "    y_train, y_val = train_labels[train_idx], train_labels[val_idx]\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DogsCatsDataset(X_train, y_train, transform=train_transform)\n",
    "    val_dataset = DogsCatsDataset(X_val, y_val, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    # Train model\n",
    "    model, val_score = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=3)\n",
    "    \n",
    "    # Store predictions\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data).squeeze()\n",
    "            val_preds.extend(output.cpu().numpy())\n",
    "    \n",
    "    oof_predictions[val_idx] = val_preds\n",
    "    cv_scores.append(val_score)\n",
    "    \n",
    "    print(f\"Fold {fold} Log Loss: {val_score:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Overall CV score\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CROSS-VALIDATION RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Mean Log Loss: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Individual folds: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a188206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T16:16:21.716047Z",
     "iopub.status.busy": "2026-01-13T16:16:21.715787Z",
     "iopub.status.idle": "2026-01-13T16:33:22.348092Z",
     "shell.execute_reply": "2026-01-13T16:33:22.347133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions on test set...\n",
      "Total test images: 2500\n",
      "Generating predictions from fold 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.0847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1518\n",
      "  Val Loss: 0.0809\n",
      "  Val Log Loss: 0.0805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.2242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0968\n",
      "  Val Loss: 0.0490\n",
      "  Val Log Loss: 0.0487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.4402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.3523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.1001\n",
      "  Val Loss: 0.0457\n",
      "  Val Log Loss: 0.0454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from fold 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.2978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1432\n",
      "  Val Loss: 0.0620\n",
      "  Val Log Loss: 0.0621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0965\n",
      "  Val Loss: 0.0567\n",
      "  Val Log Loss: 0.0568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0929\n",
      "  Val Loss: 0.0529\n",
      "  Val Log Loss: 0.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from fold 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.1747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.2432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1423\n",
      "  Val Loss: 0.0625\n",
      "  Val Log Loss: 0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.3836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.1014\n",
      "  Val Loss: 0.0540\n",
      "  Val Log Loss: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0957\n",
      "  Val Loss: 0.0584\n",
      "  Val Log Loss: 0.0584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from fold 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.2547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.0425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1461\n",
      "  Val Loss: 0.0580\n",
      "  Val Log Loss: 0.0581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.1249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.1078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.1639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0943\n",
      "  Val Loss: 0.0472\n",
      "  Val Log Loss: 0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.0518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.0327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0938\n",
      "  Val Loss: 0.0419\n",
      "  Val Log Loss: 0.0420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions from fold 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.7129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.2356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 200, Loss: 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 300, Loss: 0.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 400, Loss: 0.1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 500, Loss: 0.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "  Train Loss: 0.1442\n",
      "  Val Loss: 0.0669\n",
      "  Val Log Loss: 0.0670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 0.0695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 100, Loss: 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 200, Loss: 0.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 300, Loss: 0.0805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 400, Loss: 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 500, Loss: 0.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:\n",
      "  Train Loss: 0.0956\n",
      "  Val Loss: 0.0560\n",
      "  Val Log Loss: 0.0561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 0.0208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 100, Loss: 0.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 200, Loss: 0.0335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 300, Loss: 0.3463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 400, Loss: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 500, Loss: 0.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:\n",
      "  Train Loss: 0.0957\n",
      "  Val Loss: 0.0456\n",
      "  Val Log Loss: 0.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions shape: (2500,)\n",
      "Test predictions range: [0.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on test set\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "\n",
    "# Load test files\n",
    "test_files = [os.path.join(TEST_DIR, f) for f in sorted(os.listdir(TEST_DIR)) if f.endswith('.jpg')]\n",
    "test_ids = [int(os.path.splitext(os.path.basename(f))[0]) for f in test_files]\n",
    "\n",
    "print(f\"Total test images: {len(test_files)}\")\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = DogsCatsDataset(test_files, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Average predictions from all folds\n",
    "test_predictions = np.zeros(len(test_files))\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(train_files, train_labels):\n",
    "    print(f\"Generating predictions from fold {fold}...\")\n",
    "    \n",
    "    # Recreate and load model for this fold\n",
    "    model = create_model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create temporary training split to train model\n",
    "    X_train, X_val = train_files[train_idx], train_files[val_idx]\n",
    "    y_train, y_val = train_labels[train_idx], train_labels[val_idx]\n",
    "    \n",
    "    train_dataset = DogsCatsDataset(X_train, y_train, transform=train_transform)\n",
    "    val_dataset = DogsCatsDataset(X_val, y_val, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    # Train model\n",
    "    model, _ = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=3)\n",
    "    \n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data).squeeze()\n",
    "            fold_preds.extend(output.cpu().numpy())\n",
    "    \n",
    "    test_predictions += np.array(fold_preds)\n",
    "    fold += 1\n",
    "\n",
    "# Average predictions across folds\n",
    "test_predictions /= n_splits\n",
    "\n",
    "print(f\"Test predictions shape: {test_predictions.shape}\")\n",
    "print(f\"Test predictions range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5c4408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T16:33:22.352487Z",
     "iopub.status.busy": "2026-01-13T16:33:22.351733Z",
     "iopub.status.idle": "2026-01-13T16:33:22.456321Z",
     "shell.execute_reply": "2026-01-13T16:33:22.455743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating submission file...\n",
      "Submission shape: (2500, 2)\n",
      "Sample predictions:\n",
      "   id     label\n",
      "0   1  0.999861\n",
      "1   2  0.000488\n",
      "2   3  0.856156\n",
      "3   4  0.579628\n",
      "4   5  0.000111\n",
      "5   6  0.999985\n",
      "6   7  0.996927\n",
      "7   8  0.001029\n",
      "8   9  0.000088\n",
      "9  10  0.975234\n",
      "Submission saved to: /home/submission/submission.csv\n",
      "\n",
      "Submission format matches sample: True\n",
      "ID ranges match: True\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "print(\"\\nCreating submission file...\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Sort by id\n",
    "submission = submission.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"Sample predictions:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Save submission\n",
    "SUBMISSION_DIR = '/home/submission'\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "submission_path = os.path.join(SUBMISSION_DIR, 'submission.csv')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "\n",
    "# Verify submission format\n",
    "sample_sub = pd.read_csv('/home/data/sample_submission.csv')\n",
    "print(f\"\\nSubmission format matches sample: {list(submission.columns) == list(sample_sub.columns)}\")\n",
    "print(f\"ID ranges match: {submission['id'].min() == sample_sub['id'].min() and submission['id'].max() == sample_sub['id'].max()}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
