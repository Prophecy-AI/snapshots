{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabdb909",
   "metadata": {},
   "source": [
    "# Experiment 002: ResNet50 with Fine-Tuning and TTA\n",
    "\n",
    "**Objective**: Implement architecture upgrade with progressive fine-tuning and test-time augmentation to close the performance gap to gold.\n",
    "\n",
    "**Expected improvements:**\n",
    "- ResNet50 (2x parameters vs ResNet18): ~10-15% gain\n",
    "- Progressive fine-tuning: ~15-20% gain  \n",
    "- TTA (5 augmentations): ~5-10% gain\n",
    "- **Combined target**: 0.044-0.050 (30-40% improvement from baseline 0.0736)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9a8bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:53:55.781821Z",
     "iopub.status.busy": "2026-01-13T22:53:55.781025Z",
     "iopub.status.idle": "2026-01-13T22:54:00.141887Z",
     "shell.execute_reply": "2026-01-13T22:54:00.141134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "Memory: 85.1 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abef7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:54:00.144848Z",
     "iopub.status.busy": "2026-01-13T22:54:00.144034Z",
     "iopub.status.idle": "2026-01-13T22:54:00.167080Z",
     "shell.execute_reply": "2026-01-13T22:54:00.166488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 22500\n",
      "Dogs: 11258 (50.0%)\n",
      "Cats: 11242 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "train_dir = '/home/data/train'\n",
    "test_dir = '/home/data/test'\n",
    "\n",
    "# Get training data\n",
    "train_files = [f for f in os.listdir(train_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "train_labels = [1 if 'dog' in f.lower() else 0 for f in train_files]  # 1=dog, 0=cat\n",
    "\n",
    "print(f\"Training images: {len(train_files)}\")\n",
    "print(f\"Dogs: {sum(train_labels)} ({sum(train_labels)/len(train_labels):.1%})\")\n",
    "print(f\"Cats: {len(train_labels) - sum(train_labels)} ({1-sum(train_labels)/len(train_labels):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb50b8cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:54:00.169046Z",
     "iopub.status.busy": "2026-01-13T22:54:00.168845Z",
     "iopub.status.idle": "2026-01-13T22:54:00.177758Z",
     "shell.execute_reply": "2026-01-13T22:54:00.177208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset with advanced augmentations\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(train_dir, self.file_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Augmentation strategies\n",
    "def get_train_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_tta_transforms():\n",
    "    \"\"\"Test-time augmentation transforms\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed85be7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:54:00.179980Z",
     "iopub.status.busy": "2026-01-13T22:54:00.179745Z",
     "iopub.status.idle": "2026-01-13T22:54:00.193090Z",
     "shell.execute_reply": "2026-01-13T22:54:00.192413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model definition with progressive unfreezing capability\n",
    "class PetClassifier(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', pretrained=True):\n",
    "        super(PetClassifier, self).__init__()\n",
    "        \n",
    "        if backbone == 'resnet50':\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "        elif backbone == 'resnet18':\n",
    "            self.backbone = models.resnet18(pretrained=pretrained)\n",
    "            in_features = self.backbone.fc.in_features\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "        \n",
    "        # Replace final layer\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze all backbone layers\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze final layer\n",
    "        for param in self.backbone.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze_last_blocks(self, num_blocks=2):\n",
    "        \"\"\"Unfreeze last N residual blocks\"\"\"\n",
    "        # ResNet has 4 main layer groups: layer1, layer2, layer3, layer4\n",
    "        # layer4 is the last, layer3 is second to last, etc.\n",
    "        layers_to_unfreeze = []\n",
    "        if num_blocks >= 1:\n",
    "            layers_to_unfreeze.append(self.backbone.layer4)\n",
    "        if num_blocks >= 2:\n",
    "            layers_to_unfreeze.append(self.backbone.layer3)\n",
    "        if num_blocks >= 3:\n",
    "            layers_to_unfreeze.append(self.backbone.layer2)\n",
    "            \n",
    "        for layer in layers_to_unfreeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            all_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss = running_loss / len(dataloader.dataset)\n",
    "    val_log_loss = log_loss(all_labels, all_preds)\n",
    "    \n",
    "    return val_loss, val_log_loss, np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bf24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation setup\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "cv_scores = []\n",
    "fold_predictions = []\n",
    "fold_models = []\n",
    "\n",
    "# Training configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "early_stop_patience = 3\n",
    "max_epochs_phase1 = 3  # Train head only\n",
    "max_epochs_phase2 = 8  # Fine-tune with early stopping\n",
    "\n",
    "print(f\"\\nStarting {n_splits}-fold CV training...\")\n",
    "print(f\"Phase 1: Train head only ({max_epochs_phase1} epochs)\")\n",
    "print(f\"Phase 2: Fine-tune backbone ({max_epochs_phase2} epochs max)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_files, train_labels)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold + 1}/{n_splits}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_files_fold = [train_files[i] for i in train_idx]\n",
    "    train_labels_fold = [train_labels[i] for i in train_idx]\n",
    "    val_files_fold = [train_files[i] for i in val_idx]\n",
    "    val_labels_fold = [train_labels[i] for i in val_idx]\n",
    "    \n",
    "    print(f\"Train: {len(train_files_fold)} images\")\n",
    "    print(f\"Val: {len(val_files_fold)} images\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = PetDataset(train_files_fold, train_labels_fold, transform=get_train_transforms())\n",
    "    val_dataset = PetDataset(val_files_fold, val_labels_fold, transform=get_val_transforms())\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    # Create model\n",
    "    model = PetClassifier(backbone='resnet50', pretrained=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Loss function (with label smoothing)\n",
    "    class LabelSmoothingBCE(nn.Module):\n",
    "        def __init__(self, smoothing=0.1):\n",
    "            super().__init__()\n",
    "            self.smoothing = smoothing\n",
    "            self.bce = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        def forward(self, outputs, targets):\n",
    "            targets = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "            return self.bce(outputs, targets)\n",
    "    \n",
    "    criterion = LabelSmoothingBCE(smoothing=0.1)\n",
    "    \n",
    "    # === PHASE 1: Train head only (frozen backbone) ===\n",
    "    print(f\"\\nPhase 1: Training head only...\")\n",
    "    model.freeze_backbone()\n",
    "    \n",
    "    # Only optimize the final layer\n",
    "    head_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.AdamW(head_params, lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs_phase1)\n",
    "    \n",
    "    for epoch in range(max_epochs_phase1):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_log_loss, _, _ = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{max_epochs_phase1} - Train Loss: {train_loss:.4f}, Val Log Loss: {val_log_loss:.4f}\")\n",
    "    \n",
    "    # === PHASE 2: Fine-tune backbone ===\n",
    "    print(f\"\\nPhase 2: Fine-tuning backbone...\")\n",
    "    model.unfreeze_last_blocks(num_blocks=2)  # Unfreeze last 2 blocks\n",
    "    \n",
    "    # Different learning rates for backbone and head\n",
    "    backbone_params = [p for n, p in model.named_parameters() if 'fc' not in n and p.requires_grad]\n",
    "    head_params = [p for n, p in model.named_parameters() if 'fc' in n and p.requires_grad]\n",
    "    \n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': 0.0001},\n",
    "        {'params': head_params, 'lr': 0.001}\n",
    "    ], weight_decay=0.01)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    best_val_log_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(max_epochs_phase2):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_log_loss, _, _ = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step(val_log_loss)\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{max_epochs_phase2} - Train Loss: {train_loss:.4f}, Val Log Loss: {val_log_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_log_loss < best_val_log_loss:\n",
    "            best_val_log_loss = val_log_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"  → New best: {val_log_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(f\"  → Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final validation\n",
    "    _, final_val_log_loss, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
    "    print(f\"\\nFold {fold + 1} Final Val Log Loss: {final_val_log_loss:.4f}\")\n",
    "    \n",
    "    cv_scores.append(final_val_log_loss)\n",
    "    fold_models.append(model)\n",
    "    \n",
    "    # Clean up\n",
    "    del train_dataset, val_dataset, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CROSS-VALIDATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mean CV Log Loss: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-time augmentation (TTA) predictions\n",
    "print(f\"\\nGenerating TTA predictions on test set...\")\n",
    "\n",
    "# Get test files\n",
    "test_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(f\"Test images: {len(test_files)}\")\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(test_dir, self.file_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, self.file_paths[idx]\n",
    "\n",
    "# Number of TTA augmentations per image\n",
    "n_tta = 5\n",
    "tta_predictions = []\n",
    "\n",
    "for fold, model in enumerate(fold_models):\n",
    "    print(f\"\\nProcessing fold {fold + 1}/{len(fold_models)}...\")\n",
    "    model.eval()\n",
    "    \n",
    "    fold_tta_preds = np.zeros((len(test_files), n_tta))\n",
    "    \n",
    "    for tta_idx in range(n_tta):\n",
    "        print(f\"  TTA augmentation {tta_idx + 1}/{n_tta}\")\n",
    "        \n",
    "        # Create dataset with TTA transforms\n",
    "        test_dataset = TestDataset(test_files, transform=get_tta_transforms())\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        \n",
    "        fold_preds = []\n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images).squeeze()\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                fold_preds.extend(probs)\n",
    "        \n",
    "        fold_tta_preds[:, tta_idx] = fold_preds\n",
    "        \n",
    "        # Clean up\n",
    "        del test_dataset, test_loader\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average TTA predictions for this fold\n",
    "    fold_avg_preds = np.mean(fold_tta_preds, axis=1)\n",
    "    tta_predictions.append(fold_avg_preds)\n",
    "\n",
    "# Average predictions across all folds\n",
    "final_predictions = np.mean(tta_predictions, axis=0)\n",
    "print(f\"\\nFinal predictions shape: {final_predictions.shape}\")\n",
    "print(f\"Prediction range: [{final_predictions.min():.4f}, {final_predictions.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "print(f\"\\nCreating submission file...\")\n",
    "\n",
    "# Load sample submission to get format\n",
    "sample_submission_path = '/home/data/sample_submission.csv'\n",
    "if os.path.exists(sample_submission_path):\n",
    "    sample_submission = pd.read_csv(sample_submission_path)\n",
    "    print(f\"Sample submission columns: {sample_submission.columns.tolist()}\")\n",
    "    print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "    \n",
    "    # Create submission with same format\n",
    "    submission = pd.DataFrame({\n",
    "        'id': [f.split('.')[0] for f in test_files],  # Remove file extension\n",
    "        'label': final_predictions\n",
    "    })\n",
    "    \n",
    "    # Ensure correct column order\n",
    "    submission = submission[['id', 'label']]\n",
    "else:\n",
    "    # Fallback if no sample submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': [f.split('.')[0] for f in test_files],\n",
    "        'label': final_predictions\n",
    "    })\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_002.csv'\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 5 predictions:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EXPERIMENT 002 SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Model: ResNet50 with progressive fine-tuning\")\n",
    "print(f\"Augmentations: RandomResizedCrop, Flip, Rotation, ColorJitter\")\n",
    "print(f\"Training: {max_epochs_phase1} epochs (head) + {max_epochs_phase2} epochs (fine-tune)\")\n",
    "print(f\"TTA: {n_tta} augmentations per image\")\n",
    "print(f\"CV Score: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Submission: {submission_path}\")\n",
    "print(f\"Improvement from baseline: {((0.0736 - np.mean(cv_scores)) / 0.0736 * 100):.1f}%\")\n",
    "print(f\"Remaining gap to gold: {np.mean(cv_scores) - 0.0388:.4f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
