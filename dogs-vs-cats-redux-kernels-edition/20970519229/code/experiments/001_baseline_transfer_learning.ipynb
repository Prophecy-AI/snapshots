{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f383a09",
   "metadata": {},
   "source": [
    "# Dogs vs Cats - Baseline Transfer Learning\n",
    "\n",
    "This notebook implements a baseline using transfer learning with a pretrained CNN backbone.\n",
    "\n",
    "## Approach\n",
    "1. Load and explore the data\n",
    "2. Use Stratified K-Fold validation\n",
    "3. Fine-tune a pretrained ResNet model\n",
    "4. Generate predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data information\n",
    "train_dir = '/home/data/train'\n",
    "test_dir = '/home/data/test'\n",
    "\n",
    "# Get training images and labels\n",
    "train_files = []\n",
    "train_labels = []\n",
    "\n",
    "for filename in os.listdir(train_dir):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        train_files.append(filename)\n",
    "        # Label: 1 for dog, 0 for cat\n",
    "        label = 1 if 'dog' in filename.lower() else 0\n",
    "        train_labels.append(label)\n",
    "\n",
    "print(f\"Found {len(train_files)} training images\")\n",
    "print(f\"Dog images: {sum(train_labels)}\")\n",
    "print(f\"Cat images: {len(train_labels) - sum(train_labels)}\")\n",
    "\n",
    "# Get test images\n",
    "test_files = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(f\"Found {len(test_files)} test images\")\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "train_df = pd.DataFrame({\n",
    "    'filename': train_files,\n",
    "    'label': train_labels\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_files\n",
    "})\n",
    "\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class DogsCatsDataset(Dataset):\n",
    "    def __init__(self, dataframe, directory, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.directory, self.dataframe.iloc[idx]['filename'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image\n",
    "        else:\n",
    "            label = self.dataframe.iloc[idx]['label']\n",
    "            return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef87d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class using pretrained ResNet\n",
    "def create_model():\n",
    "    # Load pretrained ResNet18\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze all layers initially\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the final layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5102bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=5):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} - Training'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} - Validation'):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop with cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "\n",
    "# Convert to numpy for sklearn\n",
    "X = train_df['filename'].values\n",
    "y = train_df['label'].values\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Store predictions from each fold for test set\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/5\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create fold datasets\n",
    "    train_fold_df = train_df.iloc[train_idx]\n",
    "    val_fold_df = train_df.iloc[val_idx]\n",
    "    \n",
    "    train_dataset = DogsCatsDataset(train_fold_df, train_dir, transform=train_transform)\n",
    "    val_dataset = DogsCatsDataset(val_fold_df, train_dir, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Create and setup model\n",
    "    model = create_model()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    # Train model\n",
    "    model, val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=5)\n",
    "    \n",
    "    # Calculate fold log loss\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).squeeze().cpu().numpy()\n",
    "            val_preds.extend(outputs)\n",
    "            val_true.extend(labels.numpy())\n",
    "    \n",
    "    # Calculate log loss for this fold\n",
    "    from sklearn.metrics import log_loss\n",
    "    fold_log_loss = log_loss(val_true, val_preds)\n",
    "    fold_scores.append(fold_log_loss)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Log Loss: {fold_log_loss:.4f}\")\n",
    "    \n",
    "    # Predict on test set\n",
    "    test_dataset = DogsCatsDataset(test_df, test_dir, transform=test_transform, is_test=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    fold_test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader, desc=f'Predicting on test set - Fold {fold + 1}'):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).squeeze().cpu().numpy()\n",
    "            fold_test_preds.extend(outputs)\n",
    "    \n",
    "    # Add to ensemble predictions\n",
    "    test_predictions += np.array(fold_test_preds)\n",
    "\n",
    "# Average predictions across folds\n",
    "test_predictions /= 5\n",
    "\n",
    "# Calculate overall CV score\n",
    "cv_score = np.mean(fold_scores)\n",
    "cv_std = np.std(fold_scores)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CROSS-VALIDATION RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Mean Log Loss: {cv_score:.4f} Â± {cv_std:.4f}\")\n",
    "print(f\"Individual folds: {fold_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ab0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': [int(f.split('.')[0]) for f in test_df['filename']],\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Sort by id to match expected format\n",
    "submission_df = submission_df.sort_values('id')\n",
    "\n",
    "print(\"Submission file preview:\")\n",
    "print(submission_df.head())\n",
    "print(f\"\\nTotal predictions: {len(submission_df)}\")\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission.csv'\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
