{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9b2f10",
   "metadata": {},
   "source": [
    "# Evolver Loop 2: Training Dynamics Analysis\n",
    "\n",
    "## Goal\n",
    "Analyze why ResNet50 with fine-tuning and TTA only achieved 2.4% improvement instead of expected 30-40%.\n",
    "\n",
    "## Key Questions\n",
    "1. Are the training dynamics healthy (convergence, overfitting, stability)?\n",
    "2. Is the optimization configuration appropriate (LR, schedule, batch size)?\n",
    "3. Are there data loading or augmentation issues?\n",
    "4. What hyperparameters need tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load session state to understand experiment history\n",
    "with open('/home/code/session_state.json', 'r') as f:\n",
    "    session_state = json.load(f)\n",
    "\n",
    "print(\"=== EXPERIMENT SUMMARY ===\")\n",
    "print(f\"Total experiments: {len(session_state['experiments'])}\")\n",
    "print(f\"Best CV score: {min([exp['score'] for exp in session_state['experiments']]):.4f}\")\n",
    "print(f\"Baseline (exp_000): 0.0736\")\n",
    "print(f\"Best (exp_006): 0.0718\")\n",
    "print(f\"Improvement: {(0.0736 - 0.0718) / 0.0736 * 100:.1f}%\")\n",
    "print(f\"Gap to gold: {0.0718 - 0.038820:.4f}\")\n",
    "print(f\"Improvement needed: {(0.0718 - 0.038820) / 0.0718 * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fold-level details from exp_006 (ResNet50 fine-tuning)\n",
    "# Based on the notebook output we saw\n",
    "\n",
    "fold_results = {\n",
    "    'fold': [1, 2, 3, 4, 5],\n",
    "    'final_val_loss': [0.0742, 0.0679, 0.0705, 0.0735, 0.0728],\n",
    "    'best_val_loss': [0.0650, 0.0681, 0.0673, 0.0621, 0.0700],  # From training logs\n",
    "    'epochs_trained': [4, 8, 4, 5, 7],  # When early stopping triggered\n",
    "    'phase1_epochs': [3, 3, 3, 3, 3],  # Fixed at 3\n",
    "    'phase2_epochs': [1, 5, 1, 2, 4]   # Total - phase1\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(fold_results)\n",
    "print(\"=== FOLD-LEVEL ANALYSIS ===\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "print(\"=== KEY METRICS ===\")\n",
    "print(f\"Mean final loss: {df['final_val_loss'].mean():.4f} ± {df['final_val_loss'].std():.4f}\")\n",
    "print(f\"Mean best loss: {df['best_val_loss'].mean():.4f} ± {df['best_val_loss'].std():.4f}\")\n",
    "print(f\"Mean epochs trained: {df['epochs_trained'].mean():.1f}\")\n",
    "print()\n",
    "\n",
    "# Calculate degradation from best to final\n",
    "df['degradation'] = df['final_val_loss'] - df['best_val_loss']\n",
    "print(f\"Mean degradation from best to final: {df['degradation'].mean():.4f}\")\n",
    "print(f\"Max degradation: {df['degradation'].max():.4f} (fold {df.loc[df['degradation'].idxmax(), 'fold']})\")\n",
    "print()\n",
    "\n",
    "# Check if early stopping is too aggressive\n",
    "early_stopped_folds = sum(1 for epochs in df['epochs_trained'] if epochs < 8)\n",
    "print(f\"Folds that early stopped: {early_stopped_folds}/5\")\n",
    "print(f\"Average Phase 2 epochs when early stopped: {df[df['epochs_trained'] < 8]['phase2_epochs'].mean():.1f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
