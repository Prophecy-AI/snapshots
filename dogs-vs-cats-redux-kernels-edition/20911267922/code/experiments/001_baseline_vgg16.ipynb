{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ed9ef5",
   "metadata": {},
   "source": [
    "# Baseline Model: VGG16 Transfer Learning\n",
    "\n",
    "This notebook implements a baseline model using VGG16 transfer learning for the Dogs vs Cats classification problem.\n",
    "\n",
    "## Strategy\n",
    "- Use VGG16 pretrained on ImageNet\n",
    "- Freeze base layers, train custom head\n",
    "- Data augmentation to prevent overfitting\n",
    "- Stratified validation split\n",
    "- Binary cross-entropy loss (matches log loss evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a196a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T09:05:36.982930Z",
     "iopub.status.busy": "2026-01-12T09:05:36.982238Z",
     "iopub.status.idle": "2026-01-12T09:05:41.280772Z",
     "shell.execute_reply": "2026-01-12T09:05:41.280133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 09:05:38.699637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-12 09:05:38.724155: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-12 09:05:38.731047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8afb3d3",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08c939b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T09:05:41.283665Z",
     "iopub.status.busy": "2026-01-12T09:05:41.282808Z",
     "iopub.status.idle": "2026-01-12T09:05:41.329260Z",
     "shell.execute_reply": "2026-01-12T09:05:41.328711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 22500\n",
      "Dog images: 11258\n",
      "Cat images: 11242\n",
      "Class balance: 0.500\n",
      "\n",
      "First 10 files and labels:\n",
      "dog.5.jpg: 1 (dog=True)\n",
      "cat.8112.jpg: 0 (dog=False)\n",
      "cat.1197.jpg: 0 (dog=False)\n",
      "dog.8491.jpg: 1 (dog=True)\n",
      "dog.9129.jpg: 1 (dog=True)\n",
      "cat.116.jpg: 0 (dog=False)\n",
      "cat.5347.jpg: 0 (dog=False)\n",
      "dog.5627.jpg: 1 (dog=True)\n",
      "cat.1316.jpg: 0 (dog=False)\n",
      "dog.9329.jpg: 1 (dog=True)\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "TRAIN_PATH = '/home/data/train/'\n",
    "TEST_PATH = '/home/data/test/'\n",
    "SAMPLE_SUBMISSION_PATH = '/home/data/sample_submission.csv'\n",
    "\n",
    "# Get all training images\n",
    "train_files = os.listdir(TRAIN_PATH)\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "\n",
    "# Create labels from filenames (1 = dog, 0 = cat)\n",
    "train_labels = []\n",
    "train_paths = []\n",
    "\n",
    "for file in train_files:\n",
    "    if file.startswith('dog'):\n",
    "        train_labels.append(1)  # dog\n",
    "    elif file.startswith('cat'):\n",
    "        train_labels.append(0)  # cat\n",
    "    else:\n",
    "        continue\n",
    "    train_paths.append(os.path.join(TRAIN_PATH, file))\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "print(f\"Dog images: {sum(train_labels)}\")\n",
    "print(f\"Cat images: {len(train_labels) - sum(train_labels)}\")\n",
    "print(f\"Class balance: {sum(train_labels) / len(train_labels):.3f}\")\n",
    "\n",
    "# Check a few samples\n",
    "print(f\"\\nFirst 10 files and labels:\")\n",
    "for i in range(10):\n",
    "    print(f\"{os.path.basename(train_paths[i])}: {train_labels[i]} (dog={train_labels[i]==1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2736c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T09:06:19.093394Z",
     "iopub.status.busy": "2026-01-12T09:06:19.092814Z",
     "iopub.status.idle": "2026-01-12T09:06:19.112576Z",
     "shell.execute_reply": "2026-01-12T09:06:19.111991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 18000\n",
      "Validation samples: 4500\n",
      "Training class balance: 0.500\n",
      "Validation class balance: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Create stratified split\n",
    "X_train_paths, X_val_paths, y_train, y_val = train_test_split(\n",
    "    train_paths, train_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=train_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train_paths)}\")\n",
    "print(f\"Validation samples: {len(X_val_paths)}\")\n",
    "print(f\"Training class balance: {y_train.mean():.3f}\")\n",
    "print(f\"Validation class balance: {y_val.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd10ccc",
   "metadata": {},
   "source": [
    "## Create Data Generators with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0f5a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T09:06:19.115027Z",
     "iopub.status.busy": "2026-01-12T09:06:19.114434Z",
     "iopub.status.idle": "2026-01-12T09:06:19.123561Z",
     "shell.execute_reply": "2026-01-12T09:06:19.122916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# No augmentation for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "def create_generator(file_paths, labels, datagen, batch_size=32, shuffle=True):\n",
    "    while True:\n",
    "        indices = np.arange(len(file_paths))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_paths = [file_paths[i] for i in batch_indices]\n",
    "            batch_labels = labels[batch_indices]\n",
    "            \n",
    "            batch_images = []\n",
    "            for path in batch_paths:\n",
    "                img = tf.keras.preprocessing.image.load_img(\n",
    "                    path, target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "                )\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                img_array = datagen.random_transform(img_array)\n",
    "                batch_images.append(img_array)\n",
    "            \n",
    "            yield np.array(batch_images), batch_labels\n",
    "\n",
    "train_generator = create_generator(X_train_paths, y_train, train_datagen, BATCH_SIZE, shuffle=True)\n",
    "val_generator = create_generator(X_val_paths, y_val, val_datagen, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0625d",
   "metadata": {},
   "source": [
    "## Build VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    '/home/code/models/vgg16_baseline.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f30a3",
   "metadata": {},
   "source": [
    "# Load VGG16 without top layers\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "# Freeze base layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build custom head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b75680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 without top layers\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "# Freeze base layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build custom head\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_steps = len(X_train_paths) // BATCH_SIZE\n",
    "val_steps = len(X_val_paths) // BATCH_SIZE\n",
    "\n",
    "print(f\"Training steps per epoch: {train_steps}\")\n",
    "print(f\"Validation steps per epoch: {val_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e22897",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    '/home/code/models/vgg16_baseline.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[checkpoint_cb, early_stop_cb, reduce_lr_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca10076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax2.set_title('Model Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate validation log loss\n",
    "print(\"\\nCalculating validation log loss...\")\n",
    "val_predictions = []\n",
    "val_true = []\n",
    "\n",
    "for i in range(val_steps):\n",
    "    batch_images, batch_labels = next(val_generator)\n",
    "    preds = model.predict(batch_images, verbose=0)\n",
    "    val_predictions.extend(preds.flatten())\n",
    "    val_true.extend(batch_labels)\n",
    "\n",
    "val_log_loss = log_loss(val_true, val_predictions)\n",
    "print(f\"Validation Log Loss: {val_log_loss:.6f}\")\n",
    "\n",
    "# Also calculate accuracy\n",
    "val_predictions_binary = [1 if p > 0.5 else 0 for p in val_predictions]\n",
    "accuracy = np.mean([p == t for p, t in zip(val_predictions_binary, val_true)])\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbf1ba",
   "metadata": {},
   "source": [
    "## Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8002223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "test_files = sorted([f for f in os.listdir(TEST_PATH) if f.endswith('.jpg')])\n",
    "print(f\"Total test images: {len(test_files)}\")\n",
    "\n",
    "# Create test generator (no augmentation, only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def test_generator():\n",
    "    for file in test_files:\n",
    "        path = os.path.join(TEST_PATH, file)\n",
    "        img = tf.keras.preprocessing.image.load_img(\n",
    "            path, target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "        )\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = test_datagen.standardize(img_array)\n",
    "        yield np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Predict on test set\n",
    "print(\"Generating test predictions...\")\n",
    "test_predictions = []\n",
    "\n",
    "for i, test_img in enumerate(test_generator()):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processed {i}/{len(test_files)} images\")\n",
    "    pred = model.predict(test_img, verbose=0)\n",
    "    test_predictions.append(pred[0][0])\n",
    "\n",
    "print(f\"Generated {len(test_predictions)} predictions\")\n",
    "print(f\"Prediction range: {min(test_predictions):.4f} to {max(test_predictions):.4f}\")\n",
    "\n",
    "# Clip predictions to avoid log(0) errors\n",
    "test_predictions = np.clip(test_predictions, 1e-7, 1-1e-7)\n",
    "print(f\"After clipping - Min: {min(test_predictions):.6f}, Max: {max(test_predictions):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(1, len(test_predictions) + 1),\n",
    "    'label': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = '/home/submission/submission_001_vgg16_baseline.csv'\n",
    "os.makedirs('/home/submission', exist_ok=True)\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"\\nSubmission head:\")\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission tail:\")\n",
    "print(submission.tail())\n",
    "\n",
    "# Verify format matches sample\n",
    "sample_submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "print(f\"\\nSample submission format:\")\n",
    "print(sample_submission.head())\n",
    "print(f\"\\nOur submission matches format: {list(submission.columns) == list(sample_submission.columns)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
